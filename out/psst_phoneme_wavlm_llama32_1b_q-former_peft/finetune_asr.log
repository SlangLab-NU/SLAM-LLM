[2024-12-14 22:54:58,927][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 22:54:58,927][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 22:54:58,927][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'q-former', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 22:54:58,928][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_q-former_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_22-54-58.txt', 'log_interval': 5}
[2024-12-14 22:55:19,852][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 22:55:31,725][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 22:55:31,729][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 22:55:31,739][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 22:55:31,742][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 22:55:39,557][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 22:55:39,559][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 22:55:39,561][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 22:55:39,884][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 22:55:39,887][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 23:08:03,557][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 23:08:03,558][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 23:08:03,558][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'q-former', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 23:08:03,558][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_q-former_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_23-08-02.txt', 'log_interval': 5}
[2024-12-14 23:08:23,349][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 23:08:35,435][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 23:08:35,439][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 23:08:35,443][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 23:08:35,445][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 23:08:40,820][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 23:08:40,822][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 23:08:40,824][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 23:08:41,141][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 23:08:41,144][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 23:08:43,099][slam_llm.utils.train_utils][INFO] - --> Module q-former
[2024-12-14 23:08:43,100][slam_llm.utils.train_utils][INFO] - --> q-former has 69.361152 Million params

[2024-12-14 23:08:43,104][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 23:08:43,111][slam_llm.utils.train_utils][INFO] - --> asr has 74.997248 Million params

[2024-12-14 23:08:43,129][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 23:08:45,713][root][INFO] - --> Training Set Length = 2298
[2024-12-14 23:08:45,733][root][INFO] - --> Validation Set Length = 341
[2024-12-14 23:08:45,734][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 23:08:45,747][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 23:11:45,544][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-12-14 23:11:45,544][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-14 23:11:45,544][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'q-former', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-14 23:11:45,544][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_q-former_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-14_23-11-45.txt', 'log_interval': 5}
[2024-12-14 23:12:07,213][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-14 23:12:13,326][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 23:12:13,329][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-14 23:12:13,331][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-14 23:12:13,332][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-14 23:12:21,884][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 23:12:21,886][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-14 23:12:21,886][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-14 23:12:22,218][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-14 23:12:22,220][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-14 23:12:23,197][slam_llm.utils.train_utils][INFO] - --> Module q-former
[2024-12-14 23:12:23,198][slam_llm.utils.train_utils][INFO] - --> q-former has 69.361152 Million params

[2024-12-14 23:12:23,198][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-14 23:12:23,203][slam_llm.utils.train_utils][INFO] - --> asr has 74.997248 Million params

[2024-12-14 23:12:25,855][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-14 23:12:27,626][root][INFO] - --> Training Set Length = 2298
[2024-12-14 23:12:27,635][root][INFO] - --> Validation Set Length = 341
[2024-12-14 23:12:27,635][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 23:12:27,636][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-14 23:12:30,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:32,360][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-14 23:12:33,672][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 9.432172775268555, acc: 0.0)
[2024-12-14 23:12:33,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:34,150][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.965145111083984, acc: 0.0)
[2024-12-14 23:12:34,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:34,777][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 8.755611419677734, acc: 0.0)
[2024-12-14 23:12:34,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:35,224][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 8.907881736755371, acc: 0.0)
[2024-12-14 23:12:35,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:35,661][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 8.446645736694336, acc: 0.0)
[2024-12-14 23:12:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:36,070][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 8.717354774475098, acc: 0.0)
[2024-12-14 23:12:36,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:36,468][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 9.766287803649902, acc: 0.0)
[2024-12-14 23:12:36,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:36,877][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 8.962587356567383, acc: 0.0)
[2024-12-14 23:12:37,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:37,311][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.377982139587402, acc: 0.0)
[2024-12-14 23:12:37,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:37,710][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.938060283660889, acc: 0.0)
[2024-12-14 23:12:37,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:38,195][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.498176574707031, acc: 0.0)
[2024-12-14 23:12:38,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:38,642][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.920761585235596, acc: 0.0)
[2024-12-14 23:12:38,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:39,048][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 8.472966194152832, acc: 0.0)
[2024-12-14 23:12:39,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:39,440][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 7.779067516326904, acc: 0.0)
[2024-12-14 23:12:39,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:39,849][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 8.094391822814941, acc: 0.0)
[2024-12-14 23:12:40,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:40,305][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 7.7338457107543945, acc: 0.0)
[2024-12-14 23:12:40,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:40,737][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.035343170166016, acc: 0.0)
[2024-12-14 23:12:40,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:41,166][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 7.952836990356445, acc: 0.0)
[2024-12-14 23:12:41,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:41,672][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.801975727081299, acc: 0.0555555559694767)
[2024-12-14 23:12:41,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:42,147][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 7.649000644683838, acc: 0.0)
[2024-12-14 23:12:42,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:42,583][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 7.748695373535156, acc: 0.0)
[2024-12-14 23:12:42,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:43,029][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 6.828909873962402, acc: 0.0)
[2024-12-14 23:12:43,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:43,522][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.326292514801025, acc: 0.03999999910593033)
[2024-12-14 23:12:43,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:43,963][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.335209846496582, acc: 0.0476190485060215)
[2024-12-14 23:12:44,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:44,400][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.15012264251709, acc: 0.0)
[2024-12-14 23:12:44,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:44,882][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.163818359375, acc: 0.0)
[2024-12-14 23:12:45,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:45,294][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.950125217437744, acc: 0.04109589010477066)
[2024-12-14 23:12:45,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:46,586][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 6.003938674926758, acc: 0.03952569141983986)
[2024-12-14 23:12:46,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:46,994][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.654535293579102, acc: 0.023255813866853714)
[2024-12-14 23:12:47,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:47,397][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.726014137268066, acc: 0.012048192322254181)
[2024-12-14 23:12:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:47,895][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.809398651123047, acc: 0.03703703731298447)
[2024-12-14 23:12:48,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:48,351][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 6.572152614593506, acc: 0.0)
[2024-12-14 23:12:48,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:48,792][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 5.932079315185547, acc: 0.03703703731298447)
[2024-12-14 23:12:48,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:49,183][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.302097320556641, acc: 0.0)
[2024-12-14 23:12:49,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:49,609][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.810123920440674, acc: 0.03361344709992409)
[2024-12-14 23:12:49,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:50,088][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.473064422607422, acc: 0.016393441706895828)
[2024-12-14 23:12:50,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:50,589][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.456342697143555, acc: 0.0476190485060215)
[2024-12-14 23:12:50,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:51,100][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 5.843177318572998, acc: 0.0)
[2024-12-14 23:12:51,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:51,557][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 4.877491474151611, acc: 0.19540229439735413)
[2024-12-14 23:12:51,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:51,990][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 6.069716930389404, acc: 0.0476190485060215)
[2024-12-14 23:12:52,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:52,388][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 5.3476057052612305, acc: 0.03846153989434242)
[2024-12-14 23:12:52,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:52,860][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.01586389541626, acc: 0.14864864945411682)
[2024-12-14 23:12:52,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:53,281][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.3499956130981445, acc: 0.0923076942563057)
[2024-12-14 23:12:53,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:53,830][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.116357803344727, acc: 0.1515151560306549)
[2024-12-14 23:12:54,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:54,346][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.652550220489502, acc: 0.19587628543376923)
[2024-12-14 23:12:54,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:54,825][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 4.970384120941162, acc: 0.07352941483259201)
[2024-12-14 23:12:54,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:55,233][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 6.18774938583374, acc: 0.0)
[2024-12-14 23:12:55,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:55,627][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 5.356935501098633, acc: 0.03703703731298447)
[2024-12-14 23:12:55,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:56,111][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 5.584947109222412, acc: 0.0357142873108387)
[2024-12-14 23:12:56,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:56,616][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 5.103577613830566, acc: 0.0833333358168602)
[2024-12-14 23:12:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:57,082][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 4.899393558502197, acc: 0.12280701845884323)
[2024-12-14 23:12:57,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:57,486][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 4.777531623840332, acc: 0.095238097012043)
[2024-12-14 23:12:57,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:57,893][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.208542823791504, acc: 0.0845070406794548)
[2024-12-14 23:12:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:58,460][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.672780513763428, acc: 0.1599999964237213)
[2024-12-14 23:12:58,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:58,919][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 5.386204719543457, acc: 0.054054055362939835)
[2024-12-14 23:12:59,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:12:59,327][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 4.880285739898682, acc: 0.03846153989434242)
[2024-12-14 23:13:01,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:02,513][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.444706678390503, acc: 0.31740614771842957)
[2024-12-14 23:13:03,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:03,808][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.639136552810669, acc: 0.2505446672439575)
[2024-12-14 23:13:04,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:04,582][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 4.085344314575195, acc: 0.21590909361839294)
[2024-12-14 23:13:04,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:05,206][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.055598735809326, acc: 0.25)
[2024-12-14 23:13:05,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:05,816][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 3.9902312755584717, acc: 0.21739129722118378)
[2024-12-14 23:13:05,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:06,335][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 3.8986053466796875, acc: 0.25)
[2024-12-14 23:13:06,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:06,760][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 4.58811092376709, acc: 0.0)
[2024-12-14 23:13:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:07,280][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 4.755514144897461, acc: 0.1666666716337204)
[2024-12-14 23:13:07,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:07,703][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 3.500624179840088, acc: 0.28125)
[2024-12-14 23:13:07,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:08,201][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 3.8338515758514404, acc: 0.24137930572032928)
[2024-12-14 23:13:08,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:08,649][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.187092304229736, acc: 0.2678571343421936)
[2024-12-14 23:13:08,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:09,150][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 4.178192138671875, acc: 0.10000000149011612)
[2024-12-14 23:13:09,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:09,659][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 4.289112091064453, acc: 0.1599999964237213)
[2024-12-14 23:13:09,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:10,114][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 4.215208053588867, acc: 0.2222222238779068)
[2024-12-14 23:13:10,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:10,536][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 4.827484607696533, acc: 0.1515151560306549)
[2024-12-14 23:13:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:10,938][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 3.851459264755249, acc: 0.2867647111415863)
[2024-12-14 23:13:11,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:11,295][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 3.6530048847198486, acc: 0.2222222238779068)
[2024-12-14 23:13:11,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:11,686][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.013451099395752, acc: 0.2153846174478531)
[2024-12-14 23:13:11,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:12,061][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 4.645686149597168, acc: 0.0714285746216774)
[2024-12-14 23:13:12,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:12,471][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.224233150482178, acc: 0.1268656700849533)
[2024-12-14 23:13:12,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:12,929][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.7471327781677246, acc: 0.23357664048671722)
[2024-12-14 23:13:13,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:13,290][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 4.293557643890381, acc: 0.1428571492433548)
[2024-12-14 23:13:13,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:13,725][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 4.301147937774658, acc: 0.1666666716337204)
[2024-12-14 23:13:13,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:14,159][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 4.04702615737915, acc: 0.09090909361839294)
[2024-12-14 23:13:14,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:14,590][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 3.98530912399292, acc: 0.1538461595773697)
[2024-12-14 23:13:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:15,010][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.224813938140869, acc: 0.13461539149284363)
[2024-12-14 23:13:15,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:15,400][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 4.141175270080566, acc: 0.21153846383094788)
[2024-12-14 23:13:15,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:15,793][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 3.602919101715088, acc: 0.15625)
[2024-12-14 23:13:15,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:16,196][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.009211540222168, acc: 0.17391304671764374)
[2024-12-14 23:13:16,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:16,606][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 3.649301528930664, acc: 0.2800000011920929)
[2024-12-14 23:13:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:17,006][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 3.9995980262756348, acc: 0.1304347813129425)
[2024-12-14 23:13:17,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:17,576][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 3.950563669204712, acc: 0.2199999988079071)
[2024-12-14 23:13:17,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:18,009][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.2891907691955566, acc: 0.3106796145439148)
[2024-12-14 23:13:18,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:19,160][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.394589900970459, acc: 0.30582523345947266)
[2024-12-14 23:13:19,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:20,044][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 3.5165457725524902, acc: 0.2634408473968506)
[2024-12-14 23:13:20,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:20,959][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.103957414627075, acc: 0.38793104887008667)
[2024-12-14 23:13:21,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:21,758][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.311540126800537, acc: 0.34736841917037964)
[2024-12-14 23:13:22,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:22,855][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 3.5736875534057617, acc: 0.2574257552623749)
[2024-12-14 23:13:22,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:23,258][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 3.535886764526367, acc: 0.16129031777381897)
[2024-12-14 23:13:23,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:23,655][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 3.7810072898864746, acc: 0.17391304671764374)
[2024-12-14 23:13:23,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:24,091][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 3.832181215286255, acc: 0.1764705926179886)
[2024-12-14 23:13:24,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:24,548][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 3.570384979248047, acc: 0.25)
[2024-12-14 23:13:24,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:25,028][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 3.5550625324249268, acc: 0.2700729966163635)
[2024-12-14 23:13:25,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:25,467][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.185622692108154, acc: 0.1492537260055542)
[2024-12-14 23:13:25,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:25,864][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 3.9353840351104736, acc: 0.10000000149011612)
[2024-12-14 23:13:26,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:26,335][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 3.5003180503845215, acc: 0.22727273404598236)
[2024-12-14 23:13:26,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:26,751][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 2.7711379528045654, acc: 0.30434781312942505)
[2024-12-14 23:13:26,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:27,166][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 3.1813621520996094, acc: 0.3181818127632141)
[2024-12-14 23:13:27,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:27,604][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 3.5255990028381348, acc: 0.18965516984462738)
[2024-12-14 23:13:27,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:28,044][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 3.54611873626709, acc: 0.1860465109348297)
[2024-12-14 23:13:28,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:28,530][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 2.8221402168273926, acc: 0.4000000059604645)
[2024-12-14 23:13:28,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:28,944][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.631974697113037, acc: 0.1764705926179886)
[2024-12-14 23:13:29,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:29,327][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.354145050048828, acc: 0.23076923191547394)
[2024-12-14 23:13:29,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:29,843][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 3.593325614929199, acc: 0.2142857164144516)
[2024-12-14 23:13:30,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:30,342][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 3.6893506050109863, acc: 0.26153847575187683)
[2024-12-14 23:13:30,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:30,850][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.3958327770233154, acc: 0.28070175647735596)
[2024-12-14 23:13:31,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:31,327][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.3595361709594727, acc: 0.28070175647735596)
[2024-12-14 23:13:31,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:31,730][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.642731189727783, acc: 0.3333333432674408)
[2024-12-14 23:13:31,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:32,225][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 2.942359209060669, acc: 0.36734694242477417)
[2024-12-14 23:13:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:32,756][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.2044265270233154, acc: 0.3181818127632141)
[2024-12-14 23:13:32,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:33,194][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 2.9195749759674072, acc: 0.30158731341362)
[2024-12-14 23:13:33,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:33,627][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.1376986503601074, acc: 0.3008130192756653)
[2024-12-14 23:13:33,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:34,045][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.1133456230163574, acc: 0.32258063554763794)
[2024-12-14 23:13:34,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:35,011][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 2.9360361099243164, acc: 0.3079847991466522)
[2024-12-14 23:13:35,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:35,458][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 2.911423921585083, acc: 0.36000001430511475)
[2024-12-14 23:13:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:35,959][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 3.2928507328033447, acc: 0.2884615361690521)
[2024-12-14 23:13:36,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:36,340][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.632143020629883, acc: 0.25)
[2024-12-14 23:13:36,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:36,767][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 2.96008563041687, acc: 0.2631579041481018)
[2024-12-14 23:13:36,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:37,220][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.2193925380706787, acc: 0.2699386477470398)
[2024-12-14 23:13:37,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:37,669][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.5339395999908447, acc: 0.4166666567325592)
[2024-12-14 23:13:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:38,091][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.0354857444763184, acc: 0.25)
[2024-12-14 23:13:38,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:38,526][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.0009632110595703, acc: 0.261904776096344)
[2024-12-14 23:13:38,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:38,942][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.1416428089141846, acc: 0.28717949986457825)
[2024-12-14 23:13:39,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:39,416][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.603804588317871, acc: 0.3970588147640228)
[2024-12-14 23:13:39,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:39,820][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.054246664047241, acc: 0.3076923191547394)
[2024-12-14 23:13:39,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:40,227][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.540257453918457, acc: 0.43478259444236755)
[2024-12-14 23:13:40,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:40,626][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.390416145324707, acc: 0.21875)
[2024-12-14 23:13:40,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:41,046][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 3.059919595718384, acc: 0.30434781312942505)
[2024-12-14 23:13:41,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:41,481][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.770977258682251, acc: 0.3142857253551483)
[2024-12-14 23:13:41,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:41,885][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.6459972858428955, acc: 0.3076923191547394)
[2024-12-14 23:13:42,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:42,306][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.282959461212158, acc: 0.261904776096344)
[2024-12-14 23:13:42,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:42,745][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.2307958602905273, acc: 0.5)
[2024-12-14 23:13:42,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:43,115][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.4007551670074463, acc: 0.3913043439388275)
[2024-12-14 23:13:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:43,583][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 3.7973432540893555, acc: 0.3333333432674408)
[2024-12-14 23:13:43,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:44,051][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.015986919403076, acc: 0.3461538553237915)
[2024-12-14 23:13:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:44,568][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.4551453590393066, acc: 0.12903225421905518)
[2024-12-14 23:13:44,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:45,025][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.4343581199645996, acc: 0.1621621549129486)
[2024-12-14 23:13:45,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:46,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:47,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:47,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:47,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:48,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:48,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:49,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:49,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:49,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:50,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:50,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:51,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:51,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:52,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:52,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:52,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:53,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:53,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:53,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:54,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:54,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:55,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:56,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:56,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:57,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:57,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:57,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:58,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:58,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:59,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:13:59,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:00,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:00,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:00,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:01,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:01,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:02,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:02,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:03,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:03,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:03,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:04,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:04,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:05,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:05,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:05,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:06,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:06,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:07,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:08,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:08,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:09,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:09,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:09,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:10,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:10,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:11,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:11,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:12,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:12,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:12,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:13,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:13,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:14,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:14,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:14,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:15,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:15,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:16,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:17,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:17,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:18,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:18,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:19,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:20,031][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.0043, device='cuda:0') eval_epoch_loss=tensor(2.9959, device='cuda:0') eval_epoch_acc=tensor(0.2749, device='cuda:0')
[2024-12-14 23:14:20,032][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:14:20,033][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:14:20,764][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_1_step_143_loss_2.995948314666748/model.pt
[2024-12-14 23:14:20,769][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:14:20,770][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.995948314666748
[2024-12-14 23:14:20,771][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.27486321330070496
[2024-12-14 23:14:20,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:21,382][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 2.5704569816589355, acc: 0.41228070855140686)
[2024-12-14 23:14:21,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:21,787][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 2.381939172744751, acc: 0.44029849767684937)
[2024-12-14 23:14:21,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:22,271][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 3.0460803508758545, acc: 0.26530611515045166)
[2024-12-14 23:14:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:22,795][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.6590967178344727, acc: 0.3723404109477997)
[2024-12-14 23:14:22,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:23,183][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.5562894344329834, acc: 0.4000000059604645)
[2024-12-14 23:14:23,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:23,596][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.205070972442627, acc: 0.25)
[2024-12-14 23:14:23,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:23,978][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.5939579010009766, acc: 0.3913043439388275)
[2024-12-14 23:14:24,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:24,339][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.05407977104187, acc: 0.24137930572032928)
[2024-12-14 23:14:24,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:24,733][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.863431453704834, acc: 0.30434781312942505)
[2024-12-14 23:14:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:25,113][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.6284821033477783, acc: 0.3050847351551056)
[2024-12-14 23:14:25,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:25,464][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.0497519969940186, acc: 0.2631579041481018)
[2024-12-14 23:14:25,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:25,871][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.7532925605773926, acc: 0.31081080436706543)
[2024-12-14 23:14:26,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:26,271][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.7045352458953857, acc: 0.3928571343421936)
[2024-12-14 23:14:26,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:26,630][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.279914617538452, acc: 0.43478259444236755)
[2024-12-14 23:14:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:26,964][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 2.786139726638794, acc: 0.21052631735801697)
[2024-12-14 23:14:27,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:28,647][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 2.988956928253174, acc: 0.3918918967247009)
[2024-12-14 23:14:28,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:29,124][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 2.930494785308838, acc: 0.3333333432674408)
[2024-12-14 23:14:29,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:29,619][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 2.8544654846191406, acc: 0.3720930218696594)
[2024-12-14 23:14:29,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:30,274][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.659609079360962, acc: 0.4000000059604645)
[2024-12-14 23:14:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:30,891][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 2.832113265991211, acc: 0.3258427083492279)
[2024-12-14 23:14:31,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:31,303][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.5933516025543213, acc: 0.3863636255264282)
[2024-12-14 23:14:31,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:31,767][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.887342929840088, acc: 0.3333333432674408)
[2024-12-14 23:14:31,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:32,269][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.0141680240631104, acc: 0.2068965584039688)
[2024-12-14 23:14:32,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:32,690][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 2.155803918838501, acc: 0.4897959232330322)
[2024-12-14 23:14:32,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:33,065][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.4044911861419678, acc: 0.3199999928474426)
[2024-12-14 23:14:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:33,490][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.47109055519104, acc: 0.4166666567325592)
[2024-12-14 23:14:33,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:33,887][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.429838180541992, acc: 0.343137264251709)
[2024-12-14 23:14:34,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:34,950][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 2.937852144241333, acc: 0.3493150770664215)
[2024-12-14 23:14:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:35,309][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 2.65106463432312, acc: 0.375)
[2024-12-14 23:14:35,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:35,641][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 2.982288122177124, acc: 0.25925925374031067)
[2024-12-14 23:14:35,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:36,018][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 2.6617934703826904, acc: 0.3571428656578064)
[2024-12-14 23:14:36,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:36,616][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 2.403045654296875, acc: 0.44247788190841675)
[2024-12-14 23:14:36,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:37,097][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 2.9136979579925537, acc: 0.260869562625885)
[2024-12-14 23:14:37,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:37,555][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 2.8779327869415283, acc: 0.25)
[2024-12-14 23:14:37,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:38,519][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 2.9528350830078125, acc: 0.2977099120616913)
[2024-12-14 23:14:38,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:39,254][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 3.0319888591766357, acc: 0.24444444477558136)
[2024-12-14 23:14:39,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:39,651][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 2.720362424850464, acc: 0.2786885201931)
[2024-12-14 23:14:39,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:40,031][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 2.330869674682617, acc: 0.2916666567325592)
[2024-12-14 23:14:40,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:40,412][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.673595666885376, acc: 0.4000000059604645)
[2024-12-14 23:14:40,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:40,752][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 2.744875192642212, acc: 0.25)
[2024-12-14 23:14:40,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:41,139][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 3.0625858306884766, acc: 0.23170731961727142)
[2024-12-14 23:14:41,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:41,535][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 2.939826250076294, acc: 0.2839879095554352)
[2024-12-14 23:14:41,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:41,916][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 2.9407835006713867, acc: 0.23919308185577393)
[2024-12-14 23:14:42,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:42,472][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.0232691764831543, acc: 0.265625)
[2024-12-14 23:14:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:43,034][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.7510299682617188, acc: 0.2795497179031372)
[2024-12-14 23:14:43,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:43,495][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 2.7519989013671875, acc: 0.30604982376098633)
[2024-12-14 23:14:43,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:43,863][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.850599765777588, acc: 0.3199999928474426)
[2024-12-14 23:14:44,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:44,454][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.885272264480591, acc: 0.2906976640224457)
[2024-12-14 23:14:44,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:45,335][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.776658773422241, acc: 0.3333333432674408)
[2024-12-14 23:14:45,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:46,277][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.700575351715088, acc: 0.3712121248245239)
[2024-12-14 23:14:46,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:47,044][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.2992632389068604, acc: 0.4117647111415863)
[2024-12-14 23:14:47,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:48,168][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.359590530395508, acc: 0.395061731338501)
[2024-12-14 23:14:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:49,146][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.2679920196533203, acc: 0.4032258093357086)
[2024-12-14 23:14:49,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:49,494][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 2.4522876739501953, acc: 0.3214285671710968)
[2024-12-14 23:14:49,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:49,869][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 2.822380542755127, acc: 0.2750000059604645)
[2024-12-14 23:14:50,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:50,245][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 3.235581398010254, acc: 0.20588235557079315)
[2024-12-14 23:14:50,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:50,622][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 2.6432814598083496, acc: 0.3602941036224365)
[2024-12-14 23:14:50,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:51,032][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 2.8070261478424072, acc: 0.32203391194343567)
[2024-12-14 23:14:51,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:51,405][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 2.7268388271331787, acc: 0.34328359365463257)
[2024-12-14 23:14:51,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:51,831][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 2.916093587875366, acc: 0.291262149810791)
[2024-12-14 23:14:51,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:52,217][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 2.601410388946533, acc: 0.380952388048172)
[2024-12-14 23:14:52,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:52,606][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 2.7263240814208984, acc: 0.23076923191547394)
[2024-12-14 23:14:52,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:53,023][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.6946358680725098, acc: 0.2959641218185425)
[2024-12-14 23:14:53,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:53,472][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 2.583176374435425, acc: 0.36614173650741577)
[2024-12-14 23:14:53,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:53,865][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 2.6412672996520996, acc: 0.31896552443504333)
[2024-12-14 23:14:53,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:54,261][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 2.464648962020874, acc: 0.39855071902275085)
[2024-12-14 23:14:54,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:54,679][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 2.7425715923309326, acc: 0.29182878136634827)
[2024-12-14 23:14:54,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:55,083][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 2.8758394718170166, acc: 0.30434781312942505)
[2024-12-14 23:14:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:55,473][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 2.79359769821167, acc: 0.30434781312942505)
[2024-12-14 23:14:55,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:55,819][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 2.961400270462036, acc: 0.1785714328289032)
[2024-12-14 23:14:55,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:56,238][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 2.587613344192505, acc: 0.23404255509376526)
[2024-12-14 23:14:56,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:56,955][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 2.63382625579834, acc: 0.2846153974533081)
[2024-12-14 23:14:57,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:57,336][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 2.528156280517578, acc: 0.22972972691059113)
[2024-12-14 23:14:57,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:57,725][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 2.5670902729034424, acc: 0.3604651093482971)
[2024-12-14 23:14:57,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:58,305][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 2.5029609203338623, acc: 0.3963963985443115)
[2024-12-14 23:14:58,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:58,777][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 2.4981703758239746, acc: 0.35555556416511536)
[2024-12-14 23:14:58,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:59,193][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 2.1576356887817383, acc: 0.42424243688583374)
[2024-12-14 23:14:59,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:14:59,588][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 1.9988617897033691, acc: 0.4444444477558136)
[2024-12-14 23:14:59,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:00,064][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 2.0607573986053467, acc: 0.3199999928474426)
[2024-12-14 23:15:00,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:00,494][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.677276611328125, acc: 0.23076923191547394)
[2024-12-14 23:15:00,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:01,327][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.3803176879882812, acc: 0.385869562625885)
[2024-12-14 23:15:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:01,931][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.612553358078003, acc: 0.34659090638160706)
[2024-12-14 23:15:02,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:02,423][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.6823885440826416, acc: 0.28723403811454773)
[2024-12-14 23:15:02,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:02,838][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.7131290435791016, acc: 0.30188679695129395)
[2024-12-14 23:15:02,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:03,244][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.3401589393615723, acc: 0.4166666567325592)
[2024-12-14 23:15:03,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:03,573][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 1.945115566253662, acc: 0.4651162922382355)
[2024-12-14 23:15:03,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:03,947][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.384033679962158, acc: 0.4000000059604645)
[2024-12-14 23:15:04,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:04,381][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 3.0215954780578613, acc: 0.2526315748691559)
[2024-12-14 23:15:04,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:04,742][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.366544008255005, acc: 0.35555556416511536)
[2024-12-14 23:15:04,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:05,240][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.2010419368743896, acc: 0.4722222089767456)
[2024-12-14 23:15:05,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:05,785][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.202353000640869, acc: 0.4587155878543854)
[2024-12-14 23:15:05,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:06,306][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.1727709770202637, acc: 0.42307692766189575)
[2024-12-14 23:15:06,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:06,681][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.0250613689422607, acc: 0.42105263471603394)
[2024-12-14 23:15:06,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:07,050][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.118741273880005, acc: 0.4166666567325592)
[2024-12-14 23:15:07,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:07,422][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.495506525039673, acc: 0.27272728085517883)
[2024-12-14 23:15:07,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:07,801][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.9691945314407349, acc: 0.4444444477558136)
[2024-12-14 23:15:07,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:08,208][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.300614595413208, acc: 0.37142857909202576)
[2024-12-14 23:15:08,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:08,629][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 2.083749294281006, acc: 0.3863636255264282)
[2024-12-14 23:15:08,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:08,994][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.3355698585510254, acc: 0.4318181872367859)
[2024-12-14 23:15:09,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:09,628][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.344435691833496, acc: 0.33870968222618103)
[2024-12-14 23:15:09,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:10,215][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.2950592041015625, acc: 0.40909090638160706)
[2024-12-14 23:15:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:10,604][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 2.160484790802002, acc: 0.4285714328289032)
[2024-12-14 23:15:10,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:10,982][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.5270655155181885, acc: 0.26923078298568726)
[2024-12-14 23:15:11,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:11,351][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.8068034648895264, acc: 0.22580644488334656)
[2024-12-14 23:15:11,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:11,657][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 2.177487850189209, acc: 0.30000001192092896)
[2024-12-14 23:15:11,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:12,072][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.476283550262451, acc: 0.37837839126586914)
[2024-12-14 23:15:12,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:12,456][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.5714974403381348, acc: 0.29729729890823364)
[2024-12-14 23:15:12,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:12,844][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.767084836959839, acc: 0.2702702581882477)
[2024-12-14 23:15:12,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:13,231][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.6103010177612305, acc: 0.3382352888584137)
[2024-12-14 23:15:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:13,581][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.7335439920425415, acc: 0.5121951103210449)
[2024-12-14 23:15:13,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:13,947][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 2.0622763633728027, acc: 0.4399999976158142)
[2024-12-14 23:15:14,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:14,316][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 1.6263726949691772, acc: 0.5199999809265137)
[2024-12-14 23:15:14,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:14,676][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.462221384048462, acc: 0.4193548262119293)
[2024-12-14 23:15:14,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:15,042][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.5845956802368164, acc: 0.28070175647735596)
[2024-12-14 23:15:15,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:15,398][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.649467706680298, acc: 0.3142857253551483)
[2024-12-14 23:15:15,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:15,804][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.3995163440704346, acc: 0.40789473056793213)
[2024-12-14 23:15:16,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:16,399][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 2.2860426902770996, acc: 0.38679245114326477)
[2024-12-14 23:15:16,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:17,028][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.4165170192718506, acc: 0.375)
[2024-12-14 23:15:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:17,469][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.475224494934082, acc: 0.4444444477558136)
[2024-12-14 23:15:17,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:17,815][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.8075530529022217, acc: 0.29032257199287415)
[2024-12-14 23:15:17,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:18,287][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.9949328899383545, acc: 0.2933333218097687)
[2024-12-14 23:15:18,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:18,701][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.801915407180786, acc: 0.375)
[2024-12-14 23:15:19,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:19,631][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.7201504707336426, acc: 0.25600001215934753)
[2024-12-14 23:15:19,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:20,072][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.6036431789398193, acc: 0.3483146131038666)
[2024-12-14 23:15:20,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:20,609][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.561389923095703, acc: 0.36486485600471497)
[2024-12-14 23:15:20,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:21,181][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 2.1381356716156006, acc: 0.43103447556495667)
[2024-12-14 23:15:21,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:21,557][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.3886361122131348, acc: 0.3181818127632141)
[2024-12-14 23:15:21,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:21,921][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.9827369451522827, acc: 0.4545454680919647)
[2024-12-14 23:15:22,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:22,287][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 2.018134832382202, acc: 0.4375)
[2024-12-14 23:15:22,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:22,663][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 2.123469352722168, acc: 0.46666666865348816)
[2024-12-14 23:15:22,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:23,091][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.4576315879821777, acc: 0.3499999940395355)
[2024-12-14 23:15:23,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:23,460][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.117494583129883, acc: 0.40625)
[2024-12-14 23:15:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:23,850][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.8504269123077393, acc: 0.46666666865348816)
[2024-12-14 23:15:23,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:24,214][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.3547632694244385, acc: 0.3103448152542114)
[2024-12-14 23:15:24,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:24,558][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 1.8811107873916626, acc: 0.47999998927116394)
[2024-12-14 23:15:24,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:24,933][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.581467390060425, acc: 0.38297873735427856)
[2024-12-14 23:15:25,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:25,442][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.195019245147705, acc: 0.375)
[2024-12-14 23:15:25,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:25,840][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.0574793815612793, acc: 0.5227272510528564)
[2024-12-14 23:15:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:26,309][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 2.6173970699310303, acc: 0.34939759969711304)
[2024-12-14 23:15:26,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:26,711][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 2.505709409713745, acc: 0.3888888955116272)
[2024-12-14 23:15:26,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:27,054][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 2.7651169300079346, acc: 0.21052631735801697)
[2024-12-14 23:15:27,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:27,417][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.701260566711426, acc: 0.2647058963775635)
[2024-12-14 23:15:27,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:27,797][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 2.409200429916382, acc: 0.30000001192092896)
[2024-12-14 23:15:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:28,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:29,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:29,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:30,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:30,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:30,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:31,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:31,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:32,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:32,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:33,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:33,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:34,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:34,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:34,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:35,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:35,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:36,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:36,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:37,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:37,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:37,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:38,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:39,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:39,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:39,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:40,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:40,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:41,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:41,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:41,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:42,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:43,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:43,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:43,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:44,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:44,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:44,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:45,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:45,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:46,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:46,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:47,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:47,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:47,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:48,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:48,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:48,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:49,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:49,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:50,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:50,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:50,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:51,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:51,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:52,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:52,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:52,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:53,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:53,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:53,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:54,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:54,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:54,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:55,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:55,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:55,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:56,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:56,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:57,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:57,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:57,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:58,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:58,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:58,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:59,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:15:59,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:00,227][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(11.6904, device='cuda:0') eval_epoch_loss=tensor(2.4588, device='cuda:0') eval_epoch_acc=tensor(0.3693, device='cuda:0')
[2024-12-14 23:16:00,228][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:16:00,229][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:16:00,970][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_1_step_286_loss_2.458768129348755/model.pt
[2024-12-14 23:16:00,975][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:16:00,976][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.458768129348755
[2024-12-14 23:16:00,976][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.36931824684143066
[2024-12-14 23:16:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:01,373][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.460320234298706, acc: 0.34375)
[2024-12-14 23:16:01,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:01,737][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.7272400856018066, acc: 0.25600001215934753)
[2024-12-14 23:16:01,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:02,111][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.4073405265808105, acc: 0.38461539149284363)
[2024-12-14 23:16:02,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:02,508][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.6849722862243652, acc: 0.2981366515159607)
[2024-12-14 23:16:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:02,916][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.7116620540618896, acc: 0.30927833914756775)
[2024-12-14 23:16:03,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:03,316][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 1.9000273942947388, acc: 0.4545454680919647)
[2024-12-14 23:16:03,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:03,669][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.3870279788970947, acc: 0.4285714328289032)
[2024-12-14 23:16:03,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:04,065][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 2.106720209121704, acc: 0.5344827771186829)
[2024-12-14 23:16:04,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:04,678][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.7807883024215698, acc: 0.6000000238418579)
[2024-12-14 23:16:04,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:05,280][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.1028976440429688, acc: 0.4639175236225128)
[2024-12-14 23:16:05,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:05,739][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.5960853099823, acc: 0.3448275923728943)
[2024-12-14 23:16:05,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:06,181][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.2121615409851074, acc: 0.4444444477558136)
[2024-12-14 23:16:06,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:06,582][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.410816192626953, acc: 0.42105263471603394)
[2024-12-14 23:16:06,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:06,920][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.528352737426758, acc: 0.4107142984867096)
[2024-12-14 23:16:07,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:07,311][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.4104301929473877, acc: 0.3125)
[2024-12-14 23:16:07,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:07,771][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.5630297660827637, acc: 0.35849055647850037)
[2024-12-14 23:16:07,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:08,229][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.6648045778274536, acc: 0.5849056839942932)
[2024-12-14 23:16:08,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:08,645][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 2.0271036624908447, acc: 0.5)
[2024-12-14 23:16:08,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:09,038][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.608628749847412, acc: 0.34375)
[2024-12-14 23:16:09,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:09,437][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 2.058206796646118, acc: 0.5081967115402222)
[2024-12-14 23:16:09,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:09,841][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.640990972518921, acc: 0.5333333611488342)
[2024-12-14 23:16:09,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:10,278][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.6444469690322876, acc: 0.5789473652839661)
[2024-12-14 23:16:10,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:10,700][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.5752270221710205, acc: 0.3333333432674408)
[2024-12-14 23:16:10,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:11,227][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.2897069454193115, acc: 0.4444444477558136)
[2024-12-14 23:16:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:11,624][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.320535182952881, acc: 0.33734938502311707)
[2024-12-14 23:16:11,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:11,987][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.58379864692688, acc: 0.3076923191547394)
[2024-12-14 23:16:12,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:12,559][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.6783080101013184, acc: 0.2857142984867096)
[2024-12-14 23:16:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:13,002][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 1.4042056798934937, acc: 0.625)
[2024-12-14 23:16:13,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:13,466][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 2.2367169857025146, acc: 0.2916666567325592)
[2024-12-14 23:16:13,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:13,911][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.076789617538452, acc: 0.32258063554763794)
[2024-12-14 23:16:14,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:14,305][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.42585825920105, acc: 0.32258063554763794)
[2024-12-14 23:16:14,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:14,756][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 2.055778980255127, acc: 0.46268656849861145)
[2024-12-14 23:16:14,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:15,224][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 2.005218029022217, acc: 0.4615384638309479)
[2024-12-14 23:16:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:15,707][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.7754807472229004, acc: 0.2222222238779068)
[2024-12-14 23:16:15,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:16,124][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.3324739933013916, acc: 0.30645161867141724)
[2024-12-14 23:16:16,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:16,503][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.5623453855514526, acc: 0.6399999856948853)
[2024-12-14 23:16:16,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:16,899][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.026562452316284, acc: 0.2222222238779068)
[2024-12-14 23:16:16,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:17,232][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 4.057884216308594, acc: 0.11428571492433548)
[2024-12-14 23:16:17,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:17,650][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.8721299171447754, acc: 0.3076923191547394)
[2024-12-14 23:16:17,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:18,079][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.9112460613250732, acc: 0.2926829159259796)
[2024-12-14 23:16:18,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:18,486][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.4435360431671143, acc: 0.44736841320991516)
[2024-12-14 23:16:18,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:18,857][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 2.068779945373535, acc: 0.4736842215061188)
[2024-12-14 23:16:18,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:19,255][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 1.9150160551071167, acc: 0.4285714328289032)
[2024-12-14 23:16:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:19,666][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 2.448826313018799, acc: 0.37037035822868347)
[2024-12-14 23:16:19,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:20,107][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 1.681322693824768, acc: 0.5)
[2024-12-14 23:16:20,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:20,635][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 2.4494388103485107, acc: 0.32258063554763794)
[2024-12-14 23:16:20,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:21,173][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.08542537689209, acc: 0.4035087823867798)
[2024-12-14 23:16:21,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:21,596][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 2.9954495429992676, acc: 0.25)
[2024-12-14 23:16:21,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:22,040][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 2.1152396202087402, acc: 0.5)
[2024-12-14 23:16:22,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:22,406][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.094810724258423, acc: 0.3684210479259491)
[2024-12-14 23:16:22,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:22,819][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 2.3464930057525635, acc: 0.3400000035762787)
[2024-12-14 23:16:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:23,234][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 2.497579336166382, acc: 0.29885056614875793)
[2024-12-14 23:16:23,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:23,638][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 2.485532760620117, acc: 0.3510638177394867)
[2024-12-14 23:16:23,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:24,044][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 2.5781679153442383, acc: 0.3734939694404602)
[2024-12-14 23:16:24,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:24,411][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 2.0879361629486084, acc: 0.52173912525177)
[2024-12-14 23:16:24,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:24,767][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 2.6788487434387207, acc: 0.28205129504203796)
[2024-12-14 23:16:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:25,164][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 2.894845962524414, acc: 0.22891566157341003)
[2024-12-14 23:16:25,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:25,547][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 2.272024154663086, acc: 0.4150943458080292)
[2024-12-14 23:16:25,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:25,938][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 2.6669607162475586, acc: 0.27848100662231445)
[2024-12-14 23:16:26,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:26,343][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 2.380265235900879, acc: 0.3333333432674408)
[2024-12-14 23:16:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:26,765][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 2.8729958534240723, acc: 0.2537313401699066)
[2024-12-14 23:16:26,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:27,127][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 2.0740909576416016, acc: 0.550000011920929)
[2024-12-14 23:16:27,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:27,496][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 1.9527004957199097, acc: 0.47999998927116394)
[2024-12-14 23:16:27,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:27,975][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 1.8020352125167847, acc: 0.5555555820465088)
[2024-12-14 23:16:28,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:28,357][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.2801947593688965, acc: 0.44186046719551086)
[2024-12-14 23:16:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:28,746][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 2.321045398712158, acc: 0.3589743673801422)
[2024-12-14 23:16:28,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:29,177][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.2916581630706787, acc: 0.3777777850627899)
[2024-12-14 23:16:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:29,558][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.5831139087677002, acc: 0.43478259444236755)
[2024-12-14 23:16:29,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:29,963][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.8337931632995605, acc: 0.3461538553237915)
[2024-12-14 23:16:30,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:30,404][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.7157673835754395, acc: 0.3186813294887543)
[2024-12-14 23:16:30,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:30,961][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.234199047088623, acc: 0.40869563817977905)
[2024-12-14 23:16:31,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:31,379][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.5165207386016846, acc: 0.3478260934352875)
[2024-12-14 23:16:31,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:31,793][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.475144386291504, acc: 0.3469387888908386)
[2024-12-14 23:16:31,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:32,156][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 1.187691569328308, acc: 0.6666666865348816)
[2024-12-14 23:16:32,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:32,518][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 2.079378128051758, acc: 0.26923078298568726)
[2024-12-14 23:16:32,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:32,965][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 2.500368356704712, acc: 0.31707316637039185)
[2024-12-14 23:16:33,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:33,394][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.1409342288970947, acc: 0.42222222685813904)
[2024-12-14 23:16:33,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:33,882][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 2.5301620960235596, acc: 0.3552631437778473)
[2024-12-14 23:16:34,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:34,265][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 2.4801785945892334, acc: 0.4146341383457184)
[2024-12-14 23:16:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:34,635][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.589534282684326, acc: 0.3333333432674408)
[2024-12-14 23:16:34,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:35,006][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.4201661348342896, acc: 0.6666666865348816)
[2024-12-14 23:16:35,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:35,373][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 1.112545132637024, acc: 0.739130437374115)
[2024-12-14 23:16:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:35,749][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 1.9565765857696533, acc: 0.3571428656578064)
[2024-12-14 23:16:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:36,120][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 2.1076698303222656, acc: 0.375)
[2024-12-14 23:16:36,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:36,836][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 2.42612361907959, acc: 0.4060606062412262)
[2024-12-14 23:16:37,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:37,802][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 1.798939824104309, acc: 0.5660377144813538)
[2024-12-14 23:16:37,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:38,235][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.1731061935424805, acc: 0.47777777910232544)
[2024-12-14 23:16:38,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:38,642][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.249847888946533, acc: 0.4107142984867096)
[2024-12-14 23:16:38,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:39,046][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.3101861476898193, acc: 0.6000000238418579)
[2024-12-14 23:16:39,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:39,406][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 1.0526106357574463, acc: 0.7599999904632568)
[2024-12-14 23:16:39,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:39,759][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.3879485130310059, acc: 0.52173912525177)
[2024-12-14 23:16:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:40,130][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.6586599349975586, acc: 0.2708333432674408)
[2024-12-14 23:16:40,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:40,558][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.095987319946289, acc: 0.42105263471603394)
[2024-12-14 23:16:40,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:41,222][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.0536420345306396, acc: 0.46706587076187134)
[2024-12-14 23:16:41,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:41,697][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 1.9882951974868774, acc: 0.48120301961898804)
[2024-12-14 23:16:42,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:43,022][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.1258888244628906, acc: 0.4385026693344116)
[2024-12-14 23:16:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:43,609][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 1.836653232574463, acc: 0.5405405163764954)
[2024-12-14 23:16:43,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:43,968][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 1.4795278310775757, acc: 0.6071428656578064)
[2024-12-14 23:16:44,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:44,309][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 1.220849871635437, acc: 0.7142857313156128)
[2024-12-14 23:16:44,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:44,661][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 2.2804975509643555, acc: 0.375)
[2024-12-14 23:16:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:45,047][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.258298397064209, acc: 0.3888888955116272)
[2024-12-14 23:16:45,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:45,408][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 2.310335636138916, acc: 0.3947368562221527)
[2024-12-14 23:16:45,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:45,783][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 1.972603678703308, acc: 0.4545454680919647)
[2024-12-14 23:16:45,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:46,166][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.09598970413208, acc: 0.4000000059604645)
[2024-12-14 23:16:46,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:46,518][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.088226318359375, acc: 0.4761904776096344)
[2024-12-14 23:16:46,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:46,912][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.6832845211029053, acc: 0.3888888955116272)
[2024-12-14 23:16:47,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:47,331][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 2.607671022415161, acc: 0.3786407709121704)
[2024-12-14 23:16:47,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:47,912][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.2074337005615234, acc: 0.45588234066963196)
[2024-12-14 23:16:48,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:48,383][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.552307367324829, acc: 0.3799999952316284)
[2024-12-14 23:16:48,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:48,809][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.389890670776367, acc: 0.3888888955116272)
[2024-12-14 23:16:48,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:49,259][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.5051724910736084, acc: 0.39534884691238403)
[2024-12-14 23:16:49,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:49,650][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 1.7081605195999146, acc: 0.375)
[2024-12-14 23:16:49,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:50,111][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 2.086231231689453, acc: 0.44186046719551086)
[2024-12-14 23:16:50,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:50,529][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.4227800369262695, acc: 0.4399999976158142)
[2024-12-14 23:16:50,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:51,207][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.2101144790649414, acc: 0.45588234066963196)
[2024-12-14 23:16:51,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:51,684][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.0634474754333496, acc: 0.4399999976158142)
[2024-12-14 23:16:51,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:52,073][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 1.8248053789138794, acc: 0.5757575631141663)
[2024-12-14 23:16:52,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:52,426][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 2.0925285816192627, acc: 0.4545454680919647)
[2024-12-14 23:16:52,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:52,796][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 2.0541512966156006, acc: 0.3870967626571655)
[2024-12-14 23:16:52,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:53,228][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.339073419570923, acc: 0.3333333432674408)
[2024-12-14 23:16:53,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:53,632][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 1.3474326133728027, acc: 0.6800000071525574)
[2024-12-14 23:16:53,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:54,021][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.4311720132827759, acc: 0.6111111044883728)
[2024-12-14 23:16:54,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:54,393][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.5473055839538574, acc: 0.5555555820465088)
[2024-12-14 23:16:54,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:54,762][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.5333460569381714, acc: 0.6153846383094788)
[2024-12-14 23:16:54,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:55,155][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.7415623664855957, acc: 0.5517241358757019)
[2024-12-14 23:16:55,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:55,533][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.3489923477172852, acc: 0.6071428656578064)
[2024-12-14 23:16:55,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:55,906][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.3948726654052734, acc: 0.5666666626930237)
[2024-12-14 23:16:56,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:56,276][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.8927321434020996, acc: 0.4545454680919647)
[2024-12-14 23:16:56,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:56,642][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 2.1202847957611084, acc: 0.3636363744735718)
[2024-12-14 23:16:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:57,066][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.477581739425659, acc: 0.47058823704719543)
[2024-12-14 23:16:57,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:57,452][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.2373907566070557, acc: 0.38461539149284363)
[2024-12-14 23:16:57,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:57,801][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 2.083207845687866, acc: 0.4444444477558136)
[2024-12-14 23:16:57,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:58,209][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.022813320159912, acc: 0.4749999940395355)
[2024-12-14 23:16:58,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:58,596][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 2.985607147216797, acc: 0.30000001192092896)
[2024-12-14 23:16:58,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:58,979][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 1.3262860774993896, acc: 0.523809552192688)
[2024-12-14 23:16:59,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:59,353][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 1.9902739524841309, acc: 0.4000000059604645)
[2024-12-14 23:16:59,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:16:59,741][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 1.8607527017593384, acc: 0.46875)
[2024-12-14 23:16:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:00,129][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 2.091142416000366, acc: 0.4166666567325592)
[2024-12-14 23:17:00,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:00,490][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 1.9086449146270752, acc: 0.4444444477558136)
[2024-12-14 23:17:00,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:00,854][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.7134734392166138, acc: 0.5454545617103577)
[2024-12-14 23:17:00,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:01,252][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.5958654880523682, acc: 0.6086956262588501)
[2024-12-14 23:17:01,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:01,778][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.563881278038025, acc: 0.6216216087341309)
[2024-12-14 23:17:01,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:02,145][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.6221235990524292, acc: 0.5185185074806213)
[2024-12-14 23:17:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:03,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:04,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:04,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:04,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:05,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:05,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:05,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:06,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:06,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:06,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:07,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:07,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:07,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:08,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:08,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:09,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:09,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:09,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:10,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:10,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:11,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:11,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:12,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:12,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:12,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:13,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:13,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:14,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:14,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:14,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:14,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:15,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:15,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:16,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:16,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:17,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:17,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:17,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:18,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:18,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:18,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:19,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:19,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:19,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:20,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:20,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:20,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:21,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:21,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:22,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:22,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:23,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:23,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:23,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:24,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:24,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:25,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:25,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:25,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:26,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:26,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:27,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:27,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:28,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:28,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:28,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:29,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:29,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:29,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:30,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:31,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:31,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:31,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:32,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:32,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:32,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:33,535][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.6546, device='cuda:0') eval_epoch_loss=tensor(2.3660, device='cuda:0') eval_epoch_acc=tensor(0.4006, device='cuda:0')
[2024-12-14 23:17:33,538][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:17:33,538][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:17:34,282][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_1_step_429_loss_2.3659918308258057/model.pt
[2024-12-14 23:17:34,287][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:17:34,288][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.3659918308258057
[2024-12-14 23:17:34,288][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4005504548549652
[2024-12-14 23:17:34,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:34,705][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 1.6175562143325806, acc: 0.6086956262588501)
[2024-12-14 23:17:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:35,153][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 1.1345195770263672, acc: 0.7407407164573669)
[2024-12-14 23:17:35,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:35,603][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 1.0877313613891602, acc: 0.5925925970077515)
[2024-12-14 23:17:35,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:36,055][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.024840831756592, acc: 0.47826087474823)
[2024-12-14 23:17:36,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:36,519][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 1.7440190315246582, acc: 0.5833333134651184)
[2024-12-14 23:17:36,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:36,952][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 0.9367518424987793, acc: 0.6800000071525574)
[2024-12-14 23:17:37,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:37,410][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 1.7575801610946655, acc: 0.4848484992980957)
[2024-12-14 23:17:37,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:37,874][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 1.6549816131591797, acc: 0.5277777910232544)
[2024-12-14 23:17:38,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:38,361][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.8744243383407593, acc: 0.5454545617103577)
[2024-12-14 23:17:38,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:38,830][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 0.6584126353263855, acc: 0.8095238208770752)
[2024-12-14 23:17:39,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:39,357][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.62951397895813, acc: 0.41025641560554504)
[2024-12-14 23:17:39,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:39,880][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.3815574645996094, acc: 0.4545454680919647)
[2024-12-14 23:17:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:40,687][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 2.866102933883667, acc: 0.2800000011920929)
[2024-12-14 23:17:40,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:41,164][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 2.6376333236694336, acc: 0.3306451737880707)
[2024-12-14 23:17:41,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:41,850][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.5006532669067383, acc: 0.3333333432674408)
[2024-12-14 23:17:41,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:42,240][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.516216278076172, acc: 0.3207547068595886)
[2024-12-14 23:17:42,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:42,741][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.9244980812072754, acc: 0.3636363744735718)
[2024-12-14 23:17:42,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:43,173][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.248802423477173, acc: 0.47826087474823)
[2024-12-14 23:17:43,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:43,534][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.821838617324829, acc: 0.5384615659713745)
[2024-12-14 23:17:43,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:43,984][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.7434498071670532, acc: 0.5714285969734192)
[2024-12-14 23:17:44,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:44,382][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.646498680114746, acc: 0.35820895433425903)
[2024-12-14 23:17:44,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:44,781][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.171177387237549, acc: 0.4861111044883728)
[2024-12-14 23:17:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:45,237][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.561408519744873, acc: 0.3586956560611725)
[2024-12-14 23:17:45,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:45,664][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.664745569229126, acc: 0.3333333432674408)
[2024-12-14 23:17:45,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:46,095][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.715747356414795, acc: 0.34210526943206787)
[2024-12-14 23:17:46,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:46,539][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.994467854499817, acc: 0.5306122303009033)
[2024-12-14 23:17:46,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:46,899][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.854635238647461, acc: 0.5151515007019043)
[2024-12-14 23:17:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:47,315][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.35787296295166, acc: 0.30927833914756775)
[2024-12-14 23:17:47,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:47,705][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.25370192527771, acc: 0.3857142925262451)
[2024-12-14 23:17:47,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:48,177][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.322932481765747, acc: 0.35465115308761597)
[2024-12-14 23:17:48,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:48,626][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.6243896484375, acc: 0.3392857015132904)
[2024-12-14 23:17:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:49,026][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.324716567993164, acc: 0.40740740299224854)
[2024-12-14 23:17:49,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:49,480][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.8900097608566284, acc: 0.4166666567325592)
[2024-12-14 23:17:49,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:49,892][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 1.9030742645263672, acc: 0.5625)
[2024-12-14 23:17:50,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:50,340][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 1.9074934720993042, acc: 0.5384615659713745)
[2024-12-14 23:17:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:50,731][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.2610292434692383, acc: 0.43478259444236755)
[2024-12-14 23:17:50,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:51,167][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 2.453004837036133, acc: 0.261904776096344)
[2024-12-14 23:17:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:51,597][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 2.546590805053711, acc: 0.28915661573410034)
[2024-12-14 23:17:51,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:52,039][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.2603981494903564, acc: 0.4144144058227539)
[2024-12-14 23:17:52,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:52,447][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 2.364743709564209, acc: 0.43689319491386414)
[2024-12-14 23:17:52,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:52,833][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.233037233352661, acc: 0.3983739912509918)
[2024-12-14 23:17:52,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:53,199][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.9088540077209473, acc: 0.5)
[2024-12-14 23:17:53,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:53,643][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.5520520210266113, acc: 0.25)
[2024-12-14 23:17:53,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:54,159][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.3474295139312744, acc: 0.3333333432674408)
[2024-12-14 23:17:54,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:54,579][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 2.480753183364868, acc: 0.36681222915649414)
[2024-12-14 23:17:54,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:54,991][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.454320192337036, acc: 0.34375)
[2024-12-14 23:17:55,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:55,437][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.394686698913574, acc: 0.349693238735199)
[2024-12-14 23:17:55,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:55,843][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.540356397628784, acc: 0.2949640154838562)
[2024-12-14 23:17:55,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:56,264][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.4430134296417236, acc: 0.356783926486969)
[2024-12-14 23:17:56,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:56,620][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 1.7509262561798096, acc: 0.4722222089767456)
[2024-12-14 23:17:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:56,980][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.7631573677062988, acc: 0.5151515007019043)
[2024-12-14 23:17:57,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:57,422][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.8227165937423706, acc: 0.37037035822868347)
[2024-12-14 23:17:57,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:57,829][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 2.1470143795013428, acc: 0.5)
[2024-12-14 23:17:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:58,191][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 1.0250515937805176, acc: 0.699999988079071)
[2024-12-14 23:17:58,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:58,681][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.8349915742874146, acc: 0.517241358757019)
[2024-12-14 23:17:58,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:59,069][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.6029558181762695, acc: 0.6129032373428345)
[2024-12-14 23:17:59,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:59,519][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.3660629987716675, acc: 0.6842105388641357)
[2024-12-14 23:17:59,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:17:59,961][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.4879000186920166, acc: 0.40740740299224854)
[2024-12-14 23:18:00,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:00,320][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.311491012573242, acc: 0.4285714328289032)
[2024-12-14 23:18:00,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:00,684][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.9156473875045776, acc: 0.3636363744735718)
[2024-12-14 23:18:00,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:01,126][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.1411046981811523, acc: 0.4000000059604645)
[2024-12-14 23:18:01,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:01,632][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.59440279006958, acc: 0.6333333253860474)
[2024-12-14 23:18:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:02,055][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.7883732318878174, acc: 0.6206896305084229)
[2024-12-14 23:18:02,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:02,423][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.2391695976257324, acc: 0.3137255012989044)
[2024-12-14 23:18:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:02,828][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.899921178817749, acc: 0.517241358757019)
[2024-12-14 23:18:02,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:03,244][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 1.0419646501541138, acc: 0.6842105388641357)
[2024-12-14 23:18:03,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:03,666][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.080146551132202, acc: 0.21052631735801697)
[2024-12-14 23:18:03,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:04,092][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.220025062561035, acc: 0.4017857015132904)
[2024-12-14 23:18:04,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:04,581][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.1884708404541016, acc: 0.40449437499046326)
[2024-12-14 23:18:04,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:04,988][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.4686760902404785, acc: 0.3483146131038666)
[2024-12-14 23:18:05,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:05,492][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.601724147796631, acc: 0.3191489279270172)
[2024-12-14 23:18:05,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:05,916][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.5742125511169434, acc: 0.33695653080940247)
[2024-12-14 23:18:06,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:06,361][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 1.1641792058944702, acc: 0.7200000286102295)
[2024-12-14 23:18:06,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:06,755][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.3529479503631592, acc: 0.692307710647583)
[2024-12-14 23:18:06,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:07,126][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.2279667854309082, acc: 0.6296296119689941)
[2024-12-14 23:18:07,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:07,486][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 2.102964401245117, acc: 0.4444444477558136)
[2024-12-14 23:18:07,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:07,843][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.898073434829712, acc: 0.4716981053352356)
[2024-12-14 23:18:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:08,209][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 1.4339706897735596, acc: 0.6551724076271057)
[2024-12-14 23:18:08,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:08,850][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.278162956237793, acc: 0.4234234094619751)
[2024-12-14 23:18:09,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:09,401][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.1652274131774902, acc: 0.43661972880363464)
[2024-12-14 23:18:09,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:09,798][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.6016592979431152, acc: 0.8500000238418579)
[2024-12-14 23:18:09,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:10,226][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 0.9997352957725525, acc: 0.699999988079071)
[2024-12-14 23:18:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:10,617][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.471243977546692, acc: 0.5769230723381042)
[2024-12-14 23:18:12,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:13,351][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.289743661880493, acc: 0.3928571343421936)
[2024-12-14 23:18:13,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:14,207][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.3389649391174316, acc: 0.4365079402923584)
[2024-12-14 23:18:14,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:14,616][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.9392894506454468, acc: 0.5)
[2024-12-14 23:18:14,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:15,015][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.9773900508880615, acc: 0.46666666865348816)
[2024-12-14 23:18:15,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:15,796][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.015963077545166, acc: 0.5138888955116272)
[2024-12-14 23:18:15,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:16,172][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.653925895690918, acc: 0.7692307829856873)
[2024-12-14 23:18:16,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:16,567][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.2246615886688232, acc: 0.5161290168762207)
[2024-12-14 23:18:16,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:16,952][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.6364312171936035, acc: 0.44999998807907104)
[2024-12-14 23:18:17,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:17,312][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.4206759929656982, acc: 0.40740740299224854)
[2024-12-14 23:18:17,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:18,402][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.3574299812316895, acc: 0.4194915294647217)
[2024-12-14 23:18:18,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:18,882][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.378051280975342, acc: 0.38805970549583435)
[2024-12-14 23:18:19,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:19,317][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.351442813873291, acc: 0.37956205010414124)
[2024-12-14 23:18:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:19,940][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.177644729614258, acc: 0.4300000071525574)
[2024-12-14 23:18:20,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:20,315][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.3856964111328125, acc: 0.35185185074806213)
[2024-12-14 23:18:20,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:20,701][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.075943946838379, acc: 0.4615384638309479)
[2024-12-14 23:18:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:21,063][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.537646770477295, acc: 0.2380952388048172)
[2024-12-14 23:18:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:21,451][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 2.917484998703003, acc: 0.26229506731033325)
[2024-12-14 23:18:21,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:21,836][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.1256120204925537, acc: 0.4237288236618042)
[2024-12-14 23:18:21,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:22,216][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.5857207775115967, acc: 0.3488371968269348)
[2024-12-14 23:18:22,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:22,607][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.5449600219726562, acc: 0.3636363744735718)
[2024-12-14 23:18:22,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:23,006][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.535820484161377, acc: 0.3207547068595886)
[2024-12-14 23:18:23,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:23,402][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.290750741958618, acc: 0.4318181872367859)
[2024-12-14 23:18:23,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:23,824][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 2.0724871158599854, acc: 0.5600000023841858)
[2024-12-14 23:18:23,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:24,236][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.985884428024292, acc: 0.44999998807907104)
[2024-12-14 23:18:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:24,665][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.644174575805664, acc: 0.5454545617103577)
[2024-12-14 23:18:24,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:25,152][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.2387328147888184, acc: 0.446153849363327)
[2024-12-14 23:18:25,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:25,597][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 1.9869606494903564, acc: 0.484375)
[2024-12-14 23:18:25,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:26,039][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.2925665378570557, acc: 0.65625)
[2024-12-14 23:18:26,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:26,423][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.2512459754943848, acc: 0.39393940567970276)
[2024-12-14 23:18:26,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:26,886][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 1.0279316902160645, acc: 0.6875)
[2024-12-14 23:18:27,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:27,253][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.2791451215744019, acc: 0.6129032373428345)
[2024-12-14 23:18:27,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:27,637][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.8279111385345459, acc: 0.782608687877655)
[2024-12-14 23:18:27,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:28,019][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 2.4523799419403076, acc: 0.36666667461395264)
[2024-12-14 23:18:28,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:28,486][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 2.019699811935425, acc: 0.39024388790130615)
[2024-12-14 23:18:28,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:28,939][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.3289880752563477, acc: 0.5714285969734192)
[2024-12-14 23:18:29,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:29,420][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.9038089513778687, acc: 0.5263158082962036)
[2024-12-14 23:18:29,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:29,812][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.915663242340088, acc: 0.4838709533214569)
[2024-12-14 23:18:29,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:30,225][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 1.0252459049224854, acc: 0.7200000286102295)
[2024-12-14 23:18:30,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:30,642][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.6074275970458984, acc: 0.4545454680919647)
[2024-12-14 23:18:30,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:31,030][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.549407958984375, acc: 0.6000000238418579)
[2024-12-14 23:18:31,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:31,451][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.8326808214187622, acc: 0.5142857432365417)
[2024-12-14 23:18:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:31,831][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.576364278793335, acc: 0.277372270822525)
[2024-12-14 23:18:31,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:32,227][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.2611851692199707, acc: 0.4206896424293518)
[2024-12-14 23:18:32,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:32,639][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.894831657409668, acc: 0.22857142984867096)
[2024-12-14 23:18:32,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:33,125][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.8211445808410645, acc: 0.21192052960395813)
[2024-12-14 23:18:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:33,553][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.301751136779785, acc: 0.4273504316806793)
[2024-12-14 23:18:33,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:33,917][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.8547065854072571, acc: 0.800000011920929)
[2024-12-14 23:18:34,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:34,307][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.8249417543411255, acc: 0.5384615659713745)
[2024-12-14 23:18:34,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:34,657][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.235602617263794, acc: 0.6153846383094788)
[2024-12-14 23:18:34,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:35,076][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 1.8713452816009521, acc: 0.5128205418586731)
[2024-12-14 23:18:35,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:35,526][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 2.0366482734680176, acc: 0.47777777910232544)
[2024-12-14 23:18:35,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:35,982][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.420921564102173, acc: 0.33766233921051025)
[2024-12-14 23:18:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:36,365][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.2889564037323, acc: 0.375)
[2024-12-14 23:18:36,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:36,796][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.405024290084839, acc: 0.36206895112991333)
[2024-12-14 23:18:36,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:37,206][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.170806407928467, acc: 0.4047619104385376)
[2024-12-14 23:18:37,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:37,599][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.824346899986267, acc: 0.4736842215061188)
[2024-12-14 23:18:37,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:37,989][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 1.9995040893554688, acc: 0.37037035822868347)
[2024-12-14 23:18:38,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:38,440][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.2534265518188477, acc: 0.3689839541912079)
[2024-12-14 23:18:38,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:38,831][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.8337770700454712, acc: 0.4354838728904724)
[2024-12-14 23:18:38,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:39,200][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.3657777309417725, acc: 0.4017094075679779)
[2024-12-14 23:18:39,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:40,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:40,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:41,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:41,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:42,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:42,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:42,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:43,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:43,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:43,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:44,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:44,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:45,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:45,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:46,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:46,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:46,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:47,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:47,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:47,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:48,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:48,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:48,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:49,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:49,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:49,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:50,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:50,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:50,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:51,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:51,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:51,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:52,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:52,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:53,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:53,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:53,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:54,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:54,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:54,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:55,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:55,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:56,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:56,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:57,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:57,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:58,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:58,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:58,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:59,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:59,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:18:59,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:00,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:00,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:00,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:01,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:01,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:02,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:02,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:02,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:03,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:03,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:03,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:04,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:04,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:05,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:05,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:05,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:06,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:06,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:06,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:07,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:07,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:08,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:08,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:09,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:09,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:09,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:10,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:10,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:10,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:11,464][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.4048, device='cuda:0') eval_epoch_loss=tensor(2.1288, device='cuda:0') eval_epoch_acc=tensor(0.4341, device='cuda:0')
[2024-12-14 23:19:11,466][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:19:11,466][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:19:12,168][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_1_step_572_loss_2.1288061141967773/model.pt
[2024-12-14 23:19:12,175][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:19:12,176][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.1288061141967773
[2024-12-14 23:19:12,176][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4341038167476654
[2024-12-14 23:19:12,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:12,590][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.5385630130767822, acc: 0.3214285671710968)
[2024-12-14 23:19:12,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:13,045][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.4579944610595703, acc: 0.30817610025405884)
[2024-12-14 23:19:13,571][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=17.9827, train_epoch_loss=2.8894, epoch time 405.92183758411556s
[2024-12-14 23:19:13,571][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 23:19:13,571][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 17 GB
[2024-12-14 23:19:13,571][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 23:19:13,572][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-12-14 23:19:13,572][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-14 23:19:14,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:14,584][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 2.000864267349243, acc: 0.4444444477558136)
[2024-12-14 23:19:14,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:15,041][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.330299139022827, acc: 0.3199999928474426)
[2024-12-14 23:19:15,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:15,432][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.884418249130249, acc: 0.29729729890823364)
[2024-12-14 23:19:15,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:15,911][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.568518877029419, acc: 0.2368421107530594)
[2024-12-14 23:19:16,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:16,305][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 2.1224758625030518, acc: 0.4054054021835327)
[2024-12-14 23:19:16,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:16,661][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.144413709640503, acc: 0.3928571343421936)
[2024-12-14 23:19:16,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:17,004][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.613039970397949, acc: 0.3469387888908386)
[2024-12-14 23:19:17,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:17,369][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.2083706855773926, acc: 0.3333333432674408)
[2024-12-14 23:19:17,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:17,797][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.6069284081459045, acc: 0.8636363744735718)
[2024-12-14 23:19:17,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:18,192][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.8336836099624634, acc: 0.7307692170143127)
[2024-12-14 23:19:18,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:18,606][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.430242657661438, acc: 0.6296296119689941)
[2024-12-14 23:19:18,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:19,043][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.1797027587890625, acc: 0.38461539149284363)
[2024-12-14 23:19:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:19,430][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.8812652826309204, acc: 0.42424243688583374)
[2024-12-14 23:19:19,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:19,819][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 2.1004457473754883, acc: 0.32608696818351746)
[2024-12-14 23:19:19,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:20,224][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.5276923179626465, acc: 0.3529411852359772)
[2024-12-14 23:19:20,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:20,603][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 2.01116943359375, acc: 0.4285714328289032)
[2024-12-14 23:19:20,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:20,948][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.1657830476760864, acc: 0.7894737124443054)
[2024-12-14 23:19:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:21,324][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.2539312839508057, acc: 0.3333333432674408)
[2024-12-14 23:19:21,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:21,745][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.585097312927246, acc: 0.3055555522441864)
[2024-12-14 23:19:21,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:22,107][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 2.218733310699463, acc: 0.4736842215061188)
[2024-12-14 23:19:22,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:22,530][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 2.0873751640319824, acc: 0.42307692766189575)
[2024-12-14 23:19:22,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:22,900][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.1193389892578125, acc: 0.4137931168079376)
[2024-12-14 23:19:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:23,354][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.9217056035995483, acc: 0.4000000059604645)
[2024-12-14 23:19:23,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:23,818][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 1.1973737478256226, acc: 0.6666666865348816)
[2024-12-14 23:19:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:24,191][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.318148612976074, acc: 0.4375)
[2024-12-14 23:19:24,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:24,558][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.8642184734344482, acc: 0.22641509771347046)
[2024-12-14 23:19:24,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:24,952][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.6542725563049316, acc: 0.3287671208381653)
[2024-12-14 23:19:25,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:26,314][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.5660738945007324, acc: 0.3122529685497284)
[2024-12-14 23:19:26,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:26,700][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.510319471359253, acc: 0.3720930218696594)
[2024-12-14 23:19:26,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:27,086][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.3963613510131836, acc: 0.3253012001514435)
[2024-12-14 23:19:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:27,471][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.3849048614501953, acc: 0.3333333432674408)
[2024-12-14 23:19:27,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:27,868][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.4013195037841797, acc: 0.3214285671710968)
[2024-12-14 23:19:27,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:28,218][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.756687879562378, acc: 0.4444444477558136)
[2024-12-14 23:19:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:28,594][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.8459142446517944, acc: 0.43478259444236755)
[2024-12-14 23:19:28,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:29,015][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.2904200553894043, acc: 0.3529411852359772)
[2024-12-14 23:19:29,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:29,419][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 2.123554229736328, acc: 0.3606557250022888)
[2024-12-14 23:19:29,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:29,856][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 2.2286806106567383, acc: 0.3492063581943512)
[2024-12-14 23:19:30,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:30,311][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 2.4015185832977295, acc: 0.35593220591545105)
[2024-12-14 23:19:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:30,734][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 1.7804789543151855, acc: 0.48275861144065857)
[2024-12-14 23:19:30,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:31,113][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.3460869789123535, acc: 0.6190476417541504)
[2024-12-14 23:19:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:31,466][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 2.5948634147644043, acc: 0.26923078298568726)
[2024-12-14 23:19:31,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:31,935][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.7522053718566895, acc: 0.31081080436706543)
[2024-12-14 23:19:32,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:32,290][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.2731339931488037, acc: 0.38461539149284363)
[2024-12-14 23:19:32,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:32,758][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.541445016860962, acc: 0.3737373650074005)
[2024-12-14 23:19:32,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:33,202][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.1296098232269287, acc: 0.41237112879753113)
[2024-12-14 23:19:33,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:33,657][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.332775115966797, acc: 0.3897058963775635)
[2024-12-14 23:19:33,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:34,028][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 0.9754289388656616, acc: 0.7307692170143127)
[2024-12-14 23:19:34,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:34,400][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 1.0721077919006348, acc: 0.7777777910232544)
[2024-12-14 23:19:34,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:34,778][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 1.3866604566574097, acc: 0.5714285969734192)
[2024-12-14 23:19:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:35,118][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.3250603675842285, acc: 0.5833333134651184)
[2024-12-14 23:19:35,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:35,482][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.6536833047866821, acc: 0.5614035129547119)
[2024-12-14 23:19:35,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:35,842][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.8049956560134888, acc: 0.5079365372657776)
[2024-12-14 23:19:35,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:36,203][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.1896135807037354, acc: 0.43661972880363464)
[2024-12-14 23:19:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:36,709][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.646592140197754, acc: 0.40666666626930237)
[2024-12-14 23:19:36,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:37,092][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.4098201990127563, acc: 0.6756756901741028)
[2024-12-14 23:19:37,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:37,444][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.8181372284889221, acc: 0.7692307829856873)
[2024-12-14 23:19:39,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:40,376][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 1.9947043657302856, acc: 0.4880546033382416)
[2024-12-14 23:19:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:41,684][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.692887544631958, acc: 0.37690630555152893)
[2024-12-14 23:19:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:42,405][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.1849253177642822, acc: 0.4488636255264282)
[2024-12-14 23:19:42,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:43,004][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.4664385318756104, acc: 0.3602941036224365)
[2024-12-14 23:19:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:43,593][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.460230827331543, acc: 0.3188405930995941)
[2024-12-14 23:19:43,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:44,049][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 1.9179089069366455, acc: 0.48750001192092896)
[2024-12-14 23:19:44,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:44,415][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.915656566619873, acc: 0.5)
[2024-12-14 23:19:44,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:44,796][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.1060409545898438, acc: 0.4166666567325592)
[2024-12-14 23:19:44,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:45,178][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 1.9004158973693848, acc: 0.515625)
[2024-12-14 23:19:45,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:45,535][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 1.1399507522583008, acc: 0.7241379022598267)
[2024-12-14 23:19:45,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:45,923][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.451625108718872, acc: 0.375)
[2024-12-14 23:19:46,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:46,325][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.400153875350952, acc: 0.3166666626930237)
[2024-12-14 23:19:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:46,696][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.0907113552093506, acc: 0.6399999856948853)
[2024-12-14 23:19:46,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:47,063][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.4929213523864746, acc: 0.6388888955116272)
[2024-12-14 23:19:47,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:47,420][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 1.6068423986434937, acc: 0.5757575631141663)
[2024-12-14 23:19:47,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:47,800][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.2664246559143066, acc: 0.4264705777168274)
[2024-12-14 23:19:47,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:48,153][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.1945505142211914, acc: 0.3968254029750824)
[2024-12-14 23:19:48,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:48,541][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.407489061355591, acc: 0.37948718667030334)
[2024-12-14 23:19:48,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:48,941][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.241539716720581, acc: 0.40816327929496765)
[2024-12-14 23:19:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:49,328][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.6749236583709717, acc: 0.29104477167129517)
[2024-12-14 23:19:49,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:49,780][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.3648712635040283, acc: 0.3905109465122223)
[2024-12-14 23:19:49,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:50,176][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.780563473701477, acc: 0.8095238208770752)
[2024-12-14 23:19:50,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:50,553][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.7235374450683594, acc: 0.8333333134651184)
[2024-12-14 23:19:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:50,910][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.3446162939071655, acc: 0.5757575631141663)
[2024-12-14 23:19:51,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:51,344][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.203795313835144, acc: 0.692307710647583)
[2024-12-14 23:19:51,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:51,743][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 2.0977137088775635, acc: 0.4038461446762085)
[2024-12-14 23:19:51,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:52,111][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.4241230487823486, acc: 0.4038461446762085)
[2024-12-14 23:19:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:52,514][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.9661616086959839, acc: 0.4375)
[2024-12-14 23:19:52,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:52,916][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.275322198867798, acc: 0.43478259444236755)
[2024-12-14 23:19:53,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:53,285][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.826499342918396, acc: 0.46000000834465027)
[2024-12-14 23:19:53,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:53,637][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.1202847957611084, acc: 0.3478260934352875)
[2024-12-14 23:19:53,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:54,157][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.5303003787994385, acc: 0.3199999928474426)
[2024-12-14 23:19:54,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:54,593][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 2.041571617126465, acc: 0.49514561891555786)
[2024-12-14 23:19:55,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:55,752][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 1.9921337366104126, acc: 0.5097087621688843)
[2024-12-14 23:19:56,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:56,611][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.1762115955352783, acc: 0.39247313141822815)
[2024-12-14 23:19:56,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:57,454][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.9534128904342651, acc: 0.5086206793785095)
[2024-12-14 23:19:57,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:58,224][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.6889925003051758, acc: 0.49473685026168823)
[2024-12-14 23:19:58,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:59,240][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.4380903244018555, acc: 0.3564356565475464)
[2024-12-14 23:19:59,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:19:59,664][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.496128559112549, acc: 0.33870968222618103)
[2024-12-14 23:19:59,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:00,085][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.5829524993896484, acc: 0.3478260934352875)
[2024-12-14 23:20:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:00,520][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.6436550617218018, acc: 0.24369747936725616)
[2024-12-14 23:20:00,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:00,930][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.75812029838562, acc: 0.2211538404226303)
[2024-12-14 23:20:01,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:01,359][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.5135438442230225, acc: 0.36496350169181824)
[2024-12-14 23:20:01,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:01,733][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.607915163040161, acc: 0.2985074520111084)
[2024-12-14 23:20:01,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:02,081][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.4332181215286255, acc: 0.550000011920929)
[2024-12-14 23:20:02,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:02,425][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.0844166278839111, acc: 0.6363636255264282)
[2024-12-14 23:20:02,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:02,787][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.3358348608016968, acc: 0.5652173757553101)
[2024-12-14 23:20:02,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:03,141][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.924058198928833, acc: 0.40909090638160706)
[2024-12-14 23:20:03,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:03,549][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.1888418197631836, acc: 0.43103447556495667)
[2024-12-14 23:20:03,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:03,936][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 2.125868082046509, acc: 0.4883720874786377)
[2024-12-14 23:20:04,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:04,313][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.7249536514282227, acc: 0.6000000238418579)
[2024-12-14 23:20:04,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:04,703][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.8486588597297668, acc: 0.7647058963775635)
[2024-12-14 23:20:04,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:05,115][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.7094711661338806, acc: 0.8461538553237915)
[2024-12-14 23:20:05,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:05,573][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.9010071754455566, acc: 0.4761904776096344)
[2024-12-14 23:20:05,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:06,031][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 1.9760202169418335, acc: 0.5076923370361328)
[2024-12-14 23:20:06,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:06,484][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.1092348098754883, acc: 0.42105263471603394)
[2024-12-14 23:20:06,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:06,893][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 2.050450325012207, acc: 0.4385964870452881)
[2024-12-14 23:20:07,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:07,257][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.2062666416168213, acc: 0.43589743971824646)
[2024-12-14 23:20:07,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:07,658][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.5837078094482422, acc: 0.6938775777816772)
[2024-12-14 23:20:07,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:08,016][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.6350803971290588, acc: 0.8181818127632141)
[2024-12-14 23:20:08,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:08,411][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.218254804611206, acc: 0.4285714328289032)
[2024-12-14 23:20:08,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:08,848][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.1997594833374023, acc: 0.4796747863292694)
[2024-12-14 23:20:08,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:09,243][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8239941596984863, acc: 0.5645161271095276)
[2024-12-14 23:20:09,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:10,193][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.134357452392578, acc: 0.42965778708457947)
[2024-12-14 23:20:10,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:10,582][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.8226430416107178, acc: 0.5199999809265137)
[2024-12-14 23:20:10,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:11,019][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.6655534505844116, acc: 0.5961538553237915)
[2024-12-14 23:20:11,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:11,365][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 0.9624325633049011, acc: 0.875)
[2024-12-14 23:20:11,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:11,718][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.9834166765213013, acc: 0.4736842215061188)
[2024-12-14 23:20:11,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:12,091][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.280769109725952, acc: 0.3619631826877594)
[2024-12-14 23:20:12,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:12,475][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.9512602090835571, acc: 0.4722222089767456)
[2024-12-14 23:20:12,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:12,823][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.350588321685791, acc: 0.3499999940395355)
[2024-12-14 23:20:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:13,213][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.4016482830047607, acc: 0.3333333432674408)
[2024-12-14 23:20:13,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:13,641][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.188009262084961, acc: 0.41025641560554504)
[2024-12-14 23:20:13,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:14,078][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 2.014065980911255, acc: 0.5073529481887817)
[2024-12-14 23:20:14,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:14,425][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.3923684358596802, acc: 0.6538461446762085)
[2024-12-14 23:20:14,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:14,760][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.736173152923584, acc: 0.739130437374115)
[2024-12-14 23:20:14,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:15,125][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.6850405931472778, acc: 0.5)
[2024-12-14 23:20:15,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:15,482][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 2.154735803604126, acc: 0.43478259444236755)
[2024-12-14 23:20:15,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:15,852][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.5003305673599243, acc: 0.6000000238418579)
[2024-12-14 23:20:15,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:16,220][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.509818434715271, acc: 0.5769230723381042)
[2024-12-14 23:20:16,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:16,591][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.294214963912964, acc: 0.2857142984867096)
[2024-12-14 23:20:16,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:17,012][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 1.7231123447418213, acc: 0.5333333611488342)
[2024-12-14 23:20:17,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:17,365][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.8603485822677612, acc: 0.43478259444236755)
[2024-12-14 23:20:17,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:17,721][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.283395528793335, acc: 0.523809552192688)
[2024-12-14 23:20:17,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:18,085][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.432575225830078, acc: 0.38461539149284363)
[2024-12-14 23:20:18,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:19,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:19,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:20,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:20,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:20,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:21,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:22,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:22,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:23,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:23,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:24,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:24,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:25,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:25,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:26,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:26,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:26,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:27,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:27,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:28,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:28,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:29,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:29,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:30,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:30,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:30,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:31,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:32,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:32,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:32,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:33,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:33,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:34,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:34,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:35,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:35,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:35,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:36,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:36,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:37,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:38,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:38,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:38,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:39,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:40,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:40,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:41,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:41,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:41,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:42,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:42,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:43,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:43,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:44,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:44,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:44,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:45,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:46,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:46,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:46,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:47,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:47,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:48,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:48,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:49,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:49,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:49,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:50,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:50,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:50,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:50,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:51,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:52,139][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.1115, device='cuda:0') eval_epoch_loss=tensor(2.0933, device='cuda:0') eval_epoch_acc=tensor(0.4300, device='cuda:0')
[2024-12-14 23:20:52,142][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:20:52,143][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:20:52,874][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_2_step_141_loss_2.0932881832122803/model.pt
[2024-12-14 23:20:52,879][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:20:52,880][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 2.0932881832122803
[2024-12-14 23:20:52,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:53,276][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.9411706924438477, acc: 0.22580644488334656)
[2024-12-14 23:20:53,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:53,701][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.3606791496276855, acc: 0.37837839126586914)
[2024-12-14 23:20:53,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:54,287][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.2653541564941406, acc: 0.3333333432674408)
[2024-12-14 23:20:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:54,675][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9093091487884521, acc: 0.5223880410194397)
[2024-12-14 23:20:54,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:55,064][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.414370059967041, acc: 0.29591837525367737)
[2024-12-14 23:20:55,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:55,555][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.2079949378967285, acc: 0.3723404109477997)
[2024-12-14 23:20:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:55,918][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 2.1034507751464844, acc: 0.4571428596973419)
[2024-12-14 23:20:56,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:56,268][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.4110264778137207, acc: 0.4642857015132904)
[2024-12-14 23:20:56,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:56,625][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.713547706604004, acc: 0.5652173757553101)
[2024-12-14 23:20:56,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:57,009][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 2.288653612136841, acc: 0.27586206793785095)
[2024-12-14 23:20:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:57,389][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.250276565551758, acc: 0.45652174949645996)
[2024-12-14 23:20:57,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:57,841][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.106837272644043, acc: 0.47457626461982727)
[2024-12-14 23:20:57,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:58,229][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.4503049850463867, acc: 0.3684210479259491)
[2024-12-14 23:20:58,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:58,611][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 2.0218989849090576, acc: 0.4864864945411682)
[2024-12-14 23:20:58,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:59,004][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.8381130695343018, acc: 0.5357142686843872)
[2024-12-14 23:20:59,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:59,395][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.5168155431747437, acc: 0.6086956262588501)
[2024-12-14 23:20:59,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:20:59,766][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.2289931774139404, acc: 0.31578946113586426)
[2024-12-14 23:21:00,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:01,432][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 1.8736605644226074, acc: 0.4864864945411682)
[2024-12-14 23:21:01,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:01,823][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.163398265838623, acc: 0.4444444477558136)
[2024-12-14 23:21:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:02,264][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.08742618560791, acc: 0.41860464215278625)
[2024-12-14 23:21:02,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:02,885][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 1.8993335962295532, acc: 0.4470588266849518)
[2024-12-14 23:21:03,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:03,471][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.2836649417877197, acc: 0.3820224702358246)
[2024-12-14 23:21:03,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:03,841][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 2.0014450550079346, acc: 0.5)
[2024-12-14 23:21:03,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:04,215][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.877711534500122, acc: 0.3333333432674408)
[2024-12-14 23:21:04,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:04,586][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 1.9511373043060303, acc: 0.4482758641242981)
[2024-12-14 23:21:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:04,966][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.661146879196167, acc: 0.5510203838348389)
[2024-12-14 23:21:05,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:05,368][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 1.976904273033142, acc: 0.41999998688697815)
[2024-12-14 23:21:05,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:05,805][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.8448138236999512, acc: 0.5138888955116272)
[2024-12-14 23:21:05,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:06,191][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.105128049850464, acc: 0.46078431606292725)
[2024-12-14 23:21:06,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:07,320][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.4743947982788086, acc: 0.3904109597206116)
[2024-12-14 23:21:07,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:07,676][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.3163632154464722, acc: 0.7083333134651184)
[2024-12-14 23:21:07,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:08,030][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.2166677713394165, acc: 0.7037037014961243)
[2024-12-14 23:21:08,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:08,401][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.790452003479004, acc: 0.5)
[2024-12-14 23:21:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:08,996][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 2.0018091201782227, acc: 0.4690265357494354)
[2024-12-14 23:21:09,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:09,397][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 2.002171277999878, acc: 0.4492753744125366)
[2024-12-14 23:21:09,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:09,780][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.1755311489105225, acc: 0.375)
[2024-12-14 23:21:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:10,714][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.488359212875366, acc: 0.3358778655529022)
[2024-12-14 23:21:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:11,408][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.3867831230163574, acc: 0.3037036955356598)
[2024-12-14 23:21:11,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:11,760][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.7366490364074707, acc: 0.5081967115402222)
[2024-12-14 23:21:11,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:12,065][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.9977713227272034, acc: 0.6666666865348816)
[2024-12-14 23:21:12,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:12,410][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.7736639976501465, acc: 0.5199999809265137)
[2024-12-14 23:21:12,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:12,763][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.3182361125946045, acc: 0.6428571343421936)
[2024-12-14 23:21:12,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:13,118][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 2.3261959552764893, acc: 0.3414634168148041)
[2024-12-14 23:21:13,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:13,491][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.444666862487793, acc: 0.3564954698085785)
[2024-12-14 23:21:13,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:13,853][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.497297525405884, acc: 0.3573487102985382)
[2024-12-14 23:21:14,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:14,352][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.5070455074310303, acc: 0.37812501192092896)
[2024-12-14 23:21:14,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:14,901][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.270437240600586, acc: 0.3864915668964386)
[2024-12-14 23:21:15,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:15,351][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.278547763824463, acc: 0.38790035247802734)
[2024-12-14 23:21:15,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:15,701][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.5905120372772217, acc: 0.47999998927116394)
[2024-12-14 23:21:15,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:16,282][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.3927974700927734, acc: 0.39534884691238403)
[2024-12-14 23:21:16,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:17,135][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.119039535522461, acc: 0.4920634925365448)
[2024-12-14 23:21:17,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:18,088][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.2215096950531006, acc: 0.42424243688583374)
[2024-12-14 23:21:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:18,853][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 1.8891832828521729, acc: 0.5176470875740051)
[2024-12-14 23:21:19,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:19,950][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 1.8863815069198608, acc: 0.5123456716537476)
[2024-12-14 23:21:20,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:20,942][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.6181503534317017, acc: 0.5483871102333069)
[2024-12-14 23:21:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:21,282][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.9771356582641602, acc: 0.7857142686843872)
[2024-12-14 23:21:21,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:21,649][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.2401678562164307, acc: 0.5)
[2024-12-14 23:21:21,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:22,064][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 2.1451399326324463, acc: 0.4117647111415863)
[2024-12-14 23:21:22,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:22,487][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.13016939163208, acc: 0.4632352888584137)
[2024-12-14 23:21:22,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:22,883][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.362328052520752, acc: 0.39830508828163147)
[2024-12-14 23:21:22,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:23,273][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.360332489013672, acc: 0.41044774651527405)
[2024-12-14 23:21:23,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:23,663][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.314800262451172, acc: 0.3300970792770386)
[2024-12-14 23:21:23,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:24,023][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 2.1083505153656006, acc: 0.380952388048172)
[2024-12-14 23:21:24,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:24,412][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.0854263305664062, acc: 0.4175824224948883)
[2024-12-14 23:21:24,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:24,828][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.3157315254211426, acc: 0.36771300435066223)
[2024-12-14 23:21:24,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:25,274][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.1678194999694824, acc: 0.4409448802471161)
[2024-12-14 23:21:25,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:25,669][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.178049325942993, acc: 0.4094827473163605)
[2024-12-14 23:21:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:26,077][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.1701972484588623, acc: 0.4384058117866516)
[2024-12-14 23:21:26,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:26,494][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.305777072906494, acc: 0.3929961025714874)
[2024-12-14 23:21:26,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:26,885][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.539804697036743, acc: 0.32608696818351746)
[2024-12-14 23:21:26,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:27,262][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.7273941040039062, acc: 0.5652173757553101)
[2024-12-14 23:21:27,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:27,648][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 2.142937183380127, acc: 0.4285714328289032)
[2024-12-14 23:21:27,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:28,046][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.7253060340881348, acc: 0.5106382966041565)
[2024-12-14 23:21:28,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:28,763][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.9462666511535645, acc: 0.45384615659713745)
[2024-12-14 23:21:28,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:29,157][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.8490815162658691, acc: 0.47297295928001404)
[2024-12-14 23:21:29,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:29,535][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.830244779586792, acc: 0.4651162922382355)
[2024-12-14 23:21:29,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:30,132][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.9865854978561401, acc: 0.477477490901947)
[2024-12-14 23:21:30,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:30,589][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.9474430084228516, acc: 0.4555555582046509)
[2024-12-14 23:21:30,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:30,974][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 1.0190328359603882, acc: 0.6666666865348816)
[2024-12-14 23:21:31,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:31,333][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.5459149479866028, acc: 0.8518518805503845)
[2024-12-14 23:21:31,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:31,682][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 1.34130859375, acc: 0.5600000023841858)
[2024-12-14 23:21:31,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:32,060][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.279167890548706, acc: 0.38461539149284363)
[2024-12-14 23:21:32,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:32,900][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.8249752521514893, acc: 0.5163043737411499)
[2024-12-14 23:21:33,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:33,483][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 2.0524954795837402, acc: 0.4204545319080353)
[2024-12-14 23:21:33,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:33,974][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.2844254970550537, acc: 0.42553192377090454)
[2024-12-14 23:21:34,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:34,376][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.9963957071304321, acc: 0.4150943458080292)
[2024-12-14 23:21:34,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:34,750][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 2.087355136871338, acc: 0.4333333373069763)
[2024-12-14 23:21:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:35,128][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.4350733757019043, acc: 0.604651153087616)
[2024-12-14 23:21:35,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:35,493][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 1.240718126296997, acc: 0.6666666865348816)
[2024-12-14 23:21:35,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:35,902][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.4506895542144775, acc: 0.378947377204895)
[2024-12-14 23:21:36,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:36,290][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 1.968538522720337, acc: 0.5)
[2024-12-14 23:21:36,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:36,749][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 1.8082975149154663, acc: 0.550000011920929)
[2024-12-14 23:21:36,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:37,288][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 1.9128483533859253, acc: 0.536697268486023)
[2024-12-14 23:21:37,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:37,797][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 1.7928894758224487, acc: 0.5230769515037537)
[2024-12-14 23:21:37,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:38,162][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.6874254941940308, acc: 0.5263158082962036)
[2024-12-14 23:21:38,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:38,525][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.601824164390564, acc: 0.5833333134651184)
[2024-12-14 23:21:38,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:38,871][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.988051414489746, acc: 0.1818181872367859)
[2024-12-14 23:21:38,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:39,220][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.9680871963500977, acc: 0.40740740299224854)
[2024-12-14 23:21:39,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:39,605][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.6671772003173828, acc: 0.5428571701049805)
[2024-12-14 23:21:39,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:40,077][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.6368311643600464, acc: 0.5227272510528564)
[2024-12-14 23:21:40,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:40,450][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 2.0483198165893555, acc: 0.40909090638160706)
[2024-12-14 23:21:40,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:41,072][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.084249973297119, acc: 0.4193548262119293)
[2024-12-14 23:21:41,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:41,637][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.7742066383361816, acc: 0.5227272510528564)
[2024-12-14 23:21:41,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:42,004][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 1.01458740234375, acc: 0.761904776096344)
[2024-12-14 23:21:42,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:42,406][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.6659334897994995, acc: 0.6153846383094788)
[2024-12-14 23:21:42,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:42,777][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.6015698909759521, acc: 0.6129032373428345)
[2024-12-14 23:21:42,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:43,189][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 1.2548185586929321, acc: 0.550000011920929)
[2024-12-14 23:21:43,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:43,602][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.6687092781066895, acc: 0.5405405163764954)
[2024-12-14 23:21:43,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:43,985][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.85762619972229, acc: 0.5405405163764954)
[2024-12-14 23:21:44,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:44,376][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.6070573329925537, acc: 0.5675675868988037)
[2024-12-14 23:21:44,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:44,772][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 2.064776659011841, acc: 0.4264705777168274)
[2024-12-14 23:21:44,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:45,216][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 1.0080510377883911, acc: 0.6829268336296082)
[2024-12-14 23:21:45,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:45,623][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.5742751359939575, acc: 0.800000011920929)
[2024-12-14 23:21:45,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:45,983][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.5360261797904968, acc: 0.8799999952316284)
[2024-12-14 23:21:46,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:46,323][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.6672227382659912, acc: 0.8387096524238586)
[2024-12-14 23:21:46,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:46,652][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 2.052626132965088, acc: 0.4912280738353729)
[2024-12-14 23:21:46,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:47,023][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 2.0527541637420654, acc: 0.48571428656578064)
[2024-12-14 23:21:47,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:47,404][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.6439250707626343, acc: 0.5263158082962036)
[2024-12-14 23:21:47,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:48,012][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.8989231586456299, acc: 0.40566039085388184)
[2024-12-14 23:21:48,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:48,642][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 2.065772294998169, acc: 0.4833333194255829)
[2024-12-14 23:21:48,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:49,035][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.398244857788086, acc: 0.5555555820465088)
[2024-12-14 23:21:49,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:49,402][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 2.0213897228240967, acc: 0.5161290168762207)
[2024-12-14 23:21:49,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:49,781][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.96130108833313, acc: 0.2933333218097687)
[2024-12-14 23:21:49,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:50,180][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.4796602725982666, acc: 0.375)
[2024-12-14 23:21:50,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:51,061][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.5558059215545654, acc: 0.36800000071525574)
[2024-12-14 23:21:51,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:51,446][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.3517508506774902, acc: 0.4157303273677826)
[2024-12-14 23:21:51,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:51,833][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.317063570022583, acc: 0.5)
[2024-12-14 23:21:51,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:52,341][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.631685495376587, acc: 0.5344827771186829)
[2024-12-14 23:21:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:52,705][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.7234715223312378, acc: 0.6363636255264282)
[2024-12-14 23:21:52,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:53,055][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 1.623369574546814, acc: 0.5454545617103577)
[2024-12-14 23:21:53,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:53,417][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 1.163517713546753, acc: 0.6875)
[2024-12-14 23:21:53,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:53,807][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.2888681888580322, acc: 0.6666666865348816)
[2024-12-14 23:21:53,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:54,221][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 2.020946741104126, acc: 0.44999998807907104)
[2024-12-14 23:21:54,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:54,583][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.5945749282836914, acc: 0.5)
[2024-12-14 23:21:54,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:54,971][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 1.062126874923706, acc: 0.7333333492279053)
[2024-12-14 23:21:55,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:55,352][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.6192115545272827, acc: 0.6551724076271057)
[2024-12-14 23:21:55,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:55,785][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 1.3931159973144531, acc: 0.6000000238418579)
[2024-12-14 23:21:55,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:56,161][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.393859386444092, acc: 0.38297873735427856)
[2024-12-14 23:21:56,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:56,620][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.9646865129470825, acc: 0.5208333134651184)
[2024-12-14 23:21:56,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:57,013][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.8093184232711792, acc: 0.5681818127632141)
[2024-12-14 23:21:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:57,459][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.3934478759765625, acc: 0.42168673872947693)
[2024-12-14 23:21:57,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:57,842][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.1911630630493164, acc: 0.45370370149612427)
[2024-12-14 23:21:57,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:58,202][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 2.5687897205352783, acc: 0.2631579041481018)
[2024-12-14 23:21:59,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:59,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:21:59,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:00,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:00,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:00,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:01,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:02,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:02,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:03,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:03,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:03,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:04,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:04,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:05,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:05,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:05,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:06,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:06,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:06,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:07,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:07,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:08,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:08,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:08,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:09,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:09,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:10,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:10,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:11,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:11,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:11,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:12,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:12,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:13,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:13,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:13,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:14,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:14,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:15,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:15,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:16,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:17,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:17,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:18,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:18,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:18,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:19,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:19,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:20,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:20,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:20,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:21,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:21,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:22,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:22,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:23,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:23,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:23,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:24,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:24,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:25,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:25,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:26,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:26,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:26,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:27,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:28,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:28,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:29,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:29,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:30,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:30,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:31,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:31,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:31,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:32,419][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.1331, device='cuda:0') eval_epoch_loss=tensor(1.9647, device='cuda:0') eval_epoch_acc=tensor(0.4920, device='cuda:0')
[2024-12-14 23:22:32,420][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:22:32,420][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:22:33,100][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_2_step_284_loss_1.9647489786148071/model.pt
[2024-12-14 23:22:33,113][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:22:33,113][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.9647489786148071
[2024-12-14 23:22:33,114][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.49196985363960266
[2024-12-14 23:22:33,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:33,641][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 2.566416025161743, acc: 0.29411765933036804)
[2024-12-14 23:22:33,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:34,096][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 2.2179017066955566, acc: 0.32499998807907104)
[2024-12-14 23:22:34,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:34,558][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.309823989868164, acc: 0.3359375)
[2024-12-14 23:22:34,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:34,938][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.494285821914673, acc: 0.29600000381469727)
[2024-12-14 23:22:35,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:35,405][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 2.0925261974334717, acc: 0.49450549483299255)
[2024-12-14 23:22:35,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:35,794][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.499546527862549, acc: 0.32919254899024963)
[2024-12-14 23:22:35,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:36,185][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.4908862113952637, acc: 0.34536081552505493)
[2024-12-14 23:22:36,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:36,615][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 1.0729939937591553, acc: 0.6818181872367859)
[2024-12-14 23:22:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:37,045][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 2.1568310260772705, acc: 0.4523809552192688)
[2024-12-14 23:22:37,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:37,533][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.7177425622940063, acc: 0.6206896305084229)
[2024-12-14 23:22:37,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:38,059][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.5145161151885986, acc: 0.6363636255264282)
[2024-12-14 23:22:38,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:38,630][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.8773208856582642, acc: 0.5103092789649963)
[2024-12-14 23:22:38,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:38,968][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.1935291290283203, acc: 0.3965517282485962)
[2024-12-14 23:22:39,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:39,312][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 2.0818986892700195, acc: 0.40740740299224854)
[2024-12-14 23:22:39,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:39,663][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 2.1733832359313965, acc: 0.42105263471603394)
[2024-12-14 23:22:39,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:40,000][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 2.075989246368408, acc: 0.5535714030265808)
[2024-12-14 23:22:40,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:40,338][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 2.0627238750457764, acc: 0.5)
[2024-12-14 23:22:40,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:40,688][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 2.2196271419525146, acc: 0.43396225571632385)
[2024-12-14 23:22:40,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:41,045][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 1.3002570867538452, acc: 0.6037735939025879)
[2024-12-14 23:22:41,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:41,482][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 1.4625883102416992, acc: 0.6764705777168274)
[2024-12-14 23:22:41,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:41,840][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 2.1472363471984863, acc: 0.40625)
[2024-12-14 23:22:41,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:42,223][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.5914547443389893, acc: 0.6065573692321777)
[2024-12-14 23:22:42,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:42,602][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 0.9984911680221558, acc: 0.7333333492279053)
[2024-12-14 23:22:42,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:42,980][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.696355402469635, acc: 0.8421052694320679)
[2024-12-14 23:22:43,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:43,343][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 2.239074468612671, acc: 0.4057970941066742)
[2024-12-14 23:22:43,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:43,789][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.9495890140533447, acc: 0.5138888955116272)
[2024-12-14 23:22:43,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:44,170][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.9035431146621704, acc: 0.4819277226924896)
[2024-12-14 23:22:44,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:44,517][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 2.467534065246582, acc: 0.3461538553237915)
[2024-12-14 23:22:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:44,875][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.4556884765625, acc: 0.37755101919174194)
[2024-12-14 23:22:44,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:45,238][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.3801090717315674, acc: 0.9583333134651184)
[2024-12-14 23:22:45,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:45,620][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 1.5565937757492065, acc: 0.5416666865348816)
[2024-12-14 23:22:45,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:46,000][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 1.0579196214675903, acc: 0.6451612710952759)
[2024-12-14 23:22:46,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:46,363][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.3964248895645142, acc: 0.5806451439857483)
[2024-12-14 23:22:46,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:46,726][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.53267502784729, acc: 0.5820895433425903)
[2024-12-14 23:22:46,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:47,092][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.5173721313476562, acc: 0.5769230723381042)
[2024-12-14 23:22:47,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:47,459][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 2.1815950870513916, acc: 0.3777777850627899)
[2024-12-14 23:22:47,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:47,827][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.7375649213790894, acc: 0.4838709533214569)
[2024-12-14 23:22:47,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:48,196][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 1.1070291996002197, acc: 0.699999988079071)
[2024-12-14 23:22:48,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:48,579][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.488166332244873, acc: 0.3333333432674408)
[2024-12-14 23:22:48,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:48,961][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.3337574005126953, acc: 0.08571428805589676)
[2024-12-14 23:22:49,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:49,335][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.551159620285034, acc: 0.1794871836900711)
[2024-12-14 23:22:49,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:49,689][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.543201446533203, acc: 0.39024388790130615)
[2024-12-14 23:22:49,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:50,050][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.2698404788970947, acc: 0.3947368562221527)
[2024-12-14 23:22:50,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:50,372][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.6911747455596924, acc: 0.5789473652839661)
[2024-12-14 23:22:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:50,777][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 1.122851014137268, acc: 0.7142857313156128)
[2024-12-14 23:22:50,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:51,158][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 2.2696659564971924, acc: 0.40740740299224854)
[2024-12-14 23:22:51,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:51,493][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 1.1572465896606445, acc: 0.78125)
[2024-12-14 23:22:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:51,892][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 2.0236737728118896, acc: 0.4354838728904724)
[2024-12-14 23:22:52,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:52,284][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 1.8189769983291626, acc: 0.4736842215061188)
[2024-12-14 23:22:52,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:52,619][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 2.486752510070801, acc: 0.28125)
[2024-12-14 23:22:52,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:52,986][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 1.589247465133667, acc: 0.5666666626930237)
[2024-12-14 23:22:53,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:53,346][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 1.7772260904312134, acc: 0.42105263471603394)
[2024-12-14 23:22:53,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:53,738][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 2.212310552597046, acc: 0.36000001430511475)
[2024-12-14 23:22:53,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:54,130][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.3021352291107178, acc: 0.3563218414783478)
[2024-12-14 23:22:54,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:54,527][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.5550129413604736, acc: 0.3510638177394867)
[2024-12-14 23:22:54,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:54,888][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.5555260181427, acc: 0.39759036898612976)
[2024-12-14 23:22:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:55,229][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 1.1601097583770752, acc: 0.6086956262588501)
[2024-12-14 23:22:55,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:55,661][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 2.258385419845581, acc: 0.43589743971824646)
[2024-12-14 23:22:55,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:56,095][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 2.500014066696167, acc: 0.34939759969711304)
[2024-12-14 23:22:56,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:56,467][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.9750540256500244, acc: 0.5094339847564697)
[2024-12-14 23:22:56,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:56,920][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 2.151646375656128, acc: 0.3670886158943176)
[2024-12-14 23:22:57,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:57,346][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 2.0978126525878906, acc: 0.47058823704719543)
[2024-12-14 23:22:57,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:57,707][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.5652434825897217, acc: 0.2985074520111084)
[2024-12-14 23:22:57,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:58,044][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 1.326019048690796, acc: 0.699999988079071)
[2024-12-14 23:22:58,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:58,382][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 1.7261090278625488, acc: 0.4399999976158142)
[2024-12-14 23:22:58,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:58,800][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.5814990997314453, acc: 0.6111111044883728)
[2024-12-14 23:22:58,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:59,165][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.9710605144500732, acc: 0.5116279125213623)
[2024-12-14 23:22:59,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:59,536][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 2.0738048553466797, acc: 0.43589743971824646)
[2024-12-14 23:22:59,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:22:59,936][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.9986860752105713, acc: 0.3777777850627899)
[2024-12-14 23:23:00,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:00,273][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.9788807034492493, acc: 0.695652186870575)
[2024-12-14 23:23:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:00,731][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.810669183731079, acc: 0.42307692766189575)
[2024-12-14 23:23:00,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:01,079][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.5891358852386475, acc: 0.32967033982276917)
[2024-12-14 23:23:01,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:01,608][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 2.16827392578125, acc: 0.4434782564640045)
[2024-12-14 23:23:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:02,100][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 2.138517379760742, acc: 0.42391303181648254)
[2024-12-14 23:23:02,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:02,516][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 2.296806812286377, acc: 0.40816327929496765)
[2024-12-14 23:23:02,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:02,897][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.4321988523006439, acc: 0.875)
[2024-12-14 23:23:02,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:03,260][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 1.042728066444397, acc: 0.7307692170143127)
[2024-12-14 23:23:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:03,642][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.7474833726882935, acc: 0.5853658318519592)
[2024-12-14 23:23:03,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:04,061][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.952194333076477, acc: 0.46666666865348816)
[2024-12-14 23:23:04,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:04,457][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 2.1997158527374268, acc: 0.3684210479259491)
[2024-12-14 23:23:04,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:04,847][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 2.1357367038726807, acc: 0.46341463923454285)
[2024-12-14 23:23:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:05,243][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 2.1976888179779053, acc: 0.42424243688583374)
[2024-12-14 23:23:05,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:05,613][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.8906282782554626, acc: 0.7916666865348816)
[2024-12-14 23:23:05,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:05,964][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.5875980257987976, acc: 0.8695651888847351)
[2024-12-14 23:23:06,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:06,345][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.916282594203949, acc: 0.7142857313156128)
[2024-12-14 23:23:06,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:06,702][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.487618088722229, acc: 0.5)
[2024-12-14 23:23:06,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:07,324][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 2.0800211429595947, acc: 0.5030303001403809)
[2024-12-14 23:23:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:08,290][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.5586810111999512, acc: 0.6415094137191772)
[2024-12-14 23:23:08,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:08,677][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.8848364353179932, acc: 0.47777777910232544)
[2024-12-14 23:23:08,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:09,038][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.8843958377838135, acc: 0.4821428656578064)
[2024-12-14 23:23:09,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:09,423][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 1.1560171842575073, acc: 0.6571428775787354)
[2024-12-14 23:23:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:09,763][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.5750333070755005, acc: 0.8399999737739563)
[2024-12-14 23:23:09,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:10,102][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.8240581154823303, acc: 0.695652186870575)
[2024-12-14 23:23:10,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:10,431][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 2.2807953357696533, acc: 0.3958333432674408)
[2024-12-14 23:23:10,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:10,825][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.8100082874298096, acc: 0.5263158082962036)
[2024-12-14 23:23:11,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:11,426][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.8639721870422363, acc: 0.5568862557411194)
[2024-12-14 23:23:11,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:11,867][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.8501360416412354, acc: 0.5338345766067505)
[2024-12-14 23:23:12,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:13,121][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.8737566471099854, acc: 0.5133689641952515)
[2024-12-14 23:23:13,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:13,731][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 1.589853048324585, acc: 0.5945945978164673)
[2024-12-14 23:23:13,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:14,137][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 0.9060176014900208, acc: 0.75)
[2024-12-14 23:23:14,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:14,501][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.7303577661514282, acc: 0.7857142686843872)
[2024-12-14 23:23:14,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:14,843][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 1.466442346572876, acc: 0.625)
[2024-12-14 23:23:14,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:15,209][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.457622766494751, acc: 0.5555555820465088)
[2024-12-14 23:23:15,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:15,576][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 1.4460859298706055, acc: 0.5789473652839661)
[2024-12-14 23:23:15,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:15,917][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.9679243564605713, acc: 0.6818181872367859)
[2024-12-14 23:23:16,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:16,275][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 1.3465646505355835, acc: 0.550000011920929)
[2024-12-14 23:23:16,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:16,643][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 1.472534418106079, acc: 0.6190476417541504)
[2024-12-14 23:23:16,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:16,987][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.63397479057312, acc: 0.40740740299224854)
[2024-12-14 23:23:17,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:17,359][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.4375030994415283, acc: 0.3980582654476166)
[2024-12-14 23:23:17,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:17,903][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.8957310914993286, acc: 0.5367646813392639)
[2024-12-14 23:23:18,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:18,376][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.3439667224884033, acc: 0.4333333373069763)
[2024-12-14 23:23:18,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:18,835][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 2.1661856174468994, acc: 0.4791666567325592)
[2024-12-14 23:23:18,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:19,219][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 2.099419593811035, acc: 0.4883720874786377)
[2024-12-14 23:23:19,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:19,572][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 1.2918602228164673, acc: 0.6666666865348816)
[2024-12-14 23:23:19,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:19,953][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.753952145576477, acc: 0.4883720874786377)
[2024-12-14 23:23:20,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:20,312][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 1.6625370979309082, acc: 0.6000000238418579)
[2024-12-14 23:23:20,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:20,875][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 1.9968782663345337, acc: 0.5)
[2024-12-14 23:23:21,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:21,314][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.790244698524475, acc: 0.4933333396911621)
[2024-12-14 23:23:21,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:21,626][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.3386869430541992, acc: 0.6060606241226196)
[2024-12-14 23:23:21,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:22,037][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.7568913698196411, acc: 0.5454545617103577)
[2024-12-14 23:23:22,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:22,421][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 1.0322579145431519, acc: 0.774193525314331)
[2024-12-14 23:23:22,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:22,775][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.5069584846496582, acc: 0.5555555820465088)
[2024-12-14 23:23:22,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:23,188][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.8751062750816345, acc: 0.8399999737739563)
[2024-12-14 23:23:23,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:23,572][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.9512112736701965, acc: 0.6944444179534912)
[2024-12-14 23:23:23,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:23,945][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 1.017809510231018, acc: 0.7407407164573669)
[2024-12-14 23:23:24,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:24,289][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 1.1914199590682983, acc: 0.692307710647583)
[2024-12-14 23:23:24,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:24,671][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 1.465947151184082, acc: 0.5862069129943848)
[2024-12-14 23:23:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:25,033][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 1.0364524126052856, acc: 0.75)
[2024-12-14 23:23:25,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:25,400][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 1.1687836647033691, acc: 0.6666666865348816)
[2024-12-14 23:23:25,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:25,793][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 1.2885557413101196, acc: 0.6363636255264282)
[2024-12-14 23:23:25,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:26,187][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 1.2625685930252075, acc: 0.5)
[2024-12-14 23:23:26,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:26,637][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 2.152600049972534, acc: 0.4901960790157318)
[2024-12-14 23:23:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:27,057][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 2.3231310844421387, acc: 0.5769230723381042)
[2024-12-14 23:23:27,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:27,425][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 2.079357147216797, acc: 0.5555555820465088)
[2024-12-14 23:23:27,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:27,906][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.7402156591415405, acc: 0.6000000238418579)
[2024-12-14 23:23:28,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:28,269][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 2.454441547393799, acc: 0.44999998807907104)
[2024-12-14 23:23:28,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:28,655][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.6393603086471558, acc: 0.8095238208770752)
[2024-12-14 23:23:28,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:29,045][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.4880257844924927, acc: 0.6000000238418579)
[2024-12-14 23:23:29,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:29,424][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.5194408893585205, acc: 0.59375)
[2024-12-14 23:23:29,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:29,811][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.9928817749023438, acc: 0.3611111044883728)
[2024-12-14 23:23:29,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:30,178][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 1.6066091060638428, acc: 0.5925925970077515)
[2024-12-14 23:23:30,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:30,585][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 1.4723225831985474, acc: 0.6060606241226196)
[2024-12-14 23:23:30,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:30,974][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 1.606925129890442, acc: 0.5652173757553101)
[2024-12-14 23:23:31,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:32,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:32,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:33,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:33,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:33,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:34,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:34,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:35,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:35,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:36,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:36,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:36,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:37,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:38,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:38,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:38,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:39,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:39,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:40,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:40,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:40,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:41,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:41,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:42,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:43,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:43,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:43,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:44,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:44,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:45,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:45,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:46,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:46,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:46,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:47,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:47,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:47,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:48,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:48,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:49,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:49,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:50,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:50,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:50,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:51,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:51,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:51,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:52,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:52,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:53,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:53,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:54,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:54,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:55,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:55,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:55,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:56,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:56,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:56,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:57,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:58,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:58,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:59,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:59,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:23:59,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:00,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:00,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:00,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:01,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:01,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:01,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:02,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:02,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:03,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:03,745][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6445, device='cuda:0') eval_epoch_loss=tensor(2.0340, device='cuda:0') eval_epoch_acc=tensor(0.4521, device='cuda:0')
[2024-12-14 23:24:03,746][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:24:03,746][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:24:04,421][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_2_step_427_loss_2.033991575241089/model.pt
[2024-12-14 23:24:04,430][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:24:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:04,869][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 1.4803451299667358, acc: 0.5945945978164673)
[2024-12-14 23:24:04,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:05,234][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 1.1713272333145142, acc: 0.7037037014961243)
[2024-12-14 23:24:05,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:05,588][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 1.636693000793457, acc: 0.47826087474823)
[2024-12-14 23:24:05,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:05,942][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.951545774936676, acc: 0.7037037014961243)
[2024-12-14 23:24:06,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:06,358][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.9837048649787903, acc: 0.6666666865348816)
[2024-12-14 23:24:06,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:06,775][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 1.387078881263733, acc: 0.5652173757553101)
[2024-12-14 23:24:06,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:07,161][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.3846148252487183, acc: 0.6666666865348816)
[2024-12-14 23:24:07,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:07,518][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.6768738627433777, acc: 0.8399999737739563)
[2024-12-14 23:24:07,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:07,837][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 1.3575687408447266, acc: 0.6666666865348816)
[2024-12-14 23:24:07,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:08,208][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.4981006383895874, acc: 0.5555555820465088)
[2024-12-14 23:24:08,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:08,603][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.4557150602340698, acc: 0.6136363744735718)
[2024-12-14 23:24:08,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:08,993][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.6640482544898987, acc: 0.8571428656578064)
[2024-12-14 23:24:09,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:09,389][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 2.075824737548828, acc: 0.43589743971824646)
[2024-12-14 23:24:09,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:09,889][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 2.115091323852539, acc: 0.4848484992980957)
[2024-12-14 23:24:10,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:10,650][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.546902894973755, acc: 0.30399999022483826)
[2024-12-14 23:24:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:11,097][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 2.364820718765259, acc: 0.3709677457809448)
[2024-12-14 23:24:11,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:11,771][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 2.3252410888671875, acc: 0.3731343150138855)
[2024-12-14 23:24:11,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:12,138][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 2.187525510787964, acc: 0.3962264060974121)
[2024-12-14 23:24:12,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:12,619][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 1.1926251649856567, acc: 0.6590909361839294)
[2024-12-14 23:24:12,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:12,991][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.5865224599838257, acc: 0.6086956262588501)
[2024-12-14 23:24:13,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:13,334][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.757758617401123, acc: 0.4615384638309479)
[2024-12-14 23:24:13,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:13,808][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 1.3383004665374756, acc: 0.75)
[2024-12-14 23:24:13,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:14,183][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 2.15865421295166, acc: 0.38805970549583435)
[2024-12-14 23:24:14,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:14,608][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 1.985493540763855, acc: 0.4722222089767456)
[2024-12-14 23:24:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:14,981][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 2.22094464302063, acc: 0.3804347813129425)
[2024-12-14 23:24:15,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:15,349][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 2.1780717372894287, acc: 0.38461539149284363)
[2024-12-14 23:24:15,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:15,712][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 2.3090591430664062, acc: 0.3947368562221527)
[2024-12-14 23:24:15,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:16,088][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.9028172492980957, acc: 0.5510203838348389)
[2024-12-14 23:24:16,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:16,416][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.4779253005981445, acc: 0.6060606241226196)
[2024-12-14 23:24:16,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:16,832][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 2.185676336288452, acc: 0.3711340129375458)
[2024-12-14 23:24:16,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:17,150][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.8719205856323242, acc: 0.4571428596973419)
[2024-12-14 23:24:17,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:17,585][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 2.098052740097046, acc: 0.4360465109348297)
[2024-12-14 23:24:17,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:17,963][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 2.4717953205108643, acc: 0.375)
[2024-12-14 23:24:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:18,322][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 2.1547064781188965, acc: 0.40740740299224854)
[2024-12-14 23:24:18,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:18,669][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.775825023651123, acc: 0.5277777910232544)
[2024-12-14 23:24:18,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:19,029][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 1.5408674478530884, acc: 0.59375)
[2024-12-14 23:24:19,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:19,402][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 1.5192846059799194, acc: 0.5384615659713745)
[2024-12-14 23:24:19,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:19,748][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 1.9092860221862793, acc: 0.52173912525177)
[2024-12-14 23:24:19,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:20,104][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 2.100314140319824, acc: 0.3214285671710968)
[2024-12-14 23:24:20,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:20,493][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 2.1344499588012695, acc: 0.39759036898612976)
[2024-12-14 23:24:20,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:20,966][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.8814588785171509, acc: 0.4864864945411682)
[2024-12-14 23:24:21,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:21,425][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 1.9675546884536743, acc: 0.4757281541824341)
[2024-12-14 23:24:21,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:21,786][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 1.738991141319275, acc: 0.5528455376625061)
[2024-12-14 23:24:21,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:22,145][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 1.7437940835952759, acc: 0.4583333432674408)
[2024-12-14 23:24:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:22,525][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 2.4877331256866455, acc: 0.3214285671710968)
[2024-12-14 23:24:22,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:22,959][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 2.257063388824463, acc: 0.3921568691730499)
[2024-12-14 23:24:23,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:23,345][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 2.3299131393432617, acc: 0.39737990498542786)
[2024-12-14 23:24:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:23,709][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 2.239797830581665, acc: 0.3958333432674408)
[2024-12-14 23:24:23,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:24,074][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 2.2884020805358887, acc: 0.38650307059288025)
[2024-12-14 23:24:24,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:24,424][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 2.280508279800415, acc: 0.3741007149219513)
[2024-12-14 23:24:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:24,797][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 2.298903703689575, acc: 0.4170854389667511)
[2024-12-14 23:24:24,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:25,141][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.5167193412780762, acc: 0.5833333134651184)
[2024-12-14 23:24:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:25,487][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.4561687707901, acc: 0.6060606241226196)
[2024-12-14 23:24:25,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:25,847][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 1.3967896699905396, acc: 0.5925925970077515)
[2024-12-14 23:24:25,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:26,249][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.5928295850753784, acc: 0.5)
[2024-12-14 23:24:26,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:26,625][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 0.8077112436294556, acc: 0.75)
[2024-12-14 23:24:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:27,029][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.640895128250122, acc: 0.5862069129943848)
[2024-12-14 23:24:27,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:27,374][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 1.374552607536316, acc: 0.7096773982048035)
[2024-12-14 23:24:27,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:27,722][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 0.7988821864128113, acc: 0.8421052694320679)
[2024-12-14 23:24:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:28,063][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 2.233038902282715, acc: 0.5185185074806213)
[2024-12-14 23:24:28,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:28,412][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 2.352696657180786, acc: 0.380952388048172)
[2024-12-14 23:24:28,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:28,766][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.7622042894363403, acc: 0.5)
[2024-12-14 23:24:28,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:29,152][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 1.958614706993103, acc: 0.4153846204280853)
[2024-12-14 23:24:29,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:29,501][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 1.4987552165985107, acc: 0.5666666626930237)
[2024-12-14 23:24:29,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:29,858][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 1.672160267829895, acc: 0.6206896305084229)
[2024-12-14 23:24:29,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:30,223][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 1.98068106174469, acc: 0.47058823704719543)
[2024-12-14 23:24:30,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:30,608][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 1.7014492750167847, acc: 0.517241358757019)
[2024-12-14 23:24:30,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:31,045][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.7610011696815491, acc: 0.7368420958518982)
[2024-12-14 23:24:31,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:31,422][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 2.781280994415283, acc: 0.2631579041481018)
[2024-12-14 23:24:31,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:31,802][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.9200210571289062, acc: 0.4821428656578064)
[2024-12-14 23:24:31,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:32,212][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 2.0096640586853027, acc: 0.47191011905670166)
[2024-12-14 23:24:32,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:32,603][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 2.190723180770874, acc: 0.42696627974510193)
[2024-12-14 23:24:32,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:32,983][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 2.403742551803589, acc: 0.3758865296840668)
[2024-12-14 23:24:33,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:33,354][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 2.409055709838867, acc: 0.3804347813129425)
[2024-12-14 23:24:33,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:33,754][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.8745988607406616, acc: 0.800000011920929)
[2024-12-14 23:24:33,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:34,109][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 1.1051898002624512, acc: 0.7307692170143127)
[2024-12-14 23:24:34,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:34,460][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.9366297721862793, acc: 0.7407407164573669)
[2024-12-14 23:24:34,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:34,794][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 1.8084543943405151, acc: 0.48148149251937866)
[2024-12-14 23:24:34,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:35,127][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.6868784427642822, acc: 0.5471698045730591)
[2024-12-14 23:24:35,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:35,468][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 1.3289662599563599, acc: 0.6206896305084229)
[2024-12-14 23:24:35,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:36,091][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 2.045447826385498, acc: 0.44144144654273987)
[2024-12-14 23:24:36,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:36,575][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.765360951423645, acc: 0.5211267471313477)
[2024-12-14 23:24:36,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:36,923][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.5368653535842896, acc: 0.800000011920929)
[2024-12-14 23:24:37,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:37,325][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.6907550096511841, acc: 0.800000011920929)
[2024-12-14 23:24:37,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:37,666][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 1.2475612163543701, acc: 0.6153846383094788)
[2024-12-14 23:24:39,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:40,282][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 2.062349796295166, acc: 0.4928571283817291)
[2024-12-14 23:24:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:41,081][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 2.025033712387085, acc: 0.5)
[2024-12-14 23:24:41,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:41,453][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.5168243646621704, acc: 0.6071428656578064)
[2024-12-14 23:24:41,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:41,804][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 1.6426615715026855, acc: 0.5666666626930237)
[2024-12-14 23:24:42,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:42,528][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.6930609941482544, acc: 0.5555555820465088)
[2024-12-14 23:24:42,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:42,921][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.5385170578956604, acc: 0.7692307829856873)
[2024-12-14 23:24:43,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:43,274][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 1.7121303081512451, acc: 0.4838709533214569)
[2024-12-14 23:24:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:43,634][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 1.9062772989273071, acc: 0.550000011920929)
[2024-12-14 23:24:43,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:43,958][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 2.1755645275115967, acc: 0.48148149251937866)
[2024-12-14 23:24:44,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:44,971][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 2.112245798110962, acc: 0.39830508828163147)
[2024-12-14 23:24:45,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:45,379][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 2.2252063751220703, acc: 0.43283581733703613)
[2024-12-14 23:24:45,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:45,795][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 2.190796136856079, acc: 0.40875911712646484)
[2024-12-14 23:24:45,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:46,373][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 1.967051386833191, acc: 0.4399999976158142)
[2024-12-14 23:24:46,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:46,730][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 2.1471970081329346, acc: 0.37037035822868347)
[2024-12-14 23:24:46,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:47,090][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 1.8798754215240479, acc: 0.48076921701431274)
[2024-12-14 23:24:47,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:47,433][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 2.23710560798645, acc: 0.2857142984867096)
[2024-12-14 23:24:47,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:47,797][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.8682122230529785, acc: 0.24590164422988892)
[2024-12-14 23:24:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:48,158][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 1.8118172883987427, acc: 0.5932203531265259)
[2024-12-14 23:24:48,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:48,558][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.3433589935302734, acc: 0.41860464215278625)
[2024-12-14 23:24:48,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:48,936][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 2.175039052963257, acc: 0.4545454680919647)
[2024-12-14 23:24:49,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:49,282][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.384911060333252, acc: 0.4150943458080292)
[2024-12-14 23:24:49,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:49,642][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.9053996801376343, acc: 0.5454545617103577)
[2024-12-14 23:24:49,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:49,980][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.713557481765747, acc: 0.5600000023841858)
[2024-12-14 23:24:50,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:50,414][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 1.6735988855361938, acc: 0.5)
[2024-12-14 23:24:50,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:50,810][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 1.3717365264892578, acc: 0.6363636255264282)
[2024-12-14 23:24:50,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:51,247][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.9574873447418213, acc: 0.5076923370361328)
[2024-12-14 23:24:51,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:51,635][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.780659794807434, acc: 0.578125)
[2024-12-14 23:24:51,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:52,061][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 1.237890362739563, acc: 0.6875)
[2024-12-14 23:24:52,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:52,427][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.870381236076355, acc: 0.5151515007019043)
[2024-12-14 23:24:52,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:52,807][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.7901976108551025, acc: 0.75)
[2024-12-14 23:24:52,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:53,160][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.8917497992515564, acc: 0.7096773982048035)
[2024-12-14 23:24:53,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:53,524][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.6386659741401672, acc: 0.782608687877655)
[2024-12-14 23:24:53,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:53,889][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 2.0204434394836426, acc: 0.5)
[2024-12-14 23:24:53,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:54,253][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 1.633220911026001, acc: 0.4390243887901306)
[2024-12-14 23:24:54,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:54,629][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 1.1582053899765015, acc: 0.6285714507102966)
[2024-12-14 23:24:54,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:55,008][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 1.3135309219360352, acc: 0.6315789222717285)
[2024-12-14 23:24:55,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:55,346][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 1.483220100402832, acc: 0.5806451439857483)
[2024-12-14 23:24:55,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:55,695][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.7496882081031799, acc: 0.800000011920929)
[2024-12-14 23:24:55,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:56,066][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 1.4455996751785278, acc: 0.6060606241226196)
[2024-12-14 23:24:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:56,459][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 1.0866310596466064, acc: 0.7250000238418579)
[2024-12-14 23:24:56,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:56,836][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 1.3830503225326538, acc: 0.6142857074737549)
[2024-12-14 23:24:56,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:57,167][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 2.3676717281341553, acc: 0.37956205010414124)
[2024-12-14 23:24:57,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:57,515][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.9074921607971191, acc: 0.5241379141807556)
[2024-12-14 23:24:57,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:57,881][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 2.572197914123535, acc: 0.37142857909202576)
[2024-12-14 23:24:57,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:58,237][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 2.437401533126831, acc: 0.3509933650493622)
[2024-12-14 23:24:58,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:58,608][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 1.8340378999710083, acc: 0.5128205418586731)
[2024-12-14 23:24:58,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:59,049][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.7401761412620544, acc: 0.8399999737739563)
[2024-12-14 23:24:59,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:59,508][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 1.4130524396896362, acc: 0.5769230723381042)
[2024-12-14 23:24:59,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:24:59,886][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.7359593510627747, acc: 0.807692289352417)
[2024-12-14 23:25:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:00,271][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.5963696241378784, acc: 0.5384615659713745)
[2024-12-14 23:25:00,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:00,654][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.7044360637664795, acc: 0.5111111402511597)
[2024-12-14 23:25:00,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:01,020][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.8057475090026855, acc: 0.4935064911842346)
[2024-12-14 23:25:01,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:01,471][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 1.7765313386917114, acc: 0.4375)
[2024-12-14 23:25:01,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:01,838][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 1.685795783996582, acc: 0.568965494632721)
[2024-12-14 23:25:01,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:02,214][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.8962812423706055, acc: 0.4523809552192688)
[2024-12-14 23:25:02,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:02,598][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 1.6357128620147705, acc: 0.5)
[2024-12-14 23:25:02,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:02,958][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 1.437970757484436, acc: 0.5555555820465088)
[2024-12-14 23:25:03,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:03,363][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 2.051137924194336, acc: 0.4545454680919647)
[2024-12-14 23:25:04,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:04,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:04,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:05,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:05,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:06,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:06,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:06,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:07,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:07,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:08,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:08,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:09,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:09,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:10,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:10,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:10,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:11,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:11,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:12,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:12,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:12,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:13,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:13,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:14,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:14,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:14,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:15,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:15,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:15,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:16,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:16,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:17,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:17,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:18,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:18,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:18,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:19,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:19,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:19,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:20,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:20,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:20,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:21,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:21,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:21,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:22,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:22,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:22,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:23,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:23,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:24,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:24,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:24,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:25,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:25,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:25,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:26,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:26,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:27,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:27,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:28,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:28,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:29,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:30,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:30,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:31,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:31,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:32,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:32,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:33,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:33,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:33,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:34,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:34,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:34,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:35,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:36,189][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5767, device='cuda:0') eval_epoch_loss=tensor(1.8835, device='cuda:0') eval_epoch_acc=tensor(0.5086, device='cuda:0')
[2024-12-14 23:25:36,190][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:25:36,190][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:25:36,885][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_2_step_570_loss_1.883535623550415/model.pt
[2024-12-14 23:25:36,896][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:25:36,898][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.883535623550415
[2024-12-14 23:25:36,899][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.5085919499397278
[2024-12-14 23:25:37,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:37,339][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 1.6242458820343018, acc: 0.5806451439857483)
[2024-12-14 23:25:37,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:37,698][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 2.0365285873413086, acc: 0.4615384638309479)
[2024-12-14 23:25:37,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:38,062][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 2.364112377166748, acc: 0.3520408272743225)
[2024-12-14 23:25:38,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:38,460][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 2.2045769691467285, acc: 0.36477985978126526)
[2024-12-14 23:25:38,866][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=6.3646, train_epoch_loss=1.8507, epoch time 385.29357156483456s
[2024-12-14 23:25:38,867][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-12-14 23:25:38,867][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 23:25:38,867][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-12-14 23:25:38,867][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-12-14 23:25:38,867][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:25:39,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:39,767][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.6541708707809448, acc: 0.5185185074806213)
[2024-12-14 23:25:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:40,149][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 2.562703847885132, acc: 0.4000000059604645)
[2024-12-14 23:25:40,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:40,555][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 2.6504056453704834, acc: 0.3513513505458832)
[2024-12-14 23:25:40,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:40,976][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 2.2880260944366455, acc: 0.34210526943206787)
[2024-12-14 23:25:41,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:41,391][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 2.030151605606079, acc: 0.4864864945411682)
[2024-12-14 23:25:41,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:41,855][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 1.8239314556121826, acc: 0.3928571343421936)
[2024-12-14 23:25:42,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:42,308][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 2.279440402984619, acc: 0.40816327929496765)
[2024-12-14 23:25:42,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:42,742][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 1.605135202407837, acc: 0.5333333611488342)
[2024-12-14 23:25:42,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:43,201][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.4801211357116699, acc: 0.8636363744735718)
[2024-12-14 23:25:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:43,635][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.7206637263298035, acc: 0.7692307829856873)
[2024-12-14 23:25:43,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:44,073][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 1.1430699825286865, acc: 0.7407407164573669)
[2024-12-14 23:25:44,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:44,480][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.7042315006256104, acc: 0.5384615659713745)
[2024-12-14 23:25:44,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:44,858][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 1.6208245754241943, acc: 0.4848484992980957)
[2024-12-14 23:25:44,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:45,260][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.7372292280197144, acc: 0.54347825050354)
[2024-12-14 23:25:45,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:45,665][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 2.178743600845337, acc: 0.4313725531101227)
[2024-12-14 23:25:45,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:46,078][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.7506821155548096, acc: 0.5102040767669678)
[2024-12-14 23:25:46,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:46,472][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.8671646118164062, acc: 0.7894737124443054)
[2024-12-14 23:25:46,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:46,852][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.7931861877441406, acc: 0.4583333432674408)
[2024-12-14 23:25:47,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:47,325][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 1.9765177965164185, acc: 0.4722222089767456)
[2024-12-14 23:25:47,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:47,701][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 1.4003273248672485, acc: 0.6315789222717285)
[2024-12-14 23:25:47,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:48,052][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 1.382638931274414, acc: 0.6538461446762085)
[2024-12-14 23:25:48,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:48,435][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 1.5907864570617676, acc: 0.6551724076271057)
[2024-12-14 23:25:48,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:48,821][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 1.4481958150863647, acc: 0.5199999809265137)
[2024-12-14 23:25:48,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:49,193][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.9138492345809937, acc: 0.7142857313156128)
[2024-12-14 23:25:49,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:49,551][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 1.8075850009918213, acc: 0.4375)
[2024-12-14 23:25:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:49,929][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 2.513871908187866, acc: 0.30188679695129395)
[2024-12-14 23:25:50,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:50,364][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 2.3724541664123535, acc: 0.42465752363204956)
[2024-12-14 23:25:51,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:51,722][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 2.367109775543213, acc: 0.3794466257095337)
[2024-12-14 23:25:51,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:52,043][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 2.000396251678467, acc: 0.5116279125213623)
[2024-12-14 23:25:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:52,412][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 2.08467435836792, acc: 0.45783132314682007)
[2024-12-14 23:25:52,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:52,893][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 2.1099555492401123, acc: 0.43209877610206604)
[2024-12-14 23:25:53,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:53,275][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 2.224979877471924, acc: 0.3928571343421936)
[2024-12-14 23:25:53,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:53,733][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 1.49018394947052, acc: 0.5185185074806213)
[2024-12-14 23:25:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:54,127][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 1.1954015493392944, acc: 0.5652173757553101)
[2024-12-14 23:25:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:54,538][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 2.0701026916503906, acc: 0.4285714328289032)
[2024-12-14 23:25:54,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:54,897][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 1.7776376008987427, acc: 0.5081967115402222)
[2024-12-14 23:25:54,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:55,272][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 2.1163430213928223, acc: 0.4444444477558136)
[2024-12-14 23:25:55,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:55,713][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 2.158806085586548, acc: 0.4067796468734741)
[2024-12-14 23:25:55,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:56,159][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 1.4933664798736572, acc: 0.5977011322975159)
[2024-12-14 23:25:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:56,561][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 1.1528867483139038, acc: 0.6666666865348816)
[2024-12-14 23:25:56,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:56,954][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 1.7358462810516357, acc: 0.5384615659713745)
[2024-12-14 23:25:57,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:57,361][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 2.584561824798584, acc: 0.3243243098258972)
[2024-12-14 23:25:57,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:57,746][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 2.0842173099517822, acc: 0.4000000059604645)
[2024-12-14 23:25:57,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:58,198][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 2.36641526222229, acc: 0.38383838534355164)
[2024-12-14 23:25:58,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:58,648][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.8078937530517578, acc: 0.5051546096801758)
[2024-12-14 23:25:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:59,078][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 2.149794101715088, acc: 0.45588234066963196)
[2024-12-14 23:25:59,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:59,422][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.8142226338386536, acc: 0.7692307829856873)
[2024-12-14 23:25:59,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:25:59,842][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.8407925963401794, acc: 0.7777777910232544)
[2024-12-14 23:25:59,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:00,274][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 1.1672241687774658, acc: 0.6428571343421936)
[2024-12-14 23:26:00,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:00,685][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 1.0253806114196777, acc: 0.6666666865348816)
[2024-12-14 23:26:00,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:01,073][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.399743676185608, acc: 0.6140350699424744)
[2024-12-14 23:26:01,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:01,441][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.518986463546753, acc: 0.60317462682724)
[2024-12-14 23:26:01,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:01,813][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 2.1074182987213135, acc: 0.47887325286865234)
[2024-12-14 23:26:01,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:02,299][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 2.2943308353424072, acc: 0.46000000834465027)
[2024-12-14 23:26:02,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:02,711][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.3252942562103271, acc: 0.6756756901741028)
[2024-12-14 23:26:02,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:03,101][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.6930757761001587, acc: 0.7307692170143127)
[2024-12-14 23:26:04,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:06,106][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.8779536485671997, acc: 0.5255972743034363)
[2024-12-14 23:26:06,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:07,313][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 2.4914472103118896, acc: 0.4117647111415863)
[2024-12-14 23:26:07,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:08,026][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.9841399192810059, acc: 0.5)
[2024-12-14 23:26:08,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:08,632][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 2.2271883487701416, acc: 0.4117647111415863)
[2024-12-14 23:26:08,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:09,220][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 2.288498878479004, acc: 0.41304346919059753)
[2024-12-14 23:26:09,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:09,697][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.7870060205459595, acc: 0.574999988079071)
[2024-12-14 23:26:09,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:10,107][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 1.654178500175476, acc: 0.529411792755127)
[2024-12-14 23:26:10,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:10,511][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 1.9303152561187744, acc: 0.4722222089767456)
[2024-12-14 23:26:10,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:10,910][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 1.6299211978912354, acc: 0.59375)
[2024-12-14 23:26:11,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:11,341][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 1.069391131401062, acc: 0.6551724076271057)
[2024-12-14 23:26:11,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:11,743][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 2.313156843185425, acc: 0.4107142984867096)
[2024-12-14 23:26:11,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:12,139][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 2.1426825523376465, acc: 0.36666667461395264)
[2024-12-14 23:26:12,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:12,562][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.7684646844863892, acc: 0.7599999904632568)
[2024-12-14 23:26:12,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:12,970][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.3448394536972046, acc: 0.6388888955116272)
[2024-12-14 23:26:13,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:13,361][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.5276283025741577, acc: 0.5757575631141663)
[2024-12-14 23:26:13,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:13,742][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 2.116586208343506, acc: 0.44117647409439087)
[2024-12-14 23:26:13,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:14,119][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 2.023338556289673, acc: 0.4365079402923584)
[2024-12-14 23:26:14,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:14,512][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 2.2346079349517822, acc: 0.37435898184776306)
[2024-12-14 23:26:14,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:14,869][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.970723032951355, acc: 0.4897959232330322)
[2024-12-14 23:26:14,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:15,256][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 2.432640314102173, acc: 0.3208955228328705)
[2024-12-14 23:26:15,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:15,680][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 2.225085496902466, acc: 0.3759123980998993)
[2024-12-14 23:26:15,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:16,089][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.6532356142997742, acc: 0.8571428656578064)
[2024-12-14 23:26:16,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:16,453][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.5940638184547424, acc: 0.8333333134651184)
[2024-12-14 23:26:16,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:16,826][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 1.1323281526565552, acc: 0.6060606241226196)
[2024-12-14 23:26:16,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:17,184][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.9341555237770081, acc: 0.692307710647583)
[2024-12-14 23:26:17,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:17,571][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.7517201900482178, acc: 0.5384615659713745)
[2024-12-14 23:26:17,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:17,972][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 2.2706730365753174, acc: 0.4038461446762085)
[2024-12-14 23:26:18,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:18,371][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 1.611095905303955, acc: 0.46875)
[2024-12-14 23:26:18,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:18,753][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 1.9630153179168701, acc: 0.4637681245803833)
[2024-12-14 23:26:18,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:19,142][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 1.542123556137085, acc: 0.5400000214576721)
[2024-12-14 23:26:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:19,515][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 1.61847984790802, acc: 0.52173912525177)
[2024-12-14 23:26:19,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:20,025][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 2.3788115978240967, acc: 0.36000001430511475)
[2024-12-14 23:26:20,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:20,520][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.9367729425430298, acc: 0.5048543810844421)
[2024-12-14 23:26:21,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:21,681][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.8863341808319092, acc: 0.5242718458175659)
[2024-12-14 23:26:22,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:22,526][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 2.082307815551758, acc: 0.44086021184921265)
[2024-12-14 23:26:22,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:23,392][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.8114464282989502, acc: 0.5431034564971924)
[2024-12-14 23:26:23,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:24,162][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.5187891721725464, acc: 0.5473684072494507)
[2024-12-14 23:26:24,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:25,193][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 2.3214685916900635, acc: 0.39603960514068604)
[2024-12-14 23:26:25,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:25,611][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 2.3086400032043457, acc: 0.4032258093357086)
[2024-12-14 23:26:25,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:26,018][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 2.383220672607422, acc: 0.3913043439388275)
[2024-12-14 23:26:26,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:26,427][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 2.3126635551452637, acc: 0.3361344635486603)
[2024-12-14 23:26:26,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:26,831][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 2.4485268592834473, acc: 0.3076923191547394)
[2024-12-14 23:26:26,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:27,284][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 2.323763132095337, acc: 0.38686132431030273)
[2024-12-14 23:26:27,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:27,691][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 2.44838285446167, acc: 0.3731343150138855)
[2024-12-14 23:26:27,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:28,057][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 1.0027735233306885, acc: 0.699999988079071)
[2024-12-14 23:26:28,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:28,413][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.9218206405639648, acc: 0.6818181872367859)
[2024-12-14 23:26:28,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:28,838][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.992836594581604, acc: 0.782608687877655)
[2024-12-14 23:26:28,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:29,232][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 1.3824241161346436, acc: 0.6136363744735718)
[2024-12-14 23:26:29,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:29,621][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 1.9399616718292236, acc: 0.4482758641242981)
[2024-12-14 23:26:29,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:29,992][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 1.6417149305343628, acc: 0.5813953280448914)
[2024-12-14 23:26:30,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:30,341][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 1.3781346082687378, acc: 0.6000000238418579)
[2024-12-14 23:26:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:30,734][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.5772805213928223, acc: 0.8235294222831726)
[2024-12-14 23:26:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:31,128][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.5407024025917053, acc: 0.8461538553237915)
[2024-12-14 23:26:31,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:31,502][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 1.5562372207641602, acc: 0.523809552192688)
[2024-12-14 23:26:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:31,870][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 1.825879454612732, acc: 0.5230769515037537)
[2024-12-14 23:26:31,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:32,304][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.7877283096313477, acc: 0.5964912176132202)
[2024-12-14 23:26:32,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:32,700][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.657876968383789, acc: 0.5263158082962036)
[2024-12-14 23:26:32,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:33,078][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 1.9963335990905762, acc: 0.4871794879436493)
[2024-12-14 23:26:33,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:33,486][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 1.3138518333435059, acc: 0.7142857313156128)
[2024-12-14 23:26:33,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:33,840][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.5149051547050476, acc: 0.9090909361839294)
[2024-12-14 23:26:33,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:34,219][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 2.0175039768218994, acc: 0.5079365372657776)
[2024-12-14 23:26:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:34,611][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.9679349660873413, acc: 0.5284552574157715)
[2024-12-14 23:26:34,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:34,999][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 1.6206294298171997, acc: 0.5483871102333069)
[2024-12-14 23:26:35,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:35,905][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 2.0290603637695312, acc: 0.4524714946746826)
[2024-12-14 23:26:36,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:36,282][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 1.6173546314239502, acc: 0.5733333230018616)
[2024-12-14 23:26:36,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:36,719][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.5510985851287842, acc: 0.6346153616905212)
[2024-12-14 23:26:36,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:37,071][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.9092667102813721, acc: 0.875)
[2024-12-14 23:26:37,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:37,450][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 1.4048409461975098, acc: 0.6315789222717285)
[2024-12-14 23:26:37,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:37,857][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 2.0355770587921143, acc: 0.44171780347824097)
[2024-12-14 23:26:37,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:38,250][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.7661393880844116, acc: 0.5416666865348816)
[2024-12-14 23:26:38,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:38,623][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 2.1897659301757812, acc: 0.40833333134651184)
[2024-12-14 23:26:38,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:39,003][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 2.13854718208313, acc: 0.4107142984867096)
[2024-12-14 23:26:39,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:39,410][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.986700415611267, acc: 0.482051283121109)
[2024-12-14 23:26:39,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:39,850][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.8570809364318848, acc: 0.529411792755127)
[2024-12-14 23:26:39,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:40,200][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 1.2025578022003174, acc: 0.6538461446762085)
[2024-12-14 23:26:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:40,565][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.5649762749671936, acc: 0.782608687877655)
[2024-12-14 23:26:40,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:40,948][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.3839863538742065, acc: 0.59375)
[2024-12-14 23:26:41,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:41,327][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.7034186124801636, acc: 0.5652173757553101)
[2024-12-14 23:26:41,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:41,724][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 1.2636771202087402, acc: 0.6571428775787354)
[2024-12-14 23:26:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:42,075][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 1.1654168367385864, acc: 0.5384615659713745)
[2024-12-14 23:26:42,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:42,447][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 2.022106647491455, acc: 0.3095238208770752)
[2024-12-14 23:26:42,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:42,868][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.5226960182189941, acc: 0.5333333611488342)
[2024-12-14 23:26:43,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:43,359][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.8361307382583618, acc: 0.3913043439388275)
[2024-12-14 23:26:44,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:44,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:45,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:45,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:45,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:46,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:47,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:47,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:48,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:48,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:49,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:50,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:50,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:51,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:51,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:51,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:52,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:52,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:52,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:53,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:53,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:53,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:54,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:54,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:55,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:55,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:55,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:56,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:56,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:56,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:57,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:57,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:58,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:58,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:59,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:59,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:59,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:26:59,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:00,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:00,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:00,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:01,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:01,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:01,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:02,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:02,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:02,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:03,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:03,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:03,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:04,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:04,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:05,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:05,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:06,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:06,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:07,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:07,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:07,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:08,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:08,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:08,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:09,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:09,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:10,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:10,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:10,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:11,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:11,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:11,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:12,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:12,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:12,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:13,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:14,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:14,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:15,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:15,917][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.4647, device='cuda:0') eval_epoch_loss=tensor(1.8664, device='cuda:0') eval_epoch_acc=tensor(0.4901, device='cuda:0')
[2024-12-14 23:27:15,920][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:27:15,921][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:27:16,801][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_3_step_139_loss_1.8663570880889893/model.pt
[2024-12-14 23:27:16,806][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:27:16,807][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.8663570880889893
[2024-12-14 23:27:16,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:17,165][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.9229334592819214, acc: 0.6190476417541504)
[2024-12-14 23:27:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:17,511][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 2.2634503841400146, acc: 0.3461538553237915)
[2024-12-14 23:27:17,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:17,925][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 2.8541505336761475, acc: 0.19354838132858276)
[2024-12-14 23:27:18,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:18,302][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 2.2108263969421387, acc: 0.4324324429035187)
[2024-12-14 23:27:18,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:18,847][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 2.0267086029052734, acc: 0.38596490025520325)
[2024-12-14 23:27:18,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:19,236][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.716614007949829, acc: 0.5447761416435242)
[2024-12-14 23:27:19,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:19,638][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 2.325161933898926, acc: 0.36734694242477417)
[2024-12-14 23:27:19,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:20,127][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 2.0918526649475098, acc: 0.38297873735427856)
[2024-12-14 23:27:20,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:20,584][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.8328081369400024, acc: 0.5428571701049805)
[2024-12-14 23:27:20,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:20,949][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 2.2711801528930664, acc: 0.4642857015132904)
[2024-12-14 23:27:21,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:21,298][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 1.4651814699172974, acc: 0.6086956262588501)
[2024-12-14 23:27:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:21,641][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 2.0033586025238037, acc: 0.3448275923728943)
[2024-12-14 23:27:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:22,007][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.9963124990463257, acc: 0.5652173757553101)
[2024-12-14 23:27:22,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:22,442][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 2.0272185802459717, acc: 0.47457626461982727)
[2024-12-14 23:27:22,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:22,831][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 2.2716197967529297, acc: 0.4736842215061188)
[2024-12-14 23:27:22,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:23,224][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.9213420152664185, acc: 0.5)
[2024-12-14 23:27:23,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:23,593][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 1.7191649675369263, acc: 0.6428571343421936)
[2024-12-14 23:27:23,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:23,934][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 1.3738750219345093, acc: 0.6086956262588501)
[2024-12-14 23:27:24,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:24,345][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.8113148212432861, acc: 0.3684210479259491)
[2024-12-14 23:27:25,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:25,997][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.673436164855957, acc: 0.5405405163764954)
[2024-12-14 23:27:26,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:26,364][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 2.068545341491699, acc: 0.4444444477558136)
[2024-12-14 23:27:26,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:26,810][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.7331405878067017, acc: 0.5232558250427246)
[2024-12-14 23:27:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:27,428][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.639394998550415, acc: 0.5176470875740051)
[2024-12-14 23:27:27,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:28,025][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 1.9962173700332642, acc: 0.449438214302063)
[2024-12-14 23:27:28,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:28,430][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 1.6873825788497925, acc: 0.5909090638160706)
[2024-12-14 23:27:28,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:28,809][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 1.4458961486816406, acc: 0.523809552192688)
[2024-12-14 23:27:28,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:29,181][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.5308150053024292, acc: 0.48275861144065857)
[2024-12-14 23:27:29,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:29,569][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 1.6148673295974731, acc: 0.5306122303009033)
[2024-12-14 23:27:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:29,956][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 1.8905534744262695, acc: 0.46000000834465027)
[2024-12-14 23:27:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:30,400][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.6695449352264404, acc: 0.5416666865348816)
[2024-12-14 23:27:30,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:30,789][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 2.0068438053131104, acc: 0.5)
[2024-12-14 23:27:31,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:31,890][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 2.33939528465271, acc: 0.45890411734580994)
[2024-12-14 23:27:31,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:32,257][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 1.097326397895813, acc: 0.7083333134651184)
[2024-12-14 23:27:32,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:32,627][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 1.126792073249817, acc: 0.6296296119689941)
[2024-12-14 23:27:32,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:33,050][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.4881608486175537, acc: 0.7142857313156128)
[2024-12-14 23:27:33,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:33,638][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.8618050813674927, acc: 0.5663716793060303)
[2024-12-14 23:27:33,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:34,015][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.8258203268051147, acc: 0.5507246255874634)
[2024-12-14 23:27:34,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:34,374][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 1.8111884593963623, acc: 0.5)
[2024-12-14 23:27:34,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:35,305][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 2.399689197540283, acc: 0.3664122223854065)
[2024-12-14 23:27:35,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:35,996][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 2.1848232746124268, acc: 0.4000000059604645)
[2024-12-14 23:27:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:36,410][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 1.6213867664337158, acc: 0.5737704634666443)
[2024-12-14 23:27:36,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:36,822][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.9028012156486511, acc: 0.75)
[2024-12-14 23:27:36,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:37,215][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 1.4925427436828613, acc: 0.5600000023841858)
[2024-12-14 23:27:37,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:37,602][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 1.1614153385162354, acc: 0.6785714030265808)
[2024-12-14 23:27:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:37,974][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 2.0660805702209473, acc: 0.4146341383457184)
[2024-12-14 23:27:38,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:38,424][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 2.2821733951568604, acc: 0.38368579745292664)
[2024-12-14 23:27:38,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:38,881][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 2.309540033340454, acc: 0.3890489935874939)
[2024-12-14 23:27:39,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:39,400][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 2.3547425270080566, acc: 0.3843750059604645)
[2024-12-14 23:27:39,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:39,950][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 2.1346378326416016, acc: 0.4127579629421234)
[2024-12-14 23:27:40,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:40,403][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 2.145620346069336, acc: 0.41637009382247925)
[2024-12-14 23:27:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:40,793][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 2.1319704055786133, acc: 0.5199999809265137)
[2024-12-14 23:27:40,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:41,397][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 2.2573044300079346, acc: 0.4651162922382355)
[2024-12-14 23:27:41,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:42,233][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.9708229303359985, acc: 0.5396825671195984)
[2024-12-14 23:27:42,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:43,190][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 2.064061403274536, acc: 0.4545454680919647)
[2024-12-14 23:27:43,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:43,955][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.7208046913146973, acc: 0.5529412031173706)
[2024-12-14 23:27:44,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:45,059][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.7479861974716187, acc: 0.5555555820465088)
[2024-12-14 23:27:45,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:46,038][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 1.457521677017212, acc: 0.6290322542190552)
[2024-12-14 23:27:46,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:46,452][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.8220452070236206, acc: 0.7857142686843872)
[2024-12-14 23:27:46,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:46,923][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.727102279663086, acc: 0.5249999761581421)
[2024-12-14 23:27:47,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:47,328][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.8552265167236328, acc: 0.5)
[2024-12-14 23:27:47,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:47,782][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.971209168434143, acc: 0.4852941036224365)
[2024-12-14 23:27:47,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:48,253][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 2.0435431003570557, acc: 0.5169491767883301)
[2024-12-14 23:27:48,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:48,648][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 2.1765737533569336, acc: 0.447761207818985)
[2024-12-14 23:27:48,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:49,074][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 2.1761109828948975, acc: 0.40776699781417847)
[2024-12-14 23:27:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:49,440][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.8008018732070923, acc: 0.5079365372657776)
[2024-12-14 23:27:49,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:49,856][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 1.8902498483657837, acc: 0.5054945349693298)
[2024-12-14 23:27:49,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:50,296][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 2.0949950218200684, acc: 0.44843047857284546)
[2024-12-14 23:27:50,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:50,723][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 2.1450915336608887, acc: 0.4409448802471161)
[2024-12-14 23:27:50,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:51,172][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 2.0250775814056396, acc: 0.42241379618644714)
[2024-12-14 23:27:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:51,601][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 2.0752041339874268, acc: 0.4384058117866516)
[2024-12-14 23:27:51,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:52,014][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 2.120626211166382, acc: 0.400778204202652)
[2024-12-14 23:27:52,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:52,405][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 2.2742245197296143, acc: 0.3804347813129425)
[2024-12-14 23:27:52,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:52,732][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 1.2429437637329102, acc: 0.695652186870575)
[2024-12-14 23:27:52,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:53,069][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 1.7078841924667358, acc: 0.5714285969734192)
[2024-12-14 23:27:53,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:53,485][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 1.336744785308838, acc: 0.5957446694374084)
[2024-12-14 23:27:53,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:54,230][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 1.7611653804779053, acc: 0.5153846144676208)
[2024-12-14 23:27:54,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:54,601][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 1.6050305366516113, acc: 0.5405405163764954)
[2024-12-14 23:27:54,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:55,034][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 1.476566195487976, acc: 0.5581395626068115)
[2024-12-14 23:27:55,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:55,628][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 1.6215838193893433, acc: 0.5765765905380249)
[2024-12-14 23:27:55,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:56,055][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 1.6322482824325562, acc: 0.5777778029441833)
[2024-12-14 23:27:56,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:56,451][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.9294553995132446, acc: 0.6969696879386902)
[2024-12-14 23:27:56,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:56,874][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.4317914843559265, acc: 0.8888888955116272)
[2024-12-14 23:27:56,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:57,230][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.8363932967185974, acc: 0.6399999856948853)
[2024-12-14 23:27:57,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:57,628][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.9809855222702026, acc: 0.4038461446762085)
[2024-12-14 23:27:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:58,412][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 4.316192150115967, acc: 0.16847826540470123)
[2024-12-14 23:27:58,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:58,988][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 2.8339765071868896, acc: 0.27840909361839294)
[2024-12-14 23:27:59,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:59,462][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 2.28739595413208, acc: 0.3617021143436432)
[2024-12-14 23:27:59,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:27:59,851][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 1.689743995666504, acc: 0.5471698045730591)
[2024-12-14 23:27:59,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:00,239][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 1.9758696556091309, acc: 0.4833333194255829)
[2024-12-14 23:28:00,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:00,621][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 1.1438777446746826, acc: 0.6744186282157898)
[2024-12-14 23:28:00,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:01,007][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 1.156288743019104, acc: 0.699999988079071)
[2024-12-14 23:28:01,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:01,442][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.388843536376953, acc: 0.378947377204895)
[2024-12-14 23:28:01,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:01,788][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.750780701637268, acc: 0.5111111402511597)
[2024-12-14 23:28:01,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:02,238][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.5263190269470215, acc: 0.5944444537162781)
[2024-12-14 23:28:02,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:02,757][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.6923450231552124, acc: 0.5779816508293152)
[2024-12-14 23:28:02,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:03,265][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.6041879653930664, acc: 0.5692307949066162)
[2024-12-14 23:28:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:03,628][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 1.505820631980896, acc: 0.4736842215061188)
[2024-12-14 23:28:03,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:03,994][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 1.3425194025039673, acc: 0.625)
[2024-12-14 23:28:04,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:04,422][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.3784711360931396, acc: 0.3181818127632141)
[2024-12-14 23:28:04,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:04,878][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.9978607892990112, acc: 0.4444444477558136)
[2024-12-14 23:28:05,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:05,301][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 1.4642932415008545, acc: 0.6000000238418579)
[2024-12-14 23:28:05,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:05,808][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.5397299528121948, acc: 0.5681818127632141)
[2024-12-14 23:28:05,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:06,175][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.871169924736023, acc: 0.47727271914482117)
[2024-12-14 23:28:06,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:06,841][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.9328083992004395, acc: 0.4354838728904724)
[2024-12-14 23:28:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:07,429][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.5490975379943848, acc: 0.5909090638160706)
[2024-12-14 23:28:07,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:07,836][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.5566613078117371, acc: 0.8571428656578064)
[2024-12-14 23:28:07,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:08,212][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 1.1342991590499878, acc: 0.692307710647583)
[2024-12-14 23:28:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:08,607][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 1.3162600994110107, acc: 0.774193525314331)
[2024-12-14 23:28:08,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:08,988][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 1.1088802814483643, acc: 0.6000000238418579)
[2024-12-14 23:28:09,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:09,446][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 1.3327264785766602, acc: 0.6216216087341309)
[2024-12-14 23:28:09,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:09,855][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 1.7625446319580078, acc: 0.45945945382118225)
[2024-12-14 23:28:09,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:10,247][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 1.5398951768875122, acc: 0.45945945382118225)
[2024-12-14 23:28:10,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:10,681][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 1.8687578439712524, acc: 0.4852941036224365)
[2024-12-14 23:28:10,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:11,049][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.8909443020820618, acc: 0.6097561120986938)
[2024-12-14 23:28:11,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:11,395][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.5020504593849182, acc: 0.8399999737739563)
[2024-12-14 23:28:11,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:11,740][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.5881004929542542, acc: 0.8799999952316284)
[2024-12-14 23:28:11,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:12,078][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.6172882318496704, acc: 0.8387096524238586)
[2024-12-14 23:28:12,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:12,434][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 1.6043422222137451, acc: 0.5438596606254578)
[2024-12-14 23:28:12,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:12,775][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 1.5746265649795532, acc: 0.6142857074737549)
[2024-12-14 23:28:12,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:13,150][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 1.3839752674102783, acc: 0.6184210777282715)
[2024-12-14 23:28:13,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:13,753][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.7122610807418823, acc: 0.46226415038108826)
[2024-12-14 23:28:13,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:14,366][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 1.8279904127120972, acc: 0.5166666507720947)
[2024-12-14 23:28:14,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:14,746][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 1.3819268941879272, acc: 0.5555555820465088)
[2024-12-14 23:28:14,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:15,071][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 1.7473618984222412, acc: 0.5483871102333069)
[2024-12-14 23:28:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:15,451][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 2.8204915523529053, acc: 0.36000001430511475)
[2024-12-14 23:28:15,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:15,897][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 2.337106943130493, acc: 0.375)
[2024-12-14 23:28:16,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:16,793][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 2.5806033611297607, acc: 0.328000009059906)
[2024-12-14 23:28:16,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:17,161][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 2.1974642276763916, acc: 0.42696627974510193)
[2024-12-14 23:28:17,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:17,568][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 2.2441821098327637, acc: 0.5135135054588318)
[2024-12-14 23:28:17,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:18,065][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 1.547366976737976, acc: 0.5344827771186829)
[2024-12-14 23:28:18,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:18,439][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 1.3872853517532349, acc: 0.6363636255264282)
[2024-12-14 23:28:18,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:18,818][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 1.615095615386963, acc: 0.5)
[2024-12-14 23:28:18,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:19,183][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.9739278554916382, acc: 0.71875)
[2024-12-14 23:28:19,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:19,569][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 1.1901427507400513, acc: 0.6333333253860474)
[2024-12-14 23:28:19,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:20,057][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 1.9277178049087524, acc: 0.44999998807907104)
[2024-12-14 23:28:20,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:20,424][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 1.3658370971679688, acc: 0.625)
[2024-12-14 23:28:20,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:20,781][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 1.0381771326065063, acc: 0.699999988079071)
[2024-12-14 23:28:20,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:21,115][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 1.2364696264266968, acc: 0.6896551847457886)
[2024-12-14 23:28:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:21,446][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 1.155646562576294, acc: 0.6399999856948853)
[2024-12-14 23:28:21,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:21,868][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 2.0956056118011475, acc: 0.44680851697921753)
[2024-12-14 23:28:22,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:22,292][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 1.8030524253845215, acc: 0.5416666865348816)
[2024-12-14 23:28:22,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:22,639][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 1.7532674074172974, acc: 0.5909090638160706)
[2024-12-14 23:28:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:23,094][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 2.183492660522461, acc: 0.4819277226924896)
[2024-12-14 23:28:23,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:24,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:24,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:24,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:25,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:25,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:25,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:26,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:26,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:27,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:27,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:27,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:28,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:28,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:29,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:29,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:29,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:30,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:30,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:30,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:31,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:31,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:32,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:32,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:32,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:33,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:33,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:33,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:34,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:34,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:35,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:35,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:36,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:36,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:37,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:37,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:37,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:38,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:38,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:39,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:40,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:40,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:40,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:41,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:41,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:42,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:42,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:43,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:43,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:43,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:44,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:44,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:44,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:45,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:45,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:46,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:46,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:47,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:47,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:47,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:48,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:48,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:49,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:49,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:49,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:50,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:50,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:50,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:51,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:51,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:52,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:52,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:52,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:53,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:53,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:53,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:54,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:54,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:54,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:55,614][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7607, device='cuda:0') eval_epoch_loss=tensor(1.9111, device='cuda:0') eval_epoch_acc=tensor(0.5215, device='cuda:0')
[2024-12-14 23:28:55,616][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:28:55,616][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:28:56,510][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_3_step_282_loss_1.911130666732788/model.pt
[2024-12-14 23:28:56,519][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:28:56,520][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.5214832425117493
[2024-12-14 23:28:56,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:57,002][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 2.036841869354248, acc: 0.46296295523643494)
[2024-12-14 23:28:57,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:57,493][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 2.0514631271362305, acc: 0.34210526943206787)
[2024-12-14 23:28:57,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:57,858][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 2.1451802253723145, acc: 0.4117647111415863)
[2024-12-14 23:28:57,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:58,225][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 1.9474525451660156, acc: 0.44999998807907104)
[2024-12-14 23:28:58,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:58,632][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 2.131422996520996, acc: 0.3828125)
[2024-12-14 23:28:58,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:59,041][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 2.3000831604003906, acc: 0.4000000059604645)
[2024-12-14 23:28:59,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:59,412][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 1.8884996175765991, acc: 0.47252747416496277)
[2024-12-14 23:28:59,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:28:59,783][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 2.286595106124878, acc: 0.3726707994937897)
[2024-12-14 23:28:59,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:00,185][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 2.40570330619812, acc: 0.35567009449005127)
[2024-12-14 23:29:00,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:00,615][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 1.0176581144332886, acc: 0.6818181872367859)
[2024-12-14 23:29:00,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:01,000][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 2.0429890155792236, acc: 0.4285714328289032)
[2024-12-14 23:29:01,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:01,366][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 1.5111143589019775, acc: 0.6206896305084229)
[2024-12-14 23:29:01,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:01,867][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 1.3759887218475342, acc: 0.6727272868156433)
[2024-12-14 23:29:02,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:02,449][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.7397106885910034, acc: 0.5515463948249817)
[2024-12-14 23:29:02,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:02,876][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.99607253074646, acc: 0.43103447556495667)
[2024-12-14 23:29:03,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:03,255][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 1.9262670278549194, acc: 0.5555555820465088)
[2024-12-14 23:29:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:03,642][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 1.8827333450317383, acc: 0.5263158082962036)
[2024-12-14 23:29:03,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:04,027][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 1.6436063051223755, acc: 0.5535714030265808)
[2024-12-14 23:29:04,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:04,370][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 1.772782564163208, acc: 0.5)
[2024-12-14 23:29:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:04,807][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 1.7455830574035645, acc: 0.5660377144813538)
[2024-12-14 23:29:04,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:05,252][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 1.086639165878296, acc: 0.6792452931404114)
[2024-12-14 23:29:05,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:05,643][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 1.2660210132598877, acc: 0.7058823704719543)
[2024-12-14 23:29:05,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:05,997][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 1.7699607610702515, acc: 0.5625)
[2024-12-14 23:29:06,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:06,357][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 1.4564249515533447, acc: 0.6229507923126221)
[2024-12-14 23:29:06,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:06,688][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.7762669920921326, acc: 0.800000011920929)
[2024-12-14 23:29:06,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:07,064][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.6617539525032043, acc: 0.7894737124443054)
[2024-12-14 23:29:07,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:07,474][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 1.8065459728240967, acc: 0.47826087474823)
[2024-12-14 23:29:07,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:07,917][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 1.7315338850021362, acc: 0.5972222089767456)
[2024-12-14 23:29:08,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:08,299][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 1.5680556297302246, acc: 0.5060241222381592)
[2024-12-14 23:29:08,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:08,675][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 2.0701377391815186, acc: 0.44871795177459717)
[2024-12-14 23:29:08,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:09,075][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 2.2955708503723145, acc: 0.37755101919174194)
[2024-12-14 23:29:09,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:09,430][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.3273850381374359, acc: 0.9166666865348816)
[2024-12-14 23:29:09,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:09,785][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 1.0211305618286133, acc: 0.7083333134651184)
[2024-12-14 23:29:09,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:10,158][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.8835443258285522, acc: 0.7096773982048035)
[2024-12-14 23:29:10,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:10,566][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 1.033881425857544, acc: 0.6451612710952759)
[2024-12-14 23:29:10,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:10,955][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 1.421020269393921, acc: 0.5820895433425903)
[2024-12-14 23:29:11,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:11,332][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 1.3652585744857788, acc: 0.6442307829856873)
[2024-12-14 23:29:11,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:11,693][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 1.747665286064148, acc: 0.4888888895511627)
[2024-12-14 23:29:11,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:12,055][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 1.4838356971740723, acc: 0.5645161271095276)
[2024-12-14 23:29:12,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:12,448][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.9779864549636841, acc: 0.7200000286102295)
[2024-12-14 23:29:12,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:12,897][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 2.237013101577759, acc: 0.40740740299224854)
[2024-12-14 23:29:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:13,269][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.8001601696014404, acc: 0.20000000298023224)
[2024-12-14 23:29:13,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:13,648][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 2.3116090297698975, acc: 0.3333333432674408)
[2024-12-14 23:29:13,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:14,020][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.3732941150665283, acc: 0.3658536672592163)
[2024-12-14 23:29:14,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:14,385][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 2.0903983116149902, acc: 0.4736842215061188)
[2024-12-14 23:29:14,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:14,742][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 1.157230019569397, acc: 0.7368420958518982)
[2024-12-14 23:29:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:15,087][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.8225052952766418, acc: 0.7857142686843872)
[2024-12-14 23:29:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:15,455][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 2.033304214477539, acc: 0.40740740299224854)
[2024-12-14 23:29:15,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:15,875][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.9462738037109375, acc: 0.75)
[2024-12-14 23:29:16,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:16,366][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 1.6929079294204712, acc: 0.5806451439857483)
[2024-12-14 23:29:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:16,778][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 1.6953238248825073, acc: 0.4912280738353729)
[2024-12-14 23:29:16,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:17,169][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 2.3633363246917725, acc: 0.375)
[2024-12-14 23:29:17,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:17,639][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 1.2632336616516113, acc: 0.6666666865348816)
[2024-12-14 23:29:17,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:18,011][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 1.741938591003418, acc: 0.3684210479259491)
[2024-12-14 23:29:18,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:18,371][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 2.229116916656494, acc: 0.3400000035762787)
[2024-12-14 23:29:18,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:18,754][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 2.227771043777466, acc: 0.36781609058380127)
[2024-12-14 23:29:18,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:19,149][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 2.457453489303589, acc: 0.3510638177394867)
[2024-12-14 23:29:19,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:19,530][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 2.409522533416748, acc: 0.4337349534034729)
[2024-12-14 23:29:19,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:19,939][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 1.1257766485214233, acc: 0.6086956262588501)
[2024-12-14 23:29:20,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:20,287][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 2.081482172012329, acc: 0.41025641560554504)
[2024-12-14 23:29:20,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:20,682][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 2.3287606239318848, acc: 0.4337349534034729)
[2024-12-14 23:29:20,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:21,081][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 1.794358730316162, acc: 0.5471698045730591)
[2024-12-14 23:29:21,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:21,473][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 1.9065529108047485, acc: 0.49367088079452515)
[2024-12-14 23:29:21,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:21,841][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 1.8413115739822388, acc: 0.4901960790157318)
[2024-12-14 23:29:21,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:22,203][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 2.4226505756378174, acc: 0.31343284249305725)
[2024-12-14 23:29:22,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:22,596][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.9490057229995728, acc: 0.75)
[2024-12-14 23:29:22,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:22,968][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 1.3796374797821045, acc: 0.6000000238418579)
[2024-12-14 23:29:23,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:23,432][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 1.4372771978378296, acc: 0.6388888955116272)
[2024-12-14 23:29:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:23,843][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.8666843175888062, acc: 0.5581395626068115)
[2024-12-14 23:29:23,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:24,244][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 1.8767821788787842, acc: 0.4615384638309479)
[2024-12-14 23:29:24,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:24,654][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.8494467735290527, acc: 0.4888888895511627)
[2024-12-14 23:29:24,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:24,985][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.7046928405761719, acc: 0.782608687877655)
[2024-12-14 23:29:25,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:25,341][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.9551470279693604, acc: 0.5384615659713745)
[2024-12-14 23:29:25,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:25,744][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 2.296053886413574, acc: 0.3956044018268585)
[2024-12-14 23:29:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:26,297][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.9255660772323608, acc: 0.5043478012084961)
[2024-12-14 23:29:26,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:26,713][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 2.0074269771575928, acc: 0.510869562625885)
[2024-12-14 23:29:26,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:27,110][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 2.053115129470825, acc: 0.44897958636283875)
[2024-12-14 23:29:27,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:27,481][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.35006770491600037, acc: 0.875)
[2024-12-14 23:29:27,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:27,820][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.9558699131011963, acc: 0.692307710647583)
[2024-12-14 23:29:27,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:28,153][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 1.430924892425537, acc: 0.6341463327407837)
[2024-12-14 23:29:28,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:28,503][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 1.7023828029632568, acc: 0.5333333611488342)
[2024-12-14 23:29:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:28,847][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 1.929567813873291, acc: 0.4868420958518982)
[2024-12-14 23:29:28,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:29,189][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 1.7632710933685303, acc: 0.5365853905677795)
[2024-12-14 23:29:29,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:29,574][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 1.788703441619873, acc: 0.4848484992980957)
[2024-12-14 23:29:29,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:29,913][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.7562234997749329, acc: 0.75)
[2024-12-14 23:29:30,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:30,258][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.5643371343612671, acc: 0.8695651888847351)
[2024-12-14 23:29:30,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:30,618][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.7772369980812073, acc: 0.75)
[2024-12-14 23:29:30,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:30,994][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 1.2383882999420166, acc: 0.59375)
[2024-12-14 23:29:31,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:31,634][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.8229994773864746, acc: 0.521212100982666)
[2024-12-14 23:29:32,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:32,605][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 1.395774245262146, acc: 0.6792452931404114)
[2024-12-14 23:29:32,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:33,064][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 1.749359130859375, acc: 0.5444444417953491)
[2024-12-14 23:29:33,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:33,419][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 1.6638036966323853, acc: 0.5)
[2024-12-14 23:29:33,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:33,861][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 1.019921898841858, acc: 0.6857143044471741)
[2024-12-14 23:29:34,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:34,309][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.601201593875885, acc: 0.8799999952316284)
[2024-12-14 23:29:34,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:34,749][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.7203018069267273, acc: 0.695652186870575)
[2024-12-14 23:29:34,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:35,111][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 1.6365470886230469, acc: 0.5833333134651184)
[2024-12-14 23:29:35,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:35,502][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 1.5960476398468018, acc: 0.5789473652839661)
[2024-12-14 23:29:35,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:36,098][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 1.7119144201278687, acc: 0.56886225938797)
[2024-12-14 23:29:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:36,552][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 1.6217666864395142, acc: 0.5639097690582275)
[2024-12-14 23:29:37,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:37,802][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 1.6977370977401733, acc: 0.5240641832351685)
[2024-12-14 23:29:38,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:38,394][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 1.4454082250595093, acc: 0.6216216087341309)
[2024-12-14 23:29:38,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:38,763][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.855359673500061, acc: 0.75)
[2024-12-14 23:29:38,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:39,099][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.7045157551765442, acc: 0.7857142686843872)
[2024-12-14 23:29:39,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:39,471][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 1.1148093938827515, acc: 0.71875)
[2024-12-14 23:29:39,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:39,841][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 1.1480060815811157, acc: 0.6666666865348816)
[2024-12-14 23:29:39,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:40,192][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 1.0591765642166138, acc: 0.7631579041481018)
[2024-12-14 23:29:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:40,540][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.6278488636016846, acc: 0.8181818127632141)
[2024-12-14 23:29:40,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:40,925][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.8858656883239746, acc: 0.6000000238418579)
[2024-12-14 23:29:41,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:41,309][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 1.050797462463379, acc: 0.6190476417541504)
[2024-12-14 23:29:41,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:41,685][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 2.4851980209350586, acc: 0.40740740299224854)
[2024-12-14 23:29:41,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:42,064][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 2.2819619178771973, acc: 0.43689319491386414)
[2024-12-14 23:29:42,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:42,610][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.8618282079696655, acc: 0.5220588445663452)
[2024-12-14 23:29:42,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:43,018][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 2.2469594478607178, acc: 0.4533333480358124)
[2024-12-14 23:29:43,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:43,487][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 2.145418643951416, acc: 0.4513888955116272)
[2024-12-14 23:29:43,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:43,890][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 1.844826579093933, acc: 0.4883720874786377)
[2024-12-14 23:29:43,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:44,236][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 1.1517540216445923, acc: 0.6666666865348816)
[2024-12-14 23:29:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:44,614][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 1.4892399311065674, acc: 0.5813953280448914)
[2024-12-14 23:29:44,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:44,987][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 1.4874252080917358, acc: 0.6800000071525574)
[2024-12-14 23:29:45,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:45,575][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 1.7310853004455566, acc: 0.5588235259056091)
[2024-12-14 23:29:45,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:45,961][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 1.518620252609253, acc: 0.4933333396911621)
[2024-12-14 23:29:46,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:46,305][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 1.2926839590072632, acc: 0.5757575631141663)
[2024-12-14 23:29:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:46,648][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 1.3860329389572144, acc: 0.6666666865348816)
[2024-12-14 23:29:46,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:47,027][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.8969002962112427, acc: 0.8064516186714172)
[2024-12-14 23:29:47,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:47,438][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 1.2690523862838745, acc: 0.6296296119689941)
[2024-12-14 23:29:47,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:47,811][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.72332763671875, acc: 0.8399999737739563)
[2024-12-14 23:29:47,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:48,239][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.7992361783981323, acc: 0.75)
[2024-12-14 23:29:48,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:48,608][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.8459368348121643, acc: 0.7407407164573669)
[2024-12-14 23:29:48,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:48,962][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.7217117547988892, acc: 0.807692289352417)
[2024-12-14 23:29:49,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:49,346][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 1.223731517791748, acc: 0.6551724076271057)
[2024-12-14 23:29:49,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:49,687][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.7442088723182678, acc: 0.7857142686843872)
[2024-12-14 23:29:49,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:50,126][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.9745599627494812, acc: 0.699999988079071)
[2024-12-14 23:29:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:50,517][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 1.0104185342788696, acc: 0.6969696879386902)
[2024-12-14 23:29:50,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:50,882][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.8613179922103882, acc: 0.6363636255264282)
[2024-12-14 23:29:50,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:51,236][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 1.9948031902313232, acc: 0.4901960790157318)
[2024-12-14 23:29:51,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:51,576][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 2.138960361480713, acc: 0.5384615659713745)
[2024-12-14 23:29:51,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:51,985][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 1.7300039529800415, acc: 0.5555555820465088)
[2024-12-14 23:29:52,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:52,454][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 1.62594473361969, acc: 0.550000011920929)
[2024-12-14 23:29:52,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:52,825][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 1.748084306716919, acc: 0.4000000059604645)
[2024-12-14 23:29:52,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:53,187][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.5261453986167908, acc: 0.761904776096344)
[2024-12-14 23:29:53,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:53,578][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 1.137383222579956, acc: 0.699999988079071)
[2024-12-14 23:29:53,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:54,009][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 1.393046259880066, acc: 0.6875)
[2024-12-14 23:29:54,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:54,395][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 1.749111533164978, acc: 0.5277777910232544)
[2024-12-14 23:29:54,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:54,746][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 1.275598168373108, acc: 0.6666666865348816)
[2024-12-14 23:29:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:56,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:56,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:57,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:57,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:58,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:59,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:29:59,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:00,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:00,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:01,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:01,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:02,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:02,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:03,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:03,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:04,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:04,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:04,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:05,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:05,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:05,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:06,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:07,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:07,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:07,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:08,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:08,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:09,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:09,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:09,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:10,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:10,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:10,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:11,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:11,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:12,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:12,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:13,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:13,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:14,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:14,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:15,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:15,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:15,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:16,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:16,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:16,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:17,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:17,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:18,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:19,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:19,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:19,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:20,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:20,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:20,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:21,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:21,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:22,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:22,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:22,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:23,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:23,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:23,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:24,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:24,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:24,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:25,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:25,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:26,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:26,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:26,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:28,072][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.4319, device='cuda:0') eval_epoch_loss=tensor(2.1320, device='cuda:0') eval_epoch_acc=tensor(0.4834, device='cuda:0')
[2024-12-14 23:30:28,074][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:30:28,074][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:30:28,968][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_3_step_425_loss_2.132025957107544/model.pt
[2024-12-14 23:30:28,977][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:30:29,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:29,431][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 1.619315266609192, acc: 0.6969696879386902)
[2024-12-14 23:30:29,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:29,864][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 1.793787956237793, acc: 0.6086956262588501)
[2024-12-14 23:30:29,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:30,252][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 1.3815999031066895, acc: 0.5945945978164673)
[2024-12-14 23:30:30,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:30,658][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.9175360798835754, acc: 0.7407407164573669)
[2024-12-14 23:30:30,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:31,004][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 1.1182819604873657, acc: 0.52173912525177)
[2024-12-14 23:30:31,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:31,351][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.8825517296791077, acc: 0.7407407164573669)
[2024-12-14 23:30:31,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:31,702][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.7978671789169312, acc: 0.7777777910232544)
[2024-12-14 23:30:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:32,075][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 1.156391978263855, acc: 0.6521739363670349)
[2024-12-14 23:30:32,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:32,452][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 1.1271936893463135, acc: 0.7222222089767456)
[2024-12-14 23:30:32,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:32,790][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.7111100554466248, acc: 0.8799999952316284)
[2024-12-14 23:30:32,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:33,220][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 1.2245622873306274, acc: 0.6969696879386902)
[2024-12-14 23:30:33,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:33,622][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 1.4342714548110962, acc: 0.6388888955116272)
[2024-12-14 23:30:33,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:33,998][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 1.2087336778640747, acc: 0.75)
[2024-12-14 23:30:34,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:34,331][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.57374107837677, acc: 0.8571428656578064)
[2024-12-14 23:30:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:34,790][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 1.7041765451431274, acc: 0.5384615659713745)
[2024-12-14 23:30:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:35,296][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 1.846187949180603, acc: 0.5151515007019043)
[2024-12-14 23:30:35,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:36,070][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 2.3059616088867188, acc: 0.3840000033378601)
[2024-12-14 23:30:36,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:36,508][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 2.1396491527557373, acc: 0.44354838132858276)
[2024-12-14 23:30:36,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:37,180][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 2.102043390274048, acc: 0.42786070704460144)
[2024-12-14 23:30:37,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:37,554][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 1.8770681619644165, acc: 0.5094339847564697)
[2024-12-14 23:30:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:38,005][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 1.0529136657714844, acc: 0.6590909361839294)
[2024-12-14 23:30:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:38,359][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 1.182010531425476, acc: 0.6521739363670349)
[2024-12-14 23:30:38,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:38,731][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 1.1568857431411743, acc: 0.692307710647583)
[2024-12-14 23:30:38,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:39,128][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.8961337208747864, acc: 0.7857142686843872)
[2024-12-14 23:30:39,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:39,495][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 1.9019711017608643, acc: 0.4776119291782379)
[2024-12-14 23:30:39,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:39,857][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 1.764225959777832, acc: 0.5694444179534912)
[2024-12-14 23:30:40,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:40,266][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 1.7466566562652588, acc: 0.510869562625885)
[2024-12-14 23:30:40,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:40,655][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 1.7770256996154785, acc: 0.5128205418586731)
[2024-12-14 23:30:40,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:41,006][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 1.9673186540603638, acc: 0.5394737124443054)
[2024-12-14 23:30:41,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:41,364][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 1.8509597778320312, acc: 0.5102040767669678)
[2024-12-14 23:30:41,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:41,717][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 1.153681755065918, acc: 0.6666666865348816)
[2024-12-14 23:30:41,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:42,095][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 2.062561273574829, acc: 0.4536082446575165)
[2024-12-14 23:30:42,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:42,475][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 1.7569222450256348, acc: 0.5142857432365417)
[2024-12-14 23:30:42,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:42,896][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.944006323814392, acc: 0.48255813121795654)
[2024-12-14 23:30:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:43,311][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 2.1176295280456543, acc: 0.4464285671710968)
[2024-12-14 23:30:43,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:43,701][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 1.9409306049346924, acc: 0.4444444477558136)
[2024-12-14 23:30:43,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:44,063][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 1.7365974187850952, acc: 0.4722222089767456)
[2024-12-14 23:30:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:44,395][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 1.207382321357727, acc: 0.65625)
[2024-12-14 23:30:44,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:44,812][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 1.274885654449463, acc: 0.5)
[2024-12-14 23:30:44,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:45,252][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 1.4935657978057861, acc: 0.6086956262588501)
[2024-12-14 23:30:45,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:45,631][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 1.7887017726898193, acc: 0.4523809552192688)
[2024-12-14 23:30:45,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:46,023][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 1.8963266611099243, acc: 0.46987950801849365)
[2024-12-14 23:30:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:46,402][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 1.5647833347320557, acc: 0.5765765905380249)
[2024-12-14 23:30:46,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:46,798][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.756058931350708, acc: 0.5339806079864502)
[2024-12-14 23:30:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:47,203][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 1.5910155773162842, acc: 0.5691056847572327)
[2024-12-14 23:30:47,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:47,588][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 1.3268345594406128, acc: 0.625)
[2024-12-14 23:30:47,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:47,973][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 1.896849513053894, acc: 0.5357142686843872)
[2024-12-14 23:30:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:48,439][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 2.186079978942871, acc: 0.343137264251709)
[2024-12-14 23:30:48,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:48,857][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 2.187608242034912, acc: 0.4192139804363251)
[2024-12-14 23:30:48,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:49,261][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 2.089329481124878, acc: 0.4166666567325592)
[2024-12-14 23:30:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:49,655][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 2.1425654888153076, acc: 0.4171779155731201)
[2024-12-14 23:30:49,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:50,047][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 2.158583879470825, acc: 0.4532374143600464)
[2024-12-14 23:30:50,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:50,450][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 2.1714019775390625, acc: 0.402010053396225)
[2024-12-14 23:30:50,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:50,820][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 1.261486530303955, acc: 0.6388888955116272)
[2024-12-14 23:30:50,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:51,236][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 1.3121612071990967, acc: 0.6363636255264282)
[2024-12-14 23:30:51,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:51,617][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 1.1534315347671509, acc: 0.6296296119689941)
[2024-12-14 23:30:51,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:52,009][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 1.119411826133728, acc: 0.699999988079071)
[2024-12-14 23:30:52,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:52,358][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.7440139651298523, acc: 0.800000011920929)
[2024-12-14 23:30:52,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:52,780][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 1.4266506433486938, acc: 0.6034482717514038)
[2024-12-14 23:30:52,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:53,122][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 1.1131665706634521, acc: 0.6451612710952759)
[2024-12-14 23:30:53,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:53,474][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.7959261536598206, acc: 0.8421052694320679)
[2024-12-14 23:30:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:53,891][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 1.7304344177246094, acc: 0.5555555820465088)
[2024-12-14 23:30:53,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:54,243][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 1.7898244857788086, acc: 0.3333333432674408)
[2024-12-14 23:30:54,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:54,623][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 1.5567564964294434, acc: 0.5454545617103577)
[2024-12-14 23:30:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:55,021][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.8919837474822998, acc: 0.446153849363327)
[2024-12-14 23:30:55,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:55,397][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 1.4560080766677856, acc: 0.6000000238418579)
[2024-12-14 23:30:55,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:55,750][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 1.6043972969055176, acc: 0.5862069129943848)
[2024-12-14 23:30:55,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:56,101][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 1.816213607788086, acc: 0.47058823704719543)
[2024-12-14 23:30:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:56,473][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 1.5006499290466309, acc: 0.4482758641242981)
[2024-12-14 23:30:56,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:56,822][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.6509498357772827, acc: 0.8421052694320679)
[2024-12-14 23:30:56,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:57,189][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 2.064754009246826, acc: 0.42105263471603394)
[2024-12-14 23:30:57,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:57,585][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.717726707458496, acc: 0.5357142686843872)
[2024-12-14 23:30:57,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:58,005][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 1.8498601913452148, acc: 0.47191011905670166)
[2024-12-14 23:30:58,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:58,387][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 2.01822829246521, acc: 0.42696627974510193)
[2024-12-14 23:30:58,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:58,809][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 2.2836873531341553, acc: 0.39007091522216797)
[2024-12-14 23:30:58,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:59,188][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 2.413919687271118, acc: 0.3913043439388275)
[2024-12-14 23:30:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:59,555][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.8198068737983704, acc: 0.8799999952316284)
[2024-12-14 23:30:59,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:30:59,921][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.7955261468887329, acc: 0.7307692170143127)
[2024-12-14 23:31:00,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:00,260][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.7499343156814575, acc: 0.7777777910232544)
[2024-12-14 23:31:00,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:00,618][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 1.6292109489440918, acc: 0.4444444477558136)
[2024-12-14 23:31:00,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:00,984][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 1.4206979274749756, acc: 0.5660377144813538)
[2024-12-14 23:31:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:01,318][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 1.0353373289108276, acc: 0.6551724076271057)
[2024-12-14 23:31:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:01,936][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.8712005615234375, acc: 0.46846845746040344)
[2024-12-14 23:31:02,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:02,410][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 1.6827906370162964, acc: 0.5352112650871277)
[2024-12-14 23:31:02,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:02,752][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.4945439398288727, acc: 0.8500000238418579)
[2024-12-14 23:31:02,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:03,084][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.709061861038208, acc: 0.800000011920929)
[2024-12-14 23:31:03,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:03,418][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 1.0195835828781128, acc: 0.692307710647583)
[2024-12-14 23:31:05,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:06,013][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.9148972034454346, acc: 0.48571428656578064)
[2024-12-14 23:31:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:06,798][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 1.8015689849853516, acc: 0.5476190447807312)
[2024-12-14 23:31:06,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:07,143][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 1.2665590047836304, acc: 0.6428571343421936)
[2024-12-14 23:31:07,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:07,516][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 1.5264678001403809, acc: 0.5833333134651184)
[2024-12-14 23:31:07,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:08,243][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 1.5426238775253296, acc: 0.5972222089767456)
[2024-12-14 23:31:08,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:08,639][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.5234520435333252, acc: 0.7692307829856873)
[2024-12-14 23:31:08,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:09,013][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 1.3073443174362183, acc: 0.6129032373428345)
[2024-12-14 23:31:09,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:09,394][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 1.2926266193389893, acc: 0.6000000238418579)
[2024-12-14 23:31:09,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:09,757][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 1.6309806108474731, acc: 0.5555555820465088)
[2024-12-14 23:31:10,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:10,768][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 2.005622148513794, acc: 0.45338982343673706)
[2024-12-14 23:31:10,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:11,155][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 2.0389063358306885, acc: 0.49253731966018677)
[2024-12-14 23:31:11,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:11,576][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 2.02952241897583, acc: 0.44525548815727234)
[2024-12-14 23:31:11,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:12,159][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 1.875456690788269, acc: 0.5149999856948853)
[2024-12-14 23:31:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:12,498][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 1.9058140516281128, acc: 0.5)
[2024-12-14 23:31:12,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:12,840][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 1.716410756111145, acc: 0.5192307829856873)
[2024-12-14 23:31:12,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:13,180][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 1.7025455236434937, acc: 0.4285714328289032)
[2024-12-14 23:31:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:13,525][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 2.599273920059204, acc: 0.2950819730758667)
[2024-12-14 23:31:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:13,831][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 1.779664158821106, acc: 0.5762711763381958)
[2024-12-14 23:31:13,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:14,268][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 2.1009294986724854, acc: 0.4651162922382355)
[2024-12-14 23:31:14,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:14,642][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 1.9794650077819824, acc: 0.4318181872367859)
[2024-12-14 23:31:14,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:15,014][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 2.346304178237915, acc: 0.35849055647850037)
[2024-12-14 23:31:15,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:15,343][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 1.5532207489013672, acc: 0.6590909361839294)
[2024-12-14 23:31:15,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:15,705][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 1.566968560218811, acc: 0.5600000023841858)
[2024-12-14 23:31:15,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:16,122][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 1.3202297687530518, acc: 0.6499999761581421)
[2024-12-14 23:31:16,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:16,490][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 1.0740751028060913, acc: 0.7272727489471436)
[2024-12-14 23:31:16,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:16,914][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 1.7734674215316772, acc: 0.5384615659713745)
[2024-12-14 23:31:17,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:17,388][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 1.695207118988037, acc: 0.546875)
[2024-12-14 23:31:17,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:17,844][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 1.1896460056304932, acc: 0.75)
[2024-12-14 23:31:17,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:18,215][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 1.67071533203125, acc: 0.4848484992980957)
[2024-12-14 23:31:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:18,589][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.7655878067016602, acc: 0.6875)
[2024-12-14 23:31:18,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:18,967][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.7537362575531006, acc: 0.7419354915618896)
[2024-12-14 23:31:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:19,330][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.6050799489021301, acc: 0.739130437374115)
[2024-12-14 23:31:19,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:19,667][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 1.7546722888946533, acc: 0.5)
[2024-12-14 23:31:19,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:20,023][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 1.3819208145141602, acc: 0.5121951103210449)
[2024-12-14 23:31:20,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:20,369][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 1.010855793952942, acc: 0.7428571581840515)
[2024-12-14 23:31:20,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:20,733][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 1.034918189048767, acc: 0.7105262875556946)
[2024-12-14 23:31:20,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:21,115][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 1.2131949663162231, acc: 0.6451612710952759)
[2024-12-14 23:31:21,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:21,475][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.6130096316337585, acc: 0.8399999737739563)
[2024-12-14 23:31:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:21,822][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 1.0177909135818481, acc: 0.7272727489471436)
[2024-12-14 23:31:21,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:22,168][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.980108916759491, acc: 0.675000011920929)
[2024-12-14 23:31:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:22,546][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 1.202601432800293, acc: 0.6142857074737549)
[2024-12-14 23:31:22,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:22,868][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 2.1771559715270996, acc: 0.42335766553878784)
[2024-12-14 23:31:23,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:23,275][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 1.6667248010635376, acc: 0.565517246723175)
[2024-12-14 23:31:23,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:23,720][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 2.3890976905822754, acc: 0.40714284777641296)
[2024-12-14 23:31:23,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:24,132][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 2.1463284492492676, acc: 0.443708598613739)
[2024-12-14 23:31:24,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:24,506][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 1.6126649379730225, acc: 0.5470085740089417)
[2024-12-14 23:31:24,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:24,901][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.6107284426689148, acc: 0.800000011920929)
[2024-12-14 23:31:25,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:25,266][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 1.2700912952423096, acc: 0.5769230723381042)
[2024-12-14 23:31:25,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:25,645][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.626773476600647, acc: 0.8461538553237915)
[2024-12-14 23:31:25,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:26,019][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 1.452351450920105, acc: 0.5897436141967773)
[2024-12-14 23:31:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:26,404][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 1.5786678791046143, acc: 0.5666666626930237)
[2024-12-14 23:31:26,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:26,807][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 1.4534658193588257, acc: 0.6103895902633667)
[2024-12-14 23:31:26,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:27,145][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 1.5246208906173706, acc: 0.6041666865348816)
[2024-12-14 23:31:27,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:27,498][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 1.251667857170105, acc: 0.6379310488700867)
[2024-12-14 23:31:27,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:27,914][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 1.725322961807251, acc: 0.523809552192688)
[2024-12-14 23:31:28,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:28,287][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 1.332496166229248, acc: 0.6315789222717285)
[2024-12-14 23:31:29,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:29,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:30,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:30,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:30,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:31,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:31,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:32,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:32,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:32,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:33,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:33,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:34,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:34,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:34,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:35,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:35,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:35,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:36,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:36,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:36,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:37,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:37,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:37,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:38,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:38,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:40,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:40,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:40,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:41,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:42,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:42,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:43,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:43,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:43,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:44,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:44,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:45,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:45,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:45,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:46,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:46,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:46,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:46,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:47,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:47,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:48,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:48,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:48,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:49,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:49,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:49,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:50,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:50,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:51,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:51,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:51,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:52,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:52,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:53,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:53,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:54,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:54,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:54,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:55,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:55,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:55,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:56,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:56,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:57,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:57,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:57,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:58,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:58,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:58,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:58,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:31:59,565][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7197, device='cuda:0') eval_epoch_loss=tensor(1.9050, device='cuda:0') eval_epoch_acc=tensor(0.5188, device='cuda:0')
[2024-12-14 23:31:59,567][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:31:59,567][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:32:00,525][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_3_step_568_loss_1.9050498008728027/model.pt
[2024-12-14 23:32:00,531][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:32:00,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:00,916][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.946001410484314, acc: 0.7037037014961243)
[2024-12-14 23:32:01,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:01,337][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 1.8690372705459595, acc: 0.48128342628479004)
[2024-12-14 23:32:01,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:01,688][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 1.388622522354126, acc: 0.6290322542190552)
[2024-12-14 23:32:01,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:02,068][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 1.6127452850341797, acc: 0.5384615659713745)
[2024-12-14 23:32:02,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:02,458][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 2.085430145263672, acc: 0.4183673560619354)
[2024-12-14 23:32:02,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:02,861][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 2.046065092086792, acc: 0.42138364911079407)
[2024-12-14 23:32:03,300][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=5.0991, train_epoch_loss=1.6291, epoch time 384.4322214378044s
[2024-12-14 23:32:03,300][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-14 23:32:03,301][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 23:32:03,301][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-14 23:32:03,301][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-12-14 23:32:03,301][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:32:03,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:04,272][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 1.4666458368301392, acc: 0.5185185074806213)
[2024-12-14 23:32:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:04,632][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 1.5704436302185059, acc: 0.47999998927116394)
[2024-12-14 23:32:04,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:05,041][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 2.175978183746338, acc: 0.4054054021835327)
[2024-12-14 23:32:05,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:05,475][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 1.9225988388061523, acc: 0.3684210479259491)
[2024-12-14 23:32:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:05,893][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 1.9589829444885254, acc: 0.4324324429035187)
[2024-12-14 23:32:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:06,281][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 1.5573452711105347, acc: 0.5)
[2024-12-14 23:32:06,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:06,668][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.9640374183654785, acc: 0.40816327929496765)
[2024-12-14 23:32:06,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:07,029][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 1.4201587438583374, acc: 0.6333333253860474)
[2024-12-14 23:32:07,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:07,446][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.4402594268321991, acc: 0.8636363744735718)
[2024-12-14 23:32:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:07,827][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.5974326729774475, acc: 0.8846153616905212)
[2024-12-14 23:32:07,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:08,181][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.9359199404716492, acc: 0.7777777910232544)
[2024-12-14 23:32:08,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:08,534][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 1.416473627090454, acc: 0.6153846383094788)
[2024-12-14 23:32:08,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:08,873][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 1.274725317955017, acc: 0.6060606241226196)
[2024-12-14 23:32:08,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:09,255][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 1.5890651941299438, acc: 0.5652173757553101)
[2024-12-14 23:32:09,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:09,647][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 2.0429811477661133, acc: 0.47058823704719543)
[2024-12-14 23:32:09,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:10,055][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 1.6669358015060425, acc: 0.4897959232330322)
[2024-12-14 23:32:10,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:10,452][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.6967334151268005, acc: 0.8421052694320679)
[2024-12-14 23:32:10,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:10,847][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 1.465990424156189, acc: 0.5833333134651184)
[2024-12-14 23:32:10,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:11,218][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.6226195096969604, acc: 0.6111111044883728)
[2024-12-14 23:32:11,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:11,511][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 1.1062126159667969, acc: 0.6842105388641357)
[2024-12-14 23:32:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:11,919][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 1.1030999422073364, acc: 0.7692307829856873)
[2024-12-14 23:32:12,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:12,295][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 1.555950403213501, acc: 0.6206896305084229)
[2024-12-14 23:32:12,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:12,792][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 1.190321445465088, acc: 0.6000000238418579)
[2024-12-14 23:32:12,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:13,252][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.8909886479377747, acc: 0.6666666865348816)
[2024-12-14 23:32:13,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:13,636][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 1.4478918313980103, acc: 0.6875)
[2024-12-14 23:32:13,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:14,104][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 2.524644374847412, acc: 0.30188679695129395)
[2024-12-14 23:32:14,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:14,496][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 2.0055294036865234, acc: 0.42465752363204956)
[2024-12-14 23:32:15,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:15,906][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 2.2007195949554443, acc: 0.40316206216812134)
[2024-12-14 23:32:16,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:16,300][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 1.7351676225662231, acc: 0.5348837375640869)
[2024-12-14 23:32:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:16,684][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 1.910099983215332, acc: 0.42168673872947693)
[2024-12-14 23:32:16,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:17,135][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 1.8112292289733887, acc: 0.4938271641731262)
[2024-12-14 23:32:17,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:17,619][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 1.7834043502807617, acc: 0.4642857015132904)
[2024-12-14 23:32:17,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:18,016][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.9432726502418518, acc: 0.6666666865348816)
[2024-12-14 23:32:18,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:18,435][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.7313997149467468, acc: 0.782608687877655)
[2024-12-14 23:32:18,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:18,904][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 1.9700392484664917, acc: 0.462184876203537)
[2024-12-14 23:32:19,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:19,295][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 1.626298427581787, acc: 0.5573770403862)
[2024-12-14 23:32:19,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:19,666][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 2.022503137588501, acc: 0.460317462682724)
[2024-12-14 23:32:19,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:20,039][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 2.1119236946105957, acc: 0.49152541160583496)
[2024-12-14 23:32:20,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:20,416][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 1.3408230543136597, acc: 0.5747126340866089)
[2024-12-14 23:32:20,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:20,763][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.6879484057426453, acc: 0.761904776096344)
[2024-12-14 23:32:20,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:21,107][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 1.1327954530715942, acc: 0.692307710647583)
[2024-12-14 23:32:21,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:21,509][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 2.348146915435791, acc: 0.36486485600471497)
[2024-12-14 23:32:21,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:21,884][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.8112297058105469, acc: 0.4615384638309479)
[2024-12-14 23:32:22,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:22,422][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 2.15679669380188, acc: 0.4545454680919647)
[2024-12-14 23:32:22,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:22,901][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 1.6565768718719482, acc: 0.5773195624351501)
[2024-12-14 23:32:23,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:23,354][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 2.033393383026123, acc: 0.4632352888584137)
[2024-12-14 23:32:23,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:23,739][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.7998079657554626, acc: 0.7692307829856873)
[2024-12-14 23:32:23,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:24,133][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.7409613728523254, acc: 0.8148148059844971)
[2024-12-14 23:32:24,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:24,539][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 1.112418293952942, acc: 0.6071428656578064)
[2024-12-14 23:32:24,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:24,931][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.7679102420806885, acc: 0.7777777910232544)
[2024-12-14 23:32:25,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:25,341][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 1.1732255220413208, acc: 0.719298243522644)
[2024-12-14 23:32:25,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:25,730][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 1.3158363103866577, acc: 0.6507936716079712)
[2024-12-14 23:32:25,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:26,185][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.8575284481048584, acc: 0.5070422291755676)
[2024-12-14 23:32:26,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:26,705][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 2.1359589099884033, acc: 0.5)
[2024-12-14 23:32:26,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:27,137][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 1.076676368713379, acc: 0.7027027010917664)
[2024-12-14 23:32:27,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:27,589][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.5938699245452881, acc: 0.807692289352417)
[2024-12-14 23:32:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:30,637][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.7475639581680298, acc: 0.532423198223114)
[2024-12-14 23:32:31,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:31,892][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 2.3450443744659424, acc: 0.4248366057872772)
[2024-12-14 23:32:32,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:32,615][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.8617973327636719, acc: 0.5454545617103577)
[2024-12-14 23:32:32,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:33,216][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 2.012361764907837, acc: 0.49264705181121826)
[2024-12-14 23:32:33,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:33,824][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 2.1694416999816895, acc: 0.4202898442745209)
[2024-12-14 23:32:33,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:34,325][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 1.6442441940307617, acc: 0.6000000238418579)
[2024-12-14 23:32:34,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:34,802][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 1.193739891052246, acc: 0.6470588445663452)
[2024-12-14 23:32:34,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:35,238][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 1.4752252101898193, acc: 0.5555555820465088)
[2024-12-14 23:32:35,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:35,708][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 1.4829455614089966, acc: 0.625)
[2024-12-14 23:32:35,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:36,111][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.8985394239425659, acc: 0.7241379022598267)
[2024-12-14 23:32:36,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:36,485][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 2.100532293319702, acc: 0.4642857015132904)
[2024-12-14 23:32:36,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:36,932][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 1.9611371755599976, acc: 0.46666666865348816)
[2024-12-14 23:32:37,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:37,359][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.6221131086349487, acc: 0.800000011920929)
[2024-12-14 23:32:37,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:37,714][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 1.1088454723358154, acc: 0.6944444179534912)
[2024-12-14 23:32:37,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:38,119][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 1.3565059900283813, acc: 0.6060606241226196)
[2024-12-14 23:32:38,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:38,534][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.9431935548782349, acc: 0.5147058963775635)
[2024-12-14 23:32:38,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:38,920][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 1.9125657081604004, acc: 0.4523809552192688)
[2024-12-14 23:32:39,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:39,289][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 2.115525245666504, acc: 0.41025641560554504)
[2024-12-14 23:32:39,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:39,652][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.8304754495620728, acc: 0.5408163070678711)
[2024-12-14 23:32:39,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:40,048][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 2.3579719066619873, acc: 0.36567163467407227)
[2024-12-14 23:32:40,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:40,469][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 2.1825969219207764, acc: 0.4124087691307068)
[2024-12-14 23:32:40,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:40,829][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.5499604940414429, acc: 0.8571428656578064)
[2024-12-14 23:32:40,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:41,157][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.6025715470314026, acc: 0.7916666865348816)
[2024-12-14 23:32:41,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:41,517][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.9925101399421692, acc: 0.6666666865348816)
[2024-12-14 23:32:41,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:41,894][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.7402166128158569, acc: 0.807692289352417)
[2024-12-14 23:32:41,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:42,281][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 1.5914050340652466, acc: 0.5384615659713745)
[2024-12-14 23:32:42,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:42,686][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 1.8971353769302368, acc: 0.48076921701431274)
[2024-12-14 23:32:42,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:43,067][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 1.3113216161727905, acc: 0.625)
[2024-12-14 23:32:43,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:43,471][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 1.8023828268051147, acc: 0.47826087474823)
[2024-12-14 23:32:43,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:43,852][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 1.4259064197540283, acc: 0.5799999833106995)
[2024-12-14 23:32:43,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:44,226][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 1.392693042755127, acc: 0.6086956262588501)
[2024-12-14 23:32:44,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:44,728][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.9718246459960938, acc: 0.4399999976158142)
[2024-12-14 23:32:44,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:45,104][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.7766114473342896, acc: 0.5339806079864502)
[2024-12-14 23:32:45,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:46,232][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.7838945388793945, acc: 0.5339806079864502)
[2024-12-14 23:32:46,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:47,150][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 2.0058512687683105, acc: 0.45698925852775574)
[2024-12-14 23:32:47,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:47,979][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.7792177200317383, acc: 0.5646551847457886)
[2024-12-14 23:32:48,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:48,748][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 1.465132713317871, acc: 0.5684210658073425)
[2024-12-14 23:32:49,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:49,771][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 2.2007687091827393, acc: 0.3762376308441162)
[2024-12-14 23:32:49,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:50,116][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 2.115889072418213, acc: 0.35483869910240173)
[2024-12-14 23:32:50,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:50,511][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 2.2598824501037598, acc: 0.4057970941066742)
[2024-12-14 23:32:50,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:50,918][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 2.274427652359009, acc: 0.3025210201740265)
[2024-12-14 23:32:51,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:51,321][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 2.3321030139923096, acc: 0.32692307233810425)
[2024-12-14 23:32:51,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:51,740][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 2.2733545303344727, acc: 0.39416059851646423)
[2024-12-14 23:32:51,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:52,099][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 2.317920207977295, acc: 0.34328359365463257)
[2024-12-14 23:32:52,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:52,462][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.8217809796333313, acc: 0.75)
[2024-12-14 23:32:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:52,823][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.807774543762207, acc: 0.6818181872367859)
[2024-12-14 23:32:52,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:53,149][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.8218497633934021, acc: 0.782608687877655)
[2024-12-14 23:32:53,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:53,498][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 1.1383472681045532, acc: 0.6363636255264282)
[2024-12-14 23:32:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:53,861][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 1.7829205989837646, acc: 0.517241358757019)
[2024-12-14 23:32:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:54,220][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 1.4090970754623413, acc: 0.5581395626068115)
[2024-12-14 23:32:54,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:54,592][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 1.2608211040496826, acc: 0.6399999856948853)
[2024-12-14 23:32:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:54,937][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.5271681547164917, acc: 0.8823529481887817)
[2024-12-14 23:32:55,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:55,297][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.4951536953449249, acc: 0.8461538553237915)
[2024-12-14 23:32:55,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:55,675][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 1.315176010131836, acc: 0.6190476417541504)
[2024-12-14 23:32:55,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:56,037][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 1.6948959827423096, acc: 0.5384615659713745)
[2024-12-14 23:32:56,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:56,468][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 1.6289271116256714, acc: 0.6315789222717285)
[2024-12-14 23:32:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:56,846][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 1.4954371452331543, acc: 0.5964912176132202)
[2024-12-14 23:32:56,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:57,212][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 1.70539391040802, acc: 0.4871794879436493)
[2024-12-14 23:32:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:57,613][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 1.1729295253753662, acc: 0.7142857313156128)
[2024-12-14 23:32:57,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:57,982][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.4494116008281708, acc: 0.8636363744735718)
[2024-12-14 23:32:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:58,418][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 1.7806365489959717, acc: 0.5079365372657776)
[2024-12-14 23:32:58,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:58,900][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 1.8505052328109741, acc: 0.577235758304596)
[2024-12-14 23:32:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:32:59,308][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 1.3932400941848755, acc: 0.6612903475761414)
[2024-12-14 23:32:59,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:00,247][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 1.9245976209640503, acc: 0.45627376437187195)
[2024-12-14 23:33:00,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:00,629][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 1.4013890027999878, acc: 0.5866666436195374)
[2024-12-14 23:33:00,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:01,093][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 1.3796346187591553, acc: 0.6346153616905212)
[2024-12-14 23:33:01,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:01,479][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.7941429615020752, acc: 0.8333333134651184)
[2024-12-14 23:33:01,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:01,833][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 1.1054713726043701, acc: 0.6842105388641357)
[2024-12-14 23:33:01,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:02,228][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 2.0499894618988037, acc: 0.44785276055336)
[2024-12-14 23:33:02,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:02,664][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.6804195642471313, acc: 0.5763888955116272)
[2024-12-14 23:33:02,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:03,075][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 2.0785224437713623, acc: 0.44999998807907104)
[2024-12-14 23:33:03,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:03,507][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 2.0421931743621826, acc: 0.4107142984867096)
[2024-12-14 23:33:03,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:03,902][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.8731694221496582, acc: 0.5076923370361328)
[2024-12-14 23:33:04,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:04,353][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.8225287199020386, acc: 0.5)
[2024-12-14 23:33:04,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:04,746][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 1.0443297624588013, acc: 0.7692307829856873)
[2024-12-14 23:33:04,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:05,104][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.5287029147148132, acc: 0.782608687877655)
[2024-12-14 23:33:05,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:05,485][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 1.0453288555145264, acc: 0.65625)
[2024-12-14 23:33:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:05,874][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 1.5018290281295776, acc: 0.6086956262588501)
[2024-12-14 23:33:05,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:06,267][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 1.1290339231491089, acc: 0.6857143044471741)
[2024-12-14 23:33:06,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:06,633][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.8380520343780518, acc: 0.7692307829856873)
[2024-12-14 23:33:06,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:06,987][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 1.7951024770736694, acc: 0.4285714328289032)
[2024-12-14 23:33:07,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:08,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:08,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:08,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:09,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:09,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:09,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:10,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:10,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:11,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:11,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:11,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:12,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:12,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:13,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:13,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:14,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:14,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:14,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:15,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:15,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:15,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:16,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:16,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:17,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:17,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:17,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:18,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:18,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:18,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:19,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:19,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:20,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:20,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:20,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:21,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:21,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:22,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:22,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:22,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:23,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:23,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:23,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:24,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:24,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:24,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:25,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:25,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:25,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:26,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:26,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:26,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:27,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:27,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:28,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:28,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:28,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:29,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:29,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:30,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:30,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:31,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:31,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:31,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:32,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:32,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:33,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:33,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:33,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:34,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:34,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:34,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:35,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:35,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:36,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:36,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:36,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:37,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:37,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:37,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:37,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:38,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:38,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:39,435][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.3320, device='cuda:0') eval_epoch_loss=tensor(1.8456, device='cuda:0') eval_epoch_acc=tensor(0.5074, device='cuda:0')
[2024-12-14 23:33:39,436][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:33:39,436][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:33:40,199][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_4_step_137_loss_1.845609426498413/model.pt
[2024-12-14 23:33:40,204][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:33:40,204][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 1.845609426498413
[2024-12-14 23:33:40,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:40,675][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 1.4216067790985107, acc: 0.5333333611488342)
[2024-12-14 23:33:40,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:41,099][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 1.39043128490448, acc: 0.52173912525177)
[2024-12-14 23:33:41,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:41,495][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 1.6422799825668335, acc: 0.6666666865348816)
[2024-12-14 23:33:41,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:41,876][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 1.8734803199768066, acc: 0.5384615659713745)
[2024-12-14 23:33:41,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:42,217][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 2.3282430171966553, acc: 0.29032257199287415)
[2024-12-14 23:33:42,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:42,574][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 2.064095973968506, acc: 0.4054054021835327)
[2024-12-14 23:33:42,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:43,127][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 1.8933472633361816, acc: 0.42105263471603394)
[2024-12-14 23:33:43,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:43,562][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 1.6552153825759888, acc: 0.5223880410194397)
[2024-12-14 23:33:43,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:43,978][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 2.278027057647705, acc: 0.33673468232154846)
[2024-12-14 23:33:44,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:44,474][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 2.056879997253418, acc: 0.3510638177394867)
[2024-12-14 23:33:44,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:44,875][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 1.7493699789047241, acc: 0.5285714268684387)
[2024-12-14 23:33:44,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:45,249][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 2.098452568054199, acc: 0.4642857015132904)
[2024-12-14 23:33:45,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:45,636][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 1.5494118928909302, acc: 0.5652173757553101)
[2024-12-14 23:33:45,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:45,997][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 1.7433297634124756, acc: 0.517241358757019)
[2024-12-14 23:33:46,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:46,404][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.8677574396133423, acc: 0.5869565010070801)
[2024-12-14 23:33:46,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:46,780][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 1.8533366918563843, acc: 0.5254237055778503)
[2024-12-14 23:33:46,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:47,168][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.944900393486023, acc: 0.5263158082962036)
[2024-12-14 23:33:47,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:47,569][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 1.8120747804641724, acc: 0.5)
[2024-12-14 23:33:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:47,942][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 1.5552765130996704, acc: 0.6071428656578064)
[2024-12-14 23:33:48,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:48,285][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 1.3469539880752563, acc: 0.6086956262588501)
[2024-12-14 23:33:48,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:48,579][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.363855004310608, acc: 0.5789473652839661)
[2024-12-14 23:33:49,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:50,240][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.5421173572540283, acc: 0.5675675868988037)
[2024-12-14 23:33:50,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:50,620][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.8431543111801147, acc: 0.40740740299224854)
[2024-12-14 23:33:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:51,082][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 1.5559371709823608, acc: 0.5232558250427246)
[2024-12-14 23:33:51,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:51,716][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 1.4782662391662598, acc: 0.5411764979362488)
[2024-12-14 23:33:51,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:52,318][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.8947099447250366, acc: 0.49438202381134033)
[2024-12-14 23:33:52,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:52,786][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 1.3790289163589478, acc: 0.6363636255264282)
[2024-12-14 23:33:52,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:53,213][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 1.1846731901168823, acc: 0.6666666865348816)
[2024-12-14 23:33:53,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:53,618][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 1.3796261548995972, acc: 0.5517241358757019)
[2024-12-14 23:33:53,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:54,084][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 1.2403128147125244, acc: 0.6122449040412903)
[2024-12-14 23:33:54,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:54,491][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 1.5869258642196655, acc: 0.46000000834465027)
[2024-12-14 23:33:54,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:54,922][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 1.551370620727539, acc: 0.5555555820465088)
[2024-12-14 23:33:55,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:55,293][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.8789749145507812, acc: 0.529411792755127)
[2024-12-14 23:33:55,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:56,415][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 2.273102283477783, acc: 0.45890411734580994)
[2024-12-14 23:33:56,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:56,781][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.8565035462379456, acc: 0.7083333134651184)
[2024-12-14 23:33:56,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:57,150][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.7833361029624939, acc: 0.7407407164573669)
[2024-12-14 23:33:57,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:57,496][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 1.1453582048416138, acc: 0.7142857313156128)
[2024-12-14 23:33:57,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:58,073][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.635013222694397, acc: 0.6017699241638184)
[2024-12-14 23:33:58,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:58,468][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 1.6197561025619507, acc: 0.5797101259231567)
[2024-12-14 23:33:58,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:58,859][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 1.6730114221572876, acc: 0.5340909361839294)
[2024-12-14 23:33:59,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:33:59,838][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 2.262537956237793, acc: 0.4122137427330017)
[2024-12-14 23:34:00,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:00,532][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 2.086178779602051, acc: 0.43703705072402954)
[2024-12-14 23:34:00,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:00,879][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 1.583097219467163, acc: 0.5737704634666443)
[2024-12-14 23:34:00,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:01,237][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.8508110046386719, acc: 0.7083333134651184)
[2024-12-14 23:34:01,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:01,595][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 1.3510302305221558, acc: 0.6000000238418579)
[2024-12-14 23:34:01,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:01,969][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 1.0644025802612305, acc: 0.7142857313156128)
[2024-12-14 23:34:02,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:02,401][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 1.8858752250671387, acc: 0.45121949911117554)
[2024-12-14 23:34:02,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:02,816][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 2.1315295696258545, acc: 0.42598187923431396)
[2024-12-14 23:34:02,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:03,214][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 2.2236828804016113, acc: 0.40345820784568787)
[2024-12-14 23:34:03,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:03,726][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 2.235535144805908, acc: 0.4000000059604645)
[2024-12-14 23:34:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:04,273][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 2.0517337322235107, acc: 0.452157586812973)
[2024-12-14 23:34:04,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:04,738][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 2.0117835998535156, acc: 0.4555160105228424)
[2024-12-14 23:34:04,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:05,133][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 1.7362061738967896, acc: 0.5199999809265137)
[2024-12-14 23:34:05,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:05,721][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 2.051839590072632, acc: 0.4883720874786377)
[2024-12-14 23:34:06,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:06,574][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.842012882232666, acc: 0.5476190447807312)
[2024-12-14 23:34:06,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:07,513][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.9828040599822998, acc: 0.5075757503509521)
[2024-12-14 23:34:07,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:08,278][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 1.6190038919448853, acc: 0.5529412031173706)
[2024-12-14 23:34:08,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:09,379][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.6373300552368164, acc: 0.5987654328346252)
[2024-12-14 23:34:09,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:10,355][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 1.3889803886413574, acc: 0.6612903475761414)
[2024-12-14 23:34:10,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:10,766][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.6296976804733276, acc: 0.7857142686843872)
[2024-12-14 23:34:10,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:11,163][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 1.3138387203216553, acc: 0.699999988079071)
[2024-12-14 23:34:11,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:11,570][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 1.7126102447509766, acc: 0.5)
[2024-12-14 23:34:11,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:11,959][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.8265200853347778, acc: 0.5)
[2024-12-14 23:34:12,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:12,331][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 1.9351894855499268, acc: 0.5)
[2024-12-14 23:34:12,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:12,697][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 2.0168213844299316, acc: 0.4776119291782379)
[2024-12-14 23:34:12,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:13,090][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 2.101274251937866, acc: 0.4563106894493103)
[2024-12-14 23:34:13,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:13,463][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 1.6229636669158936, acc: 0.5873016119003296)
[2024-12-14 23:34:13,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:13,896][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 1.7532875537872314, acc: 0.49450549483299255)
[2024-12-14 23:34:14,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:14,400][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 2.0028536319732666, acc: 0.439461886882782)
[2024-12-14 23:34:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:14,828][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 2.0701868534088135, acc: 0.4566929042339325)
[2024-12-14 23:34:14,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:15,197][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 1.9483118057250977, acc: 0.4698275923728943)
[2024-12-14 23:34:15,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:15,598][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 2.0087122917175293, acc: 0.48188406229019165)
[2024-12-14 23:34:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:16,022][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 2.0635576248168945, acc: 0.42023345828056335)
[2024-12-14 23:34:16,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:16,433][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 2.0531563758850098, acc: 0.47826087474823)
[2024-12-14 23:34:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:16,801][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 1.0427148342132568, acc: 0.739130437374115)
[2024-12-14 23:34:16,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:17,137][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 1.4782065153121948, acc: 0.6071428656578064)
[2024-12-14 23:34:17,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:17,500][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 1.1285338401794434, acc: 0.6382978558540344)
[2024-12-14 23:34:17,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:18,225][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 1.6729097366333008, acc: 0.5230769515037537)
[2024-12-14 23:34:18,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:18,609][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 1.4740605354309082, acc: 0.5810810923576355)
[2024-12-14 23:34:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:19,006][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 1.3846455812454224, acc: 0.6162790656089783)
[2024-12-14 23:34:19,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:19,589][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 1.5486232042312622, acc: 0.5855855941772461)
[2024-12-14 23:34:19,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:20,019][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 1.5612595081329346, acc: 0.5888888835906982)
[2024-12-14 23:34:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:20,390][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.8264448046684265, acc: 0.7575757503509521)
[2024-12-14 23:34:20,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:20,759][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.4425949156284332, acc: 0.8518518805503845)
[2024-12-14 23:34:20,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:21,119][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.7068847417831421, acc: 0.7200000286102295)
[2024-12-14 23:34:21,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:21,486][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 1.6148501634597778, acc: 0.557692289352417)
[2024-12-14 23:34:21,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:22,270][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 1.5174537897109985, acc: 0.5380434989929199)
[2024-12-14 23:34:22,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:22,844][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 1.8567932844161987, acc: 0.47727271914482117)
[2024-12-14 23:34:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:23,325][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 1.9937676191329956, acc: 0.38297873735427856)
[2024-12-14 23:34:23,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:23,711][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 1.5234931707382202, acc: 0.5849056839942932)
[2024-12-14 23:34:23,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:24,085][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 1.584844708442688, acc: 0.550000011920929)
[2024-12-14 23:34:24,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:24,467][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.9574496150016785, acc: 0.7209302186965942)
[2024-12-14 23:34:24,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:24,838][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.8424619436264038, acc: 0.800000011920929)
[2024-12-14 23:34:24,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:25,238][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.252898931503296, acc: 0.4000000059604645)
[2024-12-14 23:34:25,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:25,587][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.781833529472351, acc: 0.5444444417953491)
[2024-12-14 23:34:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:26,050][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.3768250942230225, acc: 0.644444465637207)
[2024-12-14 23:34:26,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:26,591][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 1.6318976879119873, acc: 0.6009174585342407)
[2024-12-14 23:34:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:27,098][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.5316296815872192, acc: 0.5923076868057251)
[2024-12-14 23:34:27,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:27,441][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 1.1983013153076172, acc: 0.5263158082962036)
[2024-12-14 23:34:27,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:27,782][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.8730975985527039, acc: 0.75)
[2024-12-14 23:34:27,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:28,129][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 1.9065912961959839, acc: 0.40909090638160706)
[2024-12-14 23:34:28,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:28,481][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 1.8505464792251587, acc: 0.48148149251937866)
[2024-12-14 23:34:28,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:28,849][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 1.2181816101074219, acc: 0.6571428775787354)
[2024-12-14 23:34:28,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:29,245][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 1.4138107299804688, acc: 0.5909090638160706)
[2024-12-14 23:34:29,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:29,646][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 1.650722622871399, acc: 0.5454545617103577)
[2024-12-14 23:34:29,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:30,254][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.8680472373962402, acc: 0.4677419364452362)
[2024-12-14 23:34:30,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:30,827][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.5835753679275513, acc: 0.6136363744735718)
[2024-12-14 23:34:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:31,177][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.5502745509147644, acc: 0.8571428656578064)
[2024-12-14 23:34:31,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:31,539][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 1.204594373703003, acc: 0.692307710647583)
[2024-12-14 23:34:31,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:31,916][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 1.108588457107544, acc: 0.6774193644523621)
[2024-12-14 23:34:32,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:32,272][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.868545651435852, acc: 0.6000000238418579)
[2024-12-14 23:34:32,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:32,678][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 1.259578824043274, acc: 0.6216216087341309)
[2024-12-14 23:34:32,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:33,062][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 1.3785783052444458, acc: 0.5945945978164673)
[2024-12-14 23:34:33,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:33,419][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 1.2681463956832886, acc: 0.6216216087341309)
[2024-12-14 23:34:33,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:33,858][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 1.587478756904602, acc: 0.5735294222831726)
[2024-12-14 23:34:33,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:34,253][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.8168694376945496, acc: 0.7317073345184326)
[2024-12-14 23:34:34,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:34,611][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.35751351714134216, acc: 0.8799999952316284)
[2024-12-14 23:34:34,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:34,968][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.5006775259971619, acc: 0.8799999952316284)
[2024-12-14 23:34:35,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:35,355][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.5208922028541565, acc: 0.8387096524238586)
[2024-12-14 23:34:35,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:35,741][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 1.350035548210144, acc: 0.5789473652839661)
[2024-12-14 23:34:35,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:36,093][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 1.4071093797683716, acc: 0.6285714507102966)
[2024-12-14 23:34:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:36,472][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 1.2079188823699951, acc: 0.6710526347160339)
[2024-12-14 23:34:36,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:37,065][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 1.6021348237991333, acc: 0.5094339847564697)
[2024-12-14 23:34:37,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:37,698][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 1.7140487432479858, acc: 0.5166666507720947)
[2024-12-14 23:34:37,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:38,103][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 1.1387262344360352, acc: 0.6666666865348816)
[2024-12-14 23:34:38,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:38,548][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 1.4609686136245728, acc: 0.5806451439857483)
[2024-12-14 23:34:38,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:38,942][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 2.4774060249328613, acc: 0.3733333349227905)
[2024-12-14 23:34:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:39,408][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 1.9852218627929688, acc: 0.3958333432674408)
[2024-12-14 23:34:39,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:40,310][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 2.4177911281585693, acc: 0.36000001430511475)
[2024-12-14 23:34:40,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:40,697][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 2.156975507736206, acc: 0.3820224702358246)
[2024-12-14 23:34:40,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:41,043][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 2.087994337081909, acc: 0.47297295928001404)
[2024-12-14 23:34:41,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:41,560][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 1.5077732801437378, acc: 0.5517241358757019)
[2024-12-14 23:34:41,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:41,922][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.9827575087547302, acc: 0.7727272510528564)
[2024-12-14 23:34:42,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:42,270][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 1.1836680173873901, acc: 0.5909090638160706)
[2024-12-14 23:34:42,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:42,578][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.8929975628852844, acc: 0.75)
[2024-12-14 23:34:42,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:42,921][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 1.2291375398635864, acc: 0.6666666865348816)
[2024-12-14 23:34:43,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:43,327][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 1.736061930656433, acc: 0.5166666507720947)
[2024-12-14 23:34:43,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:43,670][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 1.1185600757598877, acc: 0.6875)
[2024-12-14 23:34:43,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:44,029][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.9156404137611389, acc: 0.699999988079071)
[2024-12-14 23:34:44,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:44,377][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 1.2990636825561523, acc: 0.6896551847457886)
[2024-12-14 23:34:44,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:44,719][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 1.2396230697631836, acc: 0.6399999856948853)
[2024-12-14 23:34:44,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:45,057][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 1.816119909286499, acc: 0.5106382966041565)
[2024-12-14 23:34:45,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:45,417][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 1.5526180267333984, acc: 0.6041666865348816)
[2024-12-14 23:34:46,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:46,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:46,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:47,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:48,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:48,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:49,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:49,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:49,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:50,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:51,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:51,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:51,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:52,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:53,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:53,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:54,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:54,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:55,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:55,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:56,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:56,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:57,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:57,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:57,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:58,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:58,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:59,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:34:59,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:00,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:00,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:01,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:01,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:02,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:02,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:02,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:02,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:03,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:04,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:04,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:05,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:05,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:06,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:07,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:07,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:07,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:08,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:08,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:09,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:09,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:10,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:10,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:11,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:11,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:12,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:12,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:13,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:13,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:13,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:15,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:15,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:15,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:16,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:16,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:17,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:17,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:17,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:18,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:18,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:19,135][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.8444, device='cuda:0') eval_epoch_loss=tensor(1.9234, device='cuda:0') eval_epoch_acc=tensor(0.5224, device='cuda:0')
[2024-12-14 23:35:19,136][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:35:19,136][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:35:19,816][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_4_step_280_loss_1.9234267473220825/model.pt
[2024-12-14 23:35:19,826][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:35:19,827][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5223981738090515
[2024-12-14 23:35:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:20,393][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 1.5134543180465698, acc: 0.7045454382896423)
[2024-12-14 23:35:20,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:20,899][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 1.8952181339263916, acc: 0.5301204919815063)
[2024-12-14 23:35:21,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:21,315][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 1.9778918027877808, acc: 0.49074074625968933)
[2024-12-14 23:35:21,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:21,686][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 1.5608116388320923, acc: 0.5789473652839661)
[2024-12-14 23:35:21,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:22,044][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 1.6855815649032593, acc: 0.47058823704719543)
[2024-12-14 23:35:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:22,439][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 1.2540415525436401, acc: 0.6499999761581421)
[2024-12-14 23:35:22,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:22,848][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 2.0393216609954834, acc: 0.4375)
[2024-12-14 23:35:22,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:23,242][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 2.1584300994873047, acc: 0.4000000059604645)
[2024-12-14 23:35:23,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:23,691][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 1.7176032066345215, acc: 0.49450549483299255)
[2024-12-14 23:35:23,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:24,081][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 2.2651381492614746, acc: 0.4285714328289032)
[2024-12-14 23:35:24,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:24,539][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 2.3420417308807373, acc: 0.35567009449005127)
[2024-12-14 23:35:24,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:25,001][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.715529203414917, acc: 0.7272727489471436)
[2024-12-14 23:35:25,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:25,388][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 1.7460520267486572, acc: 0.4761904776096344)
[2024-12-14 23:35:25,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:25,862][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 1.3366453647613525, acc: 0.6551724076271057)
[2024-12-14 23:35:26,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:26,746][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 1.2461061477661133, acc: 0.6727272868156433)
[2024-12-14 23:35:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:27,324][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 1.6814401149749756, acc: 0.5773195624351501)
[2024-12-14 23:35:27,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:27,752][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 1.8556296825408936, acc: 0.48275861144065857)
[2024-12-14 23:35:27,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:28,235][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 1.6669360399246216, acc: 0.5555555820465088)
[2024-12-14 23:35:28,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:28,658][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 1.6441659927368164, acc: 0.5526315569877625)
[2024-12-14 23:35:28,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:29,100][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 1.502678632736206, acc: 0.5892857313156128)
[2024-12-14 23:35:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:29,552][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 1.5099854469299316, acc: 0.5625)
[2024-12-14 23:35:29,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:30,013][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 1.4591044187545776, acc: 0.6415094137191772)
[2024-12-14 23:35:30,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:30,407][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.8486616015434265, acc: 0.7358490824699402)
[2024-12-14 23:35:30,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:30,794][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 1.1330959796905518, acc: 0.7352941036224365)
[2024-12-14 23:35:30,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:31,203][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 1.366857886314392, acc: 0.65625)
[2024-12-14 23:35:31,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:31,619][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 1.358101487159729, acc: 0.6229507923126221)
[2024-12-14 23:35:31,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:32,004][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.7040396332740784, acc: 0.800000011920929)
[2024-12-14 23:35:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:32,381][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.6372050642967224, acc: 0.7894737124443054)
[2024-12-14 23:35:32,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:32,744][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 1.6967204809188843, acc: 0.5072463750839233)
[2024-12-14 23:35:32,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:33,235][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 1.526261806488037, acc: 0.6111111044883728)
[2024-12-14 23:35:33,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:33,623][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 1.393516182899475, acc: 0.5903614163398743)
[2024-12-14 23:35:33,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:33,995][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 1.8598984479904175, acc: 0.4743589758872986)
[2024-12-14 23:35:34,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:34,392][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 2.092196464538574, acc: 0.43877550959587097)
[2024-12-14 23:35:34,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:34,816][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.3182773292064667, acc: 0.9166666865348816)
[2024-12-14 23:35:34,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:35,164][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.7922664284706116, acc: 0.7916666865348816)
[2024-12-14 23:35:35,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:35,515][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.8368794918060303, acc: 0.7096773982048035)
[2024-12-14 23:35:35,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:35,893][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.8710225224494934, acc: 0.6451612710952759)
[2024-12-14 23:35:36,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:36,285][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 1.2704050540924072, acc: 0.6268656849861145)
[2024-12-14 23:35:36,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:36,656][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 1.2804306745529175, acc: 0.6538461446762085)
[2024-12-14 23:35:36,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:37,024][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 1.433967113494873, acc: 0.5333333611488342)
[2024-12-14 23:35:37,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:37,457][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 1.4181615114212036, acc: 0.6290322542190552)
[2024-12-14 23:35:37,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:37,845][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.862626314163208, acc: 0.7799999713897705)
[2024-12-14 23:35:37,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:38,259][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 1.9768471717834473, acc: 0.40740740299224854)
[2024-12-14 23:35:38,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:38,657][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 1.97158682346344, acc: 0.4000000059604645)
[2024-12-14 23:35:38,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:39,042][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.6798725128173828, acc: 0.5128205418586731)
[2024-12-14 23:35:39,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:39,405][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 2.0557076930999756, acc: 0.4146341383457184)
[2024-12-14 23:35:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:39,776][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.5699633359909058, acc: 0.5789473652839661)
[2024-12-14 23:35:39,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:40,123][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.8948584198951721, acc: 0.7368420958518982)
[2024-12-14 23:35:40,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:40,497][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.6154170036315918, acc: 0.7857142686843872)
[2024-12-14 23:35:40,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:40,894][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 1.6089866161346436, acc: 0.5925925970077515)
[2024-12-14 23:35:40,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:41,267][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.8161899447441101, acc: 0.78125)
[2024-12-14 23:35:41,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:41,649][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 1.550902009010315, acc: 0.6290322542190552)
[2024-12-14 23:35:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:42,057][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 1.431343913078308, acc: 0.4912280738353729)
[2024-12-14 23:35:42,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:42,418][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 2.0397801399230957, acc: 0.375)
[2024-12-14 23:35:42,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:42,779][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 1.1511934995651245, acc: 0.699999988079071)
[2024-12-14 23:35:42,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:43,131][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 1.2918187379837036, acc: 0.6315789222717285)
[2024-12-14 23:35:43,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:43,515][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 2.0881261825561523, acc: 0.41999998688697815)
[2024-12-14 23:35:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:43,911][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 2.1408298015594482, acc: 0.37931033968925476)
[2024-12-14 23:35:44,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:44,287][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 2.3264553546905518, acc: 0.39361703395843506)
[2024-12-14 23:35:44,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:44,651][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 2.296614408493042, acc: 0.39759036898612976)
[2024-12-14 23:35:44,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:44,993][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.9580008387565613, acc: 0.6521739363670349)
[2024-12-14 23:35:45,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:45,327][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 1.7893707752227783, acc: 0.4615384638309479)
[2024-12-14 23:35:45,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:45,750][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 2.2365386486053467, acc: 0.3855421543121338)
[2024-12-14 23:35:45,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:46,142][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 1.747275710105896, acc: 0.5283018946647644)
[2024-12-14 23:35:46,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:46,546][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 1.707781434059143, acc: 0.49367088079452515)
[2024-12-14 23:35:46,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:46,892][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 1.5047857761383057, acc: 0.5882353186607361)
[2024-12-14 23:35:46,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:47,239][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 2.2313899993896484, acc: 0.4029850661754608)
[2024-12-14 23:35:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:47,580][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.8838077783584595, acc: 0.800000011920929)
[2024-12-14 23:35:47,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:47,988][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.9590321183204651, acc: 0.6800000071525574)
[2024-12-14 23:35:48,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:48,497][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 1.3009600639343262, acc: 0.7222222089767456)
[2024-12-14 23:35:48,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:48,967][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 1.6972384452819824, acc: 0.5348837375640869)
[2024-12-14 23:35:49,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:49,409][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 1.5872223377227783, acc: 0.5384615659713745)
[2024-12-14 23:35:49,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:49,891][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.5737799406051636, acc: 0.5333333611488342)
[2024-12-14 23:35:50,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:50,319][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.7204594612121582, acc: 0.739130437374115)
[2024-12-14 23:35:50,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:50,710][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 1.4624135494232178, acc: 0.5)
[2024-12-14 23:35:50,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:51,072][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 2.155837297439575, acc: 0.4285714328289032)
[2024-12-14 23:35:51,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:51,655][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 1.7985426187515259, acc: 0.5565217137336731)
[2024-12-14 23:35:51,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:52,132][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 1.7906986474990845, acc: 0.54347825050354)
[2024-12-14 23:35:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:52,549][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 1.6695380210876465, acc: 0.5306122303009033)
[2024-12-14 23:35:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:52,994][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.32351067662239075, acc: 0.9166666865348816)
[2024-12-14 23:35:53,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:53,382][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.8036097884178162, acc: 0.7307692170143127)
[2024-12-14 23:35:53,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:53,734][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 1.169249415397644, acc: 0.6585366129875183)
[2024-12-14 23:35:53,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:54,098][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 1.5508990287780762, acc: 0.5777778029441833)
[2024-12-14 23:35:54,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:54,467][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 1.6978468894958496, acc: 0.5131579041481018)
[2024-12-14 23:35:54,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:54,853][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 1.4391239881515503, acc: 0.5853658318519592)
[2024-12-14 23:35:54,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:55,231][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 1.4484151601791382, acc: 0.6363636255264282)
[2024-12-14 23:35:55,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:55,607][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.6311101317405701, acc: 0.7916666865348816)
[2024-12-14 23:35:55,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:55,980][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.4714629054069519, acc: 0.8695651888847351)
[2024-12-14 23:35:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:56,327][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.6065747141838074, acc: 0.8214285969734192)
[2024-12-14 23:35:56,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:56,713][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 1.0939769744873047, acc: 0.65625)
[2024-12-14 23:35:56,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:57,348][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 1.7105541229248047, acc: 0.5575757622718811)
[2024-12-14 23:35:57,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:58,290][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 1.2797985076904297, acc: 0.6603773832321167)
[2024-12-14 23:35:58,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:58,754][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 1.5660066604614258, acc: 0.5666666626930237)
[2024-12-14 23:35:58,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:59,162][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 1.4804229736328125, acc: 0.5892857313156128)
[2024-12-14 23:35:59,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:59,587][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.9355517625808716, acc: 0.6857143044471741)
[2024-12-14 23:35:59,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:35:59,978][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.45814114809036255, acc: 0.8799999952316284)
[2024-12-14 23:36:00,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:00,318][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.6378782391548157, acc: 0.739130437374115)
[2024-12-14 23:36:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:00,675][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 1.5022333860397339, acc: 0.6666666865348816)
[2024-12-14 23:36:00,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:01,054][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 1.517507791519165, acc: 0.5894736647605896)
[2024-12-14 23:36:01,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:01,647][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 1.5821584463119507, acc: 0.6167664527893066)
[2024-12-14 23:36:01,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:02,128][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 1.4455647468566895, acc: 0.61654132604599)
[2024-12-14 23:36:02,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:03,495][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 1.6664601564407349, acc: 0.5668449401855469)
[2024-12-14 23:36:03,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:04,134][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 1.366762399673462, acc: 0.6396396160125732)
[2024-12-14 23:36:04,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:04,531][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.7162522077560425, acc: 0.8571428656578064)
[2024-12-14 23:36:04,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:04,915][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.7545363306999207, acc: 0.8214285969734192)
[2024-12-14 23:36:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:05,283][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 1.1007648706436157, acc: 0.71875)
[2024-12-14 23:36:05,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:05,706][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.9629228115081787, acc: 0.75)
[2024-12-14 23:36:05,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:06,078][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.9824455380439758, acc: 0.7368420958518982)
[2024-12-14 23:36:06,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:06,485][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.5577077269554138, acc: 0.8181818127632141)
[2024-12-14 23:36:06,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:06,933][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.8815620541572571, acc: 0.6000000238418579)
[2024-12-14 23:36:07,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:07,279][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.9604108929634094, acc: 0.7142857313156128)
[2024-12-14 23:36:07,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:07,707][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 2.2757556438446045, acc: 0.40740740299224854)
[2024-12-14 23:36:07,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:08,224][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 2.551964282989502, acc: 0.3203883469104767)
[2024-12-14 23:36:08,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:08,809][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 2.456737995147705, acc: 0.4485294222831726)
[2024-12-14 23:36:08,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:09,228][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 2.16341233253479, acc: 0.47333332896232605)
[2024-12-14 23:36:09,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:09,654][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 2.141575813293457, acc: 0.4652777910232544)
[2024-12-14 23:36:09,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:10,031][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 1.7081934213638306, acc: 0.5581395626068115)
[2024-12-14 23:36:10,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:10,385][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 1.2169111967086792, acc: 0.625)
[2024-12-14 23:36:10,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:10,784][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 1.2921526432037354, acc: 0.6744186282157898)
[2024-12-14 23:36:10,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:11,161][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 2.220714569091797, acc: 0.5199999809265137)
[2024-12-14 23:36:11,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:11,714][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 1.5984607934951782, acc: 0.5735294222831726)
[2024-12-14 23:36:11,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:12,194][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 1.4405368566513062, acc: 0.5600000023841858)
[2024-12-14 23:36:12,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:12,647][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 1.2498091459274292, acc: 0.6060606241226196)
[2024-12-14 23:36:12,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:13,054][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 1.2545548677444458, acc: 0.7272727489471436)
[2024-12-14 23:36:13,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:13,458][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.80575031042099, acc: 0.7419354915618896)
[2024-12-14 23:36:13,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:13,849][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.8997111916542053, acc: 0.7777777910232544)
[2024-12-14 23:36:13,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:14,221][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.6410000324249268, acc: 0.800000011920929)
[2024-12-14 23:36:14,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:14,669][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.7932688593864441, acc: 0.75)
[2024-12-14 23:36:14,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:15,060][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.8287567496299744, acc: 0.7407407164573669)
[2024-12-14 23:36:15,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:15,401][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.6257514357566833, acc: 0.807692289352417)
[2024-12-14 23:36:15,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:15,788][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 1.1790754795074463, acc: 0.6724137663841248)
[2024-12-14 23:36:15,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:16,244][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.8214951157569885, acc: 0.7142857313156128)
[2024-12-14 23:36:16,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:16,649][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.8004719614982605, acc: 0.7333333492279053)
[2024-12-14 23:36:16,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:17,078][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.9108064770698547, acc: 0.7272727489471436)
[2024-12-14 23:36:17,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:17,442][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.5507902503013611, acc: 0.8181818127632141)
[2024-12-14 23:36:17,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:17,880][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 2.0588247776031494, acc: 0.4901960790157318)
[2024-12-14 23:36:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:18,311][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 1.7502830028533936, acc: 0.5769230723381042)
[2024-12-14 23:36:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:18,733][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 1.4312032461166382, acc: 0.5555555820465088)
[2024-12-14 23:36:18,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:19,172][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 1.7843059301376343, acc: 0.5249999761581421)
[2024-12-14 23:36:19,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:19,623][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 1.0454208850860596, acc: 0.699999988079071)
[2024-12-14 23:36:19,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:20,033][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.48953041434288025, acc: 0.8571428656578064)
[2024-12-14 23:36:20,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:20,463][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.8757330775260925, acc: 0.6666666865348816)
[2024-12-14 23:36:20,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:20,840][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 1.0814069509506226, acc: 0.6875)
[2024-12-14 23:36:21,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:21,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:22,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:22,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:23,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:23,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:23,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:24,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:24,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:25,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:25,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:25,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:26,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:26,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:27,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:27,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:27,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:28,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:28,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:28,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:29,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:29,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:30,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:30,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:30,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:31,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:31,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:32,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:32,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:32,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:33,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:33,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:33,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:34,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:34,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:34,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:35,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:35,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:36,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:36,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:37,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:37,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:37,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:38,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:38,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:39,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:39,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:39,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:40,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:40,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:40,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:41,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:41,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:41,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:42,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:42,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:42,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:43,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:43,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:43,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:44,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:44,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:45,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:45,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:46,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:46,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:47,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:47,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:47,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:48,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:48,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:49,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:49,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:49,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:50,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:50,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:50,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:51,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:51,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:51,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:52,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:52,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:53,313][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(11.7775, device='cuda:0') eval_epoch_loss=tensor(2.4662, device='cuda:0') eval_epoch_acc=tensor(0.4672, device='cuda:0')
[2024-12-14 23:36:53,314][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:36:53,315][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:36:54,045][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_4_step_423_loss_2.4661881923675537/model.pt
[2024-12-14 23:36:54,057][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:36:54,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:54,556][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 1.3150765895843506, acc: 0.6944444179534912)
[2024-12-14 23:36:54,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:54,979][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 1.316946268081665, acc: 0.5185185074806213)
[2024-12-14 23:36:55,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:55,360][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 1.6600135564804077, acc: 0.6363636255264282)
[2024-12-14 23:36:55,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:55,751][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 2.095043897628784, acc: 0.6521739363670349)
[2024-12-14 23:36:55,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:56,149][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 1.4070113897323608, acc: 0.5675675868988037)
[2024-12-14 23:36:56,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:56,525][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 1.0031596422195435, acc: 0.7037037014961243)
[2024-12-14 23:36:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:56,884][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 1.131301999092102, acc: 0.52173912525177)
[2024-12-14 23:36:56,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:57,216][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.6044398546218872, acc: 0.8148148059844971)
[2024-12-14 23:36:57,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:57,557][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.5313933491706848, acc: 0.8518518805503845)
[2024-12-14 23:36:57,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:57,889][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 1.0052851438522339, acc: 0.739130437374115)
[2024-12-14 23:36:57,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:58,268][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 1.1858311891555786, acc: 0.6944444179534912)
[2024-12-14 23:36:58,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:58,609][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.771657407283783, acc: 0.8799999952316284)
[2024-12-14 23:36:58,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:58,962][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 1.2222651243209839, acc: 0.6969696879386902)
[2024-12-14 23:36:59,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:59,318][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 1.467775821685791, acc: 0.6388888955116272)
[2024-12-14 23:36:59,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:36:59,670][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 1.2327207326889038, acc: 0.7272727489471436)
[2024-12-14 23:36:59,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:00,008][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.7271207571029663, acc: 0.761904776096344)
[2024-12-14 23:37:00,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:00,358][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 1.6565407514572144, acc: 0.5128205418586731)
[2024-12-14 23:37:00,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:00,854][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 1.9041944742202759, acc: 0.5)
[2024-12-14 23:37:01,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:01,628][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 2.1966567039489746, acc: 0.3840000033378601)
[2024-12-14 23:37:01,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:02,073][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 2.061619520187378, acc: 0.45967742800712585)
[2024-12-14 23:37:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:02,755][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 2.023264169692993, acc: 0.43283581733703613)
[2024-12-14 23:37:02,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:03,237][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 1.6817015409469604, acc: 0.5660377144813538)
[2024-12-14 23:37:03,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:03,712][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.9417662024497986, acc: 0.7272727489471436)
[2024-12-14 23:37:03,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:04,116][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.9834461808204651, acc: 0.782608687877655)
[2024-12-14 23:37:04,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:04,496][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 1.0574326515197754, acc: 0.7692307829856873)
[2024-12-14 23:37:04,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:04,941][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.8043222427368164, acc: 0.75)
[2024-12-14 23:37:05,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:05,407][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 1.6509050130844116, acc: 0.5373134613037109)
[2024-12-14 23:37:05,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:05,815][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 1.3936877250671387, acc: 0.6388888955116272)
[2024-12-14 23:37:05,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:06,205][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 1.4964590072631836, acc: 0.532608687877655)
[2024-12-14 23:37:06,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:06,599][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 1.7155834436416626, acc: 0.5256410241127014)
[2024-12-14 23:37:06,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:06,972][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 1.7186728715896606, acc: 0.5526315569877625)
[2024-12-14 23:37:07,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:07,350][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 1.5494049787521362, acc: 0.5918367505073547)
[2024-12-14 23:37:07,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:07,723][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 1.0271846055984497, acc: 0.6969696879386902)
[2024-12-14 23:37:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:08,108][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 1.8895677328109741, acc: 0.42268040776252747)
[2024-12-14 23:37:08,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:08,460][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 1.4890912771224976, acc: 0.5714285969734192)
[2024-12-14 23:37:08,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:08,879][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 1.7849739789962769, acc: 0.5058139562606812)
[2024-12-14 23:37:09,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:09,278][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 1.805524230003357, acc: 0.5)
[2024-12-14 23:37:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:09,646][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 1.8806406259536743, acc: 0.4938271641731262)
[2024-12-14 23:37:09,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:09,991][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 1.597507119178772, acc: 0.5)
[2024-12-14 23:37:10,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:10,346][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.9582535028457642, acc: 0.71875)
[2024-12-14 23:37:10,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:10,773][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 1.0281026363372803, acc: 0.692307710647583)
[2024-12-14 23:37:10,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:11,175][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 1.1431059837341309, acc: 0.695652186870575)
[2024-12-14 23:37:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:11,560][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 1.4984430074691772, acc: 0.5357142686843872)
[2024-12-14 23:37:11,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:11,935][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 1.7091854810714722, acc: 0.4939759075641632)
[2024-12-14 23:37:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:12,314][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 1.4006580114364624, acc: 0.6126126050949097)
[2024-12-14 23:37:12,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:12,679][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 1.5978177785873413, acc: 0.5922330021858215)
[2024-12-14 23:37:12,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:13,042][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 1.4672770500183105, acc: 0.6178861856460571)
[2024-12-14 23:37:13,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:13,388][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 1.0077636241912842, acc: 0.7916666865348816)
[2024-12-14 23:37:13,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:13,803][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 1.2110350131988525, acc: 0.7142857313156128)
[2024-12-14 23:37:13,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:14,273][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 2.028144598007202, acc: 0.4313725531101227)
[2024-12-14 23:37:14,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:14,708][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 2.070010185241699, acc: 0.4410480260848999)
[2024-12-14 23:37:14,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:15,107][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 1.8386887311935425, acc: 0.4895833432674408)
[2024-12-14 23:37:15,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:15,502][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 2.122154712677002, acc: 0.4110429584980011)
[2024-12-14 23:37:15,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:15,876][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 2.0202066898345947, acc: 0.4676258862018585)
[2024-12-14 23:37:15,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:16,280][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 2.0876996517181396, acc: 0.41206029057502747)
[2024-12-14 23:37:16,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:16,720][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 1.089460015296936, acc: 0.6666666865348816)
[2024-12-14 23:37:16,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:17,109][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 1.0090583562850952, acc: 0.7575757503509521)
[2024-12-14 23:37:17,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:17,470][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 1.0487405061721802, acc: 0.6666666865348816)
[2024-12-14 23:37:17,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:17,862][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.9878712892532349, acc: 0.6499999761581421)
[2024-12-14 23:37:17,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:18,227][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.7481266260147095, acc: 0.800000011920929)
[2024-12-14 23:37:18,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:18,681][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 1.3767030239105225, acc: 0.568965494632721)
[2024-12-14 23:37:18,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:19,120][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.8394585251808167, acc: 0.7096773982048035)
[2024-12-14 23:37:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:19,574][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.7663846015930176, acc: 0.7894737124443054)
[2024-12-14 23:37:19,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:19,940][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 1.3601224422454834, acc: 0.6296296119689941)
[2024-12-14 23:37:20,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:20,274][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 1.4605268239974976, acc: 0.523809552192688)
[2024-12-14 23:37:20,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:20,694][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 1.6109423637390137, acc: 0.5454545617103577)
[2024-12-14 23:37:20,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:21,070][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.9049272537231445, acc: 0.4923076927661896)
[2024-12-14 23:37:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:21,492][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 1.4285759925842285, acc: 0.6000000238418579)
[2024-12-14 23:37:21,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:21,930][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 1.5126982927322388, acc: 0.517241358757019)
[2024-12-14 23:37:22,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:22,299][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 1.6966136693954468, acc: 0.5098039507865906)
[2024-12-14 23:37:22,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:22,643][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 1.6178512573242188, acc: 0.48275861144065857)
[2024-12-14 23:37:22,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:23,016][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.6395320892333984, acc: 0.7894737124443054)
[2024-12-14 23:37:23,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:23,379][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 1.3887580633163452, acc: 0.5263158082962036)
[2024-12-14 23:37:23,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:23,807][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 1.8726893663406372, acc: 0.4910714328289032)
[2024-12-14 23:37:23,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:24,246][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 2.0167548656463623, acc: 0.47191011905670166)
[2024-12-14 23:37:24,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:24,650][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 2.2979140281677246, acc: 0.3820224702358246)
[2024-12-14 23:37:24,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:25,175][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 2.301220655441284, acc: 0.3758865296840668)
[2024-12-14 23:37:25,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:25,582][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 2.344156503677368, acc: 0.3586956560611725)
[2024-12-14 23:37:25,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:25,972][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.8378157019615173, acc: 0.800000011920929)
[2024-12-14 23:37:26,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:26,371][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.8497711420059204, acc: 0.692307710647583)
[2024-12-14 23:37:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:26,762][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.8633322715759277, acc: 0.6666666865348816)
[2024-12-14 23:37:26,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:27,149][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 1.7886885404586792, acc: 0.5185185074806213)
[2024-12-14 23:37:27,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:27,509][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 1.2715917825698853, acc: 0.6226415038108826)
[2024-12-14 23:37:27,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:27,883][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.873091995716095, acc: 0.6896551847457886)
[2024-12-14 23:37:28,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:28,516][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.905236005783081, acc: 0.5135135054588318)
[2024-12-14 23:37:28,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:29,007][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 1.885813593864441, acc: 0.5633803009986877)
[2024-12-14 23:37:29,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:29,424][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.49542874097824097, acc: 0.8999999761581421)
[2024-12-14 23:37:29,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:29,852][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.666778028011322, acc: 0.8333333134651184)
[2024-12-14 23:37:29,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:30,227][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.9493415355682373, acc: 0.7692307829856873)
[2024-12-14 23:37:31,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:32,831][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 2.1535556316375732, acc: 0.4214285612106323)
[2024-12-14 23:37:33,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:33,675][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 1.7969285249710083, acc: 0.523809552192688)
[2024-12-14 23:37:33,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:34,058][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 1.2074413299560547, acc: 0.7142857313156128)
[2024-12-14 23:37:34,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:34,462][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 1.4776822328567505, acc: 0.6333333253860474)
[2024-12-14 23:37:34,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:35,191][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 1.4483678340911865, acc: 0.625)
[2024-12-14 23:37:35,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:35,600][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.5630892515182495, acc: 0.807692289352417)
[2024-12-14 23:37:35,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:36,023][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 1.2055692672729492, acc: 0.5483871102333069)
[2024-12-14 23:37:36,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:36,416][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 1.382751703262329, acc: 0.6000000238418579)
[2024-12-14 23:37:36,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:36,807][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 1.4169116020202637, acc: 0.5555555820465088)
[2024-12-14 23:37:37,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:37,894][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 2.009871006011963, acc: 0.43644067645072937)
[2024-12-14 23:37:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:38,287][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 1.9987494945526123, acc: 0.46268656849861145)
[2024-12-14 23:37:38,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:38,694][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 1.938995599746704, acc: 0.47445255517959595)
[2024-12-14 23:37:38,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:39,287][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 1.757707953453064, acc: 0.5199999809265137)
[2024-12-14 23:37:39,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:39,667][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 1.763396143913269, acc: 0.5)
[2024-12-14 23:37:39,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:40,039][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 1.4737910032272339, acc: 0.5192307829856873)
[2024-12-14 23:37:40,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:40,395][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 1.442650318145752, acc: 0.5714285969734192)
[2024-12-14 23:37:40,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:40,799][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 2.3329997062683105, acc: 0.3442623019218445)
[2024-12-14 23:37:40,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:41,174][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 1.6657143831253052, acc: 0.5593220591545105)
[2024-12-14 23:37:41,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:41,514][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.9131637811660767, acc: 0.5348837375640869)
[2024-12-14 23:37:41,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:41,926][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 1.649633526802063, acc: 0.5227272510528564)
[2024-12-14 23:37:42,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:42,315][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 2.0012009143829346, acc: 0.4716981053352356)
[2024-12-14 23:37:42,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:42,741][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 1.4263908863067627, acc: 0.6136363744735718)
[2024-12-14 23:37:42,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:43,136][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 1.1899135112762451, acc: 0.6800000071525574)
[2024-12-14 23:37:43,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:43,538][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 1.0965583324432373, acc: 0.699999988079071)
[2024-12-14 23:37:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:43,912][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.8279645442962646, acc: 0.7727272510528564)
[2024-12-14 23:37:44,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:44,349][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 1.5814907550811768, acc: 0.5692307949066162)
[2024-12-14 23:37:44,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:44,714][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 1.6180698871612549, acc: 0.59375)
[2024-12-14 23:37:44,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:45,176][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 1.09333336353302, acc: 0.75)
[2024-12-14 23:37:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:45,546][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 1.208027958869934, acc: 0.6666666865348816)
[2024-12-14 23:37:45,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:45,904][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.8072454929351807, acc: 0.75)
[2024-12-14 23:37:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:46,264][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.7634508609771729, acc: 0.774193525314331)
[2024-12-14 23:37:46,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:46,634][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.5935458540916443, acc: 0.739130437374115)
[2024-12-14 23:37:46,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:47,022][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 1.338047742843628, acc: 0.5666666626930237)
[2024-12-14 23:37:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:47,459][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 1.3422285318374634, acc: 0.5609756112098694)
[2024-12-14 23:37:47,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:47,850][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.9243872761726379, acc: 0.7714285850524902)
[2024-12-14 23:37:47,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:48,238][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.9598758816719055, acc: 0.7368420958518982)
[2024-12-14 23:37:48,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:48,607][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 1.0557528734207153, acc: 0.7096773982048035)
[2024-12-14 23:37:48,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:48,984][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.5844867825508118, acc: 0.8799999952316284)
[2024-12-14 23:37:49,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:49,407][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.6958692669868469, acc: 0.8181818127632141)
[2024-12-14 23:37:49,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:49,830][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.9332823753356934, acc: 0.675000011920929)
[2024-12-14 23:37:49,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:50,220][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 1.1571011543273926, acc: 0.6428571343421936)
[2024-12-14 23:37:50,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:50,643][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 2.1107068061828613, acc: 0.45255473256111145)
[2024-12-14 23:37:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:51,046][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 1.6104753017425537, acc: 0.5241379141807556)
[2024-12-14 23:37:51,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:51,481][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 2.221144199371338, acc: 0.44999998807907104)
[2024-12-14 23:37:51,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:51,923][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 1.977890133857727, acc: 0.4370861053466797)
[2024-12-14 23:37:52,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:52,316][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 1.509315848350525, acc: 0.5982906222343445)
[2024-12-14 23:37:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:52,667][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.5312573909759521, acc: 0.8399999737739563)
[2024-12-14 23:37:52,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:53,099][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.8458200693130493, acc: 0.7307692170143127)
[2024-12-14 23:37:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:53,460][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.6211732625961304, acc: 0.807692289352417)
[2024-12-14 23:37:53,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:53,847][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 1.17534339427948, acc: 0.6153846383094788)
[2024-12-14 23:37:53,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:54,244][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 1.5472242832183838, acc: 0.5333333611488342)
[2024-12-14 23:37:54,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:54,636][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 1.393523931503296, acc: 0.6753246784210205)
[2024-12-14 23:37:54,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:55,009][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 1.2356643676757812, acc: 0.6041666865348816)
[2024-12-14 23:37:55,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:55,443][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 1.161506175994873, acc: 0.6206896305084229)
[2024-12-14 23:37:56,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:56,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:57,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:57,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:58,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:58,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:59,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:59,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:37:59,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:00,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:00,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:01,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:02,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:02,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:03,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:03,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:04,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:04,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:04,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:05,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:05,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:05,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:06,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:06,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:07,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:07,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:08,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:08,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:08,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:10,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:10,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:11,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:11,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:12,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:12,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:12,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:13,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:13,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:13,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:13,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:14,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:14,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:15,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:15,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:15,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:16,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:16,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:16,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:17,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:17,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:17,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:18,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:18,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:19,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:19,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:20,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:20,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:21,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:21,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:22,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:22,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:22,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:23,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:24,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:24,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:25,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:25,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:25,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:26,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:27,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:27,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:28,779][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.0628, device='cuda:0') eval_epoch_loss=tensor(1.9548, device='cuda:0') eval_epoch_acc=tensor(0.5231, device='cuda:0')
[2024-12-14 23:38:28,782][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:38:28,782][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:38:29,520][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_4_step_566_loss_1.9548413753509521/model.pt
[2024-12-14 23:38:29,524][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:38:29,524][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.5230581164360046
[2024-12-14 23:38:29,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:29,993][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 1.5220452547073364, acc: 0.5595238208770752)
[2024-12-14 23:38:30,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:30,414][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 1.2354638576507568, acc: 0.6315789222717285)
[2024-12-14 23:38:30,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:30,874][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.7173767685890198, acc: 0.8148148059844971)
[2024-12-14 23:38:31,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:31,310][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 1.7327464818954468, acc: 0.5347593426704407)
[2024-12-14 23:38:31,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:31,731][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 1.2449744939804077, acc: 0.6612903475761414)
[2024-12-14 23:38:31,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:32,200][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 1.4186077117919922, acc: 0.5897436141967773)
[2024-12-14 23:38:32,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:32,589][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 1.9724735021591187, acc: 0.43877550959587097)
[2024-12-14 23:38:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:32,992][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 1.9353660345077515, acc: 0.4528301954269409)
[2024-12-14 23:38:33,484][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=4.3178, train_epoch_loss=1.4627, epoch time 390.18221501703374s
[2024-12-14 23:38:33,485][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-14 23:38:33,485][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 23:38:33,485][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-14 23:38:33,485][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-12-14 23:38:33,485][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:38:34,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:34,508][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 1.1094000339508057, acc: 0.6666666865348816)
[2024-12-14 23:38:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:34,909][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 1.0991487503051758, acc: 0.6800000071525574)
[2024-12-14 23:38:35,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:35,391][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 1.710869312286377, acc: 0.5135135054588318)
[2024-12-14 23:38:35,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:35,901][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 1.5047568082809448, acc: 0.5263158082962036)
[2024-12-14 23:38:36,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:36,373][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 1.4949818849563599, acc: 0.5945945978164673)
[2024-12-14 23:38:36,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:36,794][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 1.175775170326233, acc: 0.6428571343421936)
[2024-12-14 23:38:36,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:37,274][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 1.5330872535705566, acc: 0.5306122303009033)
[2024-12-14 23:38:37,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:37,737][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 1.108612060546875, acc: 0.6666666865348816)
[2024-12-14 23:38:37,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:38,162][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.3567473888397217, acc: 0.8636363744735718)
[2024-12-14 23:38:38,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:38,564][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.5471071600914001, acc: 0.8846153616905212)
[2024-12-14 23:38:38,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:38,976][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.766149640083313, acc: 0.7777777910232544)
[2024-12-14 23:38:39,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:39,428][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 1.15101158618927, acc: 0.6666666865348816)
[2024-12-14 23:38:39,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:39,851][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 1.0748509168624878, acc: 0.6969696879386902)
[2024-12-14 23:38:39,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:40,248][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 1.303200125694275, acc: 0.6086956262588501)
[2024-12-14 23:38:40,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:40,641][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 2.0191118717193604, acc: 0.47058823704719543)
[2024-12-14 23:38:40,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:41,032][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 1.6940319538116455, acc: 0.4693877696990967)
[2024-12-14 23:38:41,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:41,461][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.5701743364334106, acc: 0.8421052694320679)
[2024-12-14 23:38:41,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:41,842][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 1.0768264532089233, acc: 0.625)
[2024-12-14 23:38:41,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:42,220][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 1.2027298212051392, acc: 0.6388888955116272)
[2024-12-14 23:38:42,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:42,607][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.9197154641151428, acc: 0.7368420958518982)
[2024-12-14 23:38:42,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:43,012][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 1.2797152996063232, acc: 0.692307710647583)
[2024-12-14 23:38:43,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:43,381][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 1.009382724761963, acc: 0.7241379022598267)
[2024-12-14 23:38:43,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:43,817][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 1.068373680114746, acc: 0.6000000238418579)
[2024-12-14 23:38:43,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:44,262][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.7974867820739746, acc: 0.6666666865348816)
[2024-12-14 23:38:44,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:44,653][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 1.0183049440383911, acc: 0.6875)
[2024-12-14 23:38:44,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:45,032][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 2.287637948989868, acc: 0.3207547068595886)
[2024-12-14 23:38:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:45,419][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 1.998504877090454, acc: 0.4109589159488678)
[2024-12-14 23:38:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:46,759][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 2.102102041244507, acc: 0.4150197505950928)
[2024-12-14 23:38:46,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:47,135][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 1.646807074546814, acc: 0.5116279125213623)
[2024-12-14 23:38:47,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:47,549][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 1.6831916570663452, acc: 0.5180723071098328)
[2024-12-14 23:38:47,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:47,979][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 1.7085447311401367, acc: 0.5061728358268738)
[2024-12-14 23:38:48,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:48,414][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 1.2369571924209595, acc: 0.6071428656578064)
[2024-12-14 23:38:48,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:48,811][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.9693624973297119, acc: 0.7037037014961243)
[2024-12-14 23:38:48,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:49,183][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.7713043093681335, acc: 0.739130437374115)
[2024-12-14 23:38:49,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:49,620][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 1.8717011213302612, acc: 0.5042017102241516)
[2024-12-14 23:38:49,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:50,079][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 1.3490904569625854, acc: 0.6393442749977112)
[2024-12-14 23:38:50,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:50,544][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 1.7649275064468384, acc: 0.5079365372657776)
[2024-12-14 23:38:50,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:50,956][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 1.8665539026260376, acc: 0.47457626461982727)
[2024-12-14 23:38:51,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:51,368][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 1.2970654964447021, acc: 0.6206896305084229)
[2024-12-14 23:38:51,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:51,746][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.587548017501831, acc: 0.7142857313156128)
[2024-12-14 23:38:51,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:52,251][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 1.034283995628357, acc: 0.6538461446762085)
[2024-12-14 23:38:52,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:52,697][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 2.111025333404541, acc: 0.5135135054588318)
[2024-12-14 23:38:52,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:53,121][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 1.7169009447097778, acc: 0.4923076927661896)
[2024-12-14 23:38:53,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:53,601][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 1.9101016521453857, acc: 0.5050504803657532)
[2024-12-14 23:38:53,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:54,077][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 1.512373447418213, acc: 0.5979381203651428)
[2024-12-14 23:38:54,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:54,531][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 1.9438122510910034, acc: 0.5)
[2024-12-14 23:38:54,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:54,936][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.7656775712966919, acc: 0.7307692170143127)
[2024-12-14 23:38:55,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:55,334][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.5159192085266113, acc: 0.8148148059844971)
[2024-12-14 23:38:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:55,734][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.9112557172775269, acc: 0.7142857313156128)
[2024-12-14 23:38:55,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:56,127][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.729290246963501, acc: 0.7777777910232544)
[2024-12-14 23:38:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:56,560][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 1.060809850692749, acc: 0.6666666865348816)
[2024-12-14 23:38:56,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:56,950][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 1.1432690620422363, acc: 0.6984127163887024)
[2024-12-14 23:38:57,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:57,337][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 1.7301627397537231, acc: 0.5211267471313477)
[2024-12-14 23:38:57,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:57,829][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 2.0655453205108643, acc: 0.4933333396911621)
[2024-12-14 23:38:57,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:58,223][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.9823205471038818, acc: 0.7297297120094299)
[2024-12-14 23:38:58,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:38:58,612][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.5539194345474243, acc: 0.807692289352417)
[2024-12-14 23:39:00,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:01,587][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.734710454940796, acc: 0.532423198223114)
[2024-12-14 23:39:02,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:02,812][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 2.2060317993164062, acc: 0.4095860421657562)
[2024-12-14 23:39:03,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:03,591][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 1.8393803834915161, acc: 0.5284090638160706)
[2024-12-14 23:39:03,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:04,211][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 1.9124387502670288, acc: 0.49264705181121826)
[2024-12-14 23:39:04,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:04,799][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 2.0445220470428467, acc: 0.4492753744125366)
[2024-12-14 23:39:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:05,266][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 1.524214267730713, acc: 0.6000000238418579)
[2024-12-14 23:39:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:05,651][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.6365262269973755, acc: 0.8235294222831726)
[2024-12-14 23:39:05,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:06,070][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 1.5006146430969238, acc: 0.6111111044883728)
[2024-12-14 23:39:06,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:06,511][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 1.2331883907318115, acc: 0.671875)
[2024-12-14 23:39:06,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:06,934][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.8109079599380493, acc: 0.7586206793785095)
[2024-12-14 23:39:07,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:07,391][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 1.8069055080413818, acc: 0.5357142686843872)
[2024-12-14 23:39:07,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:07,856][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 1.8285942077636719, acc: 0.46666666865348816)
[2024-12-14 23:39:07,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:08,240][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.4635292887687683, acc: 0.8399999737739563)
[2024-12-14 23:39:08,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:08,625][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 1.043386697769165, acc: 0.6666666865348816)
[2024-12-14 23:39:08,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:09,035][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 1.062526822090149, acc: 0.6060606241226196)
[2024-12-14 23:39:09,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:09,439][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 1.8972747325897217, acc: 0.529411792755127)
[2024-12-14 23:39:09,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:09,803][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 1.9444851875305176, acc: 0.4682539701461792)
[2024-12-14 23:39:09,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:10,197][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 2.12662410736084, acc: 0.4153846204280853)
[2024-12-14 23:39:10,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:10,662][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 1.8496402502059937, acc: 0.5102040767669678)
[2024-12-14 23:39:10,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:11,103][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 2.246384859085083, acc: 0.41791045665740967)
[2024-12-14 23:39:11,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:11,561][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 2.134918689727783, acc: 0.4489051103591919)
[2024-12-14 23:39:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:11,941][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.4506736099720001, acc: 0.8571428656578064)
[2024-12-14 23:39:12,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:12,298][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.5418787598609924, acc: 0.7916666865348816)
[2024-12-14 23:39:12,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:12,669][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.8013840913772583, acc: 0.7272727489471436)
[2024-12-14 23:39:12,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:13,057][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.6711981296539307, acc: 0.7692307829856873)
[2024-12-14 23:39:13,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:13,458][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 1.755353331565857, acc: 0.4615384638309479)
[2024-12-14 23:39:13,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:13,851][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 1.9142298698425293, acc: 0.5)
[2024-12-14 23:39:13,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:14,194][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 1.4310903549194336, acc: 0.53125)
[2024-12-14 23:39:14,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:14,598][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 1.6671504974365234, acc: 0.49275362491607666)
[2024-12-14 23:39:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:15,021][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 1.390108585357666, acc: 0.5799999833106995)
[2024-12-14 23:39:15,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:15,477][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 1.2822551727294922, acc: 0.6086956262588501)
[2024-12-14 23:39:15,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:16,032][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 1.8454798460006714, acc: 0.46000000834465027)
[2024-12-14 23:39:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:16,473][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 1.6739516258239746, acc: 0.5339806079864502)
[2024-12-14 23:39:16,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:17,614][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 1.7531620264053345, acc: 0.5679611563682556)
[2024-12-14 23:39:17,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:18,485][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.914788007736206, acc: 0.45698925852775574)
[2024-12-14 23:39:18,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:19,320][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 1.751023530960083, acc: 0.5603448152542114)
[2024-12-14 23:39:19,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:20,090][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 1.3963876962661743, acc: 0.5473684072494507)
[2024-12-14 23:39:20,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:21,111][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 2.053574323654175, acc: 0.42574256658554077)
[2024-12-14 23:39:21,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:21,478][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 1.9328608512878418, acc: 0.4354838728904724)
[2024-12-14 23:39:21,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:21,865][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 2.010145902633667, acc: 0.43478259444236755)
[2024-12-14 23:39:21,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:22,309][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 2.1275081634521484, acc: 0.3949579894542694)
[2024-12-14 23:39:22,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:22,756][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 2.1175358295440674, acc: 0.36538460850715637)
[2024-12-14 23:39:22,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:23,194][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 2.1815857887268066, acc: 0.41605839133262634)
[2024-12-14 23:39:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:23,540][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 2.0767874717712402, acc: 0.4029850661754608)
[2024-12-14 23:39:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:23,973][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.6573854684829712, acc: 0.800000011920929)
[2024-12-14 23:39:24,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:24,344][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.8680057525634766, acc: 0.7272727489471436)
[2024-12-14 23:39:24,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:24,753][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.8193588256835938, acc: 0.739130437374115)
[2024-12-14 23:39:24,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:25,118][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 1.1200298070907593, acc: 0.5909090638160706)
[2024-12-14 23:39:25,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:25,486][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 1.6279736757278442, acc: 0.5)
[2024-12-14 23:39:25,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:25,885][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 1.1786396503448486, acc: 0.5813953280448914)
[2024-12-14 23:39:26,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:26,323][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 1.214868426322937, acc: 0.5600000023841858)
[2024-12-14 23:39:26,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:26,743][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.6146413087844849, acc: 0.8235294222831726)
[2024-12-14 23:39:26,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:27,190][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.5062316656112671, acc: 0.8461538553237915)
[2024-12-14 23:39:27,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:27,630][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 1.103149175643921, acc: 0.6666666865348816)
[2024-12-14 23:39:27,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:28,033][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 1.422206997871399, acc: 0.6461538672447205)
[2024-12-14 23:39:28,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:28,477][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 1.5232009887695312, acc: 0.6491228342056274)
[2024-12-14 23:39:28,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:28,921][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 1.354144811630249, acc: 0.6666666865348816)
[2024-12-14 23:39:29,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:29,303][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 1.5633872747421265, acc: 0.5641025900840759)
[2024-12-14 23:39:29,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:29,754][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 1.1772339344024658, acc: 0.6734693646430969)
[2024-12-14 23:39:29,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:30,149][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.5274448990821838, acc: 0.9090909361839294)
[2024-12-14 23:39:30,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:30,531][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 1.5803897380828857, acc: 0.5555555820465088)
[2024-12-14 23:39:30,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:30,857][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 1.6851228475570679, acc: 0.6016260385513306)
[2024-12-14 23:39:30,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:31,246][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 1.3396592140197754, acc: 0.6290322542190552)
[2024-12-14 23:39:31,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:32,127][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 1.8411601781845093, acc: 0.5057034492492676)
[2024-12-14 23:39:32,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:32,555][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 1.2904527187347412, acc: 0.6266666650772095)
[2024-12-14 23:39:32,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:32,993][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 1.3051613569259644, acc: 0.6538461446762085)
[2024-12-14 23:39:33,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:33,407][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.5957568287849426, acc: 0.875)
[2024-12-14 23:39:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:33,776][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 1.0231233835220337, acc: 0.6315789222717285)
[2024-12-14 23:39:33,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:34,222][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 1.8787347078323364, acc: 0.48466256260871887)
[2024-12-14 23:39:34,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:34,659][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.6121926307678223, acc: 0.5902777910232544)
[2024-12-14 23:39:34,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:35,148][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 2.0124855041503906, acc: 0.46666666865348816)
[2024-12-14 23:39:35,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:35,578][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 1.9275869131088257, acc: 0.4702380895614624)
[2024-12-14 23:39:35,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:36,004][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 1.7820550203323364, acc: 0.5384615659713745)
[2024-12-14 23:39:36,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:36,537][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 1.8232146501541138, acc: 0.5220588445663452)
[2024-12-14 23:39:36,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:36,957][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.9907436966896057, acc: 0.7307692170143127)
[2024-12-14 23:39:37,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:37,337][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.5088933706283569, acc: 0.782608687877655)
[2024-12-14 23:39:37,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:37,727][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.9324418902397156, acc: 0.71875)
[2024-12-14 23:39:37,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:38,178][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.9695820212364197, acc: 0.782608687877655)
[2024-12-14 23:39:38,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:38,617][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 1.0763956308364868, acc: 0.6857143044471741)
[2024-12-14 23:39:39,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:39,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:40,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:40,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:41,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:41,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:41,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:42,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:42,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:43,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:43,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:44,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:44,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:45,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:47,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:47,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:48,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:48,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:49,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:49,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:50,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:50,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:50,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:51,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:51,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:51,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:52,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:52,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:52,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:53,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:53,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:54,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:54,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:54,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:55,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:55,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:55,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:56,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:56,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:56,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:57,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:57,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:57,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:58,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:58,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:59,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:59,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:39:59,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:00,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:00,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:00,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:01,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:01,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:02,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:02,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:02,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:03,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:03,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:03,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:04,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:05,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:05,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:06,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:06,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:07,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:07,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:07,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:07,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:08,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:08,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:09,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:09,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:10,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:10,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:10,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:11,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:11,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:11,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:12,426][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.5258, device='cuda:0') eval_epoch_loss=tensor(1.8758, device='cuda:0') eval_epoch_acc=tensor(0.5147, device='cuda:0')
[2024-12-14 23:40:12,428][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:40:12,428][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:40:13,163][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_5_step_135_loss_1.8757710456848145/model.pt
[2024-12-14 23:40:13,180][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:40:13,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:13,650][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.7903604507446289, acc: 0.7307692170143127)
[2024-12-14 23:40:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:14,125][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 1.664668083190918, acc: 0.4761904776096344)
[2024-12-14 23:40:14,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:14,539][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 1.3244789838790894, acc: 0.5666666626930237)
[2024-12-14 23:40:14,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:14,979][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 1.109763741493225, acc: 0.695652186870575)
[2024-12-14 23:40:15,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:15,361][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 1.0883382558822632, acc: 0.761904776096344)
[2024-12-14 23:40:15,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:15,697][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 1.6489028930664062, acc: 0.5769230723381042)
[2024-12-14 23:40:15,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:16,110][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 1.823407530784607, acc: 0.4193548262119293)
[2024-12-14 23:40:16,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:16,493][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 1.7249531745910645, acc: 0.5135135054588318)
[2024-12-14 23:40:16,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:17,066][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 2.0350732803344727, acc: 0.359649121761322)
[2024-12-14 23:40:17,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:17,447][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.689331293106079, acc: 0.5597015023231506)
[2024-12-14 23:40:17,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:17,876][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 2.1839394569396973, acc: 0.3877550959587097)
[2024-12-14 23:40:18,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:18,359][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 2.027489185333252, acc: 0.41489362716674805)
[2024-12-14 23:40:18,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:18,675][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 1.7788410186767578, acc: 0.48571428656578064)
[2024-12-14 23:40:18,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:19,010][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 1.4043376445770264, acc: 0.5714285969734192)
[2024-12-14 23:40:19,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:19,357][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 1.401190996170044, acc: 0.5652173757553101)
[2024-12-14 23:40:19,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:19,697][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 1.3949594497680664, acc: 0.517241358757019)
[2024-12-14 23:40:19,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:20,051][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 1.7644754648208618, acc: 0.54347825050354)
[2024-12-14 23:40:20,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:20,414][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 1.7745660543441772, acc: 0.47457626461982727)
[2024-12-14 23:40:20,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:20,788][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 1.765631079673767, acc: 0.5614035129547119)
[2024-12-14 23:40:20,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:21,186][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 1.7506070137023926, acc: 0.45945945382118225)
[2024-12-14 23:40:21,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:21,618][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 1.4787312746047974, acc: 0.5714285969734192)
[2024-12-14 23:40:21,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:22,002][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 1.1496678590774536, acc: 0.695652186870575)
[2024-12-14 23:40:22,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:22,425][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 0.88614422082901, acc: 0.7894737124443054)
[2024-12-14 23:40:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:24,042][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 1.4290130138397217, acc: 0.5945945978164673)
[2024-12-14 23:40:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:24,400][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.7774287462234497, acc: 0.5185185074806213)
[2024-12-14 23:40:24,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:24,846][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 1.3764479160308838, acc: 0.5581395626068115)
[2024-12-14 23:40:25,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:25,500][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.3247005939483643, acc: 0.5882353186607361)
[2024-12-14 23:40:25,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:26,122][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.8165149688720703, acc: 0.516853928565979)
[2024-12-14 23:40:26,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:26,592][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 1.1556302309036255, acc: 0.7045454382896423)
[2024-12-14 23:40:26,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:26,974][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.9428397417068481, acc: 0.7142857313156128)
[2024-12-14 23:40:27,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:27,341][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 1.0539110898971558, acc: 0.7241379022598267)
[2024-12-14 23:40:27,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:27,709][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.9349604845046997, acc: 0.7142857313156128)
[2024-12-14 23:40:27,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:28,126][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 1.241363286972046, acc: 0.5799999833106995)
[2024-12-14 23:40:28,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:28,575][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 1.3314262628555298, acc: 0.6111111044883728)
[2024-12-14 23:40:28,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:29,011][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 1.733615517616272, acc: 0.4901960790157318)
[2024-12-14 23:40:29,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:30,104][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 2.16961407661438, acc: 0.45205479860305786)
[2024-12-14 23:40:30,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:30,476][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.7251911759376526, acc: 0.7916666865348816)
[2024-12-14 23:40:30,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:30,863][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.6735743880271912, acc: 0.8148148059844971)
[2024-12-14 23:40:30,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:31,242][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.6920128464698792, acc: 0.8214285969734192)
[2024-12-14 23:40:31,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:31,827][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 1.4320226907730103, acc: 0.6283186078071594)
[2024-12-14 23:40:31,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:32,214][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 1.402343511581421, acc: 0.6086956262588501)
[2024-12-14 23:40:32,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:32,640][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 1.4822242259979248, acc: 0.5795454382896423)
[2024-12-14 23:40:33,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:33,602][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 2.13850998878479, acc: 0.442748099565506)
[2024-12-14 23:40:33,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:34,306][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 1.9639161825180054, acc: 0.43703705072402954)
[2024-12-14 23:40:34,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:34,699][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 1.3616859912872314, acc: 0.6065573692321777)
[2024-12-14 23:40:34,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:35,059][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.7146626114845276, acc: 0.75)
[2024-12-14 23:40:35,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:35,435][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.9066063165664673, acc: 0.7599999904632568)
[2024-12-14 23:40:35,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:35,815][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.9710305333137512, acc: 0.6428571343421936)
[2024-12-14 23:40:35,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:36,262][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 1.727440595626831, acc: 0.4878048896789551)
[2024-12-14 23:40:36,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:36,666][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 2.0322864055633545, acc: 0.44108760356903076)
[2024-12-14 23:40:36,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:37,027][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 2.1685822010040283, acc: 0.44092220067977905)
[2024-12-14 23:40:37,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:37,534][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 2.183100938796997, acc: 0.41874998807907104)
[2024-12-14 23:40:37,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:38,079][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 2.03774356842041, acc: 0.44840526580810547)
[2024-12-14 23:40:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:38,563][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 1.985453486442566, acc: 0.44128113985061646)
[2024-12-14 23:40:38,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:38,940][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 1.1577421426773071, acc: 0.6800000071525574)
[2024-12-14 23:40:39,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:39,542][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 1.983076810836792, acc: 0.5116279125213623)
[2024-12-14 23:40:39,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:40,400][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.7783771753311157, acc: 0.5714285969734192)
[2024-12-14 23:40:40,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:41,354][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 1.8990986347198486, acc: 0.5075757503509521)
[2024-12-14 23:40:41,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:42,290][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 1.5720964670181274, acc: 0.6117647290229797)
[2024-12-14 23:40:42,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:43,445][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 1.5778671503067017, acc: 0.5864197611808777)
[2024-12-14 23:40:43,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:44,480][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 1.2423679828643799, acc: 0.6774193644523621)
[2024-12-14 23:40:44,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:44,829][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.638583779335022, acc: 0.7857142686843872)
[2024-12-14 23:40:44,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:45,176][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.9789891242980957, acc: 0.7749999761581421)
[2024-12-14 23:40:45,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:45,614][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 1.456396222114563, acc: 0.5441176295280457)
[2024-12-14 23:40:45,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:46,041][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 1.697453498840332, acc: 0.529411792755127)
[2024-12-14 23:40:46,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:46,435][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 1.8028156757354736, acc: 0.5169491767883301)
[2024-12-14 23:40:46,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:46,861][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 1.9254270792007446, acc: 0.46268656849861145)
[2024-12-14 23:40:46,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:47,291][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 1.9408483505249023, acc: 0.4757281541824341)
[2024-12-14 23:40:47,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:47,680][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 1.498984694480896, acc: 0.5873016119003296)
[2024-12-14 23:40:47,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:48,064][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 1.6286146640777588, acc: 0.5274725556373596)
[2024-12-14 23:40:48,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:48,468][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 1.9388611316680908, acc: 0.4798206388950348)
[2024-12-14 23:40:48,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:48,910][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 1.981415867805481, acc: 0.4724409580230713)
[2024-12-14 23:40:49,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:49,318][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 1.8354555368423462, acc: 0.4784482717514038)
[2024-12-14 23:40:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:49,721][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 1.9408750534057617, acc: 0.4855072498321533)
[2024-12-14 23:40:49,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:50,143][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 1.9899474382400513, acc: 0.443579763174057)
[2024-12-14 23:40:50,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:50,596][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 1.8861342668533325, acc: 0.54347825050354)
[2024-12-14 23:40:50,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:50,990][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.8942785859107971, acc: 0.695652186870575)
[2024-12-14 23:40:51,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:51,365][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 1.2282371520996094, acc: 0.6071428656578064)
[2024-12-14 23:40:51,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:51,741][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 1.101104974746704, acc: 0.5957446694374084)
[2024-12-14 23:40:52,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:52,580][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 1.5769822597503662, acc: 0.5615384578704834)
[2024-12-14 23:40:52,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:52,995][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 1.3756085634231567, acc: 0.5675675868988037)
[2024-12-14 23:40:53,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:53,374][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 1.3309608697891235, acc: 0.604651153087616)
[2024-12-14 23:40:53,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:53,958][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 1.4191739559173584, acc: 0.6216216087341309)
[2024-12-14 23:40:54,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:54,400][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 1.412116289138794, acc: 0.5555555820465088)
[2024-12-14 23:40:54,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:54,762][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.8733189702033997, acc: 0.7575757503509521)
[2024-12-14 23:40:54,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:55,106][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.4825679063796997, acc: 0.8148148059844971)
[2024-12-14 23:40:55,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:55,444][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.7133910655975342, acc: 0.7599999904632568)
[2024-12-14 23:40:55,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:55,834][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 1.2924069166183472, acc: 0.6153846383094788)
[2024-12-14 23:40:56,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:56,661][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 1.3663361072540283, acc: 0.592391312122345)
[2024-12-14 23:40:56,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:57,236][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 1.7466984987258911, acc: 0.5227272510528564)
[2024-12-14 23:40:57,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:57,711][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 1.7409135103225708, acc: 0.457446813583374)
[2024-12-14 23:40:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:58,118][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 1.3492037057876587, acc: 0.6037735939025879)
[2024-12-14 23:40:58,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:58,540][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 1.412339687347412, acc: 0.5833333134651184)
[2024-12-14 23:40:58,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:58,992][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.8145069479942322, acc: 0.7674418687820435)
[2024-12-14 23:40:59,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:59,371][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 0.730992317199707, acc: 0.7333333492279053)
[2024-12-14 23:40:59,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:40:59,781][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 2.025266170501709, acc: 0.410526305437088)
[2024-12-14 23:40:59,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:00,153][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.6173959970474243, acc: 0.5555555820465088)
[2024-12-14 23:41:00,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:00,629][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 1.3223313093185425, acc: 0.6666666865348816)
[2024-12-14 23:41:00,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:01,169][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.6389490365982056, acc: 0.5917431116104126)
[2024-12-14 23:41:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:01,674][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.4235655069351196, acc: 0.6153846383094788)
[2024-12-14 23:41:01,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:02,033][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.9561466574668884, acc: 0.6842105388641357)
[2024-12-14 23:41:02,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:02,412][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.7159237265586853, acc: 0.8333333134651184)
[2024-12-14 23:41:02,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:02,788][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 1.5304985046386719, acc: 0.5454545617103577)
[2024-12-14 23:41:02,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:03,139][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 1.4012384414672852, acc: 0.5555555820465088)
[2024-12-14 23:41:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:03,504][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.9685943722724915, acc: 0.7142857313156128)
[2024-12-14 23:41:03,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:03,894][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 1.1881216764450073, acc: 0.6136363744735718)
[2024-12-14 23:41:04,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:04,300][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 1.4262163639068604, acc: 0.6818181872367859)
[2024-12-14 23:41:04,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:04,909][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.7101954221725464, acc: 0.4677419364452362)
[2024-12-14 23:41:05,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:05,479][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 1.2848073244094849, acc: 0.6363636255264282)
[2024-12-14 23:41:05,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:05,884][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.5108567476272583, acc: 0.8571428656578064)
[2024-12-14 23:41:05,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:06,231][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.8515886068344116, acc: 0.7692307829856873)
[2024-12-14 23:41:06,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:06,587][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.8488101959228516, acc: 0.7419354915618896)
[2024-12-14 23:41:06,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:06,957][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.8276363611221313, acc: 0.75)
[2024-12-14 23:41:07,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:07,310][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 1.0452862977981567, acc: 0.7297297120094299)
[2024-12-14 23:41:07,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:07,660][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 1.2718998193740845, acc: 0.6756756901741028)
[2024-12-14 23:41:07,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:08,060][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 1.142533540725708, acc: 0.6486486196517944)
[2024-12-14 23:41:08,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:08,433][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 1.529700756072998, acc: 0.5588235259056091)
[2024-12-14 23:41:08,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:08,795][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.85755854845047, acc: 0.7560975551605225)
[2024-12-14 23:41:08,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:09,135][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.2755928039550781, acc: 0.9599999785423279)
[2024-12-14 23:41:09,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:09,543][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.48189881443977356, acc: 0.800000011920929)
[2024-12-14 23:41:09,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:09,945][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.5129984021186829, acc: 0.8387096524238586)
[2024-12-14 23:41:10,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:10,336][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 1.182762622833252, acc: 0.6315789222717285)
[2024-12-14 23:41:10,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:10,738][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 1.3219456672668457, acc: 0.6142857074737549)
[2024-12-14 23:41:10,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:11,122][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 1.195436954498291, acc: 0.6447368264198303)
[2024-12-14 23:41:11,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:11,717][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 1.5097661018371582, acc: 0.5188679099082947)
[2024-12-14 23:41:11,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:12,337][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 1.6575199365615845, acc: 0.5333333611488342)
[2024-12-14 23:41:12,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:12,773][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 1.0148816108703613, acc: 0.6944444179534912)
[2024-12-14 23:41:12,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:13,135][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 1.196794867515564, acc: 0.6774193644523621)
[2024-12-14 23:41:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:13,505][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 2.2489211559295654, acc: 0.41333332657814026)
[2024-12-14 23:41:13,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:13,888][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 1.8103948831558228, acc: 0.4583333432674408)
[2024-12-14 23:41:14,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:14,748][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 2.3071653842926025, acc: 0.37599998712539673)
[2024-12-14 23:41:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:15,112][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 2.016598701477051, acc: 0.483146071434021)
[2024-12-14 23:41:15,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:15,505][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 1.9421217441558838, acc: 0.5135135054588318)
[2024-12-14 23:41:15,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:16,006][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 1.3732178211212158, acc: 0.6034482717514038)
[2024-12-14 23:41:16,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:16,435][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.839320182800293, acc: 0.7727272510528564)
[2024-12-14 23:41:16,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:16,852][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.9860436916351318, acc: 0.6818181872367859)
[2024-12-14 23:41:16,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:17,254][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.6946583390235901, acc: 0.78125)
[2024-12-14 23:41:17,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:17,618][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 1.0608102083206177, acc: 0.7333333492279053)
[2024-12-14 23:41:17,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:18,062][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 1.553459644317627, acc: 0.4833333194255829)
[2024-12-14 23:41:18,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:18,508][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.9621570706367493, acc: 0.78125)
[2024-12-14 23:41:18,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:18,895][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.7915096879005432, acc: 0.7666666507720947)
[2024-12-14 23:41:19,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:19,279][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 1.1875745058059692, acc: 0.7586206793785095)
[2024-12-14 23:41:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:19,687][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 1.0763823986053467, acc: 0.6800000071525574)
[2024-12-14 23:41:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:21,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:21,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:22,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:22,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:23,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:23,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:24,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:24,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:25,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:26,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:26,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:27,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:27,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:27,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:28,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:28,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:29,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:29,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:30,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:30,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:30,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:31,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:31,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:31,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:32,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:32,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:32,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:33,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:33,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:34,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:34,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:34,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:35,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:35,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:36,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:37,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:37,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:37,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:38,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:38,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:39,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:39,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:39,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:40,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:41,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:41,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:42,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:42,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:42,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:43,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:43,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:44,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:44,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:45,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:45,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:45,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:46,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:46,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:47,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:47,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:47,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:48,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:48,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:48,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:49,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:50,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:50,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:50,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:51,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:51,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:51,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:52,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:52,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:53,102][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.7871, device='cuda:0') eval_epoch_loss=tensor(1.9150, device='cuda:0') eval_epoch_acc=tensor(0.5304, device='cuda:0')
[2024-12-14 23:41:53,103][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:41:53,103][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:41:53,845][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_5_step_278_loss_1.9150272607803345/model.pt
[2024-12-14 23:41:53,855][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:41:53,857][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.5304281711578369
[2024-12-14 23:41:54,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:54,333][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 1.4958158731460571, acc: 0.5531914830207825)
[2024-12-14 23:41:54,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:54,764][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 1.4317059516906738, acc: 0.6458333134651184)
[2024-12-14 23:41:54,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:55,181][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 1.4212596416473389, acc: 0.6363636255264282)
[2024-12-14 23:41:55,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:55,701][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 1.7438721656799316, acc: 0.5662650465965271)
[2024-12-14 23:41:55,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:56,116][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 1.792195439338684, acc: 0.5092592835426331)
[2024-12-14 23:41:56,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:56,596][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 1.194616675376892, acc: 0.6578947305679321)
[2024-12-14 23:41:56,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:56,975][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 1.2342705726623535, acc: 0.6764705777168274)
[2024-12-14 23:41:57,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:57,356][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.917873203754425, acc: 0.699999988079071)
[2024-12-14 23:41:57,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:57,750][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 1.9194672107696533, acc: 0.46875)
[2024-12-14 23:41:57,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:58,147][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 1.8859986066818237, acc: 0.4480000138282776)
[2024-12-14 23:41:58,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:58,552][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 1.4508947134017944, acc: 0.593406617641449)
[2024-12-14 23:41:58,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:58,924][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 1.996171474456787, acc: 0.44720497727394104)
[2024-12-14 23:41:59,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:59,329][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 2.1899659633636475, acc: 0.41237112879753113)
[2024-12-14 23:41:59,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:41:59,697][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.666156530380249, acc: 0.7272727489471436)
[2024-12-14 23:41:59,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:00,068][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 1.3352605104446411, acc: 0.5714285969734192)
[2024-12-14 23:42:00,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:00,491][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 1.193339467048645, acc: 0.6724137663841248)
[2024-12-14 23:42:00,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:01,006][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 1.044541835784912, acc: 0.7090908885002136)
[2024-12-14 23:42:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:01,602][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 1.6347873210906982, acc: 0.5773195624351501)
[2024-12-14 23:42:01,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:02,045][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 1.479424238204956, acc: 0.5517241358757019)
[2024-12-14 23:42:02,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:02,428][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 1.1495945453643799, acc: 0.7037037014961243)
[2024-12-14 23:42:02,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:02,862][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 1.340031623840332, acc: 0.6315789222717285)
[2024-12-14 23:42:02,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:03,264][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.9915546774864197, acc: 0.7142857313156128)
[2024-12-14 23:42:03,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:03,627][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.9228253364562988, acc: 0.71875)
[2024-12-14 23:42:03,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:04,012][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 1.1870701313018799, acc: 0.698113203048706)
[2024-12-14 23:42:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:04,386][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.8353831171989441, acc: 0.7924528121948242)
[2024-12-14 23:42:04,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:04,752][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.9494696259498596, acc: 0.7647058963775635)
[2024-12-14 23:42:04,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:05,121][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 1.4264143705368042, acc: 0.65625)
[2024-12-14 23:42:05,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:05,575][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 1.2476379871368408, acc: 0.6721311211585999)
[2024-12-14 23:42:05,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:05,950][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.7359186410903931, acc: 0.800000011920929)
[2024-12-14 23:42:06,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:06,315][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.6106379628181458, acc: 0.7894737124443054)
[2024-12-14 23:42:06,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:06,707][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 1.5951855182647705, acc: 0.5507246255874634)
[2024-12-14 23:42:06,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:07,171][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 1.413221836090088, acc: 0.5416666865348816)
[2024-12-14 23:42:07,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:07,571][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 1.3027642965316772, acc: 0.6385542154312134)
[2024-12-14 23:42:07,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:07,949][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 1.743273377418518, acc: 0.5)
[2024-12-14 23:42:08,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:08,399][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 2.0403921604156494, acc: 0.44897958636283875)
[2024-12-14 23:42:08,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:08,757][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.3375606834888458, acc: 0.9166666865348816)
[2024-12-14 23:42:08,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:09,104][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.77866131067276, acc: 0.75)
[2024-12-14 23:42:09,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:09,471][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.8013128638267517, acc: 0.7096773982048035)
[2024-12-14 23:42:09,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:09,832][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.9495639204978943, acc: 0.7096773982048035)
[2024-12-14 23:42:09,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:10,210][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 1.1705259084701538, acc: 0.6567164063453674)
[2024-12-14 23:42:10,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:10,611][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 1.2882742881774902, acc: 0.625)
[2024-12-14 23:42:10,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:10,976][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 1.3477966785430908, acc: 0.644444465637207)
[2024-12-14 23:42:11,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:11,339][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 1.2838400602340698, acc: 0.5967742204666138)
[2024-12-14 23:42:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:11,684][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.823503851890564, acc: 0.7599999904632568)
[2024-12-14 23:42:11,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:12,031][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 1.6323480606079102, acc: 0.48148149251937866)
[2024-12-14 23:42:12,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:12,373][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 1.6692140102386475, acc: 0.48571428656578064)
[2024-12-14 23:42:12,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:12,722][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 1.3704848289489746, acc: 0.5641025900840759)
[2024-12-14 23:42:12,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:13,088][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.6195399761199951, acc: 0.5365853905677795)
[2024-12-14 23:42:13,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:13,491][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 1.34348464012146, acc: 0.6315789222717285)
[2024-12-14 23:42:13,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:13,843][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.7718361616134644, acc: 0.7368420958518982)
[2024-12-14 23:42:13,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:14,298][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.5520477294921875, acc: 0.7857142686843872)
[2024-12-14 23:42:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:14,697][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 1.3179141283035278, acc: 0.5555555820465088)
[2024-12-14 23:42:14,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:15,084][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.6988152861595154, acc: 0.84375)
[2024-12-14 23:42:15,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:15,512][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 1.2267957925796509, acc: 0.6612903475761414)
[2024-12-14 23:42:15,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:15,948][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 1.2406833171844482, acc: 0.5789473652839661)
[2024-12-14 23:42:16,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:16,357][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 1.4126166105270386, acc: 0.625)
[2024-12-14 23:42:16,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:16,768][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.9607329964637756, acc: 0.7333333492279053)
[2024-12-14 23:42:16,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:17,116][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.8400722146034241, acc: 0.7368420958518982)
[2024-12-14 23:42:17,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:17,509][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 1.694442868232727, acc: 0.5199999809265137)
[2024-12-14 23:42:17,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:17,904][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 2.3514885902404785, acc: 0.4137931168079376)
[2024-12-14 23:42:18,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:18,313][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 2.1854753494262695, acc: 0.38297873735427856)
[2024-12-14 23:42:18,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:18,728][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 2.1463708877563477, acc: 0.40963855385780334)
[2024-12-14 23:42:18,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:19,140][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 1.0238673686981201, acc: 0.695652186870575)
[2024-12-14 23:42:19,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:19,562][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 1.279895305633545, acc: 0.5897436141967773)
[2024-12-14 23:42:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:19,942][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 2.1005141735076904, acc: 0.45783132314682007)
[2024-12-14 23:42:20,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:20,303][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 1.581131935119629, acc: 0.5660377144813538)
[2024-12-14 23:42:20,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:20,654][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 1.6945762634277344, acc: 0.5822784900665283)
[2024-12-14 23:42:20,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:21,091][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 1.4577500820159912, acc: 0.6078431606292725)
[2024-12-14 23:42:21,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:21,462][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 2.110586643218994, acc: 0.4029850661754608)
[2024-12-14 23:42:21,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:21,798][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.7833384871482849, acc: 0.800000011920929)
[2024-12-14 23:42:21,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:22,165][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 1.1456738710403442, acc: 0.5600000023841858)
[2024-12-14 23:42:22,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:22,611][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 1.2179372310638428, acc: 0.75)
[2024-12-14 23:42:22,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:23,010][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 1.6305007934570312, acc: 0.5581395626068115)
[2024-12-14 23:42:23,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:23,387][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 1.4483187198638916, acc: 0.6153846383094788)
[2024-12-14 23:42:23,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:23,817][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 1.4040402173995972, acc: 0.644444465637207)
[2024-12-14 23:42:23,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:24,191][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.774884819984436, acc: 0.6521739363670349)
[2024-12-14 23:42:24,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:24,563][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 1.0892552137374878, acc: 0.692307710647583)
[2024-12-14 23:42:24,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:24,976][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 2.0105834007263184, acc: 0.4285714328289032)
[2024-12-14 23:42:25,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:25,509][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 1.6922361850738525, acc: 0.5565217137336731)
[2024-12-14 23:42:25,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:25,884][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 1.5897458791732788, acc: 0.5652173757553101)
[2024-12-14 23:42:25,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:26,278][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 1.5427803993225098, acc: 0.5918367505073547)
[2024-12-14 23:42:26,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:26,617][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.311030775308609, acc: 0.875)
[2024-12-14 23:42:26,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:26,956][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.6170774698257446, acc: 0.7307692170143127)
[2024-12-14 23:42:27,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:27,304][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.8844957947731018, acc: 0.7317073345184326)
[2024-12-14 23:42:27,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:27,673][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.9734023213386536, acc: 0.6888889074325562)
[2024-12-14 23:42:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:28,042][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 1.4060239791870117, acc: 0.5921052694320679)
[2024-12-14 23:42:28,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:28,470][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 1.3868181705474854, acc: 0.6341463327407837)
[2024-12-14 23:42:28,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:28,869][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 1.2757573127746582, acc: 0.6666666865348816)
[2024-12-14 23:42:28,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:29,263][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.5963428616523743, acc: 0.8333333134651184)
[2024-12-14 23:42:29,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:29,665][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.46580058336257935, acc: 0.8695651888847351)
[2024-12-14 23:42:29,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:30,047][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.7961832880973816, acc: 0.8214285969734192)
[2024-12-14 23:42:30,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:30,396][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.8355900645256042, acc: 0.65625)
[2024-12-14 23:42:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:31,018][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 1.62564218044281, acc: 0.5454545617103577)
[2024-12-14 23:42:31,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:31,903][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 1.1631369590759277, acc: 0.7169811129570007)
[2024-12-14 23:42:32,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:32,295][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 1.3625929355621338, acc: 0.6555555462837219)
[2024-12-14 23:42:32,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:32,681][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 1.274003028869629, acc: 0.6607142686843872)
[2024-12-14 23:42:32,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:33,108][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.785894513130188, acc: 0.7714285850524902)
[2024-12-14 23:42:33,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:33,459][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.40100088715553284, acc: 0.9200000166893005)
[2024-12-14 23:42:33,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:33,868][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.6204667687416077, acc: 0.8260869383811951)
[2024-12-14 23:42:33,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:34,266][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 1.4923042058944702, acc: 0.6666666865348816)
[2024-12-14 23:42:34,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:34,639][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 1.3333468437194824, acc: 0.6526315808296204)
[2024-12-14 23:42:34,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:35,244][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 1.4631502628326416, acc: 0.6227545142173767)
[2024-12-14 23:42:35,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:35,669][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 1.3063912391662598, acc: 0.61654132604599)
[2024-12-14 23:42:36,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:37,018][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 1.5061155557632446, acc: 0.5721924901008606)
[2024-12-14 23:42:37,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:37,636][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 1.2258315086364746, acc: 0.6396396160125732)
[2024-12-14 23:42:37,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:38,079][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.8163906335830688, acc: 0.75)
[2024-12-14 23:42:38,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:38,475][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.6714966893196106, acc: 0.8214285969734192)
[2024-12-14 23:42:38,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:38,832][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 1.1673083305358887, acc: 0.6875)
[2024-12-14 23:42:38,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:39,174][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.8431231379508972, acc: 0.75)
[2024-12-14 23:42:39,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:39,534][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.815414309501648, acc: 0.7894737124443054)
[2024-12-14 23:42:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:39,920][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.5898938775062561, acc: 0.7727272510528564)
[2024-12-14 23:42:40,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:40,349][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.9827693104743958, acc: 0.5)
[2024-12-14 23:42:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:40,725][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.7634099125862122, acc: 0.7142857313156128)
[2024-12-14 23:42:40,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:41,146][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 1.9831937551498413, acc: 0.5)
[2024-12-14 23:42:41,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:41,578][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 2.171729326248169, acc: 0.4563106894493103)
[2024-12-14 23:42:41,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:42,149][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 1.8848185539245605, acc: 0.5441176295280457)
[2024-12-14 23:42:42,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:42,590][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 2.132486581802368, acc: 0.46666666865348816)
[2024-12-14 23:42:42,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:43,050][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 2.121807098388672, acc: 0.4444444477558136)
[2024-12-14 23:42:43,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:43,441][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 1.6785343885421753, acc: 0.6279069781303406)
[2024-12-14 23:42:43,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:43,793][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.9813157916069031, acc: 0.7083333134651184)
[2024-12-14 23:42:43,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:44,171][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 1.2008792161941528, acc: 0.604651153087616)
[2024-12-14 23:42:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:44,608][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 1.2395671606063843, acc: 0.6800000071525574)
[2024-12-14 23:42:44,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:45,184][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 1.485658049583435, acc: 0.5735294222831726)
[2024-12-14 23:42:45,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:45,592][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 1.4386653900146484, acc: 0.5866666436195374)
[2024-12-14 23:42:45,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:46,016][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 1.0944713354110718, acc: 0.6363636255264282)
[2024-12-14 23:42:46,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:46,441][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 1.0605708360671997, acc: 0.7878788113594055)
[2024-12-14 23:42:46,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:46,835][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.769349992275238, acc: 0.7419354915618896)
[2024-12-14 23:42:46,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:47,200][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.8177822828292847, acc: 0.7407407164573669)
[2024-12-14 23:42:47,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:47,563][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.5876990556716919, acc: 0.8399999737739563)
[2024-12-14 23:42:47,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:48,017][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.7791824340820312, acc: 0.7222222089767456)
[2024-12-14 23:42:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:48,393][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.8357017040252686, acc: 0.7777777910232544)
[2024-12-14 23:42:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:48,749][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.6729497909545898, acc: 0.7692307829856873)
[2024-12-14 23:42:48,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:49,113][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 1.0857256650924683, acc: 0.7068965435028076)
[2024-12-14 23:42:49,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:49,475][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.6291425824165344, acc: 0.7857142686843872)
[2024-12-14 23:42:49,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:49,865][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.5728379487991333, acc: 0.8333333134651184)
[2024-12-14 23:42:49,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:50,209][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.9993290901184082, acc: 0.6363636255264282)
[2024-12-14 23:42:50,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:50,640][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.7424421906471252, acc: 0.7272727489471436)
[2024-12-14 23:42:50,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:51,028][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 1.8716038465499878, acc: 0.529411792755127)
[2024-12-14 23:42:51,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:51,415][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 1.6663838624954224, acc: 0.5769230723381042)
[2024-12-14 23:42:51,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:51,802][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 1.6235971450805664, acc: 0.5555555820465088)
[2024-12-14 23:42:51,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:52,278][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 1.5817158222198486, acc: 0.6000000238418579)
[2024-12-14 23:42:52,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:52,695][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 1.4480772018432617, acc: 0.550000011920929)
[2024-12-14 23:42:52,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:53,091][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.523274302482605, acc: 0.8571428656578064)
[2024-12-14 23:42:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:54,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:55,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:55,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:55,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:56,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:56,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:56,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:57,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:57,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:58,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:58,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:58,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:42:59,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:00,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:01,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:01,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:02,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:02,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:03,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:03,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:03,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:03,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:04,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:04,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:05,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:05,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:06,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:06,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:06,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:07,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:07,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:07,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:08,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:08,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:09,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:09,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:10,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:10,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:10,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:11,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:11,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:11,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:12,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:12,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:12,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:13,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:13,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:13,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:14,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:14,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:14,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:15,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:15,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:15,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:16,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:17,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:18,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:18,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:18,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:18,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:19,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:19,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:20,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:21,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:21,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:21,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:22,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:22,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:22,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:23,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:23,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:23,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:24,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:24,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:25,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:25,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:26,339][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.5557, device='cuda:0') eval_epoch_loss=tensor(2.1466, device='cuda:0') eval_epoch_acc=tensor(0.5048, device='cuda:0')
[2024-12-14 23:43:26,340][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:43:26,340][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:43:27,025][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_5_step_421_loss_2.1465957164764404/model.pt
[2024-12-14 23:43:27,032][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:43:27,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:27,470][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.7757847905158997, acc: 0.7666666507720947)
[2024-12-14 23:43:27,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:27,806][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.8162208795547485, acc: 0.75)
[2024-12-14 23:43:27,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:28,190][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.8840190172195435, acc: 0.7222222089767456)
[2024-12-14 23:43:28,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:28,566][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.7006129622459412, acc: 0.7777777910232544)
[2024-12-14 23:43:28,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:28,946][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.8584133386611938, acc: 0.7575757503509521)
[2024-12-14 23:43:29,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:29,316][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 1.8043322563171387, acc: 0.6521739363670349)
[2024-12-14 23:43:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:29,795][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 1.2031511068344116, acc: 0.6216216087341309)
[2024-12-14 23:43:29,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:30,203][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 1.1342954635620117, acc: 0.6666666865348816)
[2024-12-14 23:43:30,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:30,624][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 1.1014797687530518, acc: 0.6521739363670349)
[2024-12-14 23:43:30,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:30,994][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.5830314755439758, acc: 0.8518518805503845)
[2024-12-14 23:43:31,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:31,404][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.5534654259681702, acc: 0.7407407164573669)
[2024-12-14 23:43:31,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:31,786][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.8778170943260193, acc: 0.739130437374115)
[2024-12-14 23:43:31,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:32,179][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 1.0210762023925781, acc: 0.6944444179534912)
[2024-12-14 23:43:32,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:32,532][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.7103228569030762, acc: 0.800000011920929)
[2024-12-14 23:43:32,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:32,932][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.8861558437347412, acc: 0.6969696879386902)
[2024-12-14 23:43:33,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:33,313][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 1.2458125352859497, acc: 0.6388888955116272)
[2024-12-14 23:43:33,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:33,668][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 1.1414088010787964, acc: 0.7272727489471436)
[2024-12-14 23:43:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:34,081][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.6485470533370972, acc: 0.7142857313156128)
[2024-12-14 23:43:34,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:34,471][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 1.4685863256454468, acc: 0.5897436141967773)
[2024-12-14 23:43:34,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:34,977][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 1.7918263673782349, acc: 0.5303030014038086)
[2024-12-14 23:43:35,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:35,720][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 2.2127671241760254, acc: 0.42399999499320984)
[2024-12-14 23:43:35,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:36,161][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 2.0420656204223633, acc: 0.47580644488334656)
[2024-12-14 23:43:36,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:36,833][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 1.9677891731262207, acc: 0.4776119291782379)
[2024-12-14 23:43:36,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:37,198][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 1.5771888494491577, acc: 0.5849056839942932)
[2024-12-14 23:43:37,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:37,665][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.9728109836578369, acc: 0.75)
[2024-12-14 23:43:37,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:38,065][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 1.1206775903701782, acc: 0.6521739363670349)
[2024-12-14 23:43:38,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:38,420][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 1.0779755115509033, acc: 0.6538461446762085)
[2024-12-14 23:43:38,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:38,784][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.9952877163887024, acc: 0.7142857313156128)
[2024-12-14 23:43:38,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:39,153][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 1.3968929052352905, acc: 0.6268656849861145)
[2024-12-14 23:43:39,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:39,588][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 1.3219046592712402, acc: 0.625)
[2024-12-14 23:43:39,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:40,048][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 1.4333134889602661, acc: 0.5760869383811951)
[2024-12-14 23:43:40,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:40,419][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 1.4997639656066895, acc: 0.5769230723381042)
[2024-12-14 23:43:40,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:40,768][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 1.522655725479126, acc: 0.5789473652839661)
[2024-12-14 23:43:40,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:41,134][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 1.5529346466064453, acc: 0.5714285969734192)
[2024-12-14 23:43:41,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:41,501][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.8066022992134094, acc: 0.7878788113594055)
[2024-12-14 23:43:41,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:41,874][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 1.8436334133148193, acc: 0.49484536051750183)
[2024-12-14 23:43:42,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:42,296][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 1.2516595125198364, acc: 0.6714285612106323)
[2024-12-14 23:43:42,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:42,713][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 1.699995756149292, acc: 0.5348837375640869)
[2024-12-14 23:43:42,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:43,118][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 1.4518566131591797, acc: 0.6071428656578064)
[2024-12-14 23:43:43,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:43,503][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 1.6426864862442017, acc: 0.5308641791343689)
[2024-12-14 23:43:43,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:43,871][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 1.3239556550979614, acc: 0.6111111044883728)
[2024-12-14 23:43:44,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:44,315][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.7895414233207703, acc: 0.78125)
[2024-12-14 23:43:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:44,690][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.8848041296005249, acc: 0.6538461446762085)
[2024-12-14 23:43:44,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:45,071][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 1.0008341073989868, acc: 0.760869562625885)
[2024-12-14 23:43:45,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:45,478][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 1.4642057418823242, acc: 0.5595238208770752)
[2024-12-14 23:43:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:45,860][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 1.5887272357940674, acc: 0.5180723071098328)
[2024-12-14 23:43:45,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:46,234][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 1.31813645362854, acc: 0.5855855941772461)
[2024-12-14 23:43:46,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:46,668][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 1.477638602256775, acc: 0.6019417643547058)
[2024-12-14 23:43:46,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:47,067][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 1.2705271244049072, acc: 0.6341463327407837)
[2024-12-14 23:43:47,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:47,440][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.9861034750938416, acc: 0.7083333134651184)
[2024-12-14 23:43:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:47,816][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 1.2318776845932007, acc: 0.6785714030265808)
[2024-12-14 23:43:47,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:48,257][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 1.8150681257247925, acc: 0.5196078419685364)
[2024-12-14 23:43:48,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:48,642][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 1.9850436449050903, acc: 0.46724891662597656)
[2024-12-14 23:43:48,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:48,987][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 1.6810507774353027, acc: 0.5520833134651184)
[2024-12-14 23:43:49,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:49,354][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 1.9461544752120972, acc: 0.44785276055336)
[2024-12-14 23:43:49,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:49,712][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 1.8676567077636719, acc: 0.48201438784599304)
[2024-12-14 23:43:49,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:50,107][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 2.023486614227295, acc: 0.4422110617160797)
[2024-12-14 23:43:50,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:50,484][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.9953291416168213, acc: 0.6666666865348816)
[2024-12-14 23:43:50,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:50,855][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.8596563339233398, acc: 0.7575757503509521)
[2024-12-14 23:43:50,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:51,220][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.7337658405303955, acc: 0.7037037014961243)
[2024-12-14 23:43:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:51,581][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.8798404932022095, acc: 0.6000000238418579)
[2024-12-14 23:43:51,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:51,923][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.6303393840789795, acc: 0.800000011920929)
[2024-12-14 23:43:52,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:52,330][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 1.2993470430374146, acc: 0.6034482717514038)
[2024-12-14 23:43:52,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:52,670][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.9060075283050537, acc: 0.7419354915618896)
[2024-12-14 23:43:52,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:53,028][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.9028280377388, acc: 0.6842105388641357)
[2024-12-14 23:43:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:53,392][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 1.1526174545288086, acc: 0.6296296119689941)
[2024-12-14 23:43:53,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:53,744][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 1.0985313653945923, acc: 0.6190476417541504)
[2024-12-14 23:43:53,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:54,125][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 1.176464319229126, acc: 0.6363636255264282)
[2024-12-14 23:43:54,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:54,514][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 1.7145475149154663, acc: 0.5692307949066162)
[2024-12-14 23:43:54,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:54,857][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 1.1135685443878174, acc: 0.699999988079071)
[2024-12-14 23:43:54,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:55,204][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 1.29912531375885, acc: 0.5517241358757019)
[2024-12-14 23:43:55,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:55,553][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 1.6132853031158447, acc: 0.529411792755127)
[2024-12-14 23:43:55,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:55,912][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 1.6405049562454224, acc: 0.48275861144065857)
[2024-12-14 23:43:56,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:56,269][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.5936813950538635, acc: 0.8421052694320679)
[2024-12-14 23:43:56,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:56,622][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 1.2111393213272095, acc: 0.5789473652839661)
[2024-12-14 23:43:56,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:57,013][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 1.5199745893478394, acc: 0.6071428656578064)
[2024-12-14 23:43:57,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:57,420][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 1.6436445713043213, acc: 0.5617977380752563)
[2024-12-14 23:43:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:57,799][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 1.9524767398834229, acc: 0.5056179761886597)
[2024-12-14 23:43:57,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:58,190][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 2.2126240730285645, acc: 0.40425533056259155)
[2024-12-14 23:43:58,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:58,568][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 2.1356067657470703, acc: 0.42391303181648254)
[2024-12-14 23:43:58,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:58,910][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.6774206757545471, acc: 0.800000011920929)
[2024-12-14 23:43:59,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:59,314][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.6650266647338867, acc: 0.807692289352417)
[2024-12-14 23:43:59,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:43:59,672][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.7702777981758118, acc: 0.7777777910232544)
[2024-12-14 23:43:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:00,021][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 1.5948463678359985, acc: 0.48148149251937866)
[2024-12-14 23:44:00,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:00,353][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 1.0837215185165405, acc: 0.6792452931404114)
[2024-12-14 23:44:00,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:00,686][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 0.8531433343887329, acc: 0.7241379022598267)
[2024-12-14 23:44:00,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:01,297][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 1.7089402675628662, acc: 0.5135135054588318)
[2024-12-14 23:44:01,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:01,771][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 1.34695565700531, acc: 0.6478873491287231)
[2024-12-14 23:44:01,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:02,107][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.5654769539833069, acc: 0.8500000238418579)
[2024-12-14 23:44:02,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:02,466][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.6776041388511658, acc: 0.800000011920929)
[2024-12-14 23:44:02,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:02,815][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.8626362681388855, acc: 0.7307692170143127)
[2024-12-14 23:44:04,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:05,430][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.820773720741272, acc: 0.5142857432365417)
[2024-12-14 23:44:05,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:06,224][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 1.6476210355758667, acc: 0.5555555820465088)
[2024-12-14 23:44:06,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:06,691][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.996418833732605, acc: 0.7142857313156128)
[2024-12-14 23:44:06,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:07,088][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 1.38754141330719, acc: 0.6166666746139526)
[2024-12-14 23:44:07,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:07,814][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 1.3173397779464722, acc: 0.625)
[2024-12-14 23:44:07,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:08,193][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.5405611395835876, acc: 0.807692289352417)
[2024-12-14 23:44:08,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:08,544][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.8416170477867126, acc: 0.774193525314331)
[2024-12-14 23:44:08,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:08,879][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 1.1995315551757812, acc: 0.6499999761581421)
[2024-12-14 23:44:08,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:09,246][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 1.0383610725402832, acc: 0.6666666865348816)
[2024-12-14 23:44:09,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:10,271][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 2.000944137573242, acc: 0.4661017060279846)
[2024-12-14 23:44:10,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:10,669][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 1.8602993488311768, acc: 0.5)
[2024-12-14 23:44:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:11,066][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 1.7806167602539062, acc: 0.5328466892242432)
[2024-12-14 23:44:11,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:11,672][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 1.7058441638946533, acc: 0.5350000262260437)
[2024-12-14 23:44:11,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:12,047][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 1.5344038009643555, acc: 0.5)
[2024-12-14 23:44:12,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:12,412][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 1.3432585000991821, acc: 0.5192307829856873)
[2024-12-14 23:44:12,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:12,804][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 1.3164947032928467, acc: 0.523809552192688)
[2024-12-14 23:44:12,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:13,276][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 1.9764509201049805, acc: 0.4590163826942444)
[2024-12-14 23:44:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:13,652][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 1.4487158060073853, acc: 0.6271186470985413)
[2024-12-14 23:44:13,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:14,067][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 1.5802017450332642, acc: 0.5813953280448914)
[2024-12-14 23:44:14,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:14,447][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 1.2261605262756348, acc: 0.5909090638160706)
[2024-12-14 23:44:14,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:14,799][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 1.5827478170394897, acc: 0.5283018946647644)
[2024-12-14 23:44:14,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:15,220][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 1.0403447151184082, acc: 0.6818181872367859)
[2024-12-14 23:44:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:15,604][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.9985446929931641, acc: 0.6399999856948853)
[2024-12-14 23:44:15,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:15,997][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.765393078327179, acc: 0.75)
[2024-12-14 23:44:16,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:16,332][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.6775174140930176, acc: 0.7727272510528564)
[2024-12-14 23:44:16,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:16,765][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 1.4030605554580688, acc: 0.5538461804389954)
[2024-12-14 23:44:16,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:17,130][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 1.3982027769088745, acc: 0.59375)
[2024-12-14 23:44:17,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:17,553][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.9315220713615417, acc: 0.78125)
[2024-12-14 23:44:17,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:17,900][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.7676445245742798, acc: 0.8181818127632141)
[2024-12-14 23:44:17,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:18,248][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.739591121673584, acc: 0.75)
[2024-12-14 23:44:18,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:18,582][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.609488844871521, acc: 0.8387096524238586)
[2024-12-14 23:44:18,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:18,944][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.5369410514831543, acc: 0.782608687877655)
[2024-12-14 23:44:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:19,302][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.8669291734695435, acc: 0.699999988079071)
[2024-12-14 23:44:19,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:19,719][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 1.4054958820343018, acc: 0.5853658318519592)
[2024-12-14 23:44:19,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:20,091][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.892557680606842, acc: 0.7428571581840515)
[2024-12-14 23:44:20,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:20,467][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 1.057763695716858, acc: 0.6842105388641357)
[2024-12-14 23:44:20,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:20,820][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.826530933380127, acc: 0.8064516186714172)
[2024-12-14 23:44:20,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:21,160][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.6627944707870483, acc: 0.8399999737739563)
[2024-12-14 23:44:21,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:21,538][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.6153451204299927, acc: 0.8181818127632141)
[2024-12-14 23:44:21,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:21,950][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.9108588099479675, acc: 0.699999988079071)
[2024-12-14 23:44:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:22,333][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 1.1697115898132324, acc: 0.6285714507102966)
[2024-12-14 23:44:22,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:22,688][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 2.0450518131256104, acc: 0.45255473256111145)
[2024-12-14 23:44:22,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:23,048][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 1.431960940361023, acc: 0.6206896305084229)
[2024-12-14 23:44:23,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:23,495][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 2.0588555335998535, acc: 0.4571428596973419)
[2024-12-14 23:44:23,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:23,916][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 1.933160662651062, acc: 0.4039735198020935)
[2024-12-14 23:44:24,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:24,291][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 1.4754688739776611, acc: 0.6153846383094788)
[2024-12-14 23:44:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:24,634][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.5067212581634521, acc: 0.8799999952316284)
[2024-12-14 23:44:24,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:24,984][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.8478466272354126, acc: 0.7692307829856873)
[2024-12-14 23:44:25,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:25,323][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.5169417262077332, acc: 0.807692289352417)
[2024-12-14 23:44:25,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:25,675][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 1.2072690725326538, acc: 0.6410256624221802)
[2024-12-14 23:44:25,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:26,037][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 1.3575074672698975, acc: 0.5888888835906982)
[2024-12-14 23:44:26,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:26,385][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 1.2173107862472534, acc: 0.649350643157959)
[2024-12-14 23:44:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:27,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:27,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:28,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:28,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:29,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:29,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:30,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:30,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:30,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:31,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:32,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:32,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:32,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:33,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:33,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:34,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:34,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:34,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:35,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:35,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:35,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:36,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:36,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:36,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:37,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:37,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:37,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:38,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:38,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:38,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:39,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:39,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:39,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:40,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:40,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:40,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:41,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:41,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:42,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:42,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:42,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:43,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:43,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:44,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:44,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:44,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:45,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:45,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:45,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:46,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:47,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:47,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:48,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:48,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:48,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:49,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:50,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:50,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:50,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:51,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:51,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:51,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:53,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:53,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:53,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:54,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:54,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:55,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:55,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:55,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:56,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:56,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:56,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:57,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:57,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:58,273][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.9752, device='cuda:0') eval_epoch_loss=tensor(1.9424, device='cuda:0') eval_epoch_acc=tensor(0.5202, device='cuda:0')
[2024-12-14 23:44:58,275][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:44:58,275][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:44:58,937][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_5_step_564_loss_1.9423562288284302/model.pt
[2024-12-14 23:44:58,944][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:44:59,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:59,342][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 1.281924843788147, acc: 0.5833333134651184)
[2024-12-14 23:44:59,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:44:59,720][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 1.0014030933380127, acc: 0.7068965435028076)
[2024-12-14 23:44:59,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:00,159][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 1.3978188037872314, acc: 0.5357142686843872)
[2024-12-14 23:45:00,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:00,594][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 1.1092441082000732, acc: 0.5789473652839661)
[2024-12-14 23:45:00,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:00,959][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.6779845952987671, acc: 0.7777777910232544)
[2024-12-14 23:45:01,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:01,382][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 1.6430869102478027, acc: 0.5614973306655884)
[2024-12-14 23:45:01,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:01,757][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 1.117843747138977, acc: 0.7096773982048035)
[2024-12-14 23:45:01,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:02,128][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 1.3061076402664185, acc: 0.6153846383094788)
[2024-12-14 23:45:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:02,500][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 1.882375955581665, acc: 0.4591836631298065)
[2024-12-14 23:45:02,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:02,876][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 1.8313422203063965, acc: 0.49056604504585266)
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=3.7226, train_epoch_loss=1.3144, epoch time 389.81952061108314s
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 15
[2024-12-14 23:45:03,306][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:45:03,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:04,280][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 1.111006498336792, acc: 0.6296296119689941)
[2024-12-14 23:45:04,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:04,662][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.8225805759429932, acc: 0.7599999904632568)
[2024-12-14 23:45:04,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:05,151][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 1.13300359249115, acc: 0.6216216087341309)
[2024-12-14 23:45:05,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:05,604][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 1.3073095083236694, acc: 0.5526315569877625)
[2024-12-14 23:45:05,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:06,008][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 1.0518440008163452, acc: 0.7027027010917664)
[2024-12-14 23:45:06,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:06,377][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.943586528301239, acc: 0.6785714030265808)
[2024-12-14 23:45:06,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:06,760][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 1.2389384508132935, acc: 0.6734693646430969)
[2024-12-14 23:45:06,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:07,129][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.9324328899383545, acc: 0.699999988079071)
[2024-12-14 23:45:07,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:07,557][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.3920288383960724, acc: 0.8636363744735718)
[2024-12-14 23:45:07,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:07,955][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.5985743403434753, acc: 0.807692289352417)
[2024-12-14 23:45:08,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:08,341][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.8024157881736755, acc: 0.7037037014961243)
[2024-12-14 23:45:08,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:08,726][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 1.0738126039505005, acc: 0.6410256624221802)
[2024-12-14 23:45:08,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:09,115][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.9187812805175781, acc: 0.7272727489471436)
[2024-12-14 23:45:09,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:09,510][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 1.065364122390747, acc: 0.6086956262588501)
[2024-12-14 23:45:09,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:09,895][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 1.473865270614624, acc: 0.5490196347236633)
[2024-12-14 23:45:10,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:10,277][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 1.2210649251937866, acc: 0.5918367505073547)
[2024-12-14 23:45:10,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:10,713][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.5703524947166443, acc: 0.7894737124443054)
[2024-12-14 23:45:10,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:11,099][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.9371379017829895, acc: 0.625)
[2024-12-14 23:45:11,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:11,462][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.9640787839889526, acc: 0.6944444179534912)
[2024-12-14 23:45:11,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:11,827][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 1.0413620471954346, acc: 0.6842105388641357)
[2024-12-14 23:45:11,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:12,194][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.8825337886810303, acc: 0.692307710647583)
[2024-12-14 23:45:12,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:12,560][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.7946527600288391, acc: 0.7931034564971924)
[2024-12-14 23:45:12,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:12,949][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.9760199189186096, acc: 0.6000000238418579)
[2024-12-14 23:45:13,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:13,354][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.8056624531745911, acc: 0.6666666865348816)
[2024-12-14 23:45:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:13,803][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 1.0225125551223755, acc: 0.5625)
[2024-12-14 23:45:13,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:14,280][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 2.247511625289917, acc: 0.3396226465702057)
[2024-12-14 23:45:14,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:14,698][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 2.1448802947998047, acc: 0.4109589159488678)
[2024-12-14 23:45:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:15,968][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 2.1585612297058105, acc: 0.4308300316333771)
[2024-12-14 23:45:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:16,435][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 1.6224368810653687, acc: 0.604651153087616)
[2024-12-14 23:45:16,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:16,833][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 1.6797248125076294, acc: 0.5421686768531799)
[2024-12-14 23:45:16,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:17,221][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 1.7113374471664429, acc: 0.4938271641731262)
[2024-12-14 23:45:17,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:17,622][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 1.086910605430603, acc: 0.6785714030265808)
[2024-12-14 23:45:17,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:18,016][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 1.064473271369934, acc: 0.5925925970077515)
[2024-12-14 23:45:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:18,379][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.783297061920166, acc: 0.782608687877655)
[2024-12-14 23:45:18,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:18,767][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 1.799851417541504, acc: 0.47058823704719543)
[2024-12-14 23:45:18,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:19,143][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 1.3118350505828857, acc: 0.6229507923126221)
[2024-12-14 23:45:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:19,505][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 1.6095764636993408, acc: 0.5079365372657776)
[2024-12-14 23:45:19,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:19,884][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 1.576343297958374, acc: 0.5593220591545105)
[2024-12-14 23:45:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:20,285][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 1.2056742906570435, acc: 0.6091954112052917)
[2024-12-14 23:45:20,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:20,652][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.8952435255050659, acc: 0.7142857313156128)
[2024-12-14 23:45:20,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:21,043][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 1.0373282432556152, acc: 0.5384615659713745)
[2024-12-14 23:45:21,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:21,462][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 1.7294304370880127, acc: 0.5270270109176636)
[2024-12-14 23:45:21,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:21,858][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 1.5979079008102417, acc: 0.4923076927661896)
[2024-12-14 23:45:22,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:22,344][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 1.8055020570755005, acc: 0.5656565427780151)
[2024-12-14 23:45:22,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:22,800][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 1.5049225091934204, acc: 0.5876288414001465)
[2024-12-14 23:45:22,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:23,252][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 1.809605598449707, acc: 0.529411792755127)
[2024-12-14 23:45:23,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:23,616][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.7009276747703552, acc: 0.807692289352417)
[2024-12-14 23:45:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:24,040][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.5739393830299377, acc: 0.8148148059844971)
[2024-12-14 23:45:24,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:24,408][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 1.048730492591858, acc: 0.6428571343421936)
[2024-12-14 23:45:24,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:24,761][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.5885566473007202, acc: 0.8055555820465088)
[2024-12-14 23:45:24,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:25,206][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.9590044021606445, acc: 0.7719298005104065)
[2024-12-14 23:45:25,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:25,614][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 1.115077257156372, acc: 0.6666666865348816)
[2024-12-14 23:45:25,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:26,030][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 1.5613343715667725, acc: 0.5492957830429077)
[2024-12-14 23:45:26,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:26,525][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.9454388618469238, acc: 0.4533333480358124)
[2024-12-14 23:45:26,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:26,909][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.8457328081130981, acc: 0.7567567825317383)
[2024-12-14 23:45:27,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:27,241][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.5338705778121948, acc: 0.8461538553237915)
[2024-12-14 23:45:29,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:30,486][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.7339600324630737, acc: 0.532423198223114)
[2024-12-14 23:45:31,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:31,843][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 2.198646068572998, acc: 0.4422658085823059)
[2024-12-14 23:45:32,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:32,574][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 1.7561386823654175, acc: 0.5454545617103577)
[2024-12-14 23:45:32,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:33,171][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 1.7747318744659424, acc: 0.5588235259056091)
[2024-12-14 23:45:33,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:33,762][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 1.960471749305725, acc: 0.4492753744125366)
[2024-12-14 23:45:33,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:34,214][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 1.4199912548065186, acc: 0.625)
[2024-12-14 23:45:34,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:34,616][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.6775966882705688, acc: 0.7352941036224365)
[2024-12-14 23:45:34,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:35,055][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 1.3502144813537598, acc: 0.6111111044883728)
[2024-12-14 23:45:35,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:35,493][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 1.1988757848739624, acc: 0.65625)
[2024-12-14 23:45:35,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:35,904][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.7273866534233093, acc: 0.7931034564971924)
[2024-12-14 23:45:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:36,308][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 1.6086965799331665, acc: 0.5178571343421936)
[2024-12-14 23:45:36,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:36,686][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 1.6515693664550781, acc: 0.550000011920929)
[2024-12-14 23:45:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:37,090][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.39443787932395935, acc: 0.800000011920929)
[2024-12-14 23:45:37,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:37,469][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.8092838525772095, acc: 0.75)
[2024-12-14 23:45:37,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:37,864][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.9856574535369873, acc: 0.6969696879386902)
[2024-12-14 23:45:37,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:38,241][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 1.748487949371338, acc: 0.5514705777168274)
[2024-12-14 23:45:38,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:38,649][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 1.6648941040039062, acc: 0.5634920597076416)
[2024-12-14 23:45:38,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:39,080][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 2.0323057174682617, acc: 0.4307692348957062)
[2024-12-14 23:45:39,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:39,490][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 1.6003001928329468, acc: 0.581632673740387)
[2024-12-14 23:45:39,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:39,882][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 2.16349720954895, acc: 0.447761207818985)
[2024-12-14 23:45:40,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:40,304][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 2.0820140838623047, acc: 0.47445255517959595)
[2024-12-14 23:45:40,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:40,666][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.4663788080215454, acc: 0.8095238208770752)
[2024-12-14 23:45:40,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:41,077][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.4591493606567383, acc: 0.9166666865348816)
[2024-12-14 23:45:41,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:41,472][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.7800122499465942, acc: 0.7272727489471436)
[2024-12-14 23:45:41,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:41,828][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.5545173287391663, acc: 0.7692307829856873)
[2024-12-14 23:45:41,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:42,196][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 1.3191255331039429, acc: 0.6730769276618958)
[2024-12-14 23:45:42,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:42,582][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 1.4627411365509033, acc: 0.5961538553237915)
[2024-12-14 23:45:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:42,971][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.6895606517791748, acc: 0.78125)
[2024-12-14 23:45:43,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:43,374][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 1.5384161472320557, acc: 0.5362318754196167)
[2024-12-14 23:45:43,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:43,766][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 1.140135407447815, acc: 0.6600000262260437)
[2024-12-14 23:45:43,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:44,126][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 1.070020318031311, acc: 0.739130437374115)
[2024-12-14 23:45:44,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:44,640][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 1.5504056215286255, acc: 0.5600000023841858)
[2024-12-14 23:45:44,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:45,076][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 1.5857725143432617, acc: 0.5242718458175659)
[2024-12-14 23:45:45,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:46,198][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 1.6897202730178833, acc: 0.5582524538040161)
[2024-12-14 23:45:46,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:47,094][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 1.8366342782974243, acc: 0.48924732208251953)
[2024-12-14 23:45:47,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:47,927][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 1.7135807275772095, acc: 0.5775862336158752)
[2024-12-14 23:45:48,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:48,696][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 1.3073581457138062, acc: 0.621052622795105)
[2024-12-14 23:45:49,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:49,726][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 1.885801911354065, acc: 0.42574256658554077)
[2024-12-14 23:45:49,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:50,121][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 1.6383827924728394, acc: 0.5322580933570862)
[2024-12-14 23:45:50,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:50,526][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 1.693984031677246, acc: 0.52173912525177)
[2024-12-14 23:45:50,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:50,911][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 2.0706937313079834, acc: 0.3529411852359772)
[2024-12-14 23:45:51,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:51,318][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 1.99422025680542, acc: 0.36538460850715637)
[2024-12-14 23:45:51,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:51,747][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 2.053245782852173, acc: 0.44525548815727234)
[2024-12-14 23:45:51,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:52,127][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 1.9019142389297485, acc: 0.4776119291782379)
[2024-12-14 23:45:52,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:52,505][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.5221978425979614, acc: 0.8500000238418579)
[2024-12-14 23:45:52,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:52,872][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.7600560784339905, acc: 0.7727272510528564)
[2024-12-14 23:45:53,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:53,277][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.71384197473526, acc: 0.8260869383811951)
[2024-12-14 23:45:53,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:53,641][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.9955196380615234, acc: 0.6590909361839294)
[2024-12-14 23:45:53,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:54,078][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 1.526687502861023, acc: 0.5517241358757019)
[2024-12-14 23:45:54,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:54,451][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.9995102882385254, acc: 0.6511628031730652)
[2024-12-14 23:45:54,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:54,856][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 1.0423500537872314, acc: 0.6800000071525574)
[2024-12-14 23:45:54,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:55,299][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.5501939654350281, acc: 0.8823529481887817)
[2024-12-14 23:45:55,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:55,703][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.40855029225349426, acc: 0.8846153616905212)
[2024-12-14 23:45:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:56,118][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.9231970906257629, acc: 0.7142857313156128)
[2024-12-14 23:45:56,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:56,527][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 1.3282753229141235, acc: 0.6461538672447205)
[2024-12-14 23:45:56,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:56,976][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 1.4675266742706299, acc: 0.5964912176132202)
[2024-12-14 23:45:57,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:57,377][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 1.2320055961608887, acc: 0.6491228342056274)
[2024-12-14 23:45:57,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:57,744][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 1.21157968044281, acc: 0.6410256624221802)
[2024-12-14 23:45:57,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:58,162][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 1.0145609378814697, acc: 0.6938775777816772)
[2024-12-14 23:45:58,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:58,520][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.4955463707447052, acc: 0.9090909361839294)
[2024-12-14 23:45:58,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:58,896][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 1.4870277643203735, acc: 0.5714285969734192)
[2024-12-14 23:45:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:59,253][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 1.6352052688598633, acc: 0.5691056847572327)
[2024-12-14 23:45:59,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:45:59,630][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 1.2283486127853394, acc: 0.6935483813285828)
[2024-12-14 23:45:59,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:00,518][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 1.859011173248291, acc: 0.48288974165916443)
[2024-12-14 23:46:00,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:00,910][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 1.2115001678466797, acc: 0.6399999856948853)
[2024-12-14 23:46:01,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:01,375][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 1.0257214307785034, acc: 0.692307710647583)
[2024-12-14 23:46:01,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:01,739][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.3916443884372711, acc: 0.875)
[2024-12-14 23:46:01,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:02,134][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.9259705543518066, acc: 0.6315789222717285)
[2024-12-14 23:46:02,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:02,557][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 1.7158383131027222, acc: 0.4969325065612793)
[2024-12-14 23:46:02,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:02,975][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.5196350812911987, acc: 0.5902777910232544)
[2024-12-14 23:46:03,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:03,366][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 1.7929726839065552, acc: 0.49166667461395264)
[2024-12-14 23:46:03,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:03,757][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 1.7589235305786133, acc: 0.494047611951828)
[2024-12-14 23:46:03,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:04,145][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 1.6671626567840576, acc: 0.5384615659713745)
[2024-12-14 23:46:04,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:04,602][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 1.571524977684021, acc: 0.5808823704719543)
[2024-12-14 23:46:04,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:04,997][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.8478339910507202, acc: 0.7692307829856873)
[2024-12-14 23:46:05,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:05,380][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.5132020711898804, acc: 0.782608687877655)
[2024-12-14 23:46:05,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:05,786][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.7925752401351929, acc: 0.6875)
[2024-12-14 23:46:06,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:06,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:07,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:08,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:08,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:08,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:09,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:09,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:10,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:10,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:11,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:11,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:11,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:12,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:13,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:13,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:14,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:14,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:15,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:15,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:15,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:16,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:16,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:17,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:17,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:17,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:18,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:18,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:19,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:19,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:19,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:20,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:21,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:21,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:21,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:22,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:22,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:23,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:23,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:23,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:24,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:25,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:25,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:25,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:26,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:26,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:26,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:27,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:27,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:27,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:28,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:28,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:28,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:29,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:29,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:30,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:30,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:31,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:31,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:32,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:32,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:33,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:33,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:33,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:34,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:34,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:35,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:35,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:36,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:36,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:36,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:37,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:37,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:37,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:38,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:38,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:39,443][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(6.8593, device='cuda:0') eval_epoch_loss=tensor(1.9256, device='cuda:0') eval_epoch_acc=tensor(0.5288, device='cuda:0')
[2024-12-14 23:46:39,444][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:46:39,444][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:46:40,215][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_6_step_133_loss_1.9256031513214111/model.pt
[2024-12-14 23:46:40,222][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:46:40,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:40,708][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.7187830209732056, acc: 0.782608687877655)
[2024-12-14 23:46:40,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:41,087][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 1.0121803283691406, acc: 0.6571428775787354)
[2024-12-14 23:46:41,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:41,546][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.6183604001998901, acc: 0.7692307829856873)
[2024-12-14 23:46:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:42,034][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 1.421014666557312, acc: 0.523809552192688)
[2024-12-14 23:46:42,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:42,411][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 1.1514856815338135, acc: 0.6000000238418579)
[2024-12-14 23:46:42,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:42,782][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 1.003023624420166, acc: 0.695652186870575)
[2024-12-14 23:46:42,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:43,144][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.8711568713188171, acc: 0.7142857313156128)
[2024-12-14 23:46:43,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:43,547][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 1.2564888000488281, acc: 0.692307710647583)
[2024-12-14 23:46:43,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:43,921][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 1.2938441038131714, acc: 0.6129032373428345)
[2024-12-14 23:46:44,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:44,307][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 1.445162057876587, acc: 0.5945945978164673)
[2024-12-14 23:46:44,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:44,906][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 1.9844154119491577, acc: 0.4035087823867798)
[2024-12-14 23:46:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:45,319][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 1.5734537839889526, acc: 0.5597015023231506)
[2024-12-14 23:46:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:45,729][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 2.072497844696045, acc: 0.40816327929496765)
[2024-12-14 23:46:45,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:46,226][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 1.8921291828155518, acc: 0.41489362716674805)
[2024-12-14 23:46:46,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:46,526][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 1.591560959815979, acc: 0.5857142806053162)
[2024-12-14 23:46:46,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:46,816][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 1.0671508312225342, acc: 0.6785714030265808)
[2024-12-14 23:46:46,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:47,107][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.8878033757209778, acc: 0.695652186870575)
[2024-12-14 23:46:47,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:47,433][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 1.2351303100585938, acc: 0.6551724076271057)
[2024-12-14 23:46:47,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:47,780][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 1.2137125730514526, acc: 0.695652186870575)
[2024-12-14 23:46:47,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:48,152][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 1.7190662622451782, acc: 0.5254237055778503)
[2024-12-14 23:46:48,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:48,562][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 1.7684391736984253, acc: 0.5438596606254578)
[2024-12-14 23:46:48,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:48,929][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 1.6346980333328247, acc: 0.5405405163764954)
[2024-12-14 23:46:49,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:49,276][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 1.145873785018921, acc: 0.7142857313156128)
[2024-12-14 23:46:49,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:49,612][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.9197303056716919, acc: 0.8260869383811951)
[2024-12-14 23:46:49,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:49,960][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 1.1166200637817383, acc: 0.6842105388641357)
[2024-12-14 23:46:50,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:51,523][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 1.1625614166259766, acc: 0.6891891956329346)
[2024-12-14 23:46:51,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:51,862][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 1.3302284479141235, acc: 0.5925925970077515)
[2024-12-14 23:46:52,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:52,300][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 1.2763087749481201, acc: 0.5930232405662537)
[2024-12-14 23:46:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:52,931][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 1.1057003736495972, acc: 0.6117647290229797)
[2024-12-14 23:46:53,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:53,526][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 1.5092198848724365, acc: 0.6067415475845337)
[2024-12-14 23:46:53,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:53,940][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.8904629349708557, acc: 0.75)
[2024-12-14 23:46:54,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:54,291][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.9383344054222107, acc: 0.6666666865348816)
[2024-12-14 23:46:54,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:54,716][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.8533384799957275, acc: 0.7586206793785095)
[2024-12-14 23:46:54,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:55,106][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.9757210612297058, acc: 0.6734693646430969)
[2024-12-14 23:46:55,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:55,494][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 1.0519418716430664, acc: 0.6399999856948853)
[2024-12-14 23:46:55,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:55,922][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 1.2880237102508545, acc: 0.5833333134651184)
[2024-12-14 23:46:56,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:56,270][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.4657500982284546, acc: 0.5882353186607361)
[2024-12-14 23:46:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:57,352][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 2.097830057144165, acc: 0.465753436088562)
[2024-12-14 23:46:57,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:57,735][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.6677653193473816, acc: 0.7916666865348816)
[2024-12-14 23:46:57,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:58,081][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.6068453192710876, acc: 0.7407407164573669)
[2024-12-14 23:46:58,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:58,507][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.6450898051261902, acc: 0.8571428656578064)
[2024-12-14 23:46:58,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:59,107][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 1.4610648155212402, acc: 0.6283186078071594)
[2024-12-14 23:46:59,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:59,468][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 1.3082135915756226, acc: 0.6666666865348816)
[2024-12-14 23:46:59,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:46:59,854][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 1.3371304273605347, acc: 0.6363636255264282)
[2024-12-14 23:47:00,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:00,786][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 2.0842108726501465, acc: 0.442748099565506)
[2024-12-14 23:47:01,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:01,479][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 1.8357036113739014, acc: 0.4962962865829468)
[2024-12-14 23:47:01,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:01,835][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 1.3678303956985474, acc: 0.5901639461517334)
[2024-12-14 23:47:01,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:02,198][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.6725735664367676, acc: 0.75)
[2024-12-14 23:47:02,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:02,625][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.9565914869308472, acc: 0.6800000071525574)
[2024-12-14 23:47:02,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:02,998][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.7840188145637512, acc: 0.7142857313156128)
[2024-12-14 23:47:03,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:03,369][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 1.5550518035888672, acc: 0.5609756112098694)
[2024-12-14 23:47:03,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:03,792][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 1.9314759969711304, acc: 0.4682779312133789)
[2024-12-14 23:47:03,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:04,193][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 2.0908756256103516, acc: 0.4524495601654053)
[2024-12-14 23:47:04,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:04,708][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 2.160661458969116, acc: 0.4312500059604645)
[2024-12-14 23:47:04,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:05,256][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 2.007676839828491, acc: 0.45028141140937805)
[2024-12-14 23:47:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:05,695][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 1.907045841217041, acc: 0.4626334607601166)
[2024-12-14 23:47:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:06,108][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.9276850819587708, acc: 0.7599999904632568)
[2024-12-14 23:47:06,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:06,706][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 1.9153701066970825, acc: 0.5)
[2024-12-14 23:47:07,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:07,538][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 1.6857737302780151, acc: 0.579365074634552)
[2024-12-14 23:47:07,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:08,494][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 1.769619107246399, acc: 0.5151515007019043)
[2024-12-14 23:47:08,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:09,258][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 1.4448552131652832, acc: 0.6352941393852234)
[2024-12-14 23:47:09,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:10,380][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 1.4970459938049316, acc: 0.6296296119689941)
[2024-12-14 23:47:10,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:11,364][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 1.1177276372909546, acc: 0.6774193644523621)
[2024-12-14 23:47:11,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:11,728][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.6493478417396545, acc: 0.7857142686843872)
[2024-12-14 23:47:11,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:12,086][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.7707217931747437, acc: 0.7749999761581421)
[2024-12-14 23:47:12,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:12,446][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 1.2848329544067383, acc: 0.6176470518112183)
[2024-12-14 23:47:12,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:12,890][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 1.5071378946304321, acc: 0.5588235259056091)
[2024-12-14 23:47:13,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:13,280][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 1.5758891105651855, acc: 0.5593220591545105)
[2024-12-14 23:47:13,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:13,637][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 1.7509349584579468, acc: 0.5074626803398132)
[2024-12-14 23:47:13,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:14,014][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 1.7593610286712646, acc: 0.4660194218158722)
[2024-12-14 23:47:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:14,365][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 1.2206697463989258, acc: 0.6666666865348816)
[2024-12-14 23:47:14,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:14,723][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 1.4049642086029053, acc: 0.6373626589775085)
[2024-12-14 23:47:14,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:15,105][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 1.8439782857894897, acc: 0.5022421479225159)
[2024-12-14 23:47:15,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:15,535][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 1.914429783821106, acc: 0.4960629940032959)
[2024-12-14 23:47:15,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:15,963][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 1.7309314012527466, acc: 0.5344827771186829)
[2024-12-14 23:47:16,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:16,369][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 1.8675544261932373, acc: 0.489130437374115)
[2024-12-14 23:47:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:16,762][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 1.9451079368591309, acc: 0.43968871235847473)
[2024-12-14 23:47:16,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:17,202][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 1.67351496219635, acc: 0.554347813129425)
[2024-12-14 23:47:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:17,604][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.7879332900047302, acc: 0.782608687877655)
[2024-12-14 23:47:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:18,015][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.9576007723808289, acc: 0.7142857313156128)
[2024-12-14 23:47:18,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:18,404][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.9187831282615662, acc: 0.7446808218955994)
[2024-12-14 23:47:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:19,134][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 1.4155082702636719, acc: 0.5769230723381042)
[2024-12-14 23:47:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:19,490][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 1.1307775974273682, acc: 0.6756756901741028)
[2024-12-14 23:47:19,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:19,970][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 1.1509475708007812, acc: 0.6162790656089783)
[2024-12-14 23:47:20,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:20,549][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 1.3175491094589233, acc: 0.6396396160125732)
[2024-12-14 23:47:20,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:20,979][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 1.2908408641815186, acc: 0.6000000238418579)
[2024-12-14 23:47:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:21,324][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.7588738799095154, acc: 0.7272727489471436)
[2024-12-14 23:47:21,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:21,687][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.4325762391090393, acc: 0.8518518805503845)
[2024-12-14 23:47:21,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:22,067][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.6176515817642212, acc: 0.800000011920929)
[2024-12-14 23:47:22,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:22,456][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 1.1475201845169067, acc: 0.5961538553237915)
[2024-12-14 23:47:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:23,258][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 1.2145127058029175, acc: 0.635869562625885)
[2024-12-14 23:47:23,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:23,819][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 1.6309020519256592, acc: 0.5340909361839294)
[2024-12-14 23:47:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:24,277][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 1.587415337562561, acc: 0.5)
[2024-12-14 23:47:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:24,651][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 1.0359981060028076, acc: 0.7358490824699402)
[2024-12-14 23:47:24,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:25,037][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 1.1116408109664917, acc: 0.6333333253860474)
[2024-12-14 23:47:25,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:25,405][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.6231921315193176, acc: 0.8139534592628479)
[2024-12-14 23:47:25,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:25,739][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.5977305769920349, acc: 0.7666666507720947)
[2024-12-14 23:47:25,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:26,200][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.8343400955200195, acc: 0.49473685026168823)
[2024-12-14 23:47:26,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:26,579][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.313250184059143, acc: 0.644444465637207)
[2024-12-14 23:47:26,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:27,070][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 1.2179532051086426, acc: 0.6722221970558167)
[2024-12-14 23:47:27,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:27,607][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.5697815418243408, acc: 0.5871559381484985)
[2024-12-14 23:47:27,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:28,121][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.2532519102096558, acc: 0.6461538672447205)
[2024-12-14 23:47:28,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:28,485][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.8715242147445679, acc: 0.6842105388641357)
[2024-12-14 23:47:28,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:28,847][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.759248673915863, acc: 0.8333333134651184)
[2024-12-14 23:47:28,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:29,199][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 1.207592248916626, acc: 0.6363636255264282)
[2024-12-14 23:47:29,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:29,574][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 1.0899125337600708, acc: 0.5185185074806213)
[2024-12-14 23:47:29,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:29,987][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.6503782272338867, acc: 0.7714285850524902)
[2024-12-14 23:47:30,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:30,374][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.9668403267860413, acc: 0.7272727489471436)
[2024-12-14 23:47:30,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:30,728][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 1.0390938520431519, acc: 0.7272727489471436)
[2024-12-14 23:47:30,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:31,336][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 1.5451422929763794, acc: 0.5322580933570862)
[2024-12-14 23:47:31,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:31,903][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 1.1915768384933472, acc: 0.6818181872367859)
[2024-12-14 23:47:32,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:32,273][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.49949246644973755, acc: 0.8571428656578064)
[2024-12-14 23:47:32,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:32,636][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.8233792185783386, acc: 0.7307692170143127)
[2024-12-14 23:47:32,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:33,012][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.6299347281455994, acc: 0.8064516186714172)
[2024-12-14 23:47:33,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:33,388][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.6533135175704956, acc: 0.699999988079071)
[2024-12-14 23:47:33,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:33,871][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.7861897945404053, acc: 0.7837837934494019)
[2024-12-14 23:47:33,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:34,216][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.9833375215530396, acc: 0.6756756901741028)
[2024-12-14 23:47:34,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:34,575][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 1.1120140552520752, acc: 0.6486486196517944)
[2024-12-14 23:47:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:34,954][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 1.1876415014266968, acc: 0.6617646813392639)
[2024-12-14 23:47:35,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:35,388][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.6165556311607361, acc: 0.8292682766914368)
[2024-12-14 23:47:35,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:35,741][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.31254228949546814, acc: 0.9200000166893005)
[2024-12-14 23:47:35,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:36,100][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.4258061945438385, acc: 0.8799999952316284)
[2024-12-14 23:47:36,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:36,486][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.40327751636505127, acc: 0.9032257795333862)
[2024-12-14 23:47:36,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:36,835][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.9851980209350586, acc: 0.6666666865348816)
[2024-12-14 23:47:36,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:37,204][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 1.2717125415802002, acc: 0.6428571343421936)
[2024-12-14 23:47:37,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:37,582][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 1.193984866142273, acc: 0.6315789222717285)
[2024-12-14 23:47:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:38,208][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 1.3949357271194458, acc: 0.5566037893295288)
[2024-12-14 23:47:38,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:38,819][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 1.432823896408081, acc: 0.6333333253860474)
[2024-12-14 23:47:38,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:39,230][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.9174781441688538, acc: 0.7222222089767456)
[2024-12-14 23:47:39,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:39,604][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 1.0499207973480225, acc: 0.6451612710952759)
[2024-12-14 23:47:39,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:39,992][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 1.945404291152954, acc: 0.4533333480358124)
[2024-12-14 23:47:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:40,353][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 1.4941482543945312, acc: 0.5208333134651184)
[2024-12-14 23:47:40,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:41,218][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 2.239917039871216, acc: 0.36000001430511475)
[2024-12-14 23:47:41,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:41,676][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 1.8293898105621338, acc: 0.4606741666793823)
[2024-12-14 23:47:41,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:42,097][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 1.6254733800888062, acc: 0.5135135054588318)
[2024-12-14 23:47:42,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:42,611][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 1.1973986625671387, acc: 0.6551724076271057)
[2024-12-14 23:47:42,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:42,991][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.6998845338821411, acc: 0.7727272510528564)
[2024-12-14 23:47:43,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:43,378][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.8987846374511719, acc: 0.6363636255264282)
[2024-12-14 23:47:43,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:43,758][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.4494687616825104, acc: 0.9375)
[2024-12-14 23:47:43,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:44,108][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.8229420185089111, acc: 0.7666666507720947)
[2024-12-14 23:47:44,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:44,526][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 1.2686736583709717, acc: 0.6166666746139526)
[2024-12-14 23:47:44,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:44,876][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.6758779287338257, acc: 0.8125)
[2024-12-14 23:47:44,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:45,244][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.6578972339630127, acc: 0.7666666507720947)
[2024-12-14 23:47:46,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:46,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:46,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:47,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:47,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:47,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:48,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:48,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:49,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:49,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:50,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:50,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:50,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:51,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:51,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:51,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:52,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:52,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:52,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:53,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:53,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:54,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:54,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:55,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:55,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:55,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:56,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:56,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:56,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:57,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:57,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:57,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:58,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:58,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:59,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:47:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:00,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:00,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:00,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:01,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:01,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:02,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:02,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:03,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:03,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:04,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:04,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:04,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:05,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:05,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:06,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:06,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:07,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:07,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:08,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:09,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:09,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:10,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:10,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:11,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:11,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:11,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:12,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:12,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:13,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:13,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:14,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:14,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:15,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:15,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:15,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:16,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:16,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:17,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:17,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:18,221][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6618, device='cuda:0') eval_epoch_loss=tensor(2.0362, device='cuda:0') eval_epoch_acc=tensor(0.5209, device='cuda:0')
[2024-12-14 23:48:18,222][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:48:18,223][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:48:18,960][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_6_step_276_loss_2.036243438720703/model.pt
[2024-12-14 23:48:18,966][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:48:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:19,388][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 1.0583969354629517, acc: 0.6896551847457886)
[2024-12-14 23:48:19,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:19,770][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.9749545454978943, acc: 0.6399999856948853)
[2024-12-14 23:48:19,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:20,136][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 1.1447631120681763, acc: 0.6595744490623474)
[2024-12-14 23:48:20,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:20,604][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 1.17927086353302, acc: 0.7083333134651184)
[2024-12-14 23:48:20,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:21,009][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 1.1448588371276855, acc: 0.7045454382896423)
[2024-12-14 23:48:21,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:21,461][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 1.568090558052063, acc: 0.5903614163398743)
[2024-12-14 23:48:21,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:21,851][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 1.7188918590545654, acc: 0.5740740895271301)
[2024-12-14 23:48:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:22,206][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.7739508748054504, acc: 0.7631579041481018)
[2024-12-14 23:48:22,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:22,580][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 1.1044793128967285, acc: 0.7058823704719543)
[2024-12-14 23:48:22,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:22,934][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.5041298866271973, acc: 0.7250000238418579)
[2024-12-14 23:48:23,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:23,385][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 1.8340851068496704, acc: 0.5)
[2024-12-14 23:48:23,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:23,805][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 1.9268834590911865, acc: 0.4480000138282776)
[2024-12-14 23:48:23,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:24,202][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 1.4135339260101318, acc: 0.5494505763053894)
[2024-12-14 23:48:24,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:24,646][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 1.9395689964294434, acc: 0.5155279636383057)
[2024-12-14 23:48:24,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:25,082][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 2.0528564453125, acc: 0.39175257086753845)
[2024-12-14 23:48:25,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:25,473][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.6535616517066956, acc: 0.7272727489471436)
[2024-12-14 23:48:25,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:25,843][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 1.1995337009429932, acc: 0.6190476417541504)
[2024-12-14 23:48:25,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:26,333][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 1.05368971824646, acc: 0.7241379022598267)
[2024-12-14 23:48:26,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:26,827][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.8303382992744446, acc: 0.7090908885002136)
[2024-12-14 23:48:27,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:27,398][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 1.5510190725326538, acc: 0.5721649527549744)
[2024-12-14 23:48:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:27,761][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 1.2952775955200195, acc: 0.6206896305084229)
[2024-12-14 23:48:27,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:28,199][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 1.033518671989441, acc: 0.7777777910232544)
[2024-12-14 23:48:28,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:28,606][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 1.1111611127853394, acc: 0.7105262875556946)
[2024-12-14 23:48:28,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:28,988][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.8769863843917847, acc: 0.7857142686843872)
[2024-12-14 23:48:29,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:29,325][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.8853858113288879, acc: 0.78125)
[2024-12-14 23:48:29,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:29,727][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 1.0070922374725342, acc: 0.698113203048706)
[2024-12-14 23:48:29,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:30,186][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.6547935605049133, acc: 0.8113207817077637)
[2024-12-14 23:48:30,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:30,595][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.7354325652122498, acc: 0.7941176295280457)
[2024-12-14 23:48:30,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:30,975][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.6630947589874268, acc: 0.875)
[2024-12-14 23:48:31,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:31,364][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 1.142822265625, acc: 0.6721311211585999)
[2024-12-14 23:48:31,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:31,739][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.483987033367157, acc: 0.8333333134651184)
[2024-12-14 23:48:31,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:32,112][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.4697120189666748, acc: 0.8421052694320679)
[2024-12-14 23:48:32,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:32,473][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 1.4693975448608398, acc: 0.5652173757553101)
[2024-12-14 23:48:32,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:32,920][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 1.3109045028686523, acc: 0.6388888955116272)
[2024-12-14 23:48:33,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:33,302][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 1.190869927406311, acc: 0.6265060305595398)
[2024-12-14 23:48:33,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:33,679][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 1.5707807540893555, acc: 0.5769230723381042)
[2024-12-14 23:48:33,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:34,068][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 1.7259739637374878, acc: 0.5204081535339355)
[2024-12-14 23:48:34,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:34,399][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.2491615265607834, acc: 0.9166666865348816)
[2024-12-14 23:48:34,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:34,738][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.5518352389335632, acc: 0.8333333134651184)
[2024-12-14 23:48:34,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:35,091][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.6849627494812012, acc: 0.7419354915618896)
[2024-12-14 23:48:35,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:35,472][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.7774736285209656, acc: 0.7096773982048035)
[2024-12-14 23:48:35,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:35,880][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 1.1245282888412476, acc: 0.6716417670249939)
[2024-12-14 23:48:36,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:36,274][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 1.2557073831558228, acc: 0.6634615659713745)
[2024-12-14 23:48:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:36,664][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 1.157378077507019, acc: 0.6888889074325562)
[2024-12-14 23:48:36,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:37,039][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 1.079604983329773, acc: 0.6612903475761414)
[2024-12-14 23:48:37,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:37,427][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.7696751952171326, acc: 0.7400000095367432)
[2024-12-14 23:48:37,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:37,862][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 1.6379526853561401, acc: 0.5925925970077515)
[2024-12-14 23:48:37,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:38,244][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 1.3635014295578003, acc: 0.5428571701049805)
[2024-12-14 23:48:38,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:38,590][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 1.1300958395004272, acc: 0.6410256624221802)
[2024-12-14 23:48:38,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:38,928][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 1.4004141092300415, acc: 0.5853658318519592)
[2024-12-14 23:48:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:39,297][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.9561403393745422, acc: 0.7631579041481018)
[2024-12-14 23:48:39,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:39,672][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.978019118309021, acc: 0.6842105388641357)
[2024-12-14 23:48:39,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:40,066][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.5082796216011047, acc: 0.7857142686843872)
[2024-12-14 23:48:40,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:40,519][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 1.3525680303573608, acc: 0.5925925970077515)
[2024-12-14 23:48:40,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:40,902][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.5454506874084473, acc: 0.875)
[2024-12-14 23:48:41,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:41,272][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 1.1488597393035889, acc: 0.7096773982048035)
[2024-12-14 23:48:41,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:41,663][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 1.2466107606887817, acc: 0.6491228342056274)
[2024-12-14 23:48:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:42,025][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 1.2668228149414062, acc: 0.53125)
[2024-12-14 23:48:42,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:42,408][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.8047590255737305, acc: 0.7333333492279053)
[2024-12-14 23:48:42,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:42,761][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.8605934977531433, acc: 0.7368420958518982)
[2024-12-14 23:48:42,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:43,128][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 1.5501126050949097, acc: 0.5)
[2024-12-14 23:48:43,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:43,572][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 2.051309585571289, acc: 0.4137931168079376)
[2024-12-14 23:48:43,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:43,979][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 1.9851138591766357, acc: 0.478723406791687)
[2024-12-14 23:48:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:44,334][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 2.107957124710083, acc: 0.39759036898612976)
[2024-12-14 23:48:44,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:44,689][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.7278666496276855, acc: 0.782608687877655)
[2024-12-14 23:48:44,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:45,049][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.9421592354774475, acc: 0.692307710647583)
[2024-12-14 23:48:45,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:45,428][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 1.9767353534698486, acc: 0.5060241222381592)
[2024-12-14 23:48:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:45,798][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 1.3792989253997803, acc: 0.6792452931404114)
[2024-12-14 23:48:45,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:46,167][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 1.451330542564392, acc: 0.607594907283783)
[2024-12-14 23:48:46,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:46,560][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 1.3785467147827148, acc: 0.6470588445663452)
[2024-12-14 23:48:46,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:46,978][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 2.068779945373535, acc: 0.4029850661754608)
[2024-12-14 23:48:47,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:47,321][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.7246026396751404, acc: 0.800000011920929)
[2024-12-14 23:48:47,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:47,694][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.6902403235435486, acc: 0.800000011920929)
[2024-12-14 23:48:47,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:48,119][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 1.2996426820755005, acc: 0.75)
[2024-12-14 23:48:48,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:48,458][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 1.5856353044509888, acc: 0.4883720874786377)
[2024-12-14 23:48:48,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:48,887][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 1.29698646068573, acc: 0.6666666865348816)
[2024-12-14 23:48:49,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:49,294][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 1.3478182554244995, acc: 0.5777778029441833)
[2024-12-14 23:48:49,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:49,625][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.7067577242851257, acc: 0.739130437374115)
[2024-12-14 23:48:49,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:49,976][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 1.2937357425689697, acc: 0.6153846383094788)
[2024-12-14 23:48:50,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:50,383][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 1.9823356866836548, acc: 0.5054945349693298)
[2024-12-14 23:48:50,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:50,904][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 1.6852558851242065, acc: 0.582608699798584)
[2024-12-14 23:48:51,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:51,282][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 1.4621989727020264, acc: 0.5869565010070801)
[2024-12-14 23:48:51,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:51,650][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 1.5355101823806763, acc: 0.5918367505073547)
[2024-12-14 23:48:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:51,990][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.2756943702697754, acc: 0.9583333134651184)
[2024-12-14 23:48:52,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:52,326][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.656646728515625, acc: 0.7307692170143127)
[2024-12-14 23:48:52,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:52,663][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.7330666780471802, acc: 0.8048780560493469)
[2024-12-14 23:48:52,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:53,033][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.9672421813011169, acc: 0.644444465637207)
[2024-12-14 23:48:53,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:53,407][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 1.2681927680969238, acc: 0.6184210777282715)
[2024-12-14 23:48:53,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:53,768][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 1.2632540464401245, acc: 0.707317054271698)
[2024-12-14 23:48:53,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:54,161][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 1.0653990507125854, acc: 0.6666666865348816)
[2024-12-14 23:48:54,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:54,526][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.6985321640968323, acc: 0.7916666865348816)
[2024-12-14 23:48:54,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:54,881][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.3906579911708832, acc: 0.8695651888847351)
[2024-12-14 23:48:54,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:55,243][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.6141416430473328, acc: 0.7857142686843872)
[2024-12-14 23:48:55,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:55,635][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.9523410797119141, acc: 0.6875)
[2024-12-14 23:48:55,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:56,259][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 1.5793869495391846, acc: 0.581818163394928)
[2024-12-14 23:48:56,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:57,133][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 1.1628466844558716, acc: 0.698113203048706)
[2024-12-14 23:48:57,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:57,535][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 1.1763287782669067, acc: 0.7222222089767456)
[2024-12-14 23:48:57,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:57,912][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 1.0866038799285889, acc: 0.6785714030265808)
[2024-12-14 23:48:58,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:58,286][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.8281665444374084, acc: 0.8285714387893677)
[2024-12-14 23:48:58,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:58,626][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.4278287887573242, acc: 0.8399999737739563)
[2024-12-14 23:48:58,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:58,959][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.5974788069725037, acc: 0.739130437374115)
[2024-12-14 23:48:59,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:59,308][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 1.2692087888717651, acc: 0.625)
[2024-12-14 23:48:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:48:59,676][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 1.317438006401062, acc: 0.621052622795105)
[2024-12-14 23:48:59,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:00,278][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 1.3145129680633545, acc: 0.6347305178642273)
[2024-12-14 23:49:00,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:00,711][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 1.1279288530349731, acc: 0.6616541147232056)
[2024-12-14 23:49:01,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:01,938][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 1.3949090242385864, acc: 0.614973247051239)
[2024-12-14 23:49:02,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:02,539][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 1.1820094585418701, acc: 0.6576576828956604)
[2024-12-14 23:49:02,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:02,899][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.6265254616737366, acc: 0.7857142686843872)
[2024-12-14 23:49:02,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:03,235][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.5490491986274719, acc: 0.8214285969734192)
[2024-12-14 23:49:03,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:03,573][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.770207405090332, acc: 0.75)
[2024-12-14 23:49:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:03,916][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.6906049251556396, acc: 0.7777777910232544)
[2024-12-14 23:49:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:04,254][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.5709044933319092, acc: 0.8421052694320679)
[2024-12-14 23:49:04,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:04,590][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.5231290459632874, acc: 0.8181818127632141)
[2024-12-14 23:49:04,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:04,946][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.8713057637214661, acc: 0.6000000238418579)
[2024-12-14 23:49:05,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:05,410][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.9971820116043091, acc: 0.6666666865348816)
[2024-12-14 23:49:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:05,784][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 1.6138027906417847, acc: 0.5925925970077515)
[2024-12-14 23:49:05,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:06,172][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 1.8688362836837769, acc: 0.553398072719574)
[2024-12-14 23:49:06,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:06,722][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 1.8459317684173584, acc: 0.5441176295280457)
[2024-12-14 23:49:06,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:07,125][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 2.032395839691162, acc: 0.4866666793823242)
[2024-12-14 23:49:07,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:07,539][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 2.0572614669799805, acc: 0.4652777910232544)
[2024-12-14 23:49:07,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:07,891][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 1.4498584270477295, acc: 0.6511628031730652)
[2024-12-14 23:49:07,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:08,268][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.8881155848503113, acc: 0.6666666865348816)
[2024-12-14 23:49:08,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:08,649][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 1.1100468635559082, acc: 0.6976743936538696)
[2024-12-14 23:49:08,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:09,071][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.9938613772392273, acc: 0.6800000071525574)
[2024-12-14 23:49:09,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:09,652][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 1.4598976373672485, acc: 0.5588235259056091)
[2024-12-14 23:49:09,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:10,034][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 1.3987540006637573, acc: 0.6133333444595337)
[2024-12-14 23:49:10,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:10,398][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 1.1561648845672607, acc: 0.6666666865348816)
[2024-12-14 23:49:10,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:10,738][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.861300528049469, acc: 0.8181818127632141)
[2024-12-14 23:49:10,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:11,088][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.5452075600624084, acc: 0.8064516186714172)
[2024-12-14 23:49:11,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:11,435][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.6246350407600403, acc: 0.8518518805503845)
[2024-12-14 23:49:11,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:11,856][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.48967406153678894, acc: 0.8799999952316284)
[2024-12-14 23:49:11,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:12,242][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.7045639753341675, acc: 0.7222222089767456)
[2024-12-14 23:49:12,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:12,618][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.8289473056793213, acc: 0.7037037014961243)
[2024-12-14 23:49:12,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:12,987][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.7430718541145325, acc: 0.7692307829856873)
[2024-12-14 23:49:13,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:13,337][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 1.0590624809265137, acc: 0.7068965435028076)
[2024-12-14 23:49:13,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:13,677][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.5156320929527283, acc: 0.8571428656578064)
[2024-12-14 23:49:13,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:14,027][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.5823295712471008, acc: 0.8333333134651184)
[2024-12-14 23:49:14,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:14,399][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.8037471175193787, acc: 0.7272727489471436)
[2024-12-14 23:49:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:14,768][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.5448789000511169, acc: 0.8636363744735718)
[2024-12-14 23:49:14,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:15,135][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 1.614461064338684, acc: 0.529411792755127)
[2024-12-14 23:49:15,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:15,496][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 1.3054602146148682, acc: 0.692307710647583)
[2024-12-14 23:49:15,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:15,883][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 1.3748928308486938, acc: 0.5555555820465088)
[2024-12-14 23:49:16,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:16,259][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 1.3700947761535645, acc: 0.574999988079071)
[2024-12-14 23:49:17,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:17,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:17,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:18,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:18,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:18,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:18,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:19,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:19,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:20,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:20,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:20,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:21,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:21,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:21,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:23,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:23,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:24,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:24,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:24,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:25,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:25,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:26,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:26,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:26,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:27,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:27,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:28,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:28,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:28,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:29,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:29,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:29,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:30,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:30,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:31,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:31,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:32,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:32,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:32,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:33,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:33,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:33,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:34,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:34,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:34,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:35,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:35,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:36,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:37,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:37,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:38,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:39,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:40,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:40,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:40,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:41,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:41,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:42,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:42,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:43,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:43,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:43,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:44,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:44,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:45,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:45,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:46,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:47,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:47,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:48,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:48,620][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.5677, device='cuda:0') eval_epoch_loss=tensor(2.0239, device='cuda:0') eval_epoch_acc=tensor(0.5186, device='cuda:0')
[2024-12-14 23:49:48,621][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:49:48,622][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:49:49,309][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_6_step_419_loss_2.0238890647888184/model.pt
[2024-12-14 23:49:49,323][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:49:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:49,765][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 1.1202795505523682, acc: 0.6499999761581421)
[2024-12-14 23:49:49,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:50,148][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.41092967987060547, acc: 0.9047619104385376)
[2024-12-14 23:49:50,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:50,516][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.7185317873954773, acc: 0.699999988079071)
[2024-12-14 23:49:50,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:50,876][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.8252995610237122, acc: 0.6875)
[2024-12-14 23:49:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:51,265][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.9945332407951355, acc: 0.6944444179534912)
[2024-12-14 23:49:51,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:51,675][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.7062467932701111, acc: 0.7407407164573669)
[2024-12-14 23:49:51,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:52,119][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.8705484867095947, acc: 0.7575757503509521)
[2024-12-14 23:49:52,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:52,518][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 1.2454569339752197, acc: 0.739130437374115)
[2024-12-14 23:49:52,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:52,903][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 1.1015803813934326, acc: 0.6756756901741028)
[2024-12-14 23:49:53,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:53,258][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.7950721979141235, acc: 0.7037037014961243)
[2024-12-14 23:49:53,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:53,607][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.8636811375617981, acc: 0.695652186870575)
[2024-12-14 23:49:53,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:53,943][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.5827211737632751, acc: 0.8518518805503845)
[2024-12-14 23:49:54,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:54,287][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.43937477469444275, acc: 0.8148148059844971)
[2024-12-14 23:49:54,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:54,641][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.5923824906349182, acc: 0.739130437374115)
[2024-12-14 23:49:54,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:55,015][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.8430235981941223, acc: 0.75)
[2024-12-14 23:49:55,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:55,371][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.6760417222976685, acc: 0.800000011920929)
[2024-12-14 23:49:55,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:55,730][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.8548119068145752, acc: 0.7272727489471436)
[2024-12-14 23:49:55,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:56,144][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 1.156628131866455, acc: 0.6111111044883728)
[2024-12-14 23:49:56,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:56,500][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.9837419390678406, acc: 0.7954545617103577)
[2024-12-14 23:49:56,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:56,841][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.6620069146156311, acc: 0.8095238208770752)
[2024-12-14 23:49:56,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:57,160][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 1.0554450750350952, acc: 0.7435897588729858)
[2024-12-14 23:49:57,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:57,654][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 1.5077502727508545, acc: 0.6212121248245239)
[2024-12-14 23:49:57,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:58,412][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 2.1298410892486572, acc: 0.42399999499320984)
[2024-12-14 23:49:58,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:58,851][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 1.927960991859436, acc: 0.5)
[2024-12-14 23:49:59,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:59,524][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 1.908104419708252, acc: 0.49253731966018677)
[2024-12-14 23:49:59,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:49:59,884][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 1.4540890455245972, acc: 0.6415094137191772)
[2024-12-14 23:50:00,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:00,345][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.8923118710517883, acc: 0.7272727489471436)
[2024-12-14 23:50:00,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:00,740][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 1.0863730907440186, acc: 0.695652186870575)
[2024-12-14 23:50:00,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:01,097][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.9118298888206482, acc: 0.692307710647583)
[2024-12-14 23:50:01,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:01,469][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.7773990631103516, acc: 0.75)
[2024-12-14 23:50:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:01,810][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 1.3323432207107544, acc: 0.6716417670249939)
[2024-12-14 23:50:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:02,207][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 1.2355077266693115, acc: 0.6666666865348816)
[2024-12-14 23:50:02,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:02,577][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 1.348726749420166, acc: 0.6195651888847351)
[2024-12-14 23:50:02,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:02,987][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 1.405976414680481, acc: 0.5512820482254028)
[2024-12-14 23:50:03,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:03,327][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 1.4343003034591675, acc: 0.5526315569877625)
[2024-12-14 23:50:03,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:03,709][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 1.3077658414840698, acc: 0.5918367505073547)
[2024-12-14 23:50:03,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:04,078][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.7022875547409058, acc: 0.8181818127632141)
[2024-12-14 23:50:04,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:04,450][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 1.7771856784820557, acc: 0.49484536051750183)
[2024-12-14 23:50:04,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:04,819][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 1.2235183715820312, acc: 0.6714285612106323)
[2024-12-14 23:50:04,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:05,212][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 1.6457438468933105, acc: 0.5465116500854492)
[2024-12-14 23:50:05,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:05,574][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 1.3530123233795166, acc: 0.5892857313156128)
[2024-12-14 23:50:05,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:05,921][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 1.6097651720046997, acc: 0.5308641791343689)
[2024-12-14 23:50:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:06,269][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 1.1112143993377686, acc: 0.6666666865348816)
[2024-12-14 23:50:06,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:06,658][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.6558228135108948, acc: 0.8125)
[2024-12-14 23:50:06,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:07,111][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 1.063856601715088, acc: 0.5769230723381042)
[2024-12-14 23:50:07,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:07,600][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.5758896470069885, acc: 0.8260869383811951)
[2024-12-14 23:50:07,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:08,079][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 1.1293070316314697, acc: 0.6309523582458496)
[2024-12-14 23:50:08,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:08,477][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 1.2497539520263672, acc: 0.5783132314682007)
[2024-12-14 23:50:08,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:08,903][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 1.225347876548767, acc: 0.6576576828956604)
[2024-12-14 23:50:09,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:09,334][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 1.360566258430481, acc: 0.6116504669189453)
[2024-12-14 23:50:09,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:09,702][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 1.0407692193984985, acc: 0.7235772609710693)
[2024-12-14 23:50:09,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:10,120][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.8829640746116638, acc: 0.7916666865348816)
[2024-12-14 23:50:10,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:10,491][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.9558221101760864, acc: 0.7142857313156128)
[2024-12-14 23:50:10,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:10,930][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 1.719910979270935, acc: 0.4901960790157318)
[2024-12-14 23:50:11,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:11,310][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 1.8580845594406128, acc: 0.5109170079231262)
[2024-12-14 23:50:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:11,686][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 1.5442649126052856, acc: 0.5833333134651184)
[2024-12-14 23:50:11,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:12,076][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 1.8270533084869385, acc: 0.5153374075889587)
[2024-12-14 23:50:12,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:12,426][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 1.7076343297958374, acc: 0.5467625856399536)
[2024-12-14 23:50:12,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:12,810][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 1.9106237888336182, acc: 0.4623115658760071)
[2024-12-14 23:50:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:13,154][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.7441778182983398, acc: 0.6944444179534912)
[2024-12-14 23:50:13,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:13,503][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.7743480801582336, acc: 0.7878788113594055)
[2024-12-14 23:50:13,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:13,851][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.7904887795448303, acc: 0.7037037014961243)
[2024-12-14 23:50:14,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:14,312][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.8120591044425964, acc: 0.6499999761581421)
[2024-12-14 23:50:14,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:14,736][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.6175514459609985, acc: 0.8500000238418579)
[2024-12-14 23:50:14,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:15,152][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 1.03090238571167, acc: 0.6724137663841248)
[2024-12-14 23:50:15,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:15,600][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.6713254451751709, acc: 0.774193525314331)
[2024-12-14 23:50:15,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:15,974][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.6606906056404114, acc: 0.7894737124443054)
[2024-12-14 23:50:16,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:16,371][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 1.0994006395339966, acc: 0.6666666865348816)
[2024-12-14 23:50:16,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:16,728][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.8060514330863953, acc: 0.6190476417541504)
[2024-12-14 23:50:16,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:17,068][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 1.026247501373291, acc: 0.6363636255264282)
[2024-12-14 23:50:17,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:17,434][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 1.4865237474441528, acc: 0.5846154093742371)
[2024-12-14 23:50:17,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:17,767][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.9383859634399414, acc: 0.7666666507720947)
[2024-12-14 23:50:17,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:18,126][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 1.0116853713989258, acc: 0.6896551847457886)
[2024-12-14 23:50:18,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:18,498][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 1.2272545099258423, acc: 0.6274510025978088)
[2024-12-14 23:50:18,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:18,851][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 1.158470869064331, acc: 0.6896551847457886)
[2024-12-14 23:50:18,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:19,208][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.5226514935493469, acc: 0.8421052694320679)
[2024-12-14 23:50:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:19,599][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 1.1092716455459595, acc: 0.5789473652839661)
[2024-12-14 23:50:19,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:20,039][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 1.4629989862442017, acc: 0.5892857313156128)
[2024-12-14 23:50:20,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:20,452][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 1.4609495401382446, acc: 0.5955055952072144)
[2024-12-14 23:50:20,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:20,844][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 1.8424363136291504, acc: 0.5280898809432983)
[2024-12-14 23:50:20,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:21,301][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 2.0194623470306396, acc: 0.44680851697921753)
[2024-12-14 23:50:21,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:21,681][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 1.870505452156067, acc: 0.46739131212234497)
[2024-12-14 23:50:21,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:22,015][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.6867586374282837, acc: 0.7200000286102295)
[2024-12-14 23:50:22,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:22,350][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.6841516494750977, acc: 0.7692307829856873)
[2024-12-14 23:50:22,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:22,723][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.7812062501907349, acc: 0.7777777910232544)
[2024-12-14 23:50:22,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:23,090][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 1.3691468238830566, acc: 0.5185185074806213)
[2024-12-14 23:50:23,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:23,430][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 1.0249682664871216, acc: 0.6792452931404114)
[2024-12-14 23:50:23,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:23,862][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.7130576372146606, acc: 0.7586206793785095)
[2024-12-14 23:50:24,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:24,487][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 1.5381451845169067, acc: 0.5675675868988037)
[2024-12-14 23:50:24,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:24,972][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 1.2992619276046753, acc: 0.6197183132171631)
[2024-12-14 23:50:25,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:25,311][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.4671171307563782, acc: 0.8999999761581421)
[2024-12-14 23:50:25,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:25,674][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.6515843868255615, acc: 0.7666666507720947)
[2024-12-14 23:50:25,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:26,031][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.636898934841156, acc: 0.807692289352417)
[2024-12-14 23:50:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:28,723][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 1.6888186931610107, acc: 0.5071428418159485)
[2024-12-14 23:50:29,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:29,513][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 1.4777036905288696, acc: 0.579365074634552)
[2024-12-14 23:50:29,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:29,857][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.9040955901145935, acc: 0.6785714030265808)
[2024-12-14 23:50:29,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:30,229][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 1.2014235258102417, acc: 0.6499999761581421)
[2024-12-14 23:50:30,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:30,942][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 1.150254487991333, acc: 0.6944444179534912)
[2024-12-14 23:50:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:31,295][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.5139499306678772, acc: 0.807692289352417)
[2024-12-14 23:50:31,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:31,663][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 1.0231794118881226, acc: 0.7096773982048035)
[2024-12-14 23:50:31,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:32,040][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.9906147122383118, acc: 0.699999988079071)
[2024-12-14 23:50:32,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:32,380][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.9163708686828613, acc: 0.6296296119689941)
[2024-12-14 23:50:32,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:33,380][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 1.9287168979644775, acc: 0.47033897042274475)
[2024-12-14 23:50:33,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:33,757][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 1.6924958229064941, acc: 0.5373134613037109)
[2024-12-14 23:50:33,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:34,169][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 1.6291817426681519, acc: 0.540145993232727)
[2024-12-14 23:50:34,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:34,752][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 1.7358660697937012, acc: 0.550000011920929)
[2024-12-14 23:50:34,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:35,124][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 1.4546334743499756, acc: 0.6111111044883728)
[2024-12-14 23:50:35,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:35,566][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 1.1094070672988892, acc: 0.6153846383094788)
[2024-12-14 23:50:35,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:35,996][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 1.1595429182052612, acc: 0.7142857313156128)
[2024-12-14 23:50:36,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:36,393][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 1.657835841178894, acc: 0.5245901346206665)
[2024-12-14 23:50:36,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:36,752][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 1.1580452919006348, acc: 0.6779661178588867)
[2024-12-14 23:50:36,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:37,108][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 1.2978134155273438, acc: 0.6279069781303406)
[2024-12-14 23:50:37,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:37,477][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 1.0256844758987427, acc: 0.6818181872367859)
[2024-12-14 23:50:37,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:37,828][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 1.2945175170898438, acc: 0.6037735939025879)
[2024-12-14 23:50:37,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:38,199][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.895975649356842, acc: 0.7272727489471436)
[2024-12-14 23:50:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:38,565][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.9641157388687134, acc: 0.7200000286102295)
[2024-12-14 23:50:38,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:38,925][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.6127938628196716, acc: 0.800000011920929)
[2024-12-14 23:50:39,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:39,305][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.679161012172699, acc: 0.7727272510528564)
[2024-12-14 23:50:39,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:39,798][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 1.2421218156814575, acc: 0.692307710647583)
[2024-12-14 23:50:39,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:40,173][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 1.0575453042984009, acc: 0.6875)
[2024-12-14 23:50:40,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:40,605][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.8683912754058838, acc: 0.8125)
[2024-12-14 23:50:40,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:40,963][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.8989474177360535, acc: 0.6363636255264282)
[2024-12-14 23:50:41,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:41,307][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.8488342761993408, acc: 0.75)
[2024-12-14 23:50:41,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:41,658][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.445319265127182, acc: 0.9032257795333862)
[2024-12-14 23:50:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:42,023][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.4468485414981842, acc: 0.8695651888847351)
[2024-12-14 23:50:42,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:42,367][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.708311915397644, acc: 0.800000011920929)
[2024-12-14 23:50:42,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:42,740][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 1.0013458728790283, acc: 0.6341463327407837)
[2024-12-14 23:50:42,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:43,134][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.687861442565918, acc: 0.7428571581840515)
[2024-12-14 23:50:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:43,489][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.6505266427993774, acc: 0.8684210777282715)
[2024-12-14 23:50:43,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:43,827][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.5825554728507996, acc: 0.8709677457809448)
[2024-12-14 23:50:43,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:44,176][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.609586775302887, acc: 0.800000011920929)
[2024-12-14 23:50:44,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:44,508][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.46917060017585754, acc: 0.8787878751754761)
[2024-12-14 23:50:44,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:44,839][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.855613112449646, acc: 0.824999988079071)
[2024-12-14 23:50:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:45,191][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 1.1500791311264038, acc: 0.6714285612106323)
[2024-12-14 23:50:45,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:45,547][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 2.053481340408325, acc: 0.46715328097343445)
[2024-12-14 23:50:45,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:45,919][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 1.4365050792694092, acc: 0.6068965792655945)
[2024-12-14 23:50:46,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:46,298][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 2.1310741901397705, acc: 0.40714284777641296)
[2024-12-14 23:50:46,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:46,697][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 1.7734730243682861, acc: 0.4900662302970886)
[2024-12-14 23:50:46,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:47,073][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 1.5222378969192505, acc: 0.5726495981216431)
[2024-12-14 23:50:47,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:47,411][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.5081611275672913, acc: 0.8399999737739563)
[2024-12-14 23:50:47,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:47,766][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.7709029912948608, acc: 0.7307692170143127)
[2024-12-14 23:50:47,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:48,166][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.543574333190918, acc: 0.807692289352417)
[2024-12-14 23:50:48,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:48,614][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.9938730001449585, acc: 0.7435897588729858)
[2024-12-14 23:50:49,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:49,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:50,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:50,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:51,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:51,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:51,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:52,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:53,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:53,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:53,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:54,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:54,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:54,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:55,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:55,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:55,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:56,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:56,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:56,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:57,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:57,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:57,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:58,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:58,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:59,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:59,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:50:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:00,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:00,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:01,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:01,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:01,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:02,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:02,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:03,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:03,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:03,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:04,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:04,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:04,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:05,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:05,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:06,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:06,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:07,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:07,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:09,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:09,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:10,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:10,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:11,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:11,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:11,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:12,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:12,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:13,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:13,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:14,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:14,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:15,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:15,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:16,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:16,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:16,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:17,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:17,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:17,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:18,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:18,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:18,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:19,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:19,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:20,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:21,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:21,731][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.6466, device='cuda:0') eval_epoch_loss=tensor(2.0343, device='cuda:0') eval_epoch_acc=tensor(0.4944, device='cuda:0')
[2024-12-14 23:51:21,733][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:51:21,733][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:51:22,460][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_6_step_562_loss_2.034259796142578/model.pt
[2024-12-14 23:51:22,465][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:51:22,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:22,911][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 1.219531774520874, acc: 0.6111111044883728)
[2024-12-14 23:51:23,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:23,274][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 1.2560791969299316, acc: 0.5974025726318359)
[2024-12-14 23:51:23,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:23,700][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.9969833493232727, acc: 0.6875)
[2024-12-14 23:51:23,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:24,062][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.9284573197364807, acc: 0.7586206793785095)
[2024-12-14 23:51:24,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:24,430][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 1.3910486698150635, acc: 0.5476190447807312)
[2024-12-14 23:51:24,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:24,800][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.8508555889129639, acc: 0.6842105388641357)
[2024-12-14 23:51:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:25,142][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.6528507471084595, acc: 0.7777777910232544)
[2024-12-14 23:51:25,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:25,601][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 1.6169085502624512, acc: 0.5508021116256714)
[2024-12-14 23:51:25,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:25,982][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 1.146189570426941, acc: 0.6774193644523621)
[2024-12-14 23:51:26,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:26,348][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 1.2156332731246948, acc: 0.632478654384613)
[2024-12-14 23:51:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:26,717][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 1.7813135385513306, acc: 0.5051020383834839)
[2024-12-14 23:51:26,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:27,092][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 1.8128362894058228, acc: 0.4716981053352356)
[2024-12-14 23:51:27,563][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=3.2471, train_epoch_loss=1.1778, epoch time 384.2551252897829s
[2024-12-14 23:51:27,563][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-14 23:51:27,563][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-12-14 23:51:27,563][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-14 23:51:27,564][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 18
[2024-12-14 23:51:27,564][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:51:28,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:28,505][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.7115715146064758, acc: 0.7777777910232544)
[2024-12-14 23:51:28,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:28,892][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 1.2508823871612549, acc: 0.6800000071525574)
[2024-12-14 23:51:28,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:29,260][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 1.3753424882888794, acc: 0.5945945978164673)
[2024-12-14 23:51:29,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:29,723][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 1.1631428003311157, acc: 0.5526315569877625)
[2024-12-14 23:51:29,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:30,176][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.9897533059120178, acc: 0.6756756901741028)
[2024-12-14 23:51:30,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:30,557][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.8786457180976868, acc: 0.7142857313156128)
[2024-12-14 23:51:30,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:30,926][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 1.1303009986877441, acc: 0.5714285969734192)
[2024-12-14 23:51:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:31,294][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 1.064756155014038, acc: 0.699999988079071)
[2024-12-14 23:51:31,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:31,675][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.4437769949436188, acc: 0.8636363744735718)
[2024-12-14 23:51:31,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:32,061][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.7867152690887451, acc: 0.7307692170143127)
[2024-12-14 23:51:32,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:32,494][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 1.133923053741455, acc: 0.5925925970077515)
[2024-12-14 23:51:32,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:32,879][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 1.173974633216858, acc: 0.6153846383094788)
[2024-12-14 23:51:32,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:33,220][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.8052814602851868, acc: 0.7575757503509521)
[2024-12-14 23:51:33,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:33,629][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 1.1457918882369995, acc: 0.6086956262588501)
[2024-12-14 23:51:33,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:34,015][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 1.3168386220932007, acc: 0.6274510025978088)
[2024-12-14 23:51:34,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:34,439][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 1.322334885597229, acc: 0.5714285969734192)
[2024-12-14 23:51:34,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:34,847][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.5817734003067017, acc: 0.7894737124443054)
[2024-12-14 23:51:34,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:35,243][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.8353042006492615, acc: 0.6666666865348816)
[2024-12-14 23:51:35,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:35,686][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 1.0576177835464478, acc: 0.6944444179534912)
[2024-12-14 23:51:35,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:36,061][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.9527385830879211, acc: 0.6842105388641357)
[2024-12-14 23:51:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:36,407][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 1.0552563667297363, acc: 0.7307692170143127)
[2024-12-14 23:51:36,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:36,827][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 1.1271778345108032, acc: 0.7241379022598267)
[2024-12-14 23:51:36,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:37,259][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.7358493208885193, acc: 0.7599999904632568)
[2024-12-14 23:51:37,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:37,618][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.6548948287963867, acc: 0.761904776096344)
[2024-12-14 23:51:37,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:37,968][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 1.2174417972564697, acc: 0.5625)
[2024-12-14 23:51:38,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:38,347][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 1.4690285921096802, acc: 0.5471698045730591)
[2024-12-14 23:51:38,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:38,715][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 1.704608678817749, acc: 0.5068492889404297)
[2024-12-14 23:51:39,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:39,957][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 2.019378662109375, acc: 0.43478259444236755)
[2024-12-14 23:51:40,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:40,349][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 1.1947524547576904, acc: 0.6279069781303406)
[2024-12-14 23:51:40,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:40,811][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 1.5877858400344849, acc: 0.5180723071098328)
[2024-12-14 23:51:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:41,205][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 1.523815631866455, acc: 0.5555555820465088)
[2024-12-14 23:51:41,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:41,590][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.8017329573631287, acc: 0.8214285969734192)
[2024-12-14 23:51:41,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:41,967][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 1.1013396978378296, acc: 0.6296296119689941)
[2024-12-14 23:51:42,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:42,332][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.7894163727760315, acc: 0.782608687877655)
[2024-12-14 23:51:42,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:42,711][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 1.7387046813964844, acc: 0.4789915978908539)
[2024-12-14 23:51:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:43,068][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 1.3407827615737915, acc: 0.5409836173057556)
[2024-12-14 23:51:43,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:43,452][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 1.3476394414901733, acc: 0.6349206566810608)
[2024-12-14 23:51:43,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:43,816][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 1.6895920038223267, acc: 0.47457626461982727)
[2024-12-14 23:51:43,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:44,192][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 1.2376612424850464, acc: 0.6666666865348816)
[2024-12-14 23:51:44,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:44,536][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.6489217281341553, acc: 0.761904776096344)
[2024-12-14 23:51:44,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:44,960][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.8794467449188232, acc: 0.7692307829856873)
[2024-12-14 23:51:45,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:45,380][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 1.7709146738052368, acc: 0.5135135054588318)
[2024-12-14 23:51:45,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:45,815][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 1.418140172958374, acc: 0.5846154093742371)
[2024-12-14 23:51:45,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:46,290][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 1.7291617393493652, acc: 0.5353535413742065)
[2024-12-14 23:51:46,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:46,759][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 1.390905737876892, acc: 0.6185566782951355)
[2024-12-14 23:51:46,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:47,197][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 1.640296459197998, acc: 0.529411792755127)
[2024-12-14 23:51:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:47,494][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.7942887544631958, acc: 0.7307692170143127)
[2024-12-14 23:51:47,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:47,934][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.508385419845581, acc: 0.8148148059844971)
[2024-12-14 23:51:48,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:48,390][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.8605309724807739, acc: 0.6785714030265808)
[2024-12-14 23:51:48,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:48,805][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.5300535559654236, acc: 0.8333333134651184)
[2024-12-14 23:51:48,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:49,173][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 1.0362640619277954, acc: 0.6842105388641357)
[2024-12-14 23:51:49,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:49,608][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.9913235902786255, acc: 0.7301587462425232)
[2024-12-14 23:51:49,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:50,045][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 1.2736518383026123, acc: 0.6619718074798584)
[2024-12-14 23:51:50,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:50,533][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.8736450672149658, acc: 0.5400000214576721)
[2024-12-14 23:51:50,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:50,911][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.7286407947540283, acc: 0.8108108043670654)
[2024-12-14 23:51:51,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:51,277][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.48882678151130676, acc: 0.8846153616905212)
[2024-12-14 23:51:53,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:54,183][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 1.7465049028396606, acc: 0.5290102362632751)
[2024-12-14 23:51:54,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:55,382][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 2.294670820236206, acc: 0.43355119228363037)
[2024-12-14 23:51:55,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:56,102][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 1.7009329795837402, acc: 0.5852272510528564)
[2024-12-14 23:51:56,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:56,729][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 1.774006962776184, acc: 0.5073529481887817)
[2024-12-14 23:51:56,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:57,315][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 2.079650402069092, acc: 0.43478259444236755)
[2024-12-14 23:51:57,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:57,758][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 1.4199037551879883, acc: 0.6499999761581421)
[2024-12-14 23:51:57,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:58,120][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.5726538300514221, acc: 0.8235294222831726)
[2024-12-14 23:51:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:58,507][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 1.3251453638076782, acc: 0.6111111044883728)
[2024-12-14 23:51:58,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:58,911][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 1.036965250968933, acc: 0.734375)
[2024-12-14 23:51:59,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:59,267][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.7784565091133118, acc: 0.7931034564971924)
[2024-12-14 23:51:59,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:51:59,658][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 1.605823278427124, acc: 0.5892857313156128)
[2024-12-14 23:51:59,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:00,047][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 1.6419034004211426, acc: 0.5333333611488342)
[2024-12-14 23:52:00,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:00,407][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.43517330288887024, acc: 0.8399999737739563)
[2024-12-14 23:52:00,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:00,748][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.8442272543907166, acc: 0.7777777910232544)
[2024-12-14 23:52:00,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:01,099][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.9099746346473694, acc: 0.6666666865348816)
[2024-12-14 23:52:01,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:01,522][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 1.6843491792678833, acc: 0.5514705777168274)
[2024-12-14 23:52:01,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:01,906][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 1.5199867486953735, acc: 0.6111111044883728)
[2024-12-14 23:52:02,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:02,288][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 2.0839316844940186, acc: 0.43589743971824646)
[2024-12-14 23:52:02,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:02,662][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 1.4192856550216675, acc: 0.581632673740387)
[2024-12-14 23:52:02,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:03,022][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 1.9971473217010498, acc: 0.4701492488384247)
[2024-12-14 23:52:03,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:03,442][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 2.091552734375, acc: 0.4562043845653534)
[2024-12-14 23:52:03,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:03,853][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.4613626003265381, acc: 0.8571428656578064)
[2024-12-14 23:52:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:04,230][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.5167521834373474, acc: 0.8333333134651184)
[2024-12-14 23:52:04,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:04,636][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.8512499332427979, acc: 0.7575757503509521)
[2024-12-14 23:52:04,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:05,005][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.5857197642326355, acc: 0.7307692170143127)
[2024-12-14 23:52:05,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:05,412][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 1.1795119047164917, acc: 0.6538461446762085)
[2024-12-14 23:52:05,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:05,893][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 1.3013540506362915, acc: 0.6153846383094788)
[2024-12-14 23:52:06,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:06,338][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.8882203698158264, acc: 0.65625)
[2024-12-14 23:52:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:06,710][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 1.3700380325317383, acc: 0.5507246255874634)
[2024-12-14 23:52:06,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:07,089][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 1.035637617111206, acc: 0.7400000095367432)
[2024-12-14 23:52:07,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:07,444][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 1.002324104309082, acc: 0.695652186870575)
[2024-12-14 23:52:07,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:07,958][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 1.2861744165420532, acc: 0.5799999833106995)
[2024-12-14 23:52:08,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:08,361][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 1.3844001293182373, acc: 0.6019417643547058)
[2024-12-14 23:52:08,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:09,448][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 1.7015016078948975, acc: 0.5339806079864502)
[2024-12-14 23:52:09,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:10,292][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 1.801275610923767, acc: 0.5161290168762207)
[2024-12-14 23:52:10,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:11,122][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 1.7223842144012451, acc: 0.5431034564971924)
[2024-12-14 23:52:11,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:11,890][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 1.236993670463562, acc: 0.6315789222717285)
[2024-12-14 23:52:12,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:12,906][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 1.9307103157043457, acc: 0.4653465449810028)
[2024-12-14 23:52:13,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:13,337][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 1.668272614479065, acc: 0.4677419364452362)
[2024-12-14 23:52:13,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:13,719][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 1.6619873046875, acc: 0.5652173757553101)
[2024-12-14 23:52:13,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:14,125][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 1.9275802373886108, acc: 0.42016807198524475)
[2024-12-14 23:52:14,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:14,543][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 1.8679648637771606, acc: 0.4326923191547394)
[2024-12-14 23:52:14,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:14,955][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 1.9147913455963135, acc: 0.49635037779808044)
[2024-12-14 23:52:15,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:15,314][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 1.4351803064346313, acc: 0.5223880410194397)
[2024-12-14 23:52:15,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:15,702][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.5503218173980713, acc: 0.8999999761581421)
[2024-12-14 23:52:15,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:16,048][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.7255755066871643, acc: 0.7727272510528564)
[2024-12-14 23:52:16,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:16,392][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.5689887404441833, acc: 0.8695651888847351)
[2024-12-14 23:52:16,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:16,748][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.7585222721099854, acc: 0.7727272510528564)
[2024-12-14 23:52:16,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:17,120][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 1.2177376747131348, acc: 0.5862069129943848)
[2024-12-14 23:52:17,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:17,461][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.7784444093704224, acc: 0.6744186282157898)
[2024-12-14 23:52:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:17,807][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 1.0193289518356323, acc: 0.6399999856948853)
[2024-12-14 23:52:17,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:18,181][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.5142714381217957, acc: 0.8823529481887817)
[2024-12-14 23:52:18,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:18,591][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.49483251571655273, acc: 0.8461538553237915)
[2024-12-14 23:52:18,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:18,963][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.4729032516479492, acc: 0.8571428656578064)
[2024-12-14 23:52:19,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:19,325][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 1.1225672960281372, acc: 0.692307710647583)
[2024-12-14 23:52:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:19,758][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 1.2687277793884277, acc: 0.6491228342056274)
[2024-12-14 23:52:19,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:20,158][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 1.1502304077148438, acc: 0.719298243522644)
[2024-12-14 23:52:20,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:20,562][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 1.0338746309280396, acc: 0.692307710647583)
[2024-12-14 23:52:20,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:20,970][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.9774482250213623, acc: 0.7551020383834839)
[2024-12-14 23:52:21,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:21,388][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.4118535816669464, acc: 0.9090909361839294)
[2024-12-14 23:52:21,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:21,787][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 1.1767451763153076, acc: 0.6507936716079712)
[2024-12-14 23:52:21,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:22,174][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 1.5718746185302734, acc: 0.5691056847572327)
[2024-12-14 23:52:22,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:22,540][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 1.1123825311660767, acc: 0.6612903475761414)
[2024-12-14 23:52:22,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:23,415][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 1.7404239177703857, acc: 0.517110288143158)
[2024-12-14 23:52:23,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:23,808][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 1.1914055347442627, acc: 0.6800000071525574)
[2024-12-14 23:52:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:24,246][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.858282208442688, acc: 0.7884615659713745)
[2024-12-14 23:52:24,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:24,621][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.426769882440567, acc: 0.875)
[2024-12-14 23:52:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:25,006][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.7032417058944702, acc: 0.7368420958518982)
[2024-12-14 23:52:25,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:25,378][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 1.6553889513015747, acc: 0.5153374075889587)
[2024-12-14 23:52:25,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:25,812][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 1.4859529733657837, acc: 0.5763888955116272)
[2024-12-14 23:52:25,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:26,226][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 1.7061880826950073, acc: 0.5333333611488342)
[2024-12-14 23:52:26,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:26,661][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 1.7473082542419434, acc: 0.4642857015132904)
[2024-12-14 23:52:26,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:27,060][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 1.6354061365127563, acc: 0.5487179756164551)
[2024-12-14 23:52:27,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:27,497][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 1.5322299003601074, acc: 0.5882353186607361)
[2024-12-14 23:52:27,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:27,840][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.6734867095947266, acc: 0.807692289352417)
[2024-12-14 23:52:28,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:29,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:30,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:30,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:31,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:31,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:31,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:32,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:32,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:33,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:33,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:33,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:34,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:34,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:35,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:35,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:36,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:37,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:37,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:38,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:38,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:38,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:39,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:39,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:40,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:40,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:40,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:41,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:41,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:42,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:42,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:42,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:43,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:43,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:43,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:44,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:44,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:44,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:45,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:45,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:46,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:46,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:46,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:47,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:47,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:47,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:48,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:48,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:49,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:49,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:50,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:50,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:51,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:51,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:51,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:52,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:52,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:52,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:53,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:53,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:54,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:54,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:55,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:55,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:56,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:56,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:56,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:57,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:57,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:58,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:58,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:58,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:59,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:52:59,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:00,389][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.1189, device='cuda:0') eval_epoch_loss=tensor(1.9627, device='cuda:0') eval_epoch_acc=tensor(0.5202, device='cuda:0')
[2024-12-14 23:53:00,390][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:53:00,390][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:53:01,046][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_7_step_131_loss_1.9627482891082764/model.pt
[2024-12-14 23:53:01,054][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:53:01,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:01,472][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.5534731149673462, acc: 0.782608687877655)
[2024-12-14 23:53:01,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:01,897][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.7254626750946045, acc: 0.75)
[2024-12-14 23:53:02,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:02,268][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.5723569989204407, acc: 0.8695651888847351)
[2024-12-14 23:53:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:02,636][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.8171751499176025, acc: 0.7142857313156128)
[2024-12-14 23:53:02,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:03,012][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.6000354886054993, acc: 0.7692307829856873)
[2024-12-14 23:53:03,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:03,353][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.9326565861701965, acc: 0.7142857313156128)
[2024-12-14 23:53:03,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:03,696][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.9020175337791443, acc: 0.699999988079071)
[2024-12-14 23:53:03,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:04,065][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.969145655632019, acc: 0.6521739363670349)
[2024-12-14 23:53:04,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:04,403][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.9773009419441223, acc: 0.6666666865348816)
[2024-12-14 23:53:04,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:04,773][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 1.1749836206436157, acc: 0.5769230723381042)
[2024-12-14 23:53:04,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:05,155][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 1.0742920637130737, acc: 0.6774193644523621)
[2024-12-14 23:53:05,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:05,572][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 1.3739889860153198, acc: 0.4864864945411682)
[2024-12-14 23:53:05,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:06,162][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 1.8061025142669678, acc: 0.48245614767074585)
[2024-12-14 23:53:06,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:06,587][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 1.4919620752334595, acc: 0.5746268630027771)
[2024-12-14 23:53:06,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:06,987][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 1.901813268661499, acc: 0.47959184646606445)
[2024-12-14 23:53:07,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:07,470][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 1.8280773162841797, acc: 0.44680851697921753)
[2024-12-14 23:53:07,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:07,821][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 1.5515937805175781, acc: 0.5428571701049805)
[2024-12-14 23:53:07,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:08,166][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.8698133230209351, acc: 0.6785714030265808)
[2024-12-14 23:53:08,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:08,518][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.9259759783744812, acc: 0.695652186870575)
[2024-12-14 23:53:08,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:08,907][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.7312465310096741, acc: 0.7241379022598267)
[2024-12-14 23:53:09,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:09,260][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 1.1395585536956787, acc: 0.739130437374115)
[2024-12-14 23:53:09,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:09,639][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 1.4127380847930908, acc: 0.5932203531265259)
[2024-12-14 23:53:09,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:10,013][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 1.4525682926177979, acc: 0.5789473652839661)
[2024-12-14 23:53:10,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:10,373][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 1.4922220706939697, acc: 0.5675675868988037)
[2024-12-14 23:53:10,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:10,729][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.8019496202468872, acc: 0.7857142686843872)
[2024-12-14 23:53:10,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:11,092][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 1.0030478239059448, acc: 0.695652186870575)
[2024-12-14 23:53:11,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:11,408][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.564359188079834, acc: 0.8421052694320679)
[2024-12-14 23:53:12,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:12,983][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 1.0831654071807861, acc: 0.6756756901741028)
[2024-12-14 23:53:13,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:13,326][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 1.2813881635665894, acc: 0.6481481194496155)
[2024-12-14 23:53:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:13,765][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 1.1627014875411987, acc: 0.6511628031730652)
[2024-12-14 23:53:13,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:14,382][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 1.0005483627319336, acc: 0.7176470756530762)
[2024-12-14 23:53:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:14,970][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 1.4008903503417969, acc: 0.617977499961853)
[2024-12-14 23:53:15,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:15,394][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 1.1346913576126099, acc: 0.6590909361839294)
[2024-12-14 23:53:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:15,759][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 1.6144492626190186, acc: 0.6666666865348816)
[2024-12-14 23:53:15,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:16,123][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.881293773651123, acc: 0.7931034564971924)
[2024-12-14 23:53:16,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:16,518][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.8290072083473206, acc: 0.7346938848495483)
[2024-12-14 23:53:16,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:16,894][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 1.0405324697494507, acc: 0.6200000047683716)
[2024-12-14 23:53:17,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:17,325][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 1.0920052528381348, acc: 0.6111111044883728)
[2024-12-14 23:53:17,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:17,707][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 1.508363962173462, acc: 0.529411792755127)
[2024-12-14 23:53:18,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:18,761][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 1.902287483215332, acc: 0.5)
[2024-12-14 23:53:18,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:19,103][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.6230241060256958, acc: 0.7916666865348816)
[2024-12-14 23:53:19,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:19,467][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.6047661900520325, acc: 0.7777777910232544)
[2024-12-14 23:53:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:19,815][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.6311010122299194, acc: 0.8214285969734192)
[2024-12-14 23:53:20,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:20,383][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 1.306710124015808, acc: 0.6460176706314087)
[2024-12-14 23:53:20,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:20,788][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 1.1682205200195312, acc: 0.6231883764266968)
[2024-12-14 23:53:20,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:21,163][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 1.382121205329895, acc: 0.5909090638160706)
[2024-12-14 23:53:21,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:22,113][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 1.9570293426513672, acc: 0.4351145029067993)
[2024-12-14 23:53:22,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:22,805][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 1.7717455625534058, acc: 0.5259259343147278)
[2024-12-14 23:53:22,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:23,155][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 1.1020704507827759, acc: 0.6557376980781555)
[2024-12-14 23:53:23,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:23,548][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.5783676505088806, acc: 0.7916666865348816)
[2024-12-14 23:53:23,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:23,916][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.9004347920417786, acc: 0.6800000071525574)
[2024-12-14 23:53:24,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:24,374][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.7403853535652161, acc: 0.7142857313156128)
[2024-12-14 23:53:24,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:24,811][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 1.4936695098876953, acc: 0.5609756112098694)
[2024-12-14 23:53:24,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:25,216][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 1.9335978031158447, acc: 0.47129908204078674)
[2024-12-14 23:53:25,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:25,669][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 2.0359601974487305, acc: 0.455331414937973)
[2024-12-14 23:53:25,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:26,199][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 2.079106330871582, acc: 0.44999998807907104)
[2024-12-14 23:53:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:26,745][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 2.0114526748657227, acc: 0.4446529150009155)
[2024-12-14 23:53:26,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:27,204][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 1.854125738143921, acc: 0.4875444769859314)
[2024-12-14 23:53:27,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:27,607][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 1.1756927967071533, acc: 0.7599999904632568)
[2024-12-14 23:53:27,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:28,235][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 1.8869152069091797, acc: 0.4651162922382355)
[2024-12-14 23:53:28,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:29,059][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 1.6839911937713623, acc: 0.5714285969734192)
[2024-12-14 23:53:29,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:29,999][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 1.6773303747177124, acc: 0.5)
[2024-12-14 23:53:30,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:30,767][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 1.4331903457641602, acc: 0.6235294342041016)
[2024-12-14 23:53:31,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:31,871][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 1.4152350425720215, acc: 0.6111111044883728)
[2024-12-14 23:53:32,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:32,853][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 1.1079038381576538, acc: 0.7096773982048035)
[2024-12-14 23:53:32,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:33,188][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.49279117584228516, acc: 0.7857142686843872)
[2024-12-14 23:53:33,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:33,530][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.7044500708580017, acc: 0.800000011920929)
[2024-12-14 23:53:33,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:33,982][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 1.1984624862670898, acc: 0.6470588445663452)
[2024-12-14 23:53:34,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:34,366][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 1.4943588972091675, acc: 0.5588235259056091)
[2024-12-14 23:53:34,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:34,801][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 1.59615957736969, acc: 0.5508474707603455)
[2024-12-14 23:53:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:35,188][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 1.5907008647918701, acc: 0.5671641826629639)
[2024-12-14 23:53:35,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:35,595][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 1.5668402910232544, acc: 0.5728155374526978)
[2024-12-14 23:53:35,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:35,986][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 1.155890941619873, acc: 0.6666666865348816)
[2024-12-14 23:53:36,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:36,356][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 1.1412497758865356, acc: 0.692307710647583)
[2024-12-14 23:53:36,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:36,772][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 1.7332086563110352, acc: 0.5291479825973511)
[2024-12-14 23:53:36,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:37,228][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 1.8773882389068604, acc: 0.4763779640197754)
[2024-12-14 23:53:37,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:37,633][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 1.655910611152649, acc: 0.5301724076271057)
[2024-12-14 23:53:37,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:38,061][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 1.826844573020935, acc: 0.49637681245803833)
[2024-12-14 23:53:38,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:38,479][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 1.8990286588668823, acc: 0.4747081696987152)
[2024-12-14 23:53:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:38,873][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 1.6441223621368408, acc: 0.554347813129425)
[2024-12-14 23:53:38,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:39,222][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.8079754114151001, acc: 0.695652186870575)
[2024-12-14 23:53:39,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:39,547][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.8956232070922852, acc: 0.6428571343421936)
[2024-12-14 23:53:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:39,932][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.8026612401008606, acc: 0.7659574747085571)
[2024-12-14 23:53:40,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:40,646][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 1.2619162797927856, acc: 0.6461538672447205)
[2024-12-14 23:53:40,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:41,042][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 1.023667573928833, acc: 0.6891891956329346)
[2024-12-14 23:53:41,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:41,420][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 1.172969102859497, acc: 0.6162790656089783)
[2024-12-14 23:53:41,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:42,009][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 1.2023259401321411, acc: 0.6666666865348816)
[2024-12-14 23:53:42,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:42,430][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 1.1540402173995972, acc: 0.6111111044883728)
[2024-12-14 23:53:42,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:42,770][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.686602771282196, acc: 0.7878788113594055)
[2024-12-14 23:53:42,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:43,114][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.38440707325935364, acc: 0.8518518805503845)
[2024-12-14 23:53:43,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:43,551][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.8314536213874817, acc: 0.7200000286102295)
[2024-12-14 23:53:43,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:43,938][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 1.0911190509796143, acc: 0.6538461446762085)
[2024-12-14 23:53:44,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:44,735][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 1.1603196859359741, acc: 0.6630434989929199)
[2024-12-14 23:53:44,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:45,313][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 1.5732074975967407, acc: 0.5625)
[2024-12-14 23:53:45,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:45,802][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 1.3347601890563965, acc: 0.563829779624939)
[2024-12-14 23:53:45,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:46,226][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.8543667793273926, acc: 0.698113203048706)
[2024-12-14 23:53:46,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:46,666][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 1.0461863279342651, acc: 0.699999988079071)
[2024-12-14 23:53:46,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:47,042][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.5287172794342041, acc: 0.8604651093482971)
[2024-12-14 23:53:47,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:47,433][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.6215032935142517, acc: 0.800000011920929)
[2024-12-14 23:53:47,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:47,838][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 1.5314395427703857, acc: 0.6105263233184814)
[2024-12-14 23:53:47,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:48,191][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 1.0963809490203857, acc: 0.6333333253860474)
[2024-12-14 23:53:48,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:48,654][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.069472074508667, acc: 0.699999988079071)
[2024-12-14 23:53:48,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:49,173][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.3973835706710815, acc: 0.6192660331726074)
[2024-12-14 23:53:49,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:49,672][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 1.131696105003357, acc: 0.6538461446762085)
[2024-12-14 23:53:49,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:50,105][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.5954536199569702, acc: 0.8421052694320679)
[2024-12-14 23:53:50,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:50,483][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.468857079744339, acc: 0.875)
[2024-12-14 23:53:50,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:50,895][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 1.040639042854309, acc: 0.6818181872367859)
[2024-12-14 23:53:51,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:51,261][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.7835942506790161, acc: 0.7777777910232544)
[2024-12-14 23:53:51,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:51,619][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.5570920705795288, acc: 0.8285714387893677)
[2024-12-14 23:53:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:52,022][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.7757644057273865, acc: 0.7272727489471436)
[2024-12-14 23:53:52,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:52,410][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.9000130295753479, acc: 0.7272727489471436)
[2024-12-14 23:53:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:53,022][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 1.2647144794464111, acc: 0.5322580933570862)
[2024-12-14 23:53:53,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:53,581][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.9449519515037537, acc: 0.6363636255264282)
[2024-12-14 23:53:53,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:53,938][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.628381073474884, acc: 0.761904776096344)
[2024-12-14 23:53:54,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:54,276][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.8889580965042114, acc: 0.692307710647583)
[2024-12-14 23:53:54,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:54,633][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.571529746055603, acc: 0.9032257795333862)
[2024-12-14 23:53:54,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:55,014][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.7817709445953369, acc: 0.6499999761581421)
[2024-12-14 23:53:55,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:55,411][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.8986818194389343, acc: 0.7837837934494019)
[2024-12-14 23:53:55,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:55,843][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.866422712802887, acc: 0.7297297120094299)
[2024-12-14 23:53:55,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:56,227][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 1.0066299438476562, acc: 0.5945945978164673)
[2024-12-14 23:53:56,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:56,667][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 1.2825777530670166, acc: 0.6029411554336548)
[2024-12-14 23:53:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:57,072][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.5452543497085571, acc: 0.8292682766914368)
[2024-12-14 23:53:57,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:57,425][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.2965109348297119, acc: 0.9200000166893005)
[2024-12-14 23:53:57,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:57,780][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.33201363682746887, acc: 0.9200000166893005)
[2024-12-14 23:53:57,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:58,152][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.5084582567214966, acc: 0.8709677457809448)
[2024-12-14 23:53:58,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:58,561][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.8337648510932922, acc: 0.6842105388641357)
[2024-12-14 23:53:58,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:58,939][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.9943484663963318, acc: 0.6571428775787354)
[2024-12-14 23:53:59,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:59,294][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 1.0496023893356323, acc: 0.6973684430122375)
[2024-12-14 23:53:59,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:53:59,890][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 1.4556264877319336, acc: 0.5471698045730591)
[2024-12-14 23:54:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:00,494][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 1.6515562534332275, acc: 0.5916666388511658)
[2024-12-14 23:54:00,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:00,845][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.7684080600738525, acc: 0.75)
[2024-12-14 23:54:00,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:01,238][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.9568158984184265, acc: 0.7419354915618896)
[2024-12-14 23:54:01,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:01,631][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 1.7700719833374023, acc: 0.4933333396911621)
[2024-12-14 23:54:01,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:02,012][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 1.3583885431289673, acc: 0.625)
[2024-12-14 23:54:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:02,873][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 2.088104486465454, acc: 0.3919999897480011)
[2024-12-14 23:54:02,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:03,229][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 1.834847092628479, acc: 0.4606741666793823)
[2024-12-14 23:54:03,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:03,625][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 1.4703799486160278, acc: 0.5945945978164673)
[2024-12-14 23:54:03,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:04,127][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 1.127526044845581, acc: 0.6896551847457886)
[2024-12-14 23:54:04,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:04,491][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.7169219255447388, acc: 0.7727272510528564)
[2024-12-14 23:54:04,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:04,858][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.8656445145606995, acc: 0.6818181872367859)
[2024-12-14 23:54:04,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:05,225][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.6496673226356506, acc: 0.875)
[2024-12-14 23:54:05,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:05,592][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.7596451044082642, acc: 0.8333333134651184)
[2024-12-14 23:54:05,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:06,001][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 1.1543797254562378, acc: 0.5833333134651184)
[2024-12-14 23:54:06,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:07,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:07,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:08,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:08,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:08,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:09,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:09,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:10,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:10,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:10,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:11,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:12,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:12,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:12,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:13,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:14,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:14,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:14,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:15,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:15,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:15,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:16,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:16,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:17,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:17,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:17,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:18,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:18,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:19,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:19,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:19,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:20,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:20,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:20,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:21,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:21,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:21,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:22,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:22,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:23,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:23,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:23,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:23,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:24,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:24,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:24,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:25,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:25,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:26,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:26,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:26,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:27,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:27,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:28,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:28,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:28,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:29,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:29,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:30,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:30,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:30,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:31,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:31,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:32,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:32,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:32,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:33,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:33,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:33,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:34,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:34,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:35,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:35,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:35,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:36,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:36,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:36,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:37,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:37,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:38,167][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.1310, device='cuda:0') eval_epoch_loss=tensor(1.9644, device='cuda:0') eval_epoch_acc=tensor(0.5284, device='cuda:0')
[2024-12-14 23:54:38,169][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:54:38,169][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:54:38,880][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_7_step_274_loss_1.964449167251587/model.pt
[2024-12-14 23:54:38,886][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:54:38,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:39,276][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.7059854865074158, acc: 0.8125)
[2024-12-14 23:54:39,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:39,647][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.5401222705841064, acc: 0.800000011920929)
[2024-12-14 23:54:39,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:40,011][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.8169614672660828, acc: 0.7586206793785095)
[2024-12-14 23:54:40,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:40,368][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 1.0348334312438965, acc: 0.6800000071525574)
[2024-12-14 23:54:40,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:40,730][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.7957311868667603, acc: 0.6808510422706604)
[2024-12-14 23:54:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:41,139][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.9245507121086121, acc: 0.75)
[2024-12-14 23:54:41,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:41,558][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.9081891775131226, acc: 0.75)
[2024-12-14 23:54:41,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:42,013][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 1.4967823028564453, acc: 0.5662650465965271)
[2024-12-14 23:54:42,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:42,484][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 1.6784658432006836, acc: 0.6111111044883728)
[2024-12-14 23:54:42,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:42,858][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 1.306785225868225, acc: 0.6578947305679321)
[2024-12-14 23:54:42,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:43,204][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.8776364922523499, acc: 0.7352941036224365)
[2024-12-14 23:54:43,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:43,550][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.674776554107666, acc: 0.75)
[2024-12-14 23:54:43,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:43,927][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 1.5832862854003906, acc: 0.5625)
[2024-12-14 23:54:44,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:44,286][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 1.707402229309082, acc: 0.527999997138977)
[2024-12-14 23:54:44,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:44,634][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 1.2270392179489136, acc: 0.6483516693115234)
[2024-12-14 23:54:44,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:45,044][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 1.8286042213439941, acc: 0.4968944191932678)
[2024-12-14 23:54:45,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:45,421][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 1.9648709297180176, acc: 0.42783504724502563)
[2024-12-14 23:54:45,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:45,771][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.6242779493331909, acc: 0.7727272510528564)
[2024-12-14 23:54:45,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:46,189][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.9218466877937317, acc: 0.7142857313156128)
[2024-12-14 23:54:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:46,593][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.9716948866844177, acc: 0.7241379022598267)
[2024-12-14 23:54:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:47,102][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.7043424844741821, acc: 0.7818182110786438)
[2024-12-14 23:54:47,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:47,671][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 1.5717768669128418, acc: 0.5876288414001465)
[2024-12-14 23:54:47,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:48,034][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 1.2498362064361572, acc: 0.6206896305084229)
[2024-12-14 23:54:48,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:48,455][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.9047450423240662, acc: 0.7407407164573669)
[2024-12-14 23:54:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:48,820][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 1.087681770324707, acc: 0.7105262875556946)
[2024-12-14 23:54:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:49,175][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.8516258597373962, acc: 0.7142857313156128)
[2024-12-14 23:54:49,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:49,515][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.6910707950592041, acc: 0.78125)
[2024-12-14 23:54:49,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:49,860][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 1.0890566110610962, acc: 0.6037735939025879)
[2024-12-14 23:54:49,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:50,228][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.5245684385299683, acc: 0.8301886916160583)
[2024-12-14 23:54:50,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:50,624][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.6580790281295776, acc: 0.7941176295280457)
[2024-12-14 23:54:50,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:50,989][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.5701326131820679, acc: 0.875)
[2024-12-14 23:54:51,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:51,347][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 1.045323371887207, acc: 0.6557376980781555)
[2024-12-14 23:54:51,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:51,651][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.5440129637718201, acc: 0.8333333134651184)
[2024-12-14 23:54:51,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:52,003][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.34446725249290466, acc: 0.8947368264198303)
[2024-12-14 23:54:52,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:52,385][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 1.4209511280059814, acc: 0.5797101259231567)
[2024-12-14 23:54:52,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:52,815][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 1.2899541854858398, acc: 0.625)
[2024-12-14 23:54:52,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:53,208][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 1.0461406707763672, acc: 0.650602400302887)
[2024-12-14 23:54:53,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:53,598][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 1.7094953060150146, acc: 0.5)
[2024-12-14 23:54:53,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:54,012][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 1.4965933561325073, acc: 0.5408163070678711)
[2024-12-14 23:54:54,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:54,386][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.2209821194410324, acc: 0.9166666865348816)
[2024-12-14 23:54:54,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:54,806][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.5814955830574036, acc: 0.7916666865348816)
[2024-12-14 23:54:54,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:55,183][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.6005023717880249, acc: 0.774193525314331)
[2024-12-14 23:54:55,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:55,566][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.5515477061271667, acc: 0.8064516186714172)
[2024-12-14 23:54:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:55,949][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.9380728602409363, acc: 0.7014925479888916)
[2024-12-14 23:54:56,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:56,341][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 1.1607773303985596, acc: 0.6538461446762085)
[2024-12-14 23:54:56,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:56,716][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.7630663514137268, acc: 0.800000011920929)
[2024-12-14 23:54:56,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:57,079][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.9074203968048096, acc: 0.6774193644523621)
[2024-12-14 23:54:57,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:57,454][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.7112914323806763, acc: 0.8199999928474426)
[2024-12-14 23:54:57,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:57,833][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 1.2283345460891724, acc: 0.6666666865348816)
[2024-12-14 23:54:57,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:58,228][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 1.0624043941497803, acc: 0.6857143044471741)
[2024-12-14 23:54:58,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:58,621][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.9061779975891113, acc: 0.7435897588729858)
[2024-12-14 23:54:58,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:59,024][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 1.0820292234420776, acc: 0.6585366129875183)
[2024-12-14 23:54:59,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:59,426][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.7832741737365723, acc: 0.8421052694320679)
[2024-12-14 23:54:59,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:54:59,774][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.6426084637641907, acc: 0.7368420958518982)
[2024-12-14 23:54:59,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:00,109][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.38651156425476074, acc: 0.8214285969734192)
[2024-12-14 23:55:00,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:00,456][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.8717877864837646, acc: 0.7777777910232544)
[2024-12-14 23:55:00,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:00,821][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.5514518022537231, acc: 0.84375)
[2024-12-14 23:55:00,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:01,177][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.9427440166473389, acc: 0.7580645084381104)
[2024-12-14 23:55:01,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:01,570][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 1.1731919050216675, acc: 0.6315789222717285)
[2024-12-14 23:55:01,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:01,924][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 1.048386812210083, acc: 0.71875)
[2024-12-14 23:55:02,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:02,282][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.7529734373092651, acc: 0.7333333492279053)
[2024-12-14 23:55:02,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:02,644][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.7434172630310059, acc: 0.7894737124443054)
[2024-12-14 23:55:02,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:03,025][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 1.0808855295181274, acc: 0.6399999856948853)
[2024-12-14 23:55:03,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:03,419][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 1.733343243598938, acc: 0.4482758641242981)
[2024-12-14 23:55:03,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:03,810][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 1.6147716045379639, acc: 0.5319148898124695)
[2024-12-14 23:55:03,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:04,187][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 1.7579816579818726, acc: 0.46987950801849365)
[2024-12-14 23:55:04,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:04,518][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.6939857602119446, acc: 0.739130437374115)
[2024-12-14 23:55:04,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:04,845][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.5477864146232605, acc: 0.8205128312110901)
[2024-12-14 23:55:04,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:05,203][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 1.3967690467834473, acc: 0.6265060305595398)
[2024-12-14 23:55:05,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:05,638][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 1.177119255065918, acc: 0.6603773832321167)
[2024-12-14 23:55:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:06,050][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 1.073535680770874, acc: 0.7088607549667358)
[2024-12-14 23:55:06,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:06,419][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 1.002852201461792, acc: 0.7450980544090271)
[2024-12-14 23:55:06,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:06,782][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 1.4808377027511597, acc: 0.5522388219833374)
[2024-12-14 23:55:06,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:07,148][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.6078409552574158, acc: 0.8500000238418579)
[2024-12-14 23:55:07,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:07,532][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.6468325853347778, acc: 0.800000011920929)
[2024-12-14 23:55:07,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:08,018][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.9842084050178528, acc: 0.7222222089767456)
[2024-12-14 23:55:08,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:08,396][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 1.460491418838501, acc: 0.5348837375640869)
[2024-12-14 23:55:08,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:08,784][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 1.0083870887756348, acc: 0.692307710647583)
[2024-12-14 23:55:08,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:09,255][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 1.1592507362365723, acc: 0.644444465637207)
[2024-12-14 23:55:09,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:09,626][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.649497389793396, acc: 0.695652186870575)
[2024-12-14 23:55:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:10,005][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.6594076156616211, acc: 0.7692307829856873)
[2024-12-14 23:55:10,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:10,415][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 1.810292363166809, acc: 0.5054945349693298)
[2024-12-14 23:55:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:10,967][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 1.6201826333999634, acc: 0.6000000238418579)
[2024-12-14 23:55:11,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:11,401][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 1.3694801330566406, acc: 0.6086956262588501)
[2024-12-14 23:55:11,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:11,792][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 1.2273489236831665, acc: 0.6530612111091614)
[2024-12-14 23:55:11,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:12,144][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.3777712285518646, acc: 0.9166666865348816)
[2024-12-14 23:55:12,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:12,482][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.6967689990997314, acc: 0.7692307829856873)
[2024-12-14 23:55:12,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:12,821][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.8661687970161438, acc: 0.7804877758026123)
[2024-12-14 23:55:12,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:13,245][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.8542388677597046, acc: 0.6666666865348816)
[2024-12-14 23:55:13,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:13,650][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 1.0977216958999634, acc: 0.6710526347160339)
[2024-12-14 23:55:13,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:14,084][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.9292222857475281, acc: 0.7560975551605225)
[2024-12-14 23:55:14,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:14,471][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 1.1371763944625854, acc: 0.5757575631141663)
[2024-12-14 23:55:14,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:14,882][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.606401801109314, acc: 0.7916666865348816)
[2024-12-14 23:55:14,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:15,245][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.36706289649009705, acc: 0.8695651888847351)
[2024-12-14 23:55:15,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:15,617][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.5189512968063354, acc: 0.8571428656578064)
[2024-12-14 23:55:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:16,019][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.6005979180335999, acc: 0.78125)
[2024-12-14 23:55:16,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:16,657][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 1.5167312622070312, acc: 0.6000000238418579)
[2024-12-14 23:55:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:17,553][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 1.083328127861023, acc: 0.7169811129570007)
[2024-12-14 23:55:17,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:17,922][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 1.1374342441558838, acc: 0.6777777671813965)
[2024-12-14 23:55:18,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:18,342][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.9551544785499573, acc: 0.6607142686843872)
[2024-12-14 23:55:18,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:18,727][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.6945508718490601, acc: 0.7714285850524902)
[2024-12-14 23:55:18,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:19,082][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.42608442902565, acc: 0.8799999952316284)
[2024-12-14 23:55:19,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:19,456][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.6519965529441833, acc: 0.695652186870575)
[2024-12-14 23:55:19,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:19,810][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 1.0429012775421143, acc: 0.6666666865348816)
[2024-12-14 23:55:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:20,197][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 1.1730244159698486, acc: 0.6736842393875122)
[2024-12-14 23:55:20,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:20,801][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 1.368703842163086, acc: 0.6407185792922974)
[2024-12-14 23:55:20,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:21,242][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 1.130431890487671, acc: 0.6691729426383972)
[2024-12-14 23:55:21,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:22,471][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 1.3766186237335205, acc: 0.6203208565711975)
[2024-12-14 23:55:22,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:23,059][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 1.077292561531067, acc: 0.7027027010917664)
[2024-12-14 23:55:23,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:23,423][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.6679800748825073, acc: 0.7857142686843872)
[2024-12-14 23:55:23,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:23,798][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.5891642570495605, acc: 0.8214285969734192)
[2024-12-14 23:55:23,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:24,162][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.6730231046676636, acc: 0.78125)
[2024-12-14 23:55:24,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:24,508][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.7084968090057373, acc: 0.6944444179534912)
[2024-12-14 23:55:24,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:24,851][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.7206233739852905, acc: 0.7631579041481018)
[2024-12-14 23:55:24,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:25,204][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.5735635161399841, acc: 0.8181818127632141)
[2024-12-14 23:55:25,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:25,576][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.9140753746032715, acc: 0.6499999761581421)
[2024-12-14 23:55:25,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:25,940][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.7082267999649048, acc: 0.761904776096344)
[2024-12-14 23:55:26,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:26,278][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 1.1367745399475098, acc: 0.7407407164573669)
[2024-12-14 23:55:26,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:26,648][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 1.718284249305725, acc: 0.5339806079864502)
[2024-12-14 23:55:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:27,196][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 1.5818793773651123, acc: 0.5808823704719543)
[2024-12-14 23:55:27,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:27,623][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 1.747412085533142, acc: 0.54666668176651)
[2024-12-14 23:55:27,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:28,061][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 1.8320364952087402, acc: 0.5)
[2024-12-14 23:55:28,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:28,441][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 1.2187331914901733, acc: 0.6976743936538696)
[2024-12-14 23:55:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:28,835][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.7215147614479065, acc: 0.8333333134651184)
[2024-12-14 23:55:28,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:29,207][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.8731987476348877, acc: 0.7441860437393188)
[2024-12-14 23:55:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:29,592][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.5936999320983887, acc: 0.800000011920929)
[2024-12-14 23:55:29,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:30,169][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 1.0960158109664917, acc: 0.6764705777168274)
[2024-12-14 23:55:30,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:30,576][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 1.2785470485687256, acc: 0.5866666436195374)
[2024-12-14 23:55:30,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:31,002][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.8714462518692017, acc: 0.7272727489471436)
[2024-12-14 23:55:31,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:31,386][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.7647468447685242, acc: 0.8484848737716675)
[2024-12-14 23:55:31,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:31,791][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.6574130654335022, acc: 0.8064516186714172)
[2024-12-14 23:55:31,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:32,211][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.6731777191162109, acc: 0.8148148059844971)
[2024-12-14 23:55:32,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:32,585][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.5503884553909302, acc: 0.8399999737739563)
[2024-12-14 23:55:32,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:32,991][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.5785835385322571, acc: 0.7777777910232544)
[2024-12-14 23:55:33,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:33,358][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.664352297782898, acc: 0.7777777910232544)
[2024-12-14 23:55:33,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:33,762][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.459595263004303, acc: 0.8846153616905212)
[2024-12-14 23:55:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:34,157][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.9654950499534607, acc: 0.7241379022598267)
[2024-12-14 23:55:34,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:34,509][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.4743606448173523, acc: 0.8214285969734192)
[2024-12-14 23:55:34,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:34,929][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.533196210861206, acc: 0.8333333134651184)
[2024-12-14 23:55:35,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:35,304][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.5855317711830139, acc: 0.7878788113594055)
[2024-12-14 23:55:35,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:35,637][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.49535802006721497, acc: 0.8181818127632141)
[2024-12-14 23:55:35,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:35,998][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 1.1644245386123657, acc: 0.6666666865348816)
[2024-12-14 23:55:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:36,423][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 1.1838103532791138, acc: 0.692307710647583)
[2024-12-14 23:55:37,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:37,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:37,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:38,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:38,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:38,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:39,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:39,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:40,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:40,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:40,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:41,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:41,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:42,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:42,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:43,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:43,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:43,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:44,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:44,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:44,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:45,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:47,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:47,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:47,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:49,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:49,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:50,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:50,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:50,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:51,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:51,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:52,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:52,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:52,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:53,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:53,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:53,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:54,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:54,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:55,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:55,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:55,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:56,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:56,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:56,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:57,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:57,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:57,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:58,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:58,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:59,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:55:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:00,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:00,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:00,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:01,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:01,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:02,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:02,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:03,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:03,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:03,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:04,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:04,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:04,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:05,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:05,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:05,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:06,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:06,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:06,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:07,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:07,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:08,060][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.0689, device='cuda:0') eval_epoch_loss=tensor(2.0880, device='cuda:0') eval_epoch_acc=tensor(0.5300, device='cuda:0')
[2024-12-14 23:56:08,061][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:56:08,062][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:56:08,747][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_7_step_417_loss_2.088012218475342/model.pt
[2024-12-14 23:56:08,751][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:56:08,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:09,159][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.9823668003082275, acc: 0.5555555820465088)
[2024-12-14 23:56:09,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:09,637][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 1.0546320676803589, acc: 0.625)
[2024-12-14 23:56:09,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:10,023][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.8844792246818542, acc: 0.75)
[2024-12-14 23:56:10,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:10,386][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.4775586426258087, acc: 0.761904776096344)
[2024-12-14 23:56:10,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:10,720][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.6971489191055298, acc: 0.800000011920929)
[2024-12-14 23:56:10,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:11,075][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.6063998937606812, acc: 0.78125)
[2024-12-14 23:56:11,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:11,428][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.7612974047660828, acc: 0.75)
[2024-12-14 23:56:11,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:11,842][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.6824180483818054, acc: 0.6666666865348816)
[2024-12-14 23:56:11,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:12,181][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.8576210737228394, acc: 0.7878788113594055)
[2024-12-14 23:56:12,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:12,566][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 1.383178949356079, acc: 0.739130437374115)
[2024-12-14 23:56:12,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:12,955][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 1.0906895399093628, acc: 0.6756756901741028)
[2024-12-14 23:56:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:13,417][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.7370496392250061, acc: 0.7407407164573669)
[2024-12-14 23:56:13,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:13,781][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.7777019739151001, acc: 0.6521739363670349)
[2024-12-14 23:56:13,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:14,191][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.4234797954559326, acc: 0.8518518805503845)
[2024-12-14 23:56:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:14,576][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.5431662201881409, acc: 0.7777777910232544)
[2024-12-14 23:56:14,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:14,950][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.6490973234176636, acc: 0.782608687877655)
[2024-12-14 23:56:15,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:15,396][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.8241063356399536, acc: 0.6666666865348816)
[2024-12-14 23:56:15,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:15,770][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.6948891282081604, acc: 0.7599999904632568)
[2024-12-14 23:56:15,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:16,145][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.727007269859314, acc: 0.7575757503509521)
[2024-12-14 23:56:16,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:16,540][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.9124966859817505, acc: 0.7222222089767456)
[2024-12-14 23:56:16,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:16,917][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.7438730597496033, acc: 0.7727272510528564)
[2024-12-14 23:56:17,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:17,274][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.38767877221107483, acc: 0.8571428656578064)
[2024-12-14 23:56:17,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:17,634][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.9681053161621094, acc: 0.7179487347602844)
[2024-12-14 23:56:17,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:18,151][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 1.2468417882919312, acc: 0.6363636255264282)
[2024-12-14 23:56:18,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:18,906][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 2.1656343936920166, acc: 0.4320000112056732)
[2024-12-14 23:56:19,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:19,382][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 1.7875910997390747, acc: 0.5)
[2024-12-14 23:56:19,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:20,072][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 1.8271920680999756, acc: 0.5223880410194397)
[2024-12-14 23:56:20,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:20,480][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 1.12885582447052, acc: 0.6792452931404114)
[2024-12-14 23:56:20,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:20,931][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.6653330326080322, acc: 0.8409090638160706)
[2024-12-14 23:56:21,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:21,357][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.8499990701675415, acc: 0.739130437374115)
[2024-12-14 23:56:21,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:21,723][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.8323191404342651, acc: 0.692307710647583)
[2024-12-14 23:56:21,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:22,145][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.7494798898696899, acc: 0.75)
[2024-12-14 23:56:22,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:22,527][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 1.3341598510742188, acc: 0.611940324306488)
[2024-12-14 23:56:22,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:22,968][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 1.0771832466125488, acc: 0.7083333134651184)
[2024-12-14 23:56:23,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:23,413][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 1.0440409183502197, acc: 0.6630434989929199)
[2024-12-14 23:56:23,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:23,784][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 1.195644736289978, acc: 0.6025640964508057)
[2024-12-14 23:56:23,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:24,242][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 1.117110252380371, acc: 0.6315789222717285)
[2024-12-14 23:56:24,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:24,632][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 1.0876168012619019, acc: 0.6938775777816772)
[2024-12-14 23:56:24,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:25,039][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.5805447101593018, acc: 0.7878788113594055)
[2024-12-14 23:56:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:25,434][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 1.6698100566864014, acc: 0.4845360815525055)
[2024-12-14 23:56:25,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:25,835][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 1.1206241846084595, acc: 0.6857143044471741)
[2024-12-14 23:56:25,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:26,252][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 1.5621367692947388, acc: 0.569767415523529)
[2024-12-14 23:56:26,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:26,621][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.9853933453559875, acc: 0.7142857313156128)
[2024-12-14 23:56:26,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:26,995][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 1.37465500831604, acc: 0.5802469253540039)
[2024-12-14 23:56:27,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:27,348][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.8532187938690186, acc: 0.75)
[2024-12-14 23:56:27,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:27,707][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.575114905834198, acc: 0.78125)
[2024-12-14 23:56:27,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:28,085][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.7632723450660706, acc: 0.7307692170143127)
[2024-12-14 23:56:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:28,472][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.5895211696624756, acc: 0.8260869383811951)
[2024-12-14 23:56:28,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:28,846][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 1.1685820817947388, acc: 0.5952380895614624)
[2024-12-14 23:56:28,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:29,217][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 1.2457048892974854, acc: 0.6385542154312134)
[2024-12-14 23:56:29,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:29,669][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 1.1049762964248657, acc: 0.6486486196517944)
[2024-12-14 23:56:29,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:30,070][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 1.3073066473007202, acc: 0.6019417643547058)
[2024-12-14 23:56:30,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:30,435][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 1.1480207443237305, acc: 0.6829268336296082)
[2024-12-14 23:56:30,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:30,791][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.8086004853248596, acc: 0.7083333134651184)
[2024-12-14 23:56:30,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:31,163][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.7477731704711914, acc: 0.8214285969734192)
[2024-12-14 23:56:31,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:31,603][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 1.4792400598526, acc: 0.529411792755127)
[2024-12-14 23:56:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:31,986][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 1.8380149602890015, acc: 0.4628821015357971)
[2024-12-14 23:56:32,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:32,358][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 1.3226256370544434, acc: 0.625)
[2024-12-14 23:56:32,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:32,759][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 1.7161139249801636, acc: 0.47852760553359985)
[2024-12-14 23:56:32,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:33,145][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 1.5122987031936646, acc: 0.6115108132362366)
[2024-12-14 23:56:33,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:33,515][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 1.8615115880966187, acc: 0.4422110617160797)
[2024-12-14 23:56:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:33,923][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.6021288633346558, acc: 0.8055555820465088)
[2024-12-14 23:56:34,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:34,296][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.7164746522903442, acc: 0.7575757503509521)
[2024-12-14 23:56:34,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:34,682][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.6897010803222656, acc: 0.8148148059844971)
[2024-12-14 23:56:34,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:35,044][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 1.0582774877548218, acc: 0.6000000238418579)
[2024-12-14 23:56:35,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:35,384][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.737011194229126, acc: 0.75)
[2024-12-14 23:56:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:35,793][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.8894582986831665, acc: 0.7068965435028076)
[2024-12-14 23:56:35,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:36,163][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.5233261585235596, acc: 0.8387096524238586)
[2024-12-14 23:56:36,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:36,586][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.49248775839805603, acc: 0.8421052694320679)
[2024-12-14 23:56:36,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:36,959][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.9877283573150635, acc: 0.6296296119689941)
[2024-12-14 23:56:37,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:37,306][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.855733335018158, acc: 0.7142857313156128)
[2024-12-14 23:56:37,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:37,665][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.8509790301322937, acc: 0.6818181872367859)
[2024-12-14 23:56:37,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:38,045][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 1.2174944877624512, acc: 0.6615384817123413)
[2024-12-14 23:56:38,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:38,413][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.7766711115837097, acc: 0.699999988079071)
[2024-12-14 23:56:38,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:38,787][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.8389925956726074, acc: 0.7241379022598267)
[2024-12-14 23:56:38,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:39,206][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.9553931951522827, acc: 0.7450980544090271)
[2024-12-14 23:56:39,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:39,577][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 1.197914481163025, acc: 0.6206896305084229)
[2024-12-14 23:56:39,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:39,921][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.5034641623497009, acc: 0.8421052694320679)
[2024-12-14 23:56:40,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:40,272][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.9279006123542786, acc: 0.6842105388641357)
[2024-12-14 23:56:40,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:40,660][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 1.28031325340271, acc: 0.625)
[2024-12-14 23:56:40,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:41,074][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 1.3183521032333374, acc: 0.6404494643211365)
[2024-12-14 23:56:41,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:41,435][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 1.509387731552124, acc: 0.5955055952072144)
[2024-12-14 23:56:41,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:41,812][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 1.7696243524551392, acc: 0.5106382966041565)
[2024-12-14 23:56:41,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:42,191][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 1.4300936460494995, acc: 0.5978260636329651)
[2024-12-14 23:56:42,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:42,582][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.595969557762146, acc: 0.8399999737739563)
[2024-12-14 23:56:42,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:42,957][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.5531921982765198, acc: 0.7692307829856873)
[2024-12-14 23:56:43,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:43,315][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.8413898348808289, acc: 0.7037037014961243)
[2024-12-14 23:56:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:43,681][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.8662430644035339, acc: 0.6666666865348816)
[2024-12-14 23:56:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:44,052][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 1.0238122940063477, acc: 0.7169811129570007)
[2024-12-14 23:56:44,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:44,391][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.500261127948761, acc: 0.8275862336158752)
[2024-12-14 23:56:44,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:44,997][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 1.4879587888717651, acc: 0.5585585832595825)
[2024-12-14 23:56:45,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:45,484][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 1.2360625267028809, acc: 0.6338028311729431)
[2024-12-14 23:56:45,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:45,912][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.54942786693573, acc: 0.800000011920929)
[2024-12-14 23:56:46,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:46,306][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.4218851625919342, acc: 0.8666666746139526)
[2024-12-14 23:56:46,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:46,674][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.78030925989151, acc: 0.7692307829856873)
[2024-12-14 23:56:48,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:49,187][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 1.7069547176361084, acc: 0.5214285850524902)
[2024-12-14 23:56:49,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:49,972][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 1.4857155084609985, acc: 0.579365074634552)
[2024-12-14 23:56:50,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:50,376][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.7149551510810852, acc: 0.7142857313156128)
[2024-12-14 23:56:50,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:50,758][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.9952453970909119, acc: 0.699999988079071)
[2024-12-14 23:56:51,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:51,470][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.9707848429679871, acc: 0.7083333134651184)
[2024-12-14 23:56:51,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:51,841][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.5711110234260559, acc: 0.692307710647583)
[2024-12-14 23:56:51,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:52,207][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.7862481474876404, acc: 0.774193525314331)
[2024-12-14 23:56:52,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:52,606][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.9918457269668579, acc: 0.699999988079071)
[2024-12-14 23:56:52,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:52,993][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.700778067111969, acc: 0.7037037014961243)
[2024-12-14 23:56:53,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:54,011][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 1.857040286064148, acc: 0.4788135588169098)
[2024-12-14 23:56:54,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:54,403][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 1.5907505750656128, acc: 0.5522388219833374)
[2024-12-14 23:56:54,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:54,791][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 1.570304274559021, acc: 0.55474454164505)
[2024-12-14 23:56:54,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:55,382][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 1.6094509363174438, acc: 0.5649999976158142)
[2024-12-14 23:56:55,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:55,754][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 1.0783156156539917, acc: 0.5925925970077515)
[2024-12-14 23:56:55,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:56,105][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.8736067414283752, acc: 0.7115384340286255)
[2024-12-14 23:56:56,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:56,445][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.8818964958190918, acc: 0.761904776096344)
[2024-12-14 23:56:56,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:56,823][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 1.2459732294082642, acc: 0.688524603843689)
[2024-12-14 23:56:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:57,188][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.9559021592140198, acc: 0.694915235042572)
[2024-12-14 23:56:57,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:57,624][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 1.0833966732025146, acc: 0.6744186282157898)
[2024-12-14 23:56:57,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:58,015][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.8895955681800842, acc: 0.7272727489471436)
[2024-12-14 23:56:58,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:58,379][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.8168041110038757, acc: 0.7169811129570007)
[2024-12-14 23:56:58,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:58,735][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.6415801048278809, acc: 0.8636363744735718)
[2024-12-14 23:56:58,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:59,066][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.8799564838409424, acc: 0.7200000286102295)
[2024-12-14 23:56:59,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:59,448][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.660529375076294, acc: 0.800000011920929)
[2024-12-14 23:56:59,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:56:59,799][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.6551035046577454, acc: 0.8181818127632141)
[2024-12-14 23:56:59,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:00,239][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 1.1600472927093506, acc: 0.6307692527770996)
[2024-12-14 23:57:00,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:00,624][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 1.0022341012954712, acc: 0.71875)
[2024-12-14 23:57:00,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:01,057][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.7456501722335815, acc: 0.8125)
[2024-12-14 23:57:01,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:01,406][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.8066093325614929, acc: 0.6969696879386902)
[2024-12-14 23:57:01,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:01,754][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.7201883792877197, acc: 0.8125)
[2024-12-14 23:57:01,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:02,176][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.35214734077453613, acc: 0.8387096524238586)
[2024-12-14 23:57:02,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:02,563][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.43941518664360046, acc: 0.9130434989929199)
[2024-12-14 23:57:02,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:02,939][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.6148388385772705, acc: 0.7666666507720947)
[2024-12-14 23:57:03,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:03,299][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.819962203502655, acc: 0.7317073345184326)
[2024-12-14 23:57:03,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:03,658][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.5348211526870728, acc: 0.800000011920929)
[2024-12-14 23:57:03,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:04,068][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.6161077618598938, acc: 0.8421052694320679)
[2024-12-14 23:57:04,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:04,417][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.5072617530822754, acc: 0.8387096524238586)
[2024-12-14 23:57:04,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:04,765][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.33679312467575073, acc: 0.9200000166893005)
[2024-12-14 23:57:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:05,174][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.4422711730003357, acc: 0.8484848737716675)
[2024-12-14 23:57:05,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:05,501][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.5880621671676636, acc: 0.824999988079071)
[2024-12-14 23:57:05,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:05,866][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.6035716533660889, acc: 0.8142856955528259)
[2024-12-14 23:57:05,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:06,231][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 1.5775079727172852, acc: 0.5474452376365662)
[2024-12-14 23:57:06,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:06,587][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 1.2113826274871826, acc: 0.6551724076271057)
[2024-12-14 23:57:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:06,955][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 1.868979573249817, acc: 0.5)
[2024-12-14 23:57:07,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:07,328][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 1.6832395792007446, acc: 0.49668875336647034)
[2024-12-14 23:57:07,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:07,671][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 1.386907935142517, acc: 0.5897436141967773)
[2024-12-14 23:57:07,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:08,009][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.37298595905303955, acc: 0.9200000166893005)
[2024-12-14 23:57:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:08,387][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.6927773356437683, acc: 0.807692289352417)
[2024-12-14 23:57:09,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:09,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:09,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:10,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:10,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:10,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:10,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:11,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:11,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:12,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:12,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:12,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:13,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:13,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:14,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:14,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:15,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:15,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:15,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:15,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:16,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:17,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:17,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:17,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:18,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:18,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:19,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:19,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:19,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:20,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:20,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:21,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:21,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:21,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:22,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:22,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:23,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:23,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:23,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:24,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:24,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:25,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:25,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:25,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:26,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:26,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:26,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:27,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:27,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:27,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:29,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:29,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:30,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:30,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:30,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:31,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:31,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:32,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:32,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:33,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:33,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:33,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:34,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:34,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:35,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:35,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:35,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:36,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:36,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:36,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:37,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:37,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:38,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:38,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:38,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:39,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:39,878][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.2208, device='cuda:0') eval_epoch_loss=tensor(2.1067, device='cuda:0') eval_epoch_acc=tensor(0.5035, device='cuda:0')
[2024-12-14 23:57:39,880][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:57:39,880][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:57:40,551][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_7_step_560_loss_2.1066689491271973/model.pt
[2024-12-14 23:57:40,557][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:57:40,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:40,965][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.5120266079902649, acc: 0.8461538553237915)
[2024-12-14 23:57:41,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:41,317][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.895574688911438, acc: 0.7692307829856873)
[2024-12-14 23:57:41,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:41,688][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 1.1939610242843628, acc: 0.6333333253860474)
[2024-12-14 23:57:41,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:42,040][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 1.1919913291931152, acc: 0.6103895902633667)
[2024-12-14 23:57:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:42,413][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.912303626537323, acc: 0.7083333134651184)
[2024-12-14 23:57:42,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:42,816][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.7580898404121399, acc: 0.8275862336158752)
[2024-12-14 23:57:42,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:43,196][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 1.3199115991592407, acc: 0.6309523582458496)
[2024-12-14 23:57:43,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:43,623][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.6381497383117676, acc: 0.8157894611358643)
[2024-12-14 23:57:43,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:44,002][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.5357773900032043, acc: 0.8148148059844971)
[2024-12-14 23:57:44,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:44,447][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 1.5883533954620361, acc: 0.5347593426704407)
[2024-12-14 23:57:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:44,815][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 1.0070157051086426, acc: 0.6935483813285828)
[2024-12-14 23:57:44,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:45,236][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 1.2665443420410156, acc: 0.6153846383094788)
[2024-12-14 23:57:45,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:45,622][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 1.7213358879089355, acc: 0.4948979616165161)
[2024-12-14 23:57:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:46,023][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 1.7113735675811768, acc: 0.49685534834861755)
[2024-12-14 23:57:46,440][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=2.9149, train_epoch_loss=1.0698, epoch time 378.8756884499453s
[2024-12-14 23:57:46,441][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-14 23:57:46,441][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-12-14 23:57:46,441][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-14 23:57:46,441][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 21
[2024-12-14 23:57:46,441][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-14 23:57:47,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:47,361][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.9777461886405945, acc: 0.7407407164573669)
[2024-12-14 23:57:47,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:47,744][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.9190865159034729, acc: 0.6800000071525574)
[2024-12-14 23:57:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:48,125][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.9514299631118774, acc: 0.7567567825317383)
[2024-12-14 23:57:48,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:48,499][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.9896530508995056, acc: 0.6842105388641357)
[2024-12-14 23:57:48,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:48,888][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.8071433901786804, acc: 0.7297297120094299)
[2024-12-14 23:57:48,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:49,258][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.8611717224121094, acc: 0.6785714030265808)
[2024-12-14 23:57:49,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:49,640][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.976847767829895, acc: 0.6530612111091614)
[2024-12-14 23:57:49,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:49,995][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.8112502694129944, acc: 0.7333333492279053)
[2024-12-14 23:57:50,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:50,370][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.265085369348526, acc: 0.9545454382896423)
[2024-12-14 23:57:50,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:50,703][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.3843969702720642, acc: 0.8846153616905212)
[2024-12-14 23:57:50,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:51,060][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.5967791676521301, acc: 0.8148148059844971)
[2024-12-14 23:57:51,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:51,420][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.8205787539482117, acc: 0.7435897588729858)
[2024-12-14 23:57:51,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:51,768][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.6714434027671814, acc: 0.8181818127632141)
[2024-12-14 23:57:51,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:52,184][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.761888861656189, acc: 0.782608687877655)
[2024-12-14 23:57:52,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:52,584][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 1.1603143215179443, acc: 0.6666666865348816)
[2024-12-14 23:57:52,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:53,029][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.9021292924880981, acc: 0.6734693646430969)
[2024-12-14 23:57:53,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:53,494][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.44089075922966003, acc: 0.8947368264198303)
[2024-12-14 23:57:53,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:53,884][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.7719950079917908, acc: 0.75)
[2024-12-14 23:57:53,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:54,260][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.7325741648674011, acc: 0.7777777910232544)
[2024-12-14 23:57:54,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:54,636][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.6654565930366516, acc: 0.7894737124443054)
[2024-12-14 23:57:54,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:55,009][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.9375158548355103, acc: 0.7692307829856873)
[2024-12-14 23:57:55,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:55,361][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.7865076661109924, acc: 0.7931034564971924)
[2024-12-14 23:57:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:55,733][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.7570046186447144, acc: 0.6800000071525574)
[2024-12-14 23:57:55,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:56,124][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.5821540951728821, acc: 0.761904776096344)
[2024-12-14 23:57:56,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:56,505][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.8073094487190247, acc: 0.625)
[2024-12-14 23:57:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:56,910][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 1.046523094177246, acc: 0.6415094137191772)
[2024-12-14 23:57:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:57,256][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 1.3707340955734253, acc: 0.6027397513389587)
[2024-12-14 23:57:57,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:58,454][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 1.9256559610366821, acc: 0.4584980309009552)
[2024-12-14 23:57:58,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:58,801][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.7777765989303589, acc: 0.7906976938247681)
[2024-12-14 23:57:58,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:59,251][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 1.1189388036727905, acc: 0.7228915691375732)
[2024-12-14 23:57:59,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:57:59,678][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 1.1756504774093628, acc: 0.6419752836227417)
[2024-12-14 23:57:59,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:00,126][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.5145836472511292, acc: 0.9285714030265808)
[2024-12-14 23:58:00,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:00,517][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 1.2600969076156616, acc: 0.6296296119689941)
[2024-12-14 23:58:00,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:00,901][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.5506781935691833, acc: 0.8260869383811951)
[2024-12-14 23:58:01,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:01,277][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 1.539110541343689, acc: 0.5378151535987854)
[2024-12-14 23:58:01,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:01,635][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 1.0841717720031738, acc: 0.6721311211585999)
[2024-12-14 23:58:01,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:02,014][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 1.3803719282150269, acc: 0.5873016119003296)
[2024-12-14 23:58:02,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:02,378][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 1.5552821159362793, acc: 0.49152541160583496)
[2024-12-14 23:58:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:02,768][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 1.1839419603347778, acc: 0.5977011322975159)
[2024-12-14 23:58:02,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:03,122][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.4784200191497803, acc: 0.8571428656578064)
[2024-12-14 23:58:03,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:03,468][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.8200413584709167, acc: 0.7692307829856873)
[2024-12-14 23:58:03,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:03,894][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 1.567825436592102, acc: 0.5540540814399719)
[2024-12-14 23:58:04,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:04,382][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 1.337186574935913, acc: 0.6153846383094788)
[2024-12-14 23:58:04,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:04,837][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 1.6081371307373047, acc: 0.5858585834503174)
[2024-12-14 23:58:04,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:05,297][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 1.2790676355361938, acc: 0.6494845151901245)
[2024-12-14 23:58:05,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:05,750][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 1.5237890481948853, acc: 0.5661764740943909)
[2024-12-14 23:58:05,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:06,144][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.6011189818382263, acc: 0.807692289352417)
[2024-12-14 23:58:06,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:06,524][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.39719638228416443, acc: 0.8888888955116272)
[2024-12-14 23:58:06,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:06,917][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.8906534314155579, acc: 0.7142857313156128)
[2024-12-14 23:58:07,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:07,352][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.6902516484260559, acc: 0.7222222089767456)
[2024-12-14 23:58:07,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:07,783][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.7864015102386475, acc: 0.8070175647735596)
[2024-12-14 23:58:07,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:08,200][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 1.0709788799285889, acc: 0.6984127163887024)
[2024-12-14 23:58:08,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:08,621][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 1.231169581413269, acc: 0.6619718074798584)
[2024-12-14 23:58:08,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:09,135][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 1.6566615104675293, acc: 0.5333333611488342)
[2024-12-14 23:58:09,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:09,494][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.7041351199150085, acc: 0.7837837934494019)
[2024-12-14 23:58:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:09,832][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.41911810636520386, acc: 0.807692289352417)
[2024-12-14 23:58:11,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:12,736][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 1.6981182098388672, acc: 0.5187713503837585)
[2024-12-14 23:58:13,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:13,943][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 2.2006664276123047, acc: 0.42047929763793945)
[2024-12-14 23:58:14,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:14,682][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 1.733249545097351, acc: 0.5227272510528564)
[2024-12-14 23:58:14,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:15,283][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 1.5508315563201904, acc: 0.5882353186607361)
[2024-12-14 23:58:15,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:15,871][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 1.87040376663208, acc: 0.43478259444236755)
[2024-12-14 23:58:15,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:16,341][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 1.4055103063583374, acc: 0.6499999761581421)
[2024-12-14 23:58:16,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:16,768][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.3246026635169983, acc: 0.8823529481887817)
[2024-12-14 23:58:16,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:17,178][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 1.1631627082824707, acc: 0.5833333134651184)
[2024-12-14 23:58:17,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:17,590][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.9081941843032837, acc: 0.734375)
[2024-12-14 23:58:17,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:18,012][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.5609455704689026, acc: 0.7931034564971924)
[2024-12-14 23:58:18,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:18,407][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.9529442191123962, acc: 0.75)
[2024-12-14 23:58:18,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:18,792][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 1.3706669807434082, acc: 0.6166666746139526)
[2024-12-14 23:58:18,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:19,201][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.3165734112262726, acc: 0.8399999737739563)
[2024-12-14 23:58:19,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:19,623][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.7145998477935791, acc: 0.8055555820465088)
[2024-12-14 23:58:19,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:20,005][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.8305424451828003, acc: 0.7575757503509521)
[2024-12-14 23:58:20,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:20,389][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 1.5315296649932861, acc: 0.595588207244873)
[2024-12-14 23:58:20,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:20,820][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 1.459937334060669, acc: 0.579365074634552)
[2024-12-14 23:58:20,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:21,241][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 1.9893769025802612, acc: 0.4871794879436493)
[2024-12-14 23:58:21,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:21,638][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 1.2980612516403198, acc: 0.6326530575752258)
[2024-12-14 23:58:21,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:22,027][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 1.9655035734176636, acc: 0.3805970251560211)
[2024-12-14 23:58:22,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:22,501][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 2.0752053260803223, acc: 0.47445255517959595)
[2024-12-14 23:58:22,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:22,913][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.3706175684928894, acc: 0.8571428656578064)
[2024-12-14 23:58:23,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:23,361][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.3845995366573334, acc: 0.875)
[2024-12-14 23:58:23,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:23,761][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.6596165895462036, acc: 0.8484848737716675)
[2024-12-14 23:58:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:24,139][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.5895601511001587, acc: 0.7692307829856873)
[2024-12-14 23:58:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:24,572][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.9342777729034424, acc: 0.7115384340286255)
[2024-12-14 23:58:24,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:24,974][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 1.1073263883590698, acc: 0.5961538553237915)
[2024-12-14 23:58:25,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:25,346][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.5783933401107788, acc: 0.78125)
[2024-12-14 23:58:25,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:25,753][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 1.1820781230926514, acc: 0.5797101259231567)
[2024-12-14 23:58:25,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:26,160][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.8666321635246277, acc: 0.7599999904632568)
[2024-12-14 23:58:26,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:26,553][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 1.1693570613861084, acc: 0.6086956262588501)
[2024-12-14 23:58:26,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:27,098][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 1.3472883701324463, acc: 0.6000000238418579)
[2024-12-14 23:58:27,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:27,519][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 1.1821023225784302, acc: 0.6601941585540771)
[2024-12-14 23:58:28,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:28,655][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 1.6093705892562866, acc: 0.5485436916351318)
[2024-12-14 23:58:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:29,504][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 1.7257665395736694, acc: 0.5483871102333069)
[2024-12-14 23:58:29,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:30,337][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 1.6043930053710938, acc: 0.5948275923728943)
[2024-12-14 23:58:30,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:31,107][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 1.11514413356781, acc: 0.6315789222717285)
[2024-12-14 23:58:31,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:32,127][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 1.6024727821350098, acc: 0.5346534848213196)
[2024-12-14 23:58:32,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:32,480][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 1.4724241495132446, acc: 0.5322580933570862)
[2024-12-14 23:58:32,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:32,883][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 1.2849482297897339, acc: 0.6086956262588501)
[2024-12-14 23:58:33,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:33,290][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 1.783762812614441, acc: 0.45378151535987854)
[2024-12-14 23:58:33,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:33,682][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 1.7254869937896729, acc: 0.5288461446762085)
[2024-12-14 23:58:33,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:34,105][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 1.7849235534667969, acc: 0.510948896408081)
[2024-12-14 23:58:34,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:34,459][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 1.275189757347107, acc: 0.5970149040222168)
[2024-12-14 23:58:34,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:34,823][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.5738584399223328, acc: 0.800000011920929)
[2024-12-14 23:58:34,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:35,225][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.6119133234024048, acc: 0.9090909361839294)
[2024-12-14 23:58:35,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:35,618][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.6864162087440491, acc: 0.782608687877655)
[2024-12-14 23:58:35,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:36,067][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.6273736357688904, acc: 0.7727272510528564)
[2024-12-14 23:58:36,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:36,485][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 1.1093478202819824, acc: 0.6896551847457886)
[2024-12-14 23:58:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:36,945][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.5542062520980835, acc: 0.8139534592628479)
[2024-12-14 23:58:37,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:37,404][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.9282229542732239, acc: 0.7599999904632568)
[2024-12-14 23:58:37,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:37,779][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.45295679569244385, acc: 0.8235294222831726)
[2024-12-14 23:58:37,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:38,085][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.4074842035770416, acc: 0.8846153616905212)
[2024-12-14 23:58:38,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:38,442][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.42749619483947754, acc: 0.9047619104385376)
[2024-12-14 23:58:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:38,822][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.7782103419303894, acc: 0.800000011920929)
[2024-12-14 23:58:38,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:39,278][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 1.0216559171676636, acc: 0.7017543911933899)
[2024-12-14 23:58:39,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:39,690][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.8509233593940735, acc: 0.7543859481811523)
[2024-12-14 23:58:39,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:40,082][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.7754063010215759, acc: 0.7692307829856873)
[2024-12-14 23:58:40,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:40,481][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.6839869022369385, acc: 0.795918345451355)
[2024-12-14 23:58:40,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:40,897][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.2588958442211151, acc: 0.9090909361839294)
[2024-12-14 23:58:41,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:41,271][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 1.1559886932373047, acc: 0.60317462682724)
[2024-12-14 23:58:41,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:41,627][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 1.356068730354309, acc: 0.6504064798355103)
[2024-12-14 23:58:41,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:41,988][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.6635363698005676, acc: 0.8548387289047241)
[2024-12-14 23:58:42,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:42,863][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 1.7244938611984253, acc: 0.5399239659309387)
[2024-12-14 23:58:42,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:43,263][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.9361385107040405, acc: 0.7333333492279053)
[2024-12-14 23:58:43,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:43,697][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.8524497151374817, acc: 0.7884615659713745)
[2024-12-14 23:58:43,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:44,060][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.3788832128047943, acc: 0.875)
[2024-12-14 23:58:44,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:44,444][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.9036656618118286, acc: 0.7368420958518982)
[2024-12-14 23:58:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:44,870][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 1.5808945894241333, acc: 0.5889570713043213)
[2024-12-14 23:58:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:45,276][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 1.3691821098327637, acc: 0.6180555820465088)
[2024-12-14 23:58:45,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:45,665][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 1.3901926279067993, acc: 0.5833333134651184)
[2024-12-14 23:58:45,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:46,070][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 1.6657212972640991, acc: 0.5)
[2024-12-14 23:58:46,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:46,502][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 1.5883598327636719, acc: 0.5384615659713745)
[2024-12-14 23:58:47,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:47,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:48,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:48,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:48,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:49,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:49,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:49,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:50,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:50,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:50,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:51,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:51,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:52,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:53,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:53,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:53,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:54,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:54,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:55,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:55,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:55,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:56,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:56,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:57,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:57,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:57,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:58,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:58,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:59,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:58:59,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:00,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:00,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:00,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:01,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:02,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:02,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:02,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:03,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:03,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:04,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:04,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:05,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:06,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:06,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:06,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:07,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:07,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:07,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:08,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:08,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:09,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:09,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:10,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:11,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:11,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:11,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:12,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:13,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:13,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:13,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:14,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:14,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:14,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:15,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:15,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:16,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:16,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:16,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:17,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:17,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:18,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:19,147][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.9955, device='cuda:0') eval_epoch_loss=tensor(2.0789, device='cuda:0') eval_epoch_acc=tensor(0.5285, device='cuda:0')
[2024-12-14 23:59:19,148][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-14 23:59:19,149][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-14 23:59:20,002][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_8_step_129_loss_2.078878879547119/model.pt
[2024-12-14 23:59:20,007][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-14 23:59:20,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:20,476][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 1.3980216979980469, acc: 0.6176470518112183)
[2024-12-14 23:59:20,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:20,859][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.6618418097496033, acc: 0.8846153616905212)
[2024-12-14 23:59:20,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:21,209][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.36752623319625854, acc: 0.8695651888847351)
[2024-12-14 23:59:21,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:21,592][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.6141315698623657, acc: 0.8125)
[2024-12-14 23:59:21,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:21,972][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.7106172442436218, acc: 0.782608687877655)
[2024-12-14 23:59:22,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:22,396][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.7489240765571594, acc: 0.7142857313156128)
[2024-12-14 23:59:22,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:22,780][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.50221848487854, acc: 0.807692289352417)
[2024-12-14 23:59:22,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:23,197][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.7590602040290833, acc: 0.7857142686843872)
[2024-12-14 23:59:23,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:23,587][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.7261793613433838, acc: 0.7333333492279053)
[2024-12-14 23:59:23,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:23,953][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.8724451661109924, acc: 0.695652186870575)
[2024-12-14 23:59:24,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:24,295][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.6325007081031799, acc: 0.8571428656578064)
[2024-12-14 23:59:24,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:24,662][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 1.148340106010437, acc: 0.6538461446762085)
[2024-12-14 23:59:24,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:25,028][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.8938424587249756, acc: 0.6774193644523621)
[2024-12-14 23:59:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:25,371][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.9192004799842834, acc: 0.7027027010917664)
[2024-12-14 23:59:25,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:25,928][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 1.648772120475769, acc: 0.48245614767074585)
[2024-12-14 23:59:26,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:26,301][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 1.2895522117614746, acc: 0.5895522236824036)
[2024-12-14 23:59:26,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:26,682][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 1.874846339225769, acc: 0.43877550959587097)
[2024-12-14 23:59:26,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:27,186][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 1.5765422582626343, acc: 0.542553186416626)
[2024-12-14 23:59:27,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:27,554][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 1.4080498218536377, acc: 0.6142857074737549)
[2024-12-14 23:59:27,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:27,901][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.5341629385948181, acc: 0.8571428656578064)
[2024-12-14 23:59:27,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:28,263][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 1.0159215927124023, acc: 0.739130437374115)
[2024-12-14 23:59:28,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:28,629][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.7532774806022644, acc: 0.7241379022598267)
[2024-12-14 23:59:28,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:28,985][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.868680477142334, acc: 0.717391312122345)
[2024-12-14 23:59:29,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:29,337][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 1.4094290733337402, acc: 0.5254237055778503)
[2024-12-14 23:59:29,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:29,701][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 1.168428659439087, acc: 0.5789473652839661)
[2024-12-14 23:59:29,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:30,072][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 1.2887800931930542, acc: 0.6216216087341309)
[2024-12-14 23:59:30,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:30,419][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.5216211676597595, acc: 0.8571428656578064)
[2024-12-14 23:59:30,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:30,773][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.7731645703315735, acc: 0.782608687877655)
[2024-12-14 23:59:30,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:31,110][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.7710973620414734, acc: 0.7368420958518982)
[2024-12-14 23:59:31,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:32,680][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 1.0214488506317139, acc: 0.6486486196517944)
[2024-12-14 23:59:32,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:33,073][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 1.4113478660583496, acc: 0.5740740895271301)
[2024-12-14 23:59:33,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:33,524][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 1.0512384176254272, acc: 0.6744186282157898)
[2024-12-14 23:59:33,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:34,160][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 1.0304906368255615, acc: 0.6705882549285889)
[2024-12-14 23:59:34,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:34,753][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 1.3851791620254517, acc: 0.6292135119438171)
[2024-12-14 23:59:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:35,195][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.7957447171211243, acc: 0.7727272510528564)
[2024-12-14 23:59:35,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:35,565][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 1.123796820640564, acc: 0.6190476417541504)
[2024-12-14 23:59:35,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:35,962][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.7308850288391113, acc: 0.7931034564971924)
[2024-12-14 23:59:36,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:36,323][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.7035577893257141, acc: 0.7755101919174194)
[2024-12-14 23:59:36,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:36,699][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.9271878004074097, acc: 0.6399999856948853)
[2024-12-14 23:59:36,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:37,119][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 1.0000100135803223, acc: 0.625)
[2024-12-14 23:59:37,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:37,507][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 1.1530498266220093, acc: 0.6666666865348816)
[2024-12-14 23:59:37,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:38,563][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 1.7247048616409302, acc: 0.5068492889404297)
[2024-12-14 23:59:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:38,898][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.6374933123588562, acc: 0.7916666865348816)
[2024-12-14 23:59:38,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:39,224][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.771430492401123, acc: 0.7037037014961243)
[2024-12-14 23:59:39,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:39,680][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.8165754079818726, acc: 0.7857142686843872)
[2024-12-14 23:59:39,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:40,267][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 1.1713491678237915, acc: 0.6725663542747498)
[2024-12-14 23:59:40,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:40,648][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 1.1047214269638062, acc: 0.695652186870575)
[2024-12-14 23:59:40,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:41,018][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 1.2722163200378418, acc: 0.6477272510528564)
[2024-12-14 23:59:41,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:41,955][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 2.021744966506958, acc: 0.3893129825592041)
[2024-12-14 23:59:42,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:42,665][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 1.7625830173492432, acc: 0.5333333611488342)
[2024-12-14 23:59:42,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:43,036][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 1.0753566026687622, acc: 0.688524603843689)
[2024-12-14 23:59:43,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:43,384][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.43872371315956116, acc: 0.9583333134651184)
[2024-12-14 23:59:43,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:43,741][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.6141021251678467, acc: 0.800000011920929)
[2024-12-14 23:59:43,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:44,070][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.6560356020927429, acc: 0.75)
[2024-12-14 23:59:44,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:44,414][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 1.3187525272369385, acc: 0.6097561120986938)
[2024-12-14 23:59:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:44,823][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 1.9106882810592651, acc: 0.4864048361778259)
[2024-12-14 23:59:44,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:45,199][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 2.02587890625, acc: 0.4755043089389801)
[2024-12-14 23:59:45,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:45,702][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 2.0783071517944336, acc: 0.45625001192092896)
[2024-12-14 23:59:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:46,252][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 2.007525682449341, acc: 0.4446529150009155)
[2024-12-14 23:59:46,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:46,678][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 1.8223876953125, acc: 0.49466192722320557)
[2024-12-14 23:59:46,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:47,039][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.9185052514076233, acc: 0.7599999904632568)
[2024-12-14 23:59:47,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:47,643][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 1.8214373588562012, acc: 0.5581395626068115)
[2024-12-14 23:59:47,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:48,465][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 1.6453845500946045, acc: 0.5714285969734192)
[2024-12-14 23:59:48,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:49,406][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 1.6297459602355957, acc: 0.5227272510528564)
[2024-12-14 23:59:49,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:50,183][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 1.320267915725708, acc: 0.6823529601097107)
[2024-12-14 23:59:50,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:51,280][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 1.411964774131775, acc: 0.6172839403152466)
[2024-12-14 23:59:51,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:52,255][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 1.0806158781051636, acc: 0.7096773982048035)
[2024-12-14 23:59:52,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:52,712][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.4180889129638672, acc: 0.8571428656578064)
[2024-12-14 23:59:52,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:53,094][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.8709834218025208, acc: 0.7250000238418579)
[2024-12-14 23:59:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:53,440][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 1.174163818359375, acc: 0.6617646813392639)
[2024-12-14 23:59:53,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:53,803][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 1.4086283445358276, acc: 0.5514705777168274)
[2024-12-14 23:59:53,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:54,175][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 1.422178030014038, acc: 0.5847457647323608)
[2024-12-14 23:59:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:54,493][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 1.513824462890625, acc: 0.5820895433425903)
[2024-12-14 23:59:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:54,870][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 1.5294214487075806, acc: 0.5728155374526978)
[2024-12-14 23:59:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:55,208][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 1.0707473754882812, acc: 0.6984127163887024)
[2024-12-14 23:59:55,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:55,581][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 1.0919883251190186, acc: 0.6483516693115234)
[2024-12-14 23:59:55,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:55,974][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 1.745701789855957, acc: 0.5246636867523193)
[2024-12-14 23:59:56,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:56,399][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 1.8163834810256958, acc: 0.5039370059967041)
[2024-12-14 23:59:56,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:56,787][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 1.6216952800750732, acc: 0.5474137663841248)
[2024-12-14 23:59:56,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:57,210][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 1.6899118423461914, acc: 0.5289855003356934)
[2024-12-14 23:59:57,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:57,617][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 1.8469130992889404, acc: 0.47081711888313293)
[2024-12-14 23:59:57,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:58,011][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 1.46739661693573, acc: 0.54347825050354)
[2024-12-14 23:59:58,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:58,338][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.5695265531539917, acc: 0.782608687877655)
[2024-12-14 23:59:58,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:58,747][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.8245331645011902, acc: 0.7142857313156128)
[2024-12-14 23:59:58,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:59,143][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.7343301177024841, acc: 0.7446808218955994)
[2024-12-14 23:59:59,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-14 23:59:59,859][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 1.150904893875122, acc: 0.6692307591438293)
[2024-12-14 23:59:59,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:00,213][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.9389172196388245, acc: 0.7432432174682617)
[2024-12-15 00:00:00,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:00,594][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.9855561256408691, acc: 0.7325581312179565)
[2024-12-15 00:00:00,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:01,167][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 1.1668978929519653, acc: 0.6576576828956604)
[2024-12-15 00:00:01,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:01,607][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 1.0183879137039185, acc: 0.6666666865348816)
[2024-12-15 00:00:01,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:01,977][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.4318060874938965, acc: 0.8787878751754761)
[2024-12-15 00:00:02,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:02,345][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.30943068861961365, acc: 0.8518518805503845)
[2024-12-15 00:00:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:02,707][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.5001922249794006, acc: 0.7599999904632568)
[2024-12-15 00:00:02,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:03,070][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.6628366708755493, acc: 0.7692307829856873)
[2024-12-15 00:00:03,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:03,852][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 1.0981491804122925, acc: 0.6521739363670349)
[2024-12-15 00:00:04,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:04,420][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 1.513139247894287, acc: 0.5852272510528564)
[2024-12-15 00:00:04,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:04,900][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 1.3211933374404907, acc: 0.563829779624939)
[2024-12-15 00:00:05,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:05,283][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.8128592371940613, acc: 0.7169811129570007)
[2024-12-15 00:00:05,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:05,679][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.9402635097503662, acc: 0.75)
[2024-12-15 00:00:05,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:06,077][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.521605372428894, acc: 0.8837209343910217)
[2024-12-15 00:00:06,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:06,444][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.6620388627052307, acc: 0.7333333492279053)
[2024-12-15 00:00:06,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:06,851][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 1.3180794715881348, acc: 0.6105263233184814)
[2024-12-15 00:00:06,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:07,218][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.9874162673950195, acc: 0.699999988079071)
[2024-12-15 00:00:07,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:07,677][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 1.0485790967941284, acc: 0.7111111283302307)
[2024-12-15 00:00:07,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:08,198][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.3505977392196655, acc: 0.6192660331726074)
[2024-12-15 00:00:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:08,730][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 1.0570522546768188, acc: 0.7230769395828247)
[2024-12-15 00:00:08,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:09,111][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.8076031804084778, acc: 0.6315789222717285)
[2024-12-15 00:00:09,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:09,458][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.6337398886680603, acc: 0.8333333134651184)
[2024-12-15 00:00:09,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:09,814][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 1.067595362663269, acc: 0.6818181872367859)
[2024-12-15 00:00:09,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:10,215][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.6871945261955261, acc: 0.7407407164573669)
[2024-12-15 00:00:10,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:10,634][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.5001555681228638, acc: 0.8857142925262451)
[2024-12-15 00:00:10,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:11,029][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.6528022289276123, acc: 0.7727272510528564)
[2024-12-15 00:00:11,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:11,375][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.7069554924964905, acc: 0.7954545617103577)
[2024-12-15 00:00:11,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:11,986][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 1.0076950788497925, acc: 0.6451612710952759)
[2024-12-15 00:00:12,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:12,560][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.7450252771377563, acc: 0.75)
[2024-12-15 00:00:12,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:12,909][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.41699928045272827, acc: 0.8571428656578064)
[2024-12-15 00:00:13,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:13,268][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.5868328809738159, acc: 0.7692307829856873)
[2024-12-15 00:00:13,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:13,709][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.5744912624359131, acc: 0.8387096524238586)
[2024-12-15 00:00:13,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:14,084][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.39878588914871216, acc: 0.800000011920929)
[2024-12-15 00:00:14,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:14,531][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.5624831914901733, acc: 0.837837815284729)
[2024-12-15 00:00:14,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:14,893][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.7218220829963684, acc: 0.7567567825317383)
[2024-12-15 00:00:15,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:15,290][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.4870980679988861, acc: 0.8648648858070374)
[2024-12-15 00:00:15,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:15,672][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 1.0530129671096802, acc: 0.6764705777168274)
[2024-12-15 00:00:15,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:16,049][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.6457230448722839, acc: 0.7804877758026123)
[2024-12-15 00:00:16,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:16,460][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.3670511543750763, acc: 0.8799999952316284)
[2024-12-15 00:00:16,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:16,905][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.28077059984207153, acc: 0.8799999952316284)
[2024-12-15 00:00:17,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:17,281][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.31344074010849, acc: 0.9032257795333862)
[2024-12-15 00:00:17,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:17,647][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.8051024079322815, acc: 0.7368420958518982)
[2024-12-15 00:00:17,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:17,952][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.9373729228973389, acc: 0.7142857313156128)
[2024-12-15 00:00:18,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:18,331][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 1.1312557458877563, acc: 0.6973684430122375)
[2024-12-15 00:00:18,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:18,920][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 1.253166913986206, acc: 0.5943396091461182)
[2024-12-15 00:00:19,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:19,525][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 1.4499833583831787, acc: 0.5916666388511658)
[2024-12-15 00:00:19,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:19,868][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.7409937977790833, acc: 0.7222222089767456)
[2024-12-15 00:00:20,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:20,284][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.8676590919494629, acc: 0.8064516186714172)
[2024-12-15 00:00:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:20,670][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 1.459905743598938, acc: 0.5866666436195374)
[2024-12-15 00:00:20,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:21,048][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.898726761341095, acc: 0.7708333134651184)
[2024-12-15 00:00:21,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:21,893][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 2.0382239818573, acc: 0.4000000059604645)
[2024-12-15 00:00:21,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:22,265][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 1.5905722379684448, acc: 0.516853928565979)
[2024-12-15 00:00:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:22,664][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 1.5281964540481567, acc: 0.6081081032752991)
[2024-12-15 00:00:22,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:23,178][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.9788562059402466, acc: 0.7241379022598267)
[2024-12-15 00:00:23,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:23,559][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.5386376976966858, acc: 0.8636363744735718)
[2024-12-15 00:00:23,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:23,926][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.7212669849395752, acc: 0.7272727489471436)
[2024-12-15 00:00:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:24,267][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.5058426260948181, acc: 0.84375)
[2024-12-15 00:00:25,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:25,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:26,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:26,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:26,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:27,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:27,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:28,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:28,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:28,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:29,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:29,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:29,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:30,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:30,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:31,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:31,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:31,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:32,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:32,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:32,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:33,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:33,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:33,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:34,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:34,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:35,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:35,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:35,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:36,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:36,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:37,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:37,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:38,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:38,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:38,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:38,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:39,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:39,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:40,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:40,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:40,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:41,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:41,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:42,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:42,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:42,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:43,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:43,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:44,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:44,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:44,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:45,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:45,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:46,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:46,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:46,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:46,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:47,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:47,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:48,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:48,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:49,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:49,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:49,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:50,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:50,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:51,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:51,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:51,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:52,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:52,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:52,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:53,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:53,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:53,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:54,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:54,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:54,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:55,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:55,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:56,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:56,779][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.1324, device='cuda:0') eval_epoch_loss=tensor(1.9647, device='cuda:0') eval_epoch_acc=tensor(0.5218, device='cuda:0')
[2024-12-15 00:00:56,781][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:00:56,781][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:00:57,833][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_8_step_272_loss_1.964653730392456/model.pt
[2024-12-15 00:00:57,845][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:00:58,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:58,365][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.6863092184066772, acc: 0.8333333134651184)
[2024-12-15 00:00:58,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:58,780][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.9554921984672546, acc: 0.6333333253860474)
[2024-12-15 00:00:58,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:59,186][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.6713379621505737, acc: 0.84375)
[2024-12-15 00:00:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:59,576][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.5471121668815613, acc: 0.800000011920929)
[2024-12-15 00:00:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:00:59,952][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.67771977186203, acc: 0.7931034564971924)
[2024-12-15 00:01:00,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:00,329][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 1.2593424320220947, acc: 0.5600000023841858)
[2024-12-15 00:01:00,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:00,680][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.9214529395103455, acc: 0.7234042286872864)
[2024-12-15 00:01:00,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:01,046][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.8716690540313721, acc: 0.7083333134651184)
[2024-12-15 00:01:01,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:01,403][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.7846751809120178, acc: 0.7954545617103577)
[2024-12-15 00:01:01,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:01,854][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 1.1357356309890747, acc: 0.6265060305595398)
[2024-12-15 00:01:01,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:02,259][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 1.1735234260559082, acc: 0.6944444179534912)
[2024-12-15 00:01:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:02,632][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.5265491008758545, acc: 0.7631579041481018)
[2024-12-15 00:01:02,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:03,000][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.6985154151916504, acc: 0.7352941036224365)
[2024-12-15 00:01:03,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:03,361][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.29738935828208923, acc: 0.875)
[2024-12-15 00:01:03,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:03,781][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 1.4436678886413574, acc: 0.5703125)
[2024-12-15 00:01:03,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:04,148][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 1.4974699020385742, acc: 0.5759999752044678)
[2024-12-15 00:01:04,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:04,488][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 1.0684617757797241, acc: 0.6593406796455383)
[2024-12-15 00:01:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:04,863][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 1.6797164678573608, acc: 0.5652173757553101)
[2024-12-15 00:01:04,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:05,324][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 2.018244743347168, acc: 0.47422680258750916)
[2024-12-15 00:01:05,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:05,693][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.6400852799415588, acc: 0.7727272510528564)
[2024-12-15 00:01:05,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:06,026][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.9280329942703247, acc: 0.6904761791229248)
[2024-12-15 00:01:06,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:06,391][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.8409123420715332, acc: 0.7413793206214905)
[2024-12-15 00:01:06,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:06,923][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.6448470950126648, acc: 0.8363636136054993)
[2024-12-15 00:01:07,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:07,493][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 1.4591344594955444, acc: 0.5824742317199707)
[2024-12-15 00:01:07,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:07,870][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.9294666051864624, acc: 0.7068965435028076)
[2024-12-15 00:01:07,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:08,260][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.8776251673698425, acc: 0.7777777910232544)
[2024-12-15 00:01:08,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:08,633][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.8957471251487732, acc: 0.7105262875556946)
[2024-12-15 00:01:08,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:09,013][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.5439850091934204, acc: 0.8392857313156128)
[2024-12-15 00:01:09,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:09,448][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.7719259262084961, acc: 0.71875)
[2024-12-15 00:01:09,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:09,838][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.7302675843238831, acc: 0.8113207817077637)
[2024-12-15 00:01:09,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:10,201][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.5609874129295349, acc: 0.849056601524353)
[2024-12-15 00:01:10,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:10,573][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.7220374941825867, acc: 0.7352941036224365)
[2024-12-15 00:01:10,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:10,937][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.6805499792098999, acc: 0.75)
[2024-12-15 00:01:11,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:11,296][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.9039528369903564, acc: 0.7540983557701111)
[2024-12-15 00:01:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:11,647][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.5148937702178955, acc: 0.800000011920929)
[2024-12-15 00:01:11,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:11,992][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.5380727648735046, acc: 0.7894737124443054)
[2024-12-15 00:01:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:12,348][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 1.2347056865692139, acc: 0.5652173757553101)
[2024-12-15 00:01:12,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:12,800][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 1.057253122329712, acc: 0.7083333134651184)
[2024-12-15 00:01:12,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:13,211][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.9933332204818726, acc: 0.6626505851745605)
[2024-12-15 00:01:13,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:13,608][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 1.3380200862884521, acc: 0.6282051205635071)
[2024-12-15 00:01:13,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:13,995][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 1.2954000234603882, acc: 0.5918367505073547)
[2024-12-15 00:01:14,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:14,335][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.21180428564548492, acc: 0.9166666865348816)
[2024-12-15 00:01:14,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:14,690][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.44790855050086975, acc: 0.875)
[2024-12-15 00:01:14,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:15,086][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.6591363549232483, acc: 0.7419354915618896)
[2024-12-15 00:01:15,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:15,533][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.49887073040008545, acc: 0.8064516186714172)
[2024-12-15 00:01:15,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:15,918][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.9457348585128784, acc: 0.7014925479888916)
[2024-12-15 00:01:16,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:16,302][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 1.1913878917694092, acc: 0.6442307829856873)
[2024-12-15 00:01:16,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:16,675][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.8566633462905884, acc: 0.7333333492279053)
[2024-12-15 00:01:16,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:17,024][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.9619775414466858, acc: 0.7580645084381104)
[2024-12-15 00:01:17,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:17,392][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.6835862994194031, acc: 0.7599999904632568)
[2024-12-15 00:01:17,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:17,865][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 1.275860071182251, acc: 0.6296296119689941)
[2024-12-15 00:01:17,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:18,228][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 1.1230863332748413, acc: 0.6285714507102966)
[2024-12-15 00:01:18,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:18,598][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.8750312924385071, acc: 0.7179487347602844)
[2024-12-15 00:01:18,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:18,940][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.9541113376617432, acc: 0.6829268336296082)
[2024-12-15 00:01:19,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:19,285][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.9601868987083435, acc: 0.8157894611358643)
[2024-12-15 00:01:19,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:19,646][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.40074068307876587, acc: 0.8947368264198303)
[2024-12-15 00:01:19,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:20,023][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.25175684690475464, acc: 0.9285714030265808)
[2024-12-15 00:01:20,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:20,388][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.7263349890708923, acc: 0.7777777910232544)
[2024-12-15 00:01:20,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:20,775][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.6256087422370911, acc: 0.84375)
[2024-12-15 00:01:20,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:21,191][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.8585004210472107, acc: 0.7419354915618896)
[2024-12-15 00:01:21,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:21,603][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 1.0017673969268799, acc: 0.7719298005104065)
[2024-12-15 00:01:21,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:21,979][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 1.144097089767456, acc: 0.5625)
[2024-12-15 00:01:22,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:22,338][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.8217290043830872, acc: 0.7333333492279053)
[2024-12-15 00:01:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:22,676][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.6756650805473328, acc: 0.7894737124443054)
[2024-12-15 00:01:22,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:23,046][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.9567299485206604, acc: 0.7200000286102295)
[2024-12-15 00:01:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:23,510][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 1.4380191564559937, acc: 0.5632184147834778)
[2024-12-15 00:01:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:23,959][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 1.43738853931427, acc: 0.521276593208313)
[2024-12-15 00:01:24,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:24,321][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 1.5236917734146118, acc: 0.5060241222381592)
[2024-12-15 00:01:24,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:24,688][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.5439311265945435, acc: 0.8260869383811951)
[2024-12-15 00:01:24,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:25,050][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.6137157082557678, acc: 0.7692307829856873)
[2024-12-15 00:01:25,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:25,406][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.8835934400558472, acc: 0.7108433842658997)
[2024-12-15 00:01:25,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:25,769][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.9060533046722412, acc: 0.7924528121948242)
[2024-12-15 00:01:25,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:26,168][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.7672418355941772, acc: 0.7215189933776855)
[2024-12-15 00:01:26,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:26,566][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.6259302496910095, acc: 0.8039215803146362)
[2024-12-15 00:01:26,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:26,931][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 1.2298948764801025, acc: 0.6567164063453674)
[2024-12-15 00:01:27,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:27,287][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.4999402165412903, acc: 0.8999999761581421)
[2024-12-15 00:01:27,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:27,660][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.41884562373161316, acc: 0.8399999737739563)
[2024-12-15 00:01:27,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:28,084][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.705720841884613, acc: 0.7777777910232544)
[2024-12-15 00:01:28,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:28,448][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.9995496869087219, acc: 0.6511628031730652)
[2024-12-15 00:01:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:28,889][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.795771598815918, acc: 0.7692307829856873)
[2024-12-15 00:01:29,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:29,331][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.9063177108764648, acc: 0.7777777910232544)
[2024-12-15 00:01:29,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:29,717][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.5374594330787659, acc: 0.782608687877655)
[2024-12-15 00:01:29,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:30,033][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.6992707848548889, acc: 0.692307710647583)
[2024-12-15 00:01:30,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:30,408][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 1.5656293630599976, acc: 0.6153846383094788)
[2024-12-15 00:01:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:30,963][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 1.6512035131454468, acc: 0.5478261113166809)
[2024-12-15 00:01:31,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:31,358][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 1.2761768102645874, acc: 0.5869565010070801)
[2024-12-15 00:01:31,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:31,731][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 1.219832420349121, acc: 0.6734693646430969)
[2024-12-15 00:01:31,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:32,133][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.35023248195648193, acc: 0.875)
[2024-12-15 00:01:32,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:32,541][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.5284429788589478, acc: 0.807692289352417)
[2024-12-15 00:01:32,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:32,970][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.6951558589935303, acc: 0.7560975551605225)
[2024-12-15 00:01:33,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:33,356][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.6926521062850952, acc: 0.7777777910232544)
[2024-12-15 00:01:33,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:33,774][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 1.1043657064437866, acc: 0.6052631735801697)
[2024-12-15 00:01:33,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:34,167][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.7872682213783264, acc: 0.7317073345184326)
[2024-12-15 00:01:34,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:34,576][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.7984327673912048, acc: 0.7272727489471436)
[2024-12-15 00:01:34,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:34,949][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.49688610434532166, acc: 0.7916666865348816)
[2024-12-15 00:01:35,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:35,292][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.26348164677619934, acc: 0.95652174949646)
[2024-12-15 00:01:35,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:35,667][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.5822882056236267, acc: 0.8214285969734192)
[2024-12-15 00:01:35,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:36,043][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.3989694118499756, acc: 0.875)
[2024-12-15 00:01:36,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:36,662][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 1.35732102394104, acc: 0.6181818246841431)
[2024-12-15 00:01:37,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:37,542][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.9797791242599487, acc: 0.7452830076217651)
[2024-12-15 00:01:37,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:37,912][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.9704654216766357, acc: 0.7555555701255798)
[2024-12-15 00:01:38,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:38,269][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.8698241114616394, acc: 0.6964285969734192)
[2024-12-15 00:01:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:38,661][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.5625538229942322, acc: 0.7714285850524902)
[2024-12-15 00:01:38,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:39,027][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.2896411418914795, acc: 0.8799999952316284)
[2024-12-15 00:01:39,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:39,374][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.5384294390678406, acc: 0.782608687877655)
[2024-12-15 00:01:39,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:39,729][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.8026728630065918, acc: 0.7708333134651184)
[2024-12-15 00:01:39,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:40,159][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.8996226787567139, acc: 0.7263157963752747)
[2024-12-15 00:01:40,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:40,773][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 1.2774322032928467, acc: 0.6227545142173767)
[2024-12-15 00:01:40,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:41,216][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 1.071954607963562, acc: 0.7067669034004211)
[2024-12-15 00:01:41,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:42,543][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 1.2903320789337158, acc: 0.6363636255264282)
[2024-12-15 00:01:42,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:43,141][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.8625613451004028, acc: 0.7567567825317383)
[2024-12-15 00:01:43,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:43,542][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.6134805083274841, acc: 0.8214285969734192)
[2024-12-15 00:01:43,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:43,900][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.5133762955665588, acc: 0.8214285969734192)
[2024-12-15 00:01:43,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:44,209][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.4529270827770233, acc: 0.84375)
[2024-12-15 00:01:44,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:44,586][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.5795698761940002, acc: 0.8333333134651184)
[2024-12-15 00:01:44,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:44,968][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.5118056535720825, acc: 0.8421052694320679)
[2024-12-15 00:01:45,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:45,254][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.5706515312194824, acc: 0.7727272510528564)
[2024-12-15 00:01:45,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:45,608][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.7702252864837646, acc: 0.699999988079071)
[2024-12-15 00:01:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:46,017][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.5418270826339722, acc: 0.761904776096344)
[2024-12-15 00:01:46,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:46,386][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.9548011422157288, acc: 0.7592592835426331)
[2024-12-15 00:01:46,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:46,749][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 1.5698227882385254, acc: 0.5242718458175659)
[2024-12-15 00:01:46,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:47,293][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 1.663002371788025, acc: 0.5882353186607361)
[2024-12-15 00:01:47,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:47,693][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 1.6340566873550415, acc: 0.5400000214576721)
[2024-12-15 00:01:47,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:48,108][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 1.7080479860305786, acc: 0.5486111044883728)
[2024-12-15 00:01:48,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:48,477][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.9722764492034912, acc: 0.7209302186965942)
[2024-12-15 00:01:48,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:48,940][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.6991675496101379, acc: 0.7916666865348816)
[2024-12-15 00:01:49,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:49,336][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.7369829416275024, acc: 0.8372092843055725)
[2024-12-15 00:01:49,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:49,647][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.4846060574054718, acc: 0.800000011920929)
[2024-12-15 00:01:49,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:50,235][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.9318305253982544, acc: 0.6911764740943909)
[2024-12-15 00:01:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:50,650][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 1.069399118423462, acc: 0.6399999856948853)
[2024-12-15 00:01:50,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:51,064][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.5391108393669128, acc: 0.8484848737716675)
[2024-12-15 00:01:51,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:51,493][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.5314478278160095, acc: 0.8181818127632141)
[2024-12-15 00:01:51,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:51,865][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.6750452518463135, acc: 0.774193525314331)
[2024-12-15 00:01:51,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:52,228][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.6293946504592896, acc: 0.8148148059844971)
[2024-12-15 00:01:52,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:52,623][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.45497754216194153, acc: 0.9200000166893005)
[2024-12-15 00:01:52,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:53,002][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.6257104873657227, acc: 0.8333333134651184)
[2024-12-15 00:01:53,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:53,333][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.7830052971839905, acc: 0.7407407164573669)
[2024-12-15 00:01:53,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:53,674][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.4914040267467499, acc: 0.807692289352417)
[2024-12-15 00:01:53,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:54,065][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.8792717456817627, acc: 0.6724137663841248)
[2024-12-15 00:01:54,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:54,500][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.43192893266677856, acc: 0.8214285969734192)
[2024-12-15 00:01:54,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:54,907][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.6070989370346069, acc: 0.800000011920929)
[2024-12-15 00:01:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:55,330][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.6423420310020447, acc: 0.7878788113594055)
[2024-12-15 00:01:55,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:55,716][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.5185146927833557, acc: 0.8181818127632141)
[2024-12-15 00:01:56,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:56,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:57,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:57,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:58,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:58,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:58,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:59,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:01:59,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:00,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:00,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:00,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:01,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:01,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:02,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:02,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:02,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:03,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:03,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:04,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:04,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:04,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:05,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:06,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:06,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:06,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:07,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:07,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:07,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:08,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:08,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:08,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:09,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:09,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:09,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:10,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:10,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:10,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:11,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:11,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:12,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:12,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:12,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:13,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:13,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:14,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:14,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:15,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:15,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:16,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:17,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:17,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:17,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:18,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:18,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:19,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:19,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:20,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:21,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:21,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:21,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:22,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:22,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:22,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:23,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:23,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:23,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:24,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:24,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:25,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:25,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:25,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:25,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:26,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:26,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:27,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:27,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:28,045][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.7668, device='cuda:0') eval_epoch_loss=tensor(2.1710, device='cuda:0') eval_epoch_acc=tensor(0.5268, device='cuda:0')
[2024-12-15 00:02:28,046][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:02:28,046][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:02:28,901][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_8_step_415_loss_2.1709718704223633/model.pt
[2024-12-15 00:02:28,906][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:02:29,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:29,344][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 1.0728704929351807, acc: 0.7058823704719543)
[2024-12-15 00:02:29,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:29,723][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.8566397428512573, acc: 0.7692307829856873)
[2024-12-15 00:02:29,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:30,082][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 1.016918659210205, acc: 0.6666666865348816)
[2024-12-15 00:02:30,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:30,484][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.9232051968574524, acc: 0.699999988079071)
[2024-12-15 00:02:30,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:30,911][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.815879225730896, acc: 0.699999988079071)
[2024-12-15 00:02:31,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:31,292][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.4014383554458618, acc: 0.8571428656578064)
[2024-12-15 00:02:31,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:31,740][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.6879920959472656, acc: 0.8333333134651184)
[2024-12-15 00:02:31,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:32,134][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.639983057975769, acc: 0.75)
[2024-12-15 00:02:32,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:32,517][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.8002212643623352, acc: 0.8333333134651184)
[2024-12-15 00:02:32,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:32,945][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.6925585865974426, acc: 0.8148148059844971)
[2024-12-15 00:02:33,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:33,312][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.7358111143112183, acc: 0.7878788113594055)
[2024-12-15 00:02:33,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:33,672][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 1.1928424835205078, acc: 0.695652186870575)
[2024-12-15 00:02:33,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:34,028][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.8419407606124878, acc: 0.7297297120094299)
[2024-12-15 00:02:34,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:34,350][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.6696624159812927, acc: 0.7407407164573669)
[2024-12-15 00:02:34,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:34,749][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.7360330820083618, acc: 0.782608687877655)
[2024-12-15 00:02:34,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:35,120][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.22494365274906158, acc: 0.9629629850387573)
[2024-12-15 00:02:35,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:35,459][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.6108079552650452, acc: 0.7777777910232544)
[2024-12-15 00:02:35,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:35,880][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.736411988735199, acc: 0.782608687877655)
[2024-12-15 00:02:36,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:36,258][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.5876967906951904, acc: 0.8055555820465088)
[2024-12-15 00:02:36,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:36,617][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.7049194574356079, acc: 0.7599999904632568)
[2024-12-15 00:02:36,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:36,985][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.6738126277923584, acc: 0.8181818127632141)
[2024-12-15 00:02:37,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:37,323][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.8064897060394287, acc: 0.6666666865348816)
[2024-12-15 00:02:37,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:37,672][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.6290919780731201, acc: 0.8409090638160706)
[2024-12-15 00:02:37,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:38,004][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.43190914392471313, acc: 0.8095238208770752)
[2024-12-15 00:02:38,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:38,347][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.8674017190933228, acc: 0.692307710647583)
[2024-12-15 00:02:38,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:38,823][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 1.2749961614608765, acc: 0.6060606241226196)
[2024-12-15 00:02:39,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:39,590][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 2.0105831623077393, acc: 0.4320000112056732)
[2024-12-15 00:02:39,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:40,063][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 1.6575976610183716, acc: 0.5483871102333069)
[2024-12-15 00:02:40,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:40,760][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 1.80843186378479, acc: 0.5124378204345703)
[2024-12-15 00:02:40,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:41,123][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.9819037914276123, acc: 0.698113203048706)
[2024-12-15 00:02:41,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:41,574][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.5649096369743347, acc: 0.8181818127632141)
[2024-12-15 00:02:41,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:41,937][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.7425182461738586, acc: 0.782608687877655)
[2024-12-15 00:02:42,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:42,304][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.8166793584823608, acc: 0.7307692170143127)
[2024-12-15 00:02:42,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:42,655][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.511750340461731, acc: 0.8214285969734192)
[2024-12-15 00:02:42,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:43,008][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.7296647429466248, acc: 0.7611940503120422)
[2024-12-15 00:02:43,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:43,410][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.8759715557098389, acc: 0.7638888955116272)
[2024-12-15 00:02:43,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:43,796][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.8904154300689697, acc: 0.75)
[2024-12-15 00:02:43,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:44,151][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 1.0714378356933594, acc: 0.6282051205635071)
[2024-12-15 00:02:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:44,513][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.8943213224411011, acc: 0.6842105388641357)
[2024-12-15 00:02:44,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:44,945][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.9906539916992188, acc: 0.7346938848495483)
[2024-12-15 00:02:45,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:45,328][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.586308479309082, acc: 0.8484848737716675)
[2024-12-15 00:02:45,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:45,725][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 1.5645304918289185, acc: 0.5567010045051575)
[2024-12-15 00:02:45,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:46,183][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.8399646878242493, acc: 0.7857142686843872)
[2024-12-15 00:02:46,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:46,674][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 1.453262209892273, acc: 0.5930232405662537)
[2024-12-15 00:02:46,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:47,127][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.7853841185569763, acc: 0.7321428656578064)
[2024-12-15 00:02:47,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:47,542][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 1.2793242931365967, acc: 0.5925925970077515)
[2024-12-15 00:02:47,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:47,947][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.670868992805481, acc: 0.8333333134651184)
[2024-12-15 00:02:48,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:48,382][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.47647470235824585, acc: 0.875)
[2024-12-15 00:02:48,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:48,777][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.5807393789291382, acc: 0.7692307829856873)
[2024-12-15 00:02:48,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:49,164][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.514042854309082, acc: 0.8913043737411499)
[2024-12-15 00:02:49,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:49,534][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.9120286107063293, acc: 0.7023809552192688)
[2024-12-15 00:02:49,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:49,917][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.9917581677436829, acc: 0.6746987700462341)
[2024-12-15 00:02:50,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:50,339][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 1.0072749853134155, acc: 0.6756756901741028)
[2024-12-15 00:02:50,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:50,752][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 1.120985984802246, acc: 0.6699029207229614)
[2024-12-15 00:02:50,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:51,137][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.9683825373649597, acc: 0.6991869807243347)
[2024-12-15 00:02:51,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:51,579][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.7476188540458679, acc: 0.7916666865348816)
[2024-12-15 00:02:51,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:51,943][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.607903778553009, acc: 0.8214285969734192)
[2024-12-15 00:02:52,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:52,384][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 1.4660544395446777, acc: 0.5490196347236633)
[2024-12-15 00:02:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:52,760][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 1.775063157081604, acc: 0.5196506381034851)
[2024-12-15 00:02:52,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:53,110][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 1.2648968696594238, acc: 0.6041666865348816)
[2024-12-15 00:02:53,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:53,478][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 1.5112544298171997, acc: 0.5828220844268799)
[2024-12-15 00:02:53,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:53,825][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 1.435978651046753, acc: 0.5827338099479675)
[2024-12-15 00:02:53,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:54,221][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 1.6968717575073242, acc: 0.48241207003593445)
[2024-12-15 00:02:54,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:54,611][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.6112556457519531, acc: 0.8055555820465088)
[2024-12-15 00:02:54,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:54,996][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.6042731404304504, acc: 0.8181818127632141)
[2024-12-15 00:02:55,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:55,422][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.5343469977378845, acc: 0.8148148059844971)
[2024-12-15 00:02:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:55,858][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.6943830251693726, acc: 0.699999988079071)
[2024-12-15 00:02:55,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:56,234][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.5809413194656372, acc: 0.8999999761581421)
[2024-12-15 00:02:56,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:56,652][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.6765939593315125, acc: 0.7586206793785095)
[2024-12-15 00:02:56,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:57,116][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.6222116947174072, acc: 0.8387096524238586)
[2024-12-15 00:02:57,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:57,498][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.5154790878295898, acc: 0.8421052694320679)
[2024-12-15 00:02:57,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:57,872][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.7896637916564941, acc: 0.7037037014961243)
[2024-12-15 00:02:58,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:58,329][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.9567909240722656, acc: 0.6190476417541504)
[2024-12-15 00:02:58,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:58,778][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.9053667187690735, acc: 0.6363636255264282)
[2024-12-15 00:02:58,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:59,172][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.8770123720169067, acc: 0.7384615540504456)
[2024-12-15 00:02:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:59,548][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.7186527848243713, acc: 0.7666666507720947)
[2024-12-15 00:02:59,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:02:59,930][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.7233041524887085, acc: 0.7241379022598267)
[2024-12-15 00:03:00,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:00,305][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.7895689010620117, acc: 0.7450980544090271)
[2024-12-15 00:03:00,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:00,681][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.6889538764953613, acc: 0.7931034564971924)
[2024-12-15 00:03:00,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:01,032][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.6128018498420715, acc: 0.8421052694320679)
[2024-12-15 00:03:01,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:01,391][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.6869338154792786, acc: 0.6842105388641357)
[2024-12-15 00:03:01,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:01,814][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 1.0777013301849365, acc: 0.6785714030265808)
[2024-12-15 00:03:01,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:02,251][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 1.2146964073181152, acc: 0.6404494643211365)
[2024-12-15 00:03:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:02,653][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 1.298307180404663, acc: 0.6292135119438171)
[2024-12-15 00:03:02,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:03,043][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 1.5785892009735107, acc: 0.5531914830207825)
[2024-12-15 00:03:03,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:03,405][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 1.2030028104782104, acc: 0.6086956262588501)
[2024-12-15 00:03:03,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:03,821][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.5761569738388062, acc: 0.8399999737739563)
[2024-12-15 00:03:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:04,197][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.6532509326934814, acc: 0.692307710647583)
[2024-12-15 00:03:04,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:04,557][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.6564651131629944, acc: 0.7407407164573669)
[2024-12-15 00:03:04,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:04,914][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.9607760310173035, acc: 0.6666666865348816)
[2024-12-15 00:03:05,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:05,287][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 1.0858051776885986, acc: 0.6792452931404114)
[2024-12-15 00:03:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:05,659][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.5205191969871521, acc: 0.8275862336158752)
[2024-12-15 00:03:05,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:06,270][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 1.189652919769287, acc: 0.6396396160125732)
[2024-12-15 00:03:06,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:06,763][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 1.1689406633377075, acc: 0.6760563254356384)
[2024-12-15 00:03:06,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:07,131][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.32033511996269226, acc: 0.8999999761581421)
[2024-12-15 00:03:07,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:07,474][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.4076612591743469, acc: 0.8666666746139526)
[2024-12-15 00:03:07,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:07,810][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.664584219455719, acc: 0.807692289352417)
[2024-12-15 00:03:09,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:10,321][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 1.5220434665679932, acc: 0.5785714387893677)
[2024-12-15 00:03:10,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:11,105][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 1.2880476713180542, acc: 0.6349206566810608)
[2024-12-15 00:03:11,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:11,478][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.8141708374023438, acc: 0.7142857313156128)
[2024-12-15 00:03:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:11,837][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.9895750880241394, acc: 0.7166666388511658)
[2024-12-15 00:03:12,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:12,546][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.8857300281524658, acc: 0.75)
[2024-12-15 00:03:12,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:12,903][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.2678869962692261, acc: 0.8846153616905212)
[2024-12-15 00:03:12,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:13,239][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.5871179699897766, acc: 0.8387096524238586)
[2024-12-15 00:03:13,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:13,587][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.8418982625007629, acc: 0.75)
[2024-12-15 00:03:13,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:13,959][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.6336833238601685, acc: 0.7037037014961243)
[2024-12-15 00:03:14,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:14,960][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 1.6861052513122559, acc: 0.5338982939720154)
[2024-12-15 00:03:15,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:15,354][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 1.3198952674865723, acc: 0.60447758436203)
[2024-12-15 00:03:15,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:15,773][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 1.3820180892944336, acc: 0.540145993232727)
[2024-12-15 00:03:15,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:16,375][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 1.5615158081054688, acc: 0.5600000023841858)
[2024-12-15 00:03:16,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:16,767][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.8648117780685425, acc: 0.7222222089767456)
[2024-12-15 00:03:16,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:17,154][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.8442475199699402, acc: 0.6346153616905212)
[2024-12-15 00:03:17,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:17,518][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 1.0743831396102905, acc: 0.7142857313156128)
[2024-12-15 00:03:17,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:17,913][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 1.1743687391281128, acc: 0.7049180269241333)
[2024-12-15 00:03:18,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:18,292][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.8012475371360779, acc: 0.7457627058029175)
[2024-12-15 00:03:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:18,643][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.8820223212242126, acc: 0.7209302186965942)
[2024-12-15 00:03:18,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:19,001][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.7084290981292725, acc: 0.7954545617103577)
[2024-12-15 00:03:19,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:19,390][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.6589179635047913, acc: 0.7735849022865295)
[2024-12-15 00:03:19,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:19,781][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.39110344648361206, acc: 0.9090909361839294)
[2024-12-15 00:03:19,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:20,117][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.6947718858718872, acc: 0.7200000286102295)
[2024-12-15 00:03:20,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:20,475][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.5414038896560669, acc: 0.8500000238418579)
[2024-12-15 00:03:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:20,816][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.6776779294013977, acc: 0.7727272510528564)
[2024-12-15 00:03:20,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:21,246][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.8966902494430542, acc: 0.7384615540504456)
[2024-12-15 00:03:21,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:21,626][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.7768799066543579, acc: 0.765625)
[2024-12-15 00:03:21,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:22,050][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.6803192496299744, acc: 0.8125)
[2024-12-15 00:03:22,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:22,403][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.7039196491241455, acc: 0.7575757503509521)
[2024-12-15 00:03:22,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:22,760][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.6495205163955688, acc: 0.8125)
[2024-12-15 00:03:22,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:23,106][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.36967188119888306, acc: 0.8709677457809448)
[2024-12-15 00:03:23,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:23,463][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.3564150333404541, acc: 0.9130434989929199)
[2024-12-15 00:03:23,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:23,806][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.6525014042854309, acc: 0.800000011920929)
[2024-12-15 00:03:23,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:24,162][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.643402099609375, acc: 0.8048780560493469)
[2024-12-15 00:03:24,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:24,520][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.4886777102947235, acc: 0.800000011920929)
[2024-12-15 00:03:24,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:24,890][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.47343710064888, acc: 0.9210526347160339)
[2024-12-15 00:03:24,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:25,244][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.7060772776603699, acc: 0.8064516186714172)
[2024-12-15 00:03:25,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:25,603][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.3414304852485657, acc: 0.9200000166893005)
[2024-12-15 00:03:25,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:25,979][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.5395689010620117, acc: 0.7878788113594055)
[2024-12-15 00:03:26,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:26,334][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.5821108818054199, acc: 0.875)
[2024-12-15 00:03:26,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:26,770][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.6283038258552551, acc: 0.7571428418159485)
[2024-12-15 00:03:26,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:27,155][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 1.507953405380249, acc: 0.5474452376365662)
[2024-12-15 00:03:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:27,520][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 1.046959400177002, acc: 0.6689655184745789)
[2024-12-15 00:03:27,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:27,883][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 1.5275992155075073, acc: 0.5785714387893677)
[2024-12-15 00:03:27,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:28,280][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 1.4600845575332642, acc: 0.5761589407920837)
[2024-12-15 00:03:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:28,641][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 1.0925753116607666, acc: 0.6752136945724487)
[2024-12-15 00:03:29,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:29,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:30,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:30,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:31,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:31,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:32,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:32,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:32,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:33,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:33,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:34,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:34,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:34,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:35,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:35,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:36,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:36,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:36,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:37,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:37,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:38,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:38,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:39,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:39,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:40,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:41,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:41,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:41,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:42,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:42,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:42,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:43,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:43,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:43,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:44,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:44,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:45,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:45,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:46,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:46,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:46,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:47,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:47,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:48,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:48,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:48,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:49,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:49,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:49,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:50,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:50,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:51,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:51,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:51,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:52,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:52,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:53,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:53,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:53,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:54,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:54,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:55,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:55,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:55,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:56,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:56,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:57,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:57,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:57,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:58,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:58,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:59,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:03:59,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:00,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:00,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:01,070][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.8874, device='cuda:0') eval_epoch_loss=tensor(2.1846, device='cuda:0') eval_epoch_acc=tensor(0.5177, device='cuda:0')
[2024-12-15 00:04:01,072][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:04:01,072][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:04:01,895][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_8_step_558_loss_2.184628963470459/model.pt
[2024-12-15 00:04:01,901][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:04:01,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:02,344][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.2401493638753891, acc: 0.8799999952316284)
[2024-12-15 00:04:02,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:02,708][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.5115481019020081, acc: 0.8461538553237915)
[2024-12-15 00:04:02,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:03,064][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.37840381264686584, acc: 0.8846153616905212)
[2024-12-15 00:04:03,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:03,438][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.6182262897491455, acc: 0.8205128312110901)
[2024-12-15 00:04:03,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:03,789][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 1.073330283164978, acc: 0.644444465637207)
[2024-12-15 00:04:03,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:04,119][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.8796521425247192, acc: 0.6883116960525513)
[2024-12-15 00:04:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:04,442][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.7894975543022156, acc: 0.7291666865348816)
[2024-12-15 00:04:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:04,783][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.8235483765602112, acc: 0.7413793206214905)
[2024-12-15 00:04:04,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:05,149][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 1.2902429103851318, acc: 0.6190476417541504)
[2024-12-15 00:04:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:05,528][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.6837394833564758, acc: 0.7894737124443054)
[2024-12-15 00:04:05,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:05,895][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.5305005311965942, acc: 0.8148148059844971)
[2024-12-15 00:04:06,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:06,319][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 1.654667854309082, acc: 0.6096256971359253)
[2024-12-15 00:04:06,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:06,711][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 1.0348421335220337, acc: 0.6774193644523621)
[2024-12-15 00:04:06,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:07,063][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 1.1626964807510376, acc: 0.632478654384613)
[2024-12-15 00:04:07,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:07,405][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 1.5811655521392822, acc: 0.5102040767669678)
[2024-12-15 00:04:07,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:07,784][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 1.6118570566177368, acc: 0.553459107875824)
[2024-12-15 00:04:08,191][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=2.5812, train_epoch_loss=0.9483, epoch time 381.7486343169585s
[2024-12-15 00:04:08,191][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-15 00:04:08,191][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-15 00:04:08,191][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-15 00:04:08,191][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 24
[2024-12-15 00:04:08,192][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-15 00:04:08,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:09,167][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.5389235615730286, acc: 0.7777777910232544)
[2024-12-15 00:04:09,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:09,561][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.5440248250961304, acc: 0.800000011920929)
[2024-12-15 00:04:09,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:09,948][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.7845758199691772, acc: 0.7567567825317383)
[2024-12-15 00:04:10,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:10,415][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.861179530620575, acc: 0.7105262875556946)
[2024-12-15 00:04:10,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:10,842][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.7715868353843689, acc: 0.7297297120094299)
[2024-12-15 00:04:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:11,304][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.80022132396698, acc: 0.75)
[2024-12-15 00:04:11,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:11,788][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.8223856687545776, acc: 0.7346938848495483)
[2024-12-15 00:04:11,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:12,210][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.5128962993621826, acc: 0.7666666507720947)
[2024-12-15 00:04:12,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:12,600][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.19355176389217377, acc: 0.9090909361839294)
[2024-12-15 00:04:12,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:12,975][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.2396640181541443, acc: 0.9615384340286255)
[2024-12-15 00:04:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:13,342][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.5101414322853088, acc: 0.8518518805503845)
[2024-12-15 00:04:13,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:13,712][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.6221351027488708, acc: 0.8461538553237915)
[2024-12-15 00:04:13,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:14,149][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.6348990201950073, acc: 0.8181818127632141)
[2024-12-15 00:04:14,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:14,584][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.7273337244987488, acc: 0.782608687877655)
[2024-12-15 00:04:14,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:14,987][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.7764943242073059, acc: 0.7647058963775635)
[2024-12-15 00:04:15,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:15,375][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.6045995950698853, acc: 0.7755101919174194)
[2024-12-15 00:04:15,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:15,731][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.5300105810165405, acc: 0.8421052694320679)
[2024-12-15 00:04:15,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:16,091][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.5948864221572876, acc: 0.75)
[2024-12-15 00:04:16,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:16,468][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.7007267475128174, acc: 0.75)
[2024-12-15 00:04:16,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:16,877][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.6045778393745422, acc: 0.7368420958518982)
[2024-12-15 00:04:17,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:17,263][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.8255285024642944, acc: 0.807692289352417)
[2024-12-15 00:04:17,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:17,661][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.5754192471504211, acc: 0.8275862336158752)
[2024-12-15 00:04:17,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:18,110][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.6079431176185608, acc: 0.7200000286102295)
[2024-12-15 00:04:18,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:18,505][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.6712659597396851, acc: 0.7142857313156128)
[2024-12-15 00:04:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:18,887][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.4815666675567627, acc: 0.75)
[2024-12-15 00:04:19,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:19,304][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.7568036317825317, acc: 0.7547169923782349)
[2024-12-15 00:04:19,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:19,735][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.9869121313095093, acc: 0.698630154132843)
[2024-12-15 00:04:20,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:21,062][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 1.8663759231567383, acc: 0.47826087474823)
[2024-12-15 00:04:21,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:21,437][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.9059102535247803, acc: 0.7209302186965942)
[2024-12-15 00:04:21,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:21,815][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 1.1587313413619995, acc: 0.6626505851745605)
[2024-12-15 00:04:21,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:22,202][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.9018421769142151, acc: 0.6913580298423767)
[2024-12-15 00:04:22,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:22,558][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.7979966402053833, acc: 0.75)
[2024-12-15 00:04:22,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:22,929][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.8109989762306213, acc: 0.6666666865348816)
[2024-12-15 00:04:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:23,364][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.4876200258731842, acc: 0.9130434989929199)
[2024-12-15 00:04:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:23,754][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 1.4126003980636597, acc: 0.6302521228790283)
[2024-12-15 00:04:23,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:24,104][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.7219235301017761, acc: 0.7868852615356445)
[2024-12-15 00:04:24,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:24,482][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 1.0093563795089722, acc: 0.6666666865348816)
[2024-12-15 00:04:24,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:24,860][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.894180178642273, acc: 0.7627118825912476)
[2024-12-15 00:04:24,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:25,256][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.8779568076133728, acc: 0.7701149582862854)
[2024-12-15 00:04:25,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:25,628][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.6792842745780945, acc: 0.761904776096344)
[2024-12-15 00:04:25,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:26,025][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.8299492597579956, acc: 0.7307692170143127)
[2024-12-15 00:04:26,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:26,441][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 1.079027533531189, acc: 0.6756756901741028)
[2024-12-15 00:04:26,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:26,840][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 1.1071281433105469, acc: 0.7230769395828247)
[2024-12-15 00:04:26,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:27,289][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 1.314161777496338, acc: 0.6464646458625793)
[2024-12-15 00:04:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:27,737][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 1.1268062591552734, acc: 0.6907216310501099)
[2024-12-15 00:04:27,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:28,177][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 1.4120558500289917, acc: 0.6029411554336548)
[2024-12-15 00:04:28,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:28,536][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.7663379907608032, acc: 0.7692307829856873)
[2024-12-15 00:04:28,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:28,911][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.4006780683994293, acc: 0.8518518805503845)
[2024-12-15 00:04:29,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:29,274][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.6805429458618164, acc: 0.75)
[2024-12-15 00:04:29,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:29,651][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.4492923319339752, acc: 0.9166666865348816)
[2024-12-15 00:04:29,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:30,053][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.7801986932754517, acc: 0.7894737124443054)
[2024-12-15 00:04:30,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:30,461][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.7408568263053894, acc: 0.7777777910232544)
[2024-12-15 00:04:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:30,825][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 1.0172680616378784, acc: 0.7183098793029785)
[2024-12-15 00:04:30,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:31,316][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 1.406195044517517, acc: 0.5933333039283752)
[2024-12-15 00:04:31,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:31,712][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.654001772403717, acc: 0.8108108043670654)
[2024-12-15 00:04:31,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:32,087][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.4381052851676941, acc: 0.807692289352417)
[2024-12-15 00:04:33,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:35,045][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 1.6737209558486938, acc: 0.5460751056671143)
[2024-12-15 00:04:35,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:36,301][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 2.1145904064178467, acc: 0.4248366057872772)
[2024-12-15 00:04:36,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:36,960][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 1.661527156829834, acc: 0.5568181872367859)
[2024-12-15 00:04:37,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:37,564][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 1.3404862880706787, acc: 0.6470588445663452)
[2024-12-15 00:04:37,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:38,168][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 1.649477481842041, acc: 0.47826087474823)
[2024-12-15 00:04:38,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:38,642][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 1.1976392269134521, acc: 0.6499999761581421)
[2024-12-15 00:04:38,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:39,040][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.4103630483150482, acc: 0.8823529481887817)
[2024-12-15 00:04:39,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:39,455][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.8912338614463806, acc: 0.6944444179534912)
[2024-12-15 00:04:39,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:39,867][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.6206634044647217, acc: 0.828125)
[2024-12-15 00:04:39,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:40,233][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.3217785060405731, acc: 0.9655172228813171)
[2024-12-15 00:04:40,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:40,623][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.8196882009506226, acc: 0.7321428656578064)
[2024-12-15 00:04:40,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:40,995][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.9119283556938171, acc: 0.7166666388511658)
[2024-12-15 00:04:41,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:41,362][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.2508716285228729, acc: 0.8799999952316284)
[2024-12-15 00:04:41,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:41,719][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.8456931114196777, acc: 0.7777777910232544)
[2024-12-15 00:04:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:42,079][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.7266354560852051, acc: 0.7272727489471436)
[2024-12-15 00:04:42,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:42,441][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 1.4605263471603394, acc: 0.5735294222831726)
[2024-12-15 00:04:42,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:42,798][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 1.395878553390503, acc: 0.6190476417541504)
[2024-12-15 00:04:42,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:43,173][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 1.8756424188613892, acc: 0.4923076927661896)
[2024-12-15 00:04:43,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:43,535][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 1.0667656660079956, acc: 0.7244898080825806)
[2024-12-15 00:04:43,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:43,956][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 1.6033529043197632, acc: 0.5223880410194397)
[2024-12-15 00:04:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:44,390][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 2.0204989910125732, acc: 0.4708029329776764)
[2024-12-15 00:04:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:44,767][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.28518810868263245, acc: 0.9047619104385376)
[2024-12-15 00:04:44,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:45,104][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.2965729236602783, acc: 0.9166666865348816)
[2024-12-15 00:04:45,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:45,468][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.6348394751548767, acc: 0.8181818127632141)
[2024-12-15 00:04:45,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:45,847][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.3991045355796814, acc: 0.8461538553237915)
[2024-12-15 00:04:45,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:46,218][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.7035664319992065, acc: 0.8269230723381042)
[2024-12-15 00:04:46,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:46,592][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.7520784139633179, acc: 0.7115384340286255)
[2024-12-15 00:04:46,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:46,939][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.5029222369194031, acc: 0.8125)
[2024-12-15 00:04:47,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:47,310][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.8919407725334167, acc: 0.6666666865348816)
[2024-12-15 00:04:47,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:47,681][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.7910325527191162, acc: 0.8600000143051147)
[2024-12-15 00:04:47,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:48,048][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.8122524619102478, acc: 0.8260869383811951)
[2024-12-15 00:04:48,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:48,564][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 1.08259916305542, acc: 0.7200000286102295)
[2024-12-15 00:04:48,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:48,965][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.932648241519928, acc: 0.6796116232872009)
[2024-12-15 00:04:49,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:50,096][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 1.5602049827575684, acc: 0.5776699185371399)
[2024-12-15 00:04:50,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:50,941][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 1.6547616720199585, acc: 0.5268816947937012)
[2024-12-15 00:04:51,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:51,769][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 1.589438557624817, acc: 0.5862069129943848)
[2024-12-15 00:04:52,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:52,550][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 1.1006274223327637, acc: 0.621052622795105)
[2024-12-15 00:04:52,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:53,580][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 1.5094541311264038, acc: 0.5346534848213196)
[2024-12-15 00:04:53,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:53,957][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 1.1694109439849854, acc: 0.6290322542190552)
[2024-12-15 00:04:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:54,329][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 1.113412618637085, acc: 0.6666666865348816)
[2024-12-15 00:04:54,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:54,707][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 1.495383620262146, acc: 0.5126050710678101)
[2024-12-15 00:04:54,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:55,105][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 1.5770518779754639, acc: 0.5096153616905212)
[2024-12-15 00:04:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:55,533][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 1.5527948141098022, acc: 0.55474454164505)
[2024-12-15 00:04:55,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:55,899][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.9856472611427307, acc: 0.7910447716712952)
[2024-12-15 00:04:55,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:56,257][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.35516709089279175, acc: 0.8999999761581421)
[2024-12-15 00:04:56,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:56,614][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.4896485507488251, acc: 0.8636363744735718)
[2024-12-15 00:04:56,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:57,013][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.6433992981910706, acc: 0.782608687877655)
[2024-12-15 00:04:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:57,401][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.517394483089447, acc: 0.8636363744735718)
[2024-12-15 00:04:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:57,777][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 1.0430563688278198, acc: 0.7241379022598267)
[2024-12-15 00:04:57,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:58,153][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.4186146855354309, acc: 0.8837209343910217)
[2024-12-15 00:04:58,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:58,526][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.7787980437278748, acc: 0.800000011920929)
[2024-12-15 00:04:58,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:58,870][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.3448205590248108, acc: 0.8823529481887817)
[2024-12-15 00:04:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:59,210][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.3634888529777527, acc: 0.9230769276618958)
[2024-12-15 00:04:59,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:59,589][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.3248346149921417, acc: 0.8809523582458496)
[2024-12-15 00:04:59,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:04:59,988][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.6837813258171082, acc: 0.7846153974533081)
[2024-12-15 00:05:00,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:00,421][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.7981996536254883, acc: 0.7894737124443054)
[2024-12-15 00:05:00,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:00,793][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.8785285353660583, acc: 0.7543859481811523)
[2024-12-15 00:05:00,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:01,157][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.45837900042533875, acc: 0.9230769276618958)
[2024-12-15 00:05:01,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:01,565][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.4291725158691406, acc: 0.8571428656578064)
[2024-12-15 00:05:01,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:01,912][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.20879994332790375, acc: 0.9090909361839294)
[2024-12-15 00:05:02,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:02,281][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.6720101833343506, acc: 0.7777777910232544)
[2024-12-15 00:05:02,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:02,665][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 1.1960266828536987, acc: 0.6747967600822449)
[2024-12-15 00:05:02,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:03,057][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.7340083718299866, acc: 0.7580645084381104)
[2024-12-15 00:05:03,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:03,965][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 1.7070037126541138, acc: 0.5551331043243408)
[2024-12-15 00:05:04,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:04,369][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.8419830799102783, acc: 0.7733333110809326)
[2024-12-15 00:05:04,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:04,808][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.5901880264282227, acc: 0.8653846383094788)
[2024-12-15 00:05:04,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:05,152][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.4265929162502289, acc: 0.9166666865348816)
[2024-12-15 00:05:05,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:05,498][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.6201769709587097, acc: 0.7894737124443054)
[2024-12-15 00:05:05,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:05,909][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 1.4373151063919067, acc: 0.5950919985771179)
[2024-12-15 00:05:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:06,315][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 1.374937891960144, acc: 0.6388888955116272)
[2024-12-15 00:05:06,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:06,681][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 1.4418563842773438, acc: 0.5583333373069763)
[2024-12-15 00:05:07,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:07,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:08,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:08,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:08,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:09,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:09,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:09,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:10,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:10,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:10,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:11,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:11,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:12,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:12,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:13,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:13,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:13,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:14,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:14,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:14,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:15,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:15,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:16,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:16,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:17,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:17,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:18,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:18,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:18,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:19,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:19,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:19,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:20,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:21,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:21,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:21,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:22,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:22,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:23,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:23,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:24,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:24,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:25,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:25,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:26,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:26,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:27,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:27,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:27,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:28,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:28,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:28,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:29,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:29,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:30,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:30,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:31,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:31,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:31,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:32,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:32,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:32,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:33,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:33,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:33,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:34,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:35,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:35,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:36,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:36,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:36,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:37,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:37,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:38,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:38,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:38,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:39,257][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.0106, device='cuda:0') eval_epoch_loss=tensor(2.1984, device='cuda:0') eval_epoch_acc=tensor(0.5315, device='cuda:0')
[2024-12-15 00:05:39,258][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:05:39,258][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:05:40,052][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_9_step_127_loss_2.1983988285064697/model.pt
[2024-12-15 00:05:40,056][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:05:40,057][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.5315285325050354
[2024-12-15 00:05:40,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:40,471][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 1.4952104091644287, acc: 0.5595238208770752)
[2024-12-15 00:05:40,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:40,847][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 1.491771936416626, acc: 0.5743589997291565)
[2024-12-15 00:05:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:41,283][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 1.3249351978302002, acc: 0.6470588445663452)
[2024-12-15 00:05:41,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:41,646][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.6023271083831787, acc: 0.8461538553237915)
[2024-12-15 00:05:41,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:41,990][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.5491257309913635, acc: 0.782608687877655)
[2024-12-15 00:05:42,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:42,352][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.8035276532173157, acc: 0.71875)
[2024-12-15 00:05:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:42,696][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.7470592260360718, acc: 0.8260869383811951)
[2024-12-15 00:05:42,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:43,054][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.6319372653961182, acc: 0.7714285850524902)
[2024-12-15 00:05:43,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:43,431][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.49555936455726624, acc: 0.807692289352417)
[2024-12-15 00:05:43,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:43,874][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.5678013563156128, acc: 0.7857142686843872)
[2024-12-15 00:05:43,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:44,238][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.6794639825820923, acc: 0.699999988079071)
[2024-12-15 00:05:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:44,588][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.659338653087616, acc: 0.782608687877655)
[2024-12-15 00:05:44,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:44,922][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.5785823464393616, acc: 0.8095238208770752)
[2024-12-15 00:05:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:45,274][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.9054364562034607, acc: 0.7307692170143127)
[2024-12-15 00:05:45,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:45,631][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.8299961686134338, acc: 0.6451612710952759)
[2024-12-15 00:05:45,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:45,998][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.8833649158477783, acc: 0.7297297120094299)
[2024-12-15 00:05:46,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:46,552][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 1.4307715892791748, acc: 0.5438596606254578)
[2024-12-15 00:05:46,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:47,002][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 1.2530500888824463, acc: 0.6343283653259277)
[2024-12-15 00:05:47,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:47,390][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 1.6667299270629883, acc: 0.4897959232330322)
[2024-12-15 00:05:47,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:47,877][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 1.3784539699554443, acc: 0.5744680762290955)
[2024-12-15 00:05:47,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:48,241][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.9793925881385803, acc: 0.699999988079071)
[2024-12-15 00:05:48,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:48,576][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.8510127067565918, acc: 0.8214285969734192)
[2024-12-15 00:05:48,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:48,936][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.5669693946838379, acc: 0.8260869383811951)
[2024-12-15 00:05:49,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:49,293][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.6108189225196838, acc: 0.7931034564971924)
[2024-12-15 00:05:49,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:49,699][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.7295807003974915, acc: 0.782608687877655)
[2024-12-15 00:05:49,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:50,095][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 1.024678111076355, acc: 0.694915235042572)
[2024-12-15 00:05:50,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:50,453][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.9330739974975586, acc: 0.719298243522644)
[2024-12-15 00:05:50,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:50,837][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 1.175843596458435, acc: 0.662162184715271)
[2024-12-15 00:05:50,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:51,189][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.6256471276283264, acc: 0.8928571343421936)
[2024-12-15 00:05:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:51,555][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.733938992023468, acc: 0.739130437374115)
[2024-12-15 00:05:51,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:51,969][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.6640718579292297, acc: 0.7368420958518982)
[2024-12-15 00:05:52,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:53,625][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.9515386819839478, acc: 0.7432432174682617)
[2024-12-15 00:05:53,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:53,979][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 1.195035696029663, acc: 0.6481481194496155)
[2024-12-15 00:05:54,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:54,419][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 1.1729763746261597, acc: 0.6395348906517029)
[2024-12-15 00:05:54,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:55,035][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.9900124669075012, acc: 0.6941176652908325)
[2024-12-15 00:05:55,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:55,644][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 1.2438364028930664, acc: 0.5617977380752563)
[2024-12-15 00:05:55,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:56,028][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.5637301802635193, acc: 0.8181818127632141)
[2024-12-15 00:05:56,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:56,367][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.6238616108894348, acc: 0.8095238208770752)
[2024-12-15 00:05:56,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:56,817][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.6308915615081787, acc: 0.7931034564971924)
[2024-12-15 00:05:56,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:57,203][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.5745580196380615, acc: 0.8367347121238708)
[2024-12-15 00:05:57,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:57,573][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.9261098504066467, acc: 0.7599999904632568)
[2024-12-15 00:05:57,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:58,084][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.9575169682502747, acc: 0.7083333134651184)
[2024-12-15 00:05:58,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:58,500][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 1.483527660369873, acc: 0.5882353186607361)
[2024-12-15 00:05:59,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:05:59,641][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 1.8490180969238281, acc: 0.4931506812572479)
[2024-12-15 00:05:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:00,049][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.5578436255455017, acc: 0.7916666865348816)
[2024-12-15 00:06:00,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:00,408][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.7900952100753784, acc: 0.8518518805503845)
[2024-12-15 00:06:00,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:00,780][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.6253312826156616, acc: 0.8214285969734192)
[2024-12-15 00:06:00,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:01,343][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 1.1372538805007935, acc: 0.6637167930603027)
[2024-12-15 00:06:01,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:01,713][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.8448000550270081, acc: 0.7681159377098083)
[2024-12-15 00:06:01,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:02,112][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 1.065643548965454, acc: 0.6818181872367859)
[2024-12-15 00:06:02,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:03,107][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 1.8095427751541138, acc: 0.4580152630805969)
[2024-12-15 00:06:03,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:03,807][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 1.7015875577926636, acc: 0.5185185074806213)
[2024-12-15 00:06:03,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:04,158][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.7911728620529175, acc: 0.7704917788505554)
[2024-12-15 00:06:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:04,493][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.44535160064697266, acc: 0.875)
[2024-12-15 00:06:04,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:04,780][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.7260140776634216, acc: 0.7599999904632568)
[2024-12-15 00:06:04,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:05,105][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.7095273733139038, acc: 0.7857142686843872)
[2024-12-15 00:06:05,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:05,452][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 1.322742223739624, acc: 0.5975610017776489)
[2024-12-15 00:06:05,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:05,828][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 1.7890195846557617, acc: 0.4924471378326416)
[2024-12-15 00:06:05,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:06,221][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 2.0106265544891357, acc: 0.44668588042259216)
[2024-12-15 00:06:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:06,730][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 2.0059571266174316, acc: 0.4749999940395355)
[2024-12-15 00:06:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:07,279][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 1.9368021488189697, acc: 0.4652908146381378)
[2024-12-15 00:06:07,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:07,722][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 1.7924619913101196, acc: 0.5053380727767944)
[2024-12-15 00:06:07,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:08,074][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.7305870652198792, acc: 0.800000011920929)
[2024-12-15 00:06:08,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:08,659][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 1.6763410568237305, acc: 0.5232558250427246)
[2024-12-15 00:06:09,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:09,523][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 1.5156270265579224, acc: 0.5634920597076416)
[2024-12-15 00:06:09,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:10,464][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 1.5508073568344116, acc: 0.5681818127632141)
[2024-12-15 00:06:10,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:11,229][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 1.3849337100982666, acc: 0.6352941393852234)
[2024-12-15 00:06:11,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:12,331][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 1.3925116062164307, acc: 0.6172839403152466)
[2024-12-15 00:06:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:13,314][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.9604909420013428, acc: 0.774193525314331)
[2024-12-15 00:06:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:13,644][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.4963477551937103, acc: 0.8214285969734192)
[2024-12-15 00:06:13,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:13,983][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.5310043096542358, acc: 0.875)
[2024-12-15 00:06:14,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:14,337][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 1.011027455329895, acc: 0.720588207244873)
[2024-12-15 00:06:14,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:14,708][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 1.3682801723480225, acc: 0.595588207244873)
[2024-12-15 00:06:14,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:15,079][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 1.2537710666656494, acc: 0.6610169410705566)
[2024-12-15 00:06:15,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:15,522][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 1.4259159564971924, acc: 0.5970149040222168)
[2024-12-15 00:06:15,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:15,923][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 1.3436537981033325, acc: 0.6213592290878296)
[2024-12-15 00:06:16,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:16,266][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.8329607248306274, acc: 0.7936508059501648)
[2024-12-15 00:06:16,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:16,639][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 1.016995906829834, acc: 0.6703296899795532)
[2024-12-15 00:06:16,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:17,030][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 1.670316219329834, acc: 0.5246636867523193)
[2024-12-15 00:06:17,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:17,455][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 1.6919984817504883, acc: 0.5078740119934082)
[2024-12-15 00:06:17,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:17,822][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 1.52274751663208, acc: 0.5)
[2024-12-15 00:06:17,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:18,208][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 1.6756947040557861, acc: 0.5289855003356934)
[2024-12-15 00:06:18,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:18,622][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 1.7231923341751099, acc: 0.48638132214546204)
[2024-12-15 00:06:18,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:19,015][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 1.2247713804244995, acc: 0.6739130616188049)
[2024-12-15 00:06:19,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:19,467][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.6332204937934875, acc: 0.8260869383811951)
[2024-12-15 00:06:19,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:19,849][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.768760085105896, acc: 0.7857142686843872)
[2024-12-15 00:06:19,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:20,202][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.7764520645141602, acc: 0.7659574747085571)
[2024-12-15 00:06:20,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:20,926][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 1.0925164222717285, acc: 0.6692307591438293)
[2024-12-15 00:06:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:21,278][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.7145881056785583, acc: 0.7702702879905701)
[2024-12-15 00:06:21,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:21,641][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.8697433471679688, acc: 0.7558139562606812)
[2024-12-15 00:06:21,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:22,200][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.9845580458641052, acc: 0.684684693813324)
[2024-12-15 00:06:22,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:22,644][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.8454166054725647, acc: 0.7111111283302307)
[2024-12-15 00:06:22,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:23,020][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.38877859711647034, acc: 0.9090909361839294)
[2024-12-15 00:06:23,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:23,395][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.38954901695251465, acc: 0.8888888955116272)
[2024-12-15 00:06:23,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:23,804][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.6269802451133728, acc: 0.8799999952316284)
[2024-12-15 00:06:23,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:24,180][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.7173632383346558, acc: 0.807692289352417)
[2024-12-15 00:06:24,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:24,961][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 1.0248774290084839, acc: 0.6902173757553101)
[2024-12-15 00:06:25,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:25,528][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 1.3428072929382324, acc: 0.6193181872367859)
[2024-12-15 00:06:25,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:26,000][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.8727995753288269, acc: 0.7446808218955994)
[2024-12-15 00:06:26,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:26,452][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.5149086117744446, acc: 0.8867924809455872)
[2024-12-15 00:06:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:26,832][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.8601056933403015, acc: 0.7833333611488342)
[2024-12-15 00:06:26,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:27,191][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.5399172306060791, acc: 0.8604651093482971)
[2024-12-15 00:06:27,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:27,568][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.8017110228538513, acc: 0.699999988079071)
[2024-12-15 00:06:27,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:27,975][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 1.026354193687439, acc: 0.7368420958518982)
[2024-12-15 00:06:28,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:28,322][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.9668660759925842, acc: 0.7222222089767456)
[2024-12-15 00:06:28,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:28,776][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 1.0606037378311157, acc: 0.6833333373069763)
[2024-12-15 00:06:28,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:29,299][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 1.4761414527893066, acc: 0.6238532066345215)
[2024-12-15 00:06:29,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:29,808][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.9173598885536194, acc: 0.7384615540504456)
[2024-12-15 00:06:29,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:30,180][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.575014054775238, acc: 0.7894737124443054)
[2024-12-15 00:06:30,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:30,552][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.4828815460205078, acc: 0.9166666865348816)
[2024-12-15 00:06:30,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:30,896][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 1.0801670551300049, acc: 0.5454545617103577)
[2024-12-15 00:06:30,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:31,242][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.7094853520393372, acc: 0.7037037014961243)
[2024-12-15 00:06:31,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:31,583][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.4833947420120239, acc: 0.8857142925262451)
[2024-12-15 00:06:31,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:31,968][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.5679287314414978, acc: 0.7954545617103577)
[2024-12-15 00:06:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:32,340][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.6175503730773926, acc: 0.8181818127632141)
[2024-12-15 00:06:32,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:32,951][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 1.0965996980667114, acc: 0.6129032373428345)
[2024-12-15 00:06:33,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:33,530][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.9193807244300842, acc: 0.6818181872367859)
[2024-12-15 00:06:33,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:33,899][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.383873850107193, acc: 0.9047619104385376)
[2024-12-15 00:06:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:34,236][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.6260380148887634, acc: 0.7307692170143127)
[2024-12-15 00:06:34,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:34,607][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.45395728945732117, acc: 0.8709677457809448)
[2024-12-15 00:06:34,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:34,942][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.37229347229003906, acc: 0.800000011920929)
[2024-12-15 00:06:35,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:35,326][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.5363492965698242, acc: 0.8648648858070374)
[2024-12-15 00:06:35,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:35,690][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.5695522427558899, acc: 0.8108108043670654)
[2024-12-15 00:06:35,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:36,105][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.4265507757663727, acc: 0.837837815284729)
[2024-12-15 00:06:36,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:36,474][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.7764459848403931, acc: 0.7647058963775635)
[2024-12-15 00:06:36,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:36,884][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.25209906697273254, acc: 0.9268292784690857)
[2024-12-15 00:06:36,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:37,239][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.11849765479564667, acc: 1.0)
[2024-12-15 00:06:37,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:37,579][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.1843487173318863, acc: 0.9599999785423279)
[2024-12-15 00:06:37,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:37,922][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.22398503124713898, acc: 0.9032257795333862)
[2024-12-15 00:06:38,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:38,262][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.8152562975883484, acc: 0.7017543911933899)
[2024-12-15 00:06:38,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:38,610][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.7357482314109802, acc: 0.7571428418159485)
[2024-12-15 00:06:38,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:38,966][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.8220694065093994, acc: 0.7236841917037964)
[2024-12-15 00:06:39,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:39,559][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 1.0528583526611328, acc: 0.6415094137191772)
[2024-12-15 00:06:39,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:40,161][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 1.3293430805206299, acc: 0.625)
[2024-12-15 00:06:40,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:40,540][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.6503260135650635, acc: 0.8055555820465088)
[2024-12-15 00:06:40,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:40,910][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.6262780427932739, acc: 0.8064516186714172)
[2024-12-15 00:06:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:41,266][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 1.4518725872039795, acc: 0.5600000023841858)
[2024-12-15 00:06:41,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:41,644][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.6880345344543457, acc: 0.7291666865348816)
[2024-12-15 00:06:42,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:42,546][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 1.702736735343933, acc: 0.5040000081062317)
[2024-12-15 00:06:42,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:42,893][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 1.2122361660003662, acc: 0.6404494643211365)
[2024-12-15 00:06:43,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:43,275][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 1.1649696826934814, acc: 0.6486486196517944)
[2024-12-15 00:06:43,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:43,848][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.7427388429641724, acc: 0.7758620977401733)
[2024-12-15 00:06:43,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:44,289][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.3872430920600891, acc: 0.8636363744735718)
[2024-12-15 00:06:45,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:45,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:46,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:46,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:46,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:47,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:47,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:48,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:48,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:49,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:49,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:49,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:50,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:51,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:51,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:51,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:52,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:52,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:53,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:53,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:53,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:53,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:54,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:54,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:54,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:55,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:55,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:56,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:56,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:56,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:57,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:57,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:58,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:58,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:59,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:06:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:00,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:00,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:00,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:01,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:01,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:02,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:02,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:02,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:03,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:03,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:03,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:04,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:05,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:05,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:05,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:06,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:06,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:06,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:07,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:07,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:08,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:09,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:09,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:09,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:10,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:10,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:11,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:11,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:11,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:12,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:12,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:13,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:13,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:13,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:14,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:14,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:15,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:16,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:16,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:17,093][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.3430, device='cuda:0') eval_epoch_loss=tensor(2.1214, device='cuda:0') eval_epoch_acc=tensor(0.5255, device='cuda:0')
[2024-12-15 00:07:17,094][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:07:17,095][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:07:17,933][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_9_step_270_loss_2.121419906616211/model.pt
[2024-12-15 00:07:17,958][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:07:18,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:18,401][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.5539840459823608, acc: 0.8181818127632141)
[2024-12-15 00:07:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:18,729][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.3904021978378296, acc: 0.9375)
[2024-12-15 00:07:18,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:19,102][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.7507343292236328, acc: 0.8333333134651184)
[2024-12-15 00:07:19,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:19,524][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.9642630219459534, acc: 0.7666666507720947)
[2024-12-15 00:07:19,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:19,885][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.5587266683578491, acc: 0.84375)
[2024-12-15 00:07:19,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:20,250][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.5244262218475342, acc: 0.8333333134651184)
[2024-12-15 00:07:20,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:20,582][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.6378620266914368, acc: 0.7931034564971924)
[2024-12-15 00:07:20,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:20,972][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.7594041228294373, acc: 0.800000011920929)
[2024-12-15 00:07:21,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:21,309][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.6374458074569702, acc: 0.8510638475418091)
[2024-12-15 00:07:21,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:21,668][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.7910180687904358, acc: 0.7708333134651184)
[2024-12-15 00:07:21,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:22,014][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.7002740502357483, acc: 0.8409090638160706)
[2024-12-15 00:07:22,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:22,459][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 1.0717008113861084, acc: 0.6626505851745605)
[2024-12-15 00:07:22,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:22,850][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 1.0721615552902222, acc: 0.7222222089767456)
[2024-12-15 00:07:22,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:23,199][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.5938469767570496, acc: 0.7631579041481018)
[2024-12-15 00:07:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:23,560][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.6394208669662476, acc: 0.7647058963775635)
[2024-12-15 00:07:23,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:23,932][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.3771360516548157, acc: 0.875)
[2024-12-15 00:07:24,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:24,293][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 1.1464109420776367, acc: 0.6328125)
[2024-12-15 00:07:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:24,650][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 1.1739037036895752, acc: 0.656000018119812)
[2024-12-15 00:07:24,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:25,001][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.9031372666358948, acc: 0.692307710647583)
[2024-12-15 00:07:25,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:25,352][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 1.4297404289245605, acc: 0.5776397585868835)
[2024-12-15 00:07:25,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:25,728][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 1.7183094024658203, acc: 0.5051546096801758)
[2024-12-15 00:07:25,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:26,069][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.6001635193824768, acc: 0.7272727489471436)
[2024-12-15 00:07:26,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:26,403][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.6828436851501465, acc: 0.7857142686843872)
[2024-12-15 00:07:26,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:26,777][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.7741830348968506, acc: 0.7586206793785095)
[2024-12-15 00:07:26,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:27,272][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.4665725827217102, acc: 0.8545454740524292)
[2024-12-15 00:07:27,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:27,844][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 1.381462812423706, acc: 0.623711347579956)
[2024-12-15 00:07:27,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:28,181][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.9996168613433838, acc: 0.7068965435028076)
[2024-12-15 00:07:28,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:28,559][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.6374549865722656, acc: 0.8518518805503845)
[2024-12-15 00:07:28,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:28,928][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.6962863206863403, acc: 0.8684210777282715)
[2024-12-15 00:07:29,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:29,272][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.5385215282440186, acc: 0.8571428656578064)
[2024-12-15 00:07:29,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:29,639][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.5804129838943481, acc: 0.8125)
[2024-12-15 00:07:29,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:30,028][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.7524948716163635, acc: 0.8113207817077637)
[2024-12-15 00:07:30,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:30,410][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.47198063135147095, acc: 0.8301886916160583)
[2024-12-15 00:07:30,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:30,762][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.5251006484031677, acc: 0.8235294222831726)
[2024-12-15 00:07:30,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:31,098][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.6446970701217651, acc: 0.8125)
[2024-12-15 00:07:31,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:31,454][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.9388266205787659, acc: 0.7540983557701111)
[2024-12-15 00:07:31,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:31,872][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.4729968309402466, acc: 0.8333333134651184)
[2024-12-15 00:07:31,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:32,247][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.35822635889053345, acc: 0.8421052694320679)
[2024-12-15 00:07:32,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:32,612][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.8703730702400208, acc: 0.7536231875419617)
[2024-12-15 00:07:32,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:33,067][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.9311991930007935, acc: 0.7777777910232544)
[2024-12-15 00:07:33,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:33,464][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.8105367422103882, acc: 0.7349397540092468)
[2024-12-15 00:07:33,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:33,835][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 1.0291796922683716, acc: 0.6282051205635071)
[2024-12-15 00:07:33,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:34,202][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 1.1556990146636963, acc: 0.6428571343421936)
[2024-12-15 00:07:34,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:34,563][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.2101445347070694, acc: 0.9166666865348816)
[2024-12-15 00:07:34,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:34,921][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.42974162101745605, acc: 0.8333333134651184)
[2024-12-15 00:07:35,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:35,291][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.465634286403656, acc: 0.8387096524238586)
[2024-12-15 00:07:35,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:35,659][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.2774055302143097, acc: 0.8709677457809448)
[2024-12-15 00:07:35,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:36,088][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.7115375399589539, acc: 0.8208954930305481)
[2024-12-15 00:07:36,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:36,492][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.9750474691390991, acc: 0.7115384340286255)
[2024-12-15 00:07:36,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:36,866][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.5098018050193787, acc: 0.8444444537162781)
[2024-12-15 00:07:36,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:37,230][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.969611406326294, acc: 0.7580645084381104)
[2024-12-15 00:07:37,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:37,614][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.4980561435222626, acc: 0.8199999928474426)
[2024-12-15 00:07:37,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:37,985][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.9313962459564209, acc: 0.7777777910232544)
[2024-12-15 00:07:38,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:38,350][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.9926859140396118, acc: 0.6285714507102966)
[2024-12-15 00:07:38,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:38,700][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.6792036890983582, acc: 0.7692307829856873)
[2024-12-15 00:07:38,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:39,056][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 1.1794353723526, acc: 0.707317054271698)
[2024-12-15 00:07:39,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:39,404][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.8221896290779114, acc: 0.7894737124443054)
[2024-12-15 00:07:39,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:39,738][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.3757801651954651, acc: 0.8421052694320679)
[2024-12-15 00:07:39,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:40,087][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.2847845256328583, acc: 0.8928571343421936)
[2024-12-15 00:07:40,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:40,432][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.7836449146270752, acc: 0.6666666865348816)
[2024-12-15 00:07:40,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:40,784][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.427810937166214, acc: 0.90625)
[2024-12-15 00:07:40,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:41,148][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.731302797794342, acc: 0.8225806355476379)
[2024-12-15 00:07:41,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:41,556][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.9877808094024658, acc: 0.7017543911933899)
[2024-12-15 00:07:41,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:41,958][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.7815258502960205, acc: 0.75)
[2024-12-15 00:07:42,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:42,298][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.7977355718612671, acc: 0.7666666507720947)
[2024-12-15 00:07:42,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:42,649][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.5384748578071594, acc: 0.8947368264198303)
[2024-12-15 00:07:42,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:43,051][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.7716538906097412, acc: 0.7799999713897705)
[2024-12-15 00:07:43,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:43,437][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 1.4803335666656494, acc: 0.517241358757019)
[2024-12-15 00:07:43,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:43,899][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 1.3704874515533447, acc: 0.5531914830207825)
[2024-12-15 00:07:44,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:44,362][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 1.3764899969100952, acc: 0.5421686768531799)
[2024-12-15 00:07:44,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:44,734][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.4703030288219452, acc: 0.8260869383811951)
[2024-12-15 00:07:44,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:45,099][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.5270986557006836, acc: 0.7948718070983887)
[2024-12-15 00:07:45,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:45,495][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.7735686898231506, acc: 0.759036123752594)
[2024-12-15 00:07:45,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:45,871][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.6998599767684937, acc: 0.8301886916160583)
[2024-12-15 00:07:45,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:46,292][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.6373897790908813, acc: 0.8354430198669434)
[2024-12-15 00:07:46,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:46,690][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.6792532205581665, acc: 0.7647058963775635)
[2024-12-15 00:07:46,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:47,083][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 1.0573457479476929, acc: 0.611940324306488)
[2024-12-15 00:07:47,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:47,451][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.37678849697113037, acc: 0.8999999761581421)
[2024-12-15 00:07:47,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:47,767][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.3482380211353302, acc: 0.9200000166893005)
[2024-12-15 00:07:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:48,198][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.5228302478790283, acc: 0.8333333134651184)
[2024-12-15 00:07:48,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:48,574][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.8321778178215027, acc: 0.7441860437393188)
[2024-12-15 00:07:48,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:48,964][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.562160849571228, acc: 0.8461538553237915)
[2024-12-15 00:07:49,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:49,364][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.7740235924720764, acc: 0.7333333492279053)
[2024-12-15 00:07:49,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:49,734][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.5174663662910461, acc: 0.695652186870575)
[2024-12-15 00:07:49,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:50,105][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.6017829775810242, acc: 0.7692307829856873)
[2024-12-15 00:07:50,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:50,480][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 1.4200340509414673, acc: 0.6153846383094788)
[2024-12-15 00:07:50,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:51,025][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 1.3184236288070679, acc: 0.626086950302124)
[2024-12-15 00:07:51,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:51,419][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 1.2863067388534546, acc: 0.6195651888847351)
[2024-12-15 00:07:51,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:51,795][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.9079557657241821, acc: 0.7551020383834839)
[2024-12-15 00:07:51,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:52,133][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.16208365559577942, acc: 0.9583333134651184)
[2024-12-15 00:07:52,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:52,492][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.3862837255001068, acc: 0.8461538553237915)
[2024-12-15 00:07:52,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:52,853][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.6889438629150391, acc: 0.8292682766914368)
[2024-12-15 00:07:52,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:53,227][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.6040456891059875, acc: 0.7777777910232544)
[2024-12-15 00:07:53,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:53,596][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.8646037578582764, acc: 0.7368420958518982)
[2024-12-15 00:07:53,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:54,002][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.8201603889465332, acc: 0.8048780560493469)
[2024-12-15 00:07:54,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:54,355][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.7765678763389587, acc: 0.7575757503509521)
[2024-12-15 00:07:54,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:54,691][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.43488240242004395, acc: 0.8333333134651184)
[2024-12-15 00:07:54,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:55,036][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.3147660195827484, acc: 0.95652174949646)
[2024-12-15 00:07:55,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:55,381][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.3439522087574005, acc: 0.9285714030265808)
[2024-12-15 00:07:55,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:55,738][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.5780525803565979, acc: 0.90625)
[2024-12-15 00:07:55,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:56,369][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 1.265172004699707, acc: 0.6545454263687134)
[2024-12-15 00:07:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:57,342][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 1.0155633687973022, acc: 0.7169811129570007)
[2024-12-15 00:07:57,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:57,823][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 1.0518460273742676, acc: 0.7111111283302307)
[2024-12-15 00:07:57,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:58,238][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.7834275960922241, acc: 0.8035714030265808)
[2024-12-15 00:07:58,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:58,672][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.4800759553909302, acc: 0.8857142925262451)
[2024-12-15 00:07:58,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:59,098][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.419895738363266, acc: 0.8399999737739563)
[2024-12-15 00:07:59,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:59,463][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.5512051582336426, acc: 0.8695651888847351)
[2024-12-15 00:07:59,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:07:59,808][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.7985150814056396, acc: 0.7708333134651184)
[2024-12-15 00:07:59,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:00,164][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.8476665019989014, acc: 0.7684210538864136)
[2024-12-15 00:08:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:00,761][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 1.2070629596710205, acc: 0.6706587076187134)
[2024-12-15 00:08:00,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:01,193][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 1.0668343305587769, acc: 0.6917293071746826)
[2024-12-15 00:08:01,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:02,423][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 1.2679328918457031, acc: 0.6363636255264282)
[2024-12-15 00:08:02,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:03,032][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.7658522129058838, acc: 0.7747747898101807)
[2024-12-15 00:08:03,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:03,424][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.6188458800315857, acc: 0.8214285969734192)
[2024-12-15 00:08:03,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:03,844][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.49426165223121643, acc: 0.7857142686843872)
[2024-12-15 00:08:03,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:04,215][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.522962749004364, acc: 0.8125)
[2024-12-15 00:08:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:04,585][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.4154876470565796, acc: 0.8055555820465088)
[2024-12-15 00:08:04,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:04,953][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.5072047114372253, acc: 0.7894737124443054)
[2024-12-15 00:08:05,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:05,303][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.47639837861061096, acc: 0.8181818127632141)
[2024-12-15 00:08:05,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:05,654][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.833647608757019, acc: 0.699999988079071)
[2024-12-15 00:08:05,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:06,049][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.4510144293308258, acc: 0.8571428656578064)
[2024-12-15 00:08:06,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:06,423][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.8514901399612427, acc: 0.7037037014961243)
[2024-12-15 00:08:06,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:06,866][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 1.360642910003662, acc: 0.6019417643547058)
[2024-12-15 00:08:07,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:07,416][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 1.396157145500183, acc: 0.6029411554336548)
[2024-12-15 00:08:07,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:07,819][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 1.4765517711639404, acc: 0.5799999833106995)
[2024-12-15 00:08:07,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:08,249][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 1.587051272392273, acc: 0.5625)
[2024-12-15 00:08:08,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:08,649][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.7057539224624634, acc: 0.7441860437393188)
[2024-12-15 00:08:08,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:09,049][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.6520673632621765, acc: 0.8333333134651184)
[2024-12-15 00:08:09,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:09,425][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.7115345001220703, acc: 0.8372092843055725)
[2024-12-15 00:08:09,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:09,856][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.4168093502521515, acc: 0.8399999737739563)
[2024-12-15 00:08:10,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:10,428][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.8112195134162903, acc: 0.7941176295280457)
[2024-12-15 00:08:10,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:10,923][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.861409604549408, acc: 0.6933333277702332)
[2024-12-15 00:08:11,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:11,373][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.6679776906967163, acc: 0.7575757503509521)
[2024-12-15 00:08:11,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:11,728][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.9260151982307434, acc: 0.8181818127632141)
[2024-12-15 00:08:11,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:12,101][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.4981761872768402, acc: 0.8064516186714172)
[2024-12-15 00:08:12,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:12,469][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.537625253200531, acc: 0.8518518805503845)
[2024-12-15 00:08:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:12,834][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.5164734721183777, acc: 0.8799999952316284)
[2024-12-15 00:08:12,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:13,275][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.5432347059249878, acc: 0.8055555820465088)
[2024-12-15 00:08:13,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:13,657][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.6327717900276184, acc: 0.8148148059844971)
[2024-12-15 00:08:13,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:14,037][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.44426679611206055, acc: 0.8461538553237915)
[2024-12-15 00:08:14,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:14,388][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.726988673210144, acc: 0.7586206793785095)
[2024-12-15 00:08:14,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:14,797][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.5060794949531555, acc: 0.8571428656578064)
[2024-12-15 00:08:14,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:15,195][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.4557497203350067, acc: 0.800000011920929)
[2024-12-15 00:08:16,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:16,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:16,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:17,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:17,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:18,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:18,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:19,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:19,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:19,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:20,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:20,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:21,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:21,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:22,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:22,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:23,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:23,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:23,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:24,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:24,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:24,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:25,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:25,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:26,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:26,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:27,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:27,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:27,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:28,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:28,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:28,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:29,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:29,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:30,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:30,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:30,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:31,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:31,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:32,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:32,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:32,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:33,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:33,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:34,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:34,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:34,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:34,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:35,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:35,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:36,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:36,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:36,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:37,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:37,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:38,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:38,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:39,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:39,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:39,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:40,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:40,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:40,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:41,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:41,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:42,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:42,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:43,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:44,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:44,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:44,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:45,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:45,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:45,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:46,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:46,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:46,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:47,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:47,645][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.4183, device='cuda:0') eval_epoch_loss=tensor(2.2427, device='cuda:0') eval_epoch_acc=tensor(0.5201, device='cuda:0')
[2024-12-15 00:08:47,646][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:08:47,646][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:08:48,502][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_9_step_413_loss_2.2426578998565674/model.pt
[2024-12-15 00:08:48,512][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:08:48,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:48,923][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.47894951701164246, acc: 0.8484848737716675)
[2024-12-15 00:08:49,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:49,250][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.5152616500854492, acc: 0.8181818127632141)
[2024-12-15 00:08:49,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:49,628][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.8588362336158752, acc: 0.7254902124404907)
[2024-12-15 00:08:49,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:49,997][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.6905914545059204, acc: 0.807692289352417)
[2024-12-15 00:08:50,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:50,353][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.9550551176071167, acc: 0.6666666865348816)
[2024-12-15 00:08:50,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:50,722][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.8475459218025208, acc: 0.7250000238418579)
[2024-12-15 00:08:50,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:51,068][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.7152656316757202, acc: 0.75)
[2024-12-15 00:08:51,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:51,413][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.4385395050048828, acc: 0.8095238208770752)
[2024-12-15 00:08:51,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:51,751][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.6313858032226562, acc: 0.8333333134651184)
[2024-12-15 00:08:51,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:52,098][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.5811713337898254, acc: 0.875)
[2024-12-15 00:08:52,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:52,474][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.48979270458221436, acc: 0.8333333134651184)
[2024-12-15 00:08:52,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:52,818][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.4631066620349884, acc: 0.8518518805503845)
[2024-12-15 00:08:52,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:53,193][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.5854055285453796, acc: 0.8181818127632141)
[2024-12-15 00:08:53,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:53,548][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.8341721296310425, acc: 0.782608687877655)
[2024-12-15 00:08:53,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:53,908][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.6386381983757019, acc: 0.8648648858070374)
[2024-12-15 00:08:54,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:54,255][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.6173202991485596, acc: 0.7777777910232544)
[2024-12-15 00:08:54,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:54,606][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.4333375096321106, acc: 0.8260869383811951)
[2024-12-15 00:08:54,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:55,047][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.2014816254377365, acc: 0.9259259104728699)
[2024-12-15 00:08:55,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:55,404][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.34660619497299194, acc: 0.8888888955116272)
[2024-12-15 00:08:55,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:55,758][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.4633658826351166, acc: 0.8695651888847351)
[2024-12-15 00:08:55,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:56,073][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.5194527506828308, acc: 0.8333333134651184)
[2024-12-15 00:08:56,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:56,422][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.47932350635528564, acc: 0.8399999737739563)
[2024-12-15 00:08:56,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:56,785][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.5112072825431824, acc: 0.8484848737716675)
[2024-12-15 00:08:56,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:57,226][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.9108089804649353, acc: 0.6666666865348816)
[2024-12-15 00:08:57,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:57,628][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.6924530863761902, acc: 0.7954545617103577)
[2024-12-15 00:08:57,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:58,002][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.2691088914871216, acc: 0.9523809552192688)
[2024-12-15 00:08:58,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:58,378][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.6121609807014465, acc: 0.7948718070983887)
[2024-12-15 00:08:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:58,877][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.8443259596824646, acc: 0.7424242496490479)
[2024-12-15 00:08:59,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:08:59,651][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 1.9204978942871094, acc: 0.4880000054836273)
[2024-12-15 00:08:59,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:00,086][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 1.5737700462341309, acc: 0.5806451439857483)
[2024-12-15 00:09:00,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:00,767][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 1.6112563610076904, acc: 0.5870646834373474)
[2024-12-15 00:09:00,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:01,206][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.813200056552887, acc: 0.7169811129570007)
[2024-12-15 00:09:01,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:01,661][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.4640306532382965, acc: 0.8636363744735718)
[2024-12-15 00:09:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:02,046][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.5358068943023682, acc: 0.8695651888847351)
[2024-12-15 00:09:02,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:02,405][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.6652308702468872, acc: 0.7692307829856873)
[2024-12-15 00:09:02,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:02,751][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.39287620782852173, acc: 0.8214285969734192)
[2024-12-15 00:09:02,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:03,217][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.6850185394287109, acc: 0.7910447716712952)
[2024-12-15 00:09:03,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:03,621][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.7411590814590454, acc: 0.7777777910232544)
[2024-12-15 00:09:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:04,028][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.8213850855827332, acc: 0.717391312122345)
[2024-12-15 00:09:04,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:04,414][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.7940388917922974, acc: 0.7948718070983887)
[2024-12-15 00:09:04,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:04,804][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.9560089111328125, acc: 0.6710526347160339)
[2024-12-15 00:09:04,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:05,188][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.7804653644561768, acc: 0.7755101919174194)
[2024-12-15 00:09:05,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:05,526][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.4315130412578583, acc: 0.8484848737716675)
[2024-12-15 00:09:05,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:05,903][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 1.3296608924865723, acc: 0.5979381203651428)
[2024-12-15 00:09:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:06,284][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.8019806146621704, acc: 0.7857142686843872)
[2024-12-15 00:09:06,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:06,718][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 1.474284291267395, acc: 0.5930232405662537)
[2024-12-15 00:09:06,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:07,106][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.8032240271568298, acc: 0.75)
[2024-12-15 00:09:07,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:07,483][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 1.075953483581543, acc: 0.6790123581886292)
[2024-12-15 00:09:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:07,829][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.48745182156562805, acc: 0.8888888955116272)
[2024-12-15 00:09:07,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:08,166][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.34955546259880066, acc: 0.90625)
[2024-12-15 00:09:08,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:08,498][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.4888341724872589, acc: 0.807692289352417)
[2024-12-15 00:09:08,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:08,852][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.502906858921051, acc: 0.8260869383811951)
[2024-12-15 00:09:08,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:09,226][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.9317724108695984, acc: 0.7142857313156128)
[2024-12-15 00:09:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:09,580][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.9173105359077454, acc: 0.7228915691375732)
[2024-12-15 00:09:09,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:09,975][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.7635279893875122, acc: 0.7567567825317383)
[2024-12-15 00:09:10,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:10,336][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 1.1036221981048584, acc: 0.6796116232872009)
[2024-12-15 00:09:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:10,711][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.8610967993736267, acc: 0.7154471278190613)
[2024-12-15 00:09:10,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:11,111][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.6614584922790527, acc: 0.8333333134651184)
[2024-12-15 00:09:11,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:11,544][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.5729756355285645, acc: 0.8214285969734192)
[2024-12-15 00:09:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:12,019][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 1.2740347385406494, acc: 0.6274510025978088)
[2024-12-15 00:09:12,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:12,462][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 1.7090471982955933, acc: 0.5458515286445618)
[2024-12-15 00:09:12,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:12,859][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 1.1120665073394775, acc: 0.71875)
[2024-12-15 00:09:13,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:13,328][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 1.377332091331482, acc: 0.6073619723320007)
[2024-12-15 00:09:13,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:13,688][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 1.2354674339294434, acc: 0.6402877569198608)
[2024-12-15 00:09:13,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:14,061][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 1.7205783128738403, acc: 0.5025125741958618)
[2024-12-15 00:09:14,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:14,410][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.3863332271575928, acc: 0.8611111044883728)
[2024-12-15 00:09:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:14,763][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.6110123991966248, acc: 0.7575757503509521)
[2024-12-15 00:09:14,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:15,116][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.6087470650672913, acc: 0.7037037014961243)
[2024-12-15 00:09:15,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:15,535][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.6669569611549377, acc: 0.800000011920929)
[2024-12-15 00:09:15,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:15,911][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.7802435159683228, acc: 0.699999988079071)
[2024-12-15 00:09:16,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:16,368][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.6565487384796143, acc: 0.7758620977401733)
[2024-12-15 00:09:16,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:16,748][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.39012354612350464, acc: 0.9032257795333862)
[2024-12-15 00:09:16,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:17,120][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.38111042976379395, acc: 0.8421052694320679)
[2024-12-15 00:09:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:17,460][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.7965690493583679, acc: 0.7407407164573669)
[2024-12-15 00:09:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:17,815][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.7275944352149963, acc: 0.8571428656578064)
[2024-12-15 00:09:17,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:18,202][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.6233905553817749, acc: 0.7727272510528564)
[2024-12-15 00:09:18,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:18,590][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.886307954788208, acc: 0.7076923251152039)
[2024-12-15 00:09:18,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:18,970][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.4942094385623932, acc: 0.8333333134651184)
[2024-12-15 00:09:19,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:19,318][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.6343430876731873, acc: 0.7586206793785095)
[2024-12-15 00:09:19,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:19,678][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.5691325068473816, acc: 0.7843137383460999)
[2024-12-15 00:09:19,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:20,024][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.5488269329071045, acc: 0.7241379022598267)
[2024-12-15 00:09:20,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:20,367][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.4172764718532562, acc: 0.8947368264198303)
[2024-12-15 00:09:20,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:20,773][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.9340351223945618, acc: 0.6842105388641357)
[2024-12-15 00:09:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:21,179][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.9195432662963867, acc: 0.7053571343421936)
[2024-12-15 00:09:21,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:21,645][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.9089201092720032, acc: 0.7078651785850525)
[2024-12-15 00:09:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:22,120][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 1.007197618484497, acc: 0.6853932738304138)
[2024-12-15 00:09:22,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:22,524][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 1.3111845254898071, acc: 0.5957446694374084)
[2024-12-15 00:09:22,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:22,885][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.9258649349212646, acc: 0.75)
[2024-12-15 00:09:22,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:23,239][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.428930401802063, acc: 0.8399999737739563)
[2024-12-15 00:09:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:23,590][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.6089174151420593, acc: 0.7692307829856873)
[2024-12-15 00:09:23,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:23,958][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.5385661125183105, acc: 0.7407407164573669)
[2024-12-15 00:09:24,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:24,315][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.5515397191047668, acc: 0.7777777910232544)
[2024-12-15 00:09:24,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:24,667][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.5890509486198425, acc: 0.8113207817077637)
[2024-12-15 00:09:24,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:25,037][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.44720807671546936, acc: 0.8620689511299133)
[2024-12-15 00:09:25,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:25,647][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 1.0118894577026367, acc: 0.684684693813324)
[2024-12-15 00:09:25,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:26,121][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.9109455347061157, acc: 0.7042253613471985)
[2024-12-15 00:09:26,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:26,542][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.21979279816150665, acc: 0.949999988079071)
[2024-12-15 00:09:26,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:26,918][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.4637966752052307, acc: 0.800000011920929)
[2024-12-15 00:09:27,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:27,251][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.8439127206802368, acc: 0.7307692170143127)
[2024-12-15 00:09:28,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:29,848][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 1.4312585592269897, acc: 0.5928571224212646)
[2024-12-15 00:09:30,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:30,640][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 1.2263596057891846, acc: 0.5952380895614624)
[2024-12-15 00:09:30,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:30,989][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.7002283334732056, acc: 0.7857142686843872)
[2024-12-15 00:09:31,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:31,349][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.8085892200469971, acc: 0.7166666388511658)
[2024-12-15 00:09:31,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:32,059][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.7859714031219482, acc: 0.7361111044883728)
[2024-12-15 00:09:32,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:32,413][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.47150707244873047, acc: 0.8461538553237915)
[2024-12-15 00:09:32,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:32,751][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.4622849225997925, acc: 0.8709677457809448)
[2024-12-15 00:09:32,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:33,106][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.6806707382202148, acc: 0.75)
[2024-12-15 00:09:33,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:33,478][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.8042480945587158, acc: 0.7037037014961243)
[2024-12-15 00:09:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:34,474][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 1.6011210680007935, acc: 0.5296609997749329)
[2024-12-15 00:09:34,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:34,919][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 1.236350417137146, acc: 0.6268656849861145)
[2024-12-15 00:09:35,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:35,405][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 1.2784171104431152, acc: 0.5839415788650513)
[2024-12-15 00:09:35,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:35,988][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 1.5675615072250366, acc: 0.5249999761581421)
[2024-12-15 00:09:36,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:36,341][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.6781312227249146, acc: 0.8333333134651184)
[2024-12-15 00:09:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:36,712][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.7019424438476562, acc: 0.75)
[2024-12-15 00:09:36,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:37,096][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.9325852990150452, acc: 0.7142857313156128)
[2024-12-15 00:09:37,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:37,464][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.7347712516784668, acc: 0.7868852615356445)
[2024-12-15 00:09:37,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:37,832][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.5158628225326538, acc: 0.8305084705352783)
[2024-12-15 00:09:37,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:38,225][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.8653001189231873, acc: 0.7674418687820435)
[2024-12-15 00:09:38,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:38,629][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.7322425842285156, acc: 0.6818181872367859)
[2024-12-15 00:09:38,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:39,037][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.6448472738265991, acc: 0.7547169923782349)
[2024-12-15 00:09:39,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:39,410][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.5730912685394287, acc: 0.8863636255264282)
[2024-12-15 00:09:39,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:39,751][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.6823621392250061, acc: 0.7200000286102295)
[2024-12-15 00:09:39,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:40,111][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.4196704924106598, acc: 0.8500000238418579)
[2024-12-15 00:09:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:40,501][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.5580330491065979, acc: 0.8636363744735718)
[2024-12-15 00:09:40,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:40,927][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.7342190742492676, acc: 0.7692307829856873)
[2024-12-15 00:09:41,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:41,302][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.7358484268188477, acc: 0.765625)
[2024-12-15 00:09:41,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:41,730][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.5781199336051941, acc: 0.8125)
[2024-12-15 00:09:41,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:42,090][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.72703617811203, acc: 0.6666666865348816)
[2024-12-15 00:09:42,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:42,486][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.8403281569480896, acc: 0.75)
[2024-12-15 00:09:42,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:42,847][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.4267385005950928, acc: 0.8064516186714172)
[2024-12-15 00:09:42,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:43,196][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.33217868208885193, acc: 0.9130434989929199)
[2024-12-15 00:09:43,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:43,608][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.4842701852321625, acc: 0.800000011920929)
[2024-12-15 00:09:43,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:43,980][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.5970920324325562, acc: 0.7560975551605225)
[2024-12-15 00:09:44,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:44,330][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.30638226866722107, acc: 0.8857142925262451)
[2024-12-15 00:09:44,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:44,673][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.4361439645290375, acc: 0.8421052694320679)
[2024-12-15 00:09:44,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:45,025][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.5069393515586853, acc: 0.9032257795333862)
[2024-12-15 00:09:45,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:45,391][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.21486030519008636, acc: 0.9599999785423279)
[2024-12-15 00:09:45,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:45,727][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.2897820472717285, acc: 0.9090909361839294)
[2024-12-15 00:09:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:46,061][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.4746739864349365, acc: 0.875)
[2024-12-15 00:09:46,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:46,423][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.6155942678451538, acc: 0.8142856955528259)
[2024-12-15 00:09:46,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:46,805][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 1.326830267906189, acc: 0.5620437860488892)
[2024-12-15 00:09:46,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:47,164][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 1.103956937789917, acc: 0.6758620738983154)
[2024-12-15 00:09:47,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:47,545][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 1.410164475440979, acc: 0.6000000238418579)
[2024-12-15 00:09:48,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:48,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:49,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:49,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:49,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:50,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:50,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:51,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:51,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:51,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:52,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:53,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:53,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:53,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:54,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:54,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:55,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:55,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:56,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:56,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:56,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:56,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:57,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:57,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:58,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:58,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:59,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:59,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:09:59,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:00,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:00,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:00,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:01,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:01,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:01,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:02,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:02,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:02,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:03,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:03,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:04,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:04,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:04,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:05,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:05,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:05,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:06,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:06,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:06,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:07,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:07,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:07,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:08,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:08,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:08,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:09,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:09,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:09,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:10,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:10,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:11,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:11,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:12,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:12,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:13,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:13,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:14,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:14,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:15,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:15,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:15,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:16,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:16,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:17,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:17,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:17,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:18,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:18,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:19,619][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.2168, device='cuda:0') eval_epoch_loss=tensor(2.3240, device='cuda:0') eval_epoch_acc=tensor(0.5262, device='cuda:0')
[2024-12-15 00:10:19,621][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:10:19,621][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:10:20,502][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_9_step_556_loss_2.324035406112671/model.pt
[2024-12-15 00:10:20,517][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:10:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:21,027][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 1.2785441875457764, acc: 0.5761589407920837)
[2024-12-15 00:10:21,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:21,387][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.959495484828949, acc: 0.7094017267227173)
[2024-12-15 00:10:21,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:21,837][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.20009557902812958, acc: 0.9599999785423279)
[2024-12-15 00:10:22,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:22,292][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.6018952131271362, acc: 0.807692289352417)
[2024-12-15 00:10:22,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:22,657][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.3658604919910431, acc: 0.8461538553237915)
[2024-12-15 00:10:22,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:23,011][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.4442587196826935, acc: 0.8717948794364929)
[2024-12-15 00:10:23,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:23,402][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.8266595005989075, acc: 0.7222222089767456)
[2024-12-15 00:10:23,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:23,846][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.8081769347190857, acc: 0.7662337422370911)
[2024-12-15 00:10:23,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:24,235][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.5086061358451843, acc: 0.8125)
[2024-12-15 00:10:24,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:24,609][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.7274203896522522, acc: 0.7758620977401733)
[2024-12-15 00:10:24,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:25,029][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 1.125402569770813, acc: 0.6190476417541504)
[2024-12-15 00:10:25,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:25,367][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.36119815707206726, acc: 0.8684210777282715)
[2024-12-15 00:10:25,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:25,714][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.33954301476478577, acc: 0.8518518805503845)
[2024-12-15 00:10:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:26,152][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 1.7087124586105347, acc: 0.5614973306655884)
[2024-12-15 00:10:26,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:26,532][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.8472719788551331, acc: 0.6935483813285828)
[2024-12-15 00:10:26,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:26,880][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 1.0108329057693481, acc: 0.7264957427978516)
[2024-12-15 00:10:26,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:27,232][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 1.6254308223724365, acc: 0.545918345451355)
[2024-12-15 00:10:27,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:27,600][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 1.6288769245147705, acc: 0.5345911979675293)
[2024-12-15 00:10:28,028][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=2.3014, train_epoch_loss=0.8335, epoch time 379.8351299019996s
[2024-12-15 00:10:28,028][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-15 00:10:28,028][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-15 00:10:28,028][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-15 00:10:28,029][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 27
[2024-12-15 00:10:28,029][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-15 00:10:28,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:28,979][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.4614243805408478, acc: 0.8888888955116272)
[2024-12-15 00:10:29,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:29,342][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.6081545948982239, acc: 0.800000011920929)
[2024-12-15 00:10:29,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:29,780][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.8135262727737427, acc: 0.7297297120094299)
[2024-12-15 00:10:29,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:30,177][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.8983578681945801, acc: 0.7105262875556946)
[2024-12-15 00:10:30,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:30,554][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.80939120054245, acc: 0.7567567825317383)
[2024-12-15 00:10:30,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:31,017][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.6186375021934509, acc: 0.75)
[2024-12-15 00:10:31,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:31,409][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.924987256526947, acc: 0.7346938848495483)
[2024-12-15 00:10:31,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:31,829][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.6746084094047546, acc: 0.7333333492279053)
[2024-12-15 00:10:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:32,259][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.31466367840766907, acc: 0.9545454382896423)
[2024-12-15 00:10:32,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:32,643][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.3928898274898529, acc: 0.8846153616905212)
[2024-12-15 00:10:32,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:33,018][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.5786087512969971, acc: 0.8148148059844971)
[2024-12-15 00:10:33,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:33,395][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.7357432246208191, acc: 0.7692307829856873)
[2024-12-15 00:10:33,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:33,734][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.5206653475761414, acc: 0.8181818127632141)
[2024-12-15 00:10:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:34,118][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.5869365930557251, acc: 0.782608687877655)
[2024-12-15 00:10:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:34,535][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.8050044775009155, acc: 0.7254902124404907)
[2024-12-15 00:10:34,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:34,921][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.8292126059532166, acc: 0.7346938848495483)
[2024-12-15 00:10:35,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:35,284][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.29282650351524353, acc: 0.9473684430122375)
[2024-12-15 00:10:35,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:35,704][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.5854731798171997, acc: 0.8333333134651184)
[2024-12-15 00:10:35,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:36,121][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.5910924077033997, acc: 0.8611111044883728)
[2024-12-15 00:10:36,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:36,458][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.6938905715942383, acc: 0.6842105388641357)
[2024-12-15 00:10:36,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:36,828][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.6144891977310181, acc: 0.807692289352417)
[2024-12-15 00:10:36,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:37,227][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.7092384696006775, acc: 0.7586206793785095)
[2024-12-15 00:10:37,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:37,640][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.6855420470237732, acc: 0.800000011920929)
[2024-12-15 00:10:37,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:38,035][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.47328534722328186, acc: 0.8095238208770752)
[2024-12-15 00:10:38,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:38,394][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.3152613937854767, acc: 0.875)
[2024-12-15 00:10:38,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:38,751][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.5122070908546448, acc: 0.8301886916160583)
[2024-12-15 00:10:38,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:39,171][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.8486222624778748, acc: 0.7260273694992065)
[2024-12-15 00:10:39,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:40,468][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 1.7579562664031982, acc: 0.52173912525177)
[2024-12-15 00:10:40,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:40,855][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.7529376745223999, acc: 0.7209302186965942)
[2024-12-15 00:10:41,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:41,331][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.8776844143867493, acc: 0.7349397540092468)
[2024-12-15 00:10:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:41,804][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.7423825860023499, acc: 0.7530864477157593)
[2024-12-15 00:10:41,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:42,221][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.37845587730407715, acc: 0.8928571343421936)
[2024-12-15 00:10:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:42,657][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.6925029754638672, acc: 0.6666666865348816)
[2024-12-15 00:10:42,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:43,073][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.6508755683898926, acc: 0.782608687877655)
[2024-12-15 00:10:43,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:43,532][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 1.3240667581558228, acc: 0.5966386795043945)
[2024-12-15 00:10:43,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:43,976][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.7281776666641235, acc: 0.8196721076965332)
[2024-12-15 00:10:44,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:44,432][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.6995457410812378, acc: 0.7301587462425232)
[2024-12-15 00:10:44,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:44,901][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.7560219764709473, acc: 0.7288135886192322)
[2024-12-15 00:10:45,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:45,417][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.6792576313018799, acc: 0.8045976758003235)
[2024-12-15 00:10:45,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:45,867][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.5722619295120239, acc: 0.8571428656578064)
[2024-12-15 00:10:46,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:46,383][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.5898371338844299, acc: 0.8846153616905212)
[2024-12-15 00:10:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:46,905][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 1.0717756748199463, acc: 0.6486486196517944)
[2024-12-15 00:10:47,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:47,313][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.9354252219200134, acc: 0.7384615540504456)
[2024-12-15 00:10:47,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:47,798][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 1.23774254322052, acc: 0.6666666865348816)
[2024-12-15 00:10:47,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:48,276][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.9898661375045776, acc: 0.7113401889801025)
[2024-12-15 00:10:48,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:48,736][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 1.4190653562545776, acc: 0.6029411554336548)
[2024-12-15 00:10:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:49,151][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.6733654737472534, acc: 0.7692307829856873)
[2024-12-15 00:10:49,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:49,492][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.2757260203361511, acc: 0.8518518805503845)
[2024-12-15 00:10:49,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:49,892][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.7064231038093567, acc: 0.8214285969734192)
[2024-12-15 00:10:50,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:50,367][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.39063721895217896, acc: 0.8611111044883728)
[2024-12-15 00:10:50,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:50,814][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.6206412315368652, acc: 0.8070175647735596)
[2024-12-15 00:10:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:51,187][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.6771676540374756, acc: 0.7777777910232544)
[2024-12-15 00:10:51,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:51,576][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.8836522102355957, acc: 0.7323943376541138)
[2024-12-15 00:10:51,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:52,096][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 1.347687840461731, acc: 0.6000000238418579)
[2024-12-15 00:10:52,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:52,553][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.3835119307041168, acc: 0.8918918967247009)
[2024-12-15 00:10:52,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:53,004][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.32570913434028625, acc: 0.9230769276618958)
[2024-12-15 00:10:54,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:55,911][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 1.5974682569503784, acc: 0.5665528774261475)
[2024-12-15 00:10:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:57,161][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 2.1420786380767822, acc: 0.43790850043296814)
[2024-12-15 00:10:57,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:57,850][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 1.4863712787628174, acc: 0.5909090638160706)
[2024-12-15 00:10:58,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:58,486][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 1.312831163406372, acc: 0.6397058963775635)
[2024-12-15 00:10:58,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:59,077][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 1.5270402431488037, acc: 0.5072463750839233)
[2024-12-15 00:10:59,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:59,532][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 1.0777534246444702, acc: 0.699999988079071)
[2024-12-15 00:10:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:10:59,942][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.5467769503593445, acc: 0.8823529481887817)
[2024-12-15 00:11:00,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:00,358][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.6939022541046143, acc: 0.7222222089767456)
[2024-12-15 00:11:00,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:00,786][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.5248467326164246, acc: 0.84375)
[2024-12-15 00:11:00,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:01,220][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.48546522855758667, acc: 0.931034505367279)
[2024-12-15 00:11:01,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:01,663][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.7946870923042297, acc: 0.7321428656578064)
[2024-12-15 00:11:01,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:02,092][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.7366240620613098, acc: 0.7833333611488342)
[2024-12-15 00:11:02,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:02,486][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.28147652745246887, acc: 0.8799999952316284)
[2024-12-15 00:11:02,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:02,882][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.4803384244441986, acc: 0.8611111044883728)
[2024-12-15 00:11:02,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:03,282][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.6924505233764648, acc: 0.7272727489471436)
[2024-12-15 00:11:03,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:03,705][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 1.186313271522522, acc: 0.6764705777168274)
[2024-12-15 00:11:03,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:04,106][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 1.1624839305877686, acc: 0.6746031641960144)
[2024-12-15 00:11:04,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:04,499][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 1.6420081853866577, acc: 0.5128205418586731)
[2024-12-15 00:11:04,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:04,895][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.9075688123703003, acc: 0.7448979616165161)
[2024-12-15 00:11:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:05,315][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 1.239525556564331, acc: 0.6194030046463013)
[2024-12-15 00:11:05,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:05,783][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 1.8090611696243286, acc: 0.5218977928161621)
[2024-12-15 00:11:05,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:06,176][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.2794227600097656, acc: 0.9047619104385376)
[2024-12-15 00:11:06,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:06,578][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.30742451548576355, acc: 0.9166666865348816)
[2024-12-15 00:11:06,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:06,953][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.6029280424118042, acc: 0.7575757503509521)
[2024-12-15 00:11:07,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:07,335][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.4085712432861328, acc: 0.8461538553237915)
[2024-12-15 00:11:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:07,799][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.5296034812927246, acc: 0.8461538553237915)
[2024-12-15 00:11:07,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:08,252][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.7579306364059448, acc: 0.807692289352417)
[2024-12-15 00:11:08,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:08,663][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.562402606010437, acc: 0.78125)
[2024-12-15 00:11:08,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:09,064][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.693742036819458, acc: 0.7681159377098083)
[2024-12-15 00:11:09,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:09,450][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.6633789539337158, acc: 0.7799999713897705)
[2024-12-15 00:11:09,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:09,893][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.6969475746154785, acc: 0.695652186870575)
[2024-12-15 00:11:10,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:10,440][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.8189707398414612, acc: 0.7400000095367432)
[2024-12-15 00:11:10,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:10,932][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.6701940298080444, acc: 0.7961165308952332)
[2024-12-15 00:11:11,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:12,160][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 1.4840587377548218, acc: 0.6165048480033875)
[2024-12-15 00:11:12,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:13,271][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 1.614459753036499, acc: 0.5698924660682678)
[2024-12-15 00:11:13,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:14,158][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 1.4539815187454224, acc: 0.5862069129943848)
[2024-12-15 00:11:14,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:14,927][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.9157377481460571, acc: 0.7157894968986511)
[2024-12-15 00:11:15,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:15,997][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 1.2662923336029053, acc: 0.6435643434524536)
[2024-12-15 00:11:16,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:16,467][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 1.0841807126998901, acc: 0.6451612710952759)
[2024-12-15 00:11:16,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:16,873][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.8332033157348633, acc: 0.7536231875419617)
[2024-12-15 00:11:16,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:17,290][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 1.2654411792755127, acc: 0.605042040348053)
[2024-12-15 00:11:17,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:17,692][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 1.439098596572876, acc: 0.5384615659713745)
[2024-12-15 00:11:17,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:18,136][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 1.4354901313781738, acc: 0.5912408828735352)
[2024-12-15 00:11:18,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:18,608][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.7252591252326965, acc: 0.8059701323509216)
[2024-12-15 00:11:18,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:19,057][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.504752516746521, acc: 0.800000011920929)
[2024-12-15 00:11:19,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:19,439][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.47754356265068054, acc: 0.8636363744735718)
[2024-12-15 00:11:19,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:19,894][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.47700586915016174, acc: 0.8695651888847351)
[2024-12-15 00:11:20,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:20,387][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.49073389172554016, acc: 0.8181818127632141)
[2024-12-15 00:11:20,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:20,813][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.7294652462005615, acc: 0.7931034564971924)
[2024-12-15 00:11:20,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:21,219][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.4070344567298889, acc: 0.8837209343910217)
[2024-12-15 00:11:21,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:21,577][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.7887338399887085, acc: 0.6000000238418579)
[2024-12-15 00:11:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:21,965][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.22918426990509033, acc: 0.9411764740943909)
[2024-12-15 00:11:22,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:22,369][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.352292001247406, acc: 0.9615384340286255)
[2024-12-15 00:11:22,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:22,804][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.28695324063301086, acc: 0.9285714030265808)
[2024-12-15 00:11:22,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:23,209][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.6917425990104675, acc: 0.800000011920929)
[2024-12-15 00:11:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:23,718][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.8089439868927002, acc: 0.7894737124443054)
[2024-12-15 00:11:23,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:24,174][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.7552581429481506, acc: 0.7894737124443054)
[2024-12-15 00:11:24,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:24,605][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.7132065892219543, acc: 0.7948718070983887)
[2024-12-15 00:11:24,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:25,100][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.38158127665519714, acc: 0.8775510191917419)
[2024-12-15 00:11:25,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:25,468][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.21443258225917816, acc: 0.9090909361839294)
[2024-12-15 00:11:25,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:25,867][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.6288478970527649, acc: 0.8253968358039856)
[2024-12-15 00:11:25,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:26,254][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 1.0270459651947021, acc: 0.6991869807243347)
[2024-12-15 00:11:26,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:26,643][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.4824371635913849, acc: 0.8548387289047241)
[2024-12-15 00:11:27,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:27,542][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 1.7055307626724243, acc: 0.5437262654304504)
[2024-12-15 00:11:27,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:27,938][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.7555144429206848, acc: 0.7599999904632568)
[2024-12-15 00:11:28,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:28,394][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.5915651917457581, acc: 0.807692289352417)
[2024-12-15 00:11:28,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:28,762][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.47296154499053955, acc: 0.875)
[2024-12-15 00:11:28,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:29,217][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.5673487186431885, acc: 0.8421052694320679)
[2024-12-15 00:11:29,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:29,645][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 1.313647985458374, acc: 0.6319018602371216)
[2024-12-15 00:11:31,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:31,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:32,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:32,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:32,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:33,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:33,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:33,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:34,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:34,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:34,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:35,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:35,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:36,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:37,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:37,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:37,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:38,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:39,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:39,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:39,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:40,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:40,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:41,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:41,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:41,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:42,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:42,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:43,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:43,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:44,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:44,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:44,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:45,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:45,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:46,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:46,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:47,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:47,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:47,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:48,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:49,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:49,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:50,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:50,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:50,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:51,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:51,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:51,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:52,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:52,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:52,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:53,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:53,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:53,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:54,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:54,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:55,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:55,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:55,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:56,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:56,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:57,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:57,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:58,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:58,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:58,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:59,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:11:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:00,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:00,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:01,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:02,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:02,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:03,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:03,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:04,229][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.2741, device='cuda:0') eval_epoch_loss=tensor(2.2272, device='cuda:0') eval_epoch_acc=tensor(0.5331, device='cuda:0')
[2024-12-15 00:12:04,230][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:12:04,231][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:12:05,011][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_10_step_125_loss_2.227222204208374/model.pt
[2024-12-15 00:12:05,025][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:12:05,026][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.5330842733383179
[2024-12-15 00:12:05,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:05,594][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 1.066826343536377, acc: 0.7152777910232544)
[2024-12-15 00:12:05,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:06,056][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 1.0257328748703003, acc: 0.6916666626930237)
[2024-12-15 00:12:06,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:06,518][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 1.323007345199585, acc: 0.5416666865348816)
[2024-12-15 00:12:06,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:06,892][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 1.4191793203353882, acc: 0.5794872045516968)
[2024-12-15 00:12:07,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:07,323][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 1.0961558818817139, acc: 0.6691176295280457)
[2024-12-15 00:12:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:07,682][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.5021689534187317, acc: 0.8846153616905212)
[2024-12-15 00:12:07,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:08,034][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.2814168930053711, acc: 0.9130434989929199)
[2024-12-15 00:12:08,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:08,453][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.6087387800216675, acc: 0.84375)
[2024-12-15 00:12:08,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:08,834][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.5477083325386047, acc: 0.782608687877655)
[2024-12-15 00:12:08,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:09,201][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.5629884004592896, acc: 0.800000011920929)
[2024-12-15 00:12:09,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:09,563][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.33526942133903503, acc: 0.807692289352417)
[2024-12-15 00:12:09,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:09,928][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.5852483510971069, acc: 0.8333333134651184)
[2024-12-15 00:12:10,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:10,304][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.869378387928009, acc: 0.800000011920929)
[2024-12-15 00:12:10,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:10,651][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.4387166500091553, acc: 0.8695651888847351)
[2024-12-15 00:12:10,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:11,007][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.5529034733772278, acc: 0.8095238208770752)
[2024-12-15 00:12:11,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:11,384][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.95443195104599, acc: 0.807692289352417)
[2024-12-15 00:12:11,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:11,731][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.49938708543777466, acc: 0.8387096524238586)
[2024-12-15 00:12:11,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:12,086][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.8646091222763062, acc: 0.7567567825317383)
[2024-12-15 00:12:12,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:12,671][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 1.321954369544983, acc: 0.5964912176132202)
[2024-12-15 00:12:12,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:13,059][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 1.0455166101455688, acc: 0.6791045069694519)
[2024-12-15 00:12:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:13,448][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 1.456566333770752, acc: 0.5612244606018066)
[2024-12-15 00:12:13,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:13,943][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 1.2275491952896118, acc: 0.5957446694374084)
[2024-12-15 00:12:14,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:14,310][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.9155862927436829, acc: 0.6428571343421936)
[2024-12-15 00:12:14,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:14,657][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.8063920140266418, acc: 0.7142857313156128)
[2024-12-15 00:12:14,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:15,000][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.5964838266372681, acc: 0.782608687877655)
[2024-12-15 00:12:15,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:15,414][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.5513496994972229, acc: 0.7931034564971924)
[2024-12-15 00:12:15,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:15,872][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.660122811794281, acc: 0.8478260636329651)
[2024-12-15 00:12:16,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:16,312][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 1.0006455183029175, acc: 0.694915235042572)
[2024-12-15 00:12:16,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:16,735][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.815035343170166, acc: 0.7543859481811523)
[2024-12-15 00:12:16,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:17,107][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.9347826838493347, acc: 0.7162162065505981)
[2024-12-15 00:12:17,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:17,462][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.6354771852493286, acc: 0.8214285969734192)
[2024-12-15 00:12:17,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:17,881][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.731127142906189, acc: 0.8695651888847351)
[2024-12-15 00:12:18,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:18,329][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.4528549611568451, acc: 0.7894737124443054)
[2024-12-15 00:12:19,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:20,651][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.8423473238945007, acc: 0.7297297120094299)
[2024-12-15 00:12:20,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:21,013][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.9486260414123535, acc: 0.7407407164573669)
[2024-12-15 00:12:21,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:21,463][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.9596866965293884, acc: 0.7093023061752319)
[2024-12-15 00:12:21,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:22,089][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.6919167637825012, acc: 0.7882353067398071)
[2024-12-15 00:12:22,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:22,674][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 1.156142234802246, acc: 0.6067415475845337)
[2024-12-15 00:12:22,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:23,038][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.4379153549671173, acc: 0.8636363744735718)
[2024-12-15 00:12:23,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:23,383][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.4613671600818634, acc: 0.8571428656578064)
[2024-12-15 00:12:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:23,734][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 1.0173442363739014, acc: 0.5862069129943848)
[2024-12-15 00:12:23,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:24,074][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.768526017665863, acc: 0.7346938848495483)
[2024-12-15 00:12:24,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:24,424][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.7903144359588623, acc: 0.7599999904632568)
[2024-12-15 00:12:24,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:24,862][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 1.0870919227600098, acc: 0.625)
[2024-12-15 00:12:24,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:25,240][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 1.181203842163086, acc: 0.6176470518112183)
[2024-12-15 00:12:25,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:26,293][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 1.660957932472229, acc: 0.5547945499420166)
[2024-12-15 00:12:26,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:26,656][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.4963642358779907, acc: 0.8333333134651184)
[2024-12-15 00:12:26,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:27,039][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.33772823214530945, acc: 0.9259259104728699)
[2024-12-15 00:12:27,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:27,408][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.46137484908103943, acc: 0.8571428656578064)
[2024-12-15 00:12:27,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:27,974][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 1.0431886911392212, acc: 0.7168141603469849)
[2024-12-15 00:12:28,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:28,330][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.7605971097946167, acc: 0.7536231875419617)
[2024-12-15 00:12:28,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:28,689][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 1.110848069190979, acc: 0.6477272510528564)
[2024-12-15 00:12:29,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:29,645][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 1.8808600902557373, acc: 0.49618321657180786)
[2024-12-15 00:12:29,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:30,336][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 1.585882306098938, acc: 0.5259259343147278)
[2024-12-15 00:12:30,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:30,700][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.6473457217216492, acc: 0.7868852615356445)
[2024-12-15 00:12:30,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:31,087][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.26272428035736084, acc: 0.9583333134651184)
[2024-12-15 00:12:31,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:31,454][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.34313368797302246, acc: 0.8399999737739563)
[2024-12-15 00:12:31,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:31,790][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.582656741142273, acc: 0.7857142686843872)
[2024-12-15 00:12:31,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:32,164][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 1.0472711324691772, acc: 0.707317054271698)
[2024-12-15 00:12:32,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:32,602][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 1.7588582038879395, acc: 0.5015105605125427)
[2024-12-15 00:12:32,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:32,985][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 2.01395320892334, acc: 0.44668588042259216)
[2024-12-15 00:12:33,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:33,492][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 1.964896559715271, acc: 0.4625000059604645)
[2024-12-15 00:12:33,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:34,039][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 2.0364274978637695, acc: 0.43151968717575073)
[2024-12-15 00:12:34,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:34,523][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 1.7734684944152832, acc: 0.5088967680931091)
[2024-12-15 00:12:34,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:34,905][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.5790210962295532, acc: 0.800000011920929)
[2024-12-15 00:12:35,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:35,493][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 1.6047359704971313, acc: 0.5232558250427246)
[2024-12-15 00:12:35,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:36,320][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 1.5339707136154175, acc: 0.5714285969734192)
[2024-12-15 00:12:36,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:37,259][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 1.5072065591812134, acc: 0.5757575631141663)
[2024-12-15 00:12:37,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:38,027][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 1.2617871761322021, acc: 0.6823529601097107)
[2024-12-15 00:12:38,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:39,212][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 1.3835235834121704, acc: 0.5987654328346252)
[2024-12-15 00:12:39,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:40,199][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 1.0802984237670898, acc: 0.6612903475761414)
[2024-12-15 00:12:40,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:40,633][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.4143921434879303, acc: 0.8214285969734192)
[2024-12-15 00:12:40,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:41,014][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.8627293705940247, acc: 0.75)
[2024-12-15 00:12:41,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:41,393][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.9815939664840698, acc: 0.7352941036224365)
[2024-12-15 00:12:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:41,789][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 1.2790600061416626, acc: 0.6176470518112183)
[2024-12-15 00:12:41,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:42,211][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 1.325677752494812, acc: 0.6016949415206909)
[2024-12-15 00:12:42,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:42,634][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 1.316271424293518, acc: 0.5895522236824036)
[2024-12-15 00:12:42,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:43,033][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 1.1892890930175781, acc: 0.6213592290878296)
[2024-12-15 00:12:43,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:43,407][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.6979175806045532, acc: 0.8571428656578064)
[2024-12-15 00:12:43,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:43,776][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.9209312200546265, acc: 0.6813187003135681)
[2024-12-15 00:12:43,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:44,181][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 1.660567045211792, acc: 0.5112107396125793)
[2024-12-15 00:12:44,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:44,638][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 1.6095380783081055, acc: 0.5314960479736328)
[2024-12-15 00:12:44,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:45,045][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 1.4630688428878784, acc: 0.5775862336158752)
[2024-12-15 00:12:45,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:45,428][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 1.6097526550292969, acc: 0.5362318754196167)
[2024-12-15 00:12:45,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:45,831][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 1.5986747741699219, acc: 0.5214007496833801)
[2024-12-15 00:12:45,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:46,215][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 1.0753101110458374, acc: 0.6739130616188049)
[2024-12-15 00:12:46,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:46,549][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.4973215162754059, acc: 0.8260869383811951)
[2024-12-15 00:12:46,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:46,902][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.6906906962394714, acc: 0.7857142686843872)
[2024-12-15 00:12:47,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:47,329][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.5025664567947388, acc: 0.8936170339584351)
[2024-12-15 00:12:47,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:48,063][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.9706920385360718, acc: 0.7230769395828247)
[2024-12-15 00:12:48,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:48,424][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.6232632398605347, acc: 0.8108108043670654)
[2024-12-15 00:12:48,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:48,801][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.8811725974082947, acc: 0.8139534592628479)
[2024-12-15 00:12:48,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:49,372][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.984023928642273, acc: 0.6936936974525452)
[2024-12-15 00:12:49,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:49,807][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.7497337460517883, acc: 0.7777777910232544)
[2024-12-15 00:12:49,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:50,167][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.24416784942150116, acc: 1.0)
[2024-12-15 00:12:50,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:50,552][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.22974003851413727, acc: 0.9259259104728699)
[2024-12-15 00:12:50,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:50,902][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.37108907103538513, acc: 0.8799999952316284)
[2024-12-15 00:12:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:51,260][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.6760384440422058, acc: 0.7692307829856873)
[2024-12-15 00:12:51,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:52,073][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.9071723818778992, acc: 0.7228260636329651)
[2024-12-15 00:12:52,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:52,640][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 1.1221059560775757, acc: 0.6818181872367859)
[2024-12-15 00:12:52,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:53,118][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.832847535610199, acc: 0.7127659320831299)
[2024-12-15 00:12:53,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:53,522][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.5887889266014099, acc: 0.8301886916160583)
[2024-12-15 00:12:53,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:53,869][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.6994007229804993, acc: 0.7833333611488342)
[2024-12-15 00:12:53,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:54,233][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.4716627299785614, acc: 0.8837209343910217)
[2024-12-15 00:12:54,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:54,591][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.7484223246574402, acc: 0.7666666507720947)
[2024-12-15 00:12:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:54,996][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.7510727643966675, acc: 0.7684210538864136)
[2024-12-15 00:12:55,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:55,390][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.6391131281852722, acc: 0.7888888716697693)
[2024-12-15 00:12:55,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:55,851][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.8836680054664612, acc: 0.7611111402511597)
[2024-12-15 00:12:56,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:56,393][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 1.3246195316314697, acc: 0.6605504751205444)
[2024-12-15 00:12:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:56,907][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.8295707106590271, acc: 0.7307692170143127)
[2024-12-15 00:12:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:57,263][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.6211946606636047, acc: 0.7894737124443054)
[2024-12-15 00:12:57,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:57,625][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.31988611817359924, acc: 0.9166666865348816)
[2024-12-15 00:12:57,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:58,005][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.8721128106117249, acc: 0.6818181872367859)
[2024-12-15 00:12:58,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:58,439][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.6830435395240784, acc: 0.7037037014961243)
[2024-12-15 00:12:58,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:58,843][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.3645343780517578, acc: 0.9142857193946838)
[2024-12-15 00:12:58,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:59,276][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.6580719947814941, acc: 0.8181818127632141)
[2024-12-15 00:12:59,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:12:59,710][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.5169753432273865, acc: 0.8636363744735718)
[2024-12-15 00:12:59,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:00,324][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 1.0478159189224243, acc: 0.6774193644523621)
[2024-12-15 00:13:00,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:00,903][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.7993793487548828, acc: 0.7954545617103577)
[2024-12-15 00:13:01,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:01,315][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.5676079988479614, acc: 0.9047619104385376)
[2024-12-15 00:13:01,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:01,684][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.5603563785552979, acc: 0.807692289352417)
[2024-12-15 00:13:01,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:02,094][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.35862746834754944, acc: 0.8387096524238586)
[2024-12-15 00:13:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:02,525][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.516591489315033, acc: 0.75)
[2024-12-15 00:13:02,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:02,978][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.7739554047584534, acc: 0.7297297120094299)
[2024-12-15 00:13:03,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:03,423][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.6330256462097168, acc: 0.837837815284729)
[2024-12-15 00:13:03,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:03,856][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.4917248487472534, acc: 0.8648648858070374)
[2024-12-15 00:13:04,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:04,290][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.9648860692977905, acc: 0.6911764740943909)
[2024-12-15 00:13:04,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:04,711][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.32571133971214294, acc: 0.9024389982223511)
[2024-12-15 00:13:04,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:05,101][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.18211732804775238, acc: 0.9599999785423279)
[2024-12-15 00:13:05,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:05,511][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.2751708924770355, acc: 0.9200000166893005)
[2024-12-15 00:13:05,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:05,920][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.2943553924560547, acc: 0.8709677457809448)
[2024-12-15 00:13:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:06,289][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.4821625053882599, acc: 0.8245614171028137)
[2024-12-15 00:13:06,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:06,685][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.7185627818107605, acc: 0.7857142686843872)
[2024-12-15 00:13:06,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:07,075][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.6636388897895813, acc: 0.8157894611358643)
[2024-12-15 00:13:07,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:07,663][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.9855251908302307, acc: 0.6698113083839417)
[2024-12-15 00:13:07,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:08,265][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 1.1853731870651245, acc: 0.6666666865348816)
[2024-12-15 00:13:08,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:08,728][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.42598623037338257, acc: 0.9166666865348816)
[2024-12-15 00:13:08,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:09,116][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.6208158731460571, acc: 0.774193525314331)
[2024-12-15 00:13:09,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:09,537][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 1.1523066759109497, acc: 0.6666666865348816)
[2024-12-15 00:13:09,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:09,977][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.7798042893409729, acc: 0.7708333134651184)
[2024-12-15 00:13:10,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:10,880][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 1.6164356470108032, acc: 0.5120000243186951)
[2024-12-15 00:13:10,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:11,309][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 1.1378244161605835, acc: 0.6629213690757751)
[2024-12-15 00:13:11,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:11,720][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 1.0970309972763062, acc: 0.6891891956329346)
[2024-12-15 00:13:12,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:12,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:13,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:13,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:13,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:14,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:14,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:15,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:15,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:15,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:16,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:16,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:17,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:17,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:18,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:18,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:18,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:19,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:19,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:19,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:20,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:20,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:21,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:21,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:21,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:22,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:22,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:23,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:23,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:23,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:24,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:24,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:24,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:25,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:25,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:25,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:26,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:26,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:26,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:27,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:27,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:28,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:28,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:29,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:29,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:30,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:30,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:31,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:31,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:32,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:32,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:32,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:33,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:33,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:34,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:34,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:35,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:35,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:35,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:36,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:36,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:37,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:37,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:37,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:38,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:38,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:39,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:39,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:39,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:40,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:41,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:41,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:42,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:42,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:43,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:43,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:44,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:44,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:44,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:45,504][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.4943, device='cuda:0') eval_epoch_loss=tensor(2.2507, device='cuda:0') eval_epoch_acc=tensor(0.5260, device='cuda:0')
[2024-12-15 00:13:45,505][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:13:45,506][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:13:46,209][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_10_step_268_loss_2.250687837600708/model.pt
[2024-12-15 00:13:46,213][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:13:46,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:46,834][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.6689001321792603, acc: 0.7931034564971924)
[2024-12-15 00:13:46,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:47,249][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.583554208278656, acc: 0.8636363744735718)
[2024-12-15 00:13:47,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:47,704][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.4335986375808716, acc: 0.8181818127632141)
[2024-12-15 00:13:47,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:48,084][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.3228878378868103, acc: 0.90625)
[2024-12-15 00:13:48,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:48,552][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.48153045773506165, acc: 0.800000011920929)
[2024-12-15 00:13:48,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:49,001][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.9748026728630066, acc: 0.6833333373069763)
[2024-12-15 00:13:49,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:49,416][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.4179099202156067, acc: 0.875)
[2024-12-15 00:13:49,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:49,812][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.22582216560840607, acc: 0.9666666388511658)
[2024-12-15 00:13:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:50,197][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.5140961408615112, acc: 0.7931034564971924)
[2024-12-15 00:13:50,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:50,591][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.7732604146003723, acc: 0.7599999904632568)
[2024-12-15 00:13:50,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:50,980][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.5177915096282959, acc: 0.8085106611251831)
[2024-12-15 00:13:51,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:51,366][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.7980439066886902, acc: 0.75)
[2024-12-15 00:13:51,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:51,777][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.5045142769813538, acc: 0.8636363744735718)
[2024-12-15 00:13:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:52,241][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 1.0615895986557007, acc: 0.6385542154312134)
[2024-12-15 00:13:52,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:52,633][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 1.127239465713501, acc: 0.6851851940155029)
[2024-12-15 00:13:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:53,014][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.41743186116218567, acc: 0.8421052694320679)
[2024-12-15 00:13:53,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:53,373][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.6499588489532471, acc: 0.7941176295280457)
[2024-12-15 00:13:53,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:53,731][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.23649263381958008, acc: 0.949999988079071)
[2024-12-15 00:13:53,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:54,135][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 1.2050676345825195, acc: 0.625)
[2024-12-15 00:13:54,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:54,542][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 1.2942512035369873, acc: 0.6000000238418579)
[2024-12-15 00:13:54,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:54,920][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.8099358677864075, acc: 0.7802197933197021)
[2024-12-15 00:13:55,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:55,288][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 1.4656723737716675, acc: 0.5776397585868835)
[2024-12-15 00:13:55,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:55,687][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 1.6205689907073975, acc: 0.5206185579299927)
[2024-12-15 00:13:55,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:56,043][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.34777960181236267, acc: 0.8181818127632141)
[2024-12-15 00:13:56,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:56,392][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.4421517550945282, acc: 0.8333333134651184)
[2024-12-15 00:13:56,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:56,773][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.7086347341537476, acc: 0.7586206793785095)
[2024-12-15 00:13:56,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:57,293][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.5574498772621155, acc: 0.8363636136054993)
[2024-12-15 00:13:57,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:57,868][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 1.1983352899551392, acc: 0.6546391844749451)
[2024-12-15 00:13:57,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:58,213][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.761396050453186, acc: 0.7241379022598267)
[2024-12-15 00:13:58,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:58,598][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.7626038789749146, acc: 0.7407407164573669)
[2024-12-15 00:13:58,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:58,990][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.6619948148727417, acc: 0.8157894611358643)
[2024-12-15 00:13:59,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:59,370][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.4103993773460388, acc: 0.8571428656578064)
[2024-12-15 00:13:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:13:59,727][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.5639603734016418, acc: 0.875)
[2024-12-15 00:13:59,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:00,118][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.4022718369960785, acc: 0.9056603908538818)
[2024-12-15 00:14:00,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:00,539][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.27890175580978394, acc: 0.9056603908538818)
[2024-12-15 00:14:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:00,990][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.4239443242549896, acc: 0.7941176295280457)
[2024-12-15 00:14:01,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:01,343][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.31163039803504944, acc: 0.9375)
[2024-12-15 00:14:01,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:01,701][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.7327075004577637, acc: 0.7377049326896667)
[2024-12-15 00:14:01,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:02,047][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.384513795375824, acc: 0.8333333134651184)
[2024-12-15 00:14:02,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:02,404][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.2901301383972168, acc: 0.9473684430122375)
[2024-12-15 00:14:02,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:02,780][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 1.0223842859268188, acc: 0.6811594367027283)
[2024-12-15 00:14:02,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:03,278][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.8291639685630798, acc: 0.7777777910232544)
[2024-12-15 00:14:03,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:03,720][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.7636480927467346, acc: 0.759036123752594)
[2024-12-15 00:14:03,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:04,101][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 1.051249384880066, acc: 0.692307710647583)
[2024-12-15 00:14:04,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:04,489][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 1.12932550907135, acc: 0.6428571343421936)
[2024-12-15 00:14:04,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:04,903][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.1255456954240799, acc: 1.0)
[2024-12-15 00:14:05,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:05,262][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.5137875080108643, acc: 0.8333333134651184)
[2024-12-15 00:14:05,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:05,636][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.4291646182537079, acc: 0.8387096524238586)
[2024-12-15 00:14:05,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:06,003][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.49900227785110474, acc: 0.8064516186714172)
[2024-12-15 00:14:06,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:06,379][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.671582818031311, acc: 0.8208954930305481)
[2024-12-15 00:14:06,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:06,768][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.8860329985618591, acc: 0.75)
[2024-12-15 00:14:06,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:07,221][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.6542699337005615, acc: 0.800000011920929)
[2024-12-15 00:14:07,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:07,641][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.5061287879943848, acc: 0.8548387289047241)
[2024-12-15 00:14:07,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:08,131][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.46116581559181213, acc: 0.8799999952316284)
[2024-12-15 00:14:08,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:08,527][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.9352000951766968, acc: 0.5925925970077515)
[2024-12-15 00:14:08,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:08,952][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.54984050989151, acc: 0.8285714387893677)
[2024-12-15 00:14:09,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:09,305][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.6845077276229858, acc: 0.7948718070983887)
[2024-12-15 00:14:09,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:09,650][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.6941140294075012, acc: 0.8048780560493469)
[2024-12-15 00:14:09,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:10,001][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.7895416617393494, acc: 0.8157894611358643)
[2024-12-15 00:14:10,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:10,346][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.3240538239479065, acc: 0.8947368264198303)
[2024-12-15 00:14:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:10,719][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.3003673553466797, acc: 0.8928571343421936)
[2024-12-15 00:14:10,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:11,105][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.5531609058380127, acc: 0.8148148059844971)
[2024-12-15 00:14:11,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:11,482][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.5121959447860718, acc: 0.90625)
[2024-12-15 00:14:11,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:11,876][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.8065255880355835, acc: 0.7580645084381104)
[2024-12-15 00:14:11,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:12,272][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.9330750107765198, acc: 0.7017543911933899)
[2024-12-15 00:14:12,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:12,635][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.8286557197570801, acc: 0.78125)
[2024-12-15 00:14:12,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:13,010][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.6276626586914062, acc: 0.8333333134651184)
[2024-12-15 00:14:13,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:13,355][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.5844206809997559, acc: 0.7894737124443054)
[2024-12-15 00:14:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:13,720][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.9653216600418091, acc: 0.6800000071525574)
[2024-12-15 00:14:13,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:14,091][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 1.1286194324493408, acc: 0.6321839094161987)
[2024-12-15 00:14:14,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:14,463][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 1.0441275835037231, acc: 0.7021276354789734)
[2024-12-15 00:14:14,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:14,819][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 1.1516575813293457, acc: 0.6265060305595398)
[2024-12-15 00:14:14,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:15,179][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.40459221601486206, acc: 0.8260869383811951)
[2024-12-15 00:14:15,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:15,538][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.34909266233444214, acc: 0.8974359035491943)
[2024-12-15 00:14:15,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:15,918][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.5340757369995117, acc: 0.8433734774589539)
[2024-12-15 00:14:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:16,344][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.5331223607063293, acc: 0.8679245114326477)
[2024-12-15 00:14:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:16,789][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.5447971820831299, acc: 0.797468364238739)
[2024-12-15 00:14:16,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:17,183][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.49451345205307007, acc: 0.8039215803146362)
[2024-12-15 00:14:17,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:17,543][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.819450318813324, acc: 0.7761194109916687)
[2024-12-15 00:14:17,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:17,898][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.33602240681648254, acc: 0.8999999761581421)
[2024-12-15 00:14:17,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:18,248][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.7389698624610901, acc: 0.800000011920929)
[2024-12-15 00:14:18,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:18,681][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.4609031677246094, acc: 0.8888888955116272)
[2024-12-15 00:14:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:19,059][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.8673515319824219, acc: 0.6976743936538696)
[2024-12-15 00:14:19,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:19,451][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.7989740371704102, acc: 0.8205128312110901)
[2024-12-15 00:14:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:19,855][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.5351629257202148, acc: 0.8222222328186035)
[2024-12-15 00:14:19,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:20,204][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.3639656901359558, acc: 0.8695651888847351)
[2024-12-15 00:14:20,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:20,567][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.44764137268066406, acc: 0.8846153616905212)
[2024-12-15 00:14:20,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:21,011][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 1.0513538122177124, acc: 0.6813187003135681)
[2024-12-15 00:14:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:21,565][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 1.2227421998977661, acc: 0.634782612323761)
[2024-12-15 00:14:21,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:21,958][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.9278743863105774, acc: 0.72826087474823)
[2024-12-15 00:14:22,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:22,336][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.8411397337913513, acc: 0.7142857313156128)
[2024-12-15 00:14:22,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:22,714][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.15284784138202667, acc: 0.9583333134651184)
[2024-12-15 00:14:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:23,056][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.5017052292823792, acc: 0.7307692170143127)
[2024-12-15 00:14:23,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:23,457][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.6163315773010254, acc: 0.8292682766914368)
[2024-12-15 00:14:23,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:23,862][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.5007137060165405, acc: 0.8222222328186035)
[2024-12-15 00:14:24,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:24,262][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.7921131253242493, acc: 0.7894737124443054)
[2024-12-15 00:14:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:24,689][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.792296826839447, acc: 0.7804877758026123)
[2024-12-15 00:14:24,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:25,128][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.6676135063171387, acc: 0.7878788113594055)
[2024-12-15 00:14:25,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:25,496][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.7664600014686584, acc: 0.8333333134651184)
[2024-12-15 00:14:25,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:25,905][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.19891801476478577, acc: 1.0)
[2024-12-15 00:14:26,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:26,351][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.6430349349975586, acc: 0.8571428656578064)
[2024-12-15 00:14:26,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:26,745][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.5448048114776611, acc: 0.8125)
[2024-12-15 00:14:26,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:27,387][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 1.1839345693588257, acc: 0.6606060862541199)
[2024-12-15 00:14:27,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:28,332][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.9281556606292725, acc: 0.7735849022865295)
[2024-12-15 00:14:28,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:28,726][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 1.0064290761947632, acc: 0.7222222089767456)
[2024-12-15 00:14:28,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:29,127][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.791586697101593, acc: 0.7142857313156128)
[2024-12-15 00:14:29,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:29,504][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.3358309268951416, acc: 0.9428571462631226)
[2024-12-15 00:14:29,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:29,935][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.1823829710483551, acc: 1.0)
[2024-12-15 00:14:30,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:30,303][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.48835456371307373, acc: 0.8260869383811951)
[2024-12-15 00:14:30,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:30,654][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.6859191060066223, acc: 0.7916666865348816)
[2024-12-15 00:14:30,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:31,016][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.8061365485191345, acc: 0.7473683953285217)
[2024-12-15 00:14:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:31,640][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 1.1393264532089233, acc: 0.658682644367218)
[2024-12-15 00:14:31,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:32,084][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.9520508050918579, acc: 0.7368420958518982)
[2024-12-15 00:14:32,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:33,558][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 1.1920467615127563, acc: 0.6737967729568481)
[2024-12-15 00:14:33,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:34,190][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.6671234965324402, acc: 0.7477477192878723)
[2024-12-15 00:14:34,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:34,656][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.3993595242500305, acc: 0.8571428656578064)
[2024-12-15 00:14:34,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:35,059][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.4588332772254944, acc: 0.8571428656578064)
[2024-12-15 00:14:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:35,496][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.4226544499397278, acc: 0.90625)
[2024-12-15 00:14:35,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:35,852][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.3157450258731842, acc: 0.9166666865348816)
[2024-12-15 00:14:35,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:36,193][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.4427512288093567, acc: 0.8421052694320679)
[2024-12-15 00:14:36,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:36,554][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.40335842967033386, acc: 0.8636363744735718)
[2024-12-15 00:14:36,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:36,915][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.7280045747756958, acc: 0.699999988079071)
[2024-12-15 00:14:37,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:37,318][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.4275033473968506, acc: 0.8571428656578064)
[2024-12-15 00:14:37,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:37,666][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.8594225645065308, acc: 0.7592592835426331)
[2024-12-15 00:14:37,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:38,076][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 1.4120415449142456, acc: 0.5631067752838135)
[2024-12-15 00:14:38,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:38,651][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 1.3614397048950195, acc: 0.5882353186607361)
[2024-12-15 00:14:38,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:39,100][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 1.5323269367218018, acc: 0.5866666436195374)
[2024-12-15 00:14:39,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:39,533][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 1.5027339458465576, acc: 0.6111111044883728)
[2024-12-15 00:14:39,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:39,912][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 1.0280957221984863, acc: 0.6976743936538696)
[2024-12-15 00:14:40,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:40,341][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.6253150105476379, acc: 0.7916666865348816)
[2024-12-15 00:14:40,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:40,750][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.5275598764419556, acc: 0.8604651093482971)
[2024-12-15 00:14:40,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:41,161][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.4665093719959259, acc: 0.8399999737739563)
[2024-12-15 00:14:41,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:41,733][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.8456107378005981, acc: 0.7352941036224365)
[2024-12-15 00:14:41,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:42,133][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.7118250727653503, acc: 0.7733333110809326)
[2024-12-15 00:14:42,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:42,522][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.5303850173950195, acc: 0.8787878751754761)
[2024-12-15 00:14:42,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:42,872][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.5594553351402283, acc: 0.8484848737716675)
[2024-12-15 00:14:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:43,230][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.44431859254837036, acc: 0.8387096524238586)
[2024-12-15 00:14:43,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:43,576][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.4041830599308014, acc: 0.8888888955116272)
[2024-12-15 00:14:43,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:43,922][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.5185056924819946, acc: 0.8799999952316284)
[2024-12-15 00:14:44,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:44,271][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.3952525556087494, acc: 0.8611111044883728)
[2024-12-15 00:14:44,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:44,699][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.42978259921073914, acc: 0.8888888955116272)
[2024-12-15 00:14:44,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:45,128][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.2086736261844635, acc: 0.9615384340286255)
[2024-12-15 00:14:45,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:45,581][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.5774574875831604, acc: 0.8275862336158752)
[2024-12-15 00:14:46,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:46,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:46,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:47,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:47,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:47,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:48,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:48,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:49,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:49,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:49,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:50,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:50,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:50,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:51,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:51,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:52,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:52,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:52,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:53,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:53,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:53,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:54,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:55,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:55,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:56,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:56,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:56,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:57,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:57,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:57,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:58,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:58,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:58,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:59,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:14:59,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:00,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:00,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:01,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:01,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:01,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:02,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:02,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:03,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:03,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:03,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:04,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:04,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:04,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:05,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:06,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:06,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:06,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:07,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:07,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:08,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:08,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:08,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:09,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:09,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:10,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:10,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:10,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:11,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:12,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:12,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:12,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:13,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:13,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:13,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:14,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:14,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:14,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:15,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:16,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:16,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:16,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:17,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:17,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:18,433][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(8.7504, device='cuda:0') eval_epoch_loss=tensor(2.1691, device='cuda:0') eval_epoch_acc=tensor(0.5379, device='cuda:0')
[2024-12-15 00:15:18,435][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:15:18,435][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:15:19,136][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_10_step_411_loss_2.1690986156463623/model.pt
[2024-12-15 00:15:19,147][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:15:19,148][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.5379030108451843
[2024-12-15 00:15:19,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:19,636][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.27455925941467285, acc: 0.8928571343421936)
[2024-12-15 00:15:19,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:20,044][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.2002352923154831, acc: 0.9666666388511658)
[2024-12-15 00:15:20,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:20,489][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.4468179941177368, acc: 0.8484848737716675)
[2024-12-15 00:15:20,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:20,863][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.5200404524803162, acc: 0.8181818127632141)
[2024-12-15 00:15:21,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:21,296][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.8235083222389221, acc: 0.7647058963775635)
[2024-12-15 00:15:21,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:21,767][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.6464201807975769, acc: 0.7692307829856873)
[2024-12-15 00:15:21,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:22,147][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.8729487657546997, acc: 0.6666666865348816)
[2024-12-15 00:15:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:22,588][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.6644022464752197, acc: 0.824999988079071)
[2024-12-15 00:15:22,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:23,017][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.5887355208396912, acc: 0.800000011920929)
[2024-12-15 00:15:23,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:23,432][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.33790138363838196, acc: 0.9047619104385376)
[2024-12-15 00:15:23,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:23,807][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.39761778712272644, acc: 0.8333333134651184)
[2024-12-15 00:15:23,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:24,232][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.5034016370773315, acc: 0.84375)
[2024-12-15 00:15:24,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:24,639][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.510086178779602, acc: 0.8055555820465088)
[2024-12-15 00:15:24,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:25,030][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.7397019863128662, acc: 0.7777777910232544)
[2024-12-15 00:15:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:25,439][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.6336793899536133, acc: 0.7878788113594055)
[2024-12-15 00:15:25,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:25,816][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.8869931697845459, acc: 0.782608687877655)
[2024-12-15 00:15:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:26,214][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.6203956604003906, acc: 0.8648648858070374)
[2024-12-15 00:15:26,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:26,634][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.4176369905471802, acc: 0.8518518805503845)
[2024-12-15 00:15:26,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:27,011][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.5248528122901917, acc: 0.782608687877655)
[2024-12-15 00:15:27,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:27,380][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.2716240882873535, acc: 0.8888888955116272)
[2024-12-15 00:15:27,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:27,740][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.3443658947944641, acc: 0.8888888955116272)
[2024-12-15 00:15:27,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:28,133][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.4121128022670746, acc: 0.8695651888847351)
[2024-12-15 00:15:28,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:28,602][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.46487632393836975, acc: 0.8611111044883728)
[2024-12-15 00:15:28,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:29,069][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.400700181722641, acc: 0.8399999737739563)
[2024-12-15 00:15:29,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:29,507][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.5868503451347351, acc: 0.8484848737716675)
[2024-12-15 00:15:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:29,891][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.4534892439842224, acc: 0.8055555820465088)
[2024-12-15 00:15:30,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:30,339][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.6574366688728333, acc: 0.8181818127632141)
[2024-12-15 00:15:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:30,753][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.212253138422966, acc: 0.9523809552192688)
[2024-12-15 00:15:30,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:31,098][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.7011004090309143, acc: 0.8461538553237915)
[2024-12-15 00:15:31,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:31,640][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.8257703185081482, acc: 0.7727272510528564)
[2024-12-15 00:15:32,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:32,460][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 1.604551076889038, acc: 0.5360000133514404)
[2024-12-15 00:15:32,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:32,918][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 1.32937490940094, acc: 0.6451612710952759)
[2024-12-15 00:15:33,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:33,587][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 1.5187737941741943, acc: 0.5671641826629639)
[2024-12-15 00:15:33,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:33,954][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.6232330799102783, acc: 0.8301886916160583)
[2024-12-15 00:15:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:34,405][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.32815471291542053, acc: 0.9318181872367859)
[2024-12-15 00:15:34,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:34,764][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.4296790361404419, acc: 0.8695651888847351)
[2024-12-15 00:15:34,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:35,105][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.43671077489852905, acc: 0.8461538553237915)
[2024-12-15 00:15:35,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:35,554][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.6810329556465149, acc: 0.7857142686843872)
[2024-12-15 00:15:35,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:36,019][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.6881012916564941, acc: 0.8059701323509216)
[2024-12-15 00:15:36,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:36,462][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.54884934425354, acc: 0.8194444179534912)
[2024-12-15 00:15:36,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:36,861][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.6206414103507996, acc: 0.79347825050354)
[2024-12-15 00:15:36,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:37,253][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.7071969509124756, acc: 0.7820512652397156)
[2024-12-15 00:15:37,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:37,620][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.6412116885185242, acc: 0.7763158082962036)
[2024-12-15 00:15:37,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:38,054][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.6857075095176697, acc: 0.795918345451355)
[2024-12-15 00:15:38,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:38,467][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.3363516330718994, acc: 0.8484848737716675)
[2024-12-15 00:15:38,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:38,900][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 1.1920390129089355, acc: 0.6494845151901245)
[2024-12-15 00:15:39,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:39,281][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.7592649459838867, acc: 0.7857142686843872)
[2024-12-15 00:15:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:39,742][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 1.2632862329483032, acc: 0.6395348906517029)
[2024-12-15 00:15:39,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:40,122][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.6558499336242676, acc: 0.75)
[2024-12-15 00:15:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:40,498][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 1.043687105178833, acc: 0.7160493731498718)
[2024-12-15 00:15:40,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:40,915][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.46269410848617554, acc: 0.8888888955116272)
[2024-12-15 00:15:41,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:41,350][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.3440740704536438, acc: 0.9375)
[2024-12-15 00:15:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:41,737][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.4752292335033417, acc: 0.8461538553237915)
[2024-12-15 00:15:41,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:42,179][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.41650909185409546, acc: 0.8695651888847351)
[2024-12-15 00:15:42,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:42,594][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.8223252296447754, acc: 0.75)
[2024-12-15 00:15:42,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:43,054][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.8373904824256897, acc: 0.7469879388809204)
[2024-12-15 00:15:43,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:43,510][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.7776778340339661, acc: 0.7837837934494019)
[2024-12-15 00:15:43,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:43,896][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 1.0239276885986328, acc: 0.6796116232872009)
[2024-12-15 00:15:44,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:44,297][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.9142077565193176, acc: 0.7154471278190613)
[2024-12-15 00:15:44,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:44,704][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.661045253276825, acc: 0.7916666865348816)
[2024-12-15 00:15:44,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:45,155][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.4992803633213043, acc: 0.8214285969734192)
[2024-12-15 00:15:45,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:45,633][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 1.2079229354858398, acc: 0.6470588445663452)
[2024-12-15 00:15:45,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:46,045][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 1.519138216972351, acc: 0.5633187890052795)
[2024-12-15 00:15:46,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:46,422][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 1.0377025604248047, acc: 0.7083333134651184)
[2024-12-15 00:15:46,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:46,819][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 1.289516568183899, acc: 0.6012269854545593)
[2024-12-15 00:15:46,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:47,211][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 1.1111152172088623, acc: 0.6043165326118469)
[2024-12-15 00:15:47,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:47,609][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 1.6019738912582397, acc: 0.5427135825157166)
[2024-12-15 00:15:47,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:47,956][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.3797501027584076, acc: 0.8888888955116272)
[2024-12-15 00:15:48,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:48,326][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.6099557280540466, acc: 0.8484848737716675)
[2024-12-15 00:15:48,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:48,678][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.7043251991271973, acc: 0.7777777910232544)
[2024-12-15 00:15:48,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:49,032][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.6369538307189941, acc: 0.8500000238418579)
[2024-12-15 00:15:49,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:49,372][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.42628416419029236, acc: 0.8999999761581421)
[2024-12-15 00:15:49,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:49,803][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.6765970587730408, acc: 0.7413793206214905)
[2024-12-15 00:15:49,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:50,177][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.43190357089042664, acc: 0.8387096524238586)
[2024-12-15 00:15:50,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:50,619][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.34437835216522217, acc: 0.8947368264198303)
[2024-12-15 00:15:50,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:51,034][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.7152611017227173, acc: 0.7777777910232544)
[2024-12-15 00:15:51,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:51,426][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.7717588543891907, acc: 0.761904776096344)
[2024-12-15 00:15:51,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:51,857][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.627976655960083, acc: 0.7272727489471436)
[2024-12-15 00:15:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:52,294][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.5551843643188477, acc: 0.8769230842590332)
[2024-12-15 00:15:52,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:52,713][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.5873128771781921, acc: 0.7666666507720947)
[2024-12-15 00:15:52,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:53,102][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.6220505833625793, acc: 0.7931034564971924)
[2024-12-15 00:15:53,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:53,467][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.5062382817268372, acc: 0.843137264251709)
[2024-12-15 00:15:53,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:53,793][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.6364832520484924, acc: 0.7586206793785095)
[2024-12-15 00:15:53,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:54,200][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.33866286277770996, acc: 0.8947368264198303)
[2024-12-15 00:15:54,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:54,663][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.6470412015914917, acc: 0.6842105388641357)
[2024-12-15 00:15:54,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:55,110][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.8968104720115662, acc: 0.6785714030265808)
[2024-12-15 00:15:55,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:55,588][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.7800852060317993, acc: 0.7977527976036072)
[2024-12-15 00:15:55,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:56,049][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.8814836144447327, acc: 0.7191011309623718)
[2024-12-15 00:15:56,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:56,460][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 1.2797844409942627, acc: 0.652482271194458)
[2024-12-15 00:15:56,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:56,846][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.8740735054016113, acc: 0.72826087474823)
[2024-12-15 00:15:56,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:57,273][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.35609063506126404, acc: 0.8399999737739563)
[2024-12-15 00:15:57,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:57,706][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.5304504632949829, acc: 0.8846153616905212)
[2024-12-15 00:15:57,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:58,121][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.4604846239089966, acc: 0.7777777910232544)
[2024-12-15 00:15:58,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:58,466][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.6975507140159607, acc: 0.7037037014961243)
[2024-12-15 00:15:58,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:58,869][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.7196721434593201, acc: 0.7735849022865295)
[2024-12-15 00:15:58,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:59,248][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.5873389840126038, acc: 0.7931034564971924)
[2024-12-15 00:15:59,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:15:59,869][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 1.0684022903442383, acc: 0.6666666865348816)
[2024-12-15 00:16:00,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:00,349][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.8710639476776123, acc: 0.7323943376541138)
[2024-12-15 00:16:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:00,704][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.12968376278877258, acc: 0.8999999761581421)
[2024-12-15 00:16:00,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:01,156][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.38583824038505554, acc: 0.8666666746139526)
[2024-12-15 00:16:01,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:01,533][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.40855005383491516, acc: 0.8461538553237915)
[2024-12-15 00:16:03,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:04,547][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 1.2563860416412354, acc: 0.6642857193946838)
[2024-12-15 00:16:04,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:05,332][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.9627287983894348, acc: 0.7063491940498352)
[2024-12-15 00:16:05,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:05,742][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.26543304324150085, acc: 0.9285714030265808)
[2024-12-15 00:16:05,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:06,183][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.7886123657226562, acc: 0.7333333492279053)
[2024-12-15 00:16:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:06,896][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.6566803455352783, acc: 0.7916666865348816)
[2024-12-15 00:16:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:07,260][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.20927412807941437, acc: 0.9615384340286255)
[2024-12-15 00:16:07,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:07,630][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.5471378564834595, acc: 0.8064516186714172)
[2024-12-15 00:16:07,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:08,015][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.9690150022506714, acc: 0.699999988079071)
[2024-12-15 00:16:08,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:08,429][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.5701937675476074, acc: 0.8148148059844971)
[2024-12-15 00:16:08,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:09,487][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 1.6055567264556885, acc: 0.5296609997749329)
[2024-12-15 00:16:09,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:09,952][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 1.203525185585022, acc: 0.641791045665741)
[2024-12-15 00:16:10,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:10,387][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 1.109457015991211, acc: 0.6277372241020203)
[2024-12-15 00:16:10,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:10,970][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 1.3381385803222656, acc: 0.625)
[2024-12-15 00:16:11,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:11,383][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.7410722374916077, acc: 0.7037037014961243)
[2024-12-15 00:16:11,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:11,802][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.5922941565513611, acc: 0.8461538553237915)
[2024-12-15 00:16:11,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:12,216][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.666983962059021, acc: 0.8571428656578064)
[2024-12-15 00:16:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:12,717][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 1.0922662019729614, acc: 0.7377049326896667)
[2024-12-15 00:16:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:13,143][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.5394729971885681, acc: 0.8305084705352783)
[2024-12-15 00:16:13,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:13,582][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.789726972579956, acc: 0.7209302186965942)
[2024-12-15 00:16:13,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:14,030][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.5975655317306519, acc: 0.7727272510528564)
[2024-12-15 00:16:14,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:14,405][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.6652564406394958, acc: 0.7735849022865295)
[2024-12-15 00:16:14,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:14,773][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.42938753962516785, acc: 0.9318181872367859)
[2024-12-15 00:16:14,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:15,172][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.48210400342941284, acc: 0.8399999737739563)
[2024-12-15 00:16:15,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:15,674][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.22644619643688202, acc: 0.949999988079071)
[2024-12-15 00:16:15,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:16,029][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.4317833185195923, acc: 0.8181818127632141)
[2024-12-15 00:16:16,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:16,451][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.6495655179023743, acc: 0.7846153974533081)
[2024-12-15 00:16:16,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:16,895][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.6095598936080933, acc: 0.84375)
[2024-12-15 00:16:17,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:17,393][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.5294437408447266, acc: 0.875)
[2024-12-15 00:16:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:17,829][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.63587486743927, acc: 0.7878788113594055)
[2024-12-15 00:16:17,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:18,227][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.397224485874176, acc: 0.875)
[2024-12-15 00:16:18,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:18,646][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.30754590034484863, acc: 0.9032257795333862)
[2024-12-15 00:16:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:19,050][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.20888158679008484, acc: 0.95652174949646)
[2024-12-15 00:16:19,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:19,467][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.44373273849487305, acc: 0.800000011920929)
[2024-12-15 00:16:19,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:19,933][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.49770137667655945, acc: 0.8780487775802612)
[2024-12-15 00:16:20,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:20,361][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.3767135739326477, acc: 0.8571428656578064)
[2024-12-15 00:16:20,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:20,791][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.37621745467185974, acc: 0.9210526347160339)
[2024-12-15 00:16:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:21,107][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.5089619755744934, acc: 0.8387096524238586)
[2024-12-15 00:16:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:21,459][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.28516340255737305, acc: 0.9200000166893005)
[2024-12-15 00:16:21,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:21,907][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.2577499747276306, acc: 0.9090909361839294)
[2024-12-15 00:16:22,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:22,296][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.4261951446533203, acc: 0.875)
[2024-12-15 00:16:22,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:22,682][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.38459500670433044, acc: 0.8857142925262451)
[2024-12-15 00:16:22,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:23,069][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.9429208636283875, acc: 0.7080292105674744)
[2024-12-15 00:16:23,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:24,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:24,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:25,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:25,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:25,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:26,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:26,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:27,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:27,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:28,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:28,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:29,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:30,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:30,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:30,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:31,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:31,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:32,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:32,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:33,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:33,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:33,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:34,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:34,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:35,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:35,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:35,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:36,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:36,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:37,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:37,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:37,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:38,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:39,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:39,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:40,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:40,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:40,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:41,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:41,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:41,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:42,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:42,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:42,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:43,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:43,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:44,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:44,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:45,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:45,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:46,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:46,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:47,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:47,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:47,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:48,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:49,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:49,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:49,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:50,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:50,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:51,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:51,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:51,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:52,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:52,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:52,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:53,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:53,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:53,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:54,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:54,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:54,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:55,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:55,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:56,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:56,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:57,074][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(9.8372, device='cuda:0') eval_epoch_loss=tensor(2.2862, device='cuda:0') eval_epoch_acc=tensor(0.5509, device='cuda:0')
[2024-12-15 00:16:57,075][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-15 00:16:57,075][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-15 00:16:57,810][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_10_step_554_loss_2.2861762046813965/model.pt
[2024-12-15 00:16:57,816][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft directory
[2024-12-15 00:16:57,817][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 10 is 0.5508953332901001
[2024-12-15 00:16:57,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:58,231][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.914455771446228, acc: 0.7379310131072998)
[2024-12-15 00:16:58,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:58,584][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 1.0997264385223389, acc: 0.6142857074737549)
[2024-12-15 00:16:58,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:58,977][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 1.0158286094665527, acc: 0.6754966974258423)
[2024-12-15 00:16:59,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:59,344][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.7668899297714233, acc: 0.7863247990608215)
[2024-12-15 00:16:59,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:16:59,724][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.3585609495639801, acc: 0.8799999952316284)
[2024-12-15 00:16:59,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:00,073][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.35151368379592896, acc: 0.9230769276618958)
[2024-12-15 00:17:00,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:00,410][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.2770056426525116, acc: 0.9230769276618958)
[2024-12-15 00:17:00,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:00,752][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.42437586188316345, acc: 0.8461538553237915)
[2024-12-15 00:17:00,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:01,111][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.6840701103210449, acc: 0.8111110925674438)
[2024-12-15 00:17:01,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:01,473][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.4867296516895294, acc: 0.8311688303947449)
[2024-12-15 00:17:01,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:01,820][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.36745381355285645, acc: 0.8958333134651184)
[2024-12-15 00:17:01,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:02,175][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.4376223385334015, acc: 0.8620689511299133)
[2024-12-15 00:17:02,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:02,601][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.6981913447380066, acc: 0.75)
[2024-12-15 00:17:02,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:02,980][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.3679434657096863, acc: 0.8684210777282715)
[2024-12-15 00:17:03,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:03,331][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.24134235084056854, acc: 0.9259259104728699)
[2024-12-15 00:17:03,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:03,758][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 1.457227110862732, acc: 0.614973247051239)
[2024-12-15 00:17:03,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:04,194][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.7583122253417969, acc: 0.7903226017951965)
[2024-12-15 00:17:04,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:04,585][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.8891717791557312, acc: 0.7094017267227173)
[2024-12-15 00:17:04,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:04,977][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 1.4038082361221313, acc: 0.6020408272743225)
[2024-12-15 00:17:05,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:05,394][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 1.3897314071655273, acc: 0.5471698045730591)
[2024-12-15 00:17:05,917][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=2.1158, train_epoch_loss=0.7494, epoch time 397.88649764610454s
[2024-12-15 00:17:05,918][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 14 GB
[2024-12-15 00:17:05,918][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-12-15 00:17:05,919][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 14 GB
[2024-12-15 00:17:05,919][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 30
[2024-12-15 00:17:05,919][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-15 00:17:05,931][root][INFO] - Key: avg_train_prep, Value: 5.064714431762695
[2024-12-15 00:17:05,933][root][INFO] - Key: avg_train_loss, Value: 1.392519235610962
[2024-12-15 00:17:05,933][root][INFO] - Key: avg_train_acc, Value: 0.6196480393409729
[2024-12-15 00:17:05,933][root][INFO] - Key: avg_eval_prep, Value: 8.42148208618164
[2024-12-15 00:17:05,934][root][INFO] - Key: avg_eval_loss, Value: 2.1042544841766357
[2024-12-15 00:17:05,934][root][INFO] - Key: avg_eval_acc, Value: 0.49891477823257446
[2024-12-15 00:17:05,934][root][INFO] - Key: avg_epoch_time, Value: 387.82504418196623
[2024-12-15 00:17:05,934][root][INFO] - Key: avg_checkpoint_time, Value: 0.7738210435898509
