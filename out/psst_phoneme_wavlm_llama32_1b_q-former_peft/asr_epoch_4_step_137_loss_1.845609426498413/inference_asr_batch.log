[2024-12-15 00:17:25,236][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'resume_step': 0, 'resume_epoch': 0, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 1000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': False, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': True, 'freeze_encoder': True, 'freeze_encoder2': False}
[2024-12-15 00:17:25,236][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': False, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-15 00:17:25,236][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'q-former', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-15 00:17:26,808][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-15 00:17:33,219][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-15 00:17:33,221][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-15 00:17:33,223][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-15 00:17:33,224][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-15 00:17:38,026][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-15 00:17:38,027][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-15 00:17:38,028][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-15 00:17:38,149][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-15 00:17:38,151][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-15 00:17:39,281][slam_llm.utils.train_utils][INFO] - --> Module q-former
[2024-12-15 00:17:39,282][slam_llm.utils.train_utils][INFO] - --> q-former has 69.361152 Million params

[2024-12-15 00:17:39,282][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_q-former_peft/asr_epoch_4_step_137_loss_1.845609426498413/model.pt
[2024-12-15 00:17:40,067][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-15 00:17:40,072][slam_llm.utils.train_utils][INFO] - --> asr has 74.997248 Million params

[2024-12-15 00:17:42,618][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': None, 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/test.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': True, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-15 00:17:43,446][root][INFO] - --> Training Set Length = 652
[2024-12-15 00:17:43,447][root][INFO] - =====================================
[2024-12-15 00:17:44,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:46,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:51,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:52,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:17:58,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:04,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:11,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:17,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:23,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:29,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:35,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:41,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:47,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:53,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:18:59,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:00,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:05,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:11,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:17,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:23,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:28,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:29,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:29,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:35,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:40,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:46,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:19:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:03,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:03,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:04,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:10,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:15,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:21,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:26,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:38,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:38,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:49,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:55,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:20:56,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:01,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:02,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:07,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:08,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:09,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:21,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:27,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:39,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:39,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:45,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:46,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:51,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:21:57,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:03,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:09,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:15,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:16,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:22,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:27,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:33,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:39,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:46,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:51,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:52,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:22:58,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:04,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:10,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:16,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:22,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:29,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:34,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:41,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:47,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:53,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:23:59,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:06,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:12,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:12,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:12,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:18,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:24,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:29,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:36,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:43,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:50,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:24:56,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:03,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:10,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:15,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:21,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:27,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:33,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:39,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:46,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:47,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:47,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:48,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:48,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:54,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:55,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:56,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:25:56,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:02,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:08,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:14,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:20,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:31,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:37,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:43,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:48,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:54,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:26:55,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:00,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:12,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:18,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:18,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:19,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:25,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:30,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:36,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:42,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:48,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:49,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:27:55,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:01,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:13,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:19,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:20,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:25,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:26,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:37,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:43,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:49,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:55,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:28:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:01,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:13,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:19,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:33,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:39,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:45,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:45,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:46,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:52,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:29:58,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:30:04,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-15 00:30:11,636][slam_llm.models.slam_model][INFO] - modality encoder
