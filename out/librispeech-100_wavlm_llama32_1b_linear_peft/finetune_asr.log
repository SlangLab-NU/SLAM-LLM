[2024-12-16 01:02:08,622][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:02:08,622][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:02:08,622][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:02:08,622][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-02-07.txt', 'log_interval': 5}
[2024-12-16 01:02:35,607][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:02:41,369][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:02:41,371][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:02:41,373][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:02:41,374][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:02:48,136][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:02:48,138][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:02:48,138][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 01:02:48,556][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:02:48,558][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 01:02:48,676][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:02:48,676][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:02:48,677][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:02:48,681][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 01:02:50,632][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:02:53,176][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:02:53,202][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:02:53,202][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:02:53,203][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:05:59,110][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:05:59,111][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:05:59,111][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:05:59,111][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-05-58.txt', 'log_interval': 5}
[2024-12-16 01:06:18,752][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:06:25,002][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:25,005][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:06:25,007][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:06:25,008][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:06:29,811][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:29,812][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:06:29,812][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 01:06:30,160][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:06:30,162][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 01:06:30,275][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:06:30,275][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:06:30,276][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:06:30,280][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 01:06:32,905][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:06:35,588][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:06:35,603][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:06:35,604][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:06:35,605][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:13:58,924][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 01:13:58,924][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 01:13:58,924][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 01:13:58,924][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_01-13-58.txt', 'log_interval': 5}
[2024-12-16 01:14:18,233][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 01:14:23,670][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:14:23,672][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 01:14:23,674][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 01:14:23,675][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 01:14:27,757][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:14:27,758][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 01:14:27,758][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 01:14:28,080][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 01:14:28,082][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 01:14:28,198][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 01:14:28,198][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 01:14:28,199][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 01:14:28,203][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 01:14:29,604][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 01:14:30,268][root][INFO] - --> Training Set Length = 28539
[2024-12-16 01:14:30,282][root][INFO] - --> Validation Set Length = 2703
[2024-12-16 01:14:30,282][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 01:14:30,282][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:32:56,555][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 2, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': False}
[2024-12-17 01:32:56,556][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-17 01:32:56,556][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-17 01:32:56,556][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'librispeech-100_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-17_01-32-55.txt', 'log_interval': 5}
[2024-12-17 01:33:27,974][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-17 01:33:33,902][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:33,905][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-17 01:33:33,907][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-17 01:33:33,908][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-17 01:33:45,218][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:45,220][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-17 01:33:45,221][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-17 01:33:45,555][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-17 01:33:45,557][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-17 01:33:45,676][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-17 01:33:45,676][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-17 01:33:45,676][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-17 01:33:45,680][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-17 01:33:48,542][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/librispeech-100/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-17 01:33:52,292][root][INFO] - --> Training Set Length = 28539
[2024-12-17 01:33:52,311][root][INFO] - --> Validation Set Length = 2703
[2024-12-17 01:33:52,311][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:52,312][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-17 01:33:55,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:33:58,105][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-12-17 01:34:00,128][root][INFO] - Training Epoch: 1/2, step 0/7134 completed (loss: 6.460538864135742, acc: 0.08974359184503555)
[2024-12-17 01:34:00,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:00,647][root][INFO] - Training Epoch: 1/2, step 1/7134 completed (loss: 6.859320640563965, acc: 0.07643312215805054)
[2024-12-17 01:34:00,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,034][root][INFO] - Training Epoch: 1/2, step 2/7134 completed (loss: 6.1916117668151855, acc: 0.13636364042758942)
[2024-12-17 01:34:01,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:01,573][root][INFO] - Training Epoch: 1/2, step 3/7134 completed (loss: 6.852880477905273, acc: 0.09883721172809601)
[2024-12-17 01:34:01,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,053][root][INFO] - Training Epoch: 1/2, step 4/7134 completed (loss: 6.572570323944092, acc: 0.1320754736661911)
[2024-12-17 01:34:02,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,468][root][INFO] - Training Epoch: 1/2, step 5/7134 completed (loss: 6.838906764984131, acc: 0.11173184216022491)
[2024-12-17 01:34:02,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:02,920][root][INFO] - Training Epoch: 1/2, step 6/7134 completed (loss: 5.913163185119629, acc: 0.21830986440181732)
[2024-12-17 01:34:03,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,343][root][INFO] - Training Epoch: 1/2, step 7/7134 completed (loss: 6.970270156860352, acc: 0.06989247351884842)
[2024-12-17 01:34:03,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:03,760][root][INFO] - Training Epoch: 1/2, step 8/7134 completed (loss: 6.583796977996826, acc: 0.11585365980863571)
[2024-12-17 01:34:03,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,145][root][INFO] - Training Epoch: 1/2, step 9/7134 completed (loss: 6.017714977264404, acc: 0.125827819108963)
[2024-12-17 01:34:04,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:04,596][root][INFO] - Training Epoch: 1/2, step 10/7134 completed (loss: 6.103972911834717, acc: 0.1538461595773697)
[2024-12-17 01:34:04,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,014][root][INFO] - Training Epoch: 1/2, step 11/7134 completed (loss: 6.697436809539795, acc: 0.06666667014360428)
[2024-12-17 01:34:05,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,434][root][INFO] - Training Epoch: 1/2, step 12/7134 completed (loss: 5.965653896331787, acc: 0.13294798135757446)
[2024-12-17 01:34:05,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:05,864][root][INFO] - Training Epoch: 1/2, step 13/7134 completed (loss: 5.546245574951172, acc: 0.21348313987255096)
[2024-12-17 01:34:06,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,317][root][INFO] - Training Epoch: 1/2, step 14/7134 completed (loss: 6.042051792144775, acc: 0.10135135054588318)
[2024-12-17 01:34:06,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:06,786][root][INFO] - Training Epoch: 1/2, step 15/7134 completed (loss: 5.964356422424316, acc: 0.09420289844274521)
[2024-12-17 01:34:06,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,216][root][INFO] - Training Epoch: 1/2, step 16/7134 completed (loss: 5.97506856918335, acc: 0.12280701845884323)
[2024-12-17 01:34:07,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:07,639][root][INFO] - Training Epoch: 1/2, step 17/7134 completed (loss: 6.886795997619629, acc: 0.11702127754688263)
[2024-12-17 01:34:07,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,038][root][INFO] - Training Epoch: 1/2, step 18/7134 completed (loss: 5.618563652038574, acc: 0.16867469251155853)
[2024-12-17 01:34:08,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,472][root][INFO] - Training Epoch: 1/2, step 19/7134 completed (loss: 5.747324466705322, acc: 0.16763006150722504)
[2024-12-17 01:34:08,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:08,893][root][INFO] - Training Epoch: 1/2, step 20/7134 completed (loss: 5.315877437591553, acc: 0.17613635957241058)
[2024-12-17 01:34:09,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,316][root][INFO] - Training Epoch: 1/2, step 21/7134 completed (loss: 5.70166015625, acc: 0.15340909361839294)
[2024-12-17 01:34:09,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:09,731][root][INFO] - Training Epoch: 1/2, step 22/7134 completed (loss: 4.987650394439697, acc: 0.19018404185771942)
[2024-12-17 01:34:09,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,156][root][INFO] - Training Epoch: 1/2, step 23/7134 completed (loss: 5.0634565353393555, acc: 0.21468926966190338)
[2024-12-17 01:34:10,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:10,623][root][INFO] - Training Epoch: 1/2, step 24/7134 completed (loss: 5.493713855743408, acc: 0.16111111640930176)
[2024-12-17 01:34:10,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,084][root][INFO] - Training Epoch: 1/2, step 25/7134 completed (loss: 4.9599714279174805, acc: 0.20710058510303497)
[2024-12-17 01:34:11,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:11,542][root][INFO] - Training Epoch: 1/2, step 26/7134 completed (loss: 5.437014579772949, acc: 0.17177914083003998)
[2024-12-17 01:34:11,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,014][root][INFO] - Training Epoch: 1/2, step 27/7134 completed (loss: 5.302431106567383, acc: 0.17307692766189575)
[2024-12-17 01:34:12,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,470][root][INFO] - Training Epoch: 1/2, step 28/7134 completed (loss: 5.568821430206299, acc: 0.18274112045764923)
[2024-12-17 01:34:12,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:12,877][root][INFO] - Training Epoch: 1/2, step 29/7134 completed (loss: 5.195214748382568, acc: 0.18934911489486694)
[2024-12-17 01:34:13,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,305][root][INFO] - Training Epoch: 1/2, step 30/7134 completed (loss: 5.411044120788574, acc: 0.15942029654979706)
[2024-12-17 01:34:13,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:13,718][root][INFO] - Training Epoch: 1/2, step 31/7134 completed (loss: 5.528094291687012, acc: 0.17209301888942719)
[2024-12-17 01:34:13,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,212][root][INFO] - Training Epoch: 1/2, step 32/7134 completed (loss: 5.401943206787109, acc: 0.19565217196941376)
[2024-12-17 01:34:14,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:14,694][root][INFO] - Training Epoch: 1/2, step 33/7134 completed (loss: 5.283904075622559, acc: 0.20769231021404266)
[2024-12-17 01:34:14,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,153][root][INFO] - Training Epoch: 1/2, step 34/7134 completed (loss: 5.022140026092529, acc: 0.2142857164144516)
[2024-12-17 01:34:15,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:15,623][root][INFO] - Training Epoch: 1/2, step 35/7134 completed (loss: 4.961584091186523, acc: 0.16862745583057404)
[2024-12-17 01:34:15,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,033][root][INFO] - Training Epoch: 1/2, step 36/7134 completed (loss: 5.321651935577393, acc: 0.18894009292125702)
[2024-12-17 01:34:16,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,464][root][INFO] - Training Epoch: 1/2, step 37/7134 completed (loss: 5.682126998901367, acc: 0.16931216418743134)
[2024-12-17 01:34:16,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:16,888][root][INFO] - Training Epoch: 1/2, step 38/7134 completed (loss: 5.579004287719727, acc: 0.1949685513973236)
[2024-12-17 01:34:17,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,285][root][INFO] - Training Epoch: 1/2, step 39/7134 completed (loss: 4.987209796905518, acc: 0.19883041083812714)
[2024-12-17 01:34:17,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:17,711][root][INFO] - Training Epoch: 1/2, step 40/7134 completed (loss: 5.779911518096924, acc: 0.1785714328289032)
[2024-12-17 01:34:17,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,133][root][INFO] - Training Epoch: 1/2, step 41/7134 completed (loss: 5.055520057678223, acc: 0.21808511018753052)
[2024-12-17 01:34:18,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,546][root][INFO] - Training Epoch: 1/2, step 42/7134 completed (loss: 5.2333292961120605, acc: 0.15432098507881165)
[2024-12-17 01:34:18,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:18,966][root][INFO] - Training Epoch: 1/2, step 43/7134 completed (loss: 4.545116901397705, acc: 0.25139665603637695)
[2024-12-17 01:34:19,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,416][root][INFO] - Training Epoch: 1/2, step 44/7134 completed (loss: 5.046611785888672, acc: 0.1871657818555832)
[2024-12-17 01:34:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:19,835][root][INFO] - Training Epoch: 1/2, step 45/7134 completed (loss: 4.899264335632324, acc: 0.2216981202363968)
[2024-12-17 01:34:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,255][root][INFO] - Training Epoch: 1/2, step 46/7134 completed (loss: 5.839572429656982, acc: 0.1744185984134674)
[2024-12-17 01:34:20,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:20,707][root][INFO] - Training Epoch: 1/2, step 47/7134 completed (loss: 5.213327884674072, acc: 0.18435753881931305)
[2024-12-17 01:34:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,146][root][INFO] - Training Epoch: 1/2, step 48/7134 completed (loss: 4.843891620635986, acc: 0.2028985470533371)
[2024-12-17 01:34:21,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,542][root][INFO] - Training Epoch: 1/2, step 49/7134 completed (loss: 5.4123311042785645, acc: 0.1882352977991104)
[2024-12-17 01:34:21,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:21,973][root][INFO] - Training Epoch: 1/2, step 50/7134 completed (loss: 5.165451526641846, acc: 0.25242719054222107)
[2024-12-17 01:34:22,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,366][root][INFO] - Training Epoch: 1/2, step 51/7134 completed (loss: 5.152547836303711, acc: 0.16326530277729034)
[2024-12-17 01:34:22,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:22,765][root][INFO] - Training Epoch: 1/2, step 52/7134 completed (loss: 4.853100299835205, acc: 0.16556291282176971)
[2024-12-17 01:34:22,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,182][root][INFO] - Training Epoch: 1/2, step 53/7134 completed (loss: 4.896786689758301, acc: 0.2108108103275299)
[2024-12-17 01:34:23,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:23,630][root][INFO] - Training Epoch: 1/2, step 54/7134 completed (loss: 5.048093795776367, acc: 0.18571428954601288)
[2024-12-17 01:34:23,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,061][root][INFO] - Training Epoch: 1/2, step 55/7134 completed (loss: 5.110714912414551, acc: 0.20108695328235626)
[2024-12-17 01:34:24,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,471][root][INFO] - Training Epoch: 1/2, step 56/7134 completed (loss: 5.746679306030273, acc: 0.13846154510974884)
[2024-12-17 01:34:24,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:24,891][root][INFO] - Training Epoch: 1/2, step 57/7134 completed (loss: 5.718896389007568, acc: 0.15934066474437714)
[2024-12-17 01:34:25,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,318][root][INFO] - Training Epoch: 1/2, step 58/7134 completed (loss: 5.458789348602295, acc: 0.16201117634773254)
[2024-12-17 01:34:25,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:25,716][root][INFO] - Training Epoch: 1/2, step 59/7134 completed (loss: 5.017969131469727, acc: 0.1871657818555832)
[2024-12-17 01:34:25,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,160][root][INFO] - Training Epoch: 1/2, step 60/7134 completed (loss: 5.382837772369385, acc: 0.15189872682094574)
[2024-12-17 01:34:26,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,552][root][INFO] - Training Epoch: 1/2, step 61/7134 completed (loss: 5.263857841491699, acc: 0.16759777069091797)
[2024-12-17 01:34:26,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:26,965][root][INFO] - Training Epoch: 1/2, step 62/7134 completed (loss: 5.865617752075195, acc: 0.12359550595283508)
[2024-12-17 01:34:27,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,396][root][INFO] - Training Epoch: 1/2, step 63/7134 completed (loss: 5.14392614364624, acc: 0.13736264407634735)
[2024-12-17 01:34:27,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:27,811][root][INFO] - Training Epoch: 1/2, step 64/7134 completed (loss: 5.542994499206543, acc: 0.16470588743686676)
[2024-12-17 01:34:27,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,235][root][INFO] - Training Epoch: 1/2, step 65/7134 completed (loss: 6.007785320281982, acc: 0.1595744639635086)
[2024-12-17 01:34:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:28,638][root][INFO] - Training Epoch: 1/2, step 66/7134 completed (loss: 5.636174201965332, acc: 0.13636364042758942)
[2024-12-17 01:34:28,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,065][root][INFO] - Training Epoch: 1/2, step 67/7134 completed (loss: 5.688236713409424, acc: 0.1781609207391739)
[2024-12-17 01:34:29,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,437][root][INFO] - Training Epoch: 1/2, step 68/7134 completed (loss: 5.4050164222717285, acc: 0.25280898809432983)
[2024-12-17 01:34:29,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:29,828][root][INFO] - Training Epoch: 1/2, step 69/7134 completed (loss: 5.489248752593994, acc: 0.17989417910575867)
[2024-12-17 01:34:29,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,235][root][INFO] - Training Epoch: 1/2, step 70/7134 completed (loss: 5.890438079833984, acc: 0.125)
[2024-12-17 01:34:30,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:30,640][root][INFO] - Training Epoch: 1/2, step 71/7134 completed (loss: 4.9101786613464355, acc: 0.21212121844291687)
[2024-12-17 01:34:30,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,065][root][INFO] - Training Epoch: 1/2, step 72/7134 completed (loss: 5.381311416625977, acc: 0.1538461595773697)
[2024-12-17 01:34:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,437][root][INFO] - Training Epoch: 1/2, step 73/7134 completed (loss: 5.479894161224365, acc: 0.12716762721538544)
[2024-12-17 01:34:31,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:31,830][root][INFO] - Training Epoch: 1/2, step 74/7134 completed (loss: 5.139676094055176, acc: 0.1744185984134674)
[2024-12-17 01:34:31,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,264][root][INFO] - Training Epoch: 1/2, step 75/7134 completed (loss: 5.362345218658447, acc: 0.2023809552192688)
[2024-12-17 01:34:32,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:32,689][root][INFO] - Training Epoch: 1/2, step 76/7134 completed (loss: 5.161408424377441, acc: 0.20108695328235626)
[2024-12-17 01:34:32,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,088][root][INFO] - Training Epoch: 1/2, step 77/7134 completed (loss: 5.168837070465088, acc: 0.16022099554538727)
[2024-12-17 01:34:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,524][root][INFO] - Training Epoch: 1/2, step 78/7134 completed (loss: 5.395753383636475, acc: 0.18543046712875366)
[2024-12-17 01:34:33,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:33,928][root][INFO] - Training Epoch: 1/2, step 79/7134 completed (loss: 5.1690874099731445, acc: 0.18666666746139526)
[2024-12-17 01:34:34,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,320][root][INFO] - Training Epoch: 1/2, step 80/7134 completed (loss: 4.75396728515625, acc: 0.21348313987255096)
[2024-12-17 01:34:34,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:34,726][root][INFO] - Training Epoch: 1/2, step 81/7134 completed (loss: 5.120894432067871, acc: 0.23280423879623413)
[2024-12-17 01:34:34,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,160][root][INFO] - Training Epoch: 1/2, step 82/7134 completed (loss: 4.927736759185791, acc: 0.1927710771560669)
[2024-12-17 01:34:35,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:35,640][root][INFO] - Training Epoch: 1/2, step 83/7134 completed (loss: 5.419585704803467, acc: 0.16489361226558685)
[2024-12-17 01:34:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,079][root][INFO] - Training Epoch: 1/2, step 84/7134 completed (loss: 4.497745513916016, acc: 0.26618704199790955)
[2024-12-17 01:34:36,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,493][root][INFO] - Training Epoch: 1/2, step 85/7134 completed (loss: 4.635614395141602, acc: 0.20999999344348907)
[2024-12-17 01:34:36,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:36,940][root][INFO] - Training Epoch: 1/2, step 86/7134 completed (loss: 4.739291191101074, acc: 0.2142857164144516)
[2024-12-17 01:34:37,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,420][root][INFO] - Training Epoch: 1/2, step 87/7134 completed (loss: 4.582701683044434, acc: 0.2922077775001526)
[2024-12-17 01:34:37,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:37,834][root][INFO] - Training Epoch: 1/2, step 88/7134 completed (loss: 5.007107257843018, acc: 0.20481927692890167)
[2024-12-17 01:34:37,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,303][root][INFO] - Training Epoch: 1/2, step 89/7134 completed (loss: 4.775479316711426, acc: 0.21142856776714325)
[2024-12-17 01:34:38,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:38,761][root][INFO] - Training Epoch: 1/2, step 90/7134 completed (loss: 4.858765602111816, acc: 0.1596638709306717)
[2024-12-17 01:34:38,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,187][root][INFO] - Training Epoch: 1/2, step 91/7134 completed (loss: 5.105633735656738, acc: 0.23140496015548706)
[2024-12-17 01:34:39,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:39,608][root][INFO] - Training Epoch: 1/2, step 92/7134 completed (loss: 4.7787652015686035, acc: 0.2467532455921173)
[2024-12-17 01:34:39,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,010][root][INFO] - Training Epoch: 1/2, step 93/7134 completed (loss: 4.604669570922852, acc: 0.24571429193019867)
[2024-12-17 01:34:40,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,381][root][INFO] - Training Epoch: 1/2, step 94/7134 completed (loss: 4.731257438659668, acc: 0.3207547068595886)
[2024-12-17 01:34:40,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:40,784][root][INFO] - Training Epoch: 1/2, step 95/7134 completed (loss: 4.948366165161133, acc: 0.23170731961727142)
[2024-12-17 01:34:40,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,179][root][INFO] - Training Epoch: 1/2, step 96/7134 completed (loss: 4.83173942565918, acc: 0.21495327353477478)
[2024-12-17 01:34:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:41,618][root][INFO] - Training Epoch: 1/2, step 97/7134 completed (loss: 5.940203666687012, acc: 0.02380952425301075)
[2024-12-17 01:34:41,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,040][root][INFO] - Training Epoch: 1/2, step 98/7134 completed (loss: 4.917027950286865, acc: 0.22535210847854614)
[2024-12-17 01:34:42,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,436][root][INFO] - Training Epoch: 1/2, step 99/7134 completed (loss: 4.233860492706299, acc: 0.3076923191547394)
[2024-12-17 01:34:42,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:42,885][root][INFO] - Training Epoch: 1/2, step 100/7134 completed (loss: 4.70446252822876, acc: 0.2707182466983795)
[2024-12-17 01:34:43,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,310][root][INFO] - Training Epoch: 1/2, step 101/7134 completed (loss: 5.254892826080322, acc: 0.171875)
[2024-12-17 01:34:43,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:43,716][root][INFO] - Training Epoch: 1/2, step 102/7134 completed (loss: 4.608795166015625, acc: 0.1912568360567093)
[2024-12-17 01:34:43,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,157][root][INFO] - Training Epoch: 1/2, step 103/7134 completed (loss: 5.083614826202393, acc: 0.18493150174617767)
[2024-12-17 01:34:44,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:44,593][root][INFO] - Training Epoch: 1/2, step 104/7134 completed (loss: 4.263674736022949, acc: 0.23999999463558197)
[2024-12-17 01:34:44,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,015][root][INFO] - Training Epoch: 1/2, step 105/7134 completed (loss: 4.377039909362793, acc: 0.2238806039094925)
[2024-12-17 01:34:45,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,440][root][INFO] - Training Epoch: 1/2, step 106/7134 completed (loss: 4.4077558517456055, acc: 0.2981366515159607)
[2024-12-17 01:34:45,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:45,846][root][INFO] - Training Epoch: 1/2, step 107/7134 completed (loss: 4.523617267608643, acc: 0.302325576543808)
[2024-12-17 01:34:45,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,267][root][INFO] - Training Epoch: 1/2, step 108/7134 completed (loss: 4.687408924102783, acc: 0.21621622145175934)
[2024-12-17 01:34:46,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:46,681][root][INFO] - Training Epoch: 1/2, step 109/7134 completed (loss: 4.688861846923828, acc: 0.190476194024086)
[2024-12-17 01:34:46,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,075][root][INFO] - Training Epoch: 1/2, step 110/7134 completed (loss: 4.210392475128174, acc: 0.2625698447227478)
[2024-12-17 01:34:47,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,493][root][INFO] - Training Epoch: 1/2, step 111/7134 completed (loss: 4.195777893066406, acc: 0.25757575035095215)
[2024-12-17 01:34:47,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:47,883][root][INFO] - Training Epoch: 1/2, step 112/7134 completed (loss: 4.584583282470703, acc: 0.2638888955116272)
[2024-12-17 01:34:47,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,260][root][INFO] - Training Epoch: 1/2, step 113/7134 completed (loss: 3.9693946838378906, acc: 0.3687150776386261)
[2024-12-17 01:34:48,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:48,663][root][INFO] - Training Epoch: 1/2, step 114/7134 completed (loss: 4.560824871063232, acc: 0.22285714745521545)
[2024-12-17 01:34:48,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,033][root][INFO] - Training Epoch: 1/2, step 115/7134 completed (loss: 4.997029781341553, acc: 0.24752475321292877)
[2024-12-17 01:34:49,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,460][root][INFO] - Training Epoch: 1/2, step 116/7134 completed (loss: 4.81445837020874, acc: 0.2183908075094223)
[2024-12-17 01:34:49,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:49,857][root][INFO] - Training Epoch: 1/2, step 117/7134 completed (loss: 4.4142608642578125, acc: 0.27272728085517883)
[2024-12-17 01:34:49,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,269][root][INFO] - Training Epoch: 1/2, step 118/7134 completed (loss: 4.897004127502441, acc: 0.25555557012557983)
[2024-12-17 01:34:50,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:50,669][root][INFO] - Training Epoch: 1/2, step 119/7134 completed (loss: 4.845343112945557, acc: 0.228723406791687)
[2024-12-17 01:34:50,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,101][root][INFO] - Training Epoch: 1/2, step 120/7134 completed (loss: 4.457363128662109, acc: 0.2023809552192688)
[2024-12-17 01:34:51,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,499][root][INFO] - Training Epoch: 1/2, step 121/7134 completed (loss: 4.769407272338867, acc: 0.2402234673500061)
[2024-12-17 01:34:51,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:51,889][root][INFO] - Training Epoch: 1/2, step 122/7134 completed (loss: 4.114297866821289, acc: 0.29120880365371704)
[2024-12-17 01:34:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,294][root][INFO] - Training Epoch: 1/2, step 123/7134 completed (loss: 4.416569709777832, acc: 0.24528302252292633)
[2024-12-17 01:34:52,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:52,712][root][INFO] - Training Epoch: 1/2, step 124/7134 completed (loss: 4.340665340423584, acc: 0.2847222089767456)
[2024-12-17 01:34:52,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,162][root][INFO] - Training Epoch: 1/2, step 125/7134 completed (loss: 4.5288496017456055, acc: 0.2696078419685364)
[2024-12-17 01:34:53,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,588][root][INFO] - Training Epoch: 1/2, step 126/7134 completed (loss: 4.798008918762207, acc: 0.2393617033958435)
[2024-12-17 01:34:53,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:53,995][root][INFO] - Training Epoch: 1/2, step 127/7134 completed (loss: 3.8794267177581787, acc: 0.3177083432674408)
[2024-12-17 01:34:54,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,501][root][INFO] - Training Epoch: 1/2, step 128/7134 completed (loss: 4.489331245422363, acc: 0.27272728085517883)
[2024-12-17 01:34:54,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:54,937][root][INFO] - Training Epoch: 1/2, step 129/7134 completed (loss: 4.040378570556641, acc: 0.22905027866363525)
[2024-12-17 01:34:55,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,345][root][INFO] - Training Epoch: 1/2, step 130/7134 completed (loss: 4.114214897155762, acc: 0.2823529541492462)
[2024-12-17 01:34:55,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:55,783][root][INFO] - Training Epoch: 1/2, step 131/7134 completed (loss: 4.287111759185791, acc: 0.2631579041481018)
[2024-12-17 01:34:55,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,202][root][INFO] - Training Epoch: 1/2, step 132/7134 completed (loss: 4.27317476272583, acc: 0.2515723407268524)
[2024-12-17 01:34:56,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:56,620][root][INFO] - Training Epoch: 1/2, step 133/7134 completed (loss: 4.338954448699951, acc: 0.25)
[2024-12-17 01:34:56,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,021][root][INFO] - Training Epoch: 1/2, step 134/7134 completed (loss: 4.451075077056885, acc: 0.24060150980949402)
[2024-12-17 01:34:57,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,410][root][INFO] - Training Epoch: 1/2, step 135/7134 completed (loss: 4.019376754760742, acc: 0.2857142984867096)
[2024-12-17 01:34:57,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:57,789][root][INFO] - Training Epoch: 1/2, step 136/7134 completed (loss: 4.583512783050537, acc: 0.2554347813129425)
[2024-12-17 01:34:57,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,159][root][INFO] - Training Epoch: 1/2, step 137/7134 completed (loss: 4.0292792320251465, acc: 0.286432147026062)
[2024-12-17 01:34:58,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,583][root][INFO] - Training Epoch: 1/2, step 138/7134 completed (loss: 4.131561279296875, acc: 0.32258063554763794)
[2024-12-17 01:34:58,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:58,998][root][INFO] - Training Epoch: 1/2, step 139/7134 completed (loss: 4.499271392822266, acc: 0.23404255509376526)
[2024-12-17 01:34:59,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,428][root][INFO] - Training Epoch: 1/2, step 140/7134 completed (loss: 3.9969279766082764, acc: 0.2822085916996002)
[2024-12-17 01:34:59,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:34:59,871][root][INFO] - Training Epoch: 1/2, step 141/7134 completed (loss: 4.208388805389404, acc: 0.28999999165534973)
[2024-12-17 01:35:00,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,380][root][INFO] - Training Epoch: 1/2, step 142/7134 completed (loss: 4.416192054748535, acc: 0.2429378479719162)
[2024-12-17 01:35:00,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:00,884][root][INFO] - Training Epoch: 1/2, step 143/7134 completed (loss: 3.8425803184509277, acc: 0.28729280829429626)
[2024-12-17 01:35:01,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,328][root][INFO] - Training Epoch: 1/2, step 144/7134 completed (loss: 4.699685573577881, acc: 0.20945945382118225)
[2024-12-17 01:35:01,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:01,722][root][INFO] - Training Epoch: 1/2, step 145/7134 completed (loss: 5.27065896987915, acc: 0.22797927260398865)
[2024-12-17 01:35:01,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,204][root][INFO] - Training Epoch: 1/2, step 146/7134 completed (loss: 4.898260116577148, acc: 0.21468926966190338)
[2024-12-17 01:35:02,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:02,614][root][INFO] - Training Epoch: 1/2, step 147/7134 completed (loss: 4.807006359100342, acc: 0.2344827651977539)
[2024-12-17 01:35:02,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,005][root][INFO] - Training Epoch: 1/2, step 148/7134 completed (loss: 5.103347301483154, acc: 0.27419355511665344)
[2024-12-17 01:35:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,434][root][INFO] - Training Epoch: 1/2, step 149/7134 completed (loss: 4.805140972137451, acc: 0.23350253701210022)
[2024-12-17 01:35:03,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:03,853][root][INFO] - Training Epoch: 1/2, step 150/7134 completed (loss: 4.9992218017578125, acc: 0.2041884809732437)
[2024-12-17 01:35:03,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,244][root][INFO] - Training Epoch: 1/2, step 151/7134 completed (loss: 4.2386322021484375, acc: 0.27419355511665344)
[2024-12-17 01:35:04,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:04,652][root][INFO] - Training Epoch: 1/2, step 152/7134 completed (loss: 4.421881198883057, acc: 0.20095694065093994)
[2024-12-17 01:35:04,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,062][root][INFO] - Training Epoch: 1/2, step 153/7134 completed (loss: 4.8326873779296875, acc: 0.22651933133602142)
[2024-12-17 01:35:05,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,486][root][INFO] - Training Epoch: 1/2, step 154/7134 completed (loss: 4.7972412109375, acc: 0.23529411852359772)
[2024-12-17 01:35:05,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:05,920][root][INFO] - Training Epoch: 1/2, step 155/7134 completed (loss: 4.381178855895996, acc: 0.2568306028842926)
[2024-12-17 01:35:06,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,333][root][INFO] - Training Epoch: 1/2, step 156/7134 completed (loss: 4.481967449188232, acc: 0.2216748744249344)
[2024-12-17 01:35:06,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:06,722][root][INFO] - Training Epoch: 1/2, step 157/7134 completed (loss: 4.9771857261657715, acc: 0.19576719403266907)
[2024-12-17 01:35:06,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,139][root][INFO] - Training Epoch: 1/2, step 158/7134 completed (loss: 4.500893592834473, acc: 0.19883041083812714)
[2024-12-17 01:35:07,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,541][root][INFO] - Training Epoch: 1/2, step 159/7134 completed (loss: 4.07836389541626, acc: 0.2832369804382324)
[2024-12-17 01:35:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:07,909][root][INFO] - Training Epoch: 1/2, step 160/7134 completed (loss: 4.585518836975098, acc: 0.18644067645072937)
[2024-12-17 01:35:08,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,268][root][INFO] - Training Epoch: 1/2, step 161/7134 completed (loss: 3.910430908203125, acc: 0.37837839126586914)
[2024-12-17 01:35:08,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:08,674][root][INFO] - Training Epoch: 1/2, step 162/7134 completed (loss: 3.9845387935638428, acc: 0.3086419701576233)
[2024-12-17 01:35:08,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,099][root][INFO] - Training Epoch: 1/2, step 163/7134 completed (loss: 4.2912983894348145, acc: 0.23021583259105682)
[2024-12-17 01:35:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,574][root][INFO] - Training Epoch: 1/2, step 164/7134 completed (loss: 4.391794681549072, acc: 0.3232323229312897)
[2024-12-17 01:35:09,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:09,978][root][INFO] - Training Epoch: 1/2, step 165/7134 completed (loss: 3.8828351497650146, acc: 0.3100000023841858)
[2024-12-17 01:35:10,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,416][root][INFO] - Training Epoch: 1/2, step 166/7134 completed (loss: 4.311964988708496, acc: 0.31578946113586426)
[2024-12-17 01:35:10,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:10,842][root][INFO] - Training Epoch: 1/2, step 167/7134 completed (loss: 5.440035343170166, acc: 0.1807228922843933)
[2024-12-17 01:35:11,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,249][root][INFO] - Training Epoch: 1/2, step 168/7134 completed (loss: 6.272202968597412, acc: 0.12727272510528564)
[2024-12-17 01:35:11,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:11,675][root][INFO] - Training Epoch: 1/2, step 169/7134 completed (loss: 6.273968696594238, acc: 0.1015625)
[2024-12-17 01:35:11,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,086][root][INFO] - Training Epoch: 1/2, step 170/7134 completed (loss: 5.17287015914917, acc: 0.2380952388048172)
[2024-12-17 01:35:12,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,521][root][INFO] - Training Epoch: 1/2, step 171/7134 completed (loss: 6.020698070526123, acc: 0.10891088843345642)
[2024-12-17 01:35:12,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:12,967][root][INFO] - Training Epoch: 1/2, step 172/7134 completed (loss: 4.982810974121094, acc: 0.23255814611911774)
[2024-12-17 01:35:13,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,347][root][INFO] - Training Epoch: 1/2, step 173/7134 completed (loss: 5.460095405578613, acc: 0.14399999380111694)
[2024-12-17 01:35:13,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:13,787][root][INFO] - Training Epoch: 1/2, step 174/7134 completed (loss: 5.264206409454346, acc: 0.19736842811107635)
[2024-12-17 01:35:13,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,197][root][INFO] - Training Epoch: 1/2, step 175/7134 completed (loss: 4.684375286102295, acc: 0.2384105920791626)
[2024-12-17 01:35:14,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,601][root][INFO] - Training Epoch: 1/2, step 176/7134 completed (loss: 4.630034923553467, acc: 0.284153014421463)
[2024-12-17 01:35:14,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:14,975][root][INFO] - Training Epoch: 1/2, step 177/7134 completed (loss: 5.004451274871826, acc: 0.21556885540485382)
[2024-12-17 01:35:15,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,388][root][INFO] - Training Epoch: 1/2, step 178/7134 completed (loss: 4.723190784454346, acc: 0.20779220759868622)
[2024-12-17 01:35:15,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:15,786][root][INFO] - Training Epoch: 1/2, step 179/7134 completed (loss: 4.1303229331970215, acc: 0.29927006363868713)
[2024-12-17 01:35:15,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,203][root][INFO] - Training Epoch: 1/2, step 180/7134 completed (loss: 4.4641242027282715, acc: 0.281879186630249)
[2024-12-17 01:35:16,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:16,604][root][INFO] - Training Epoch: 1/2, step 181/7134 completed (loss: 4.206149101257324, acc: 0.2896551787853241)
[2024-12-17 01:35:16,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,079][root][INFO] - Training Epoch: 1/2, step 182/7134 completed (loss: 4.1157917976379395, acc: 0.2484472095966339)
[2024-12-17 01:35:17,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,500][root][INFO] - Training Epoch: 1/2, step 183/7134 completed (loss: 4.284073829650879, acc: 0.2602739632129669)
[2024-12-17 01:35:17,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:17,873][root][INFO] - Training Epoch: 1/2, step 184/7134 completed (loss: 4.40825891494751, acc: 0.2734375)
[2024-12-17 01:35:17,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,252][root][INFO] - Training Epoch: 1/2, step 185/7134 completed (loss: 4.021021366119385, acc: 0.31972789764404297)
[2024-12-17 01:35:18,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:18,666][root][INFO] - Training Epoch: 1/2, step 186/7134 completed (loss: 4.273438453674316, acc: 0.2537313401699066)
[2024-12-17 01:35:18,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,085][root][INFO] - Training Epoch: 1/2, step 187/7134 completed (loss: 3.720438241958618, acc: 0.3529411852359772)
[2024-12-17 01:35:19,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,465][root][INFO] - Training Epoch: 1/2, step 188/7134 completed (loss: 3.877674102783203, acc: 0.3048780560493469)
[2024-12-17 01:35:19,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:19,825][root][INFO] - Training Epoch: 1/2, step 189/7134 completed (loss: 3.9320714473724365, acc: 0.3196721374988556)
[2024-12-17 01:35:19,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,234][root][INFO] - Training Epoch: 1/2, step 190/7134 completed (loss: 4.171839237213135, acc: 0.26865673065185547)
[2024-12-17 01:35:20,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:20,643][root][INFO] - Training Epoch: 1/2, step 191/7134 completed (loss: 4.0049543380737305, acc: 0.3461538553237915)
[2024-12-17 01:35:20,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,085][root][INFO] - Training Epoch: 1/2, step 192/7134 completed (loss: 3.6901934146881104, acc: 0.2848837077617645)
[2024-12-17 01:35:21,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,489][root][INFO] - Training Epoch: 1/2, step 193/7134 completed (loss: 4.040151119232178, acc: 0.31137725710868835)
[2024-12-17 01:35:21,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:21,936][root][INFO] - Training Epoch: 1/2, step 194/7134 completed (loss: 4.37531852722168, acc: 0.28930819034576416)
[2024-12-17 01:35:22,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,439][root][INFO] - Training Epoch: 1/2, step 195/7134 completed (loss: 4.535361289978027, acc: 0.1796875)
[2024-12-17 01:35:22,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:22,891][root][INFO] - Training Epoch: 1/2, step 196/7134 completed (loss: 4.788198947906494, acc: 0.2402234673500061)
[2024-12-17 01:35:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,337][root][INFO] - Training Epoch: 1/2, step 197/7134 completed (loss: 3.444868564605713, acc: 0.3378378450870514)
[2024-12-17 01:35:23,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:23,775][root][INFO] - Training Epoch: 1/2, step 198/7134 completed (loss: 3.9345781803131104, acc: 0.30573248863220215)
[2024-12-17 01:35:23,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,175][root][INFO] - Training Epoch: 1/2, step 199/7134 completed (loss: 3.9345881938934326, acc: 0.31617647409439087)
[2024-12-17 01:35:24,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:24,662][root][INFO] - Training Epoch: 1/2, step 200/7134 completed (loss: 3.8959598541259766, acc: 0.31972789764404297)
[2024-12-17 01:35:24,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,131][root][INFO] - Training Epoch: 1/2, step 201/7134 completed (loss: 4.458576202392578, acc: 0.20567375421524048)
[2024-12-17 01:35:25,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,536][root][INFO] - Training Epoch: 1/2, step 202/7134 completed (loss: 4.378041744232178, acc: 0.31612902879714966)
[2024-12-17 01:35:25,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:25,913][root][INFO] - Training Epoch: 1/2, step 203/7134 completed (loss: 4.819273471832275, acc: 0.2662721872329712)
[2024-12-17 01:35:26,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,299][root][INFO] - Training Epoch: 1/2, step 204/7134 completed (loss: 4.681517601013184, acc: 0.23899370431900024)
[2024-12-17 01:35:26,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:26,679][root][INFO] - Training Epoch: 1/2, step 205/7134 completed (loss: 4.756563186645508, acc: 0.2150000035762787)
[2024-12-17 01:35:26,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,068][root][INFO] - Training Epoch: 1/2, step 206/7134 completed (loss: 4.132821559906006, acc: 0.2777777910232544)
[2024-12-17 01:35:27,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,452][root][INFO] - Training Epoch: 1/2, step 207/7134 completed (loss: 4.276982307434082, acc: 0.27210885286331177)
[2024-12-17 01:35:27,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:27,881][root][INFO] - Training Epoch: 1/2, step 208/7134 completed (loss: 4.932398319244385, acc: 0.24285714328289032)
[2024-12-17 01:35:28,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,326][root][INFO] - Training Epoch: 1/2, step 209/7134 completed (loss: 4.86505126953125, acc: 0.22905027866363525)
[2024-12-17 01:35:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:28,736][root][INFO] - Training Epoch: 1/2, step 210/7134 completed (loss: 4.44093656539917, acc: 0.24229075014591217)
[2024-12-17 01:35:28,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,113][root][INFO] - Training Epoch: 1/2, step 211/7134 completed (loss: 4.3948235511779785, acc: 0.29729729890823364)
[2024-12-17 01:35:29,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,541][root][INFO] - Training Epoch: 1/2, step 212/7134 completed (loss: 5.521448612213135, acc: 0.1900826394557953)
[2024-12-17 01:35:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:29,958][root][INFO] - Training Epoch: 1/2, step 213/7134 completed (loss: 4.367232799530029, acc: 0.3199999928474426)
[2024-12-17 01:35:30,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,406][root][INFO] - Training Epoch: 1/2, step 214/7134 completed (loss: 5.229636192321777, acc: 0.1683168262243271)
[2024-12-17 01:35:30,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:30,890][root][INFO] - Training Epoch: 1/2, step 215/7134 completed (loss: 4.133878231048584, acc: 0.3142857253551483)
[2024-12-17 01:35:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,351][root][INFO] - Training Epoch: 1/2, step 216/7134 completed (loss: 3.8250162601470947, acc: 0.31460675597190857)
[2024-12-17 01:35:31,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:31,853][root][INFO] - Training Epoch: 1/2, step 217/7134 completed (loss: 3.715815782546997, acc: 0.3072916567325592)
[2024-12-17 01:35:32,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,330][root][INFO] - Training Epoch: 1/2, step 218/7134 completed (loss: 3.880182981491089, acc: 0.30481284856796265)
[2024-12-17 01:35:32,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:32,740][root][INFO] - Training Epoch: 1/2, step 219/7134 completed (loss: 4.794865608215332, acc: 0.21929824352264404)
[2024-12-17 01:35:32,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,153][root][INFO] - Training Epoch: 1/2, step 220/7134 completed (loss: 3.983203172683716, acc: 0.2956521809101105)
[2024-12-17 01:35:33,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,549][root][INFO] - Training Epoch: 1/2, step 221/7134 completed (loss: 3.884157180786133, acc: 0.3062500059604645)
[2024-12-17 01:35:33,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:33,968][root][INFO] - Training Epoch: 1/2, step 222/7134 completed (loss: 4.190713882446289, acc: 0.31213873624801636)
[2024-12-17 01:35:34,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,348][root][INFO] - Training Epoch: 1/2, step 223/7134 completed (loss: 4.823486328125, acc: 0.21621622145175934)
[2024-12-17 01:35:34,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:34,734][root][INFO] - Training Epoch: 1/2, step 224/7134 completed (loss: 5.087031841278076, acc: 0.22346368432044983)
[2024-12-17 01:35:34,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,197][root][INFO] - Training Epoch: 1/2, step 225/7134 completed (loss: 4.6056389808654785, acc: 0.2840236723423004)
[2024-12-17 01:35:35,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,617][root][INFO] - Training Epoch: 1/2, step 226/7134 completed (loss: 4.646676063537598, acc: 0.22857142984867096)
[2024-12-17 01:35:35,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:35,986][root][INFO] - Training Epoch: 1/2, step 227/7134 completed (loss: 4.6917548179626465, acc: 0.25)
[2024-12-17 01:35:36,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,421][root][INFO] - Training Epoch: 1/2, step 228/7134 completed (loss: 4.547504901885986, acc: 0.2934131622314453)
[2024-12-17 01:35:36,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:36,825][root][INFO] - Training Epoch: 1/2, step 229/7134 completed (loss: 4.985389232635498, acc: 0.23999999463558197)
[2024-12-17 01:35:36,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,212][root][INFO] - Training Epoch: 1/2, step 230/7134 completed (loss: 4.810750484466553, acc: 0.24309392273426056)
[2024-12-17 01:35:37,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,582][root][INFO] - Training Epoch: 1/2, step 231/7134 completed (loss: 4.883620738983154, acc: 0.21929824352264404)
[2024-12-17 01:35:37,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:37,971][root][INFO] - Training Epoch: 1/2, step 232/7134 completed (loss: 4.826420307159424, acc: 0.24475523829460144)
[2024-12-17 01:35:38,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,412][root][INFO] - Training Epoch: 1/2, step 233/7134 completed (loss: 4.6533203125, acc: 0.29197078943252563)
[2024-12-17 01:35:38,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:38,874][root][INFO] - Training Epoch: 1/2, step 234/7134 completed (loss: 4.801942825317383, acc: 0.18309858441352844)
[2024-12-17 01:35:38,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,275][root][INFO] - Training Epoch: 1/2, step 235/7134 completed (loss: 4.580081462860107, acc: 0.23780487477779388)
[2024-12-17 01:35:39,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:39,720][root][INFO] - Training Epoch: 1/2, step 236/7134 completed (loss: 4.2530436515808105, acc: 0.30463576316833496)
[2024-12-17 01:35:39,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,127][root][INFO] - Training Epoch: 1/2, step 237/7134 completed (loss: 4.984062671661377, acc: 0.20382165908813477)
[2024-12-17 01:35:40,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,548][root][INFO] - Training Epoch: 1/2, step 238/7134 completed (loss: 4.835888862609863, acc: 0.2442748099565506)
[2024-12-17 01:35:40,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:40,973][root][INFO] - Training Epoch: 1/2, step 239/7134 completed (loss: 5.149668216705322, acc: 0.17924527823925018)
[2024-12-17 01:35:41,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,378][root][INFO] - Training Epoch: 1/2, step 240/7134 completed (loss: 4.423764705657959, acc: 0.28155338764190674)
[2024-12-17 01:35:41,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:41,781][root][INFO] - Training Epoch: 1/2, step 241/7134 completed (loss: 4.477132797241211, acc: 0.24626865983009338)
[2024-12-17 01:35:41,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,192][root][INFO] - Training Epoch: 1/2, step 242/7134 completed (loss: 4.629542350769043, acc: 0.23489932715892792)
[2024-12-17 01:35:42,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,631][root][INFO] - Training Epoch: 1/2, step 243/7134 completed (loss: 4.950045585632324, acc: 0.24827586114406586)
[2024-12-17 01:35:42,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:42,983][root][INFO] - Training Epoch: 1/2, step 244/7134 completed (loss: 4.216374397277832, acc: 0.22302158176898956)
[2024-12-17 01:35:43,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,353][root][INFO] - Training Epoch: 1/2, step 245/7134 completed (loss: 4.22703742980957, acc: 0.3196721374988556)
[2024-12-17 01:35:43,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:43,727][root][INFO] - Training Epoch: 1/2, step 246/7134 completed (loss: 4.309799671173096, acc: 0.30434781312942505)
[2024-12-17 01:35:43,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,108][root][INFO] - Training Epoch: 1/2, step 247/7134 completed (loss: 4.084803581237793, acc: 0.30158731341362)
[2024-12-17 01:35:44,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,515][root][INFO] - Training Epoch: 1/2, step 248/7134 completed (loss: 4.189443588256836, acc: 0.2601625919342041)
[2024-12-17 01:35:44,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:44,909][root][INFO] - Training Epoch: 1/2, step 249/7134 completed (loss: 4.09619140625, acc: 0.3586956560611725)
[2024-12-17 01:35:45,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,314][root][INFO] - Training Epoch: 1/2, step 250/7134 completed (loss: 4.23590087890625, acc: 0.2715231776237488)
[2024-12-17 01:35:45,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:45,716][root][INFO] - Training Epoch: 1/2, step 251/7134 completed (loss: 4.515686511993408, acc: 0.2733812928199768)
[2024-12-17 01:35:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,095][root][INFO] - Training Epoch: 1/2, step 252/7134 completed (loss: 4.095911026000977, acc: 0.2949640154838562)
[2024-12-17 01:35:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,486][root][INFO] - Training Epoch: 1/2, step 253/7134 completed (loss: 3.9308972358703613, acc: 0.23999999463558197)
[2024-12-17 01:35:46,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:46,878][root][INFO] - Training Epoch: 1/2, step 254/7134 completed (loss: 4.5389509201049805, acc: 0.2368421107530594)
[2024-12-17 01:35:47,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,320][root][INFO] - Training Epoch: 1/2, step 255/7134 completed (loss: 4.05450963973999, acc: 0.23076923191547394)
[2024-12-17 01:35:47,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:47,729][root][INFO] - Training Epoch: 1/2, step 256/7134 completed (loss: 4.4729814529418945, acc: 0.22972972691059113)
[2024-12-17 01:35:47,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,151][root][INFO] - Training Epoch: 1/2, step 257/7134 completed (loss: 4.486016273498535, acc: 0.2926829159259796)
[2024-12-17 01:35:48,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,560][root][INFO] - Training Epoch: 1/2, step 258/7134 completed (loss: 4.181407451629639, acc: 0.27419355511665344)
[2024-12-17 01:35:48,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:48,983][root][INFO] - Training Epoch: 1/2, step 259/7134 completed (loss: 4.204357624053955, acc: 0.32575756311416626)
[2024-12-17 01:35:49,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,391][root][INFO] - Training Epoch: 1/2, step 260/7134 completed (loss: 3.8599395751953125, acc: 0.31578946113586426)
[2024-12-17 01:35:49,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:49,790][root][INFO] - Training Epoch: 1/2, step 261/7134 completed (loss: 4.302052974700928, acc: 0.3055555522441864)
[2024-12-17 01:35:49,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,152][root][INFO] - Training Epoch: 1/2, step 262/7134 completed (loss: 4.097306251525879, acc: 0.28455284237861633)
[2024-12-17 01:35:50,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,530][root][INFO] - Training Epoch: 1/2, step 263/7134 completed (loss: 4.252862453460693, acc: 0.2716049253940582)
[2024-12-17 01:35:50,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:50,914][root][INFO] - Training Epoch: 1/2, step 264/7134 completed (loss: 4.072551250457764, acc: 0.23529411852359772)
[2024-12-17 01:35:51,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,290][root][INFO] - Training Epoch: 1/2, step 265/7134 completed (loss: 4.28018856048584, acc: 0.26966291666030884)
[2024-12-17 01:35:51,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:51,709][root][INFO] - Training Epoch: 1/2, step 266/7134 completed (loss: 4.286301136016846, acc: 0.25)
[2024-12-17 01:35:51,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,157][root][INFO] - Training Epoch: 1/2, step 267/7134 completed (loss: 4.494642734527588, acc: 0.24468085169792175)
[2024-12-17 01:35:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,572][root][INFO] - Training Epoch: 1/2, step 268/7134 completed (loss: 4.454987525939941, acc: 0.27272728085517883)
[2024-12-17 01:35:52,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:52,969][root][INFO] - Training Epoch: 1/2, step 269/7134 completed (loss: 4.590539455413818, acc: 0.190476194024086)
[2024-12-17 01:35:53,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,342][root][INFO] - Training Epoch: 1/2, step 270/7134 completed (loss: 4.388363361358643, acc: 0.3062500059604645)
[2024-12-17 01:35:53,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:53,737][root][INFO] - Training Epoch: 1/2, step 271/7134 completed (loss: 4.775657653808594, acc: 0.23333333432674408)
[2024-12-17 01:35:53,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,131][root][INFO] - Training Epoch: 1/2, step 272/7134 completed (loss: 4.4753737449646, acc: 0.29050278663635254)
[2024-12-17 01:35:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,523][root][INFO] - Training Epoch: 1/2, step 273/7134 completed (loss: 4.06069278717041, acc: 0.25)
[2024-12-17 01:35:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:54,935][root][INFO] - Training Epoch: 1/2, step 274/7134 completed (loss: 4.787831783294678, acc: 0.22807016968727112)
[2024-12-17 01:35:55,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,369][root][INFO] - Training Epoch: 1/2, step 275/7134 completed (loss: 4.1430182456970215, acc: 0.2842639684677124)
[2024-12-17 01:35:55,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:55,844][root][INFO] - Training Epoch: 1/2, step 276/7134 completed (loss: 4.5360941886901855, acc: 0.26288658380508423)
[2024-12-17 01:35:56,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,301][root][INFO] - Training Epoch: 1/2, step 277/7134 completed (loss: 4.419892311096191, acc: 0.2756756842136383)
[2024-12-17 01:35:56,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:56,693][root][INFO] - Training Epoch: 1/2, step 278/7134 completed (loss: 4.571930408477783, acc: 0.25)
[2024-12-17 01:35:56,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,077][root][INFO] - Training Epoch: 1/2, step 279/7134 completed (loss: 4.2009077072143555, acc: 0.227027028799057)
[2024-12-17 01:35:57,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,481][root][INFO] - Training Epoch: 1/2, step 280/7134 completed (loss: 4.769548416137695, acc: 0.24799999594688416)
[2024-12-17 01:35:57,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:57,877][root][INFO] - Training Epoch: 1/2, step 281/7134 completed (loss: 4.578364372253418, acc: 0.27966102957725525)
[2024-12-17 01:35:57,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,255][root][INFO] - Training Epoch: 1/2, step 282/7134 completed (loss: 4.628580570220947, acc: 0.24683544039726257)
[2024-12-17 01:35:58,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:58,648][root][INFO] - Training Epoch: 1/2, step 283/7134 completed (loss: 4.6187825202941895, acc: 0.2442748099565506)
[2024-12-17 01:35:58,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,054][root][INFO] - Training Epoch: 1/2, step 284/7134 completed (loss: 4.29210090637207, acc: 0.2097902148962021)
[2024-12-17 01:35:59,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,459][root][INFO] - Training Epoch: 1/2, step 285/7134 completed (loss: 4.551084041595459, acc: 0.25925925374031067)
[2024-12-17 01:35:59,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:35:59,836][root][INFO] - Training Epoch: 1/2, step 286/7134 completed (loss: 4.895664215087891, acc: 0.2013888955116272)
[2024-12-17 01:35:59,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,224][root][INFO] - Training Epoch: 1/2, step 287/7134 completed (loss: 4.362775802612305, acc: 0.28859061002731323)
[2024-12-17 01:36:00,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:00,668][root][INFO] - Training Epoch: 1/2, step 288/7134 completed (loss: 4.353825092315674, acc: 0.29921260476112366)
[2024-12-17 01:36:00,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,083][root][INFO] - Training Epoch: 1/2, step 289/7134 completed (loss: 4.360016345977783, acc: 0.26356589794158936)
[2024-12-17 01:36:01,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,433][root][INFO] - Training Epoch: 1/2, step 290/7134 completed (loss: 4.2202301025390625, acc: 0.26623377203941345)
[2024-12-17 01:36:01,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:01,860][root][INFO] - Training Epoch: 1/2, step 291/7134 completed (loss: 4.216555595397949, acc: 0.2857142984867096)
[2024-12-17 01:36:01,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,251][root][INFO] - Training Epoch: 1/2, step 292/7134 completed (loss: 4.730043411254883, acc: 0.23456789553165436)
[2024-12-17 01:36:02,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:02,688][root][INFO] - Training Epoch: 1/2, step 293/7134 completed (loss: 4.493043899536133, acc: 0.29203540086746216)
[2024-12-17 01:36:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,118][root][INFO] - Training Epoch: 1/2, step 294/7134 completed (loss: 5.038431644439697, acc: 0.20338982343673706)
[2024-12-17 01:36:03,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,541][root][INFO] - Training Epoch: 1/2, step 295/7134 completed (loss: 4.309405326843262, acc: 0.2884615361690521)
[2024-12-17 01:36:03,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:03,958][root][INFO] - Training Epoch: 1/2, step 296/7134 completed (loss: 4.105044364929199, acc: 0.3333333432674408)
[2024-12-17 01:36:04,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,388][root][INFO] - Training Epoch: 1/2, step 297/7134 completed (loss: 4.283436298370361, acc: 0.26446279883384705)
[2024-12-17 01:36:04,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:04,811][root][INFO] - Training Epoch: 1/2, step 298/7134 completed (loss: 4.514947891235352, acc: 0.23076923191547394)
[2024-12-17 01:36:04,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,236][root][INFO] - Training Epoch: 1/2, step 299/7134 completed (loss: 4.170109748840332, acc: 0.2846715450286865)
[2024-12-17 01:36:05,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:05,657][root][INFO] - Training Epoch: 1/2, step 300/7134 completed (loss: 3.743337392807007, acc: 0.36231884360313416)
[2024-12-17 01:36:05,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,073][root][INFO] - Training Epoch: 1/2, step 301/7134 completed (loss: 4.273177623748779, acc: 0.31468531489372253)
[2024-12-17 01:36:06,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,439][root][INFO] - Training Epoch: 1/2, step 302/7134 completed (loss: 4.339446067810059, acc: 0.31683167815208435)
[2024-12-17 01:36:06,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:06,831][root][INFO] - Training Epoch: 1/2, step 303/7134 completed (loss: 4.855230331420898, acc: 0.2432432472705841)
[2024-12-17 01:36:07,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,298][root][INFO] - Training Epoch: 1/2, step 304/7134 completed (loss: 4.60681676864624, acc: 0.21782177686691284)
[2024-12-17 01:36:07,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:07,683][root][INFO] - Training Epoch: 1/2, step 305/7134 completed (loss: 4.159523963928223, acc: 0.2265625)
[2024-12-17 01:36:07,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,143][root][INFO] - Training Epoch: 1/2, step 306/7134 completed (loss: 4.499456405639648, acc: 0.260869562625885)
[2024-12-17 01:36:08,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:08,617][root][INFO] - Training Epoch: 1/2, step 307/7134 completed (loss: 4.31785249710083, acc: 0.336448609828949)
[2024-12-17 01:36:08,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,005][root][INFO] - Training Epoch: 1/2, step 308/7134 completed (loss: 4.085855484008789, acc: 0.26771652698516846)
[2024-12-17 01:36:09,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,418][root][INFO] - Training Epoch: 1/2, step 309/7134 completed (loss: 4.719686985015869, acc: 0.1946902722120285)
[2024-12-17 01:36:09,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:09,840][root][INFO] - Training Epoch: 1/2, step 310/7134 completed (loss: 3.9671106338500977, acc: 0.302325576543808)
[2024-12-17 01:36:09,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,232][root][INFO] - Training Epoch: 1/2, step 311/7134 completed (loss: 4.2324042320251465, acc: 0.2631579041481018)
[2024-12-17 01:36:10,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:10,652][root][INFO] - Training Epoch: 1/2, step 312/7134 completed (loss: 3.974618911743164, acc: 0.26229506731033325)
[2024-12-17 01:36:10,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,064][root][INFO] - Training Epoch: 1/2, step 313/7134 completed (loss: 4.146636009216309, acc: 0.29600000381469727)
[2024-12-17 01:36:11,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,473][root][INFO] - Training Epoch: 1/2, step 314/7134 completed (loss: 4.287820816040039, acc: 0.34074074029922485)
[2024-12-17 01:36:11,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:11,950][root][INFO] - Training Epoch: 1/2, step 315/7134 completed (loss: 4.1943678855896, acc: 0.3333333432674408)
[2024-12-17 01:36:12,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,367][root][INFO] - Training Epoch: 1/2, step 316/7134 completed (loss: 3.9555556774139404, acc: 0.3333333432674408)
[2024-12-17 01:36:12,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:12,859][root][INFO] - Training Epoch: 1/2, step 317/7134 completed (loss: 4.20522928237915, acc: 0.20886075496673584)
[2024-12-17 01:36:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,357][root][INFO] - Training Epoch: 1/2, step 318/7134 completed (loss: 4.610043525695801, acc: 0.2526881694793701)
[2024-12-17 01:36:13,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:13,738][root][INFO] - Training Epoch: 1/2, step 319/7134 completed (loss: 4.602237224578857, acc: 0.23602484166622162)
[2024-12-17 01:36:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,155][root][INFO] - Training Epoch: 1/2, step 320/7134 completed (loss: 4.1273040771484375, acc: 0.3095238208770752)
[2024-12-17 01:36:14,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,611][root][INFO] - Training Epoch: 1/2, step 321/7134 completed (loss: 4.321470260620117, acc: 0.2816092073917389)
[2024-12-17 01:36:14,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:14,995][root][INFO] - Training Epoch: 1/2, step 322/7134 completed (loss: 4.276830196380615, acc: 0.27450981736183167)
[2024-12-17 01:36:15,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,393][root][INFO] - Training Epoch: 1/2, step 323/7134 completed (loss: 4.683089256286621, acc: 0.27551019191741943)
[2024-12-17 01:36:15,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:15,790][root][INFO] - Training Epoch: 1/2, step 324/7134 completed (loss: 4.050957202911377, acc: 0.28703704476356506)
[2024-12-17 01:36:15,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,215][root][INFO] - Training Epoch: 1/2, step 325/7134 completed (loss: 4.213646411895752, acc: 0.27272728085517883)
[2024-12-17 01:36:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:16,611][root][INFO] - Training Epoch: 1/2, step 326/7134 completed (loss: 4.126087665557861, acc: 0.2752808928489685)
[2024-12-17 01:36:16,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,018][root][INFO] - Training Epoch: 1/2, step 327/7134 completed (loss: 4.060669422149658, acc: 0.2777777910232544)
[2024-12-17 01:36:17,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,443][root][INFO] - Training Epoch: 1/2, step 328/7134 completed (loss: 4.063404083251953, acc: 0.2874999940395355)
[2024-12-17 01:36:17,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:17,834][root][INFO] - Training Epoch: 1/2, step 329/7134 completed (loss: 4.010903835296631, acc: 0.2885572016239166)
[2024-12-17 01:36:17,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,254][root][INFO] - Training Epoch: 1/2, step 330/7134 completed (loss: 3.639892101287842, acc: 0.31578946113586426)
[2024-12-17 01:36:18,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:18,698][root][INFO] - Training Epoch: 1/2, step 331/7134 completed (loss: 4.0634331703186035, acc: 0.296875)
[2024-12-17 01:36:18,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,126][root][INFO] - Training Epoch: 1/2, step 332/7134 completed (loss: 3.7636988162994385, acc: 0.27363184094429016)
[2024-12-17 01:36:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,516][root][INFO] - Training Epoch: 1/2, step 333/7134 completed (loss: 4.5028767585754395, acc: 0.24731183052062988)
[2024-12-17 01:36:19,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:19,934][root][INFO] - Training Epoch: 1/2, step 334/7134 completed (loss: 4.3191938400268555, acc: 0.2527472674846649)
[2024-12-17 01:36:20,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,309][root][INFO] - Training Epoch: 1/2, step 335/7134 completed (loss: 4.084780693054199, acc: 0.29729729890823364)
[2024-12-17 01:36:20,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:20,720][root][INFO] - Training Epoch: 1/2, step 336/7134 completed (loss: 4.033527374267578, acc: 0.25388601422309875)
[2024-12-17 01:36:20,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,111][root][INFO] - Training Epoch: 1/2, step 337/7134 completed (loss: 4.1019744873046875, acc: 0.2857142984867096)
[2024-12-17 01:36:21,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,509][root][INFO] - Training Epoch: 1/2, step 338/7134 completed (loss: 4.466631889343262, acc: 0.2513088881969452)
[2024-12-17 01:36:21,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:21,938][root][INFO] - Training Epoch: 1/2, step 339/7134 completed (loss: 4.212224006652832, acc: 0.28877004981040955)
[2024-12-17 01:36:22,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,369][root][INFO] - Training Epoch: 1/2, step 340/7134 completed (loss: 3.8079307079315186, acc: 0.3232323229312897)
[2024-12-17 01:36:22,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:22,797][root][INFO] - Training Epoch: 1/2, step 341/7134 completed (loss: 4.023752212524414, acc: 0.29591837525367737)
[2024-12-17 01:36:22,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,212][root][INFO] - Training Epoch: 1/2, step 342/7134 completed (loss: 4.034999847412109, acc: 0.30188679695129395)
[2024-12-17 01:36:23,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,621][root][INFO] - Training Epoch: 1/2, step 343/7134 completed (loss: 4.115752220153809, acc: 0.26923078298568726)
[2024-12-17 01:36:23,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:23,981][root][INFO] - Training Epoch: 1/2, step 344/7134 completed (loss: 4.598654747009277, acc: 0.21705426275730133)
[2024-12-17 01:36:24,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,398][root][INFO] - Training Epoch: 1/2, step 345/7134 completed (loss: 4.51420783996582, acc: 0.23404255509376526)
[2024-12-17 01:36:24,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:24,844][root][INFO] - Training Epoch: 1/2, step 346/7134 completed (loss: 4.458342552185059, acc: 0.21710526943206787)
[2024-12-17 01:36:24,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,239][root][INFO] - Training Epoch: 1/2, step 347/7134 completed (loss: 4.110325813293457, acc: 0.26875001192092896)
[2024-12-17 01:36:25,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:25,627][root][INFO] - Training Epoch: 1/2, step 348/7134 completed (loss: 3.9011595249176025, acc: 0.3076923191547394)
[2024-12-17 01:36:25,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,061][root][INFO] - Training Epoch: 1/2, step 349/7134 completed (loss: 4.215651988983154, acc: 0.27218934893608093)
[2024-12-17 01:36:26,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,456][root][INFO] - Training Epoch: 1/2, step 350/7134 completed (loss: 4.465610980987549, acc: 0.205263152718544)
[2024-12-17 01:36:26,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:26,858][root][INFO] - Training Epoch: 1/2, step 351/7134 completed (loss: 4.5497307777404785, acc: 0.27173912525177)
[2024-12-17 01:36:26,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,252][root][INFO] - Training Epoch: 1/2, step 352/7134 completed (loss: 4.021792888641357, acc: 0.31578946113586426)
[2024-12-17 01:36:27,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:27,669][root][INFO] - Training Epoch: 1/2, step 353/7134 completed (loss: 4.222587585449219, acc: 0.25153374671936035)
[2024-12-17 01:36:27,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,127][root][INFO] - Training Epoch: 1/2, step 354/7134 completed (loss: 4.099794387817383, acc: 0.286432147026062)
[2024-12-17 01:36:28,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:28,607][root][INFO] - Training Epoch: 1/2, step 355/7134 completed (loss: 4.163187503814697, acc: 0.2840236723423004)
[2024-12-17 01:36:28,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,069][root][INFO] - Training Epoch: 1/2, step 356/7134 completed (loss: 3.7475380897521973, acc: 0.329341322183609)
[2024-12-17 01:36:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,521][root][INFO] - Training Epoch: 1/2, step 357/7134 completed (loss: 4.031591892242432, acc: 0.22674418985843658)
[2024-12-17 01:36:29,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:29,971][root][INFO] - Training Epoch: 1/2, step 358/7134 completed (loss: 3.469341516494751, acc: 0.34090909361839294)
[2024-12-17 01:36:30,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,377][root][INFO] - Training Epoch: 1/2, step 359/7134 completed (loss: 3.883023977279663, acc: 0.3176470696926117)
[2024-12-17 01:36:30,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:30,788][root][INFO] - Training Epoch: 1/2, step 360/7134 completed (loss: 3.8575639724731445, acc: 0.2875817120075226)
[2024-12-17 01:36:30,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,164][root][INFO] - Training Epoch: 1/2, step 361/7134 completed (loss: 3.5565459728240967, acc: 0.2699386477470398)
[2024-12-17 01:36:31,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,578][root][INFO] - Training Epoch: 1/2, step 362/7134 completed (loss: 4.1211724281311035, acc: 0.2848101258277893)
[2024-12-17 01:36:31,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:31,989][root][INFO] - Training Epoch: 1/2, step 363/7134 completed (loss: 4.223784923553467, acc: 0.22404371201992035)
[2024-12-17 01:36:32,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,418][root][INFO] - Training Epoch: 1/2, step 364/7134 completed (loss: 4.075380325317383, acc: 0.28155338764190674)
[2024-12-17 01:36:32,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:32,844][root][INFO] - Training Epoch: 1/2, step 365/7134 completed (loss: 3.797102451324463, acc: 0.3037974536418915)
[2024-12-17 01:36:32,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,266][root][INFO] - Training Epoch: 1/2, step 366/7134 completed (loss: 3.7409768104553223, acc: 0.2866241931915283)
[2024-12-17 01:36:33,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:33,691][root][INFO] - Training Epoch: 1/2, step 367/7134 completed (loss: 3.772655963897705, acc: 0.2835051417350769)
[2024-12-17 01:36:33,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,074][root][INFO] - Training Epoch: 1/2, step 368/7134 completed (loss: 3.4762845039367676, acc: 0.27218934893608093)
[2024-12-17 01:36:34,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,453][root][INFO] - Training Epoch: 1/2, step 369/7134 completed (loss: 4.222909927368164, acc: 0.21472392976284027)
[2024-12-17 01:36:34,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:34,848][root][INFO] - Training Epoch: 1/2, step 370/7134 completed (loss: 4.279432773590088, acc: 0.20886075496673584)
[2024-12-17 01:36:34,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,214][root][INFO] - Training Epoch: 1/2, step 371/7134 completed (loss: 3.8337721824645996, acc: 0.31677019596099854)
[2024-12-17 01:36:35,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,587][root][INFO] - Training Epoch: 1/2, step 372/7134 completed (loss: 4.200945854187012, acc: 0.30817610025405884)
[2024-12-17 01:36:35,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:35,983][root][INFO] - Training Epoch: 1/2, step 373/7134 completed (loss: 3.8724122047424316, acc: 0.27450981736183167)
[2024-12-17 01:36:36,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,368][root][INFO] - Training Epoch: 1/2, step 374/7134 completed (loss: 3.5419657230377197, acc: 0.31081080436706543)
[2024-12-17 01:36:36,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:36,762][root][INFO] - Training Epoch: 1/2, step 375/7134 completed (loss: 3.8712940216064453, acc: 0.2819148898124695)
[2024-12-17 01:36:36,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,116][root][INFO] - Training Epoch: 1/2, step 376/7134 completed (loss: 4.181710720062256, acc: 0.2888889014720917)
[2024-12-17 01:36:37,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,517][root][INFO] - Training Epoch: 1/2, step 377/7134 completed (loss: 4.052133083343506, acc: 0.2849161922931671)
[2024-12-17 01:36:37,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:37,910][root][INFO] - Training Epoch: 1/2, step 378/7134 completed (loss: 4.4941325187683105, acc: 0.2259887009859085)
[2024-12-17 01:36:38,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,300][root][INFO] - Training Epoch: 1/2, step 379/7134 completed (loss: 3.4390509128570557, acc: 0.30392158031463623)
[2024-12-17 01:36:38,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:38,733][root][INFO] - Training Epoch: 1/2, step 380/7134 completed (loss: 4.543095111846924, acc: 0.2525773048400879)
[2024-12-17 01:36:38,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,118][root][INFO] - Training Epoch: 1/2, step 381/7134 completed (loss: 4.164475440979004, acc: 0.2684210538864136)
[2024-12-17 01:36:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,533][root][INFO] - Training Epoch: 1/2, step 382/7134 completed (loss: 3.736811399459839, acc: 0.3333333432674408)
[2024-12-17 01:36:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:39,902][root][INFO] - Training Epoch: 1/2, step 383/7134 completed (loss: 3.7982261180877686, acc: 0.26356589794158936)
[2024-12-17 01:36:40,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,281][root][INFO] - Training Epoch: 1/2, step 384/7134 completed (loss: 3.5102930068969727, acc: 0.33701658248901367)
[2024-12-17 01:36:40,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:40,675][root][INFO] - Training Epoch: 1/2, step 385/7134 completed (loss: 3.5802245140075684, acc: 0.3202614486217499)
[2024-12-17 01:36:40,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,068][root][INFO] - Training Epoch: 1/2, step 386/7134 completed (loss: 4.050220012664795, acc: 0.28828829526901245)
[2024-12-17 01:36:41,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,516][root][INFO] - Training Epoch: 1/2, step 387/7134 completed (loss: 4.2244768142700195, acc: 0.21301774680614471)
[2024-12-17 01:36:41,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:41,899][root][INFO] - Training Epoch: 1/2, step 388/7134 completed (loss: 3.588088035583496, acc: 0.3349282443523407)
[2024-12-17 01:36:41,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,280][root][INFO] - Training Epoch: 1/2, step 389/7134 completed (loss: 3.7343590259552, acc: 0.33714285492897034)
[2024-12-17 01:36:42,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:42,695][root][INFO] - Training Epoch: 1/2, step 390/7134 completed (loss: 3.6348440647125244, acc: 0.31081080436706543)
[2024-12-17 01:36:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,070][root][INFO] - Training Epoch: 1/2, step 391/7134 completed (loss: 3.474158525466919, acc: 0.3400000035762787)
[2024-12-17 01:36:43,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,476][root][INFO] - Training Epoch: 1/2, step 392/7134 completed (loss: 3.481067657470703, acc: 0.34302327036857605)
[2024-12-17 01:36:43,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:43,850][root][INFO] - Training Epoch: 1/2, step 393/7134 completed (loss: 3.582834482192993, acc: 0.33155080676078796)
[2024-12-17 01:36:43,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,246][root][INFO] - Training Epoch: 1/2, step 394/7134 completed (loss: 3.9114561080932617, acc: 0.25190839171409607)
[2024-12-17 01:36:44,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,625][root][INFO] - Training Epoch: 1/2, step 395/7134 completed (loss: 3.425173759460449, acc: 0.3297872245311737)
[2024-12-17 01:36:44,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:44,995][root][INFO] - Training Epoch: 1/2, step 396/7134 completed (loss: 3.968043565750122, acc: 0.27586206793785095)
[2024-12-17 01:36:45,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,421][root][INFO] - Training Epoch: 1/2, step 397/7134 completed (loss: 3.8570401668548584, acc: 0.28260868787765503)
[2024-12-17 01:36:45,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:45,796][root][INFO] - Training Epoch: 1/2, step 398/7134 completed (loss: 3.5060348510742188, acc: 0.3787878751754761)
[2024-12-17 01:36:45,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,195][root][INFO] - Training Epoch: 1/2, step 399/7134 completed (loss: 3.6204776763916016, acc: 0.3291139304637909)
[2024-12-17 01:36:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,568][root][INFO] - Training Epoch: 1/2, step 400/7134 completed (loss: 4.1473307609558105, acc: 0.31012657284736633)
[2024-12-17 01:36:46,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:46,976][root][INFO] - Training Epoch: 1/2, step 401/7134 completed (loss: 3.926124095916748, acc: 0.30392158031463623)
[2024-12-17 01:36:47,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,364][root][INFO] - Training Epoch: 1/2, step 402/7134 completed (loss: 4.173660755157471, acc: 0.21608039736747742)
[2024-12-17 01:36:47,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:47,797][root][INFO] - Training Epoch: 1/2, step 403/7134 completed (loss: 3.6378400325775146, acc: 0.3144104778766632)
[2024-12-17 01:36:47,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,178][root][INFO] - Training Epoch: 1/2, step 404/7134 completed (loss: 3.6621503829956055, acc: 0.3494623601436615)
[2024-12-17 01:36:48,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:48,593][root][INFO] - Training Epoch: 1/2, step 405/7134 completed (loss: 3.962726593017578, acc: 0.3255814015865326)
[2024-12-17 01:36:48,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,001][root][INFO] - Training Epoch: 1/2, step 406/7134 completed (loss: 3.74774432182312, acc: 0.28108108043670654)
[2024-12-17 01:36:49,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,344][root][INFO] - Training Epoch: 1/2, step 407/7134 completed (loss: 3.5954973697662354, acc: 0.2929936349391937)
[2024-12-17 01:36:49,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:49,700][root][INFO] - Training Epoch: 1/2, step 408/7134 completed (loss: 3.475261688232422, acc: 0.34078213572502136)
[2024-12-17 01:36:49,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,054][root][INFO] - Training Epoch: 1/2, step 409/7134 completed (loss: 3.9067225456237793, acc: 0.28947368264198303)
[2024-12-17 01:36:50,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,460][root][INFO] - Training Epoch: 1/2, step 410/7134 completed (loss: 3.394362688064575, acc: 0.35757574439048767)
[2024-12-17 01:36:50,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:50,864][root][INFO] - Training Epoch: 1/2, step 411/7134 completed (loss: 3.6699259281158447, acc: 0.30180180072784424)
[2024-12-17 01:36:50,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,245][root][INFO] - Training Epoch: 1/2, step 412/7134 completed (loss: 3.6254923343658447, acc: 0.2825112044811249)
[2024-12-17 01:36:51,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,614][root][INFO] - Training Epoch: 1/2, step 413/7134 completed (loss: 3.9033989906311035, acc: 0.30890053510665894)
[2024-12-17 01:36:51,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:51,988][root][INFO] - Training Epoch: 1/2, step 414/7134 completed (loss: 3.991466999053955, acc: 0.35260117053985596)
[2024-12-17 01:36:52,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,351][root][INFO] - Training Epoch: 1/2, step 415/7134 completed (loss: 3.837251901626587, acc: 0.2809523940086365)
[2024-12-17 01:36:52,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:52,730][root][INFO] - Training Epoch: 1/2, step 416/7134 completed (loss: 3.4592082500457764, acc: 0.3173076808452606)
[2024-12-17 01:36:52,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,172][root][INFO] - Training Epoch: 1/2, step 417/7134 completed (loss: 3.799562931060791, acc: 0.30219781398773193)
[2024-12-17 01:36:53,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,590][root][INFO] - Training Epoch: 1/2, step 418/7134 completed (loss: 3.8067476749420166, acc: 0.3719806671142578)
[2024-12-17 01:36:53,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:53,973][root][INFO] - Training Epoch: 1/2, step 419/7134 completed (loss: 3.475825309753418, acc: 0.3465346395969391)
[2024-12-17 01:36:54,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,395][root][INFO] - Training Epoch: 1/2, step 420/7134 completed (loss: 4.274040222167969, acc: 0.23571428656578064)
[2024-12-17 01:36:54,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:54,800][root][INFO] - Training Epoch: 1/2, step 421/7134 completed (loss: 3.489638566970825, acc: 0.3396226465702057)
[2024-12-17 01:36:54,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,201][root][INFO] - Training Epoch: 1/2, step 422/7134 completed (loss: 4.052497386932373, acc: 0.26035502552986145)
[2024-12-17 01:36:55,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,605][root][INFO] - Training Epoch: 1/2, step 423/7134 completed (loss: 3.3500723838806152, acc: 0.3314606845378876)
[2024-12-17 01:36:55,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:55,992][root][INFO] - Training Epoch: 1/2, step 424/7134 completed (loss: 3.543069362640381, acc: 0.3024691343307495)
[2024-12-17 01:36:56,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,391][root][INFO] - Training Epoch: 1/2, step 425/7134 completed (loss: 3.356456995010376, acc: 0.3295454680919647)
[2024-12-17 01:36:56,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:56,783][root][INFO] - Training Epoch: 1/2, step 426/7134 completed (loss: 3.430482864379883, acc: 0.3235294222831726)
[2024-12-17 01:36:56,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,169][root][INFO] - Training Epoch: 1/2, step 427/7134 completed (loss: 3.6599106788635254, acc: 0.3459119498729706)
[2024-12-17 01:36:57,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,574][root][INFO] - Training Epoch: 1/2, step 428/7134 completed (loss: 3.8720531463623047, acc: 0.28143712878227234)
[2024-12-17 01:36:57,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:57,930][root][INFO] - Training Epoch: 1/2, step 429/7134 completed (loss: 4.1427321434021, acc: 0.28289473056793213)
[2024-12-17 01:36:58,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,309][root][INFO] - Training Epoch: 1/2, step 430/7134 completed (loss: 4.174022197723389, acc: 0.25882354378700256)
[2024-12-17 01:36:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:58,709][root][INFO] - Training Epoch: 1/2, step 431/7134 completed (loss: 3.755512237548828, acc: 0.3076923191547394)
[2024-12-17 01:36:58,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,063][root][INFO] - Training Epoch: 1/2, step 432/7134 completed (loss: 4.012392044067383, acc: 0.31060606241226196)
[2024-12-17 01:36:59,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,539][root][INFO] - Training Epoch: 1/2, step 433/7134 completed (loss: 3.2843141555786133, acc: 0.41489362716674805)
[2024-12-17 01:36:59,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:36:59,940][root][INFO] - Training Epoch: 1/2, step 434/7134 completed (loss: 3.6651227474212646, acc: 0.32098764181137085)
[2024-12-17 01:37:00,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,327][root][INFO] - Training Epoch: 1/2, step 435/7134 completed (loss: 3.723095417022705, acc: 0.2888889014720917)
[2024-12-17 01:37:00,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:00,686][root][INFO] - Training Epoch: 1/2, step 436/7134 completed (loss: 3.404996156692505, acc: 0.375)
[2024-12-17 01:37:00,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,047][root][INFO] - Training Epoch: 1/2, step 437/7134 completed (loss: 4.042469024658203, acc: 0.22535210847854614)
[2024-12-17 01:37:01,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,409][root][INFO] - Training Epoch: 1/2, step 438/7134 completed (loss: 3.6499078273773193, acc: 0.27559053897857666)
[2024-12-17 01:37:01,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:01,820][root][INFO] - Training Epoch: 1/2, step 439/7134 completed (loss: 3.7541136741638184, acc: 0.3333333432674408)
[2024-12-17 01:37:01,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,229][root][INFO] - Training Epoch: 1/2, step 440/7134 completed (loss: 4.040502071380615, acc: 0.30000001192092896)
[2024-12-17 01:37:02,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:02,668][root][INFO] - Training Epoch: 1/2, step 441/7134 completed (loss: 3.603943347930908, acc: 0.33561643958091736)
[2024-12-17 01:37:02,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,051][root][INFO] - Training Epoch: 1/2, step 442/7134 completed (loss: 3.2456984519958496, acc: 0.3488371968269348)
[2024-12-17 01:37:03,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,435][root][INFO] - Training Epoch: 1/2, step 443/7134 completed (loss: 3.337404727935791, acc: 0.3469387888908386)
[2024-12-17 01:37:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:03,844][root][INFO] - Training Epoch: 1/2, step 444/7134 completed (loss: 3.322382688522339, acc: 0.356589138507843)
[2024-12-17 01:37:03,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,236][root][INFO] - Training Epoch: 1/2, step 445/7134 completed (loss: 3.6975369453430176, acc: 0.3270440399646759)
[2024-12-17 01:37:04,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:04,659][root][INFO] - Training Epoch: 1/2, step 446/7134 completed (loss: 3.6522154808044434, acc: 0.3076923191547394)
[2024-12-17 01:37:04,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,058][root][INFO] - Training Epoch: 1/2, step 447/7134 completed (loss: 3.8110148906707764, acc: 0.28834354877471924)
[2024-12-17 01:37:05,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,456][root][INFO] - Training Epoch: 1/2, step 448/7134 completed (loss: 3.989819049835205, acc: 0.2698412835597992)
[2024-12-17 01:37:05,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:05,836][root][INFO] - Training Epoch: 1/2, step 449/7134 completed (loss: 4.042683124542236, acc: 0.2819148898124695)
[2024-12-17 01:37:05,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,218][root][INFO] - Training Epoch: 1/2, step 450/7134 completed (loss: 4.0257720947265625, acc: 0.2830188572406769)
[2024-12-17 01:37:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,583][root][INFO] - Training Epoch: 1/2, step 451/7134 completed (loss: 4.0195393562316895, acc: 0.347457617521286)
[2024-12-17 01:37:06,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:06,959][root][INFO] - Training Epoch: 1/2, step 452/7134 completed (loss: 4.1147894859313965, acc: 0.3314606845378876)
[2024-12-17 01:37:07,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,298][root][INFO] - Training Epoch: 1/2, step 453/7134 completed (loss: 3.8434574604034424, acc: 0.3333333432674408)
[2024-12-17 01:37:07,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:07,674][root][INFO] - Training Epoch: 1/2, step 454/7134 completed (loss: 3.7572572231292725, acc: 0.3080168664455414)
[2024-12-17 01:37:07,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,055][root][INFO] - Training Epoch: 1/2, step 455/7134 completed (loss: 4.099235534667969, acc: 0.34871795773506165)
[2024-12-17 01:37:08,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,493][root][INFO] - Training Epoch: 1/2, step 456/7134 completed (loss: 4.051218509674072, acc: 0.23926380276679993)
[2024-12-17 01:37:08,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:08,860][root][INFO] - Training Epoch: 1/2, step 457/7134 completed (loss: 3.7928924560546875, acc: 0.25517240166664124)
[2024-12-17 01:37:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,264][root][INFO] - Training Epoch: 1/2, step 458/7134 completed (loss: 4.0471625328063965, acc: 0.27419355511665344)
[2024-12-17 01:37:09,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:09,672][root][INFO] - Training Epoch: 1/2, step 459/7134 completed (loss: 3.8687057495117188, acc: 0.28915661573410034)
[2024-12-17 01:37:09,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,073][root][INFO] - Training Epoch: 1/2, step 460/7134 completed (loss: 4.088667869567871, acc: 0.25999999046325684)
[2024-12-17 01:37:10,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,449][root][INFO] - Training Epoch: 1/2, step 461/7134 completed (loss: 4.1917548179626465, acc: 0.2705882489681244)
[2024-12-17 01:37:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:10,848][root][INFO] - Training Epoch: 1/2, step 462/7134 completed (loss: 3.7986111640930176, acc: 0.32870370149612427)
[2024-12-17 01:37:10,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,263][root][INFO] - Training Epoch: 1/2, step 463/7134 completed (loss: 4.156007289886475, acc: 0.30845770239830017)
[2024-12-17 01:37:11,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:11,727][root][INFO] - Training Epoch: 1/2, step 464/7134 completed (loss: 3.638603448867798, acc: 0.33522728085517883)
[2024-12-17 01:37:11,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,171][root][INFO] - Training Epoch: 1/2, step 465/7134 completed (loss: 3.5603365898132324, acc: 0.3296089470386505)
[2024-12-17 01:37:12,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:12,565][root][INFO] - Training Epoch: 1/2, step 466/7134 completed (loss: 4.2096333503723145, acc: 0.2982456088066101)
[2024-12-17 01:37:12,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,024][root][INFO] - Training Epoch: 1/2, step 467/7134 completed (loss: 4.140442848205566, acc: 0.3333333432674408)
[2024-12-17 01:37:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,465][root][INFO] - Training Epoch: 1/2, step 468/7134 completed (loss: 4.0417656898498535, acc: 0.31333333253860474)
[2024-12-17 01:37:13,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:13,800][root][INFO] - Training Epoch: 1/2, step 469/7134 completed (loss: 4.105710029602051, acc: 0.375)
[2024-12-17 01:37:13,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,146][root][INFO] - Training Epoch: 1/2, step 470/7134 completed (loss: 4.017923355102539, acc: 0.3918918967247009)
[2024-12-17 01:37:14,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,483][root][INFO] - Training Epoch: 1/2, step 471/7134 completed (loss: 4.098179817199707, acc: 0.3461538553237915)
[2024-12-17 01:37:14,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:14,894][root][INFO] - Training Epoch: 1/2, step 472/7134 completed (loss: 4.19223690032959, acc: 0.3333333432674408)
[2024-12-17 01:37:15,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,299][root][INFO] - Training Epoch: 1/2, step 473/7134 completed (loss: 3.9844748973846436, acc: 0.25)
[2024-12-17 01:37:15,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:15,689][root][INFO] - Training Epoch: 1/2, step 474/7134 completed (loss: 4.419008731842041, acc: 0.260606050491333)
[2024-12-17 01:37:15,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,096][root][INFO] - Training Epoch: 1/2, step 475/7134 completed (loss: 3.914771795272827, acc: 0.37062937021255493)
[2024-12-17 01:37:16,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,567][root][INFO] - Training Epoch: 1/2, step 476/7134 completed (loss: 4.349055767059326, acc: 0.2562499940395355)
[2024-12-17 01:37:16,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:16,985][root][INFO] - Training Epoch: 1/2, step 477/7134 completed (loss: 3.808624029159546, acc: 0.32085561752319336)
[2024-12-17 01:37:17,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,378][root][INFO] - Training Epoch: 1/2, step 478/7134 completed (loss: 3.88459849357605, acc: 0.2956521809101105)
[2024-12-17 01:37:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:17,760][root][INFO] - Training Epoch: 1/2, step 479/7134 completed (loss: 4.268388748168945, acc: 0.3509933650493622)
[2024-12-17 01:37:17,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,131][root][INFO] - Training Epoch: 1/2, step 480/7134 completed (loss: 4.331896781921387, acc: 0.26875001192092896)
[2024-12-17 01:37:18,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,536][root][INFO] - Training Epoch: 1/2, step 481/7134 completed (loss: 4.217637538909912, acc: 0.2981366515159607)
[2024-12-17 01:37:18,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:18,933][root][INFO] - Training Epoch: 1/2, step 482/7134 completed (loss: 4.04439115524292, acc: 0.30188679695129395)
[2024-12-17 01:37:19,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,370][root][INFO] - Training Epoch: 1/2, step 483/7134 completed (loss: 4.054754257202148, acc: 0.28021979331970215)
[2024-12-17 01:37:19,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:19,749][root][INFO] - Training Epoch: 1/2, step 484/7134 completed (loss: 4.666814804077148, acc: 0.21938775479793549)
[2024-12-17 01:37:19,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,116][root][INFO] - Training Epoch: 1/2, step 485/7134 completed (loss: 4.625336647033691, acc: 0.260869562625885)
[2024-12-17 01:37:20,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,489][root][INFO] - Training Epoch: 1/2, step 486/7134 completed (loss: 4.617419719696045, acc: 0.22580644488334656)
[2024-12-17 01:37:20,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:20,878][root][INFO] - Training Epoch: 1/2, step 487/7134 completed (loss: 4.275643348693848, acc: 0.22839505970478058)
[2024-12-17 01:37:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,250][root][INFO] - Training Epoch: 1/2, step 488/7134 completed (loss: 4.553265571594238, acc: 0.23134328424930573)
[2024-12-17 01:37:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:21,663][root][INFO] - Training Epoch: 1/2, step 489/7134 completed (loss: 4.240377902984619, acc: 0.28057554364204407)
[2024-12-17 01:37:21,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,058][root][INFO] - Training Epoch: 1/2, step 490/7134 completed (loss: 3.746181011199951, acc: 0.34810125827789307)
[2024-12-17 01:37:22,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,428][root][INFO] - Training Epoch: 1/2, step 491/7134 completed (loss: 3.9215519428253174, acc: 0.3263888955116272)
[2024-12-17 01:37:22,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:22,817][root][INFO] - Training Epoch: 1/2, step 492/7134 completed (loss: 3.9673123359680176, acc: 0.2967741787433624)
[2024-12-17 01:37:23,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,300][root][INFO] - Training Epoch: 1/2, step 493/7134 completed (loss: 4.379046440124512, acc: 0.2544378638267517)
[2024-12-17 01:37:23,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:23,680][root][INFO] - Training Epoch: 1/2, step 494/7134 completed (loss: 4.489623069763184, acc: 0.25333333015441895)
[2024-12-17 01:37:23,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,084][root][INFO] - Training Epoch: 1/2, step 495/7134 completed (loss: 3.2067978382110596, acc: 0.35537189245224)
[2024-12-17 01:37:24,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,473][root][INFO] - Training Epoch: 1/2, step 496/7134 completed (loss: 4.1338958740234375, acc: 0.2947368323802948)
[2024-12-17 01:37:24,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:24,888][root][INFO] - Training Epoch: 1/2, step 497/7134 completed (loss: 3.6416451930999756, acc: 0.4076923131942749)
[2024-12-17 01:37:25,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,280][root][INFO] - Training Epoch: 1/2, step 498/7134 completed (loss: 3.7115790843963623, acc: 0.3288590610027313)
[2024-12-17 01:37:25,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:25,698][root][INFO] - Training Epoch: 1/2, step 499/7134 completed (loss: 3.2862250804901123, acc: 0.364705890417099)
[2024-12-17 01:37:25,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,089][root][INFO] - Training Epoch: 1/2, step 500/7134 completed (loss: 3.819854736328125, acc: 0.2906976640224457)
[2024-12-17 01:37:26,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,500][root][INFO] - Training Epoch: 1/2, step 501/7134 completed (loss: 3.858860969543457, acc: 0.2832369804382324)
[2024-12-17 01:37:26,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:26,894][root][INFO] - Training Epoch: 1/2, step 502/7134 completed (loss: 3.1271913051605225, acc: 0.37012988328933716)
[2024-12-17 01:37:27,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,247][root][INFO] - Training Epoch: 1/2, step 503/7134 completed (loss: 3.637294054031372, acc: 0.3125)
[2024-12-17 01:37:27,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,627][root][INFO] - Training Epoch: 1/2, step 504/7134 completed (loss: 3.7439699172973633, acc: 0.29192546010017395)
[2024-12-17 01:37:27,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:27,993][root][INFO] - Training Epoch: 1/2, step 505/7134 completed (loss: 4.1305694580078125, acc: 0.3333333432674408)
[2024-12-17 01:37:28,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,398][root][INFO] - Training Epoch: 1/2, step 506/7134 completed (loss: 3.522042751312256, acc: 0.3011363744735718)
[2024-12-17 01:37:28,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:28,870][root][INFO] - Training Epoch: 1/2, step 507/7134 completed (loss: 3.7514073848724365, acc: 0.3442623019218445)
[2024-12-17 01:37:29,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,276][root][INFO] - Training Epoch: 1/2, step 508/7134 completed (loss: 3.9825122356414795, acc: 0.2647058963775635)
[2024-12-17 01:37:29,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:29,705][root][INFO] - Training Epoch: 1/2, step 509/7134 completed (loss: 4.631994247436523, acc: 0.25)
[2024-12-17 01:37:29,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,127][root][INFO] - Training Epoch: 1/2, step 510/7134 completed (loss: 5.178422451019287, acc: 0.17886178195476532)
[2024-12-17 01:37:30,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,490][root][INFO] - Training Epoch: 1/2, step 511/7134 completed (loss: 4.557028293609619, acc: 0.22857142984867096)
[2024-12-17 01:37:30,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:30,861][root][INFO] - Training Epoch: 1/2, step 512/7134 completed (loss: 4.849420547485352, acc: 0.19083969295024872)
[2024-12-17 01:37:31,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,249][root][INFO] - Training Epoch: 1/2, step 513/7134 completed (loss: 4.388360977172852, acc: 0.30201342701911926)
[2024-12-17 01:37:31,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:31,652][root][INFO] - Training Epoch: 1/2, step 514/7134 completed (loss: 4.940344333648682, acc: 0.1388888955116272)
[2024-12-17 01:37:31,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,028][root][INFO] - Training Epoch: 1/2, step 515/7134 completed (loss: 4.687371730804443, acc: 0.190476194024086)
[2024-12-17 01:37:32,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,398][root][INFO] - Training Epoch: 1/2, step 516/7134 completed (loss: 4.384457111358643, acc: 0.20338982343673706)
[2024-12-17 01:37:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:32,797][root][INFO] - Training Epoch: 1/2, step 517/7134 completed (loss: 5.100759506225586, acc: 0.19565217196941376)
[2024-12-17 01:37:32,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,188][root][INFO] - Training Epoch: 1/2, step 518/7134 completed (loss: 4.311948776245117, acc: 0.2450331151485443)
[2024-12-17 01:37:33,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,590][root][INFO] - Training Epoch: 1/2, step 519/7134 completed (loss: 4.396417140960693, acc: 0.24347825348377228)
[2024-12-17 01:37:33,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:33,961][root][INFO] - Training Epoch: 1/2, step 520/7134 completed (loss: 4.0395331382751465, acc: 0.2565789520740509)
[2024-12-17 01:37:34,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,334][root][INFO] - Training Epoch: 1/2, step 521/7134 completed (loss: 4.382875442504883, acc: 0.26900583505630493)
[2024-12-17 01:37:34,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:34,750][root][INFO] - Training Epoch: 1/2, step 522/7134 completed (loss: 4.194537162780762, acc: 0.25280898809432983)
[2024-12-17 01:37:34,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,146][root][INFO] - Training Epoch: 1/2, step 523/7134 completed (loss: 3.656374216079712, acc: 0.33139535784721375)
[2024-12-17 01:37:35,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,518][root][INFO] - Training Epoch: 1/2, step 524/7134 completed (loss: 3.997894525527954, acc: 0.2429378479719162)
[2024-12-17 01:37:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:35,905][root][INFO] - Training Epoch: 1/2, step 525/7134 completed (loss: 3.9439632892608643, acc: 0.2760736048221588)
[2024-12-17 01:37:36,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,296][root][INFO] - Training Epoch: 1/2, step 526/7134 completed (loss: 4.123244285583496, acc: 0.27840909361839294)
[2024-12-17 01:37:36,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:36,685][root][INFO] - Training Epoch: 1/2, step 527/7134 completed (loss: 4.3806867599487305, acc: 0.2421875)
[2024-12-17 01:37:36,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,065][root][INFO] - Training Epoch: 1/2, step 528/7134 completed (loss: 4.339335918426514, acc: 0.26724138855934143)
[2024-12-17 01:37:37,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,503][root][INFO] - Training Epoch: 1/2, step 529/7134 completed (loss: 4.3403801918029785, acc: 0.2738853394985199)
[2024-12-17 01:37:37,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:37,863][root][INFO] - Training Epoch: 1/2, step 530/7134 completed (loss: 4.559271812438965, acc: 0.2230769246816635)
[2024-12-17 01:37:38,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,248][root][INFO] - Training Epoch: 1/2, step 531/7134 completed (loss: 4.183218955993652, acc: 0.22602739930152893)
[2024-12-17 01:37:38,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:38,634][root][INFO] - Training Epoch: 1/2, step 532/7134 completed (loss: 4.331724643707275, acc: 0.22123894095420837)
[2024-12-17 01:37:38,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,030][root][INFO] - Training Epoch: 1/2, step 533/7134 completed (loss: 4.330150127410889, acc: 0.2312925159931183)
[2024-12-17 01:37:39,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,438][root][INFO] - Training Epoch: 1/2, step 534/7134 completed (loss: 4.462424278259277, acc: 0.2215568870306015)
[2024-12-17 01:37:39,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:39,842][root][INFO] - Training Epoch: 1/2, step 535/7134 completed (loss: 4.149703025817871, acc: 0.29927006363868713)
[2024-12-17 01:37:39,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,232][root][INFO] - Training Epoch: 1/2, step 536/7134 completed (loss: 4.357198715209961, acc: 0.23780487477779388)
[2024-12-17 01:37:40,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:40,607][root][INFO] - Training Epoch: 1/2, step 537/7134 completed (loss: 4.395383834838867, acc: 0.2832369804382324)
[2024-12-17 01:37:40,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,040][root][INFO] - Training Epoch: 1/2, step 538/7134 completed (loss: 4.236973762512207, acc: 0.2650602459907532)
[2024-12-17 01:37:41,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,430][root][INFO] - Training Epoch: 1/2, step 539/7134 completed (loss: 4.5117950439453125, acc: 0.3358778655529022)
[2024-12-17 01:37:41,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:41,798][root][INFO] - Training Epoch: 1/2, step 540/7134 completed (loss: 4.676721096038818, acc: 0.22641509771347046)
[2024-12-17 01:37:41,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,205][root][INFO] - Training Epoch: 1/2, step 541/7134 completed (loss: 4.411984920501709, acc: 0.2738095223903656)
[2024-12-17 01:37:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,570][root][INFO] - Training Epoch: 1/2, step 542/7134 completed (loss: 4.832333564758301, acc: 0.23000000417232513)
[2024-12-17 01:37:42,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:42,970][root][INFO] - Training Epoch: 1/2, step 543/7134 completed (loss: 4.05440092086792, acc: 0.31578946113586426)
[2024-12-17 01:37:43,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,415][root][INFO] - Training Epoch: 1/2, step 544/7134 completed (loss: 4.54764461517334, acc: 0.27142858505249023)
[2024-12-17 01:37:43,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:43,854][root][INFO] - Training Epoch: 1/2, step 545/7134 completed (loss: 4.549097537994385, acc: 0.29323309659957886)
[2024-12-17 01:37:43,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,261][root][INFO] - Training Epoch: 1/2, step 546/7134 completed (loss: 4.03052282333374, acc: 0.3055555522441864)
[2024-12-17 01:37:44,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,636][root][INFO] - Training Epoch: 1/2, step 547/7134 completed (loss: 4.139549732208252, acc: 0.3178808093070984)
[2024-12-17 01:37:44,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:44,993][root][INFO] - Training Epoch: 1/2, step 548/7134 completed (loss: 4.2958784103393555, acc: 0.32894736528396606)
[2024-12-17 01:37:45,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,367][root][INFO] - Training Epoch: 1/2, step 549/7134 completed (loss: 4.769645690917969, acc: 0.30000001192092896)
[2024-12-17 01:37:45,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:45,782][root][INFO] - Training Epoch: 1/2, step 550/7134 completed (loss: 4.658917427062988, acc: 0.24409449100494385)
[2024-12-17 01:37:45,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,162][root][INFO] - Training Epoch: 1/2, step 551/7134 completed (loss: 4.385240077972412, acc: 0.3125)
[2024-12-17 01:37:46,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,530][root][INFO] - Training Epoch: 1/2, step 552/7134 completed (loss: 4.195250034332275, acc: 0.35374149680137634)
[2024-12-17 01:37:46,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:46,942][root][INFO] - Training Epoch: 1/2, step 553/7134 completed (loss: 4.363785743713379, acc: 0.35789474844932556)
[2024-12-17 01:37:47,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,422][root][INFO] - Training Epoch: 1/2, step 554/7134 completed (loss: 4.397528171539307, acc: 0.2675159275531769)
[2024-12-17 01:37:47,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:47,822][root][INFO] - Training Epoch: 1/2, step 555/7134 completed (loss: 4.34230375289917, acc: 0.31168830394744873)
[2024-12-17 01:37:47,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,193][root][INFO] - Training Epoch: 1/2, step 556/7134 completed (loss: 3.7151291370391846, acc: 0.375)
[2024-12-17 01:37:48,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,581][root][INFO] - Training Epoch: 1/2, step 557/7134 completed (loss: 4.2870988845825195, acc: 0.3191489279270172)
[2024-12-17 01:37:48,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:48,999][root][INFO] - Training Epoch: 1/2, step 558/7134 completed (loss: 4.279744625091553, acc: 0.30128204822540283)
[2024-12-17 01:37:49,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,392][root][INFO] - Training Epoch: 1/2, step 559/7134 completed (loss: 3.9844560623168945, acc: 0.3087248206138611)
[2024-12-17 01:37:49,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:49,771][root][INFO] - Training Epoch: 1/2, step 560/7134 completed (loss: 4.565986156463623, acc: 0.23577235639095306)
[2024-12-17 01:37:49,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,196][root][INFO] - Training Epoch: 1/2, step 561/7134 completed (loss: 3.8073570728302, acc: 0.34375)
[2024-12-17 01:37:50,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,566][root][INFO] - Training Epoch: 1/2, step 562/7134 completed (loss: 4.056369304656982, acc: 0.3181818127632141)
[2024-12-17 01:37:50,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:50,950][root][INFO] - Training Epoch: 1/2, step 563/7134 completed (loss: 4.865020751953125, acc: 0.25874125957489014)
[2024-12-17 01:37:51,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,344][root][INFO] - Training Epoch: 1/2, step 564/7134 completed (loss: 3.928431510925293, acc: 0.3333333432674408)
[2024-12-17 01:37:51,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:51,732][root][INFO] - Training Epoch: 1/2, step 565/7134 completed (loss: 4.148258686065674, acc: 0.33070865273475647)
[2024-12-17 01:37:51,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,114][root][INFO] - Training Epoch: 1/2, step 566/7134 completed (loss: 4.184144496917725, acc: 0.2612612545490265)
[2024-12-17 01:37:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,561][root][INFO] - Training Epoch: 1/2, step 567/7134 completed (loss: 4.570436000823975, acc: 0.27544909715652466)
[2024-12-17 01:37:52,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:52,993][root][INFO] - Training Epoch: 1/2, step 568/7134 completed (loss: 3.8762435913085938, acc: 0.34736841917037964)
[2024-12-17 01:37:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,426][root][INFO] - Training Epoch: 1/2, step 569/7134 completed (loss: 4.268418788909912, acc: 0.3016759753227234)
[2024-12-17 01:37:53,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:53,829][root][INFO] - Training Epoch: 1/2, step 570/7134 completed (loss: 4.242537498474121, acc: 0.3034825921058655)
[2024-12-17 01:37:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,202][root][INFO] - Training Epoch: 1/2, step 571/7134 completed (loss: 4.316989421844482, acc: 0.2527472674846649)
[2024-12-17 01:37:54,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,569][root][INFO] - Training Epoch: 1/2, step 572/7134 completed (loss: 3.963552951812744, acc: 0.35428571701049805)
[2024-12-17 01:37:54,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:54,940][root][INFO] - Training Epoch: 1/2, step 573/7134 completed (loss: 4.272209167480469, acc: 0.27272728085517883)
[2024-12-17 01:37:55,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,296][root][INFO] - Training Epoch: 1/2, step 574/7134 completed (loss: 4.256601333618164, acc: 0.2840236723423004)
[2024-12-17 01:37:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:55,729][root][INFO] - Training Epoch: 1/2, step 575/7134 completed (loss: 4.161024570465088, acc: 0.28654971718788147)
[2024-12-17 01:37:55,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,099][root][INFO] - Training Epoch: 1/2, step 576/7134 completed (loss: 4.1964945793151855, acc: 0.2688172161579132)
[2024-12-17 01:37:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,445][root][INFO] - Training Epoch: 1/2, step 577/7134 completed (loss: 4.627109527587891, acc: 0.23636363446712494)
[2024-12-17 01:37:56,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:56,856][root][INFO] - Training Epoch: 1/2, step 578/7134 completed (loss: 3.9355592727661133, acc: 0.31343284249305725)
[2024-12-17 01:37:56,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,226][root][INFO] - Training Epoch: 1/2, step 579/7134 completed (loss: 4.015178203582764, acc: 0.3333333432674408)
[2024-12-17 01:37:57,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:57,684][root][INFO] - Training Epoch: 1/2, step 580/7134 completed (loss: 4.6028666496276855, acc: 0.2888889014720917)
[2024-12-17 01:37:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,054][root][INFO] - Training Epoch: 1/2, step 581/7134 completed (loss: 4.223386287689209, acc: 0.2631579041481018)
[2024-12-17 01:37:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,421][root][INFO] - Training Epoch: 1/2, step 582/7134 completed (loss: 4.1417460441589355, acc: 0.29347825050354004)
[2024-12-17 01:37:58,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:58,802][root][INFO] - Training Epoch: 1/2, step 583/7134 completed (loss: 4.40556526184082, acc: 0.257485032081604)
[2024-12-17 01:37:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,185][root][INFO] - Training Epoch: 1/2, step 584/7134 completed (loss: 3.7632579803466797, acc: 0.2950819730758667)
[2024-12-17 01:37:59,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,579][root][INFO] - Training Epoch: 1/2, step 585/7134 completed (loss: 3.9683148860931396, acc: 0.2918919026851654)
[2024-12-17 01:37:59,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:37:59,959][root][INFO] - Training Epoch: 1/2, step 586/7134 completed (loss: 3.850994110107422, acc: 0.35638296604156494)
[2024-12-17 01:38:00,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,359][root][INFO] - Training Epoch: 1/2, step 587/7134 completed (loss: 4.103952884674072, acc: 0.36464089155197144)
[2024-12-17 01:38:00,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:00,733][root][INFO] - Training Epoch: 1/2, step 588/7134 completed (loss: 4.196839809417725, acc: 0.29054054617881775)
[2024-12-17 01:38:00,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,100][root][INFO] - Training Epoch: 1/2, step 589/7134 completed (loss: 4.503952503204346, acc: 0.25766870379447937)
[2024-12-17 01:38:01,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,476][root][INFO] - Training Epoch: 1/2, step 590/7134 completed (loss: 3.9835941791534424, acc: 0.29139071702957153)
[2024-12-17 01:38:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:01,839][root][INFO] - Training Epoch: 1/2, step 591/7134 completed (loss: 3.918896436691284, acc: 0.2542372941970825)
[2024-12-17 01:38:01,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,257][root][INFO] - Training Epoch: 1/2, step 592/7134 completed (loss: 3.7763681411743164, acc: 0.27840909361839294)
[2024-12-17 01:38:02,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:02,623][root][INFO] - Training Epoch: 1/2, step 593/7134 completed (loss: 3.845203399658203, acc: 0.2923976480960846)
[2024-12-17 01:38:02,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,006][root][INFO] - Training Epoch: 1/2, step 594/7134 completed (loss: 3.949737310409546, acc: 0.2634730637073517)
[2024-12-17 01:38:03,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,420][root][INFO] - Training Epoch: 1/2, step 595/7134 completed (loss: 3.7043049335479736, acc: 0.3333333432674408)
[2024-12-17 01:38:03,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:03,831][root][INFO] - Training Epoch: 1/2, step 596/7134 completed (loss: 4.222822189331055, acc: 0.2944444417953491)
[2024-12-17 01:38:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,206][root][INFO] - Training Epoch: 1/2, step 597/7134 completed (loss: 4.042113304138184, acc: 0.2625698447227478)
[2024-12-17 01:38:04,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,595][root][INFO] - Training Epoch: 1/2, step 598/7134 completed (loss: 4.3572893142700195, acc: 0.28260868787765503)
[2024-12-17 01:38:04,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:04,990][root][INFO] - Training Epoch: 1/2, step 599/7134 completed (loss: 3.7925546169281006, acc: 0.3172042965888977)
[2024-12-17 01:38:05,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,432][root][INFO] - Training Epoch: 1/2, step 600/7134 completed (loss: 4.187493801116943, acc: 0.30054643750190735)
[2024-12-17 01:38:05,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:05,891][root][INFO] - Training Epoch: 1/2, step 601/7134 completed (loss: 4.1962809562683105, acc: 0.3125)
[2024-12-17 01:38:06,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,273][root][INFO] - Training Epoch: 1/2, step 602/7134 completed (loss: 3.733652114868164, acc: 0.32972973585128784)
[2024-12-17 01:38:06,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,646][root][INFO] - Training Epoch: 1/2, step 603/7134 completed (loss: 4.25341796875, acc: 0.30158731341362)
[2024-12-17 01:38:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:06,976][root][INFO] - Training Epoch: 1/2, step 604/7134 completed (loss: 3.983515977859497, acc: 0.34545454382896423)
[2024-12-17 01:38:07,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,357][root][INFO] - Training Epoch: 1/2, step 605/7134 completed (loss: 3.9199180603027344, acc: 0.28342247009277344)
[2024-12-17 01:38:07,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:07,740][root][INFO] - Training Epoch: 1/2, step 606/7134 completed (loss: 3.9658424854278564, acc: 0.27000001072883606)
[2024-12-17 01:38:07,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,122][root][INFO] - Training Epoch: 1/2, step 607/7134 completed (loss: 3.7146778106689453, acc: 0.3218390941619873)
[2024-12-17 01:38:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,550][root][INFO] - Training Epoch: 1/2, step 608/7134 completed (loss: 4.3214311599731445, acc: 0.2702702581882477)
[2024-12-17 01:38:08,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:08,987][root][INFO] - Training Epoch: 1/2, step 609/7134 completed (loss: 3.925494432449341, acc: 0.3589743673801422)
[2024-12-17 01:38:09,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,398][root][INFO] - Training Epoch: 1/2, step 610/7134 completed (loss: 3.972459077835083, acc: 0.29556649923324585)
[2024-12-17 01:38:09,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:09,821][root][INFO] - Training Epoch: 1/2, step 611/7134 completed (loss: 4.066382884979248, acc: 0.3446327745914459)
[2024-12-17 01:38:10,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,280][root][INFO] - Training Epoch: 1/2, step 612/7134 completed (loss: 3.836387872695923, acc: 0.3695652186870575)
[2024-12-17 01:38:10,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:10,712][root][INFO] - Training Epoch: 1/2, step 613/7134 completed (loss: 4.10748815536499, acc: 0.3232323229312897)
[2024-12-17 01:38:10,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,171][root][INFO] - Training Epoch: 1/2, step 614/7134 completed (loss: 4.044489860534668, acc: 0.260869562625885)
[2024-12-17 01:38:11,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:11,611][root][INFO] - Training Epoch: 1/2, step 615/7134 completed (loss: 3.509918212890625, acc: 0.34736841917037964)
[2024-12-17 01:38:11,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,034][root][INFO] - Training Epoch: 1/2, step 616/7134 completed (loss: 4.042522430419922, acc: 0.31336405873298645)
[2024-12-17 01:38:12,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,432][root][INFO] - Training Epoch: 1/2, step 617/7134 completed (loss: 3.8472068309783936, acc: 0.31100478768348694)
[2024-12-17 01:38:12,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:12,847][root][INFO] - Training Epoch: 1/2, step 618/7134 completed (loss: 3.906036138534546, acc: 0.28877004981040955)
[2024-12-17 01:38:13,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,275][root][INFO] - Training Epoch: 1/2, step 619/7134 completed (loss: 4.443638324737549, acc: 0.2950819730758667)
[2024-12-17 01:38:13,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:13,675][root][INFO] - Training Epoch: 1/2, step 620/7134 completed (loss: 3.8997747898101807, acc: 0.30136987566947937)
[2024-12-17 01:38:13,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,070][root][INFO] - Training Epoch: 1/2, step 621/7134 completed (loss: 4.03102445602417, acc: 0.36000001430511475)
[2024-12-17 01:38:14,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,456][root][INFO] - Training Epoch: 1/2, step 622/7134 completed (loss: 4.0766096115112305, acc: 0.28947368264198303)
[2024-12-17 01:38:14,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:14,856][root][INFO] - Training Epoch: 1/2, step 623/7134 completed (loss: 3.791849374771118, acc: 0.316546767950058)
[2024-12-17 01:38:14,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,229][root][INFO] - Training Epoch: 1/2, step 624/7134 completed (loss: 4.020310878753662, acc: 0.32846716046333313)
[2024-12-17 01:38:15,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:15,609][root][INFO] - Training Epoch: 1/2, step 625/7134 completed (loss: 3.7679429054260254, acc: 0.3187499940395355)
[2024-12-17 01:38:15,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,003][root][INFO] - Training Epoch: 1/2, step 626/7134 completed (loss: 4.059239864349365, acc: 0.30399999022483826)
[2024-12-17 01:38:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,394][root][INFO] - Training Epoch: 1/2, step 627/7134 completed (loss: 3.8794286251068115, acc: 0.2789115607738495)
[2024-12-17 01:38:16,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:16,765][root][INFO] - Training Epoch: 1/2, step 628/7134 completed (loss: 4.1326704025268555, acc: 0.2448979616165161)
[2024-12-17 01:38:16,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,150][root][INFO] - Training Epoch: 1/2, step 629/7134 completed (loss: 3.914687156677246, acc: 0.3546099364757538)
[2024-12-17 01:38:17,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,613][root][INFO] - Training Epoch: 1/2, step 630/7134 completed (loss: 4.115828037261963, acc: 0.31847134232521057)
[2024-12-17 01:38:17,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:17,984][root][INFO] - Training Epoch: 1/2, step 631/7134 completed (loss: 4.138552665710449, acc: 0.23376622796058655)
[2024-12-17 01:38:18,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,381][root][INFO] - Training Epoch: 1/2, step 632/7134 completed (loss: 3.91841459274292, acc: 0.2957746386528015)
[2024-12-17 01:38:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:18,767][root][INFO] - Training Epoch: 1/2, step 633/7134 completed (loss: 4.208612442016602, acc: 0.26875001192092896)
[2024-12-17 01:38:18,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,184][root][INFO] - Training Epoch: 1/2, step 634/7134 completed (loss: 3.720235824584961, acc: 0.3311688303947449)
[2024-12-17 01:38:19,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,558][root][INFO] - Training Epoch: 1/2, step 635/7134 completed (loss: 3.9348394870758057, acc: 0.33766233921051025)
[2024-12-17 01:38:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:19,938][root][INFO] - Training Epoch: 1/2, step 636/7134 completed (loss: 4.065950393676758, acc: 0.28143712878227234)
[2024-12-17 01:38:20,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,311][root][INFO] - Training Epoch: 1/2, step 637/7134 completed (loss: 3.731884002685547, acc: 0.30215826630592346)
[2024-12-17 01:38:20,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:20,674][root][INFO] - Training Epoch: 1/2, step 638/7134 completed (loss: 4.199486255645752, acc: 0.2751677930355072)
[2024-12-17 01:38:20,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,072][root][INFO] - Training Epoch: 1/2, step 639/7134 completed (loss: 3.835217237472534, acc: 0.3571428656578064)
[2024-12-17 01:38:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,433][root][INFO] - Training Epoch: 1/2, step 640/7134 completed (loss: 4.265960216522217, acc: 0.239130437374115)
[2024-12-17 01:38:21,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:21,819][root][INFO] - Training Epoch: 1/2, step 641/7134 completed (loss: 3.995980978012085, acc: 0.28985506296157837)
[2024-12-17 01:38:21,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,230][root][INFO] - Training Epoch: 1/2, step 642/7134 completed (loss: 3.9654362201690674, acc: 0.31617647409439087)
[2024-12-17 01:38:22,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:22,609][root][INFO] - Training Epoch: 1/2, step 643/7134 completed (loss: 3.5031137466430664, acc: 0.33707866072654724)
[2024-12-17 01:38:22,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,022][root][INFO] - Training Epoch: 1/2, step 644/7134 completed (loss: 3.857919931411743, acc: 0.2734375)
[2024-12-17 01:38:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,389][root][INFO] - Training Epoch: 1/2, step 645/7134 completed (loss: 3.757918119430542, acc: 0.3379310369491577)
[2024-12-17 01:38:23,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:23,742][root][INFO] - Training Epoch: 1/2, step 646/7134 completed (loss: 3.8017585277557373, acc: 0.24683544039726257)
[2024-12-17 01:38:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,142][root][INFO] - Training Epoch: 1/2, step 647/7134 completed (loss: 3.934583902359009, acc: 0.3037036955356598)
[2024-12-17 01:38:24,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,536][root][INFO] - Training Epoch: 1/2, step 648/7134 completed (loss: 4.935628414154053, acc: 0.23846153914928436)
[2024-12-17 01:38:24,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:24,956][root][INFO] - Training Epoch: 1/2, step 649/7134 completed (loss: 4.615485668182373, acc: 0.21621622145175934)
[2024-12-17 01:38:25,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,374][root][INFO] - Training Epoch: 1/2, step 650/7134 completed (loss: 5.006102561950684, acc: 0.21232876181602478)
[2024-12-17 01:38:25,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:25,751][root][INFO] - Training Epoch: 1/2, step 651/7134 completed (loss: 4.751861572265625, acc: 0.24025973677635193)
[2024-12-17 01:38:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,120][root][INFO] - Training Epoch: 1/2, step 652/7134 completed (loss: 4.759795188903809, acc: 0.23239436745643616)
[2024-12-17 01:38:26,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,504][root][INFO] - Training Epoch: 1/2, step 653/7134 completed (loss: 4.265217304229736, acc: 0.2545454502105713)
[2024-12-17 01:38:26,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:26,879][root][INFO] - Training Epoch: 1/2, step 654/7134 completed (loss: 3.897495746612549, acc: 0.35338345170021057)
[2024-12-17 01:38:27,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,280][root][INFO] - Training Epoch: 1/2, step 655/7134 completed (loss: 4.940278053283691, acc: 0.18965516984462738)
[2024-12-17 01:38:27,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:27,689][root][INFO] - Training Epoch: 1/2, step 656/7134 completed (loss: 4.554733753204346, acc: 0.2525252401828766)
[2024-12-17 01:38:27,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,074][root][INFO] - Training Epoch: 1/2, step 657/7134 completed (loss: 5.066210746765137, acc: 0.17605634033679962)
[2024-12-17 01:38:28,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,447][root][INFO] - Training Epoch: 1/2, step 658/7134 completed (loss: 3.942049741744995, acc: 0.3050847351551056)
[2024-12-17 01:38:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:28,818][root][INFO] - Training Epoch: 1/2, step 659/7134 completed (loss: 3.606311082839966, acc: 0.269461065530777)
[2024-12-17 01:38:28,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,195][root][INFO] - Training Epoch: 1/2, step 660/7134 completed (loss: 4.016822814941406, acc: 0.2705882489681244)
[2024-12-17 01:38:29,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,585][root][INFO] - Training Epoch: 1/2, step 661/7134 completed (loss: 3.6656851768493652, acc: 0.3093220293521881)
[2024-12-17 01:38:29,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:29,986][root][INFO] - Training Epoch: 1/2, step 662/7134 completed (loss: 3.8222343921661377, acc: 0.2888889014720917)
[2024-12-17 01:38:30,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,382][root][INFO] - Training Epoch: 1/2, step 663/7134 completed (loss: 4.349319934844971, acc: 0.2330097109079361)
[2024-12-17 01:38:30,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:30,794][root][INFO] - Training Epoch: 1/2, step 664/7134 completed (loss: 4.419820308685303, acc: 0.2657342553138733)
[2024-12-17 01:38:30,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,157][root][INFO] - Training Epoch: 1/2, step 665/7134 completed (loss: 4.016811847686768, acc: 0.2950819730758667)
[2024-12-17 01:38:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,548][root][INFO] - Training Epoch: 1/2, step 666/7134 completed (loss: 4.459627628326416, acc: 0.22285714745521545)
[2024-12-17 01:38:31,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:31,954][root][INFO] - Training Epoch: 1/2, step 667/7134 completed (loss: 4.411545276641846, acc: 0.21556885540485382)
[2024-12-17 01:38:32,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,320][root][INFO] - Training Epoch: 1/2, step 668/7134 completed (loss: 3.9106969833374023, acc: 0.284153014421463)
[2024-12-17 01:38:32,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:32,708][root][INFO] - Training Epoch: 1/2, step 669/7134 completed (loss: 3.820063591003418, acc: 0.29608938097953796)
[2024-12-17 01:38:32,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,158][root][INFO] - Training Epoch: 1/2, step 670/7134 completed (loss: 3.975341320037842, acc: 0.31963470578193665)
[2024-12-17 01:38:33,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,564][root][INFO] - Training Epoch: 1/2, step 671/7134 completed (loss: 4.14395809173584, acc: 0.29411765933036804)
[2024-12-17 01:38:33,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:33,964][root][INFO] - Training Epoch: 1/2, step 672/7134 completed (loss: 4.008888244628906, acc: 0.23749999701976776)
[2024-12-17 01:38:34,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,364][root][INFO] - Training Epoch: 1/2, step 673/7134 completed (loss: 4.245079040527344, acc: 0.2189054787158966)
[2024-12-17 01:38:34,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:34,746][root][INFO] - Training Epoch: 1/2, step 674/7134 completed (loss: 3.4881739616394043, acc: 0.2804878056049347)
[2024-12-17 01:38:34,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,148][root][INFO] - Training Epoch: 1/2, step 675/7134 completed (loss: 3.59201717376709, acc: 0.3480663001537323)
[2024-12-17 01:38:35,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,525][root][INFO] - Training Epoch: 1/2, step 676/7134 completed (loss: 4.085940361022949, acc: 0.2663043439388275)
[2024-12-17 01:38:35,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:35,923][root][INFO] - Training Epoch: 1/2, step 677/7134 completed (loss: 3.6120948791503906, acc: 0.30687829852104187)
[2024-12-17 01:38:36,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,320][root][INFO] - Training Epoch: 1/2, step 678/7134 completed (loss: 3.7760560512542725, acc: 0.24390244483947754)
[2024-12-17 01:38:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:36,679][root][INFO] - Training Epoch: 1/2, step 679/7134 completed (loss: 3.883357286453247, acc: 0.3233082592487335)
[2024-12-17 01:38:36,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,140][root][INFO] - Training Epoch: 1/2, step 680/7134 completed (loss: 3.780000686645508, acc: 0.32663315534591675)
[2024-12-17 01:38:37,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:37,586][root][INFO] - Training Epoch: 1/2, step 681/7134 completed (loss: 3.473454236984253, acc: 0.35789474844932556)
[2024-12-17 01:38:37,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,028][root][INFO] - Training Epoch: 1/2, step 682/7134 completed (loss: 3.531522035598755, acc: 0.3333333432674408)
[2024-12-17 01:38:38,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,436][root][INFO] - Training Epoch: 1/2, step 683/7134 completed (loss: 3.7933828830718994, acc: 0.2918919026851654)
[2024-12-17 01:38:38,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:38,884][root][INFO] - Training Epoch: 1/2, step 684/7134 completed (loss: 3.6880486011505127, acc: 0.3888888955116272)
[2024-12-17 01:38:38,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,268][root][INFO] - Training Epoch: 1/2, step 685/7134 completed (loss: 3.931933641433716, acc: 0.3065326511859894)
[2024-12-17 01:38:39,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:39,643][root][INFO] - Training Epoch: 1/2, step 686/7134 completed (loss: 3.4622678756713867, acc: 0.3169398903846741)
[2024-12-17 01:38:39,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,021][root][INFO] - Training Epoch: 1/2, step 687/7134 completed (loss: 4.117776870727539, acc: 0.31496062874794006)
[2024-12-17 01:38:40,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,441][root][INFO] - Training Epoch: 1/2, step 688/7134 completed (loss: 3.471064329147339, acc: 0.31012657284736633)
[2024-12-17 01:38:40,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:40,844][root][INFO] - Training Epoch: 1/2, step 689/7134 completed (loss: 4.167102336883545, acc: 0.29629629850387573)
[2024-12-17 01:38:40,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,206][root][INFO] - Training Epoch: 1/2, step 690/7134 completed (loss: 3.643331527709961, acc: 0.31612902879714966)
[2024-12-17 01:38:41,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,592][root][INFO] - Training Epoch: 1/2, step 691/7134 completed (loss: 4.8363142013549805, acc: 0.2532467544078827)
[2024-12-17 01:38:41,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:41,948][root][INFO] - Training Epoch: 1/2, step 692/7134 completed (loss: 4.0329179763793945, acc: 0.2690355181694031)
[2024-12-17 01:38:42,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,318][root][INFO] - Training Epoch: 1/2, step 693/7134 completed (loss: 4.241369724273682, acc: 0.26950353384017944)
[2024-12-17 01:38:42,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:42,676][root][INFO] - Training Epoch: 1/2, step 694/7134 completed (loss: 4.492635250091553, acc: 0.24242424964904785)
[2024-12-17 01:38:42,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,072][root][INFO] - Training Epoch: 1/2, step 695/7134 completed (loss: 4.769433975219727, acc: 0.2761194109916687)
[2024-12-17 01:38:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,447][root][INFO] - Training Epoch: 1/2, step 696/7134 completed (loss: 4.3582353591918945, acc: 0.3207547068595886)
[2024-12-17 01:38:43,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:43,826][root][INFO] - Training Epoch: 1/2, step 697/7134 completed (loss: 3.765503168106079, acc: 0.3586956560611725)
[2024-12-17 01:38:43,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,210][root][INFO] - Training Epoch: 1/2, step 698/7134 completed (loss: 4.140235900878906, acc: 0.24242424964904785)
[2024-12-17 01:38:44,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:44,620][root][INFO] - Training Epoch: 1/2, step 699/7134 completed (loss: 4.300955772399902, acc: 0.27397260069847107)
[2024-12-17 01:38:44,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,008][root][INFO] - Training Epoch: 1/2, step 700/7134 completed (loss: 4.181638240814209, acc: 0.31200000643730164)
[2024-12-17 01:38:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,351][root][INFO] - Training Epoch: 1/2, step 701/7134 completed (loss: 4.766302585601807, acc: 0.260869562625885)
[2024-12-17 01:38:45,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:45,744][root][INFO] - Training Epoch: 1/2, step 702/7134 completed (loss: 4.3958563804626465, acc: 0.2781457006931305)
[2024-12-17 01:38:45,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,088][root][INFO] - Training Epoch: 1/2, step 703/7134 completed (loss: 4.705713748931885, acc: 0.27702704071998596)
[2024-12-17 01:38:46,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,451][root][INFO] - Training Epoch: 1/2, step 704/7134 completed (loss: 4.124386310577393, acc: 0.2922077775001526)
[2024-12-17 01:38:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:46,842][root][INFO] - Training Epoch: 1/2, step 705/7134 completed (loss: 3.823928117752075, acc: 0.35321101546287537)
[2024-12-17 01:38:46,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,214][root][INFO] - Training Epoch: 1/2, step 706/7134 completed (loss: 3.8204028606414795, acc: 0.3066037595272064)
[2024-12-17 01:38:47,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,564][root][INFO] - Training Epoch: 1/2, step 707/7134 completed (loss: 4.0998148918151855, acc: 0.26237624883651733)
[2024-12-17 01:38:47,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:47,917][root][INFO] - Training Epoch: 1/2, step 708/7134 completed (loss: 4.276854038238525, acc: 0.26404494047164917)
[2024-12-17 01:38:48,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,280][root][INFO] - Training Epoch: 1/2, step 709/7134 completed (loss: 3.7574009895324707, acc: 0.3028571307659149)
[2024-12-17 01:38:48,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:48,667][root][INFO] - Training Epoch: 1/2, step 710/7134 completed (loss: 3.9905738830566406, acc: 0.2864583432674408)
[2024-12-17 01:38:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,007][root][INFO] - Training Epoch: 1/2, step 711/7134 completed (loss: 3.972747564315796, acc: 0.2647058963775635)
[2024-12-17 01:38:49,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,395][root][INFO] - Training Epoch: 1/2, step 712/7134 completed (loss: 3.708082914352417, acc: 0.3229166567325592)
[2024-12-17 01:38:49,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:49,786][root][INFO] - Training Epoch: 1/2, step 713/7134 completed (loss: 3.7613329887390137, acc: 0.28140702843666077)
[2024-12-17 01:38:49,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,182][root][INFO] - Training Epoch: 1/2, step 714/7134 completed (loss: 4.278130054473877, acc: 0.17000000178813934)
[2024-12-17 01:38:50,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:50,614][root][INFO] - Training Epoch: 1/2, step 715/7134 completed (loss: 3.643432855606079, acc: 0.27173912525177)
[2024-12-17 01:38:50,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,035][root][INFO] - Training Epoch: 1/2, step 716/7134 completed (loss: 3.4611427783966064, acc: 0.343137264251709)
[2024-12-17 01:38:51,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,437][root][INFO] - Training Epoch: 1/2, step 717/7134 completed (loss: 3.7866344451904297, acc: 0.31550800800323486)
[2024-12-17 01:38:51,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:51,835][root][INFO] - Training Epoch: 1/2, step 718/7134 completed (loss: 3.918325662612915, acc: 0.24867725372314453)
[2024-12-17 01:38:51,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,218][root][INFO] - Training Epoch: 1/2, step 719/7134 completed (loss: 3.3389453887939453, acc: 0.27659574151039124)
[2024-12-17 01:38:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:52,640][root][INFO] - Training Epoch: 1/2, step 720/7134 completed (loss: 3.57253098487854, acc: 0.29729729890823364)
[2024-12-17 01:38:52,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,034][root][INFO] - Training Epoch: 1/2, step 721/7134 completed (loss: 3.414243698120117, acc: 0.28947368264198303)
[2024-12-17 01:38:53,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,480][root][INFO] - Training Epoch: 1/2, step 722/7134 completed (loss: 3.7396106719970703, acc: 0.3232323229312897)
[2024-12-17 01:38:53,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:53,858][root][INFO] - Training Epoch: 1/2, step 723/7134 completed (loss: 3.592912197113037, acc: 0.31521740555763245)
[2024-12-17 01:38:54,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,286][root][INFO] - Training Epoch: 1/2, step 724/7134 completed (loss: 3.979706048965454, acc: 0.2578616440296173)
[2024-12-17 01:38:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:54,671][root][INFO] - Training Epoch: 1/2, step 725/7134 completed (loss: 3.287811279296875, acc: 0.3452380895614624)
[2024-12-17 01:38:54,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,058][root][INFO] - Training Epoch: 1/2, step 726/7134 completed (loss: 3.035723924636841, acc: 0.3296089470386505)
[2024-12-17 01:38:55,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,446][root][INFO] - Training Epoch: 1/2, step 727/7134 completed (loss: 3.399970054626465, acc: 0.28901734948158264)
[2024-12-17 01:38:55,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:55,821][root][INFO] - Training Epoch: 1/2, step 728/7134 completed (loss: 3.5945801734924316, acc: 0.3257142901420593)
[2024-12-17 01:38:55,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,226][root][INFO] - Training Epoch: 1/2, step 729/7134 completed (loss: 3.2956326007843018, acc: 0.3417721390724182)
[2024-12-17 01:38:56,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:56,643][root][INFO] - Training Epoch: 1/2, step 730/7134 completed (loss: 3.0473737716674805, acc: 0.34574466943740845)
[2024-12-17 01:38:56,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,014][root][INFO] - Training Epoch: 1/2, step 731/7134 completed (loss: 3.0969831943511963, acc: 0.3502824902534485)
[2024-12-17 01:38:57,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,394][root][INFO] - Training Epoch: 1/2, step 732/7134 completed (loss: 4.002301216125488, acc: 0.3196721374988556)
[2024-12-17 01:38:57,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:57,793][root][INFO] - Training Epoch: 1/2, step 733/7134 completed (loss: 4.335860252380371, acc: 0.2461538463830948)
[2024-12-17 01:38:57,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,172][root][INFO] - Training Epoch: 1/2, step 734/7134 completed (loss: 4.307946681976318, acc: 0.33870968222618103)
[2024-12-17 01:38:58,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,544][root][INFO] - Training Epoch: 1/2, step 735/7134 completed (loss: 4.066720485687256, acc: 0.28169015049934387)
[2024-12-17 01:38:58,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:58,894][root][INFO] - Training Epoch: 1/2, step 736/7134 completed (loss: 4.278907775878906, acc: 0.2871287167072296)
[2024-12-17 01:38:59,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,274][root][INFO] - Training Epoch: 1/2, step 737/7134 completed (loss: 3.8842782974243164, acc: 0.3050847351551056)
[2024-12-17 01:38:59,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:38:59,644][root][INFO] - Training Epoch: 1/2, step 738/7134 completed (loss: 4.712684631347656, acc: 0.18867924809455872)
[2024-12-17 01:38:59,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,071][root][INFO] - Training Epoch: 1/2, step 739/7134 completed (loss: 4.482000350952148, acc: 0.21739129722118378)
[2024-12-17 01:39:00,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,422][root][INFO] - Training Epoch: 1/2, step 740/7134 completed (loss: 3.806981086730957, acc: 0.3983739912509918)
[2024-12-17 01:39:00,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:00,803][root][INFO] - Training Epoch: 1/2, step 741/7134 completed (loss: 3.8729798793792725, acc: 0.28148147463798523)
[2024-12-17 01:39:00,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,139][root][INFO] - Training Epoch: 1/2, step 742/7134 completed (loss: 4.186313152313232, acc: 0.27368420362472534)
[2024-12-17 01:39:01,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,550][root][INFO] - Training Epoch: 1/2, step 743/7134 completed (loss: 3.8604354858398438, acc: 0.3333333432674408)
[2024-12-17 01:39:01,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:01,926][root][INFO] - Training Epoch: 1/2, step 744/7134 completed (loss: 4.0509562492370605, acc: 0.2800000011920929)
[2024-12-17 01:39:02,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,328][root][INFO] - Training Epoch: 1/2, step 745/7134 completed (loss: 3.4783525466918945, acc: 0.29411765933036804)
[2024-12-17 01:39:02,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:02,762][root][INFO] - Training Epoch: 1/2, step 746/7134 completed (loss: 4.231431007385254, acc: 0.30534350872039795)
[2024-12-17 01:39:02,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,138][root][INFO] - Training Epoch: 1/2, step 747/7134 completed (loss: 4.004611968994141, acc: 0.34645670652389526)
[2024-12-17 01:39:03,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,524][root][INFO] - Training Epoch: 1/2, step 748/7134 completed (loss: 3.8303701877593994, acc: 0.3805970251560211)
[2024-12-17 01:39:03,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:03,887][root][INFO] - Training Epoch: 1/2, step 749/7134 completed (loss: 3.5861668586730957, acc: 0.3214285671710968)
[2024-12-17 01:39:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,283][root][INFO] - Training Epoch: 1/2, step 750/7134 completed (loss: 4.189870834350586, acc: 0.3057851195335388)
[2024-12-17 01:39:04,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,631][root][INFO] - Training Epoch: 1/2, step 751/7134 completed (loss: 4.552929401397705, acc: 0.2800000011920929)
[2024-12-17 01:39:04,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:04,994][root][INFO] - Training Epoch: 1/2, step 752/7134 completed (loss: 4.355292797088623, acc: 0.31081080436706543)
[2024-12-17 01:39:05,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,358][root][INFO] - Training Epoch: 1/2, step 753/7134 completed (loss: 4.040800094604492, acc: 0.296875)
[2024-12-17 01:39:05,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:05,773][root][INFO] - Training Epoch: 1/2, step 754/7134 completed (loss: 3.4147887229919434, acc: 0.4420289993286133)
[2024-12-17 01:39:05,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,235][root][INFO] - Training Epoch: 1/2, step 755/7134 completed (loss: 4.10526180267334, acc: 0.2800000011920929)
[2024-12-17 01:39:06,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,610][root][INFO] - Training Epoch: 1/2, step 756/7134 completed (loss: 4.318984031677246, acc: 0.2589285671710968)
[2024-12-17 01:39:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:06,975][root][INFO] - Training Epoch: 1/2, step 757/7134 completed (loss: 4.351525783538818, acc: 0.25)
[2024-12-17 01:39:07,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,348][root][INFO] - Training Epoch: 1/2, step 758/7134 completed (loss: 3.74289870262146, acc: 0.29729729890823364)
[2024-12-17 01:39:07,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:07,677][root][INFO] - Training Epoch: 1/2, step 759/7134 completed (loss: 4.285097599029541, acc: 0.22522522509098053)
[2024-12-17 01:39:07,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,023][root][INFO] - Training Epoch: 1/2, step 760/7134 completed (loss: 3.8615529537200928, acc: 0.35606059432029724)
[2024-12-17 01:39:08,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,383][root][INFO] - Training Epoch: 1/2, step 761/7134 completed (loss: 3.745055675506592, acc: 0.2934131622314453)
[2024-12-17 01:39:08,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:08,727][root][INFO] - Training Epoch: 1/2, step 762/7134 completed (loss: 4.309128284454346, acc: 0.26811593770980835)
[2024-12-17 01:39:08,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,056][root][INFO] - Training Epoch: 1/2, step 763/7134 completed (loss: 4.100331783294678, acc: 0.30263158679008484)
[2024-12-17 01:39:09,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,397][root][INFO] - Training Epoch: 1/2, step 764/7134 completed (loss: 4.0689921379089355, acc: 0.24852071702480316)
[2024-12-17 01:39:09,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:09,773][root][INFO] - Training Epoch: 1/2, step 765/7134 completed (loss: 3.785097122192383, acc: 0.30817610025405884)
[2024-12-17 01:39:09,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,136][root][INFO] - Training Epoch: 1/2, step 766/7134 completed (loss: 3.716672897338867, acc: 0.2750000059604645)
[2024-12-17 01:39:10,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,477][root][INFO] - Training Epoch: 1/2, step 767/7134 completed (loss: 3.420633316040039, acc: 0.3452380895614624)
[2024-12-17 01:39:10,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:10,826][root][INFO] - Training Epoch: 1/2, step 768/7134 completed (loss: 3.566372871398926, acc: 0.30054643750190735)
[2024-12-17 01:39:10,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,181][root][INFO] - Training Epoch: 1/2, step 769/7134 completed (loss: 3.9550490379333496, acc: 0.21739129722118378)
[2024-12-17 01:39:11,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,519][root][INFO] - Training Epoch: 1/2, step 770/7134 completed (loss: 3.730391025543213, acc: 0.34567901492118835)
[2024-12-17 01:39:11,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:11,845][root][INFO] - Training Epoch: 1/2, step 771/7134 completed (loss: 3.720050811767578, acc: 0.32116788625717163)
[2024-12-17 01:39:11,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,180][root][INFO] - Training Epoch: 1/2, step 772/7134 completed (loss: 3.6285104751586914, acc: 0.30612245202064514)
[2024-12-17 01:39:12,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,552][root][INFO] - Training Epoch: 1/2, step 773/7134 completed (loss: 3.6366355419158936, acc: 0.31578946113586426)
[2024-12-17 01:39:12,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:12,924][root][INFO] - Training Epoch: 1/2, step 774/7134 completed (loss: 4.286452770233154, acc: 0.23943662643432617)
[2024-12-17 01:39:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,357][root][INFO] - Training Epoch: 1/2, step 775/7134 completed (loss: 3.5927035808563232, acc: 0.28723403811454773)
[2024-12-17 01:39:13,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:13,723][root][INFO] - Training Epoch: 1/2, step 776/7134 completed (loss: 3.555654764175415, acc: 0.35031846165657043)
[2024-12-17 01:39:13,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,088][root][INFO] - Training Epoch: 1/2, step 777/7134 completed (loss: 3.4791507720947266, acc: 0.35333332419395447)
[2024-12-17 01:39:14,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,451][root][INFO] - Training Epoch: 1/2, step 778/7134 completed (loss: 4.021183967590332, acc: 0.29559749364852905)
[2024-12-17 01:39:14,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:14,795][root][INFO] - Training Epoch: 1/2, step 779/7134 completed (loss: 3.6209070682525635, acc: 0.3274853825569153)
[2024-12-17 01:39:14,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,133][root][INFO] - Training Epoch: 1/2, step 780/7134 completed (loss: 3.976578950881958, acc: 0.318918913602829)
[2024-12-17 01:39:15,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,527][root][INFO] - Training Epoch: 1/2, step 781/7134 completed (loss: 3.7937071323394775, acc: 0.29411765933036804)
[2024-12-17 01:39:15,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:15,918][root][INFO] - Training Epoch: 1/2, step 782/7134 completed (loss: 4.1344380378723145, acc: 0.27848100662231445)
[2024-12-17 01:39:16,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,310][root][INFO] - Training Epoch: 1/2, step 783/7134 completed (loss: 3.686596155166626, acc: 0.29906541109085083)
[2024-12-17 01:39:16,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:16,684][root][INFO] - Training Epoch: 1/2, step 784/7134 completed (loss: 3.3258554935455322, acc: 0.3283582031726837)
[2024-12-17 01:39:16,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,103][root][INFO] - Training Epoch: 1/2, step 785/7134 completed (loss: 4.124133110046387, acc: 0.2666666805744171)
[2024-12-17 01:39:17,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,559][root][INFO] - Training Epoch: 1/2, step 786/7134 completed (loss: 3.9638545513153076, acc: 0.3208955228328705)
[2024-12-17 01:39:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:17,957][root][INFO] - Training Epoch: 1/2, step 787/7134 completed (loss: 3.713250160217285, acc: 0.27067670226097107)
[2024-12-17 01:39:18,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,335][root][INFO] - Training Epoch: 1/2, step 788/7134 completed (loss: 3.718430280685425, acc: 0.3072625696659088)
[2024-12-17 01:39:18,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:18,770][root][INFO] - Training Epoch: 1/2, step 789/7134 completed (loss: 4.386438369750977, acc: 0.18589743971824646)
[2024-12-17 01:39:18,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,161][root][INFO] - Training Epoch: 1/2, step 790/7134 completed (loss: 4.517592430114746, acc: 0.18243242800235748)
[2024-12-17 01:39:19,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,617][root][INFO] - Training Epoch: 1/2, step 791/7134 completed (loss: 4.16746711730957, acc: 0.24390244483947754)
[2024-12-17 01:39:19,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:19,973][root][INFO] - Training Epoch: 1/2, step 792/7134 completed (loss: 4.099695205688477, acc: 0.32278481125831604)
[2024-12-17 01:39:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,334][root][INFO] - Training Epoch: 1/2, step 793/7134 completed (loss: 4.310603618621826, acc: 0.21875)
[2024-12-17 01:39:20,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:20,683][root][INFO] - Training Epoch: 1/2, step 794/7134 completed (loss: 4.196126937866211, acc: 0.27586206793785095)
[2024-12-17 01:39:20,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,118][root][INFO] - Training Epoch: 1/2, step 795/7134 completed (loss: 4.218096733093262, acc: 0.2531645596027374)
[2024-12-17 01:39:21,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,533][root][INFO] - Training Epoch: 1/2, step 796/7134 completed (loss: 4.248457431793213, acc: 0.2666666805744171)
[2024-12-17 01:39:21,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:21,910][root][INFO] - Training Epoch: 1/2, step 797/7134 completed (loss: 4.401209354400635, acc: 0.22834645211696625)
[2024-12-17 01:39:22,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,226][root][INFO] - Training Epoch: 1/2, step 798/7134 completed (loss: 4.290406703948975, acc: 0.24242424964904785)
[2024-12-17 01:39:22,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,603][root][INFO] - Training Epoch: 1/2, step 799/7134 completed (loss: 4.352110862731934, acc: 0.28099173307418823)
[2024-12-17 01:39:22,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:22,946][root][INFO] - Training Epoch: 1/2, step 800/7134 completed (loss: 3.8738417625427246, acc: 0.29629629850387573)
[2024-12-17 01:39:23,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,321][root][INFO] - Training Epoch: 1/2, step 801/7134 completed (loss: 4.567062854766846, acc: 0.23225806653499603)
[2024-12-17 01:39:23,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:23,672][root][INFO] - Training Epoch: 1/2, step 802/7134 completed (loss: 4.173707008361816, acc: 0.283687949180603)
[2024-12-17 01:39:23,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,014][root][INFO] - Training Epoch: 1/2, step 803/7134 completed (loss: 4.082002639770508, acc: 0.2028985470533371)
[2024-12-17 01:39:24,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,415][root][INFO] - Training Epoch: 1/2, step 804/7134 completed (loss: 3.9937984943389893, acc: 0.2868216931819916)
[2024-12-17 01:39:24,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:24,770][root][INFO] - Training Epoch: 1/2, step 805/7134 completed (loss: 4.333444595336914, acc: 0.27272728085517883)
[2024-12-17 01:39:24,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,118][root][INFO] - Training Epoch: 1/2, step 806/7134 completed (loss: 3.5859954357147217, acc: 0.31481480598449707)
[2024-12-17 01:39:25,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,504][root][INFO] - Training Epoch: 1/2, step 807/7134 completed (loss: 3.9137511253356934, acc: 0.30000001192092896)
[2024-12-17 01:39:25,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:25,867][root][INFO] - Training Epoch: 1/2, step 808/7134 completed (loss: 3.8787407875061035, acc: 0.2690355181694031)
[2024-12-17 01:39:25,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,237][root][INFO] - Training Epoch: 1/2, step 809/7134 completed (loss: 3.945282459259033, acc: 0.2666666805744171)
[2024-12-17 01:39:26,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,584][root][INFO] - Training Epoch: 1/2, step 810/7134 completed (loss: 3.736311912536621, acc: 0.25925925374031067)
[2024-12-17 01:39:26,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:26,943][root][INFO] - Training Epoch: 1/2, step 811/7134 completed (loss: 3.8381738662719727, acc: 0.3448275923728943)
[2024-12-17 01:39:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,310][root][INFO] - Training Epoch: 1/2, step 812/7134 completed (loss: 3.8903353214263916, acc: 0.33157894015312195)
[2024-12-17 01:39:27,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:27,681][root][INFO] - Training Epoch: 1/2, step 813/7134 completed (loss: 3.7065911293029785, acc: 0.30588236451148987)
[2024-12-17 01:39:27,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,114][root][INFO] - Training Epoch: 1/2, step 814/7134 completed (loss: 3.885211229324341, acc: 0.2881355881690979)
[2024-12-17 01:39:28,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,463][root][INFO] - Training Epoch: 1/2, step 815/7134 completed (loss: 3.880855083465576, acc: 0.3205128312110901)
[2024-12-17 01:39:28,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:28,810][root][INFO] - Training Epoch: 1/2, step 816/7134 completed (loss: 4.230027198791504, acc: 0.20567375421524048)
[2024-12-17 01:39:28,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,197][root][INFO] - Training Epoch: 1/2, step 817/7134 completed (loss: 4.4657182693481445, acc: 0.2374100685119629)
[2024-12-17 01:39:29,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,590][root][INFO] - Training Epoch: 1/2, step 818/7134 completed (loss: 4.225915908813477, acc: 0.27450981736183167)
[2024-12-17 01:39:29,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:29,959][root][INFO] - Training Epoch: 1/2, step 819/7134 completed (loss: 4.186050891876221, acc: 0.267123281955719)
[2024-12-17 01:39:30,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,390][root][INFO] - Training Epoch: 1/2, step 820/7134 completed (loss: 3.739302635192871, acc: 0.37012988328933716)
[2024-12-17 01:39:30,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:30,832][root][INFO] - Training Epoch: 1/2, step 821/7134 completed (loss: 3.6132333278656006, acc: 0.3352601230144501)
[2024-12-17 01:39:30,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,220][root][INFO] - Training Epoch: 1/2, step 822/7134 completed (loss: 3.4025914669036865, acc: 0.3607594966888428)
[2024-12-17 01:39:31,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:31,617][root][INFO] - Training Epoch: 1/2, step 823/7134 completed (loss: 3.755746841430664, acc: 0.3414634168148041)
[2024-12-17 01:39:31,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,022][root][INFO] - Training Epoch: 1/2, step 824/7134 completed (loss: 3.9675450325012207, acc: 0.24242424964904785)
[2024-12-17 01:39:32,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,472][root][INFO] - Training Epoch: 1/2, step 825/7134 completed (loss: 3.698230028152466, acc: 0.33522728085517883)
[2024-12-17 01:39:32,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:32,906][root][INFO] - Training Epoch: 1/2, step 826/7134 completed (loss: 3.505549192428589, acc: 0.3274853825569153)
[2024-12-17 01:39:33,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,311][root][INFO] - Training Epoch: 1/2, step 827/7134 completed (loss: 3.7915196418762207, acc: 0.2923976480960846)
[2024-12-17 01:39:33,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:33,688][root][INFO] - Training Epoch: 1/2, step 828/7134 completed (loss: 3.544772148132324, acc: 0.350649356842041)
[2024-12-17 01:39:33,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,094][root][INFO] - Training Epoch: 1/2, step 829/7134 completed (loss: 4.139878749847412, acc: 0.24038460850715637)
[2024-12-17 01:39:34,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,513][root][INFO] - Training Epoch: 1/2, step 830/7134 completed (loss: 3.2968332767486572, acc: 0.38129496574401855)
[2024-12-17 01:39:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:34,912][root][INFO] - Training Epoch: 1/2, step 831/7134 completed (loss: 3.701427698135376, acc: 0.28915661573410034)
[2024-12-17 01:39:35,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,313][root][INFO] - Training Epoch: 1/2, step 832/7134 completed (loss: 4.034008026123047, acc: 0.29931971430778503)
[2024-12-17 01:39:35,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:35,713][root][INFO] - Training Epoch: 1/2, step 833/7134 completed (loss: 4.292973041534424, acc: 0.2261904776096344)
[2024-12-17 01:39:35,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,104][root][INFO] - Training Epoch: 1/2, step 834/7134 completed (loss: 3.491753339767456, acc: 0.3705882430076599)
[2024-12-17 01:39:36,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:36,522][root][INFO] - Training Epoch: 1/2, step 835/7134 completed (loss: 3.859886884689331, acc: 0.3333333432674408)
[2024-12-17 01:39:36,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,030][root][INFO] - Training Epoch: 1/2, step 836/7134 completed (loss: 3.598869562149048, acc: 0.29949238896369934)
[2024-12-17 01:39:37,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,495][root][INFO] - Training Epoch: 1/2, step 837/7134 completed (loss: 3.871910333633423, acc: 0.29378530383110046)
[2024-12-17 01:39:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:37,877][root][INFO] - Training Epoch: 1/2, step 838/7134 completed (loss: 4.152296543121338, acc: 0.27450981736183167)
[2024-12-17 01:39:37,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,269][root][INFO] - Training Epoch: 1/2, step 839/7134 completed (loss: 3.760080575942993, acc: 0.2772277295589447)
[2024-12-17 01:39:38,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:38,666][root][INFO] - Training Epoch: 1/2, step 840/7134 completed (loss: 3.2330589294433594, acc: 0.38922154903411865)
[2024-12-17 01:39:38,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,062][root][INFO] - Training Epoch: 1/2, step 841/7134 completed (loss: 3.957758665084839, acc: 0.3333333432674408)
[2024-12-17 01:39:39,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,452][root][INFO] - Training Epoch: 1/2, step 842/7134 completed (loss: 3.6133055686950684, acc: 0.3117647171020508)
[2024-12-17 01:39:39,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:39,826][root][INFO] - Training Epoch: 1/2, step 843/7134 completed (loss: 3.378162145614624, acc: 0.35087719559669495)
[2024-12-17 01:39:39,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,194][root][INFO] - Training Epoch: 1/2, step 844/7134 completed (loss: 3.148681879043579, acc: 0.4041095972061157)
[2024-12-17 01:39:40,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,563][root][INFO] - Training Epoch: 1/2, step 845/7134 completed (loss: 3.8013694286346436, acc: 0.3333333432674408)
[2024-12-17 01:39:40,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:40,937][root][INFO] - Training Epoch: 1/2, step 846/7134 completed (loss: 3.5536253452301025, acc: 0.39726027846336365)
[2024-12-17 01:39:41,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,299][root][INFO] - Training Epoch: 1/2, step 847/7134 completed (loss: 3.8834152221679688, acc: 0.34730538725852966)
[2024-12-17 01:39:41,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:41,681][root][INFO] - Training Epoch: 1/2, step 848/7134 completed (loss: 4.405250549316406, acc: 0.26900583505630493)
[2024-12-17 01:39:41,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,091][root][INFO] - Training Epoch: 1/2, step 849/7134 completed (loss: 3.962538480758667, acc: 0.24390244483947754)
[2024-12-17 01:39:42,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,512][root][INFO] - Training Epoch: 1/2, step 850/7134 completed (loss: 3.325568199157715, acc: 0.3557046949863434)
[2024-12-17 01:39:42,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:42,954][root][INFO] - Training Epoch: 1/2, step 851/7134 completed (loss: 3.7661759853363037, acc: 0.3488371968269348)
[2024-12-17 01:39:43,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,369][root][INFO] - Training Epoch: 1/2, step 852/7134 completed (loss: 3.5746138095855713, acc: 0.3403141498565674)
[2024-12-17 01:39:43,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:43,798][root][INFO] - Training Epoch: 1/2, step 853/7134 completed (loss: 3.8776533603668213, acc: 0.3141361176967621)
[2024-12-17 01:39:43,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,191][root][INFO] - Training Epoch: 1/2, step 854/7134 completed (loss: 3.4173452854156494, acc: 0.353658527135849)
[2024-12-17 01:39:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:44,588][root][INFO] - Training Epoch: 1/2, step 855/7134 completed (loss: 3.5785751342773438, acc: 0.3410404622554779)
[2024-12-17 01:39:44,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,018][root][INFO] - Training Epoch: 1/2, step 856/7134 completed (loss: 3.54498553276062, acc: 0.34972676634788513)
[2024-12-17 01:39:45,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,458][root][INFO] - Training Epoch: 1/2, step 857/7134 completed (loss: 3.8148157596588135, acc: 0.2785714268684387)
[2024-12-17 01:39:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:45,873][root][INFO] - Training Epoch: 1/2, step 858/7134 completed (loss: 3.991689682006836, acc: 0.3273809552192688)
[2024-12-17 01:39:46,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,290][root][INFO] - Training Epoch: 1/2, step 859/7134 completed (loss: 3.9974443912506104, acc: 0.29378530383110046)
[2024-12-17 01:39:46,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:46,686][root][INFO] - Training Epoch: 1/2, step 860/7134 completed (loss: 4.559398174285889, acc: 0.30463576316833496)
[2024-12-17 01:39:46,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,145][root][INFO] - Training Epoch: 1/2, step 861/7134 completed (loss: 3.6322829723358154, acc: 0.3709677457809448)
[2024-12-17 01:39:47,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,601][root][INFO] - Training Epoch: 1/2, step 862/7134 completed (loss: 4.40530252456665, acc: 0.24571429193019867)
[2024-12-17 01:39:47,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:47,999][root][INFO] - Training Epoch: 1/2, step 863/7134 completed (loss: 4.176403522491455, acc: 0.31147539615631104)
[2024-12-17 01:39:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,428][root][INFO] - Training Epoch: 1/2, step 864/7134 completed (loss: 4.004507541656494, acc: 0.2777777910232544)
[2024-12-17 01:39:48,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:48,816][root][INFO] - Training Epoch: 1/2, step 865/7134 completed (loss: 4.1948652267456055, acc: 0.27906978130340576)
[2024-12-17 01:39:48,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,184][root][INFO] - Training Epoch: 1/2, step 866/7134 completed (loss: 4.011617183685303, acc: 0.2785714268684387)
[2024-12-17 01:39:49,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,598][root][INFO] - Training Epoch: 1/2, step 867/7134 completed (loss: 4.207564353942871, acc: 0.25)
[2024-12-17 01:39:49,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:49,990][root][INFO] - Training Epoch: 1/2, step 868/7134 completed (loss: 4.099884986877441, acc: 0.2732558250427246)
[2024-12-17 01:39:50,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,408][root][INFO] - Training Epoch: 1/2, step 869/7134 completed (loss: 5.258167266845703, acc: 0.2409638613462448)
[2024-12-17 01:39:50,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:50,866][root][INFO] - Training Epoch: 1/2, step 870/7134 completed (loss: 4.264366149902344, acc: 0.2982456088066101)
[2024-12-17 01:39:51,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,306][root][INFO] - Training Epoch: 1/2, step 871/7134 completed (loss: 4.469287395477295, acc: 0.25342464447021484)
[2024-12-17 01:39:51,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:51,740][root][INFO] - Training Epoch: 1/2, step 872/7134 completed (loss: 3.843045234680176, acc: 0.2777777910232544)
[2024-12-17 01:39:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,153][root][INFO] - Training Epoch: 1/2, step 873/7134 completed (loss: 4.0326151847839355, acc: 0.3030303120613098)
[2024-12-17 01:39:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:52,589][root][INFO] - Training Epoch: 1/2, step 874/7134 completed (loss: 4.419042110443115, acc: 0.2361111044883728)
[2024-12-17 01:39:52,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,031][root][INFO] - Training Epoch: 1/2, step 875/7134 completed (loss: 4.009449481964111, acc: 0.24460431933403015)
[2024-12-17 01:39:53,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,491][root][INFO] - Training Epoch: 1/2, step 876/7134 completed (loss: 3.8470137119293213, acc: 0.30263158679008484)
[2024-12-17 01:39:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:53,919][root][INFO] - Training Epoch: 1/2, step 877/7134 completed (loss: 3.9141194820404053, acc: 0.25766870379447937)
[2024-12-17 01:39:54,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,346][root][INFO] - Training Epoch: 1/2, step 878/7134 completed (loss: 4.220696926116943, acc: 0.26249998807907104)
[2024-12-17 01:39:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:54,769][root][INFO] - Training Epoch: 1/2, step 879/7134 completed (loss: 4.258976459503174, acc: 0.25477707386016846)
[2024-12-17 01:39:54,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,279][root][INFO] - Training Epoch: 1/2, step 880/7134 completed (loss: 4.174012184143066, acc: 0.25153374671936035)
[2024-12-17 01:39:55,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:55,691][root][INFO] - Training Epoch: 1/2, step 881/7134 completed (loss: 4.186478614807129, acc: 0.24390244483947754)
[2024-12-17 01:39:55,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,121][root][INFO] - Training Epoch: 1/2, step 882/7134 completed (loss: 3.7608261108398438, acc: 0.25)
[2024-12-17 01:39:56,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:56,575][root][INFO] - Training Epoch: 1/2, step 883/7134 completed (loss: 4.285061836242676, acc: 0.34210526943206787)
[2024-12-17 01:39:56,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,004][root][INFO] - Training Epoch: 1/2, step 884/7134 completed (loss: 4.026419639587402, acc: 0.28143712878227234)
[2024-12-17 01:39:57,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,456][root][INFO] - Training Epoch: 1/2, step 885/7134 completed (loss: 3.670555353164673, acc: 0.3353658616542816)
[2024-12-17 01:39:57,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:57,865][root][INFO] - Training Epoch: 1/2, step 886/7134 completed (loss: 3.861830949783325, acc: 0.2521008551120758)
[2024-12-17 01:39:58,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,298][root][INFO] - Training Epoch: 1/2, step 887/7134 completed (loss: 4.000528335571289, acc: 0.2238806039094925)
[2024-12-17 01:39:58,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:58,741][root][INFO] - Training Epoch: 1/2, step 888/7134 completed (loss: 4.0233612060546875, acc: 0.24832214415073395)
[2024-12-17 01:39:58,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,223][root][INFO] - Training Epoch: 1/2, step 889/7134 completed (loss: 4.325618267059326, acc: 0.2871287167072296)
[2024-12-17 01:39:59,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:39:59,655][root][INFO] - Training Epoch: 1/2, step 890/7134 completed (loss: 4.070793628692627, acc: 0.28859061002731323)
[2024-12-17 01:39:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,090][root][INFO] - Training Epoch: 1/2, step 891/7134 completed (loss: 3.7069807052612305, acc: 0.27374300360679626)
[2024-12-17 01:40:00,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,526][root][INFO] - Training Epoch: 1/2, step 892/7134 completed (loss: 3.6472020149230957, acc: 0.2797619104385376)
[2024-12-17 01:40:00,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:00,951][root][INFO] - Training Epoch: 1/2, step 893/7134 completed (loss: 3.8018579483032227, acc: 0.3006536066532135)
[2024-12-17 01:40:01,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,373][root][INFO] - Training Epoch: 1/2, step 894/7134 completed (loss: 3.3669254779815674, acc: 0.37288135290145874)
[2024-12-17 01:40:01,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:01,796][root][INFO] - Training Epoch: 1/2, step 895/7134 completed (loss: 3.454096794128418, acc: 0.3561643958091736)
[2024-12-17 01:40:01,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,220][root][INFO] - Training Epoch: 1/2, step 896/7134 completed (loss: 3.592388391494751, acc: 0.34645670652389526)
[2024-12-17 01:40:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:02,681][root][INFO] - Training Epoch: 1/2, step 897/7134 completed (loss: 3.533510684967041, acc: 0.31843575835227966)
[2024-12-17 01:40:02,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,103][root][INFO] - Training Epoch: 1/2, step 898/7134 completed (loss: 3.941507577896118, acc: 0.27840909361839294)
[2024-12-17 01:40:03,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,510][root][INFO] - Training Epoch: 1/2, step 899/7134 completed (loss: 3.710969924926758, acc: 0.31550800800323486)
[2024-12-17 01:40:03,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:03,915][root][INFO] - Training Epoch: 1/2, step 900/7134 completed (loss: 3.5717356204986572, acc: 0.29878050088882446)
[2024-12-17 01:40:04,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,358][root][INFO] - Training Epoch: 1/2, step 901/7134 completed (loss: 3.689244508743286, acc: 0.3571428656578064)
[2024-12-17 01:40:04,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:04,821][root][INFO] - Training Epoch: 1/2, step 902/7134 completed (loss: 3.9799625873565674, acc: 0.24025973677635193)
[2024-12-17 01:40:04,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,200][root][INFO] - Training Epoch: 1/2, step 903/7134 completed (loss: 3.51203989982605, acc: 0.3179190754890442)
[2024-12-17 01:40:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:05,608][root][INFO] - Training Epoch: 1/2, step 904/7134 completed (loss: 3.6726973056793213, acc: 0.3050847351551056)
[2024-12-17 01:40:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,002][root][INFO] - Training Epoch: 1/2, step 905/7134 completed (loss: 3.512005567550659, acc: 0.31609195470809937)
[2024-12-17 01:40:06,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,374][root][INFO] - Training Epoch: 1/2, step 906/7134 completed (loss: 3.772578716278076, acc: 0.32044199109077454)
[2024-12-17 01:40:06,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:06,759][root][INFO] - Training Epoch: 1/2, step 907/7134 completed (loss: 3.7410452365875244, acc: 0.32258063554763794)
[2024-12-17 01:40:06,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,164][root][INFO] - Training Epoch: 1/2, step 908/7134 completed (loss: 3.369429588317871, acc: 0.35555556416511536)
[2024-12-17 01:40:07,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,534][root][INFO] - Training Epoch: 1/2, step 909/7134 completed (loss: 3.1025664806365967, acc: 0.40789473056793213)
[2024-12-17 01:40:07,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:07,938][root][INFO] - Training Epoch: 1/2, step 910/7134 completed (loss: 4.296326637268066, acc: 0.26249998807907104)
[2024-12-17 01:40:08,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,330][root][INFO] - Training Epoch: 1/2, step 911/7134 completed (loss: 4.235289573669434, acc: 0.32258063554763794)
[2024-12-17 01:40:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:08,732][root][INFO] - Training Epoch: 1/2, step 912/7134 completed (loss: 3.8246896266937256, acc: 0.3052631616592407)
[2024-12-17 01:40:08,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,118][root][INFO] - Training Epoch: 1/2, step 913/7134 completed (loss: 3.8858323097229004, acc: 0.30219781398773193)
[2024-12-17 01:40:09,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,547][root][INFO] - Training Epoch: 1/2, step 914/7134 completed (loss: 4.034267902374268, acc: 0.2545454502105713)
[2024-12-17 01:40:09,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:09,926][root][INFO] - Training Epoch: 1/2, step 915/7134 completed (loss: 4.074960231781006, acc: 0.2857142984867096)
[2024-12-17 01:40:10,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,344][root][INFO] - Training Epoch: 1/2, step 916/7134 completed (loss: 3.809607744216919, acc: 0.3100775182247162)
[2024-12-17 01:40:10,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:10,699][root][INFO] - Training Epoch: 1/2, step 917/7134 completed (loss: 4.252313613891602, acc: 0.26623377203941345)
[2024-12-17 01:40:10,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,112][root][INFO] - Training Epoch: 1/2, step 918/7134 completed (loss: 3.5907068252563477, acc: 0.3509933650493622)
[2024-12-17 01:40:11,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,507][root][INFO] - Training Epoch: 1/2, step 919/7134 completed (loss: 3.5378167629241943, acc: 0.29870128631591797)
[2024-12-17 01:40:11,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:11,929][root][INFO] - Training Epoch: 1/2, step 920/7134 completed (loss: 3.71909499168396, acc: 0.26744186878204346)
[2024-12-17 01:40:12,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,355][root][INFO] - Training Epoch: 1/2, step 921/7134 completed (loss: 4.018300533294678, acc: 0.22807016968727112)
[2024-12-17 01:40:12,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:12,732][root][INFO] - Training Epoch: 1/2, step 922/7134 completed (loss: 3.5481011867523193, acc: 0.3208955228328705)
[2024-12-17 01:40:12,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,122][root][INFO] - Training Epoch: 1/2, step 923/7134 completed (loss: 3.310725688934326, acc: 0.3333333432674408)
[2024-12-17 01:40:13,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:13,607][root][INFO] - Training Epoch: 1/2, step 924/7134 completed (loss: 3.4306607246398926, acc: 0.29378530383110046)
[2024-12-17 01:40:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,024][root][INFO] - Training Epoch: 1/2, step 925/7134 completed (loss: 3.841527223587036, acc: 0.3354838788509369)
[2024-12-17 01:40:14,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,430][root][INFO] - Training Epoch: 1/2, step 926/7134 completed (loss: 3.311180353164673, acc: 0.3222222328186035)
[2024-12-17 01:40:14,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:14,831][root][INFO] - Training Epoch: 1/2, step 927/7134 completed (loss: 3.4748270511627197, acc: 0.316546767950058)
[2024-12-17 01:40:14,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,272][root][INFO] - Training Epoch: 1/2, step 928/7134 completed (loss: 3.5071115493774414, acc: 0.33944955468177795)
[2024-12-17 01:40:15,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:15,714][root][INFO] - Training Epoch: 1/2, step 929/7134 completed (loss: 3.890366315841675, acc: 0.30921053886413574)
[2024-12-17 01:40:15,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,091][root][INFO] - Training Epoch: 1/2, step 930/7134 completed (loss: 3.7391791343688965, acc: 0.3467741906642914)
[2024-12-17 01:40:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,538][root][INFO] - Training Epoch: 1/2, step 931/7134 completed (loss: 3.7833974361419678, acc: 0.31617647409439087)
[2024-12-17 01:40:16,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:16,940][root][INFO] - Training Epoch: 1/2, step 932/7134 completed (loss: 3.4901249408721924, acc: 0.3154761791229248)
[2024-12-17 01:40:17,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,325][root][INFO] - Training Epoch: 1/2, step 933/7134 completed (loss: 4.235775947570801, acc: 0.27544909715652466)
[2024-12-17 01:40:17,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:17,744][root][INFO] - Training Epoch: 1/2, step 934/7134 completed (loss: 3.956892251968384, acc: 0.25581395626068115)
[2024-12-17 01:40:17,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,140][root][INFO] - Training Epoch: 1/2, step 935/7134 completed (loss: 3.5509040355682373, acc: 0.3488371968269348)
[2024-12-17 01:40:18,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,524][root][INFO] - Training Epoch: 1/2, step 936/7134 completed (loss: 3.926936388015747, acc: 0.26771652698516846)
[2024-12-17 01:40:18,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:18,911][root][INFO] - Training Epoch: 1/2, step 937/7134 completed (loss: 4.351237773895264, acc: 0.2195121943950653)
[2024-12-17 01:40:19,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,335][root][INFO] - Training Epoch: 1/2, step 938/7134 completed (loss: 3.8240602016448975, acc: 0.2756410241127014)
[2024-12-17 01:40:19,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:19,721][root][INFO] - Training Epoch: 1/2, step 939/7134 completed (loss: 3.9108567237854004, acc: 0.3048780560493469)
[2024-12-17 01:40:19,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,113][root][INFO] - Training Epoch: 1/2, step 940/7134 completed (loss: 3.8824779987335205, acc: 0.3005780279636383)
[2024-12-17 01:40:20,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,522][root][INFO] - Training Epoch: 1/2, step 941/7134 completed (loss: 3.530444622039795, acc: 0.3089887499809265)
[2024-12-17 01:40:20,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:20,908][root][INFO] - Training Epoch: 1/2, step 942/7134 completed (loss: 3.778515100479126, acc: 0.31976744532585144)
[2024-12-17 01:40:21,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,307][root][INFO] - Training Epoch: 1/2, step 943/7134 completed (loss: 3.710045099258423, acc: 0.2822085916996002)
[2024-12-17 01:40:21,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:21,749][root][INFO] - Training Epoch: 1/2, step 944/7134 completed (loss: 3.669996976852417, acc: 0.2929936349391937)
[2024-12-17 01:40:21,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,188][root][INFO] - Training Epoch: 1/2, step 945/7134 completed (loss: 3.7346394062042236, acc: 0.3245033025741577)
[2024-12-17 01:40:22,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:22,621][root][INFO] - Training Epoch: 1/2, step 946/7134 completed (loss: 4.120259761810303, acc: 0.3106796145439148)
[2024-12-17 01:40:22,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,036][root][INFO] - Training Epoch: 1/2, step 947/7134 completed (loss: 3.9885613918304443, acc: 0.25735294818878174)
[2024-12-17 01:40:23,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,502][root][INFO] - Training Epoch: 1/2, step 948/7134 completed (loss: 3.5529563426971436, acc: 0.29518070816993713)
[2024-12-17 01:40:23,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:23,992][root][INFO] - Training Epoch: 1/2, step 949/7134 completed (loss: 3.763104200363159, acc: 0.3375000059604645)
[2024-12-17 01:40:24,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,410][root][INFO] - Training Epoch: 1/2, step 950/7134 completed (loss: 3.5120785236358643, acc: 0.33766233921051025)
[2024-12-17 01:40:24,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:24,804][root][INFO] - Training Epoch: 1/2, step 951/7134 completed (loss: 3.7368040084838867, acc: 0.32824426889419556)
[2024-12-17 01:40:24,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,226][root][INFO] - Training Epoch: 1/2, step 952/7134 completed (loss: 3.3801753520965576, acc: 0.3970588147640228)
[2024-12-17 01:40:25,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:25,643][root][INFO] - Training Epoch: 1/2, step 953/7134 completed (loss: 4.236411094665527, acc: 0.29878050088882446)
[2024-12-17 01:40:25,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,015][root][INFO] - Training Epoch: 1/2, step 954/7134 completed (loss: 3.774254083633423, acc: 0.33103448152542114)
[2024-12-17 01:40:26,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,430][root][INFO] - Training Epoch: 1/2, step 955/7134 completed (loss: 3.9293739795684814, acc: 0.32203391194343567)
[2024-12-17 01:40:26,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:26,834][root][INFO] - Training Epoch: 1/2, step 956/7134 completed (loss: 3.627729654312134, acc: 0.30978259444236755)
[2024-12-17 01:40:26,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,242][root][INFO] - Training Epoch: 1/2, step 957/7134 completed (loss: 3.438498020172119, acc: 0.3235294222831726)
[2024-12-17 01:40:27,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:27,658][root][INFO] - Training Epoch: 1/2, step 958/7134 completed (loss: 3.981544256210327, acc: 0.3208955228328705)
[2024-12-17 01:40:27,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,081][root][INFO] - Training Epoch: 1/2, step 959/7134 completed (loss: 4.193467140197754, acc: 0.29381442070007324)
[2024-12-17 01:40:28,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,499][root][INFO] - Training Epoch: 1/2, step 960/7134 completed (loss: 4.2959160804748535, acc: 0.305970162153244)
[2024-12-17 01:40:28,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:28,897][root][INFO] - Training Epoch: 1/2, step 961/7134 completed (loss: 4.115304470062256, acc: 0.26923078298568726)
[2024-12-17 01:40:28,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,295][root][INFO] - Training Epoch: 1/2, step 962/7134 completed (loss: 4.178804397583008, acc: 0.28654971718788147)
[2024-12-17 01:40:29,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:29,717][root][INFO] - Training Epoch: 1/2, step 963/7134 completed (loss: 3.558438777923584, acc: 0.2906976640224457)
[2024-12-17 01:40:29,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,096][root][INFO] - Training Epoch: 1/2, step 964/7134 completed (loss: 4.258664608001709, acc: 0.27439025044441223)
[2024-12-17 01:40:30,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,515][root][INFO] - Training Epoch: 1/2, step 965/7134 completed (loss: 3.842629909515381, acc: 0.33155080676078796)
[2024-12-17 01:40:30,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:30,906][root][INFO] - Training Epoch: 1/2, step 966/7134 completed (loss: 3.750977039337158, acc: 0.3190183937549591)
[2024-12-17 01:40:31,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,321][root][INFO] - Training Epoch: 1/2, step 967/7134 completed (loss: 3.782771110534668, acc: 0.3404255211353302)
[2024-12-17 01:40:31,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:31,739][root][INFO] - Training Epoch: 1/2, step 968/7134 completed (loss: 4.289669036865234, acc: 0.2857142984867096)
[2024-12-17 01:40:31,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,155][root][INFO] - Training Epoch: 1/2, step 969/7134 completed (loss: 4.0244293212890625, acc: 0.2857142984867096)
[2024-12-17 01:40:32,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,551][root][INFO] - Training Epoch: 1/2, step 970/7134 completed (loss: 3.8203353881835938, acc: 0.3602941036224365)
[2024-12-17 01:40:32,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:32,926][root][INFO] - Training Epoch: 1/2, step 971/7134 completed (loss: 3.3873767852783203, acc: 0.3649289011955261)
[2024-12-17 01:40:33,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,307][root][INFO] - Training Epoch: 1/2, step 972/7134 completed (loss: 4.1358489990234375, acc: 0.25128206610679626)
[2024-12-17 01:40:33,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:33,723][root][INFO] - Training Epoch: 1/2, step 973/7134 completed (loss: 3.8594188690185547, acc: 0.3186813294887543)
[2024-12-17 01:40:33,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,129][root][INFO] - Training Epoch: 1/2, step 974/7134 completed (loss: 4.051232814788818, acc: 0.24752475321292877)
[2024-12-17 01:40:34,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,514][root][INFO] - Training Epoch: 1/2, step 975/7134 completed (loss: 4.408491134643555, acc: 0.23404255509376526)
[2024-12-17 01:40:34,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:34,901][root][INFO] - Training Epoch: 1/2, step 976/7134 completed (loss: 3.589855909347534, acc: 0.29139071702957153)
[2024-12-17 01:40:34,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,282][root][INFO] - Training Epoch: 1/2, step 977/7134 completed (loss: 3.928511381149292, acc: 0.3483146131038666)
[2024-12-17 01:40:35,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:35,671][root][INFO] - Training Epoch: 1/2, step 978/7134 completed (loss: 3.7504990100860596, acc: 0.3144329786300659)
[2024-12-17 01:40:35,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,053][root][INFO] - Training Epoch: 1/2, step 979/7134 completed (loss: 3.743668794631958, acc: 0.3891891837120056)
[2024-12-17 01:40:36,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,424][root][INFO] - Training Epoch: 1/2, step 980/7134 completed (loss: 3.837912082672119, acc: 0.2863849699497223)
[2024-12-17 01:40:36,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:36,827][root][INFO] - Training Epoch: 1/2, step 981/7134 completed (loss: 4.051024436950684, acc: 0.29559749364852905)
[2024-12-17 01:40:36,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,217][root][INFO] - Training Epoch: 1/2, step 982/7134 completed (loss: 3.9727208614349365, acc: 0.3199999928474426)
[2024-12-17 01:40:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,597][root][INFO] - Training Epoch: 1/2, step 983/7134 completed (loss: 3.79059100151062, acc: 0.3308270573616028)
[2024-12-17 01:40:37,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:37,942][root][INFO] - Training Epoch: 1/2, step 984/7134 completed (loss: 3.5225062370300293, acc: 0.368794322013855)
[2024-12-17 01:40:38,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,303][root][INFO] - Training Epoch: 1/2, step 985/7134 completed (loss: 3.38200044631958, acc: 0.32777777314186096)
[2024-12-17 01:40:38,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:38,689][root][INFO] - Training Epoch: 1/2, step 986/7134 completed (loss: 3.3689470291137695, acc: 0.3519552946090698)
[2024-12-17 01:40:38,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,096][root][INFO] - Training Epoch: 1/2, step 987/7134 completed (loss: 3.237091541290283, acc: 0.3758389353752136)
[2024-12-17 01:40:39,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,461][root][INFO] - Training Epoch: 1/2, step 988/7134 completed (loss: 4.110927104949951, acc: 0.3163841664791107)
[2024-12-17 01:40:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:39,858][root][INFO] - Training Epoch: 1/2, step 989/7134 completed (loss: 4.117156982421875, acc: 0.29447853565216064)
[2024-12-17 01:40:39,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,235][root][INFO] - Training Epoch: 1/2, step 990/7134 completed (loss: 3.989784002304077, acc: 0.28021979331970215)
[2024-12-17 01:40:40,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:40,614][root][INFO] - Training Epoch: 1/2, step 991/7134 completed (loss: 4.326017379760742, acc: 0.30817610025405884)
[2024-12-17 01:40:40,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,010][root][INFO] - Training Epoch: 1/2, step 992/7134 completed (loss: 3.900500774383545, acc: 0.3005780279636383)
[2024-12-17 01:40:41,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,396][root][INFO] - Training Epoch: 1/2, step 993/7134 completed (loss: 4.365950107574463, acc: 0.24460431933403015)
[2024-12-17 01:40:41,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:41,823][root][INFO] - Training Epoch: 1/2, step 994/7134 completed (loss: 3.3466405868530273, acc: 0.3980582654476166)
[2024-12-17 01:40:41,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,206][root][INFO] - Training Epoch: 1/2, step 995/7134 completed (loss: 4.141704082489014, acc: 0.25850340723991394)
[2024-12-17 01:40:42,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,592][root][INFO] - Training Epoch: 1/2, step 996/7134 completed (loss: 3.838883876800537, acc: 0.3255814015865326)
[2024-12-17 01:40:42,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:42,977][root][INFO] - Training Epoch: 1/2, step 997/7134 completed (loss: 3.61016583442688, acc: 0.3529411852359772)
[2024-12-17 01:40:43,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,376][root][INFO] - Training Epoch: 1/2, step 998/7134 completed (loss: 3.701291799545288, acc: 0.3053892254829407)
[2024-12-17 01:40:43,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:43,751][root][INFO] - Training Epoch: 1/2, step 999/7134 completed (loss: 4.009856224060059, acc: 0.2846153974533081)
[2024-12-17 01:40:43,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,129][root][INFO] - Training Epoch: 1/2, step 1000/7134 completed (loss: 3.8859920501708984, acc: 0.2867647111415863)
[2024-12-17 01:40:44,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,543][root][INFO] - Training Epoch: 1/2, step 1001/7134 completed (loss: 3.7511940002441406, acc: 0.3909091055393219)
[2024-12-17 01:40:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:44,903][root][INFO] - Training Epoch: 1/2, step 1002/7134 completed (loss: 3.9958510398864746, acc: 0.31446540355682373)
[2024-12-17 01:40:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,288][root][INFO] - Training Epoch: 1/2, step 1003/7134 completed (loss: 3.4944984912872314, acc: 0.3611111044883728)
[2024-12-17 01:40:45,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:45,653][root][INFO] - Training Epoch: 1/2, step 1004/7134 completed (loss: 3.9133739471435547, acc: 0.36283186078071594)
[2024-12-17 01:40:45,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,042][root][INFO] - Training Epoch: 1/2, step 1005/7134 completed (loss: 3.8223345279693604, acc: 0.2978723347187042)
[2024-12-17 01:40:46,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,390][root][INFO] - Training Epoch: 1/2, step 1006/7134 completed (loss: 4.480520248413086, acc: 0.2292993664741516)
[2024-12-17 01:40:46,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:46,740][root][INFO] - Training Epoch: 1/2, step 1007/7134 completed (loss: 4.205557823181152, acc: 0.27464789152145386)
[2024-12-17 01:40:46,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,122][root][INFO] - Training Epoch: 1/2, step 1008/7134 completed (loss: 4.052384376525879, acc: 0.29012346267700195)
[2024-12-17 01:40:47,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,500][root][INFO] - Training Epoch: 1/2, step 1009/7134 completed (loss: 3.4087398052215576, acc: 0.3178294599056244)
[2024-12-17 01:40:47,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:47,849][root][INFO] - Training Epoch: 1/2, step 1010/7134 completed (loss: 3.4897074699401855, acc: 0.3589743673801422)
[2024-12-17 01:40:47,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,254][root][INFO] - Training Epoch: 1/2, step 1011/7134 completed (loss: 3.961153507232666, acc: 0.29559749364852905)
[2024-12-17 01:40:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:48,654][root][INFO] - Training Epoch: 1/2, step 1012/7134 completed (loss: 3.75825834274292, acc: 0.38749998807907104)
[2024-12-17 01:40:48,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,043][root][INFO] - Training Epoch: 1/2, step 1013/7134 completed (loss: 4.052955627441406, acc: 0.3072289228439331)
[2024-12-17 01:40:49,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,414][root][INFO] - Training Epoch: 1/2, step 1014/7134 completed (loss: 4.045312881469727, acc: 0.3191489279270172)
[2024-12-17 01:40:49,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:49,836][root][INFO] - Training Epoch: 1/2, step 1015/7134 completed (loss: 3.860053300857544, acc: 0.33774834871292114)
[2024-12-17 01:40:49,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,233][root][INFO] - Training Epoch: 1/2, step 1016/7134 completed (loss: 4.077637195587158, acc: 0.26050421595573425)
[2024-12-17 01:40:50,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,611][root][INFO] - Training Epoch: 1/2, step 1017/7134 completed (loss: 3.7936794757843018, acc: 0.33142855763435364)
[2024-12-17 01:40:50,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:50,986][root][INFO] - Training Epoch: 1/2, step 1018/7134 completed (loss: 4.346987724304199, acc: 0.31677019596099854)
[2024-12-17 01:40:51,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,363][root][INFO] - Training Epoch: 1/2, step 1019/7134 completed (loss: 4.25485372543335, acc: 0.26623377203941345)
[2024-12-17 01:40:51,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:51,772][root][INFO] - Training Epoch: 1/2, step 1020/7134 completed (loss: 4.169968605041504, acc: 0.2802547812461853)
[2024-12-17 01:40:51,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,146][root][INFO] - Training Epoch: 1/2, step 1021/7134 completed (loss: 3.404254198074341, acc: 0.33986929059028625)
[2024-12-17 01:40:52,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,557][root][INFO] - Training Epoch: 1/2, step 1022/7134 completed (loss: 3.475168228149414, acc: 0.31213873624801636)
[2024-12-17 01:40:52,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:52,996][root][INFO] - Training Epoch: 1/2, step 1023/7134 completed (loss: 4.022449493408203, acc: 0.2625698447227478)
[2024-12-17 01:40:53,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,471][root][INFO] - Training Epoch: 1/2, step 1024/7134 completed (loss: 3.660346031188965, acc: 0.33582088351249695)
[2024-12-17 01:40:53,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:53,866][root][INFO] - Training Epoch: 1/2, step 1025/7134 completed (loss: 3.3264572620391846, acc: 0.3404255211353302)
[2024-12-17 01:40:53,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,213][root][INFO] - Training Epoch: 1/2, step 1026/7134 completed (loss: 3.6928205490112305, acc: 0.3451327383518219)
[2024-12-17 01:40:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,584][root][INFO] - Training Epoch: 1/2, step 1027/7134 completed (loss: 3.700038433074951, acc: 0.3176470696926117)
[2024-12-17 01:40:54,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:54,974][root][INFO] - Training Epoch: 1/2, step 1028/7134 completed (loss: 3.6356420516967773, acc: 0.2641509473323822)
[2024-12-17 01:40:55,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,392][root][INFO] - Training Epoch: 1/2, step 1029/7134 completed (loss: 3.441654920578003, acc: 0.3024691343307495)
[2024-12-17 01:40:55,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:55,823][root][INFO] - Training Epoch: 1/2, step 1030/7134 completed (loss: 3.5995101928710938, acc: 0.2816092073917389)
[2024-12-17 01:40:55,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,201][root][INFO] - Training Epoch: 1/2, step 1031/7134 completed (loss: 4.613066673278809, acc: 0.21739129722118378)
[2024-12-17 01:40:56,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,590][root][INFO] - Training Epoch: 1/2, step 1032/7134 completed (loss: 3.665008306503296, acc: 0.3776595890522003)
[2024-12-17 01:40:56,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:56,999][root][INFO] - Training Epoch: 1/2, step 1033/7134 completed (loss: 3.8947954177856445, acc: 0.2945205569267273)
[2024-12-17 01:40:57,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,350][root][INFO] - Training Epoch: 1/2, step 1034/7134 completed (loss: 4.257286071777344, acc: 0.3181818127632141)
[2024-12-17 01:40:57,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:57,741][root][INFO] - Training Epoch: 1/2, step 1035/7134 completed (loss: 4.941838264465332, acc: 0.20945945382118225)
[2024-12-17 01:40:57,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,183][root][INFO] - Training Epoch: 1/2, step 1036/7134 completed (loss: 4.962197303771973, acc: 0.23728813230991364)
[2024-12-17 01:40:58,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,560][root][INFO] - Training Epoch: 1/2, step 1037/7134 completed (loss: 3.3685381412506104, acc: 0.3723404109477997)
[2024-12-17 01:40:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:58,948][root][INFO] - Training Epoch: 1/2, step 1038/7134 completed (loss: 3.858264207839966, acc: 0.36000001430511475)
[2024-12-17 01:40:59,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,332][root][INFO] - Training Epoch: 1/2, step 1039/7134 completed (loss: 3.7672665119171143, acc: 0.302752286195755)
[2024-12-17 01:40:59,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:40:59,775][root][INFO] - Training Epoch: 1/2, step 1040/7134 completed (loss: 4.07126522064209, acc: 0.21014492213726044)
[2024-12-17 01:40:59,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,177][root][INFO] - Training Epoch: 1/2, step 1041/7134 completed (loss: 3.586696147918701, acc: 0.3154362440109253)
[2024-12-17 01:41:00,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,611][root][INFO] - Training Epoch: 1/2, step 1042/7134 completed (loss: 3.6192708015441895, acc: 0.3463687002658844)
[2024-12-17 01:41:00,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:00,973][root][INFO] - Training Epoch: 1/2, step 1043/7134 completed (loss: 3.6759793758392334, acc: 0.301980197429657)
[2024-12-17 01:41:01,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,327][root][INFO] - Training Epoch: 1/2, step 1044/7134 completed (loss: 2.979666233062744, acc: 0.42236024141311646)
[2024-12-17 01:41:01,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:01,775][root][INFO] - Training Epoch: 1/2, step 1045/7134 completed (loss: 4.935440540313721, acc: 0.1801242232322693)
[2024-12-17 01:41:01,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,170][root][INFO] - Training Epoch: 1/2, step 1046/7134 completed (loss: 4.235735893249512, acc: 0.29323309659957886)
[2024-12-17 01:41:02,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:02,561][root][INFO] - Training Epoch: 1/2, step 1047/7134 completed (loss: 4.154219150543213, acc: 0.3028571307659149)
[2024-12-17 01:41:02,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,024][root][INFO] - Training Epoch: 1/2, step 1048/7134 completed (loss: 3.9848861694335938, acc: 0.2929936349391937)
[2024-12-17 01:41:03,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,420][root][INFO] - Training Epoch: 1/2, step 1049/7134 completed (loss: 4.3140716552734375, acc: 0.2434210479259491)
[2024-12-17 01:41:03,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:03,822][root][INFO] - Training Epoch: 1/2, step 1050/7134 completed (loss: 4.385410785675049, acc: 0.2864583432674408)
[2024-12-17 01:41:03,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,205][root][INFO] - Training Epoch: 1/2, step 1051/7134 completed (loss: 3.768676519393921, acc: 0.33714285492897034)
[2024-12-17 01:41:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,570][root][INFO] - Training Epoch: 1/2, step 1052/7134 completed (loss: 3.938871145248413, acc: 0.3253012001514435)
[2024-12-17 01:41:04,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:04,930][root][INFO] - Training Epoch: 1/2, step 1053/7134 completed (loss: 3.933626890182495, acc: 0.341317355632782)
[2024-12-17 01:41:05,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,316][root][INFO] - Training Epoch: 1/2, step 1054/7134 completed (loss: 3.687849760055542, acc: 0.296875)
[2024-12-17 01:41:05,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:05,704][root][INFO] - Training Epoch: 1/2, step 1055/7134 completed (loss: 4.106884479522705, acc: 0.28244274854660034)
[2024-12-17 01:41:05,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,065][root][INFO] - Training Epoch: 1/2, step 1056/7134 completed (loss: 3.7571468353271484, acc: 0.3488371968269348)
[2024-12-17 01:41:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,425][root][INFO] - Training Epoch: 1/2, step 1057/7134 completed (loss: 3.6038641929626465, acc: 0.3108808398246765)
[2024-12-17 01:41:06,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:06,825][root][INFO] - Training Epoch: 1/2, step 1058/7134 completed (loss: 3.7092201709747314, acc: 0.3210526406764984)
[2024-12-17 01:41:06,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,244][root][INFO] - Training Epoch: 1/2, step 1059/7134 completed (loss: 3.641335964202881, acc: 0.3412322402000427)
[2024-12-17 01:41:07,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:07,626][root][INFO] - Training Epoch: 1/2, step 1060/7134 completed (loss: 3.6742992401123047, acc: 0.3589743673801422)
[2024-12-17 01:41:07,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,040][root][INFO] - Training Epoch: 1/2, step 1061/7134 completed (loss: 3.5516271591186523, acc: 0.3350515365600586)
[2024-12-17 01:41:08,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,401][root][INFO] - Training Epoch: 1/2, step 1062/7134 completed (loss: 3.963595390319824, acc: 0.28915661573410034)
[2024-12-17 01:41:08,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:08,772][root][INFO] - Training Epoch: 1/2, step 1063/7134 completed (loss: 3.3956079483032227, acc: 0.39411765336990356)
[2024-12-17 01:41:08,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,143][root][INFO] - Training Epoch: 1/2, step 1064/7134 completed (loss: 3.4587979316711426, acc: 0.31351351737976074)
[2024-12-17 01:41:09,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,519][root][INFO] - Training Epoch: 1/2, step 1065/7134 completed (loss: 3.770467758178711, acc: 0.3093922734260559)
[2024-12-17 01:41:09,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:09,878][root][INFO] - Training Epoch: 1/2, step 1066/7134 completed (loss: 4.170912265777588, acc: 0.290076345205307)
[2024-12-17 01:41:09,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,251][root][INFO] - Training Epoch: 1/2, step 1067/7134 completed (loss: 4.0847554206848145, acc: 0.3202614486217499)
[2024-12-17 01:41:10,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:10,656][root][INFO] - Training Epoch: 1/2, step 1068/7134 completed (loss: 4.233165740966797, acc: 0.2890625)
[2024-12-17 01:41:10,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,046][root][INFO] - Training Epoch: 1/2, step 1069/7134 completed (loss: 4.107402801513672, acc: 0.2986111044883728)
[2024-12-17 01:41:11,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,420][root][INFO] - Training Epoch: 1/2, step 1070/7134 completed (loss: 4.021903038024902, acc: 0.232876718044281)
[2024-12-17 01:41:11,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:11,842][root][INFO] - Training Epoch: 1/2, step 1071/7134 completed (loss: 3.934391498565674, acc: 0.28125)
[2024-12-17 01:41:11,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,229][root][INFO] - Training Epoch: 1/2, step 1072/7134 completed (loss: 3.4389102458953857, acc: 0.3048780560493469)
[2024-12-17 01:41:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,604][root][INFO] - Training Epoch: 1/2, step 1073/7134 completed (loss: 3.6659624576568604, acc: 0.20496894419193268)
[2024-12-17 01:41:12,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:12,981][root][INFO] - Training Epoch: 1/2, step 1074/7134 completed (loss: 3.8111398220062256, acc: 0.304964542388916)
[2024-12-17 01:41:13,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,367][root][INFO] - Training Epoch: 1/2, step 1075/7134 completed (loss: 4.200737953186035, acc: 0.30656933784484863)
[2024-12-17 01:41:13,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:13,728][root][INFO] - Training Epoch: 1/2, step 1076/7134 completed (loss: 4.083949089050293, acc: 0.32446807622909546)
[2024-12-17 01:41:13,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,089][root][INFO] - Training Epoch: 1/2, step 1077/7134 completed (loss: 4.180649280548096, acc: 0.3185840845108032)
[2024-12-17 01:41:14,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,462][root][INFO] - Training Epoch: 1/2, step 1078/7134 completed (loss: 4.692803382873535, acc: 0.28930819034576416)
[2024-12-17 01:41:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:14,872][root][INFO] - Training Epoch: 1/2, step 1079/7134 completed (loss: 4.0865159034729, acc: 0.2764976918697357)
[2024-12-17 01:41:15,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,284][root][INFO] - Training Epoch: 1/2, step 1080/7134 completed (loss: 4.180359840393066, acc: 0.2868216931819916)
[2024-12-17 01:41:15,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:15,626][root][INFO] - Training Epoch: 1/2, step 1081/7134 completed (loss: 3.756889581680298, acc: 0.29518070816993713)
[2024-12-17 01:41:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,027][root][INFO] - Training Epoch: 1/2, step 1082/7134 completed (loss: 3.037414789199829, acc: 0.4170403480529785)
[2024-12-17 01:41:16,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,398][root][INFO] - Training Epoch: 1/2, step 1083/7134 completed (loss: 4.118648052215576, acc: 0.25380709767341614)
[2024-12-17 01:41:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:16,780][root][INFO] - Training Epoch: 1/2, step 1084/7134 completed (loss: 3.3834102153778076, acc: 0.36702126264572144)
[2024-12-17 01:41:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,176][root][INFO] - Training Epoch: 1/2, step 1085/7134 completed (loss: 3.9939916133880615, acc: 0.29559749364852905)
[2024-12-17 01:41:17,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,542][root][INFO] - Training Epoch: 1/2, step 1086/7134 completed (loss: 4.405303001403809, acc: 0.2983871102333069)
[2024-12-17 01:41:17,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:17,937][root][INFO] - Training Epoch: 1/2, step 1087/7134 completed (loss: 3.6972126960754395, acc: 0.32258063554763794)
[2024-12-17 01:41:18,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,413][root][INFO] - Training Epoch: 1/2, step 1088/7134 completed (loss: 3.5897321701049805, acc: 0.28977271914482117)
[2024-12-17 01:41:18,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:18,791][root][INFO] - Training Epoch: 1/2, step 1089/7134 completed (loss: 3.7929718494415283, acc: 0.3190183937549591)
[2024-12-17 01:41:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,200][root][INFO] - Training Epoch: 1/2, step 1090/7134 completed (loss: 3.5469741821289062, acc: 0.3988095223903656)
[2024-12-17 01:41:19,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,581][root][INFO] - Training Epoch: 1/2, step 1091/7134 completed (loss: 3.621579647064209, acc: 0.3602484464645386)
[2024-12-17 01:41:19,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:19,967][root][INFO] - Training Epoch: 1/2, step 1092/7134 completed (loss: 3.470466375350952, acc: 0.31137725710868835)
[2024-12-17 01:41:20,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,338][root][INFO] - Training Epoch: 1/2, step 1093/7134 completed (loss: 3.391425848007202, acc: 0.40816327929496765)
[2024-12-17 01:41:20,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:20,718][root][INFO] - Training Epoch: 1/2, step 1094/7134 completed (loss: 4.045254230499268, acc: 0.308270663022995)
[2024-12-17 01:41:20,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,133][root][INFO] - Training Epoch: 1/2, step 1095/7134 completed (loss: 3.6916091442108154, acc: 0.33862432837486267)
[2024-12-17 01:41:21,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,534][root][INFO] - Training Epoch: 1/2, step 1096/7134 completed (loss: 3.8879811763763428, acc: 0.2956989109516144)
[2024-12-17 01:41:21,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:21,924][root][INFO] - Training Epoch: 1/2, step 1097/7134 completed (loss: 4.421571731567383, acc: 0.22404371201992035)
[2024-12-17 01:41:22,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,273][root][INFO] - Training Epoch: 1/2, step 1098/7134 completed (loss: 4.211530685424805, acc: 0.2666666805744171)
[2024-12-17 01:41:22,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:22,642][root][INFO] - Training Epoch: 1/2, step 1099/7134 completed (loss: 3.6935794353485107, acc: 0.3229166567325592)
[2024-12-17 01:41:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,081][root][INFO] - Training Epoch: 1/2, step 1100/7134 completed (loss: 4.01567268371582, acc: 0.2982456088066101)
[2024-12-17 01:41:23,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,487][root][INFO] - Training Epoch: 1/2, step 1101/7134 completed (loss: 3.750997543334961, acc: 0.32307693362236023)
[2024-12-17 01:41:23,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:23,862][root][INFO] - Training Epoch: 1/2, step 1102/7134 completed (loss: 3.715381145477295, acc: 0.3263888955116272)
[2024-12-17 01:41:23,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,246][root][INFO] - Training Epoch: 1/2, step 1103/7134 completed (loss: 4.130213260650635, acc: 0.3154761791229248)
[2024-12-17 01:41:24,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,607][root][INFO] - Training Epoch: 1/2, step 1104/7134 completed (loss: 4.173075199127197, acc: 0.3199999928474426)
[2024-12-17 01:41:24,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:24,973][root][INFO] - Training Epoch: 1/2, step 1105/7134 completed (loss: 3.955596923828125, acc: 0.2839506268501282)
[2024-12-17 01:41:25,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,381][root][INFO] - Training Epoch: 1/2, step 1106/7134 completed (loss: 3.996936559677124, acc: 0.26490065455436707)
[2024-12-17 01:41:25,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:25,759][root][INFO] - Training Epoch: 1/2, step 1107/7134 completed (loss: 3.816941976547241, acc: 0.24444444477558136)
[2024-12-17 01:41:25,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,137][root][INFO] - Training Epoch: 1/2, step 1108/7134 completed (loss: 3.6046977043151855, acc: 0.3491124212741852)
[2024-12-17 01:41:26,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:26,586][root][INFO] - Training Epoch: 1/2, step 1109/7134 completed (loss: 3.718832492828369, acc: 0.2832369804382324)
[2024-12-17 01:41:26,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,056][root][INFO] - Training Epoch: 1/2, step 1110/7134 completed (loss: 3.8498222827911377, acc: 0.30645161867141724)
[2024-12-17 01:41:27,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,460][root][INFO] - Training Epoch: 1/2, step 1111/7134 completed (loss: 3.9851536750793457, acc: 0.33125001192092896)
[2024-12-17 01:41:27,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:27,862][root][INFO] - Training Epoch: 1/2, step 1112/7134 completed (loss: 3.710073709487915, acc: 0.3356643319129944)
[2024-12-17 01:41:27,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,252][root][INFO] - Training Epoch: 1/2, step 1113/7134 completed (loss: 4.041079044342041, acc: 0.30817610025405884)
[2024-12-17 01:41:28,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:28,662][root][INFO] - Training Epoch: 1/2, step 1114/7134 completed (loss: 3.9588468074798584, acc: 0.32275131344795227)
[2024-12-17 01:41:28,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,040][root][INFO] - Training Epoch: 1/2, step 1115/7134 completed (loss: 4.035126209259033, acc: 0.2709677517414093)
[2024-12-17 01:41:29,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,405][root][INFO] - Training Epoch: 1/2, step 1116/7134 completed (loss: 3.69008469581604, acc: 0.2926829159259796)
[2024-12-17 01:41:29,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:29,770][root][INFO] - Training Epoch: 1/2, step 1117/7134 completed (loss: 3.1246135234832764, acc: 0.40789473056793213)
[2024-12-17 01:41:29,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,161][root][INFO] - Training Epoch: 1/2, step 1118/7134 completed (loss: 3.84843111038208, acc: 0.23664122819900513)
[2024-12-17 01:41:30,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,542][root][INFO] - Training Epoch: 1/2, step 1119/7134 completed (loss: 3.3475987911224365, acc: 0.3103448152542114)
[2024-12-17 01:41:30,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:30,924][root][INFO] - Training Epoch: 1/2, step 1120/7134 completed (loss: 4.26500129699707, acc: 0.22900763154029846)
[2024-12-17 01:41:31,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,349][root][INFO] - Training Epoch: 1/2, step 1121/7134 completed (loss: 3.413602590560913, acc: 0.31612902879714966)
[2024-12-17 01:41:31,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:31,755][root][INFO] - Training Epoch: 1/2, step 1122/7134 completed (loss: 3.280482292175293, acc: 0.3153846263885498)
[2024-12-17 01:41:31,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,129][root][INFO] - Training Epoch: 1/2, step 1123/7134 completed (loss: 3.6811935901641846, acc: 0.3103448152542114)
[2024-12-17 01:41:32,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,508][root][INFO] - Training Epoch: 1/2, step 1124/7134 completed (loss: 4.0115966796875, acc: 0.30405405163764954)
[2024-12-17 01:41:32,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:32,904][root][INFO] - Training Epoch: 1/2, step 1125/7134 completed (loss: 3.7444353103637695, acc: 0.2976190447807312)
[2024-12-17 01:41:33,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,272][root][INFO] - Training Epoch: 1/2, step 1126/7134 completed (loss: 3.5345137119293213, acc: 0.3314606845378876)
[2024-12-17 01:41:33,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:33,639][root][INFO] - Training Epoch: 1/2, step 1127/7134 completed (loss: 3.9266586303710938, acc: 0.27941176295280457)
[2024-12-17 01:41:33,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,018][root][INFO] - Training Epoch: 1/2, step 1128/7134 completed (loss: 4.142570495605469, acc: 0.290076345205307)
[2024-12-17 01:41:34,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,397][root][INFO] - Training Epoch: 1/2, step 1129/7134 completed (loss: 3.792747735977173, acc: 0.32499998807907104)
[2024-12-17 01:41:34,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:34,782][root][INFO] - Training Epoch: 1/2, step 1130/7134 completed (loss: 3.61236572265625, acc: 0.316546767950058)
[2024-12-17 01:41:34,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,179][root][INFO] - Training Epoch: 1/2, step 1131/7134 completed (loss: 3.553919553756714, acc: 0.3484848439693451)
[2024-12-17 01:41:35,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,565][root][INFO] - Training Epoch: 1/2, step 1132/7134 completed (loss: 4.500813007354736, acc: 0.2751677930355072)
[2024-12-17 01:41:35,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:35,939][root][INFO] - Training Epoch: 1/2, step 1133/7134 completed (loss: 4.130985260009766, acc: 0.2774566411972046)
[2024-12-17 01:41:36,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,285][root][INFO] - Training Epoch: 1/2, step 1134/7134 completed (loss: 4.103871822357178, acc: 0.26923078298568726)
[2024-12-17 01:41:36,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:36,685][root][INFO] - Training Epoch: 1/2, step 1135/7134 completed (loss: 4.137503623962402, acc: 0.24832214415073395)
[2024-12-17 01:41:36,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,076][root][INFO] - Training Epoch: 1/2, step 1136/7134 completed (loss: 4.203050136566162, acc: 0.29591837525367737)
[2024-12-17 01:41:37,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,479][root][INFO] - Training Epoch: 1/2, step 1137/7134 completed (loss: 4.6134843826293945, acc: 0.21698112785816193)
[2024-12-17 01:41:37,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:37,894][root][INFO] - Training Epoch: 1/2, step 1138/7134 completed (loss: 3.912870168685913, acc: 0.2800000011920929)
[2024-12-17 01:41:38,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,292][root][INFO] - Training Epoch: 1/2, step 1139/7134 completed (loss: 4.1443891525268555, acc: 0.30219781398773193)
[2024-12-17 01:41:38,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:38,694][root][INFO] - Training Epoch: 1/2, step 1140/7134 completed (loss: 3.739906072616577, acc: 0.3052631616592407)
[2024-12-17 01:41:38,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,039][root][INFO] - Training Epoch: 1/2, step 1141/7134 completed (loss: 3.494951009750366, acc: 0.34545454382896423)
[2024-12-17 01:41:39,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,399][root][INFO] - Training Epoch: 1/2, step 1142/7134 completed (loss: 3.5319807529449463, acc: 0.28333333134651184)
[2024-12-17 01:41:39,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:39,782][root][INFO] - Training Epoch: 1/2, step 1143/7134 completed (loss: 3.8572704792022705, acc: 0.3192771077156067)
[2024-12-17 01:41:39,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,165][root][INFO] - Training Epoch: 1/2, step 1144/7134 completed (loss: 4.09290075302124, acc: 0.2916666567325592)
[2024-12-17 01:41:40,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,560][root][INFO] - Training Epoch: 1/2, step 1145/7134 completed (loss: 3.86311411857605, acc: 0.29608938097953796)
[2024-12-17 01:41:40,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:40,933][root][INFO] - Training Epoch: 1/2, step 1146/7134 completed (loss: 3.4227705001831055, acc: 0.35606059432029724)
[2024-12-17 01:41:41,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,317][root][INFO] - Training Epoch: 1/2, step 1147/7134 completed (loss: 3.668383836746216, acc: 0.318918913602829)
[2024-12-17 01:41:41,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:41,698][root][INFO] - Training Epoch: 1/2, step 1148/7134 completed (loss: 3.578132152557373, acc: 0.32374101877212524)
[2024-12-17 01:41:41,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,047][root][INFO] - Training Epoch: 1/2, step 1149/7134 completed (loss: 3.7220382690429688, acc: 0.3888888955116272)
[2024-12-17 01:41:42,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,416][root][INFO] - Training Epoch: 1/2, step 1150/7134 completed (loss: 3.968528985977173, acc: 0.3137255012989044)
[2024-12-17 01:41:42,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:42,852][root][INFO] - Training Epoch: 1/2, step 1151/7134 completed (loss: 3.9413626194000244, acc: 0.32773110270500183)
[2024-12-17 01:41:42,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,313][root][INFO] - Training Epoch: 1/2, step 1152/7134 completed (loss: 3.8628718852996826, acc: 0.30645161867141724)
[2024-12-17 01:41:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:43,693][root][INFO] - Training Epoch: 1/2, step 1153/7134 completed (loss: 4.098091125488281, acc: 0.2810457646846771)
[2024-12-17 01:41:43,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,071][root][INFO] - Training Epoch: 1/2, step 1154/7134 completed (loss: 3.780874729156494, acc: 0.375)
[2024-12-17 01:41:44,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,458][root][INFO] - Training Epoch: 1/2, step 1155/7134 completed (loss: 4.297870635986328, acc: 0.2735042870044708)
[2024-12-17 01:41:44,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:44,805][root][INFO] - Training Epoch: 1/2, step 1156/7134 completed (loss: 4.213336944580078, acc: 0.280303031206131)
[2024-12-17 01:41:44,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,195][root][INFO] - Training Epoch: 1/2, step 1157/7134 completed (loss: 3.8951008319854736, acc: 0.317241370677948)
[2024-12-17 01:41:45,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,580][root][INFO] - Training Epoch: 1/2, step 1158/7134 completed (loss: 4.330221652984619, acc: 0.208695650100708)
[2024-12-17 01:41:45,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:45,975][root][INFO] - Training Epoch: 1/2, step 1159/7134 completed (loss: 4.016769886016846, acc: 0.23952095210552216)
[2024-12-17 01:41:46,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,355][root][INFO] - Training Epoch: 1/2, step 1160/7134 completed (loss: 3.321376085281372, acc: 0.37654322385787964)
[2024-12-17 01:41:46,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:46,719][root][INFO] - Training Epoch: 1/2, step 1161/7134 completed (loss: 3.4946234226226807, acc: 0.32608696818351746)
[2024-12-17 01:41:46,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,098][root][INFO] - Training Epoch: 1/2, step 1162/7134 completed (loss: 3.9414796829223633, acc: 0.2848101258277893)
[2024-12-17 01:41:47,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,457][root][INFO] - Training Epoch: 1/2, step 1163/7134 completed (loss: 3.6878421306610107, acc: 0.2620689570903778)
[2024-12-17 01:41:47,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:47,832][root][INFO] - Training Epoch: 1/2, step 1164/7134 completed (loss: 3.5741586685180664, acc: 0.32044199109077454)
[2024-12-17 01:41:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,251][root][INFO] - Training Epoch: 1/2, step 1165/7134 completed (loss: 3.6435165405273438, acc: 0.3025641143321991)
[2024-12-17 01:41:48,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:48,648][root][INFO] - Training Epoch: 1/2, step 1166/7134 completed (loss: 3.7347607612609863, acc: 0.32446807622909546)
[2024-12-17 01:41:48,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,036][root][INFO] - Training Epoch: 1/2, step 1167/7134 completed (loss: 4.3488383293151855, acc: 0.2240000069141388)
[2024-12-17 01:41:49,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,464][root][INFO] - Training Epoch: 1/2, step 1168/7134 completed (loss: 3.804518222808838, acc: 0.2380952388048172)
[2024-12-17 01:41:49,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:49,843][root][INFO] - Training Epoch: 1/2, step 1169/7134 completed (loss: 3.8593504428863525, acc: 0.32446807622909546)
[2024-12-17 01:41:50,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,266][root][INFO] - Training Epoch: 1/2, step 1170/7134 completed (loss: 3.9577550888061523, acc: 0.2711864411830902)
[2024-12-17 01:41:50,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:50,691][root][INFO] - Training Epoch: 1/2, step 1171/7134 completed (loss: 4.53729772567749, acc: 0.23999999463558197)
[2024-12-17 01:41:50,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,079][root][INFO] - Training Epoch: 1/2, step 1172/7134 completed (loss: 3.892169713973999, acc: 0.3035714328289032)
[2024-12-17 01:41:51,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,428][root][INFO] - Training Epoch: 1/2, step 1173/7134 completed (loss: 3.83596134185791, acc: 0.2539682686328888)
[2024-12-17 01:41:51,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:51,812][root][INFO] - Training Epoch: 1/2, step 1174/7134 completed (loss: 3.456737995147705, acc: 0.3128834366798401)
[2024-12-17 01:41:51,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,231][root][INFO] - Training Epoch: 1/2, step 1175/7134 completed (loss: 4.12358283996582, acc: 0.24705882370471954)
[2024-12-17 01:41:52,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,615][root][INFO] - Training Epoch: 1/2, step 1176/7134 completed (loss: 3.8231658935546875, acc: 0.2569444477558136)
[2024-12-17 01:41:52,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:52,970][root][INFO] - Training Epoch: 1/2, step 1177/7134 completed (loss: 3.6500191688537598, acc: 0.2846153974533081)
[2024-12-17 01:41:53,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,348][root][INFO] - Training Epoch: 1/2, step 1178/7134 completed (loss: 4.010621070861816, acc: 0.25)
[2024-12-17 01:41:53,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:53,717][root][INFO] - Training Epoch: 1/2, step 1179/7134 completed (loss: 4.02738618850708, acc: 0.25)
[2024-12-17 01:41:53,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,113][root][INFO] - Training Epoch: 1/2, step 1180/7134 completed (loss: 3.742973566055298, acc: 0.2635135054588318)
[2024-12-17 01:41:54,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,507][root][INFO] - Training Epoch: 1/2, step 1181/7134 completed (loss: 3.5137252807617188, acc: 0.2967033088207245)
[2024-12-17 01:41:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:54,895][root][INFO] - Training Epoch: 1/2, step 1182/7134 completed (loss: 3.907236099243164, acc: 0.27210885286331177)
[2024-12-17 01:41:55,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,276][root][INFO] - Training Epoch: 1/2, step 1183/7134 completed (loss: 3.572619915008545, acc: 0.2601155936717987)
[2024-12-17 01:41:55,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:55,657][root][INFO] - Training Epoch: 1/2, step 1184/7134 completed (loss: 3.5705361366271973, acc: 0.27167630195617676)
[2024-12-17 01:41:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,049][root][INFO] - Training Epoch: 1/2, step 1185/7134 completed (loss: 3.4924020767211914, acc: 0.27878788113594055)
[2024-12-17 01:41:56,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,408][root][INFO] - Training Epoch: 1/2, step 1186/7134 completed (loss: 3.3226308822631836, acc: 0.32608696818351746)
[2024-12-17 01:41:56,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:56,792][root][INFO] - Training Epoch: 1/2, step 1187/7134 completed (loss: 3.620647668838501, acc: 0.2797619104385376)
[2024-12-17 01:41:56,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,172][root][INFO] - Training Epoch: 1/2, step 1188/7134 completed (loss: 3.4490184783935547, acc: 0.3494623601436615)
[2024-12-17 01:41:57,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,543][root][INFO] - Training Epoch: 1/2, step 1189/7134 completed (loss: 3.3050684928894043, acc: 0.3076923191547394)
[2024-12-17 01:41:57,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:57,912][root][INFO] - Training Epoch: 1/2, step 1190/7134 completed (loss: 3.732055425643921, acc: 0.36666667461395264)
[2024-12-17 01:41:58,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,309][root][INFO] - Training Epoch: 1/2, step 1191/7134 completed (loss: 3.665726661682129, acc: 0.3265306055545807)
[2024-12-17 01:41:58,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:58,708][root][INFO] - Training Epoch: 1/2, step 1192/7134 completed (loss: 4.278373718261719, acc: 0.27067670226097107)
[2024-12-17 01:41:58,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,106][root][INFO] - Training Epoch: 1/2, step 1193/7134 completed (loss: 4.418672561645508, acc: 0.24409449100494385)
[2024-12-17 01:41:59,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,487][root][INFO] - Training Epoch: 1/2, step 1194/7134 completed (loss: 3.743896007537842, acc: 0.3154362440109253)
[2024-12-17 01:41:59,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:41:59,878][root][INFO] - Training Epoch: 1/2, step 1195/7134 completed (loss: 4.138035774230957, acc: 0.32307693362236023)
[2024-12-17 01:42:00,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,254][root][INFO] - Training Epoch: 1/2, step 1196/7134 completed (loss: 3.7973010540008545, acc: 0.3120567500591278)
[2024-12-17 01:42:00,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,579][root][INFO] - Training Epoch: 1/2, step 1197/7134 completed (loss: 3.51993727684021, acc: 0.33561643958091736)
[2024-12-17 01:42:00,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:00,944][root][INFO] - Training Epoch: 1/2, step 1198/7134 completed (loss: 3.6084938049316406, acc: 0.3375000059604645)
[2024-12-17 01:42:01,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,359][root][INFO] - Training Epoch: 1/2, step 1199/7134 completed (loss: 3.3496944904327393, acc: 0.3896103799343109)
[2024-12-17 01:42:01,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:01,733][root][INFO] - Training Epoch: 1/2, step 1200/7134 completed (loss: 3.438019037246704, acc: 0.37383177876472473)
[2024-12-17 01:42:01,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,134][root][INFO] - Training Epoch: 1/2, step 1201/7134 completed (loss: 4.154647350311279, acc: 0.31446540355682373)
[2024-12-17 01:42:02,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,509][root][INFO] - Training Epoch: 1/2, step 1202/7134 completed (loss: 4.177944660186768, acc: 0.30978259444236755)
[2024-12-17 01:42:02,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:02,869][root][INFO] - Training Epoch: 1/2, step 1203/7134 completed (loss: 4.552023887634277, acc: 0.2199999988079071)
[2024-12-17 01:42:02,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,239][root][INFO] - Training Epoch: 1/2, step 1204/7134 completed (loss: 4.032649993896484, acc: 0.2647058963775635)
[2024-12-17 01:42:03,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,616][root][INFO] - Training Epoch: 1/2, step 1205/7134 completed (loss: 4.150671482086182, acc: 0.270114928483963)
[2024-12-17 01:42:03,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:03,994][root][INFO] - Training Epoch: 1/2, step 1206/7134 completed (loss: 4.255908966064453, acc: 0.25628140568733215)
[2024-12-17 01:42:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,393][root][INFO] - Training Epoch: 1/2, step 1207/7134 completed (loss: 4.159428119659424, acc: 0.2849462330341339)
[2024-12-17 01:42:04,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:04,817][root][INFO] - Training Epoch: 1/2, step 1208/7134 completed (loss: 4.368006229400635, acc: 0.290076345205307)
[2024-12-17 01:42:04,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,198][root][INFO] - Training Epoch: 1/2, step 1209/7134 completed (loss: 4.35152530670166, acc: 0.28688523173332214)
[2024-12-17 01:42:05,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,586][root][INFO] - Training Epoch: 1/2, step 1210/7134 completed (loss: 4.406799793243408, acc: 0.3400000035762787)
[2024-12-17 01:42:05,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:05,981][root][INFO] - Training Epoch: 1/2, step 1211/7134 completed (loss: 4.468911647796631, acc: 0.316546767950058)
[2024-12-17 01:42:06,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,362][root][INFO] - Training Epoch: 1/2, step 1212/7134 completed (loss: 4.849630355834961, acc: 0.30656933784484863)
[2024-12-17 01:42:06,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:06,722][root][INFO] - Training Epoch: 1/2, step 1213/7134 completed (loss: 4.133988380432129, acc: 0.2840236723423004)
[2024-12-17 01:42:06,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,102][root][INFO] - Training Epoch: 1/2, step 1214/7134 completed (loss: 4.504054546356201, acc: 0.24666666984558105)
[2024-12-17 01:42:07,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,498][root][INFO] - Training Epoch: 1/2, step 1215/7134 completed (loss: 4.352651596069336, acc: 0.29411765933036804)
[2024-12-17 01:42:07,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:07,872][root][INFO] - Training Epoch: 1/2, step 1216/7134 completed (loss: 4.212826251983643, acc: 0.26490065455436707)
[2024-12-17 01:42:07,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,258][root][INFO] - Training Epoch: 1/2, step 1217/7134 completed (loss: 3.8649075031280518, acc: 0.29605263471603394)
[2024-12-17 01:42:08,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:08,650][root][INFO] - Training Epoch: 1/2, step 1218/7134 completed (loss: 4.313981056213379, acc: 0.2750000059604645)
[2024-12-17 01:42:08,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,027][root][INFO] - Training Epoch: 1/2, step 1219/7134 completed (loss: 4.477097511291504, acc: 0.25999999046325684)
[2024-12-17 01:42:09,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,407][root][INFO] - Training Epoch: 1/2, step 1220/7134 completed (loss: 4.352603435516357, acc: 0.26288658380508423)
[2024-12-17 01:42:09,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:09,800][root][INFO] - Training Epoch: 1/2, step 1221/7134 completed (loss: 4.362324237823486, acc: 0.27149322628974915)
[2024-12-17 01:42:09,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,163][root][INFO] - Training Epoch: 1/2, step 1222/7134 completed (loss: 4.595418453216553, acc: 0.27184465527534485)
[2024-12-17 01:42:10,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,530][root][INFO] - Training Epoch: 1/2, step 1223/7134 completed (loss: 4.889488697052002, acc: 0.1818181872367859)
[2024-12-17 01:42:10,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:10,901][root][INFO] - Training Epoch: 1/2, step 1224/7134 completed (loss: 4.535863876342773, acc: 0.18867924809455872)
[2024-12-17 01:42:10,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,279][root][INFO] - Training Epoch: 1/2, step 1225/7134 completed (loss: 3.951643466949463, acc: 0.29680365324020386)
[2024-12-17 01:42:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:11,674][root][INFO] - Training Epoch: 1/2, step 1226/7134 completed (loss: 4.539805889129639, acc: 0.2222222238779068)
[2024-12-17 01:42:11,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,050][root][INFO] - Training Epoch: 1/2, step 1227/7134 completed (loss: 4.358600616455078, acc: 0.3195876181125641)
[2024-12-17 01:42:12,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,438][root][INFO] - Training Epoch: 1/2, step 1228/7134 completed (loss: 4.484729290008545, acc: 0.2383720874786377)
[2024-12-17 01:42:12,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:12,858][root][INFO] - Training Epoch: 1/2, step 1229/7134 completed (loss: 4.439002990722656, acc: 0.2772277295589447)
[2024-12-17 01:42:12,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,264][root][INFO] - Training Epoch: 1/2, step 1230/7134 completed (loss: 4.23268985748291, acc: 0.2688679099082947)
[2024-12-17 01:42:13,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:13,713][root][INFO] - Training Epoch: 1/2, step 1231/7134 completed (loss: 4.231593608856201, acc: 0.2284482717514038)
[2024-12-17 01:42:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,119][root][INFO] - Training Epoch: 1/2, step 1232/7134 completed (loss: 4.076013565063477, acc: 0.25112107396125793)
[2024-12-17 01:42:14,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,506][root][INFO] - Training Epoch: 1/2, step 1233/7134 completed (loss: 4.061540603637695, acc: 0.33936652541160583)
[2024-12-17 01:42:14,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:14,922][root][INFO] - Training Epoch: 1/2, step 1234/7134 completed (loss: 4.321470737457275, acc: 0.2628205120563507)
[2024-12-17 01:42:15,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,312][root][INFO] - Training Epoch: 1/2, step 1235/7134 completed (loss: 4.091793537139893, acc: 0.2857142984867096)
[2024-12-17 01:42:15,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:15,693][root][INFO] - Training Epoch: 1/2, step 1236/7134 completed (loss: 4.198461532592773, acc: 0.2647058963775635)
[2024-12-17 01:42:15,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,088][root][INFO] - Training Epoch: 1/2, step 1237/7134 completed (loss: 3.990856409072876, acc: 0.22516556084156036)
[2024-12-17 01:42:16,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,467][root][INFO] - Training Epoch: 1/2, step 1238/7134 completed (loss: 4.214039325714111, acc: 0.367441862821579)
[2024-12-17 01:42:16,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:16,859][root][INFO] - Training Epoch: 1/2, step 1239/7134 completed (loss: 4.244714736938477, acc: 0.27439025044441223)
[2024-12-17 01:42:16,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,266][root][INFO] - Training Epoch: 1/2, step 1240/7134 completed (loss: 4.196746349334717, acc: 0.302325576543808)
[2024-12-17 01:42:17,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:17,669][root][INFO] - Training Epoch: 1/2, step 1241/7134 completed (loss: 4.741986274719238, acc: 0.2950819730758667)
[2024-12-17 01:42:17,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,069][root][INFO] - Training Epoch: 1/2, step 1242/7134 completed (loss: 3.984248161315918, acc: 0.30890053510665894)
[2024-12-17 01:42:18,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,485][root][INFO] - Training Epoch: 1/2, step 1243/7134 completed (loss: 3.933171510696411, acc: 0.3333333432674408)
[2024-12-17 01:42:18,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:18,881][root][INFO] - Training Epoch: 1/2, step 1244/7134 completed (loss: 4.380482196807861, acc: 0.246478870511055)
[2024-12-17 01:42:18,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,260][root][INFO] - Training Epoch: 1/2, step 1245/7134 completed (loss: 3.821033000946045, acc: 0.3080808222293854)
[2024-12-17 01:42:19,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:19,648][root][INFO] - Training Epoch: 1/2, step 1246/7134 completed (loss: 4.390137672424316, acc: 0.28421053290367126)
[2024-12-17 01:42:19,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,074][root][INFO] - Training Epoch: 1/2, step 1247/7134 completed (loss: 3.889768600463867, acc: 0.3313252925872803)
[2024-12-17 01:42:20,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,453][root][INFO] - Training Epoch: 1/2, step 1248/7134 completed (loss: 4.198620796203613, acc: 0.3400000035762787)
[2024-12-17 01:42:20,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:20,870][root][INFO] - Training Epoch: 1/2, step 1249/7134 completed (loss: 4.163744926452637, acc: 0.2844827473163605)
[2024-12-17 01:42:20,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,239][root][INFO] - Training Epoch: 1/2, step 1250/7134 completed (loss: 3.920386552810669, acc: 0.2133333384990692)
[2024-12-17 01:42:21,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,613][root][INFO] - Training Epoch: 1/2, step 1251/7134 completed (loss: 4.188235282897949, acc: 0.28484848141670227)
[2024-12-17 01:42:21,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:21,989][root][INFO] - Training Epoch: 1/2, step 1252/7134 completed (loss: 4.739324569702148, acc: 0.24409449100494385)
[2024-12-17 01:42:22,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,417][root][INFO] - Training Epoch: 1/2, step 1253/7134 completed (loss: 4.161920070648193, acc: 0.34188035130500793)
[2024-12-17 01:42:22,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:22,826][root][INFO] - Training Epoch: 1/2, step 1254/7134 completed (loss: 3.9879963397979736, acc: 0.3400000035762787)
[2024-12-17 01:42:22,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,245][root][INFO] - Training Epoch: 1/2, step 1255/7134 completed (loss: 4.089328765869141, acc: 0.30344828963279724)
[2024-12-17 01:42:23,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,629][root][INFO] - Training Epoch: 1/2, step 1256/7134 completed (loss: 4.168516159057617, acc: 0.25954198837280273)
[2024-12-17 01:42:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:23,995][root][INFO] - Training Epoch: 1/2, step 1257/7134 completed (loss: 3.7531893253326416, acc: 0.30534350872039795)
[2024-12-17 01:42:24,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:24,354][root][INFO] - Training Epoch: 1/2, step 1258/7134 completed (loss: 3.407302141189575, acc: 0.369047611951828)
[2024-12-17 01:42:24,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:24,749][root][INFO] - Training Epoch: 1/2, step 1259/7134 completed (loss: 3.801241636276245, acc: 0.3173076808452606)
[2024-12-17 01:42:24,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:25,183][root][INFO] - Training Epoch: 1/2, step 1260/7134 completed (loss: 3.9150853157043457, acc: 0.3087248206138611)
[2024-12-17 01:42:25,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:25,618][root][INFO] - Training Epoch: 1/2, step 1261/7134 completed (loss: 4.10190486907959, acc: 0.2432432472705841)
[2024-12-17 01:42:25,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,020][root][INFO] - Training Epoch: 1/2, step 1262/7134 completed (loss: 3.8563499450683594, acc: 0.22480620443820953)
[2024-12-17 01:42:26,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,381][root][INFO] - Training Epoch: 1/2, step 1263/7134 completed (loss: 3.3830506801605225, acc: 0.3290322721004486)
[2024-12-17 01:42:26,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:26,807][root][INFO] - Training Epoch: 1/2, step 1264/7134 completed (loss: 4.185214996337891, acc: 0.2518518567085266)
[2024-12-17 01:42:26,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:27,255][root][INFO] - Training Epoch: 1/2, step 1265/7134 completed (loss: 3.3841705322265625, acc: 0.33714285492897034)
[2024-12-17 01:42:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:27,716][root][INFO] - Training Epoch: 1/2, step 1266/7134 completed (loss: 3.165396213531494, acc: 0.4122137427330017)
[2024-12-17 01:42:27,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:28,136][root][INFO] - Training Epoch: 1/2, step 1267/7134 completed (loss: 3.7044951915740967, acc: 0.3246753215789795)
[2024-12-17 01:42:28,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:28,531][root][INFO] - Training Epoch: 1/2, step 1268/7134 completed (loss: 4.345632076263428, acc: 0.28148147463798523)
[2024-12-17 01:42:28,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:28,941][root][INFO] - Training Epoch: 1/2, step 1269/7134 completed (loss: 3.796477794647217, acc: 0.3333333432674408)
[2024-12-17 01:42:29,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,342][root][INFO] - Training Epoch: 1/2, step 1270/7134 completed (loss: 3.9817593097686768, acc: 0.31506848335266113)
[2024-12-17 01:42:29,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:29,759][root][INFO] - Training Epoch: 1/2, step 1271/7134 completed (loss: 3.6767454147338867, acc: 0.32499998807907104)
[2024-12-17 01:42:29,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,223][root][INFO] - Training Epoch: 1/2, step 1272/7134 completed (loss: 3.581775188446045, acc: 0.3333333432674408)
[2024-12-17 01:42:30,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:30,650][root][INFO] - Training Epoch: 1/2, step 1273/7134 completed (loss: 4.070441722869873, acc: 0.3037036955356598)
[2024-12-17 01:42:30,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,054][root][INFO] - Training Epoch: 1/2, step 1274/7134 completed (loss: 3.6541666984558105, acc: 0.27272728085517883)
[2024-12-17 01:42:31,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,472][root][INFO] - Training Epoch: 1/2, step 1275/7134 completed (loss: 3.818455219268799, acc: 0.30434781312942505)
[2024-12-17 01:42:31,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:31,893][root][INFO] - Training Epoch: 1/2, step 1276/7134 completed (loss: 3.4799532890319824, acc: 0.32575756311416626)
[2024-12-17 01:42:32,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,312][root][INFO] - Training Epoch: 1/2, step 1277/7134 completed (loss: 3.761030673980713, acc: 0.3239436745643616)
[2024-12-17 01:42:32,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:32,736][root][INFO] - Training Epoch: 1/2, step 1278/7134 completed (loss: 4.630227088928223, acc: 0.2750000059604645)
[2024-12-17 01:42:32,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,108][root][INFO] - Training Epoch: 1/2, step 1279/7134 completed (loss: 3.8930511474609375, acc: 0.30978259444236755)
[2024-12-17 01:42:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,549][root][INFO] - Training Epoch: 1/2, step 1280/7134 completed (loss: 4.061933994293213, acc: 0.27807486057281494)
[2024-12-17 01:42:33,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:33,910][root][INFO] - Training Epoch: 1/2, step 1281/7134 completed (loss: 4.254095077514648, acc: 0.28787878155708313)
[2024-12-17 01:42:34,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,286][root][INFO] - Training Epoch: 1/2, step 1282/7134 completed (loss: 4.127617835998535, acc: 0.2950819730758667)
[2024-12-17 01:42:34,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:34,675][root][INFO] - Training Epoch: 1/2, step 1283/7134 completed (loss: 4.004129886627197, acc: 0.3178294599056244)
[2024-12-17 01:42:34,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,058][root][INFO] - Training Epoch: 1/2, step 1284/7134 completed (loss: 4.079705238342285, acc: 0.23353293538093567)
[2024-12-17 01:42:35,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,444][root][INFO] - Training Epoch: 1/2, step 1285/7134 completed (loss: 4.001410484313965, acc: 0.23125000298023224)
[2024-12-17 01:42:35,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:35,830][root][INFO] - Training Epoch: 1/2, step 1286/7134 completed (loss: 3.6740026473999023, acc: 0.3658536672592163)
[2024-12-17 01:42:35,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,218][root][INFO] - Training Epoch: 1/2, step 1287/7134 completed (loss: 4.064464092254639, acc: 0.28148147463798523)
[2024-12-17 01:42:36,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,612][root][INFO] - Training Epoch: 1/2, step 1288/7134 completed (loss: 3.8526787757873535, acc: 0.3108808398246765)
[2024-12-17 01:42:36,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:36,992][root][INFO] - Training Epoch: 1/2, step 1289/7134 completed (loss: 3.821023464202881, acc: 0.32413792610168457)
[2024-12-17 01:42:37,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,363][root][INFO] - Training Epoch: 1/2, step 1290/7134 completed (loss: 3.6725687980651855, acc: 0.299401193857193)
[2024-12-17 01:42:37,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:37,761][root][INFO] - Training Epoch: 1/2, step 1291/7134 completed (loss: 3.5276737213134766, acc: 0.3235294222831726)
[2024-12-17 01:42:37,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,123][root][INFO] - Training Epoch: 1/2, step 1292/7134 completed (loss: 3.897681951522827, acc: 0.28021979331970215)
[2024-12-17 01:42:38,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,486][root][INFO] - Training Epoch: 1/2, step 1293/7134 completed (loss: 4.286830425262451, acc: 0.25641027092933655)
[2024-12-17 01:42:38,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:38,885][root][INFO] - Training Epoch: 1/2, step 1294/7134 completed (loss: 4.0064697265625, acc: 0.2786885201931)
[2024-12-17 01:42:39,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,269][root][INFO] - Training Epoch: 1/2, step 1295/7134 completed (loss: 4.238059997558594, acc: 0.2537313401699066)
[2024-12-17 01:42:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:39,683][root][INFO] - Training Epoch: 1/2, step 1296/7134 completed (loss: 4.272454738616943, acc: 0.2211538404226303)
[2024-12-17 01:42:39,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,060][root][INFO] - Training Epoch: 1/2, step 1297/7134 completed (loss: 4.345426082611084, acc: 0.3035714328289032)
[2024-12-17 01:42:40,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,452][root][INFO] - Training Epoch: 1/2, step 1298/7134 completed (loss: 4.201430320739746, acc: 0.22314049303531647)
[2024-12-17 01:42:40,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:40,839][root][INFO] - Training Epoch: 1/2, step 1299/7134 completed (loss: 3.9296631813049316, acc: 0.3253012001514435)
[2024-12-17 01:42:40,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,267][root][INFO] - Training Epoch: 1/2, step 1300/7134 completed (loss: 3.79349684715271, acc: 0.2574257552623749)
[2024-12-17 01:42:41,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:41,650][root][INFO] - Training Epoch: 1/2, step 1301/7134 completed (loss: 3.755307674407959, acc: 0.2434210479259491)
[2024-12-17 01:42:41,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,040][root][INFO] - Training Epoch: 1/2, step 1302/7134 completed (loss: 3.4201207160949707, acc: 0.3465346395969391)
[2024-12-17 01:42:42,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,446][root][INFO] - Training Epoch: 1/2, step 1303/7134 completed (loss: 3.845313787460327, acc: 0.3100000023841858)
[2024-12-17 01:42:42,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:42,822][root][INFO] - Training Epoch: 1/2, step 1304/7134 completed (loss: 3.8145411014556885, acc: 0.2542372941970825)
[2024-12-17 01:42:42,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,214][root][INFO] - Training Epoch: 1/2, step 1305/7134 completed (loss: 3.9253125190734863, acc: 0.2525773048400879)
[2024-12-17 01:42:43,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:43,657][root][INFO] - Training Epoch: 1/2, step 1306/7134 completed (loss: 3.9547481536865234, acc: 0.30263158679008484)
[2024-12-17 01:42:43,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,058][root][INFO] - Training Epoch: 1/2, step 1307/7134 completed (loss: 4.141414165496826, acc: 0.2589927911758423)
[2024-12-17 01:42:44,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,422][root][INFO] - Training Epoch: 1/2, step 1308/7134 completed (loss: 4.185419082641602, acc: 0.26451611518859863)
[2024-12-17 01:42:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:44,797][root][INFO] - Training Epoch: 1/2, step 1309/7134 completed (loss: 4.1969780921936035, acc: 0.27053138613700867)
[2024-12-17 01:42:44,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,179][root][INFO] - Training Epoch: 1/2, step 1310/7134 completed (loss: 4.042304515838623, acc: 0.31491711735725403)
[2024-12-17 01:42:45,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:45,606][root][INFO] - Training Epoch: 1/2, step 1311/7134 completed (loss: 4.0854668617248535, acc: 0.25)
[2024-12-17 01:42:45,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,004][root][INFO] - Training Epoch: 1/2, step 1312/7134 completed (loss: 4.05776309967041, acc: 0.2981366515159607)
[2024-12-17 01:42:46,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,414][root][INFO] - Training Epoch: 1/2, step 1313/7134 completed (loss: 3.926170825958252, acc: 0.34567901492118835)
[2024-12-17 01:42:46,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:46,805][root][INFO] - Training Epoch: 1/2, step 1314/7134 completed (loss: 3.8807663917541504, acc: 0.2971014380455017)
[2024-12-17 01:42:46,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,220][root][INFO] - Training Epoch: 1/2, step 1315/7134 completed (loss: 3.9606966972351074, acc: 0.34594595432281494)
[2024-12-17 01:42:47,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:47,663][root][INFO] - Training Epoch: 1/2, step 1316/7134 completed (loss: 4.2268147468566895, acc: 0.24390244483947754)
[2024-12-17 01:42:47,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,032][root][INFO] - Training Epoch: 1/2, step 1317/7134 completed (loss: 4.294566631317139, acc: 0.2537313401699066)
[2024-12-17 01:42:48,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,419][root][INFO] - Training Epoch: 1/2, step 1318/7134 completed (loss: 3.9776782989501953, acc: 0.2857142984867096)
[2024-12-17 01:42:48,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:48,761][root][INFO] - Training Epoch: 1/2, step 1319/7134 completed (loss: 4.13950252532959, acc: 0.290909081697464)
[2024-12-17 01:42:48,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,102][root][INFO] - Training Epoch: 1/2, step 1320/7134 completed (loss: 4.043705940246582, acc: 0.34437087178230286)
[2024-12-17 01:42:49,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,498][root][INFO] - Training Epoch: 1/2, step 1321/7134 completed (loss: 3.893524646759033, acc: 0.3056994676589966)
[2024-12-17 01:42:49,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:49,862][root][INFO] - Training Epoch: 1/2, step 1322/7134 completed (loss: 3.974616527557373, acc: 0.30612245202064514)
[2024-12-17 01:42:49,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,225][root][INFO] - Training Epoch: 1/2, step 1323/7134 completed (loss: 4.07350492477417, acc: 0.246478870511055)
[2024-12-17 01:42:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:50,616][root][INFO] - Training Epoch: 1/2, step 1324/7134 completed (loss: 3.687018871307373, acc: 0.3333333432674408)
[2024-12-17 01:42:50,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,044][root][INFO] - Training Epoch: 1/2, step 1325/7134 completed (loss: 4.190359115600586, acc: 0.28155338764190674)
[2024-12-17 01:42:51,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,421][root][INFO] - Training Epoch: 1/2, step 1326/7134 completed (loss: 3.5171329975128174, acc: 0.3607305884361267)
[2024-12-17 01:42:51,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:51,799][root][INFO] - Training Epoch: 1/2, step 1327/7134 completed (loss: 3.5943808555603027, acc: 0.3195266127586365)
[2024-12-17 01:42:51,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,150][root][INFO] - Training Epoch: 1/2, step 1328/7134 completed (loss: 4.355918884277344, acc: 0.21782177686691284)
[2024-12-17 01:42:52,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,553][root][INFO] - Training Epoch: 1/2, step 1329/7134 completed (loss: 3.9129629135131836, acc: 0.33000001311302185)
[2024-12-17 01:42:52,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:52,912][root][INFO] - Training Epoch: 1/2, step 1330/7134 completed (loss: 3.8167552947998047, acc: 0.32374101877212524)
[2024-12-17 01:42:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,269][root][INFO] - Training Epoch: 1/2, step 1331/7134 completed (loss: 3.5840277671813965, acc: 0.34507042169570923)
[2024-12-17 01:42:53,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:53,662][root][INFO] - Training Epoch: 1/2, step 1332/7134 completed (loss: 3.8108971118927, acc: 0.25438597798347473)
[2024-12-17 01:42:53,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,054][root][INFO] - Training Epoch: 1/2, step 1333/7134 completed (loss: 4.030559539794922, acc: 0.2697368562221527)
[2024-12-17 01:42:54,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,450][root][INFO] - Training Epoch: 1/2, step 1334/7134 completed (loss: 4.675168991088867, acc: 0.22839505970478058)
[2024-12-17 01:42:54,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:54,835][root][INFO] - Training Epoch: 1/2, step 1335/7134 completed (loss: 3.7882306575775146, acc: 0.35078534483909607)
[2024-12-17 01:42:54,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,224][root][INFO] - Training Epoch: 1/2, step 1336/7134 completed (loss: 3.837928056716919, acc: 0.2513369023799896)
[2024-12-17 01:42:55,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,632][root][INFO] - Training Epoch: 1/2, step 1337/7134 completed (loss: 3.8628182411193848, acc: 0.3612903356552124)
[2024-12-17 01:42:55,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:55,999][root][INFO] - Training Epoch: 1/2, step 1338/7134 completed (loss: 4.142383575439453, acc: 0.328125)
[2024-12-17 01:42:56,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,356][root][INFO] - Training Epoch: 1/2, step 1339/7134 completed (loss: 3.7785308361053467, acc: 0.3877550959587097)
[2024-12-17 01:42:56,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:56,718][root][INFO] - Training Epoch: 1/2, step 1340/7134 completed (loss: 4.487067699432373, acc: 0.27272728085517883)
[2024-12-17 01:42:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,107][root][INFO] - Training Epoch: 1/2, step 1341/7134 completed (loss: 3.998316526412964, acc: 0.24175824224948883)
[2024-12-17 01:42:57,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,502][root][INFO] - Training Epoch: 1/2, step 1342/7134 completed (loss: 3.5989391803741455, acc: 0.33774834871292114)
[2024-12-17 01:42:57,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:57,861][root][INFO] - Training Epoch: 1/2, step 1343/7134 completed (loss: 4.386056900024414, acc: 0.31617647409439087)
[2024-12-17 01:42:57,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,193][root][INFO] - Training Epoch: 1/2, step 1344/7134 completed (loss: 3.9044225215911865, acc: 0.24770642817020416)
[2024-12-17 01:42:58,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:58,544][root][INFO] - Training Epoch: 1/2, step 1345/7134 completed (loss: 4.378293991088867, acc: 0.2795698940753937)
[2024-12-17 01:42:58,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,010][root][INFO] - Training Epoch: 1/2, step 1346/7134 completed (loss: 3.9275453090667725, acc: 0.30054643750190735)
[2024-12-17 01:42:59,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,364][root][INFO] - Training Epoch: 1/2, step 1347/7134 completed (loss: 3.983194589614868, acc: 0.2708333432674408)
[2024-12-17 01:42:59,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:42:59,736][root][INFO] - Training Epoch: 1/2, step 1348/7134 completed (loss: 3.6622583866119385, acc: 0.3535911738872528)
[2024-12-17 01:42:59,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,117][root][INFO] - Training Epoch: 1/2, step 1349/7134 completed (loss: 3.568767547607422, acc: 0.3333333432674408)
[2024-12-17 01:43:00,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,484][root][INFO] - Training Epoch: 1/2, step 1350/7134 completed (loss: 3.6102211475372314, acc: 0.257485032081604)
[2024-12-17 01:43:00,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:00,868][root][INFO] - Training Epoch: 1/2, step 1351/7134 completed (loss: 3.6630332469940186, acc: 0.3166666626930237)
[2024-12-17 01:43:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,266][root][INFO] - Training Epoch: 1/2, step 1352/7134 completed (loss: 3.7255380153656006, acc: 0.24390244483947754)
[2024-12-17 01:43:01,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:01,660][root][INFO] - Training Epoch: 1/2, step 1353/7134 completed (loss: 3.5113210678100586, acc: 0.32499998807907104)
[2024-12-17 01:43:01,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,052][root][INFO] - Training Epoch: 1/2, step 1354/7134 completed (loss: 3.4609131813049316, acc: 0.2933333218097687)
[2024-12-17 01:43:02,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,397][root][INFO] - Training Epoch: 1/2, step 1355/7134 completed (loss: 3.291238784790039, acc: 0.35483869910240173)
[2024-12-17 01:43:02,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:02,790][root][INFO] - Training Epoch: 1/2, step 1356/7134 completed (loss: 3.338386058807373, acc: 0.34302327036857605)
[2024-12-17 01:43:02,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,189][root][INFO] - Training Epoch: 1/2, step 1357/7134 completed (loss: 3.382326364517212, acc: 0.3333333432674408)
[2024-12-17 01:43:03,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:03,618][root][INFO] - Training Epoch: 1/2, step 1358/7134 completed (loss: 3.6622910499572754, acc: 0.28977271914482117)
[2024-12-17 01:43:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,038][root][INFO] - Training Epoch: 1/2, step 1359/7134 completed (loss: 3.198284387588501, acc: 0.3471074402332306)
[2024-12-17 01:43:04,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,426][root][INFO] - Training Epoch: 1/2, step 1360/7134 completed (loss: 3.6727190017700195, acc: 0.2738095223903656)
[2024-12-17 01:43:04,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:04,875][root][INFO] - Training Epoch: 1/2, step 1361/7134 completed (loss: 3.8075063228607178, acc: 0.27218934893608093)
[2024-12-17 01:43:04,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,261][root][INFO] - Training Epoch: 1/2, step 1362/7134 completed (loss: 3.9056975841522217, acc: 0.2786885201931)
[2024-12-17 01:43:05,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:05,662][root][INFO] - Training Epoch: 1/2, step 1363/7134 completed (loss: 3.6171629428863525, acc: 0.3103448152542114)
[2024-12-17 01:43:05,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,049][root][INFO] - Training Epoch: 1/2, step 1364/7134 completed (loss: 3.5782742500305176, acc: 0.29411765933036804)
[2024-12-17 01:43:06,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,430][root][INFO] - Training Epoch: 1/2, step 1365/7134 completed (loss: 3.340259552001953, acc: 0.34074074029922485)
[2024-12-17 01:43:06,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:06,855][root][INFO] - Training Epoch: 1/2, step 1366/7134 completed (loss: 3.698775291442871, acc: 0.2520325183868408)
[2024-12-17 01:43:06,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,246][root][INFO] - Training Epoch: 1/2, step 1367/7134 completed (loss: 3.7431929111480713, acc: 0.2647058963775635)
[2024-12-17 01:43:07,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:07,673][root][INFO] - Training Epoch: 1/2, step 1368/7134 completed (loss: 3.733609676361084, acc: 0.2931034564971924)
[2024-12-17 01:43:07,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,065][root][INFO] - Training Epoch: 1/2, step 1369/7134 completed (loss: 3.528069019317627, acc: 0.31386861205101013)
[2024-12-17 01:43:08,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,468][root][INFO] - Training Epoch: 1/2, step 1370/7134 completed (loss: 3.570418119430542, acc: 0.25)
[2024-12-17 01:43:08,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:08,845][root][INFO] - Training Epoch: 1/2, step 1371/7134 completed (loss: 3.3218319416046143, acc: 0.3580246865749359)
[2024-12-17 01:43:08,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,214][root][INFO] - Training Epoch: 1/2, step 1372/7134 completed (loss: 3.7945261001586914, acc: 0.32575756311416626)
[2024-12-17 01:43:09,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:09,598][root][INFO] - Training Epoch: 1/2, step 1373/7134 completed (loss: 3.905325412750244, acc: 0.25581395626068115)
[2024-12-17 01:43:09,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,010][root][INFO] - Training Epoch: 1/2, step 1374/7134 completed (loss: 4.453441143035889, acc: 0.30000001192092896)
[2024-12-17 01:43:10,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,397][root][INFO] - Training Epoch: 1/2, step 1375/7134 completed (loss: 3.925760269165039, acc: 0.28431373834609985)
[2024-12-17 01:43:10,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:10,775][root][INFO] - Training Epoch: 1/2, step 1376/7134 completed (loss: 4.743768215179443, acc: 0.25)
[2024-12-17 01:43:10,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,178][root][INFO] - Training Epoch: 1/2, step 1377/7134 completed (loss: 4.470766067504883, acc: 0.28431373834609985)
[2024-12-17 01:43:11,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,505][root][INFO] - Training Epoch: 1/2, step 1378/7134 completed (loss: 4.630504131317139, acc: 0.2884615361690521)
[2024-12-17 01:43:11,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:11,847][root][INFO] - Training Epoch: 1/2, step 1379/7134 completed (loss: 4.4578328132629395, acc: 0.2970297038555145)
[2024-12-17 01:43:11,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,245][root][INFO] - Training Epoch: 1/2, step 1380/7134 completed (loss: 4.439263820648193, acc: 0.23148147761821747)
[2024-12-17 01:43:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:12,705][root][INFO] - Training Epoch: 1/2, step 1381/7134 completed (loss: 4.336061000823975, acc: 0.18840579688549042)
[2024-12-17 01:43:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,107][root][INFO] - Training Epoch: 1/2, step 1382/7134 completed (loss: 4.573747158050537, acc: 0.30000001192092896)
[2024-12-17 01:43:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,522][root][INFO] - Training Epoch: 1/2, step 1383/7134 completed (loss: 4.471104621887207, acc: 0.2867647111415863)
[2024-12-17 01:43:13,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:13,909][root][INFO] - Training Epoch: 1/2, step 1384/7134 completed (loss: 4.769460201263428, acc: 0.25531914830207825)
[2024-12-17 01:43:14,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,291][root][INFO] - Training Epoch: 1/2, step 1385/7134 completed (loss: 5.060315132141113, acc: 0.25600001215934753)
[2024-12-17 01:43:14,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:14,696][root][INFO] - Training Epoch: 1/2, step 1386/7134 completed (loss: 4.211346626281738, acc: 0.30985915660858154)
[2024-12-17 01:43:14,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,078][root][INFO] - Training Epoch: 1/2, step 1387/7134 completed (loss: 4.284618377685547, acc: 0.2937062978744507)
[2024-12-17 01:43:15,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,467][root][INFO] - Training Epoch: 1/2, step 1388/7134 completed (loss: 4.755701541900635, acc: 0.2240000069141388)
[2024-12-17 01:43:15,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:15,845][root][INFO] - Training Epoch: 1/2, step 1389/7134 completed (loss: 4.850079536437988, acc: 0.21641790866851807)
[2024-12-17 01:43:15,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,235][root][INFO] - Training Epoch: 1/2, step 1390/7134 completed (loss: 4.8636908531188965, acc: 0.21897810697555542)
[2024-12-17 01:43:16,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,619][root][INFO] - Training Epoch: 1/2, step 1391/7134 completed (loss: 4.340889930725098, acc: 0.3014705777168274)
[2024-12-17 01:43:16,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:16,998][root][INFO] - Training Epoch: 1/2, step 1392/7134 completed (loss: 4.729565143585205, acc: 0.23577235639095306)
[2024-12-17 01:43:17,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,408][root][INFO] - Training Epoch: 1/2, step 1393/7134 completed (loss: 4.416009426116943, acc: 0.2708333432674408)
[2024-12-17 01:43:17,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:17,826][root][INFO] - Training Epoch: 1/2, step 1394/7134 completed (loss: 4.833057880401611, acc: 0.25471699237823486)
[2024-12-17 01:43:17,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,232][root][INFO] - Training Epoch: 1/2, step 1395/7134 completed (loss: 4.236320495605469, acc: 0.296875)
[2024-12-17 01:43:18,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:18,664][root][INFO] - Training Epoch: 1/2, step 1396/7134 completed (loss: 3.8481998443603516, acc: 0.3440000116825104)
[2024-12-17 01:43:18,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,049][root][INFO] - Training Epoch: 1/2, step 1397/7134 completed (loss: 4.595063209533691, acc: 0.2702702581882477)
[2024-12-17 01:43:19,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,424][root][INFO] - Training Epoch: 1/2, step 1398/7134 completed (loss: 4.2635345458984375, acc: 0.2970297038555145)
[2024-12-17 01:43:19,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:19,817][root][INFO] - Training Epoch: 1/2, step 1399/7134 completed (loss: 4.316732406616211, acc: 0.22302158176898956)
[2024-12-17 01:43:19,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,202][root][INFO] - Training Epoch: 1/2, step 1400/7134 completed (loss: 4.3505401611328125, acc: 0.28985506296157837)
[2024-12-17 01:43:20,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:20,684][root][INFO] - Training Epoch: 1/2, step 1401/7134 completed (loss: 4.100193023681641, acc: 0.3037036955356598)
[2024-12-17 01:43:20,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,080][root][INFO] - Training Epoch: 1/2, step 1402/7134 completed (loss: 4.124185085296631, acc: 0.26119402050971985)
[2024-12-17 01:43:21,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,488][root][INFO] - Training Epoch: 1/2, step 1403/7134 completed (loss: 3.897740364074707, acc: 0.24852071702480316)
[2024-12-17 01:43:21,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:21,894][root][INFO] - Training Epoch: 1/2, step 1404/7134 completed (loss: 3.6959784030914307, acc: 0.2797619104385376)
[2024-12-17 01:43:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,303][root][INFO] - Training Epoch: 1/2, step 1405/7134 completed (loss: 3.6847352981567383, acc: 0.3273809552192688)
[2024-12-17 01:43:22,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:22,721][root][INFO] - Training Epoch: 1/2, step 1406/7134 completed (loss: 3.616105556488037, acc: 0.31677019596099854)
[2024-12-17 01:43:22,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,135][root][INFO] - Training Epoch: 1/2, step 1407/7134 completed (loss: 4.180838108062744, acc: 0.29651162028312683)
[2024-12-17 01:43:23,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:23,604][root][INFO] - Training Epoch: 1/2, step 1408/7134 completed (loss: 4.025327682495117, acc: 0.27586206793785095)
[2024-12-17 01:43:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,019][root][INFO] - Training Epoch: 1/2, step 1409/7134 completed (loss: 3.6154181957244873, acc: 0.30188679695129395)
[2024-12-17 01:43:24,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,441][root][INFO] - Training Epoch: 1/2, step 1410/7134 completed (loss: 3.8717217445373535, acc: 0.2707182466983795)
[2024-12-17 01:43:24,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:24,834][root][INFO] - Training Epoch: 1/2, step 1411/7134 completed (loss: 3.947997808456421, acc: 0.2514285743236542)
[2024-12-17 01:43:24,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,211][root][INFO] - Training Epoch: 1/2, step 1412/7134 completed (loss: 3.5903737545013428, acc: 0.3210526406764984)
[2024-12-17 01:43:25,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:25,631][root][INFO] - Training Epoch: 1/2, step 1413/7134 completed (loss: 3.6948084831237793, acc: 0.3053892254829407)
[2024-12-17 01:43:25,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,096][root][INFO] - Training Epoch: 1/2, step 1414/7134 completed (loss: 3.6691360473632812, acc: 0.3245033025741577)
[2024-12-17 01:43:26,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,508][root][INFO] - Training Epoch: 1/2, step 1415/7134 completed (loss: 3.7570831775665283, acc: 0.32116788625717163)
[2024-12-17 01:43:26,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:26,927][root][INFO] - Training Epoch: 1/2, step 1416/7134 completed (loss: 3.3099896907806396, acc: 0.3163841664791107)
[2024-12-17 01:43:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,317][root][INFO] - Training Epoch: 1/2, step 1417/7134 completed (loss: 3.2953295707702637, acc: 0.3472222089767456)
[2024-12-17 01:43:27,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:27,708][root][INFO] - Training Epoch: 1/2, step 1418/7134 completed (loss: 3.442593812942505, acc: 0.302325576543808)
[2024-12-17 01:43:27,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,093][root][INFO] - Training Epoch: 1/2, step 1419/7134 completed (loss: 3.3483834266662598, acc: 0.3181818127632141)
[2024-12-17 01:43:28,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,479][root][INFO] - Training Epoch: 1/2, step 1420/7134 completed (loss: 3.187600612640381, acc: 0.3210526406764984)
[2024-12-17 01:43:28,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:28,890][root][INFO] - Training Epoch: 1/2, step 1421/7134 completed (loss: 3.1679069995880127, acc: 0.3691275119781494)
[2024-12-17 01:43:29,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,312][root][INFO] - Training Epoch: 1/2, step 1422/7134 completed (loss: 4.009432315826416, acc: 0.3253012001514435)
[2024-12-17 01:43:29,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:29,714][root][INFO] - Training Epoch: 1/2, step 1423/7134 completed (loss: 4.24503755569458, acc: 0.3129771053791046)
[2024-12-17 01:43:29,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,145][root][INFO] - Training Epoch: 1/2, step 1424/7134 completed (loss: 4.409341812133789, acc: 0.28455284237861633)
[2024-12-17 01:43:30,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,550][root][INFO] - Training Epoch: 1/2, step 1425/7134 completed (loss: 4.158383846282959, acc: 0.2543352544307709)
[2024-12-17 01:43:30,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:30,985][root][INFO] - Training Epoch: 1/2, step 1426/7134 completed (loss: 3.6213860511779785, acc: 0.35567009449005127)
[2024-12-17 01:43:31,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,393][root][INFO] - Training Epoch: 1/2, step 1427/7134 completed (loss: 4.195937156677246, acc: 0.2711864411830902)
[2024-12-17 01:43:31,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:31,797][root][INFO] - Training Epoch: 1/2, step 1428/7134 completed (loss: 4.110461711883545, acc: 0.3870967626571655)
[2024-12-17 01:43:31,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,185][root][INFO] - Training Epoch: 1/2, step 1429/7134 completed (loss: 3.734010934829712, acc: 0.3055555522441864)
[2024-12-17 01:43:32,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,576][root][INFO] - Training Epoch: 1/2, step 1430/7134 completed (loss: 3.245432138442993, acc: 0.3884892165660858)
[2024-12-17 01:43:32,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:32,960][root][INFO] - Training Epoch: 1/2, step 1431/7134 completed (loss: 3.5871548652648926, acc: 0.34408602118492126)
[2024-12-17 01:43:33,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,363][root][INFO] - Training Epoch: 1/2, step 1432/7134 completed (loss: 3.4990673065185547, acc: 0.311557799577713)
[2024-12-17 01:43:33,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:33,775][root][INFO] - Training Epoch: 1/2, step 1433/7134 completed (loss: 3.5878844261169434, acc: 0.30882352590560913)
[2024-12-17 01:43:33,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,178][root][INFO] - Training Epoch: 1/2, step 1434/7134 completed (loss: 3.361128568649292, acc: 0.3631840944290161)
[2024-12-17 01:43:34,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,564][root][INFO] - Training Epoch: 1/2, step 1435/7134 completed (loss: 3.786656618118286, acc: 0.3172042965888977)
[2024-12-17 01:43:34,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:34,968][root][INFO] - Training Epoch: 1/2, step 1436/7134 completed (loss: 3.787585496902466, acc: 0.2916666567325592)
[2024-12-17 01:43:35,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,359][root][INFO] - Training Epoch: 1/2, step 1437/7134 completed (loss: 3.2833776473999023, acc: 0.4032258093357086)
[2024-12-17 01:43:35,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:35,754][root][INFO] - Training Epoch: 1/2, step 1438/7134 completed (loss: 3.675065517425537, acc: 0.28484848141670227)
[2024-12-17 01:43:35,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,117][root][INFO] - Training Epoch: 1/2, step 1439/7134 completed (loss: 3.676213264465332, acc: 0.32592591643333435)
[2024-12-17 01:43:36,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,516][root][INFO] - Training Epoch: 1/2, step 1440/7134 completed (loss: 3.8378849029541016, acc: 0.3478260934352875)
[2024-12-17 01:43:36,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:36,957][root][INFO] - Training Epoch: 1/2, step 1441/7134 completed (loss: 3.306950092315674, acc: 0.37931033968925476)
[2024-12-17 01:43:37,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,369][root][INFO] - Training Epoch: 1/2, step 1442/7134 completed (loss: 3.4433093070983887, acc: 0.3482142984867096)
[2024-12-17 01:43:37,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:37,771][root][INFO] - Training Epoch: 1/2, step 1443/7134 completed (loss: 3.105743885040283, acc: 0.37037035822868347)
[2024-12-17 01:43:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,148][root][INFO] - Training Epoch: 1/2, step 1444/7134 completed (loss: 3.47251033782959, acc: 0.3611111044883728)
[2024-12-17 01:43:38,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,522][root][INFO] - Training Epoch: 1/2, step 1445/7134 completed (loss: 3.371014356613159, acc: 0.35031846165657043)
[2024-12-17 01:43:38,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:38,887][root][INFO] - Training Epoch: 1/2, step 1446/7134 completed (loss: 3.2496731281280518, acc: 0.3787878751754761)
[2024-12-17 01:43:38,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,257][root][INFO] - Training Epoch: 1/2, step 1447/7134 completed (loss: 3.594982862472534, acc: 0.35483869910240173)
[2024-12-17 01:43:39,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:39,671][root][INFO] - Training Epoch: 1/2, step 1448/7134 completed (loss: 4.131015777587891, acc: 0.305970162153244)
[2024-12-17 01:43:39,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,076][root][INFO] - Training Epoch: 1/2, step 1449/7134 completed (loss: 3.787339448928833, acc: 0.35519126057624817)
[2024-12-17 01:43:40,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,456][root][INFO] - Training Epoch: 1/2, step 1450/7134 completed (loss: 3.2298104763031006, acc: 0.3903743326663971)
[2024-12-17 01:43:40,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:40,840][root][INFO] - Training Epoch: 1/2, step 1451/7134 completed (loss: 2.8466796875, acc: 0.4293193817138672)
[2024-12-17 01:43:41,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,257][root][INFO] - Training Epoch: 1/2, step 1452/7134 completed (loss: 3.4959096908569336, acc: 0.3611111044883728)
[2024-12-17 01:43:41,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:41,666][root][INFO] - Training Epoch: 1/2, step 1453/7134 completed (loss: 3.7136311531066895, acc: 0.34302327036857605)
[2024-12-17 01:43:41,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,060][root][INFO] - Training Epoch: 1/2, step 1454/7134 completed (loss: 3.655524492263794, acc: 0.3489583432674408)
[2024-12-17 01:43:42,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,427][root][INFO] - Training Epoch: 1/2, step 1455/7134 completed (loss: 3.500443696975708, acc: 0.37931033968925476)
[2024-12-17 01:43:42,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:42,825][root][INFO] - Training Epoch: 1/2, step 1456/7134 completed (loss: 3.6737680435180664, acc: 0.3057851195335388)
[2024-12-17 01:43:42,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,229][root][INFO] - Training Epoch: 1/2, step 1457/7134 completed (loss: 3.6742687225341797, acc: 0.3478260934352875)
[2024-12-17 01:43:43,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:43,629][root][INFO] - Training Epoch: 1/2, step 1458/7134 completed (loss: 3.686005115509033, acc: 0.3254437744617462)
[2024-12-17 01:43:43,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,018][root][INFO] - Training Epoch: 1/2, step 1459/7134 completed (loss: 4.000686168670654, acc: 0.28148147463798523)
[2024-12-17 01:43:44,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,423][root][INFO] - Training Epoch: 1/2, step 1460/7134 completed (loss: 4.474846839904785, acc: 0.24260355532169342)
[2024-12-17 01:43:44,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:44,801][root][INFO] - Training Epoch: 1/2, step 1461/7134 completed (loss: 4.484634876251221, acc: 0.2450331151485443)
[2024-12-17 01:43:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,208][root][INFO] - Training Epoch: 1/2, step 1462/7134 completed (loss: 3.4193649291992188, acc: 0.3805970251560211)
[2024-12-17 01:43:45,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:45,609][root][INFO] - Training Epoch: 1/2, step 1463/7134 completed (loss: 4.3545098304748535, acc: 0.3137255012989044)
[2024-12-17 01:43:45,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,011][root][INFO] - Training Epoch: 1/2, step 1464/7134 completed (loss: 4.409913063049316, acc: 0.23493975400924683)
[2024-12-17 01:43:46,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,409][root][INFO] - Training Epoch: 1/2, step 1465/7134 completed (loss: 4.029022216796875, acc: 0.3205128312110901)
[2024-12-17 01:43:46,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:46,807][root][INFO] - Training Epoch: 1/2, step 1466/7134 completed (loss: 3.6043930053710938, acc: 0.27374300360679626)
[2024-12-17 01:43:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,193][root][INFO] - Training Epoch: 1/2, step 1467/7134 completed (loss: 4.066544532775879, acc: 0.19393938779830933)
[2024-12-17 01:43:47,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:47,608][root][INFO] - Training Epoch: 1/2, step 1468/7134 completed (loss: 4.328817844390869, acc: 0.2078651636838913)
[2024-12-17 01:43:47,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,004][root][INFO] - Training Epoch: 1/2, step 1469/7134 completed (loss: 3.867421865463257, acc: 0.25)
[2024-12-17 01:43:48,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,392][root][INFO] - Training Epoch: 1/2, step 1470/7134 completed (loss: 4.049074172973633, acc: 0.31847134232521057)
[2024-12-17 01:43:48,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:48,788][root][INFO] - Training Epoch: 1/2, step 1471/7134 completed (loss: 4.199939727783203, acc: 0.33076924085617065)
[2024-12-17 01:43:48,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,187][root][INFO] - Training Epoch: 1/2, step 1472/7134 completed (loss: 3.5002124309539795, acc: 0.35672515630722046)
[2024-12-17 01:43:49,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,576][root][INFO] - Training Epoch: 1/2, step 1473/7134 completed (loss: 3.5029714107513428, acc: 0.27878788113594055)
[2024-12-17 01:43:49,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:49,952][root][INFO] - Training Epoch: 1/2, step 1474/7134 completed (loss: 3.6729609966278076, acc: 0.30344828963279724)
[2024-12-17 01:43:50,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,346][root][INFO] - Training Epoch: 1/2, step 1475/7134 completed (loss: 3.883979082107544, acc: 0.3393939435482025)
[2024-12-17 01:43:50,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:50,748][root][INFO] - Training Epoch: 1/2, step 1476/7134 completed (loss: 4.496941089630127, acc: 0.2866666615009308)
[2024-12-17 01:43:50,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,157][root][INFO] - Training Epoch: 1/2, step 1477/7134 completed (loss: 3.750710964202881, acc: 0.2620689570903778)
[2024-12-17 01:43:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,572][root][INFO] - Training Epoch: 1/2, step 1478/7134 completed (loss: 4.006894111633301, acc: 0.2565789520740509)
[2024-12-17 01:43:51,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:51,969][root][INFO] - Training Epoch: 1/2, step 1479/7134 completed (loss: 3.7768797874450684, acc: 0.3045977056026459)
[2024-12-17 01:43:52,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,381][root][INFO] - Training Epoch: 1/2, step 1480/7134 completed (loss: 3.891921281814575, acc: 0.2541436553001404)
[2024-12-17 01:43:52,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:52,784][root][INFO] - Training Epoch: 1/2, step 1481/7134 completed (loss: 3.5402750968933105, acc: 0.3444444537162781)
[2024-12-17 01:43:52,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,167][root][INFO] - Training Epoch: 1/2, step 1482/7134 completed (loss: 3.9180963039398193, acc: 0.33136093616485596)
[2024-12-17 01:43:53,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,577][root][INFO] - Training Epoch: 1/2, step 1483/7134 completed (loss: 4.552586078643799, acc: 0.2442748099565506)
[2024-12-17 01:43:53,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:53,964][root][INFO] - Training Epoch: 1/2, step 1484/7134 completed (loss: 3.8850038051605225, acc: 0.3072289228439331)
[2024-12-17 01:43:54,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,346][root][INFO] - Training Epoch: 1/2, step 1485/7134 completed (loss: 4.31603479385376, acc: 0.2163742631673813)
[2024-12-17 01:43:54,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:54,731][root][INFO] - Training Epoch: 1/2, step 1486/7134 completed (loss: 3.9326844215393066, acc: 0.3207547068595886)
[2024-12-17 01:43:54,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,122][root][INFO] - Training Epoch: 1/2, step 1487/7134 completed (loss: 3.568305015563965, acc: 0.3243243098258972)
[2024-12-17 01:43:55,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,509][root][INFO] - Training Epoch: 1/2, step 1488/7134 completed (loss: 4.12192964553833, acc: 0.24651162326335907)
[2024-12-17 01:43:55,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:55,873][root][INFO] - Training Epoch: 1/2, step 1489/7134 completed (loss: 4.382288932800293, acc: 0.23469388484954834)
[2024-12-17 01:43:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,251][root][INFO] - Training Epoch: 1/2, step 1490/7134 completed (loss: 4.221412181854248, acc: 0.3053097426891327)
[2024-12-17 01:43:56,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,620][root][INFO] - Training Epoch: 1/2, step 1491/7134 completed (loss: 3.7932655811309814, acc: 0.31904762983322144)
[2024-12-17 01:43:56,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:56,986][root][INFO] - Training Epoch: 1/2, step 1492/7134 completed (loss: 3.7517125606536865, acc: 0.3127962052822113)
[2024-12-17 01:43:57,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,354][root][INFO] - Training Epoch: 1/2, step 1493/7134 completed (loss: 3.8217365741729736, acc: 0.21962617337703705)
[2024-12-17 01:43:57,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:57,737][root][INFO] - Training Epoch: 1/2, step 1494/7134 completed (loss: 4.063098907470703, acc: 0.2331606149673462)
[2024-12-17 01:43:57,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,112][root][INFO] - Training Epoch: 1/2, step 1495/7134 completed (loss: 4.125502109527588, acc: 0.29756098985671997)
[2024-12-17 01:43:58,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,498][root][INFO] - Training Epoch: 1/2, step 1496/7134 completed (loss: 4.218454360961914, acc: 0.25)
[2024-12-17 01:43:58,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:58,895][root][INFO] - Training Epoch: 1/2, step 1497/7134 completed (loss: 3.529217004776001, acc: 0.33796295523643494)
[2024-12-17 01:43:58,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,247][root][INFO] - Training Epoch: 1/2, step 1498/7134 completed (loss: 4.393101215362549, acc: 0.2432432472705841)
[2024-12-17 01:43:59,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,634][root][INFO] - Training Epoch: 1/2, step 1499/7134 completed (loss: 3.701460838317871, acc: 0.3255814015865326)
[2024-12-17 01:43:59,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:43:59,999][root][INFO] - Training Epoch: 1/2, step 1500/7134 completed (loss: 4.570162296295166, acc: 0.2397260218858719)
[2024-12-17 01:44:00,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,395][root][INFO] - Training Epoch: 1/2, step 1501/7134 completed (loss: 4.582352638244629, acc: 0.24852071702480316)
[2024-12-17 01:44:00,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:00,782][root][INFO] - Training Epoch: 1/2, step 1502/7134 completed (loss: 3.9872705936431885, acc: 0.3545454442501068)
[2024-12-17 01:44:00,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,157][root][INFO] - Training Epoch: 1/2, step 1503/7134 completed (loss: 4.668081760406494, acc: 0.2571428716182709)
[2024-12-17 01:44:01,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,521][root][INFO] - Training Epoch: 1/2, step 1504/7134 completed (loss: 4.249973773956299, acc: 0.24338623881340027)
[2024-12-17 01:44:01,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:01,890][root][INFO] - Training Epoch: 1/2, step 1505/7134 completed (loss: 4.433250904083252, acc: 0.2531645596027374)
[2024-12-17 01:44:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,260][root][INFO] - Training Epoch: 1/2, step 1506/7134 completed (loss: 4.334697723388672, acc: 0.31446540355682373)
[2024-12-17 01:44:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:02,648][root][INFO] - Training Epoch: 1/2, step 1507/7134 completed (loss: 4.464146614074707, acc: 0.2864583432674408)
[2024-12-17 01:44:02,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,022][root][INFO] - Training Epoch: 1/2, step 1508/7134 completed (loss: 3.689642906188965, acc: 0.36915886402130127)
[2024-12-17 01:44:03,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,401][root][INFO] - Training Epoch: 1/2, step 1509/7134 completed (loss: 3.7794182300567627, acc: 0.3055555522441864)
[2024-12-17 01:44:03,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:03,788][root][INFO] - Training Epoch: 1/2, step 1510/7134 completed (loss: 4.134355068206787, acc: 0.32258063554763794)
[2024-12-17 01:44:03,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,159][root][INFO] - Training Epoch: 1/2, step 1511/7134 completed (loss: 4.07483434677124, acc: 0.29050278663635254)
[2024-12-17 01:44:04,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,535][root][INFO] - Training Epoch: 1/2, step 1512/7134 completed (loss: 3.468790292739868, acc: 0.3799999952316284)
[2024-12-17 01:44:04,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:04,902][root][INFO] - Training Epoch: 1/2, step 1513/7134 completed (loss: 3.9032161235809326, acc: 0.27624309062957764)
[2024-12-17 01:44:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,280][root][INFO] - Training Epoch: 1/2, step 1514/7134 completed (loss: 3.9425418376922607, acc: 0.24870465695858002)
[2024-12-17 01:44:05,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:05,677][root][INFO] - Training Epoch: 1/2, step 1515/7134 completed (loss: 4.1161017417907715, acc: 0.27927929162979126)
[2024-12-17 01:44:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,042][root][INFO] - Training Epoch: 1/2, step 1516/7134 completed (loss: 4.39683723449707, acc: 0.26249998807907104)
[2024-12-17 01:44:06,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,398][root][INFO] - Training Epoch: 1/2, step 1517/7134 completed (loss: 4.671339988708496, acc: 0.1875)
[2024-12-17 01:44:06,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:06,751][root][INFO] - Training Epoch: 1/2, step 1518/7134 completed (loss: 4.118347644805908, acc: 0.24742268025875092)
[2024-12-17 01:44:06,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,131][root][INFO] - Training Epoch: 1/2, step 1519/7134 completed (loss: 4.201089382171631, acc: 0.223300963640213)
[2024-12-17 01:44:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,503][root][INFO] - Training Epoch: 1/2, step 1520/7134 completed (loss: 4.16901969909668, acc: 0.32116788625717163)
[2024-12-17 01:44:07,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:07,914][root][INFO] - Training Epoch: 1/2, step 1521/7134 completed (loss: 4.186524391174316, acc: 0.2867647111415863)
[2024-12-17 01:44:08,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,292][root][INFO] - Training Epoch: 1/2, step 1522/7134 completed (loss: 4.29604434967041, acc: 0.2936508059501648)
[2024-12-17 01:44:08,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:08,662][root][INFO] - Training Epoch: 1/2, step 1523/7134 completed (loss: 5.260924339294434, acc: 0.21052631735801697)
[2024-12-17 01:44:08,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,012][root][INFO] - Training Epoch: 1/2, step 1524/7134 completed (loss: 4.892494201660156, acc: 0.2054794579744339)
[2024-12-17 01:44:09,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,378][root][INFO] - Training Epoch: 1/2, step 1525/7134 completed (loss: 4.331005096435547, acc: 0.27000001072883606)
[2024-12-17 01:44:09,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:09,800][root][INFO] - Training Epoch: 1/2, step 1526/7134 completed (loss: 4.7346320152282715, acc: 0.26530611515045166)
[2024-12-17 01:44:09,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,195][root][INFO] - Training Epoch: 1/2, step 1527/7134 completed (loss: 4.589204788208008, acc: 0.32743361592292786)
[2024-12-17 01:44:10,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,593][root][INFO] - Training Epoch: 1/2, step 1528/7134 completed (loss: 4.460442066192627, acc: 0.260869562625885)
[2024-12-17 01:44:10,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:10,964][root][INFO] - Training Epoch: 1/2, step 1529/7134 completed (loss: 3.888792037963867, acc: 0.28723403811454773)
[2024-12-17 01:44:11,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,317][root][INFO] - Training Epoch: 1/2, step 1530/7134 completed (loss: 4.405751705169678, acc: 0.2767857015132904)
[2024-12-17 01:44:11,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:11,738][root][INFO] - Training Epoch: 1/2, step 1531/7134 completed (loss: 4.835903167724609, acc: 0.22727273404598236)
[2024-12-17 01:44:11,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,178][root][INFO] - Training Epoch: 1/2, step 1532/7134 completed (loss: 3.6802778244018555, acc: 0.3282051384449005)
[2024-12-17 01:44:12,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,567][root][INFO] - Training Epoch: 1/2, step 1533/7134 completed (loss: 4.333379745483398, acc: 0.2469879537820816)
[2024-12-17 01:44:12,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:12,939][root][INFO] - Training Epoch: 1/2, step 1534/7134 completed (loss: 4.666506290435791, acc: 0.18705035746097565)
[2024-12-17 01:44:13,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,355][root][INFO] - Training Epoch: 1/2, step 1535/7134 completed (loss: 3.7558698654174805, acc: 0.35428571701049805)
[2024-12-17 01:44:13,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:13,751][root][INFO] - Training Epoch: 1/2, step 1536/7134 completed (loss: 3.9217991828918457, acc: 0.37037035822868347)
[2024-12-17 01:44:13,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,160][root][INFO] - Training Epoch: 1/2, step 1537/7134 completed (loss: 4.048378944396973, acc: 0.3391812741756439)
[2024-12-17 01:44:14,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,533][root][INFO] - Training Epoch: 1/2, step 1538/7134 completed (loss: 4.1578521728515625, acc: 0.2916666567325592)
[2024-12-17 01:44:14,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:14,917][root][INFO] - Training Epoch: 1/2, step 1539/7134 completed (loss: 4.117074966430664, acc: 0.290909081697464)
[2024-12-17 01:44:15,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,319][root][INFO] - Training Epoch: 1/2, step 1540/7134 completed (loss: 4.387442111968994, acc: 0.2151898741722107)
[2024-12-17 01:44:15,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:15,722][root][INFO] - Training Epoch: 1/2, step 1541/7134 completed (loss: 4.188777446746826, acc: 0.2368421107530594)
[2024-12-17 01:44:15,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,115][root][INFO] - Training Epoch: 1/2, step 1542/7134 completed (loss: 3.803581714630127, acc: 0.30337077379226685)
[2024-12-17 01:44:16,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,497][root][INFO] - Training Epoch: 1/2, step 1543/7134 completed (loss: 4.065795421600342, acc: 0.261904776096344)
[2024-12-17 01:44:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:16,861][root][INFO] - Training Epoch: 1/2, step 1544/7134 completed (loss: 3.9959716796875, acc: 0.23499999940395355)
[2024-12-17 01:44:16,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,226][root][INFO] - Training Epoch: 1/2, step 1545/7134 completed (loss: 4.008429527282715, acc: 0.2857142984867096)
[2024-12-17 01:44:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:17,619][root][INFO] - Training Epoch: 1/2, step 1546/7134 completed (loss: 4.400511741638184, acc: 0.29411765933036804)
[2024-12-17 01:44:17,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,000][root][INFO] - Training Epoch: 1/2, step 1547/7134 completed (loss: 4.4893574714660645, acc: 0.24074074625968933)
[2024-12-17 01:44:18,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,386][root][INFO] - Training Epoch: 1/2, step 1548/7134 completed (loss: 4.265693187713623, acc: 0.2789473831653595)
[2024-12-17 01:44:18,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:18,762][root][INFO] - Training Epoch: 1/2, step 1549/7134 completed (loss: 3.7120773792266846, acc: 0.3257142901420593)
[2024-12-17 01:44:18,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,138][root][INFO] - Training Epoch: 1/2, step 1550/7134 completed (loss: 3.924671173095703, acc: 0.30000001192092896)
[2024-12-17 01:44:19,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,493][root][INFO] - Training Epoch: 1/2, step 1551/7134 completed (loss: 4.0598554611206055, acc: 0.3112582862377167)
[2024-12-17 01:44:19,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:19,851][root][INFO] - Training Epoch: 1/2, step 1552/7134 completed (loss: 3.677438735961914, acc: 0.29591837525367737)
[2024-12-17 01:44:19,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,187][root][INFO] - Training Epoch: 1/2, step 1553/7134 completed (loss: 4.486340045928955, acc: 0.31168830394744873)
[2024-12-17 01:44:20,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,588][root][INFO] - Training Epoch: 1/2, step 1554/7134 completed (loss: 4.1136980056762695, acc: 0.30635836720466614)
[2024-12-17 01:44:20,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:20,971][root][INFO] - Training Epoch: 1/2, step 1555/7134 completed (loss: 4.154473781585693, acc: 0.2750000059604645)
[2024-12-17 01:44:21,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,371][root][INFO] - Training Epoch: 1/2, step 1556/7134 completed (loss: 4.148951530456543, acc: 0.2711864411830902)
[2024-12-17 01:44:21,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:21,772][root][INFO] - Training Epoch: 1/2, step 1557/7134 completed (loss: 3.9596519470214844, acc: 0.30000001192092896)
[2024-12-17 01:44:21,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,158][root][INFO] - Training Epoch: 1/2, step 1558/7134 completed (loss: 4.230630397796631, acc: 0.2397260218858719)
[2024-12-17 01:44:22,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,539][root][INFO] - Training Epoch: 1/2, step 1559/7134 completed (loss: 3.8071107864379883, acc: 0.3142857253551483)
[2024-12-17 01:44:22,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:22,946][root][INFO] - Training Epoch: 1/2, step 1560/7134 completed (loss: 3.0532453060150146, acc: 0.32487308979034424)
[2024-12-17 01:44:23,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,329][root][INFO] - Training Epoch: 1/2, step 1561/7134 completed (loss: 4.03449010848999, acc: 0.2715517282485962)
[2024-12-17 01:44:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:23,737][root][INFO] - Training Epoch: 1/2, step 1562/7134 completed (loss: 3.6114425659179688, acc: 0.2958579957485199)
[2024-12-17 01:44:23,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,138][root][INFO] - Training Epoch: 1/2, step 1563/7134 completed (loss: 4.199580669403076, acc: 0.2696078419685364)
[2024-12-17 01:44:24,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,512][root][INFO] - Training Epoch: 1/2, step 1564/7134 completed (loss: 4.236767768859863, acc: 0.24257425963878632)
[2024-12-17 01:44:24,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:24,869][root][INFO] - Training Epoch: 1/2, step 1565/7134 completed (loss: 4.392735004425049, acc: 0.2578616440296173)
[2024-12-17 01:44:24,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,238][root][INFO] - Training Epoch: 1/2, step 1566/7134 completed (loss: 4.027990818023682, acc: 0.3038673996925354)
[2024-12-17 01:44:25,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:25,632][root][INFO] - Training Epoch: 1/2, step 1567/7134 completed (loss: 4.004582405090332, acc: 0.33170732855796814)
[2024-12-17 01:44:25,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,020][root][INFO] - Training Epoch: 1/2, step 1568/7134 completed (loss: 4.019079208374023, acc: 0.29326921701431274)
[2024-12-17 01:44:26,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,397][root][INFO] - Training Epoch: 1/2, step 1569/7134 completed (loss: 4.032853603363037, acc: 0.27878788113594055)
[2024-12-17 01:44:26,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:26,780][root][INFO] - Training Epoch: 1/2, step 1570/7134 completed (loss: 4.124685287475586, acc: 0.2535211145877838)
[2024-12-17 01:44:26,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,150][root][INFO] - Training Epoch: 1/2, step 1571/7134 completed (loss: 3.507328987121582, acc: 0.3410138189792633)
[2024-12-17 01:44:27,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,543][root][INFO] - Training Epoch: 1/2, step 1572/7134 completed (loss: 3.316399097442627, acc: 0.32863849401474)
[2024-12-17 01:44:27,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:27,900][root][INFO] - Training Epoch: 1/2, step 1573/7134 completed (loss: 3.551640748977661, acc: 0.299401193857193)
[2024-12-17 01:44:27,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,284][root][INFO] - Training Epoch: 1/2, step 1574/7134 completed (loss: 3.4840240478515625, acc: 0.34529146552085876)
[2024-12-17 01:44:28,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:28,657][root][INFO] - Training Epoch: 1/2, step 1575/7134 completed (loss: 3.6984105110168457, acc: 0.290909081697464)
[2024-12-17 01:44:28,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,033][root][INFO] - Training Epoch: 1/2, step 1576/7134 completed (loss: 3.1467716693878174, acc: 0.3333333432674408)
[2024-12-17 01:44:29,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,445][root][INFO] - Training Epoch: 1/2, step 1577/7134 completed (loss: 3.5270044803619385, acc: 0.3478260934352875)
[2024-12-17 01:44:29,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:29,846][root][INFO] - Training Epoch: 1/2, step 1578/7134 completed (loss: 4.2093400955200195, acc: 0.27272728085517883)
[2024-12-17 01:44:29,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,246][root][INFO] - Training Epoch: 1/2, step 1579/7134 completed (loss: 3.819681406021118, acc: 0.35576921701431274)
[2024-12-17 01:44:30,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:30,633][root][INFO] - Training Epoch: 1/2, step 1580/7134 completed (loss: 4.382534980773926, acc: 0.260869562625885)
[2024-12-17 01:44:30,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,073][root][INFO] - Training Epoch: 1/2, step 1581/7134 completed (loss: 4.140428066253662, acc: 0.363095223903656)
[2024-12-17 01:44:31,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,456][root][INFO] - Training Epoch: 1/2, step 1582/7134 completed (loss: 4.306398391723633, acc: 0.2866666615009308)
[2024-12-17 01:44:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:31,825][root][INFO] - Training Epoch: 1/2, step 1583/7134 completed (loss: 4.287440299987793, acc: 0.3142857253551483)
[2024-12-17 01:44:31,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,217][root][INFO] - Training Epoch: 1/2, step 1584/7134 completed (loss: 3.848905086517334, acc: 0.29279279708862305)
[2024-12-17 01:44:32,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,594][root][INFO] - Training Epoch: 1/2, step 1585/7134 completed (loss: 3.65578293800354, acc: 0.276699036359787)
[2024-12-17 01:44:32,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:32,971][root][INFO] - Training Epoch: 1/2, step 1586/7134 completed (loss: 3.824044704437256, acc: 0.3526569902896881)
[2024-12-17 01:44:33,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,354][root][INFO] - Training Epoch: 1/2, step 1587/7134 completed (loss: 4.231557846069336, acc: 0.24203822016716003)
[2024-12-17 01:44:33,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:33,733][root][INFO] - Training Epoch: 1/2, step 1588/7134 completed (loss: 3.5928783416748047, acc: 0.30573248863220215)
[2024-12-17 01:44:33,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,106][root][INFO] - Training Epoch: 1/2, step 1589/7134 completed (loss: 4.102015495300293, acc: 0.25)
[2024-12-17 01:44:34,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,503][root][INFO] - Training Epoch: 1/2, step 1590/7134 completed (loss: 3.969017744064331, acc: 0.30000001192092896)
[2024-12-17 01:44:34,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:34,883][root][INFO] - Training Epoch: 1/2, step 1591/7134 completed (loss: 3.6940982341766357, acc: 0.3178294599056244)
[2024-12-17 01:44:35,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,301][root][INFO] - Training Epoch: 1/2, step 1592/7134 completed (loss: 3.883531093597412, acc: 0.2922077775001526)
[2024-12-17 01:44:35,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:35,742][root][INFO] - Training Epoch: 1/2, step 1593/7134 completed (loss: 3.9586756229400635, acc: 0.27807486057281494)
[2024-12-17 01:44:35,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,127][root][INFO] - Training Epoch: 1/2, step 1594/7134 completed (loss: 3.9533727169036865, acc: 0.25)
[2024-12-17 01:44:36,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,498][root][INFO] - Training Epoch: 1/2, step 1595/7134 completed (loss: 3.5585312843322754, acc: 0.3025210201740265)
[2024-12-17 01:44:36,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:36,889][root][INFO] - Training Epoch: 1/2, step 1596/7134 completed (loss: 3.7292065620422363, acc: 0.2986111044883728)
[2024-12-17 01:44:36,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,268][root][INFO] - Training Epoch: 1/2, step 1597/7134 completed (loss: 4.140639305114746, acc: 0.29139071702957153)
[2024-12-17 01:44:37,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:37,624][root][INFO] - Training Epoch: 1/2, step 1598/7134 completed (loss: 3.7898857593536377, acc: 0.34166666865348816)
[2024-12-17 01:44:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,003][root][INFO] - Training Epoch: 1/2, step 1599/7134 completed (loss: 3.9197700023651123, acc: 0.3379310369491577)
[2024-12-17 01:44:38,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,365][root][INFO] - Training Epoch: 1/2, step 1600/7134 completed (loss: 3.2669098377227783, acc: 0.37755101919174194)
[2024-12-17 01:44:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:38,734][root][INFO] - Training Epoch: 1/2, step 1601/7134 completed (loss: 3.3141558170318604, acc: 0.4000000059604645)
[2024-12-17 01:44:38,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,118][root][INFO] - Training Epoch: 1/2, step 1602/7134 completed (loss: 3.4640064239501953, acc: 0.3717948794364929)
[2024-12-17 01:44:39,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,480][root][INFO] - Training Epoch: 1/2, step 1603/7134 completed (loss: 4.168628692626953, acc: 0.2650602459907532)
[2024-12-17 01:44:39,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:39,849][root][INFO] - Training Epoch: 1/2, step 1604/7134 completed (loss: 3.6155946254730225, acc: 0.34545454382896423)
[2024-12-17 01:44:39,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,233][root][INFO] - Training Epoch: 1/2, step 1605/7134 completed (loss: 3.943416118621826, acc: 0.34117648005485535)
[2024-12-17 01:44:40,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:40,599][root][INFO] - Training Epoch: 1/2, step 1606/7134 completed (loss: 3.3756771087646484, acc: 0.36054420471191406)
[2024-12-17 01:44:40,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,041][root][INFO] - Training Epoch: 1/2, step 1607/7134 completed (loss: 3.114375114440918, acc: 0.41818180680274963)
[2024-12-17 01:44:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,459][root][INFO] - Training Epoch: 1/2, step 1608/7134 completed (loss: 3.3426856994628906, acc: 0.3700787425041199)
[2024-12-17 01:44:41,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:41,833][root][INFO] - Training Epoch: 1/2, step 1609/7134 completed (loss: 3.70699143409729, acc: 0.4027777910232544)
[2024-12-17 01:44:41,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,205][root][INFO] - Training Epoch: 1/2, step 1610/7134 completed (loss: 3.395897626876831, acc: 0.38167938590049744)
[2024-12-17 01:44:42,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,604][root][INFO] - Training Epoch: 1/2, step 1611/7134 completed (loss: 3.7780494689941406, acc: 0.2777777910232544)
[2024-12-17 01:44:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:42,967][root][INFO] - Training Epoch: 1/2, step 1612/7134 completed (loss: 3.5941812992095947, acc: 0.3192771077156067)
[2024-12-17 01:44:43,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,348][root][INFO] - Training Epoch: 1/2, step 1613/7134 completed (loss: 3.911470651626587, acc: 0.260869562625885)
[2024-12-17 01:44:43,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:43,748][root][INFO] - Training Epoch: 1/2, step 1614/7134 completed (loss: 4.0325117111206055, acc: 0.2368421107530594)
[2024-12-17 01:44:43,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,150][root][INFO] - Training Epoch: 1/2, step 1615/7134 completed (loss: 3.4480745792388916, acc: 0.34939759969711304)
[2024-12-17 01:44:44,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,531][root][INFO] - Training Epoch: 1/2, step 1616/7134 completed (loss: 3.6298258304595947, acc: 0.3032258152961731)
[2024-12-17 01:44:44,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:44,935][root][INFO] - Training Epoch: 1/2, step 1617/7134 completed (loss: 3.500047445297241, acc: 0.30215826630592346)
[2024-12-17 01:44:45,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,313][root][INFO] - Training Epoch: 1/2, step 1618/7134 completed (loss: 4.054072856903076, acc: 0.2977099120616913)
[2024-12-17 01:44:45,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:45,701][root][INFO] - Training Epoch: 1/2, step 1619/7134 completed (loss: 4.274172782897949, acc: 0.3353658616542816)
[2024-12-17 01:44:45,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,113][root][INFO] - Training Epoch: 1/2, step 1620/7134 completed (loss: 3.8783466815948486, acc: 0.3636363744735718)
[2024-12-17 01:44:46,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,499][root][INFO] - Training Epoch: 1/2, step 1621/7134 completed (loss: 4.463377475738525, acc: 0.29411765933036804)
[2024-12-17 01:44:46,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:46,866][root][INFO] - Training Epoch: 1/2, step 1622/7134 completed (loss: 4.442581653594971, acc: 0.2810457646846771)
[2024-12-17 01:44:46,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,261][root][INFO] - Training Epoch: 1/2, step 1623/7134 completed (loss: 4.472949504852295, acc: 0.21794871985912323)
[2024-12-17 01:44:47,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:47,648][root][INFO] - Training Epoch: 1/2, step 1624/7134 completed (loss: 4.210511207580566, acc: 0.25974026322364807)
[2024-12-17 01:44:47,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,031][root][INFO] - Training Epoch: 1/2, step 1625/7134 completed (loss: 4.102939128875732, acc: 0.3125)
[2024-12-17 01:44:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,405][root][INFO] - Training Epoch: 1/2, step 1626/7134 completed (loss: 4.811092853546143, acc: 0.19587628543376923)
[2024-12-17 01:44:48,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:48,767][root][INFO] - Training Epoch: 1/2, step 1627/7134 completed (loss: 4.621749401092529, acc: 0.2195121943950653)
[2024-12-17 01:44:48,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,140][root][INFO] - Training Epoch: 1/2, step 1628/7134 completed (loss: 4.0111494064331055, acc: 0.2839506268501282)
[2024-12-17 01:44:49,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,522][root][INFO] - Training Epoch: 1/2, step 1629/7134 completed (loss: 4.375436305999756, acc: 0.2348484843969345)
[2024-12-17 01:44:49,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:49,900][root][INFO] - Training Epoch: 1/2, step 1630/7134 completed (loss: 4.516368389129639, acc: 0.26241135597229004)
[2024-12-17 01:44:50,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,290][root][INFO] - Training Epoch: 1/2, step 1631/7134 completed (loss: 4.741024017333984, acc: 0.2158273309469223)
[2024-12-17 01:44:50,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:50,688][root][INFO] - Training Epoch: 1/2, step 1632/7134 completed (loss: 4.386405944824219, acc: 0.34328359365463257)
[2024-12-17 01:44:50,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,090][root][INFO] - Training Epoch: 1/2, step 1633/7134 completed (loss: 4.569296360015869, acc: 0.27142858505249023)
[2024-12-17 01:44:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,485][root][INFO] - Training Epoch: 1/2, step 1634/7134 completed (loss: 3.9911649227142334, acc: 0.2578616440296173)
[2024-12-17 01:44:51,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:51,875][root][INFO] - Training Epoch: 1/2, step 1635/7134 completed (loss: 4.3268723487854, acc: 0.26851850748062134)
[2024-12-17 01:44:51,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,265][root][INFO] - Training Epoch: 1/2, step 1636/7134 completed (loss: 5.109103202819824, acc: 0.22018349170684814)
[2024-12-17 01:44:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:52,652][root][INFO] - Training Epoch: 1/2, step 1637/7134 completed (loss: 4.05979061126709, acc: 0.27950310707092285)
[2024-12-17 01:44:52,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,040][root][INFO] - Training Epoch: 1/2, step 1638/7134 completed (loss: 4.166957378387451, acc: 0.34645670652389526)
[2024-12-17 01:44:53,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,439][root][INFO] - Training Epoch: 1/2, step 1639/7134 completed (loss: 4.345884323120117, acc: 0.32608696818351746)
[2024-12-17 01:44:53,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:53,829][root][INFO] - Training Epoch: 1/2, step 1640/7134 completed (loss: 3.54632568359375, acc: 0.3695652186870575)
[2024-12-17 01:44:53,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,212][root][INFO] - Training Epoch: 1/2, step 1641/7134 completed (loss: 3.213210344314575, acc: 0.42105263471603394)
[2024-12-17 01:44:54,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,590][root][INFO] - Training Epoch: 1/2, step 1642/7134 completed (loss: 4.070511341094971, acc: 0.3333333432674408)
[2024-12-17 01:44:54,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:54,960][root][INFO] - Training Epoch: 1/2, step 1643/7134 completed (loss: 4.798408508300781, acc: 0.26363635063171387)
[2024-12-17 01:44:55,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,363][root][INFO] - Training Epoch: 1/2, step 1644/7134 completed (loss: 3.998004198074341, acc: 0.402515709400177)
[2024-12-17 01:44:55,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:55,747][root][INFO] - Training Epoch: 1/2, step 1645/7134 completed (loss: 4.227376461029053, acc: 0.2689655125141144)
[2024-12-17 01:44:55,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,127][root][INFO] - Training Epoch: 1/2, step 1646/7134 completed (loss: 3.6907873153686523, acc: 0.4000000059604645)
[2024-12-17 01:44:56,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,496][root][INFO] - Training Epoch: 1/2, step 1647/7134 completed (loss: 3.461923122406006, acc: 0.35211268067359924)
[2024-12-17 01:44:56,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:56,868][root][INFO] - Training Epoch: 1/2, step 1648/7134 completed (loss: 3.9478049278259277, acc: 0.31343284249305725)
[2024-12-17 01:44:56,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,242][root][INFO] - Training Epoch: 1/2, step 1649/7134 completed (loss: 3.6125075817108154, acc: 0.32743361592292786)
[2024-12-17 01:44:57,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,614][root][INFO] - Training Epoch: 1/2, step 1650/7134 completed (loss: 4.015905857086182, acc: 0.30150753259658813)
[2024-12-17 01:44:57,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:57,988][root][INFO] - Training Epoch: 1/2, step 1651/7134 completed (loss: 3.6818926334381104, acc: 0.30909091234207153)
[2024-12-17 01:44:58,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,396][root][INFO] - Training Epoch: 1/2, step 1652/7134 completed (loss: 4.005504131317139, acc: 0.28632479906082153)
[2024-12-17 01:44:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:58,773][root][INFO] - Training Epoch: 1/2, step 1653/7134 completed (loss: 4.151604652404785, acc: 0.2950819730758667)
[2024-12-17 01:44:58,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,174][root][INFO] - Training Epoch: 1/2, step 1654/7134 completed (loss: 3.6353116035461426, acc: 0.3476394712924957)
[2024-12-17 01:44:59,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,565][root][INFO] - Training Epoch: 1/2, step 1655/7134 completed (loss: 3.7908053398132324, acc: 0.30102041363716125)
[2024-12-17 01:44:59,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:44:59,932][root][INFO] - Training Epoch: 1/2, step 1656/7134 completed (loss: 3.8150594234466553, acc: 0.3094170391559601)
[2024-12-17 01:45:00,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,314][root][INFO] - Training Epoch: 1/2, step 1657/7134 completed (loss: 3.5175693035125732, acc: 0.3294573724269867)
[2024-12-17 01:45:00,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:00,692][root][INFO] - Training Epoch: 1/2, step 1658/7134 completed (loss: 3.6143226623535156, acc: 0.2946058213710785)
[2024-12-17 01:45:00,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,076][root][INFO] - Training Epoch: 1/2, step 1659/7134 completed (loss: 3.7401270866394043, acc: 0.31200000643730164)
[2024-12-17 01:45:01,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,462][root][INFO] - Training Epoch: 1/2, step 1660/7134 completed (loss: 3.6437928676605225, acc: 0.3413461446762085)
[2024-12-17 01:45:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:01,858][root][INFO] - Training Epoch: 1/2, step 1661/7134 completed (loss: 3.638715982437134, acc: 0.350649356842041)
[2024-12-17 01:45:01,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,229][root][INFO] - Training Epoch: 1/2, step 1662/7134 completed (loss: 3.436842203140259, acc: 0.3364928960800171)
[2024-12-17 01:45:02,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,607][root][INFO] - Training Epoch: 1/2, step 1663/7134 completed (loss: 3.6449830532073975, acc: 0.32765957713127136)
[2024-12-17 01:45:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:02,977][root][INFO] - Training Epoch: 1/2, step 1664/7134 completed (loss: 3.8517074584960938, acc: 0.2800000011920929)
[2024-12-17 01:45:03,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,361][root][INFO] - Training Epoch: 1/2, step 1665/7134 completed (loss: 3.2657134532928467, acc: 0.38036808371543884)
[2024-12-17 01:45:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:03,757][root][INFO] - Training Epoch: 1/2, step 1666/7134 completed (loss: 3.5564818382263184, acc: 0.29411765933036804)
[2024-12-17 01:45:03,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,138][root][INFO] - Training Epoch: 1/2, step 1667/7134 completed (loss: 3.50986909866333, acc: 0.2929292917251587)
[2024-12-17 01:45:04,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,509][root][INFO] - Training Epoch: 1/2, step 1668/7134 completed (loss: 3.438577890396118, acc: 0.3094170391559601)
[2024-12-17 01:45:04,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:04,908][root][INFO] - Training Epoch: 1/2, step 1669/7134 completed (loss: 3.373971462249756, acc: 0.37022900581359863)
[2024-12-17 01:45:05,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,302][root][INFO] - Training Epoch: 1/2, step 1670/7134 completed (loss: 3.2778496742248535, acc: 0.33840304613113403)
[2024-12-17 01:45:05,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:05,705][root][INFO] - Training Epoch: 1/2, step 1671/7134 completed (loss: 3.357973575592041, acc: 0.3979591727256775)
[2024-12-17 01:45:05,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,085][root][INFO] - Training Epoch: 1/2, step 1672/7134 completed (loss: 3.8489744663238525, acc: 0.27485379576683044)
[2024-12-17 01:45:06,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,477][root][INFO] - Training Epoch: 1/2, step 1673/7134 completed (loss: 3.814598321914673, acc: 0.29192546010017395)
[2024-12-17 01:45:06,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:06,874][root][INFO] - Training Epoch: 1/2, step 1674/7134 completed (loss: 4.146419525146484, acc: 0.30263158679008484)
[2024-12-17 01:45:06,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,266][root][INFO] - Training Epoch: 1/2, step 1675/7134 completed (loss: 4.32487154006958, acc: 0.30136987566947937)
[2024-12-17 01:45:07,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:07,659][root][INFO] - Training Epoch: 1/2, step 1676/7134 completed (loss: 3.839176654815674, acc: 0.31410256028175354)
[2024-12-17 01:45:07,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,037][root][INFO] - Training Epoch: 1/2, step 1677/7134 completed (loss: 3.9655840396881104, acc: 0.3546099364757538)
[2024-12-17 01:45:08,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,477][root][INFO] - Training Epoch: 1/2, step 1678/7134 completed (loss: 3.9428534507751465, acc: 0.2934131622314453)
[2024-12-17 01:45:08,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:08,852][root][INFO] - Training Epoch: 1/2, step 1679/7134 completed (loss: 4.0709662437438965, acc: 0.25609755516052246)
[2024-12-17 01:45:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,235][root][INFO] - Training Epoch: 1/2, step 1680/7134 completed (loss: 3.816014289855957, acc: 0.30588236451148987)
[2024-12-17 01:45:09,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,605][root][INFO] - Training Epoch: 1/2, step 1681/7134 completed (loss: 4.162461757659912, acc: 0.30188679695129395)
[2024-12-17 01:45:09,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:09,974][root][INFO] - Training Epoch: 1/2, step 1682/7134 completed (loss: 4.2118144035339355, acc: 0.28082191944122314)
[2024-12-17 01:45:10,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,361][root][INFO] - Training Epoch: 1/2, step 1683/7134 completed (loss: 3.2463667392730713, acc: 0.3655172288417816)
[2024-12-17 01:45:10,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:10,740][root][INFO] - Training Epoch: 1/2, step 1684/7134 completed (loss: 3.690217971801758, acc: 0.3404255211353302)
[2024-12-17 01:45:10,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,121][root][INFO] - Training Epoch: 1/2, step 1685/7134 completed (loss: 3.6037611961364746, acc: 0.2969697117805481)
[2024-12-17 01:45:11,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,495][root][INFO] - Training Epoch: 1/2, step 1686/7134 completed (loss: 4.057718276977539, acc: 0.25563910603523254)
[2024-12-17 01:45:11,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:11,895][root][INFO] - Training Epoch: 1/2, step 1687/7134 completed (loss: 3.7577672004699707, acc: 0.38053098320961)
[2024-12-17 01:45:11,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,253][root][INFO] - Training Epoch: 1/2, step 1688/7134 completed (loss: 3.6703085899353027, acc: 0.3219178020954132)
[2024-12-17 01:45:12,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,620][root][INFO] - Training Epoch: 1/2, step 1689/7134 completed (loss: 3.9356400966644287, acc: 0.2967741787433624)
[2024-12-17 01:45:12,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:12,994][root][INFO] - Training Epoch: 1/2, step 1690/7134 completed (loss: 4.060245513916016, acc: 0.24778760969638824)
[2024-12-17 01:45:13,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,371][root][INFO] - Training Epoch: 1/2, step 1691/7134 completed (loss: 4.250819683074951, acc: 0.22695034742355347)
[2024-12-17 01:45:13,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:13,739][root][INFO] - Training Epoch: 1/2, step 1692/7134 completed (loss: 4.441539764404297, acc: 0.2601625919342041)
[2024-12-17 01:45:13,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,157][root][INFO] - Training Epoch: 1/2, step 1693/7134 completed (loss: 3.6180341243743896, acc: 0.3469387888908386)
[2024-12-17 01:45:14,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,553][root][INFO] - Training Epoch: 1/2, step 1694/7134 completed (loss: 3.7790324687957764, acc: 0.29655173420906067)
[2024-12-17 01:45:14,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:14,938][root][INFO] - Training Epoch: 1/2, step 1695/7134 completed (loss: 3.911123037338257, acc: 0.2689075767993927)
[2024-12-17 01:45:15,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,317][root][INFO] - Training Epoch: 1/2, step 1696/7134 completed (loss: 4.012494087219238, acc: 0.308270663022995)
[2024-12-17 01:45:15,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:15,695][root][INFO] - Training Epoch: 1/2, step 1697/7134 completed (loss: 3.62182879447937, acc: 0.31468531489372253)
[2024-12-17 01:45:15,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,101][root][INFO] - Training Epoch: 1/2, step 1698/7134 completed (loss: 3.7492666244506836, acc: 0.28671327233314514)
[2024-12-17 01:45:16,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,489][root][INFO] - Training Epoch: 1/2, step 1699/7134 completed (loss: 3.9076614379882812, acc: 0.2985074520111084)
[2024-12-17 01:45:16,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:16,889][root][INFO] - Training Epoch: 1/2, step 1700/7134 completed (loss: 4.309694766998291, acc: 0.29104477167129517)
[2024-12-17 01:45:17,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,275][root][INFO] - Training Epoch: 1/2, step 1701/7134 completed (loss: 3.9484968185424805, acc: 0.3466666638851166)
[2024-12-17 01:45:17,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:17,653][root][INFO] - Training Epoch: 1/2, step 1702/7134 completed (loss: 4.026228427886963, acc: 0.299401193857193)
[2024-12-17 01:45:17,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,025][root][INFO] - Training Epoch: 1/2, step 1703/7134 completed (loss: 4.57835578918457, acc: 0.25827813148498535)
[2024-12-17 01:45:18,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,416][root][INFO] - Training Epoch: 1/2, step 1704/7134 completed (loss: 4.226343154907227, acc: 0.27439025044441223)
[2024-12-17 01:45:18,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:18,857][root][INFO] - Training Epoch: 1/2, step 1705/7134 completed (loss: 4.138501167297363, acc: 0.2879999876022339)
[2024-12-17 01:45:18,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,188][root][INFO] - Training Epoch: 1/2, step 1706/7134 completed (loss: 3.930389404296875, acc: 0.27142858505249023)
[2024-12-17 01:45:19,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:19,640][root][INFO] - Training Epoch: 1/2, step 1707/7134 completed (loss: 4.176840782165527, acc: 0.3103448152542114)
[2024-12-17 01:45:19,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,016][root][INFO] - Training Epoch: 1/2, step 1708/7134 completed (loss: 3.8878633975982666, acc: 0.27407407760620117)
[2024-12-17 01:45:20,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,375][root][INFO] - Training Epoch: 1/2, step 1709/7134 completed (loss: 4.486141204833984, acc: 0.273333340883255)
[2024-12-17 01:45:20,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:20,779][root][INFO] - Training Epoch: 1/2, step 1710/7134 completed (loss: 4.064486026763916, acc: 0.28378379344940186)
[2024-12-17 01:45:20,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,147][root][INFO] - Training Epoch: 1/2, step 1711/7134 completed (loss: 3.983086109161377, acc: 0.2177419364452362)
[2024-12-17 01:45:21,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,540][root][INFO] - Training Epoch: 1/2, step 1712/7134 completed (loss: 3.614176034927368, acc: 0.30158731341362)
[2024-12-17 01:45:21,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:21,903][root][INFO] - Training Epoch: 1/2, step 1713/7134 completed (loss: 4.5328826904296875, acc: 0.190476194024086)
[2024-12-17 01:45:21,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,281][root][INFO] - Training Epoch: 1/2, step 1714/7134 completed (loss: 3.830138683319092, acc: 0.3120567500591278)
[2024-12-17 01:45:22,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,637][root][INFO] - Training Epoch: 1/2, step 1715/7134 completed (loss: 4.320946216583252, acc: 0.33018869161605835)
[2024-12-17 01:45:22,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:22,990][root][INFO] - Training Epoch: 1/2, step 1716/7134 completed (loss: 4.074267864227295, acc: 0.3684210479259491)
[2024-12-17 01:45:23,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,358][root][INFO] - Training Epoch: 1/2, step 1717/7134 completed (loss: 4.139100074768066, acc: 0.302325576543808)
[2024-12-17 01:45:23,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:23,765][root][INFO] - Training Epoch: 1/2, step 1718/7134 completed (loss: 4.346610069274902, acc: 0.24786324799060822)
[2024-12-17 01:45:23,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,162][root][INFO] - Training Epoch: 1/2, step 1719/7134 completed (loss: 4.2451252937316895, acc: 0.2840236723423004)
[2024-12-17 01:45:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,525][root][INFO] - Training Epoch: 1/2, step 1720/7134 completed (loss: 4.587433338165283, acc: 0.2230769246816635)
[2024-12-17 01:45:24,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:24,874][root][INFO] - Training Epoch: 1/2, step 1721/7134 completed (loss: 3.8754239082336426, acc: 0.3046875)
[2024-12-17 01:45:24,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,265][root][INFO] - Training Epoch: 1/2, step 1722/7134 completed (loss: 3.812154531478882, acc: 0.28282827138900757)
[2024-12-17 01:45:25,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:25,635][root][INFO] - Training Epoch: 1/2, step 1723/7134 completed (loss: 4.041717052459717, acc: 0.3641975224018097)
[2024-12-17 01:45:25,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,004][root][INFO] - Training Epoch: 1/2, step 1724/7134 completed (loss: 3.9420716762542725, acc: 0.265625)
[2024-12-17 01:45:26,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,345][root][INFO] - Training Epoch: 1/2, step 1725/7134 completed (loss: 4.091554641723633, acc: 0.2537313401699066)
[2024-12-17 01:45:26,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:26,703][root][INFO] - Training Epoch: 1/2, step 1726/7134 completed (loss: 3.62870717048645, acc: 0.3333333432674408)
[2024-12-17 01:45:26,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,067][root][INFO] - Training Epoch: 1/2, step 1727/7134 completed (loss: 4.258825778961182, acc: 0.29203540086746216)
[2024-12-17 01:45:27,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,433][root][INFO] - Training Epoch: 1/2, step 1728/7134 completed (loss: 3.859013795852661, acc: 0.35384616255760193)
[2024-12-17 01:45:27,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:27,757][root][INFO] - Training Epoch: 1/2, step 1729/7134 completed (loss: 4.1760573387146, acc: 0.2702702581882477)
[2024-12-17 01:45:27,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,125][root][INFO] - Training Epoch: 1/2, step 1730/7134 completed (loss: 3.9718756675720215, acc: 0.32710281014442444)
[2024-12-17 01:45:28,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,449][root][INFO] - Training Epoch: 1/2, step 1731/7134 completed (loss: 4.107751846313477, acc: 0.3253012001514435)
[2024-12-17 01:45:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:28,785][root][INFO] - Training Epoch: 1/2, step 1732/7134 completed (loss: 3.847569227218628, acc: 0.31481480598449707)
[2024-12-17 01:45:28,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,134][root][INFO] - Training Epoch: 1/2, step 1733/7134 completed (loss: 4.101691246032715, acc: 0.3211009204387665)
[2024-12-17 01:45:29,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,508][root][INFO] - Training Epoch: 1/2, step 1734/7134 completed (loss: 4.156681537628174, acc: 0.3192771077156067)
[2024-12-17 01:45:29,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:29,871][root][INFO] - Training Epoch: 1/2, step 1735/7134 completed (loss: 3.9725148677825928, acc: 0.2715231776237488)
[2024-12-17 01:45:29,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,245][root][INFO] - Training Epoch: 1/2, step 1736/7134 completed (loss: 4.373312473297119, acc: 0.297468364238739)
[2024-12-17 01:45:30,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:30,620][root][INFO] - Training Epoch: 1/2, step 1737/7134 completed (loss: 4.193798542022705, acc: 0.30000001192092896)
[2024-12-17 01:45:30,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,022][root][INFO] - Training Epoch: 1/2, step 1738/7134 completed (loss: 4.277856826782227, acc: 0.22905027866363525)
[2024-12-17 01:45:31,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,405][root][INFO] - Training Epoch: 1/2, step 1739/7134 completed (loss: 4.211608409881592, acc: 0.2857142984867096)
[2024-12-17 01:45:31,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:31,805][root][INFO] - Training Epoch: 1/2, step 1740/7134 completed (loss: 3.9512550830841064, acc: 0.30405405163764954)
[2024-12-17 01:45:31,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,231][root][INFO] - Training Epoch: 1/2, step 1741/7134 completed (loss: 4.051586151123047, acc: 0.2484472095966339)
[2024-12-17 01:45:32,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,606][root][INFO] - Training Epoch: 1/2, step 1742/7134 completed (loss: 3.9885752201080322, acc: 0.3178808093070984)
[2024-12-17 01:45:32,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:32,989][root][INFO] - Training Epoch: 1/2, step 1743/7134 completed (loss: 4.212197303771973, acc: 0.2789115607738495)
[2024-12-17 01:45:33,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,393][root][INFO] - Training Epoch: 1/2, step 1744/7134 completed (loss: 3.8379626274108887, acc: 0.3308270573616028)
[2024-12-17 01:45:33,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:33,771][root][INFO] - Training Epoch: 1/2, step 1745/7134 completed (loss: 4.1169257164001465, acc: 0.3235294222831726)
[2024-12-17 01:45:33,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,220][root][INFO] - Training Epoch: 1/2, step 1746/7134 completed (loss: 3.7666847705841064, acc: 0.3120567500591278)
[2024-12-17 01:45:34,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:34,663][root][INFO] - Training Epoch: 1/2, step 1747/7134 completed (loss: 4.298352241516113, acc: 0.2804878056049347)
[2024-12-17 01:45:34,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,064][root][INFO] - Training Epoch: 1/2, step 1748/7134 completed (loss: 4.026943206787109, acc: 0.30000001192092896)
[2024-12-17 01:45:35,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,507][root][INFO] - Training Epoch: 1/2, step 1749/7134 completed (loss: 3.838052988052368, acc: 0.36125653982162476)
[2024-12-17 01:45:35,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:35,926][root][INFO] - Training Epoch: 1/2, step 1750/7134 completed (loss: 3.7054855823516846, acc: 0.3550295829772949)
[2024-12-17 01:45:36,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,311][root][INFO] - Training Epoch: 1/2, step 1751/7134 completed (loss: 3.9488205909729004, acc: 0.3333333432674408)
[2024-12-17 01:45:36,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:36,699][root][INFO] - Training Epoch: 1/2, step 1752/7134 completed (loss: 4.092209339141846, acc: 0.27878788113594055)
[2024-12-17 01:45:36,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,089][root][INFO] - Training Epoch: 1/2, step 1753/7134 completed (loss: 3.8807356357574463, acc: 0.3112582862377167)
[2024-12-17 01:45:37,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,501][root][INFO] - Training Epoch: 1/2, step 1754/7134 completed (loss: 3.9864020347595215, acc: 0.30718955397605896)
[2024-12-17 01:45:37,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:37,879][root][INFO] - Training Epoch: 1/2, step 1755/7134 completed (loss: 4.156634330749512, acc: 0.2875817120075226)
[2024-12-17 01:45:37,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,245][root][INFO] - Training Epoch: 1/2, step 1756/7134 completed (loss: 4.043636322021484, acc: 0.31333333253860474)
[2024-12-17 01:45:38,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,599][root][INFO] - Training Epoch: 1/2, step 1757/7134 completed (loss: 3.8941171169281006, acc: 0.2975206673145294)
[2024-12-17 01:45:38,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:38,978][root][INFO] - Training Epoch: 1/2, step 1758/7134 completed (loss: 3.6684458255767822, acc: 0.3294117748737335)
[2024-12-17 01:45:39,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,351][root][INFO] - Training Epoch: 1/2, step 1759/7134 completed (loss: 4.0766825675964355, acc: 0.2631579041481018)
[2024-12-17 01:45:39,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:39,721][root][INFO] - Training Epoch: 1/2, step 1760/7134 completed (loss: 3.7986667156219482, acc: 0.30327868461608887)
[2024-12-17 01:45:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,061][root][INFO] - Training Epoch: 1/2, step 1761/7134 completed (loss: 4.164239883422852, acc: 0.2857142984867096)
[2024-12-17 01:45:40,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,431][root][INFO] - Training Epoch: 1/2, step 1762/7134 completed (loss: 4.022706508636475, acc: 0.3203883469104767)
[2024-12-17 01:45:40,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:40,784][root][INFO] - Training Epoch: 1/2, step 1763/7134 completed (loss: 3.4594762325286865, acc: 0.4383561611175537)
[2024-12-17 01:45:40,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,147][root][INFO] - Training Epoch: 1/2, step 1764/7134 completed (loss: 3.6588516235351562, acc: 0.3145161271095276)
[2024-12-17 01:45:41,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,517][root][INFO] - Training Epoch: 1/2, step 1765/7134 completed (loss: 3.790515422821045, acc: 0.30718955397605896)
[2024-12-17 01:45:41,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:41,911][root][INFO] - Training Epoch: 1/2, step 1766/7134 completed (loss: 3.913783550262451, acc: 0.3246753215789795)
[2024-12-17 01:45:42,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,312][root][INFO] - Training Epoch: 1/2, step 1767/7134 completed (loss: 3.9781625270843506, acc: 0.299435019493103)
[2024-12-17 01:45:42,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:42,699][root][INFO] - Training Epoch: 1/2, step 1768/7134 completed (loss: 3.6959688663482666, acc: 0.2678571343421936)
[2024-12-17 01:45:42,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,136][root][INFO] - Training Epoch: 1/2, step 1769/7134 completed (loss: 3.810279607772827, acc: 0.3199999928474426)
[2024-12-17 01:45:43,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,505][root][INFO] - Training Epoch: 1/2, step 1770/7134 completed (loss: 3.7100908756256104, acc: 0.3561643958091736)
[2024-12-17 01:45:43,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:43,883][root][INFO] - Training Epoch: 1/2, step 1771/7134 completed (loss: 4.381180286407471, acc: 0.2792207896709442)
[2024-12-17 01:45:43,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,261][root][INFO] - Training Epoch: 1/2, step 1772/7134 completed (loss: 4.048171520233154, acc: 0.30714285373687744)
[2024-12-17 01:45:44,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:44,634][root][INFO] - Training Epoch: 1/2, step 1773/7134 completed (loss: 3.745535373687744, acc: 0.3404255211353302)
[2024-12-17 01:45:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,010][root][INFO] - Training Epoch: 1/2, step 1774/7134 completed (loss: 3.7246487140655518, acc: 0.3484848439693451)
[2024-12-17 01:45:45,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,392][root][INFO] - Training Epoch: 1/2, step 1775/7134 completed (loss: 3.379260778427124, acc: 0.3219178020954132)
[2024-12-17 01:45:45,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:45,758][root][INFO] - Training Epoch: 1/2, step 1776/7134 completed (loss: 3.733520030975342, acc: 0.2620689570903778)
[2024-12-17 01:45:45,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,119][root][INFO] - Training Epoch: 1/2, step 1777/7134 completed (loss: 3.331216335296631, acc: 0.331210196018219)
[2024-12-17 01:45:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,488][root][INFO] - Training Epoch: 1/2, step 1778/7134 completed (loss: 3.8479325771331787, acc: 0.3270440399646759)
[2024-12-17 01:45:46,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:46,846][root][INFO] - Training Epoch: 1/2, step 1779/7134 completed (loss: 3.3902602195739746, acc: 0.37168142199516296)
[2024-12-17 01:45:47,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,308][root][INFO] - Training Epoch: 1/2, step 1780/7134 completed (loss: 3.544393301010132, acc: 0.32335329055786133)
[2024-12-17 01:45:47,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:47,667][root][INFO] - Training Epoch: 1/2, step 1781/7134 completed (loss: 3.844102382659912, acc: 0.268456369638443)
[2024-12-17 01:45:47,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:48,106][root][INFO] - Training Epoch: 1/2, step 1782/7134 completed (loss: 3.7484495639801025, acc: 0.33974358439445496)
[2024-12-17 01:45:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:49,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:50,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:51,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:52,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:53,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:54,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:55,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:56,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:57,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:58,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:45:59,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:00,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:01,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:02,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:03,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:05,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:06,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:07,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:08,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:09,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:10,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:11,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:12,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:13,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:14,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:15,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:16,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:17,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:18,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:19,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:21,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:22,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:23,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:24,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:25,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:26,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:27,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:28,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:29,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:31,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:32,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:33,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:34,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:38,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:39,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:42,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:43,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:44,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:46,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:48,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:49,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:50,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:51,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:52,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:53,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:54,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:55,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:56,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:57,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:58,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:46:59,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:02,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:03,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:04,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:05,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:06,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:07,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:08,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:09,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:10,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:11,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:12,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:13,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:14,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:15,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:16,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:17,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:18,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:19,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:21,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:22,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:23,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:24,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:25,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:27,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:28,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:29,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:30,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:31,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:32,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:33,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:34,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:35,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:36,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:37,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:38,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:39,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:40,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:41,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:42,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:43,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:44,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:45,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:46,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:48,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:49,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:50,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:51,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:52,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:53,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:54,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:55,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:56,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:57,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:58,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:47:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:00,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:01,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:02,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:03,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:04,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:05,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:06,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:07,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:08,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:09,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:10,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:11,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:12,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:14,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:15,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:16,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:17,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:18,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:19,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:20,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:21,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:22,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:23,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:24,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:25,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:26,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:27,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:29,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:30,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:31,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:32,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:33,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:35,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:36,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:37,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:38,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:39,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:40,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:42,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:43,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:44,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:45,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:46,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:47,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:48,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:49,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:50,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:51,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:52,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:53,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:54,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:55,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:56,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:57,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:58,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:48:59,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:00,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:01,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:02,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:03,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:04,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:05,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:06,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:07,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:08,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:09,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:10,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:11,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:15,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:16,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:17,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:18,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:19,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:20,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:21,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:22,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:23,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:24,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:26,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:27,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:28,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:29,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:31,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:32,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:33,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:34,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:35,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:36,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:37,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:38,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:39,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:40,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:41,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:42,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:43,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:44,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:46,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:47,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:48,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:49,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:50,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:51,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:52,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:53,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:54,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:55,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:56,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:57,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:58,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:49:59,997][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(57.3666, device='cuda:0') eval_epoch_loss=tensor(4.0495, device='cuda:0') eval_epoch_acc=tensor(0.2940, device='cuda:0')
[2024-12-17 01:49:59,999][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 01:49:59,999][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 01:50:00,257][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_1783_loss_4.04946231842041/model.pt
[2024-12-17 01:50:00,261][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 01:50:00,261][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 4.04946231842041
[2024-12-17 01:50:00,262][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.29404059052467346
[2024-12-17 01:50:00,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:00,658][root][INFO] - Training Epoch: 1/2, step 1783/7134 completed (loss: 3.7763357162475586, acc: 0.32947975397109985)
[2024-12-17 01:50:00,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,031][root][INFO] - Training Epoch: 1/2, step 1784/7134 completed (loss: 3.5890424251556396, acc: 0.30128204822540283)
[2024-12-17 01:50:01,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,408][root][INFO] - Training Epoch: 1/2, step 1785/7134 completed (loss: 3.8651671409606934, acc: 0.3253012001514435)
[2024-12-17 01:50:01,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:01,766][root][INFO] - Training Epoch: 1/2, step 1786/7134 completed (loss: 3.745338201522827, acc: 0.3096774220466614)
[2024-12-17 01:50:01,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,137][root][INFO] - Training Epoch: 1/2, step 1787/7134 completed (loss: 4.088630676269531, acc: 0.305970162153244)
[2024-12-17 01:50:02,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,522][root][INFO] - Training Epoch: 1/2, step 1788/7134 completed (loss: 3.82049822807312, acc: 0.30344828963279724)
[2024-12-17 01:50:02,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:02,888][root][INFO] - Training Epoch: 1/2, step 1789/7134 completed (loss: 4.104272365570068, acc: 0.29605263471603394)
[2024-12-17 01:50:03,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,306][root][INFO] - Training Epoch: 1/2, step 1790/7134 completed (loss: 3.4588756561279297, acc: 0.37419354915618896)
[2024-12-17 01:50:03,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:03,684][root][INFO] - Training Epoch: 1/2, step 1791/7134 completed (loss: 4.384266376495361, acc: 0.3251533806324005)
[2024-12-17 01:50:03,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,057][root][INFO] - Training Epoch: 1/2, step 1792/7134 completed (loss: 4.177864074707031, acc: 0.2793295979499817)
[2024-12-17 01:50:04,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,435][root][INFO] - Training Epoch: 1/2, step 1793/7134 completed (loss: 4.312376976013184, acc: 0.33136093616485596)
[2024-12-17 01:50:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:04,818][root][INFO] - Training Epoch: 1/2, step 1794/7134 completed (loss: 4.294506549835205, acc: 0.2565789520740509)
[2024-12-17 01:50:04,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,189][root][INFO] - Training Epoch: 1/2, step 1795/7134 completed (loss: 4.468815803527832, acc: 0.26875001192092896)
[2024-12-17 01:50:05,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,557][root][INFO] - Training Epoch: 1/2, step 1796/7134 completed (loss: 3.918375015258789, acc: 0.31073445081710815)
[2024-12-17 01:50:05,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:05,927][root][INFO] - Training Epoch: 1/2, step 1797/7134 completed (loss: 4.260064125061035, acc: 0.2800000011920929)
[2024-12-17 01:50:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,299][root][INFO] - Training Epoch: 1/2, step 1798/7134 completed (loss: 4.237933158874512, acc: 0.2945736348628998)
[2024-12-17 01:50:06,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:06,698][root][INFO] - Training Epoch: 1/2, step 1799/7134 completed (loss: 4.096704483032227, acc: 0.34343433380126953)
[2024-12-17 01:50:06,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,102][root][INFO] - Training Epoch: 1/2, step 1800/7134 completed (loss: 4.1543707847595215, acc: 0.3380952477455139)
[2024-12-17 01:50:07,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,470][root][INFO] - Training Epoch: 1/2, step 1801/7134 completed (loss: 4.067522048950195, acc: 0.29729729890823364)
[2024-12-17 01:50:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:07,813][root][INFO] - Training Epoch: 1/2, step 1802/7134 completed (loss: 3.9836320877075195, acc: 0.30319148302078247)
[2024-12-17 01:50:07,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,210][root][INFO] - Training Epoch: 1/2, step 1803/7134 completed (loss: 4.073341369628906, acc: 0.32926830649375916)
[2024-12-17 01:50:08,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,567][root][INFO] - Training Epoch: 1/2, step 1804/7134 completed (loss: 4.013227939605713, acc: 0.27513226866722107)
[2024-12-17 01:50:08,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:08,934][root][INFO] - Training Epoch: 1/2, step 1805/7134 completed (loss: 3.7753071784973145, acc: 0.27485379576683044)
[2024-12-17 01:50:09,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,302][root][INFO] - Training Epoch: 1/2, step 1806/7134 completed (loss: 3.9526047706604004, acc: 0.3060109317302704)
[2024-12-17 01:50:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:09,669][root][INFO] - Training Epoch: 1/2, step 1807/7134 completed (loss: 4.368010997772217, acc: 0.2409638613462448)
[2024-12-17 01:50:09,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,042][root][INFO] - Training Epoch: 1/2, step 1808/7134 completed (loss: 4.237064838409424, acc: 0.2429378479719162)
[2024-12-17 01:50:10,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,451][root][INFO] - Training Epoch: 1/2, step 1809/7134 completed (loss: 4.101815700531006, acc: 0.27167630195617676)
[2024-12-17 01:50:10,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:10,832][root][INFO] - Training Epoch: 1/2, step 1810/7134 completed (loss: 3.86969256401062, acc: 0.29120880365371704)
[2024-12-17 01:50:10,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,241][root][INFO] - Training Epoch: 1/2, step 1811/7134 completed (loss: 4.131830215454102, acc: 0.27659574151039124)
[2024-12-17 01:50:11,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,611][root][INFO] - Training Epoch: 1/2, step 1812/7134 completed (loss: 4.020196914672852, acc: 0.3050847351551056)
[2024-12-17 01:50:11,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:11,996][root][INFO] - Training Epoch: 1/2, step 1813/7134 completed (loss: 4.320014476776123, acc: 0.3425414264202118)
[2024-12-17 01:50:12,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,369][root][INFO] - Training Epoch: 1/2, step 1814/7134 completed (loss: 3.860544443130493, acc: 0.31491711735725403)
[2024-12-17 01:50:12,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:12,746][root][INFO] - Training Epoch: 1/2, step 1815/7134 completed (loss: 4.13893985748291, acc: 0.3439490497112274)
[2024-12-17 01:50:12,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,158][root][INFO] - Training Epoch: 1/2, step 1816/7134 completed (loss: 4.538235664367676, acc: 0.2847222089767456)
[2024-12-17 01:50:13,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,563][root][INFO] - Training Epoch: 1/2, step 1817/7134 completed (loss: 4.159768104553223, acc: 0.2864583432674408)
[2024-12-17 01:50:13,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:13,954][root][INFO] - Training Epoch: 1/2, step 1818/7134 completed (loss: 4.038427352905273, acc: 0.30890053510665894)
[2024-12-17 01:50:14,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,337][root][INFO] - Training Epoch: 1/2, step 1819/7134 completed (loss: 3.9070754051208496, acc: 0.31976744532585144)
[2024-12-17 01:50:14,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:14,777][root][INFO] - Training Epoch: 1/2, step 1820/7134 completed (loss: 4.233462810516357, acc: 0.25943395495414734)
[2024-12-17 01:50:14,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,151][root][INFO] - Training Epoch: 1/2, step 1821/7134 completed (loss: 3.666546106338501, acc: 0.30841121077537537)
[2024-12-17 01:50:15,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:15,610][root][INFO] - Training Epoch: 1/2, step 1822/7134 completed (loss: 3.816823959350586, acc: 0.3486842215061188)
[2024-12-17 01:50:15,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,006][root][INFO] - Training Epoch: 1/2, step 1823/7134 completed (loss: 3.7393507957458496, acc: 0.3139534890651703)
[2024-12-17 01:50:16,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,391][root][INFO] - Training Epoch: 1/2, step 1824/7134 completed (loss: 3.9164392948150635, acc: 0.2950819730758667)
[2024-12-17 01:50:16,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:16,785][root][INFO] - Training Epoch: 1/2, step 1825/7134 completed (loss: 3.6984150409698486, acc: 0.3037383258342743)
[2024-12-17 01:50:16,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,167][root][INFO] - Training Epoch: 1/2, step 1826/7134 completed (loss: 3.834146738052368, acc: 0.2573099434375763)
[2024-12-17 01:50:17,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,541][root][INFO] - Training Epoch: 1/2, step 1827/7134 completed (loss: 3.479445695877075, acc: 0.3364928960800171)
[2024-12-17 01:50:17,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:17,931][root][INFO] - Training Epoch: 1/2, step 1828/7134 completed (loss: 3.734525442123413, acc: 0.3499999940395355)
[2024-12-17 01:50:18,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,324][root][INFO] - Training Epoch: 1/2, step 1829/7134 completed (loss: 4.212125778198242, acc: 0.25806450843811035)
[2024-12-17 01:50:18,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:18,702][root][INFO] - Training Epoch: 1/2, step 1830/7134 completed (loss: 4.205299377441406, acc: 0.23834197223186493)
[2024-12-17 01:50:18,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,109][root][INFO] - Training Epoch: 1/2, step 1831/7134 completed (loss: 4.350657939910889, acc: 0.27272728085517883)
[2024-12-17 01:50:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,523][root][INFO] - Training Epoch: 1/2, step 1832/7134 completed (loss: 3.9329586029052734, acc: 0.356589138507843)
[2024-12-17 01:50:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:19,935][root][INFO] - Training Epoch: 1/2, step 1833/7134 completed (loss: 4.347067832946777, acc: 0.27642276883125305)
[2024-12-17 01:50:20,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,335][root][INFO] - Training Epoch: 1/2, step 1834/7134 completed (loss: 3.553914785385132, acc: 0.32692307233810425)
[2024-12-17 01:50:20,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:20,697][root][INFO] - Training Epoch: 1/2, step 1835/7134 completed (loss: 4.097720623016357, acc: 0.2792207896709442)
[2024-12-17 01:50:20,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,067][root][INFO] - Training Epoch: 1/2, step 1836/7134 completed (loss: 3.747887372970581, acc: 0.3368983864784241)
[2024-12-17 01:50:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,448][root][INFO] - Training Epoch: 1/2, step 1837/7134 completed (loss: 4.187170505523682, acc: 0.2857142984867096)
[2024-12-17 01:50:21,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:21,880][root][INFO] - Training Epoch: 1/2, step 1838/7134 completed (loss: 4.039122581481934, acc: 0.2844036817550659)
[2024-12-17 01:50:21,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,273][root][INFO] - Training Epoch: 1/2, step 1839/7134 completed (loss: 3.596719264984131, acc: 0.3351648449897766)
[2024-12-17 01:50:22,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:22,725][root][INFO] - Training Epoch: 1/2, step 1840/7134 completed (loss: 4.051905632019043, acc: 0.3037974536418915)
[2024-12-17 01:50:22,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,112][root][INFO] - Training Epoch: 1/2, step 1841/7134 completed (loss: 3.8713479042053223, acc: 0.34545454382896423)
[2024-12-17 01:50:23,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,486][root][INFO] - Training Epoch: 1/2, step 1842/7134 completed (loss: 3.7154574394226074, acc: 0.32926830649375916)
[2024-12-17 01:50:23,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:23,871][root][INFO] - Training Epoch: 1/2, step 1843/7134 completed (loss: 3.8113853931427, acc: 0.3214285671710968)
[2024-12-17 01:50:23,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,248][root][INFO] - Training Epoch: 1/2, step 1844/7134 completed (loss: 3.0527727603912354, acc: 0.3617021143436432)
[2024-12-17 01:50:24,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:24,629][root][INFO] - Training Epoch: 1/2, step 1845/7134 completed (loss: 3.9284660816192627, acc: 0.29347825050354004)
[2024-12-17 01:50:24,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,009][root][INFO] - Training Epoch: 1/2, step 1846/7134 completed (loss: 3.506565570831299, acc: 0.3461538553237915)
[2024-12-17 01:50:25,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,383][root][INFO] - Training Epoch: 1/2, step 1847/7134 completed (loss: 4.085996150970459, acc: 0.2613636255264282)
[2024-12-17 01:50:25,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:25,764][root][INFO] - Training Epoch: 1/2, step 1848/7134 completed (loss: 4.257010459899902, acc: 0.25)
[2024-12-17 01:50:25,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,131][root][INFO] - Training Epoch: 1/2, step 1849/7134 completed (loss: 4.285415172576904, acc: 0.26056337356567383)
[2024-12-17 01:50:26,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,503][root][INFO] - Training Epoch: 1/2, step 1850/7134 completed (loss: 4.0718092918396, acc: 0.30927833914756775)
[2024-12-17 01:50:26,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:26,874][root][INFO] - Training Epoch: 1/2, step 1851/7134 completed (loss: 4.094005584716797, acc: 0.28205129504203796)
[2024-12-17 01:50:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,239][root][INFO] - Training Epoch: 1/2, step 1852/7134 completed (loss: 4.515330791473389, acc: 0.2750000059604645)
[2024-12-17 01:50:27,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,605][root][INFO] - Training Epoch: 1/2, step 1853/7134 completed (loss: 3.8766744136810303, acc: 0.34170854091644287)
[2024-12-17 01:50:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:27,977][root][INFO] - Training Epoch: 1/2, step 1854/7134 completed (loss: 3.5289723873138428, acc: 0.37556561827659607)
[2024-12-17 01:50:28,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,349][root][INFO] - Training Epoch: 1/2, step 1855/7134 completed (loss: 3.9161934852600098, acc: 0.3364928960800171)
[2024-12-17 01:50:28,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:28,697][root][INFO] - Training Epoch: 1/2, step 1856/7134 completed (loss: 3.8078625202178955, acc: 0.3469387888908386)
[2024-12-17 01:50:28,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,127][root][INFO] - Training Epoch: 1/2, step 1857/7134 completed (loss: 4.118015766143799, acc: 0.28431373834609985)
[2024-12-17 01:50:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,501][root][INFO] - Training Epoch: 1/2, step 1858/7134 completed (loss: 3.6954824924468994, acc: 0.3265306055545807)
[2024-12-17 01:50:29,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:29,879][root][INFO] - Training Epoch: 1/2, step 1859/7134 completed (loss: 3.713277816772461, acc: 0.3253588378429413)
[2024-12-17 01:50:29,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,242][root][INFO] - Training Epoch: 1/2, step 1860/7134 completed (loss: 3.717139720916748, acc: 0.284153014421463)
[2024-12-17 01:50:30,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:30,629][root][INFO] - Training Epoch: 1/2, step 1861/7134 completed (loss: 3.614375114440918, acc: 0.33507853746414185)
[2024-12-17 01:50:30,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,017][root][INFO] - Training Epoch: 1/2, step 1862/7134 completed (loss: 3.764791250228882, acc: 0.2698412835597992)
[2024-12-17 01:50:31,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,409][root][INFO] - Training Epoch: 1/2, step 1863/7134 completed (loss: 3.178349733352661, acc: 0.3694581389427185)
[2024-12-17 01:50:31,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:31,798][root][INFO] - Training Epoch: 1/2, step 1864/7134 completed (loss: 3.7430379390716553, acc: 0.2842639684677124)
[2024-12-17 01:50:31,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,175][root][INFO] - Training Epoch: 1/2, step 1865/7134 completed (loss: 3.897674322128296, acc: 0.28859061002731323)
[2024-12-17 01:50:32,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,549][root][INFO] - Training Epoch: 1/2, step 1866/7134 completed (loss: 3.339136838912964, acc: 0.3176470696926117)
[2024-12-17 01:50:32,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:32,949][root][INFO] - Training Epoch: 1/2, step 1867/7134 completed (loss: 3.7487807273864746, acc: 0.33522728085517883)
[2024-12-17 01:50:33,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,385][root][INFO] - Training Epoch: 1/2, step 1868/7134 completed (loss: 4.007946014404297, acc: 0.2822085916996002)
[2024-12-17 01:50:33,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:33,778][root][INFO] - Training Epoch: 1/2, step 1869/7134 completed (loss: 3.4355709552764893, acc: 0.3561643958091736)
[2024-12-17 01:50:33,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,218][root][INFO] - Training Epoch: 1/2, step 1870/7134 completed (loss: 3.4864914417266846, acc: 0.3837837874889374)
[2024-12-17 01:50:34,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,592][root][INFO] - Training Epoch: 1/2, step 1871/7134 completed (loss: 3.588557004928589, acc: 0.3354838788509369)
[2024-12-17 01:50:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:34,925][root][INFO] - Training Epoch: 1/2, step 1872/7134 completed (loss: 6.257119655609131, acc: 0.14492753148078918)
[2024-12-17 01:50:35,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,300][root][INFO] - Training Epoch: 1/2, step 1873/7134 completed (loss: 4.6779069900512695, acc: 0.23966942727565765)
[2024-12-17 01:50:35,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:35,685][root][INFO] - Training Epoch: 1/2, step 1874/7134 completed (loss: 3.9916887283325195, acc: 0.2931034564971924)
[2024-12-17 01:50:35,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,068][root][INFO] - Training Epoch: 1/2, step 1875/7134 completed (loss: 3.4759178161621094, acc: 0.3214285671710968)
[2024-12-17 01:50:36,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,436][root][INFO] - Training Epoch: 1/2, step 1876/7134 completed (loss: 4.082526683807373, acc: 0.2628571391105652)
[2024-12-17 01:50:36,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:36,804][root][INFO] - Training Epoch: 1/2, step 1877/7134 completed (loss: 3.649637460708618, acc: 0.3615819215774536)
[2024-12-17 01:50:36,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,162][root][INFO] - Training Epoch: 1/2, step 1878/7134 completed (loss: 3.582298517227173, acc: 0.35947713255882263)
[2024-12-17 01:50:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,533][root][INFO] - Training Epoch: 1/2, step 1879/7134 completed (loss: 4.035803318023682, acc: 0.3333333432674408)
[2024-12-17 01:50:37,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:37,912][root][INFO] - Training Epoch: 1/2, step 1880/7134 completed (loss: 4.507809162139893, acc: 0.3414634168148041)
[2024-12-17 01:50:38,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,269][root][INFO] - Training Epoch: 1/2, step 1881/7134 completed (loss: 4.354615688323975, acc: 0.27464789152145386)
[2024-12-17 01:50:38,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,615][root][INFO] - Training Epoch: 1/2, step 1882/7134 completed (loss: 4.948633193969727, acc: 0.20652173459529877)
[2024-12-17 01:50:38,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:38,978][root][INFO] - Training Epoch: 1/2, step 1883/7134 completed (loss: 4.255716800689697, acc: 0.26356589794158936)
[2024-12-17 01:50:39,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,342][root][INFO] - Training Epoch: 1/2, step 1884/7134 completed (loss: 4.6195173263549805, acc: 0.2635135054588318)
[2024-12-17 01:50:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:39,719][root][INFO] - Training Epoch: 1/2, step 1885/7134 completed (loss: 4.540711402893066, acc: 0.28169015049934387)
[2024-12-17 01:50:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,091][root][INFO] - Training Epoch: 1/2, step 1886/7134 completed (loss: 4.392245769500732, acc: 0.30158731341362)
[2024-12-17 01:50:40,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,459][root][INFO] - Training Epoch: 1/2, step 1887/7134 completed (loss: 4.0192365646362305, acc: 0.3576158881187439)
[2024-12-17 01:50:40,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:40,843][root][INFO] - Training Epoch: 1/2, step 1888/7134 completed (loss: 4.564698219299316, acc: 0.3076923191547394)
[2024-12-17 01:50:40,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,223][root][INFO] - Training Epoch: 1/2, step 1889/7134 completed (loss: 3.659017324447632, acc: 0.3333333432674408)
[2024-12-17 01:50:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,608][root][INFO] - Training Epoch: 1/2, step 1890/7134 completed (loss: 3.40670108795166, acc: 0.37748345732688904)
[2024-12-17 01:50:41,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:41,978][root][INFO] - Training Epoch: 1/2, step 1891/7134 completed (loss: 4.054464817047119, acc: 0.3255814015865326)
[2024-12-17 01:50:42,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,355][root][INFO] - Training Epoch: 1/2, step 1892/7134 completed (loss: 4.486504077911377, acc: 0.2934131622314453)
[2024-12-17 01:50:42,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:42,716][root][INFO] - Training Epoch: 1/2, step 1893/7134 completed (loss: 4.009812355041504, acc: 0.327160507440567)
[2024-12-17 01:50:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,122][root][INFO] - Training Epoch: 1/2, step 1894/7134 completed (loss: 4.550589561462402, acc: 0.29054054617881775)
[2024-12-17 01:50:43,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,537][root][INFO] - Training Epoch: 1/2, step 1895/7134 completed (loss: 4.8682708740234375, acc: 0.24719101190567017)
[2024-12-17 01:50:43,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:43,926][root][INFO] - Training Epoch: 1/2, step 1896/7134 completed (loss: 4.474686145782471, acc: 0.2181818187236786)
[2024-12-17 01:50:44,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,304][root][INFO] - Training Epoch: 1/2, step 1897/7134 completed (loss: 4.150319576263428, acc: 0.2887323796749115)
[2024-12-17 01:50:44,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:44,674][root][INFO] - Training Epoch: 1/2, step 1898/7134 completed (loss: 3.9802494049072266, acc: 0.317241370677948)
[2024-12-17 01:50:44,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,036][root][INFO] - Training Epoch: 1/2, step 1899/7134 completed (loss: 4.512931823730469, acc: 0.2651515007019043)
[2024-12-17 01:50:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,408][root][INFO] - Training Epoch: 1/2, step 1900/7134 completed (loss: 4.2396650314331055, acc: 0.29411765933036804)
[2024-12-17 01:50:45,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:45,777][root][INFO] - Training Epoch: 1/2, step 1901/7134 completed (loss: 4.22260046005249, acc: 0.3093525171279907)
[2024-12-17 01:50:45,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,153][root][INFO] - Training Epoch: 1/2, step 1902/7134 completed (loss: 3.9578351974487305, acc: 0.2949640154838562)
[2024-12-17 01:50:46,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,528][root][INFO] - Training Epoch: 1/2, step 1903/7134 completed (loss: 3.9776909351348877, acc: 0.27450981736183167)
[2024-12-17 01:50:46,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:46,874][root][INFO] - Training Epoch: 1/2, step 1904/7134 completed (loss: 4.0973663330078125, acc: 0.3047619163990021)
[2024-12-17 01:50:46,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,237][root][INFO] - Training Epoch: 1/2, step 1905/7134 completed (loss: 3.84958553314209, acc: 0.347517728805542)
[2024-12-17 01:50:47,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:47,647][root][INFO] - Training Epoch: 1/2, step 1906/7134 completed (loss: 3.247953414916992, acc: 0.39416059851646423)
[2024-12-17 01:50:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,018][root][INFO] - Training Epoch: 1/2, step 1907/7134 completed (loss: 3.8303239345550537, acc: 0.31292515993118286)
[2024-12-17 01:50:48,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,385][root][INFO] - Training Epoch: 1/2, step 1908/7134 completed (loss: 3.7887089252471924, acc: 0.3037383258342743)
[2024-12-17 01:50:48,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:48,753][root][INFO] - Training Epoch: 1/2, step 1909/7134 completed (loss: 4.058930397033691, acc: 0.22448979318141937)
[2024-12-17 01:50:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,129][root][INFO] - Training Epoch: 1/2, step 1910/7134 completed (loss: 3.8497376441955566, acc: 0.31162789463996887)
[2024-12-17 01:50:49,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,545][root][INFO] - Training Epoch: 1/2, step 1911/7134 completed (loss: 3.4638724327087402, acc: 0.3096446692943573)
[2024-12-17 01:50:49,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:49,977][root][INFO] - Training Epoch: 1/2, step 1912/7134 completed (loss: 3.728956460952759, acc: 0.30909091234207153)
[2024-12-17 01:50:50,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,362][root][INFO] - Training Epoch: 1/2, step 1913/7134 completed (loss: 3.9882652759552, acc: 0.27559053897857666)
[2024-12-17 01:50:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:50,790][root][INFO] - Training Epoch: 1/2, step 1914/7134 completed (loss: 3.7396984100341797, acc: 0.30054643750190735)
[2024-12-17 01:50:50,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,201][root][INFO] - Training Epoch: 1/2, step 1915/7134 completed (loss: 3.6027495861053467, acc: 0.32867133617401123)
[2024-12-17 01:50:51,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,573][root][INFO] - Training Epoch: 1/2, step 1916/7134 completed (loss: 4.2726263999938965, acc: 0.24175824224948883)
[2024-12-17 01:50:51,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:51,945][root][INFO] - Training Epoch: 1/2, step 1917/7134 completed (loss: 3.8691658973693848, acc: 0.23030303418636322)
[2024-12-17 01:50:52,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,284][root][INFO] - Training Epoch: 1/2, step 1918/7134 completed (loss: 3.89851713180542, acc: 0.23178808391094208)
[2024-12-17 01:50:52,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:52,683][root][INFO] - Training Epoch: 1/2, step 1919/7134 completed (loss: 3.592890977859497, acc: 0.35975611209869385)
[2024-12-17 01:50:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,055][root][INFO] - Training Epoch: 1/2, step 1920/7134 completed (loss: 4.107451438903809, acc: 0.25850340723991394)
[2024-12-17 01:50:53,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,405][root][INFO] - Training Epoch: 1/2, step 1921/7134 completed (loss: 3.971564769744873, acc: 0.28070175647735596)
[2024-12-17 01:50:53,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:53,783][root][INFO] - Training Epoch: 1/2, step 1922/7134 completed (loss: 3.1133105754852295, acc: 0.35655736923217773)
[2024-12-17 01:50:53,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,149][root][INFO] - Training Epoch: 1/2, step 1923/7134 completed (loss: 3.483973741531372, acc: 0.3216783106327057)
[2024-12-17 01:50:54,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,510][root][INFO] - Training Epoch: 1/2, step 1924/7134 completed (loss: 3.1528120040893555, acc: 0.40625)
[2024-12-17 01:50:54,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:54,884][root][INFO] - Training Epoch: 1/2, step 1925/7134 completed (loss: 3.2984540462493896, acc: 0.3472803235054016)
[2024-12-17 01:50:54,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,243][root][INFO] - Training Epoch: 1/2, step 1926/7134 completed (loss: 3.504882574081421, acc: 0.3169642984867096)
[2024-12-17 01:50:55,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:55,623][root][INFO] - Training Epoch: 1/2, step 1927/7134 completed (loss: 3.6235618591308594, acc: 0.25471699237823486)
[2024-12-17 01:50:55,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,015][root][INFO] - Training Epoch: 1/2, step 1928/7134 completed (loss: 3.977121353149414, acc: 0.2678571343421936)
[2024-12-17 01:50:56,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,412][root][INFO] - Training Epoch: 1/2, step 1929/7134 completed (loss: 3.833956480026245, acc: 0.2793295979499817)
[2024-12-17 01:50:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:56,781][root][INFO] - Training Epoch: 1/2, step 1930/7134 completed (loss: 4.181360721588135, acc: 0.28985506296157837)
[2024-12-17 01:50:56,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,158][root][INFO] - Training Epoch: 1/2, step 1931/7134 completed (loss: 3.9533932209014893, acc: 0.29629629850387573)
[2024-12-17 01:50:57,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,519][root][INFO] - Training Epoch: 1/2, step 1932/7134 completed (loss: 4.042303085327148, acc: 0.27374300360679626)
[2024-12-17 01:50:57,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:57,900][root][INFO] - Training Epoch: 1/2, step 1933/7134 completed (loss: 4.264251708984375, acc: 0.2713567912578583)
[2024-12-17 01:50:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,275][root][INFO] - Training Epoch: 1/2, step 1934/7134 completed (loss: 4.209948539733887, acc: 0.24571429193019867)
[2024-12-17 01:50:58,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:58,669][root][INFO] - Training Epoch: 1/2, step 1935/7134 completed (loss: 4.2247796058654785, acc: 0.19512194395065308)
[2024-12-17 01:50:58,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,045][root][INFO] - Training Epoch: 1/2, step 1936/7134 completed (loss: 4.111063003540039, acc: 0.22875817120075226)
[2024-12-17 01:50:59,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,395][root][INFO] - Training Epoch: 1/2, step 1937/7134 completed (loss: 3.9002041816711426, acc: 0.24390244483947754)
[2024-12-17 01:50:59,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:50:59,765][root][INFO] - Training Epoch: 1/2, step 1938/7134 completed (loss: 4.285937309265137, acc: 0.27173912525177)
[2024-12-17 01:50:59,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,131][root][INFO] - Training Epoch: 1/2, step 1939/7134 completed (loss: 3.9265925884246826, acc: 0.2844827473163605)
[2024-12-17 01:51:00,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,492][root][INFO] - Training Epoch: 1/2, step 1940/7134 completed (loss: 3.891799211502075, acc: 0.3053892254829407)
[2024-12-17 01:51:00,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:00,856][root][INFO] - Training Epoch: 1/2, step 1941/7134 completed (loss: 3.8777201175689697, acc: 0.3076923191547394)
[2024-12-17 01:51:00,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,235][root][INFO] - Training Epoch: 1/2, step 1942/7134 completed (loss: 4.129189491271973, acc: 0.32407405972480774)
[2024-12-17 01:51:01,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,607][root][INFO] - Training Epoch: 1/2, step 1943/7134 completed (loss: 3.8836467266082764, acc: 0.28421053290367126)
[2024-12-17 01:51:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:01,967][root][INFO] - Training Epoch: 1/2, step 1944/7134 completed (loss: 3.8963863849639893, acc: 0.30327868461608887)
[2024-12-17 01:51:02,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,330][root][INFO] - Training Epoch: 1/2, step 1945/7134 completed (loss: 4.165834426879883, acc: 0.30645161867141724)
[2024-12-17 01:51:02,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:02,708][root][INFO] - Training Epoch: 1/2, step 1946/7134 completed (loss: 3.8951478004455566, acc: 0.33571428060531616)
[2024-12-17 01:51:02,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,073][root][INFO] - Training Epoch: 1/2, step 1947/7134 completed (loss: 3.991811513900757, acc: 0.3005780279636383)
[2024-12-17 01:51:03,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,434][root][INFO] - Training Epoch: 1/2, step 1948/7134 completed (loss: 3.4117214679718018, acc: 0.4000000059604645)
[2024-12-17 01:51:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:03,784][root][INFO] - Training Epoch: 1/2, step 1949/7134 completed (loss: 3.7154242992401123, acc: 0.3246753215789795)
[2024-12-17 01:51:03,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,155][root][INFO] - Training Epoch: 1/2, step 1950/7134 completed (loss: 3.6033458709716797, acc: 0.3188405930995941)
[2024-12-17 01:51:04,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,554][root][INFO] - Training Epoch: 1/2, step 1951/7134 completed (loss: 3.9339754581451416, acc: 0.3458646535873413)
[2024-12-17 01:51:04,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:04,922][root][INFO] - Training Epoch: 1/2, step 1952/7134 completed (loss: 3.790051221847534, acc: 0.3313252925872803)
[2024-12-17 01:51:05,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,292][root][INFO] - Training Epoch: 1/2, step 1953/7134 completed (loss: 3.927335262298584, acc: 0.3544303774833679)
[2024-12-17 01:51:05,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:05,649][root][INFO] - Training Epoch: 1/2, step 1954/7134 completed (loss: 3.680034875869751, acc: 0.30392158031463623)
[2024-12-17 01:51:05,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,013][root][INFO] - Training Epoch: 1/2, step 1955/7134 completed (loss: 3.9410605430603027, acc: 0.3283582031726837)
[2024-12-17 01:51:06,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,345][root][INFO] - Training Epoch: 1/2, step 1956/7134 completed (loss: 3.853567123413086, acc: 0.28260868787765503)
[2024-12-17 01:51:06,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:06,714][root][INFO] - Training Epoch: 1/2, step 1957/7134 completed (loss: 3.958301544189453, acc: 0.24812030792236328)
[2024-12-17 01:51:06,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,061][root][INFO] - Training Epoch: 1/2, step 1958/7134 completed (loss: 3.845472812652588, acc: 0.2888889014720917)
[2024-12-17 01:51:07,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,445][root][INFO] - Training Epoch: 1/2, step 1959/7134 completed (loss: 4.00889253616333, acc: 0.3035714328289032)
[2024-12-17 01:51:07,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:07,810][root][INFO] - Training Epoch: 1/2, step 1960/7134 completed (loss: 3.782343626022339, acc: 0.3499999940395355)
[2024-12-17 01:51:07,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,170][root][INFO] - Training Epoch: 1/2, step 1961/7134 completed (loss: 3.8562228679656982, acc: 0.3164556920528412)
[2024-12-17 01:51:08,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,542][root][INFO] - Training Epoch: 1/2, step 1962/7134 completed (loss: 4.0131402015686035, acc: 0.2183908075094223)
[2024-12-17 01:51:08,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:08,905][root][INFO] - Training Epoch: 1/2, step 1963/7134 completed (loss: 3.829540491104126, acc: 0.34437087178230286)
[2024-12-17 01:51:08,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,262][root][INFO] - Training Epoch: 1/2, step 1964/7134 completed (loss: 3.832990884780884, acc: 0.3333333432674408)
[2024-12-17 01:51:09,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:09,622][root][INFO] - Training Epoch: 1/2, step 1965/7134 completed (loss: 3.9799156188964844, acc: 0.3314606845378876)
[2024-12-17 01:51:09,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,011][root][INFO] - Training Epoch: 1/2, step 1966/7134 completed (loss: 4.190808296203613, acc: 0.36305731534957886)
[2024-12-17 01:51:10,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,399][root][INFO] - Training Epoch: 1/2, step 1967/7134 completed (loss: 3.935929536819458, acc: 0.3105263113975525)
[2024-12-17 01:51:10,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:10,768][root][INFO] - Training Epoch: 1/2, step 1968/7134 completed (loss: 3.810044050216675, acc: 0.34574466943740845)
[2024-12-17 01:51:10,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,129][root][INFO] - Training Epoch: 1/2, step 1969/7134 completed (loss: 3.741978883743286, acc: 0.3785310685634613)
[2024-12-17 01:51:11,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,569][root][INFO] - Training Epoch: 1/2, step 1970/7134 completed (loss: 3.3609824180603027, acc: 0.3964497148990631)
[2024-12-17 01:51:11,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:11,928][root][INFO] - Training Epoch: 1/2, step 1971/7134 completed (loss: 3.685723304748535, acc: 0.3141361176967621)
[2024-12-17 01:51:12,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,280][root][INFO] - Training Epoch: 1/2, step 1972/7134 completed (loss: 4.270626068115234, acc: 0.2719298303127289)
[2024-12-17 01:51:12,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:12,647][root][INFO] - Training Epoch: 1/2, step 1973/7134 completed (loss: 4.423893928527832, acc: 0.2430555522441864)
[2024-12-17 01:51:12,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,034][root][INFO] - Training Epoch: 1/2, step 1974/7134 completed (loss: 3.3703229427337646, acc: 0.3865979313850403)
[2024-12-17 01:51:13,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,394][root][INFO] - Training Epoch: 1/2, step 1975/7134 completed (loss: 3.3712291717529297, acc: 0.35624998807907104)
[2024-12-17 01:51:13,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:13,763][root][INFO] - Training Epoch: 1/2, step 1976/7134 completed (loss: 4.024800777435303, acc: 0.2788461446762085)
[2024-12-17 01:51:13,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,132][root][INFO] - Training Epoch: 1/2, step 1977/7134 completed (loss: 4.081066131591797, acc: 0.24550898373126984)
[2024-12-17 01:51:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,540][root][INFO] - Training Epoch: 1/2, step 1978/7134 completed (loss: 3.1691460609436035, acc: 0.3139534890651703)
[2024-12-17 01:51:14,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:14,919][root][INFO] - Training Epoch: 1/2, step 1979/7134 completed (loss: 3.6827392578125, acc: 0.28021979331970215)
[2024-12-17 01:51:15,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,315][root][INFO] - Training Epoch: 1/2, step 1980/7134 completed (loss: 3.3143198490142822, acc: 0.3298429250717163)
[2024-12-17 01:51:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:15,702][root][INFO] - Training Epoch: 1/2, step 1981/7134 completed (loss: 3.500047206878662, acc: 0.30219781398773193)
[2024-12-17 01:51:15,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,080][root][INFO] - Training Epoch: 1/2, step 1982/7134 completed (loss: 3.477494716644287, acc: 0.28205129504203796)
[2024-12-17 01:51:16,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,424][root][INFO] - Training Epoch: 1/2, step 1983/7134 completed (loss: 3.4030656814575195, acc: 0.2956989109516144)
[2024-12-17 01:51:16,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:16,790][root][INFO] - Training Epoch: 1/2, step 1984/7134 completed (loss: 3.5472891330718994, acc: 0.302325576543808)
[2024-12-17 01:51:16,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,165][root][INFO] - Training Epoch: 1/2, step 1985/7134 completed (loss: 3.521044969558716, acc: 0.34161490201950073)
[2024-12-17 01:51:17,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,533][root][INFO] - Training Epoch: 1/2, step 1986/7134 completed (loss: 3.376549482345581, acc: 0.3463687002658844)
[2024-12-17 01:51:17,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:17,911][root][INFO] - Training Epoch: 1/2, step 1987/7134 completed (loss: 3.7307236194610596, acc: 0.3426966369152069)
[2024-12-17 01:51:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,278][root][INFO] - Training Epoch: 1/2, step 1988/7134 completed (loss: 3.552370309829712, acc: 0.3696969747543335)
[2024-12-17 01:51:18,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:18,627][root][INFO] - Training Epoch: 1/2, step 1989/7134 completed (loss: 3.6628284454345703, acc: 0.3767123222351074)
[2024-12-17 01:51:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,015][root][INFO] - Training Epoch: 1/2, step 1990/7134 completed (loss: 3.594388008117676, acc: 0.31491711735725403)
[2024-12-17 01:51:19,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,409][root][INFO] - Training Epoch: 1/2, step 1991/7134 completed (loss: 4.174956321716309, acc: 0.2822580635547638)
[2024-12-17 01:51:19,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:19,795][root][INFO] - Training Epoch: 1/2, step 1992/7134 completed (loss: 4.7684431076049805, acc: 0.239130437374115)
[2024-12-17 01:51:19,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,172][root][INFO] - Training Epoch: 1/2, step 1993/7134 completed (loss: 4.922235012054443, acc: 0.22608695924282074)
[2024-12-17 01:51:20,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,570][root][INFO] - Training Epoch: 1/2, step 1994/7134 completed (loss: 4.146722316741943, acc: 0.26356589794158936)
[2024-12-17 01:51:20,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:20,961][root][INFO] - Training Epoch: 1/2, step 1995/7134 completed (loss: 3.6983680725097656, acc: 0.32413792610168457)
[2024-12-17 01:51:21,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,345][root][INFO] - Training Epoch: 1/2, step 1996/7134 completed (loss: 4.508479595184326, acc: 0.2846715450286865)
[2024-12-17 01:51:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:21,727][root][INFO] - Training Epoch: 1/2, step 1997/7134 completed (loss: 4.055018424987793, acc: 0.3285714387893677)
[2024-12-17 01:51:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,090][root][INFO] - Training Epoch: 1/2, step 1998/7134 completed (loss: 3.8992390632629395, acc: 0.2887323796749115)
[2024-12-17 01:51:22,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,461][root][INFO] - Training Epoch: 1/2, step 1999/7134 completed (loss: 4.166770935058594, acc: 0.27272728085517883)
[2024-12-17 01:51:22,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:22,839][root][INFO] - Training Epoch: 1/2, step 2000/7134 completed (loss: 4.1762776374816895, acc: 0.2777777910232544)
[2024-12-17 01:51:22,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,186][root][INFO] - Training Epoch: 1/2, step 2001/7134 completed (loss: 3.872683525085449, acc: 0.27586206793785095)
[2024-12-17 01:51:23,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,563][root][INFO] - Training Epoch: 1/2, step 2002/7134 completed (loss: 4.647770881652832, acc: 0.21052631735801697)
[2024-12-17 01:51:23,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:23,944][root][INFO] - Training Epoch: 1/2, step 2003/7134 completed (loss: 3.802762269973755, acc: 0.35087719559669495)
[2024-12-17 01:51:24,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,341][root][INFO] - Training Epoch: 1/2, step 2004/7134 completed (loss: 4.539400100708008, acc: 0.2950819730758667)
[2024-12-17 01:51:24,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:24,783][root][INFO] - Training Epoch: 1/2, step 2005/7134 completed (loss: 3.9773566722869873, acc: 0.3163265287876129)
[2024-12-17 01:51:24,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,154][root][INFO] - Training Epoch: 1/2, step 2006/7134 completed (loss: 4.182021141052246, acc: 0.3372093141078949)
[2024-12-17 01:51:25,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,575][root][INFO] - Training Epoch: 1/2, step 2007/7134 completed (loss: 3.724552869796753, acc: 0.31092438101768494)
[2024-12-17 01:51:25,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:25,940][root][INFO] - Training Epoch: 1/2, step 2008/7134 completed (loss: 4.558116436004639, acc: 0.28082191944122314)
[2024-12-17 01:51:26,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,298][root][INFO] - Training Epoch: 1/2, step 2009/7134 completed (loss: 3.995194911956787, acc: 0.3037036955356598)
[2024-12-17 01:51:26,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:26,663][root][INFO] - Training Epoch: 1/2, step 2010/7134 completed (loss: 4.1000447273254395, acc: 0.262773722410202)
[2024-12-17 01:51:26,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,079][root][INFO] - Training Epoch: 1/2, step 2011/7134 completed (loss: 4.070291996002197, acc: 0.261904776096344)
[2024-12-17 01:51:27,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,465][root][INFO] - Training Epoch: 1/2, step 2012/7134 completed (loss: 4.391118049621582, acc: 0.2711864411830902)
[2024-12-17 01:51:27,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:27,850][root][INFO] - Training Epoch: 1/2, step 2013/7134 completed (loss: 3.9923789501190186, acc: 0.2540983557701111)
[2024-12-17 01:51:27,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,241][root][INFO] - Training Epoch: 1/2, step 2014/7134 completed (loss: 3.6622068881988525, acc: 0.29629629850387573)
[2024-12-17 01:51:28,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:28,612][root][INFO] - Training Epoch: 1/2, step 2015/7134 completed (loss: 3.681769847869873, acc: 0.32499998807907104)
[2024-12-17 01:51:28,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,005][root][INFO] - Training Epoch: 1/2, step 2016/7134 completed (loss: 3.452172040939331, acc: 0.380952388048172)
[2024-12-17 01:51:29,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,375][root][INFO] - Training Epoch: 1/2, step 2017/7134 completed (loss: 4.2039031982421875, acc: 0.3178808093070984)
[2024-12-17 01:51:29,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:29,739][root][INFO] - Training Epoch: 1/2, step 2018/7134 completed (loss: 3.95327091217041, acc: 0.3219178020954132)
[2024-12-17 01:51:29,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,134][root][INFO] - Training Epoch: 1/2, step 2019/7134 completed (loss: 3.8982138633728027, acc: 0.3509933650493622)
[2024-12-17 01:51:30,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,516][root][INFO] - Training Epoch: 1/2, step 2020/7134 completed (loss: 4.0892863273620605, acc: 0.3057851195335388)
[2024-12-17 01:51:30,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:30,907][root][INFO] - Training Epoch: 1/2, step 2021/7134 completed (loss: 3.9813308715820312, acc: 0.3243243098258972)
[2024-12-17 01:51:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,303][root][INFO] - Training Epoch: 1/2, step 2022/7134 completed (loss: 4.1059112548828125, acc: 0.305970162153244)
[2024-12-17 01:51:31,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:31,680][root][INFO] - Training Epoch: 1/2, step 2023/7134 completed (loss: 3.64178466796875, acc: 0.30674847960472107)
[2024-12-17 01:51:31,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,040][root][INFO] - Training Epoch: 1/2, step 2024/7134 completed (loss: 4.053374767303467, acc: 0.2383720874786377)
[2024-12-17 01:51:32,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,436][root][INFO] - Training Epoch: 1/2, step 2025/7134 completed (loss: 3.9957492351531982, acc: 0.2163742631673813)
[2024-12-17 01:51:32,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:32,815][root][INFO] - Training Epoch: 1/2, step 2026/7134 completed (loss: 4.054528713226318, acc: 0.30994153022766113)
[2024-12-17 01:51:32,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,167][root][INFO] - Training Epoch: 1/2, step 2027/7134 completed (loss: 4.736780166625977, acc: 0.19548872113227844)
[2024-12-17 01:51:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:33,561][root][INFO] - Training Epoch: 1/2, step 2028/7134 completed (loss: 3.969270944595337, acc: 0.3251533806324005)
[2024-12-17 01:51:33,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,007][root][INFO] - Training Epoch: 1/2, step 2029/7134 completed (loss: 3.935579538345337, acc: 0.2764706015586853)
[2024-12-17 01:51:34,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,382][root][INFO] - Training Epoch: 1/2, step 2030/7134 completed (loss: 3.7951152324676514, acc: 0.3253012001514435)
[2024-12-17 01:51:34,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:34,765][root][INFO] - Training Epoch: 1/2, step 2031/7134 completed (loss: 3.62865948677063, acc: 0.3093922734260559)
[2024-12-17 01:51:34,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,135][root][INFO] - Training Epoch: 1/2, step 2032/7134 completed (loss: 4.05526876449585, acc: 0.2514619827270508)
[2024-12-17 01:51:35,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,531][root][INFO] - Training Epoch: 1/2, step 2033/7134 completed (loss: 3.8675689697265625, acc: 0.32824426889419556)
[2024-12-17 01:51:35,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:35,913][root][INFO] - Training Epoch: 1/2, step 2034/7134 completed (loss: 3.9712040424346924, acc: 0.268456369638443)
[2024-12-17 01:51:36,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,319][root][INFO] - Training Epoch: 1/2, step 2035/7134 completed (loss: 3.7861077785491943, acc: 0.3494623601436615)
[2024-12-17 01:51:36,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:36,701][root][INFO] - Training Epoch: 1/2, step 2036/7134 completed (loss: 4.143313407897949, acc: 0.2977099120616913)
[2024-12-17 01:51:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,065][root][INFO] - Training Epoch: 1/2, step 2037/7134 completed (loss: 3.7781569957733154, acc: 0.3251533806324005)
[2024-12-17 01:51:37,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,450][root][INFO] - Training Epoch: 1/2, step 2038/7134 completed (loss: 3.832871913909912, acc: 0.3186813294887543)
[2024-12-17 01:51:37,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:37,855][root][INFO] - Training Epoch: 1/2, step 2039/7134 completed (loss: 3.9344918727874756, acc: 0.23357664048671722)
[2024-12-17 01:51:38,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,229][root][INFO] - Training Epoch: 1/2, step 2040/7134 completed (loss: 3.930884838104248, acc: 0.27586206793785095)
[2024-12-17 01:51:38,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,595][root][INFO] - Training Epoch: 1/2, step 2041/7134 completed (loss: 4.303839206695557, acc: 0.260606050491333)
[2024-12-17 01:51:38,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:38,953][root][INFO] - Training Epoch: 1/2, step 2042/7134 completed (loss: 4.057515621185303, acc: 0.3050847351551056)
[2024-12-17 01:51:39,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,324][root][INFO] - Training Epoch: 1/2, step 2043/7134 completed (loss: 3.6385273933410645, acc: 0.3288590610027313)
[2024-12-17 01:51:39,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:39,710][root][INFO] - Training Epoch: 1/2, step 2044/7134 completed (loss: 4.046869277954102, acc: 0.23199999332427979)
[2024-12-17 01:51:39,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,091][root][INFO] - Training Epoch: 1/2, step 2045/7134 completed (loss: 4.18312931060791, acc: 0.28333333134651184)
[2024-12-17 01:51:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,468][root][INFO] - Training Epoch: 1/2, step 2046/7134 completed (loss: 4.250899791717529, acc: 0.29411765933036804)
[2024-12-17 01:51:40,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:40,848][root][INFO] - Training Epoch: 1/2, step 2047/7134 completed (loss: 4.185240745544434, acc: 0.2827586233615875)
[2024-12-17 01:51:40,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,254][root][INFO] - Training Epoch: 1/2, step 2048/7134 completed (loss: 4.171816825866699, acc: 0.3154761791229248)
[2024-12-17 01:51:41,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:41,646][root][INFO] - Training Epoch: 1/2, step 2049/7134 completed (loss: 3.846560478210449, acc: 0.26363635063171387)
[2024-12-17 01:51:41,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,033][root][INFO] - Training Epoch: 1/2, step 2050/7134 completed (loss: 3.804143190383911, acc: 0.33561643958091736)
[2024-12-17 01:51:42,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,400][root][INFO] - Training Epoch: 1/2, step 2051/7134 completed (loss: 4.316511631011963, acc: 0.3539822995662689)
[2024-12-17 01:51:42,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:42,759][root][INFO] - Training Epoch: 1/2, step 2052/7134 completed (loss: 4.008946895599365, acc: 0.3541666567325592)
[2024-12-17 01:51:42,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,205][root][INFO] - Training Epoch: 1/2, step 2053/7134 completed (loss: 4.428236484527588, acc: 0.221374049782753)
[2024-12-17 01:51:43,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,597][root][INFO] - Training Epoch: 1/2, step 2054/7134 completed (loss: 4.404937744140625, acc: 0.2628205120563507)
[2024-12-17 01:51:43,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:43,978][root][INFO] - Training Epoch: 1/2, step 2055/7134 completed (loss: 4.422693729400635, acc: 0.267123281955719)
[2024-12-17 01:51:44,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,407][root][INFO] - Training Epoch: 1/2, step 2056/7134 completed (loss: 4.59356689453125, acc: 0.2711864411830902)
[2024-12-17 01:51:44,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:44,804][root][INFO] - Training Epoch: 1/2, step 2057/7134 completed (loss: 4.3087544441223145, acc: 0.31460675597190857)
[2024-12-17 01:51:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,184][root][INFO] - Training Epoch: 1/2, step 2058/7134 completed (loss: 4.610864162445068, acc: 0.2774566411972046)
[2024-12-17 01:51:45,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,577][root][INFO] - Training Epoch: 1/2, step 2059/7134 completed (loss: 4.448108196258545, acc: 0.26950353384017944)
[2024-12-17 01:51:45,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:45,953][root][INFO] - Training Epoch: 1/2, step 2060/7134 completed (loss: 4.342935562133789, acc: 0.2675159275531769)
[2024-12-17 01:51:46,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,349][root][INFO] - Training Epoch: 1/2, step 2061/7134 completed (loss: 4.533051490783691, acc: 0.2857142984867096)
[2024-12-17 01:51:46,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:46,774][root][INFO] - Training Epoch: 1/2, step 2062/7134 completed (loss: 4.520674705505371, acc: 0.3359375)
[2024-12-17 01:51:46,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,153][root][INFO] - Training Epoch: 1/2, step 2063/7134 completed (loss: 3.8147189617156982, acc: 0.29078012704849243)
[2024-12-17 01:51:47,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,513][root][INFO] - Training Epoch: 1/2, step 2064/7134 completed (loss: 3.6681265830993652, acc: 0.3382352888584137)
[2024-12-17 01:51:47,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:47,874][root][INFO] - Training Epoch: 1/2, step 2065/7134 completed (loss: 3.9108471870422363, acc: 0.30714285373687744)
[2024-12-17 01:51:47,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,234][root][INFO] - Training Epoch: 1/2, step 2066/7134 completed (loss: 3.757009267807007, acc: 0.2926829159259796)
[2024-12-17 01:51:48,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:48,622][root][INFO] - Training Epoch: 1/2, step 2067/7134 completed (loss: 4.368913173675537, acc: 0.3083333373069763)
[2024-12-17 01:51:48,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,001][root][INFO] - Training Epoch: 1/2, step 2068/7134 completed (loss: 3.7872421741485596, acc: 0.28431373834609985)
[2024-12-17 01:51:49,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,399][root][INFO] - Training Epoch: 1/2, step 2069/7134 completed (loss: 3.9100136756896973, acc: 0.25503355264663696)
[2024-12-17 01:51:49,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:49,765][root][INFO] - Training Epoch: 1/2, step 2070/7134 completed (loss: 3.9232051372528076, acc: 0.2931034564971924)
[2024-12-17 01:51:49,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,200][root][INFO] - Training Epoch: 1/2, step 2071/7134 completed (loss: 3.849445343017578, acc: 0.3009708821773529)
[2024-12-17 01:51:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,615][root][INFO] - Training Epoch: 1/2, step 2072/7134 completed (loss: 3.7013676166534424, acc: 0.29411765933036804)
[2024-12-17 01:51:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:50,978][root][INFO] - Training Epoch: 1/2, step 2073/7134 completed (loss: 4.072815418243408, acc: 0.28925618529319763)
[2024-12-17 01:51:51,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,393][root][INFO] - Training Epoch: 1/2, step 2074/7134 completed (loss: 3.8918240070343018, acc: 0.2670156955718994)
[2024-12-17 01:51:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:51,825][root][INFO] - Training Epoch: 1/2, step 2075/7134 completed (loss: 3.9502744674682617, acc: 0.31446540355682373)
[2024-12-17 01:51:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,208][root][INFO] - Training Epoch: 1/2, step 2076/7134 completed (loss: 3.9730756282806396, acc: 0.2789115607738495)
[2024-12-17 01:51:52,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:52,591][root][INFO] - Training Epoch: 1/2, step 2077/7134 completed (loss: 3.901815176010132, acc: 0.24858756363391876)
[2024-12-17 01:51:52,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,009][root][INFO] - Training Epoch: 1/2, step 2078/7134 completed (loss: 3.645221471786499, acc: 0.31979694962501526)
[2024-12-17 01:51:53,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,400][root][INFO] - Training Epoch: 1/2, step 2079/7134 completed (loss: 3.9346888065338135, acc: 0.2590361535549164)
[2024-12-17 01:51:53,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:53,793][root][INFO] - Training Epoch: 1/2, step 2080/7134 completed (loss: 4.171676158905029, acc: 0.24836601316928864)
[2024-12-17 01:51:53,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,170][root][INFO] - Training Epoch: 1/2, step 2081/7134 completed (loss: 4.041919231414795, acc: 0.2675159275531769)
[2024-12-17 01:51:54,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,556][root][INFO] - Training Epoch: 1/2, step 2082/7134 completed (loss: 3.9315874576568604, acc: 0.2881355881690979)
[2024-12-17 01:51:54,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:54,907][root][INFO] - Training Epoch: 1/2, step 2083/7134 completed (loss: 3.628558874130249, acc: 0.2868216931819916)
[2024-12-17 01:51:55,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,275][root][INFO] - Training Epoch: 1/2, step 2084/7134 completed (loss: 4.123476505279541, acc: 0.25999999046325684)
[2024-12-17 01:51:55,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:55,679][root][INFO] - Training Epoch: 1/2, step 2085/7134 completed (loss: 3.772472858428955, acc: 0.3252032399177551)
[2024-12-17 01:51:55,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,064][root][INFO] - Training Epoch: 1/2, step 2086/7134 completed (loss: 4.2029337882995605, acc: 0.3137255012989044)
[2024-12-17 01:51:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,462][root][INFO] - Training Epoch: 1/2, step 2087/7134 completed (loss: 3.8738644123077393, acc: 0.2857142984867096)
[2024-12-17 01:51:56,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:56,837][root][INFO] - Training Epoch: 1/2, step 2088/7134 completed (loss: 3.8751108646392822, acc: 0.3076923191547394)
[2024-12-17 01:51:56,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,238][root][INFO] - Training Epoch: 1/2, step 2089/7134 completed (loss: 4.008171558380127, acc: 0.3214285671710968)
[2024-12-17 01:51:57,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:57,611][root][INFO] - Training Epoch: 1/2, step 2090/7134 completed (loss: 3.703334331512451, acc: 0.2875817120075226)
[2024-12-17 01:51:57,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,025][root][INFO] - Training Epoch: 1/2, step 2091/7134 completed (loss: 3.085026741027832, acc: 0.3724137842655182)
[2024-12-17 01:51:58,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,409][root][INFO] - Training Epoch: 1/2, step 2092/7134 completed (loss: 3.0776901245117188, acc: 0.3907284736633301)
[2024-12-17 01:51:58,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:58,838][root][INFO] - Training Epoch: 1/2, step 2093/7134 completed (loss: 3.5355916023254395, acc: 0.3684210479259491)
[2024-12-17 01:51:58,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,214][root][INFO] - Training Epoch: 1/2, step 2094/7134 completed (loss: 3.766883373260498, acc: 0.3731343150138855)
[2024-12-17 01:51:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,611][root][INFO] - Training Epoch: 1/2, step 2095/7134 completed (loss: 3.478881597518921, acc: 0.39303481578826904)
[2024-12-17 01:51:59,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:51:59,979][root][INFO] - Training Epoch: 1/2, step 2096/7134 completed (loss: 3.843338966369629, acc: 0.3216783106327057)
[2024-12-17 01:52:00,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,343][root][INFO] - Training Epoch: 1/2, step 2097/7134 completed (loss: 3.2675423622131348, acc: 0.39156627655029297)
[2024-12-17 01:52:00,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:00,707][root][INFO] - Training Epoch: 1/2, step 2098/7134 completed (loss: 3.473858594894409, acc: 0.375)
[2024-12-17 01:52:00,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,094][root][INFO] - Training Epoch: 1/2, step 2099/7134 completed (loss: 3.8961682319641113, acc: 0.3046875)
[2024-12-17 01:52:01,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,455][root][INFO] - Training Epoch: 1/2, step 2100/7134 completed (loss: 3.8762288093566895, acc: 0.33714285492897034)
[2024-12-17 01:52:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:01,813][root][INFO] - Training Epoch: 1/2, step 2101/7134 completed (loss: 4.870532035827637, acc: 0.1964285671710968)
[2024-12-17 01:52:01,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,268][root][INFO] - Training Epoch: 1/2, step 2102/7134 completed (loss: 3.622878074645996, acc: 0.2594594657421112)
[2024-12-17 01:52:02,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:02,676][root][INFO] - Training Epoch: 1/2, step 2103/7134 completed (loss: 4.210995674133301, acc: 0.2562499940395355)
[2024-12-17 01:52:02,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,064][root][INFO] - Training Epoch: 1/2, step 2104/7134 completed (loss: 3.8715336322784424, acc: 0.3028571307659149)
[2024-12-17 01:52:03,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,431][root][INFO] - Training Epoch: 1/2, step 2105/7134 completed (loss: 3.9763858318328857, acc: 0.3333333432674408)
[2024-12-17 01:52:03,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:03,800][root][INFO] - Training Epoch: 1/2, step 2106/7134 completed (loss: 3.7855875492095947, acc: 0.3552631437778473)
[2024-12-17 01:52:03,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,164][root][INFO] - Training Epoch: 1/2, step 2107/7134 completed (loss: 4.120530605316162, acc: 0.20994475483894348)
[2024-12-17 01:52:04,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,531][root][INFO] - Training Epoch: 1/2, step 2108/7134 completed (loss: 3.7530291080474854, acc: 0.3664596378803253)
[2024-12-17 01:52:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:04,881][root][INFO] - Training Epoch: 1/2, step 2109/7134 completed (loss: 4.198915958404541, acc: 0.25362318754196167)
[2024-12-17 01:52:04,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,257][root][INFO] - Training Epoch: 1/2, step 2110/7134 completed (loss: 4.2694573402404785, acc: 0.27544909715652466)
[2024-12-17 01:52:05,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,609][root][INFO] - Training Epoch: 1/2, step 2111/7134 completed (loss: 4.148298740386963, acc: 0.25388601422309875)
[2024-12-17 01:52:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:05,957][root][INFO] - Training Epoch: 1/2, step 2112/7134 completed (loss: 3.6445186138153076, acc: 0.36666667461395264)
[2024-12-17 01:52:06,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,347][root][INFO] - Training Epoch: 1/2, step 2113/7134 completed (loss: 3.8427186012268066, acc: 0.3266666531562805)
[2024-12-17 01:52:06,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:06,715][root][INFO] - Training Epoch: 1/2, step 2114/7134 completed (loss: 4.293606281280518, acc: 0.3076923191547394)
[2024-12-17 01:52:06,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,098][root][INFO] - Training Epoch: 1/2, step 2115/7134 completed (loss: 4.092020511627197, acc: 0.3045977056026459)
[2024-12-17 01:52:07,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,465][root][INFO] - Training Epoch: 1/2, step 2116/7134 completed (loss: 4.688060760498047, acc: 0.3401360511779785)
[2024-12-17 01:52:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:07,839][root][INFO] - Training Epoch: 1/2, step 2117/7134 completed (loss: 4.631317615509033, acc: 0.2598870098590851)
[2024-12-17 01:52:07,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,222][root][INFO] - Training Epoch: 1/2, step 2118/7134 completed (loss: 4.0178141593933105, acc: 0.30177515745162964)
[2024-12-17 01:52:08,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,616][root][INFO] - Training Epoch: 1/2, step 2119/7134 completed (loss: 3.783780336380005, acc: 0.3005780279636383)
[2024-12-17 01:52:08,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:08,979][root][INFO] - Training Epoch: 1/2, step 2120/7134 completed (loss: 4.0764079093933105, acc: 0.26543208956718445)
[2024-12-17 01:52:09,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,310][root][INFO] - Training Epoch: 1/2, step 2121/7134 completed (loss: 3.9282968044281006, acc: 0.268456369638443)
[2024-12-17 01:52:09,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:09,685][root][INFO] - Training Epoch: 1/2, step 2122/7134 completed (loss: 3.8723690509796143, acc: 0.3672316372394562)
[2024-12-17 01:52:09,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,055][root][INFO] - Training Epoch: 1/2, step 2123/7134 completed (loss: 4.399452209472656, acc: 0.23026315867900848)
[2024-12-17 01:52:10,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,429][root][INFO] - Training Epoch: 1/2, step 2124/7134 completed (loss: 4.1886491775512695, acc: 0.27702704071998596)
[2024-12-17 01:52:10,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:10,802][root][INFO] - Training Epoch: 1/2, step 2125/7134 completed (loss: 3.5901477336883545, acc: 0.3652694523334503)
[2024-12-17 01:52:10,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,185][root][INFO] - Training Epoch: 1/2, step 2126/7134 completed (loss: 4.0919718742370605, acc: 0.24822695553302765)
[2024-12-17 01:52:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,527][root][INFO] - Training Epoch: 1/2, step 2127/7134 completed (loss: 4.106719017028809, acc: 0.27108433842658997)
[2024-12-17 01:52:11,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:11,870][root][INFO] - Training Epoch: 1/2, step 2128/7134 completed (loss: 3.868185520172119, acc: 0.30000001192092896)
[2024-12-17 01:52:11,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,260][root][INFO] - Training Epoch: 1/2, step 2129/7134 completed (loss: 3.989792585372925, acc: 0.27218934893608093)
[2024-12-17 01:52:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,634][root][INFO] - Training Epoch: 1/2, step 2130/7134 completed (loss: 3.957540512084961, acc: 0.30405405163764954)
[2024-12-17 01:52:12,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:12,993][root][INFO] - Training Epoch: 1/2, step 2131/7134 completed (loss: 3.856736898422241, acc: 0.29447853565216064)
[2024-12-17 01:52:13,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,376][root][INFO] - Training Epoch: 1/2, step 2132/7134 completed (loss: 3.542672872543335, acc: 0.32926830649375916)
[2024-12-17 01:52:13,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:13,770][root][INFO] - Training Epoch: 1/2, step 2133/7134 completed (loss: 3.527994394302368, acc: 0.3801169693470001)
[2024-12-17 01:52:13,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,129][root][INFO] - Training Epoch: 1/2, step 2134/7134 completed (loss: 3.8363311290740967, acc: 0.33908045291900635)
[2024-12-17 01:52:14,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,521][root][INFO] - Training Epoch: 1/2, step 2135/7134 completed (loss: 3.7208991050720215, acc: 0.2781457006931305)
[2024-12-17 01:52:14,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:14,905][root][INFO] - Training Epoch: 1/2, step 2136/7134 completed (loss: 3.3999147415161133, acc: 0.35164836049079895)
[2024-12-17 01:52:15,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,288][root][INFO] - Training Epoch: 1/2, step 2137/7134 completed (loss: 3.8460874557495117, acc: 0.32446807622909546)
[2024-12-17 01:52:15,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:15,640][root][INFO] - Training Epoch: 1/2, step 2138/7134 completed (loss: 3.55977463722229, acc: 0.35329341888427734)
[2024-12-17 01:52:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,001][root][INFO] - Training Epoch: 1/2, step 2139/7134 completed (loss: 3.782378911972046, acc: 0.2732558250427246)
[2024-12-17 01:52:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,399][root][INFO] - Training Epoch: 1/2, step 2140/7134 completed (loss: 4.114114284515381, acc: 0.28248587250709534)
[2024-12-17 01:52:16,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:16,760][root][INFO] - Training Epoch: 1/2, step 2141/7134 completed (loss: 4.941958904266357, acc: 0.23404255509376526)
[2024-12-17 01:52:16,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,131][root][INFO] - Training Epoch: 1/2, step 2142/7134 completed (loss: 4.535945415496826, acc: 0.1977401077747345)
[2024-12-17 01:52:17,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,520][root][INFO] - Training Epoch: 1/2, step 2143/7134 completed (loss: 4.0615458488464355, acc: 0.24827586114406586)
[2024-12-17 01:52:17,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:17,899][root][INFO] - Training Epoch: 1/2, step 2144/7134 completed (loss: 3.7549333572387695, acc: 0.28409090638160706)
[2024-12-17 01:52:18,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,293][root][INFO] - Training Epoch: 1/2, step 2145/7134 completed (loss: 4.656195163726807, acc: 0.24418604373931885)
[2024-12-17 01:52:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:18,714][root][INFO] - Training Epoch: 1/2, step 2146/7134 completed (loss: 3.657395124435425, acc: 0.3513513505458832)
[2024-12-17 01:52:18,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,084][root][INFO] - Training Epoch: 1/2, step 2147/7134 completed (loss: 4.2545623779296875, acc: 0.26767677068710327)
[2024-12-17 01:52:19,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,476][root][INFO] - Training Epoch: 1/2, step 2148/7134 completed (loss: 3.6646933555603027, acc: 0.34659090638160706)
[2024-12-17 01:52:19,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:19,864][root][INFO] - Training Epoch: 1/2, step 2149/7134 completed (loss: 3.9074254035949707, acc: 0.3274853825569153)
[2024-12-17 01:52:20,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,273][root][INFO] - Training Epoch: 1/2, step 2150/7134 completed (loss: 3.8401458263397217, acc: 0.2881355881690979)
[2024-12-17 01:52:20,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:20,629][root][INFO] - Training Epoch: 1/2, step 2151/7134 completed (loss: 4.046391487121582, acc: 0.28915661573410034)
[2024-12-17 01:52:20,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,049][root][INFO] - Training Epoch: 1/2, step 2152/7134 completed (loss: 4.00089168548584, acc: 0.28387096524238586)
[2024-12-17 01:52:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,462][root][INFO] - Training Epoch: 1/2, step 2153/7134 completed (loss: 4.228724479675293, acc: 0.27941176295280457)
[2024-12-17 01:52:21,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:21,888][root][INFO] - Training Epoch: 1/2, step 2154/7134 completed (loss: 4.700047492980957, acc: 0.24712643027305603)
[2024-12-17 01:52:22,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,311][root][INFO] - Training Epoch: 1/2, step 2155/7134 completed (loss: 4.286322593688965, acc: 0.25641027092933655)
[2024-12-17 01:52:22,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:22,667][root][INFO] - Training Epoch: 1/2, step 2156/7134 completed (loss: 3.949023485183716, acc: 0.25)
[2024-12-17 01:52:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,095][root][INFO] - Training Epoch: 1/2, step 2157/7134 completed (loss: 4.243197441101074, acc: 0.24747474491596222)
[2024-12-17 01:52:23,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,501][root][INFO] - Training Epoch: 1/2, step 2158/7134 completed (loss: 4.346414089202881, acc: 0.22164948284626007)
[2024-12-17 01:52:23,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:23,878][root][INFO] - Training Epoch: 1/2, step 2159/7134 completed (loss: 4.055654048919678, acc: 0.2380952388048172)
[2024-12-17 01:52:24,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,290][root][INFO] - Training Epoch: 1/2, step 2160/7134 completed (loss: 3.895070791244507, acc: 0.27439025044441223)
[2024-12-17 01:52:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:24,659][root][INFO] - Training Epoch: 1/2, step 2161/7134 completed (loss: 3.7211310863494873, acc: 0.32777777314186096)
[2024-12-17 01:52:24,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,043][root][INFO] - Training Epoch: 1/2, step 2162/7134 completed (loss: 4.029667854309082, acc: 0.2709677517414093)
[2024-12-17 01:52:25,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,449][root][INFO] - Training Epoch: 1/2, step 2163/7134 completed (loss: 4.15841007232666, acc: 0.25333333015441895)
[2024-12-17 01:52:25,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:25,815][root][INFO] - Training Epoch: 1/2, step 2164/7134 completed (loss: 4.114840030670166, acc: 0.25)
[2024-12-17 01:52:25,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,251][root][INFO] - Training Epoch: 1/2, step 2165/7134 completed (loss: 3.6743812561035156, acc: 0.3048780560493469)
[2024-12-17 01:52:26,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:26,645][root][INFO] - Training Epoch: 1/2, step 2166/7134 completed (loss: 3.653108835220337, acc: 0.3333333432674408)
[2024-12-17 01:52:26,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,060][root][INFO] - Training Epoch: 1/2, step 2167/7134 completed (loss: 3.9106264114379883, acc: 0.28155338764190674)
[2024-12-17 01:52:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,429][root][INFO] - Training Epoch: 1/2, step 2168/7134 completed (loss: 3.8956034183502197, acc: 0.3093525171279907)
[2024-12-17 01:52:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:27,812][root][INFO] - Training Epoch: 1/2, step 2169/7134 completed (loss: 3.3056886196136475, acc: 0.41206029057502747)
[2024-12-17 01:52:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,188][root][INFO] - Training Epoch: 1/2, step 2170/7134 completed (loss: 3.9662795066833496, acc: 0.3006536066532135)
[2024-12-17 01:52:28,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,560][root][INFO] - Training Epoch: 1/2, step 2171/7134 completed (loss: 4.041064262390137, acc: 0.29729729890823364)
[2024-12-17 01:52:28,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:28,916][root][INFO] - Training Epoch: 1/2, step 2172/7134 completed (loss: 3.8033525943756104, acc: 0.30805686116218567)
[2024-12-17 01:52:29,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,292][root][INFO] - Training Epoch: 1/2, step 2173/7134 completed (loss: 4.198462963104248, acc: 0.31506848335266113)
[2024-12-17 01:52:29,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:29,680][root][INFO] - Training Epoch: 1/2, step 2174/7134 completed (loss: 3.740631341934204, acc: 0.31137725710868835)
[2024-12-17 01:52:29,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,056][root][INFO] - Training Epoch: 1/2, step 2175/7134 completed (loss: 3.66758394241333, acc: 0.35151514410972595)
[2024-12-17 01:52:30,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,435][root][INFO] - Training Epoch: 1/2, step 2176/7134 completed (loss: 3.8906235694885254, acc: 0.29891303181648254)
[2024-12-17 01:52:30,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:30,858][root][INFO] - Training Epoch: 1/2, step 2177/7134 completed (loss: 3.830605983734131, acc: 0.2568306028842926)
[2024-12-17 01:52:30,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,239][root][INFO] - Training Epoch: 1/2, step 2178/7134 completed (loss: 3.777637481689453, acc: 0.2864583432674408)
[2024-12-17 01:52:31,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,619][root][INFO] - Training Epoch: 1/2, step 2179/7134 completed (loss: 3.523627996444702, acc: 0.3045977056026459)
[2024-12-17 01:52:31,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:31,988][root][INFO] - Training Epoch: 1/2, step 2180/7134 completed (loss: 4.045312404632568, acc: 0.2527472674846649)
[2024-12-17 01:52:32,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,372][root][INFO] - Training Epoch: 1/2, step 2181/7134 completed (loss: 3.668809652328491, acc: 0.32919254899024963)
[2024-12-17 01:52:32,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:32,749][root][INFO] - Training Epoch: 1/2, step 2182/7134 completed (loss: 4.049134731292725, acc: 0.3025641143321991)
[2024-12-17 01:52:32,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,148][root][INFO] - Training Epoch: 1/2, step 2183/7134 completed (loss: 3.7668488025665283, acc: 0.3093922734260559)
[2024-12-17 01:52:33,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,537][root][INFO] - Training Epoch: 1/2, step 2184/7134 completed (loss: 3.9957640171051025, acc: 0.2887323796749115)
[2024-12-17 01:52:33,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:33,920][root][INFO] - Training Epoch: 1/2, step 2185/7134 completed (loss: 4.1429853439331055, acc: 0.30817610025405884)
[2024-12-17 01:52:34,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,301][root][INFO] - Training Epoch: 1/2, step 2186/7134 completed (loss: 3.8533716201782227, acc: 0.30000001192092896)
[2024-12-17 01:52:34,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:34,705][root][INFO] - Training Epoch: 1/2, step 2187/7134 completed (loss: 4.157070636749268, acc: 0.2949640154838562)
[2024-12-17 01:52:34,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,109][root][INFO] - Training Epoch: 1/2, step 2188/7134 completed (loss: 3.4370474815368652, acc: 0.3636363744735718)
[2024-12-17 01:52:35,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,479][root][INFO] - Training Epoch: 1/2, step 2189/7134 completed (loss: 3.9365646839141846, acc: 0.34415584802627563)
[2024-12-17 01:52:35,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:35,851][root][INFO] - Training Epoch: 1/2, step 2190/7134 completed (loss: 3.608247756958008, acc: 0.33519554138183594)
[2024-12-17 01:52:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,174][root][INFO] - Training Epoch: 1/2, step 2191/7134 completed (loss: 4.3053364753723145, acc: 0.34736841917037964)
[2024-12-17 01:52:36,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,512][root][INFO] - Training Epoch: 1/2, step 2192/7134 completed (loss: 3.846008777618408, acc: 0.24444444477558136)
[2024-12-17 01:52:36,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:36,859][root][INFO] - Training Epoch: 1/2, step 2193/7134 completed (loss: 3.8503944873809814, acc: 0.2732240557670593)
[2024-12-17 01:52:36,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,241][root][INFO] - Training Epoch: 1/2, step 2194/7134 completed (loss: 4.1067352294921875, acc: 0.2631579041481018)
[2024-12-17 01:52:37,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:37,631][root][INFO] - Training Epoch: 1/2, step 2195/7134 completed (loss: 3.4535269737243652, acc: 0.34567901492118835)
[2024-12-17 01:52:37,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,006][root][INFO] - Training Epoch: 1/2, step 2196/7134 completed (loss: 4.055607318878174, acc: 0.2252747267484665)
[2024-12-17 01:52:38,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,388][root][INFO] - Training Epoch: 1/2, step 2197/7134 completed (loss: 3.8034987449645996, acc: 0.32283464074134827)
[2024-12-17 01:52:38,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:38,765][root][INFO] - Training Epoch: 1/2, step 2198/7134 completed (loss: 3.5431036949157715, acc: 0.3563218414783478)
[2024-12-17 01:52:38,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,138][root][INFO] - Training Epoch: 1/2, step 2199/7134 completed (loss: 3.676912784576416, acc: 0.24683544039726257)
[2024-12-17 01:52:39,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,502][root][INFO] - Training Epoch: 1/2, step 2200/7134 completed (loss: 3.8884363174438477, acc: 0.24409449100494385)
[2024-12-17 01:52:39,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:39,874][root][INFO] - Training Epoch: 1/2, step 2201/7134 completed (loss: 3.727342367172241, acc: 0.37162160873413086)
[2024-12-17 01:52:39,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,240][root][INFO] - Training Epoch: 1/2, step 2202/7134 completed (loss: 3.953836441040039, acc: 0.31386861205101013)
[2024-12-17 01:52:40,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:40,613][root][INFO] - Training Epoch: 1/2, step 2203/7134 completed (loss: 3.605339765548706, acc: 0.359281450510025)
[2024-12-17 01:52:40,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,002][root][INFO] - Training Epoch: 1/2, step 2204/7134 completed (loss: 3.5928738117218018, acc: 0.3218390941619873)
[2024-12-17 01:52:41,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,391][root][INFO] - Training Epoch: 1/2, step 2205/7134 completed (loss: 3.4224956035614014, acc: 0.3333333432674408)
[2024-12-17 01:52:41,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:41,758][root][INFO] - Training Epoch: 1/2, step 2206/7134 completed (loss: 3.824305534362793, acc: 0.28859061002731323)
[2024-12-17 01:52:41,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,109][root][INFO] - Training Epoch: 1/2, step 2207/7134 completed (loss: 3.559927463531494, acc: 0.2448979616165161)
[2024-12-17 01:52:42,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,447][root][INFO] - Training Epoch: 1/2, step 2208/7134 completed (loss: 3.7269811630249023, acc: 0.35483869910240173)
[2024-12-17 01:52:42,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:42,786][root][INFO] - Training Epoch: 1/2, step 2209/7134 completed (loss: 3.791254997253418, acc: 0.3414634168148041)
[2024-12-17 01:52:42,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,158][root][INFO] - Training Epoch: 1/2, step 2210/7134 completed (loss: 3.7678706645965576, acc: 0.29878050088882446)
[2024-12-17 01:52:43,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,540][root][INFO] - Training Epoch: 1/2, step 2211/7134 completed (loss: 4.049280166625977, acc: 0.2469879537820816)
[2024-12-17 01:52:43,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:43,936][root][INFO] - Training Epoch: 1/2, step 2212/7134 completed (loss: 4.015980243682861, acc: 0.2514285743236542)
[2024-12-17 01:52:44,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,326][root][INFO] - Training Epoch: 1/2, step 2213/7134 completed (loss: 4.174501895904541, acc: 0.2647058963775635)
[2024-12-17 01:52:44,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:44,684][root][INFO] - Training Epoch: 1/2, step 2214/7134 completed (loss: 3.5362589359283447, acc: 0.37837839126586914)
[2024-12-17 01:52:44,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,038][root][INFO] - Training Epoch: 1/2, step 2215/7134 completed (loss: 3.873958110809326, acc: 0.3544303774833679)
[2024-12-17 01:52:45,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,376][root][INFO] - Training Epoch: 1/2, step 2216/7134 completed (loss: 3.808486223220825, acc: 0.3040935695171356)
[2024-12-17 01:52:45,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:45,740][root][INFO] - Training Epoch: 1/2, step 2217/7134 completed (loss: 3.6248209476470947, acc: 0.28742516040802)
[2024-12-17 01:52:45,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,122][root][INFO] - Training Epoch: 1/2, step 2218/7134 completed (loss: 4.2183990478515625, acc: 0.25925925374031067)
[2024-12-17 01:52:46,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,495][root][INFO] - Training Epoch: 1/2, step 2219/7134 completed (loss: 3.884101629257202, acc: 0.2928571403026581)
[2024-12-17 01:52:46,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:46,878][root][INFO] - Training Epoch: 1/2, step 2220/7134 completed (loss: 4.188745498657227, acc: 0.27407407760620117)
[2024-12-17 01:52:47,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,305][root][INFO] - Training Epoch: 1/2, step 2221/7134 completed (loss: 4.074235916137695, acc: 0.29192546010017395)
[2024-12-17 01:52:47,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:47,717][root][INFO] - Training Epoch: 1/2, step 2222/7134 completed (loss: 4.384281635284424, acc: 0.2945205569267273)
[2024-12-17 01:52:47,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,094][root][INFO] - Training Epoch: 1/2, step 2223/7134 completed (loss: 4.045883655548096, acc: 0.3087248206138611)
[2024-12-17 01:52:48,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,495][root][INFO] - Training Epoch: 1/2, step 2224/7134 completed (loss: 3.706019639968872, acc: 0.3544303774833679)
[2024-12-17 01:52:48,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:48,887][root][INFO] - Training Epoch: 1/2, step 2225/7134 completed (loss: 4.56486177444458, acc: 0.21768707036972046)
[2024-12-17 01:52:49,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,259][root][INFO] - Training Epoch: 1/2, step 2226/7134 completed (loss: 3.7185475826263428, acc: 0.3154362440109253)
[2024-12-17 01:52:49,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,646][root][INFO] - Training Epoch: 1/2, step 2227/7134 completed (loss: 4.035625457763672, acc: 0.2857142984867096)
[2024-12-17 01:52:49,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:49,988][root][INFO] - Training Epoch: 1/2, step 2228/7134 completed (loss: 3.9354751110076904, acc: 0.3100775182247162)
[2024-12-17 01:52:50,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,349][root][INFO] - Training Epoch: 1/2, step 2229/7134 completed (loss: 3.766052722930908, acc: 0.33980581164360046)
[2024-12-17 01:52:50,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:50,720][root][INFO] - Training Epoch: 1/2, step 2230/7134 completed (loss: 3.4811317920684814, acc: 0.3525179922580719)
[2024-12-17 01:52:50,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,095][root][INFO] - Training Epoch: 1/2, step 2231/7134 completed (loss: 4.262507915496826, acc: 0.27731093764305115)
[2024-12-17 01:52:51,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,490][root][INFO] - Training Epoch: 1/2, step 2232/7134 completed (loss: 3.754526138305664, acc: 0.28735631704330444)
[2024-12-17 01:52:51,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:51,854][root][INFO] - Training Epoch: 1/2, step 2233/7134 completed (loss: 3.873894214630127, acc: 0.3205128312110901)
[2024-12-17 01:52:51,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,243][root][INFO] - Training Epoch: 1/2, step 2234/7134 completed (loss: 4.111701011657715, acc: 0.29870128631591797)
[2024-12-17 01:52:52,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,608][root][INFO] - Training Epoch: 1/2, step 2235/7134 completed (loss: 4.42353630065918, acc: 0.20279720425605774)
[2024-12-17 01:52:52,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:52,980][root][INFO] - Training Epoch: 1/2, step 2236/7134 completed (loss: 3.9486756324768066, acc: 0.3199999928474426)
[2024-12-17 01:52:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,359][root][INFO] - Training Epoch: 1/2, step 2237/7134 completed (loss: 3.921851873397827, acc: 0.20000000298023224)
[2024-12-17 01:52:53,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:53,729][root][INFO] - Training Epoch: 1/2, step 2238/7134 completed (loss: 4.089476585388184, acc: 0.2839506268501282)
[2024-12-17 01:52:53,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,079][root][INFO] - Training Epoch: 1/2, step 2239/7134 completed (loss: 4.308056831359863, acc: 0.3368983864784241)
[2024-12-17 01:52:54,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,421][root][INFO] - Training Epoch: 1/2, step 2240/7134 completed (loss: 4.4696736335754395, acc: 0.2613636255264282)
[2024-12-17 01:52:54,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:54,724][root][INFO] - Training Epoch: 1/2, step 2241/7134 completed (loss: 4.271953582763672, acc: 0.25)
[2024-12-17 01:52:54,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,064][root][INFO] - Training Epoch: 1/2, step 2242/7134 completed (loss: 4.314005374908447, acc: 0.3055555522441864)
[2024-12-17 01:52:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,448][root][INFO] - Training Epoch: 1/2, step 2243/7134 completed (loss: 4.276118278503418, acc: 0.3677419424057007)
[2024-12-17 01:52:55,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:55,838][root][INFO] - Training Epoch: 1/2, step 2244/7134 completed (loss: 4.747295379638672, acc: 0.27397260069847107)
[2024-12-17 01:52:55,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,177][root][INFO] - Training Epoch: 1/2, step 2245/7134 completed (loss: 4.294370651245117, acc: 0.30718955397605896)
[2024-12-17 01:52:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,571][root][INFO] - Training Epoch: 1/2, step 2246/7134 completed (loss: 5.231183052062988, acc: 0.2295081913471222)
[2024-12-17 01:52:56,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:56,950][root][INFO] - Training Epoch: 1/2, step 2247/7134 completed (loss: 5.056606292724609, acc: 0.22543352842330933)
[2024-12-17 01:52:57,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,332][root][INFO] - Training Epoch: 1/2, step 2248/7134 completed (loss: 4.9437665939331055, acc: 0.24277456104755402)
[2024-12-17 01:52:57,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:57,703][root][INFO] - Training Epoch: 1/2, step 2249/7134 completed (loss: 4.267032623291016, acc: 0.28729280829429626)
[2024-12-17 01:52:57,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,088][root][INFO] - Training Epoch: 1/2, step 2250/7134 completed (loss: 4.3844804763793945, acc: 0.3191489279270172)
[2024-12-17 01:52:58,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,442][root][INFO] - Training Epoch: 1/2, step 2251/7134 completed (loss: 3.99489164352417, acc: 0.2950819730758667)
[2024-12-17 01:52:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:58,851][root][INFO] - Training Epoch: 1/2, step 2252/7134 completed (loss: 4.068040370941162, acc: 0.21739129722118378)
[2024-12-17 01:52:59,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,242][root][INFO] - Training Epoch: 1/2, step 2253/7134 completed (loss: 4.186301231384277, acc: 0.20382165908813477)
[2024-12-17 01:52:59,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,609][root][INFO] - Training Epoch: 1/2, step 2254/7134 completed (loss: 4.149204254150391, acc: 0.32258063554763794)
[2024-12-17 01:52:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:52:59,978][root][INFO] - Training Epoch: 1/2, step 2255/7134 completed (loss: 3.819619655609131, acc: 0.31446540355682373)
[2024-12-17 01:53:00,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,347][root][INFO] - Training Epoch: 1/2, step 2256/7134 completed (loss: 4.475809097290039, acc: 0.2926829159259796)
[2024-12-17 01:53:00,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:00,728][root][INFO] - Training Epoch: 1/2, step 2257/7134 completed (loss: 3.832432985305786, acc: 0.3333333432674408)
[2024-12-17 01:53:00,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,102][root][INFO] - Training Epoch: 1/2, step 2258/7134 completed (loss: 4.186441898345947, acc: 0.3100775182247162)
[2024-12-17 01:53:01,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,462][root][INFO] - Training Epoch: 1/2, step 2259/7134 completed (loss: 3.7532060146331787, acc: 0.4017094075679779)
[2024-12-17 01:53:01,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:01,842][root][INFO] - Training Epoch: 1/2, step 2260/7134 completed (loss: 4.008760929107666, acc: 0.3181818127632141)
[2024-12-17 01:53:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,204][root][INFO] - Training Epoch: 1/2, step 2261/7134 completed (loss: 3.6923580169677734, acc: 0.3395061790943146)
[2024-12-17 01:53:02,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,589][root][INFO] - Training Epoch: 1/2, step 2262/7134 completed (loss: 4.4306416511535645, acc: 0.29323309659957886)
[2024-12-17 01:53:02,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:02,952][root][INFO] - Training Epoch: 1/2, step 2263/7134 completed (loss: 4.081109523773193, acc: 0.31578946113586426)
[2024-12-17 01:53:03,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,304][root][INFO] - Training Epoch: 1/2, step 2264/7134 completed (loss: 3.8631060123443604, acc: 0.3675675690174103)
[2024-12-17 01:53:03,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:03,709][root][INFO] - Training Epoch: 1/2, step 2265/7134 completed (loss: 4.4130120277404785, acc: 0.2857142984867096)
[2024-12-17 01:53:03,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,138][root][INFO] - Training Epoch: 1/2, step 2266/7134 completed (loss: 4.007115840911865, acc: 0.2983425557613373)
[2024-12-17 01:53:04,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,552][root][INFO] - Training Epoch: 1/2, step 2267/7134 completed (loss: 3.742300033569336, acc: 0.3414634168148041)
[2024-12-17 01:53:04,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:04,940][root][INFO] - Training Epoch: 1/2, step 2268/7134 completed (loss: 4.364346027374268, acc: 0.267123281955719)
[2024-12-17 01:53:05,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,310][root][INFO] - Training Epoch: 1/2, step 2269/7134 completed (loss: 4.134101867675781, acc: 0.31284916400909424)
[2024-12-17 01:53:05,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:05,677][root][INFO] - Training Epoch: 1/2, step 2270/7134 completed (loss: 4.419458389282227, acc: 0.296875)
[2024-12-17 01:53:05,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,063][root][INFO] - Training Epoch: 1/2, step 2271/7134 completed (loss: 4.402196884155273, acc: 0.3027026951313019)
[2024-12-17 01:53:06,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,419][root][INFO] - Training Epoch: 1/2, step 2272/7134 completed (loss: 3.853088140487671, acc: 0.3494623601436615)
[2024-12-17 01:53:06,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:06,777][root][INFO] - Training Epoch: 1/2, step 2273/7134 completed (loss: 4.019322872161865, acc: 0.2666666805744171)
[2024-12-17 01:53:06,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,205][root][INFO] - Training Epoch: 1/2, step 2274/7134 completed (loss: 4.834113597869873, acc: 0.2153846174478531)
[2024-12-17 01:53:07,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:07,591][root][INFO] - Training Epoch: 1/2, step 2275/7134 completed (loss: 3.5714221000671387, acc: 0.3235294222831726)
[2024-12-17 01:53:07,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,003][root][INFO] - Training Epoch: 1/2, step 2276/7134 completed (loss: 4.075806140899658, acc: 0.28042328357696533)
[2024-12-17 01:53:08,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,387][root][INFO] - Training Epoch: 1/2, step 2277/7134 completed (loss: 4.304442405700684, acc: 0.23589743673801422)
[2024-12-17 01:53:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:08,797][root][INFO] - Training Epoch: 1/2, step 2278/7134 completed (loss: 4.452544212341309, acc: 0.29032257199287415)
[2024-12-17 01:53:08,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,191][root][INFO] - Training Epoch: 1/2, step 2279/7134 completed (loss: 3.9507713317871094, acc: 0.29441624879837036)
[2024-12-17 01:53:09,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:09,592][root][INFO] - Training Epoch: 1/2, step 2280/7134 completed (loss: 3.6507022380828857, acc: 0.35321101546287537)
[2024-12-17 01:53:09,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,007][root][INFO] - Training Epoch: 1/2, step 2281/7134 completed (loss: 3.9731462001800537, acc: 0.30319148302078247)
[2024-12-17 01:53:10,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,425][root][INFO] - Training Epoch: 1/2, step 2282/7134 completed (loss: 3.6509780883789062, acc: 0.3210526406764984)
[2024-12-17 01:53:10,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:10,806][root][INFO] - Training Epoch: 1/2, step 2283/7134 completed (loss: 3.7741587162017822, acc: 0.29326921701431274)
[2024-12-17 01:53:10,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,204][root][INFO] - Training Epoch: 1/2, step 2284/7134 completed (loss: 3.91573166847229, acc: 0.32258063554763794)
[2024-12-17 01:53:11,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:11,670][root][INFO] - Training Epoch: 1/2, step 2285/7134 completed (loss: 3.6108803749084473, acc: 0.35499998927116394)
[2024-12-17 01:53:11,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,049][root][INFO] - Training Epoch: 1/2, step 2286/7134 completed (loss: 4.417121410369873, acc: 0.2931034564971924)
[2024-12-17 01:53:12,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,430][root][INFO] - Training Epoch: 1/2, step 2287/7134 completed (loss: 4.293315410614014, acc: 0.3128834366798401)
[2024-12-17 01:53:12,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:12,816][root][INFO] - Training Epoch: 1/2, step 2288/7134 completed (loss: 3.7245147228240967, acc: 0.2857142984867096)
[2024-12-17 01:53:12,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,207][root][INFO] - Training Epoch: 1/2, step 2289/7134 completed (loss: 3.67380690574646, acc: 0.29411765933036804)
[2024-12-17 01:53:13,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,545][root][INFO] - Training Epoch: 1/2, step 2290/7134 completed (loss: 3.842411518096924, acc: 0.30645161867141724)
[2024-12-17 01:53:13,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:13,916][root][INFO] - Training Epoch: 1/2, step 2291/7134 completed (loss: 4.092342376708984, acc: 0.2983425557613373)
[2024-12-17 01:53:14,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,334][root][INFO] - Training Epoch: 1/2, step 2292/7134 completed (loss: 3.8220245838165283, acc: 0.31313130259513855)
[2024-12-17 01:53:14,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:14,733][root][INFO] - Training Epoch: 1/2, step 2293/7134 completed (loss: 3.6245651245117188, acc: 0.2831050157546997)
[2024-12-17 01:53:14,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,097][root][INFO] - Training Epoch: 1/2, step 2294/7134 completed (loss: 3.9433374404907227, acc: 0.32057416439056396)
[2024-12-17 01:53:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,491][root][INFO] - Training Epoch: 1/2, step 2295/7134 completed (loss: 3.860356569290161, acc: 0.3125)
[2024-12-17 01:53:15,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:15,866][root][INFO] - Training Epoch: 1/2, step 2296/7134 completed (loss: 3.6117594242095947, acc: 0.2788461446762085)
[2024-12-17 01:53:15,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,234][root][INFO] - Training Epoch: 1/2, step 2297/7134 completed (loss: 3.6082544326782227, acc: 0.3066037595272064)
[2024-12-17 01:53:16,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,602][root][INFO] - Training Epoch: 1/2, step 2298/7134 completed (loss: 3.9488162994384766, acc: 0.30000001192092896)
[2024-12-17 01:53:16,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:16,995][root][INFO] - Training Epoch: 1/2, step 2299/7134 completed (loss: 4.222721099853516, acc: 0.2956989109516144)
[2024-12-17 01:53:17,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,363][root][INFO] - Training Epoch: 1/2, step 2300/7134 completed (loss: 3.5333054065704346, acc: 0.3636363744735718)
[2024-12-17 01:53:17,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:17,737][root][INFO] - Training Epoch: 1/2, step 2301/7134 completed (loss: 3.8891494274139404, acc: 0.32065218687057495)
[2024-12-17 01:53:17,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,114][root][INFO] - Training Epoch: 1/2, step 2302/7134 completed (loss: 4.14991569519043, acc: 0.2717948853969574)
[2024-12-17 01:53:18,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,460][root][INFO] - Training Epoch: 1/2, step 2303/7134 completed (loss: 3.656653881072998, acc: 0.3317972421646118)
[2024-12-17 01:53:18,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:18,834][root][INFO] - Training Epoch: 1/2, step 2304/7134 completed (loss: 4.082239151000977, acc: 0.3171806037425995)
[2024-12-17 01:53:18,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,217][root][INFO] - Training Epoch: 1/2, step 2305/7134 completed (loss: 4.088154315948486, acc: 0.2924528419971466)
[2024-12-17 01:53:19,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,596][root][INFO] - Training Epoch: 1/2, step 2306/7134 completed (loss: 3.6001265048980713, acc: 0.34418603777885437)
[2024-12-17 01:53:19,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:19,954][root][INFO] - Training Epoch: 1/2, step 2307/7134 completed (loss: 3.5697457790374756, acc: 0.3262711763381958)
[2024-12-17 01:53:20,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,323][root][INFO] - Training Epoch: 1/2, step 2308/7134 completed (loss: 4.046394348144531, acc: 0.3259911835193634)
[2024-12-17 01:53:20,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:20,689][root][INFO] - Training Epoch: 1/2, step 2309/7134 completed (loss: 3.504229784011841, acc: 0.3650793731212616)
[2024-12-17 01:53:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,062][root][INFO] - Training Epoch: 1/2, step 2310/7134 completed (loss: 3.534841537475586, acc: 0.37142857909202576)
[2024-12-17 01:53:21,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,416][root][INFO] - Training Epoch: 1/2, step 2311/7134 completed (loss: 3.5297577381134033, acc: 0.30049261450767517)
[2024-12-17 01:53:21,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:21,792][root][INFO] - Training Epoch: 1/2, step 2312/7134 completed (loss: 3.7840077877044678, acc: 0.3333333432674408)
[2024-12-17 01:53:21,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,156][root][INFO] - Training Epoch: 1/2, step 2313/7134 completed (loss: 4.1937055587768555, acc: 0.33173078298568726)
[2024-12-17 01:53:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,540][root][INFO] - Training Epoch: 1/2, step 2314/7134 completed (loss: 3.8278284072875977, acc: 0.29357796907424927)
[2024-12-17 01:53:22,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:22,924][root][INFO] - Training Epoch: 1/2, step 2315/7134 completed (loss: 3.763894557952881, acc: 0.3348837196826935)
[2024-12-17 01:53:23,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,285][root][INFO] - Training Epoch: 1/2, step 2316/7134 completed (loss: 3.847247838973999, acc: 0.30687829852104187)
[2024-12-17 01:53:23,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:23,675][root][INFO] - Training Epoch: 1/2, step 2317/7134 completed (loss: 3.462348461151123, acc: 0.3403361439704895)
[2024-12-17 01:53:23,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,059][root][INFO] - Training Epoch: 1/2, step 2318/7134 completed (loss: 3.3254096508026123, acc: 0.35807859897613525)
[2024-12-17 01:53:24,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,426][root][INFO] - Training Epoch: 1/2, step 2319/7134 completed (loss: 3.205080032348633, acc: 0.36036035418510437)
[2024-12-17 01:53:24,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:24,801][root][INFO] - Training Epoch: 1/2, step 2320/7134 completed (loss: 3.366041898727417, acc: 0.34358975291252136)
[2024-12-17 01:53:24,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,178][root][INFO] - Training Epoch: 1/2, step 2321/7134 completed (loss: 3.7082109451293945, acc: 0.30000001192092896)
[2024-12-17 01:53:25,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,555][root][INFO] - Training Epoch: 1/2, step 2322/7134 completed (loss: 4.000044345855713, acc: 0.28834354877471924)
[2024-12-17 01:53:25,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:25,915][root][INFO] - Training Epoch: 1/2, step 2323/7134 completed (loss: 4.640501976013184, acc: 0.20382165908813477)
[2024-12-17 01:53:26,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,282][root][INFO] - Training Epoch: 1/2, step 2324/7134 completed (loss: 4.265775203704834, acc: 0.2469879537820816)
[2024-12-17 01:53:26,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:26,661][root][INFO] - Training Epoch: 1/2, step 2325/7134 completed (loss: 4.348848342895508, acc: 0.2142857164144516)
[2024-12-17 01:53:26,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,033][root][INFO] - Training Epoch: 1/2, step 2326/7134 completed (loss: 3.7560858726501465, acc: 0.33076924085617065)
[2024-12-17 01:53:27,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,389][root][INFO] - Training Epoch: 1/2, step 2327/7134 completed (loss: 4.498228549957275, acc: 0.23489932715892792)
[2024-12-17 01:53:27,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:27,776][root][INFO] - Training Epoch: 1/2, step 2328/7134 completed (loss: 4.521834373474121, acc: 0.24832214415073395)
[2024-12-17 01:53:27,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,152][root][INFO] - Training Epoch: 1/2, step 2329/7134 completed (loss: 3.688340187072754, acc: 0.33986929059028625)
[2024-12-17 01:53:28,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,511][root][INFO] - Training Epoch: 1/2, step 2330/7134 completed (loss: 4.231651782989502, acc: 0.290909081697464)
[2024-12-17 01:53:28,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:28,879][root][INFO] - Training Epoch: 1/2, step 2331/7134 completed (loss: 3.6756935119628906, acc: 0.29032257199287415)
[2024-12-17 01:53:28,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,253][root][INFO] - Training Epoch: 1/2, step 2332/7134 completed (loss: 3.6538925170898438, acc: 0.30909091234207153)
[2024-12-17 01:53:29,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,618][root][INFO] - Training Epoch: 1/2, step 2333/7134 completed (loss: 3.62119197845459, acc: 0.353658527135849)
[2024-12-17 01:53:29,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:29,993][root][INFO] - Training Epoch: 1/2, step 2334/7134 completed (loss: 3.828073024749756, acc: 0.31210190057754517)
[2024-12-17 01:53:30,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,386][root][INFO] - Training Epoch: 1/2, step 2335/7134 completed (loss: 3.6972880363464355, acc: 0.3037974536418915)
[2024-12-17 01:53:30,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:30,748][root][INFO] - Training Epoch: 1/2, step 2336/7134 completed (loss: 4.0145392417907715, acc: 0.268456369638443)
[2024-12-17 01:53:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,118][root][INFO] - Training Epoch: 1/2, step 2337/7134 completed (loss: 4.012145519256592, acc: 0.25)
[2024-12-17 01:53:31,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,494][root][INFO] - Training Epoch: 1/2, step 2338/7134 completed (loss: 3.9445321559906006, acc: 0.31168830394744873)
[2024-12-17 01:53:31,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:31,871][root][INFO] - Training Epoch: 1/2, step 2339/7134 completed (loss: 3.9324097633361816, acc: 0.3205128312110901)
[2024-12-17 01:53:31,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,247][root][INFO] - Training Epoch: 1/2, step 2340/7134 completed (loss: 3.573380947113037, acc: 0.3961038887500763)
[2024-12-17 01:53:32,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,618][root][INFO] - Training Epoch: 1/2, step 2341/7134 completed (loss: 3.81642746925354, acc: 0.3636363744735718)
[2024-12-17 01:53:32,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:32,993][root][INFO] - Training Epoch: 1/2, step 2342/7134 completed (loss: 3.4584593772888184, acc: 0.4047619104385376)
[2024-12-17 01:53:33,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,386][root][INFO] - Training Epoch: 1/2, step 2343/7134 completed (loss: 3.7426459789276123, acc: 0.33125001192092896)
[2024-12-17 01:53:33,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:33,766][root][INFO] - Training Epoch: 1/2, step 2344/7134 completed (loss: 4.09929084777832, acc: 0.29629629850387573)
[2024-12-17 01:53:33,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,140][root][INFO] - Training Epoch: 1/2, step 2345/7134 completed (loss: 4.300895690917969, acc: 0.2586206793785095)
[2024-12-17 01:53:34,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,516][root][INFO] - Training Epoch: 1/2, step 2346/7134 completed (loss: 3.49161696434021, acc: 0.3977900445461273)
[2024-12-17 01:53:34,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:34,881][root][INFO] - Training Epoch: 1/2, step 2347/7134 completed (loss: 3.5495054721832275, acc: 0.34507042169570923)
[2024-12-17 01:53:34,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,243][root][INFO] - Training Epoch: 1/2, step 2348/7134 completed (loss: 4.346668720245361, acc: 0.27835050225257874)
[2024-12-17 01:53:35,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:35,606][root][INFO] - Training Epoch: 1/2, step 2349/7134 completed (loss: 4.913152694702148, acc: 0.25)
[2024-12-17 01:53:35,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,006][root][INFO] - Training Epoch: 1/2, step 2350/7134 completed (loss: 5.08400297164917, acc: 0.20253165066242218)
[2024-12-17 01:53:36,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,383][root][INFO] - Training Epoch: 1/2, step 2351/7134 completed (loss: 3.966965913772583, acc: 0.3224043846130371)
[2024-12-17 01:53:36,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:36,790][root][INFO] - Training Epoch: 1/2, step 2352/7134 completed (loss: 4.836804389953613, acc: 0.2451612949371338)
[2024-12-17 01:53:36,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,192][root][INFO] - Training Epoch: 1/2, step 2353/7134 completed (loss: 4.047853469848633, acc: 0.31612902879714966)
[2024-12-17 01:53:37,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:37,563][root][INFO] - Training Epoch: 1/2, step 2354/7134 completed (loss: 3.795368194580078, acc: 0.3333333432674408)
[2024-12-17 01:53:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,001][root][INFO] - Training Epoch: 1/2, step 2355/7134 completed (loss: 4.526535511016846, acc: 0.2928176820278168)
[2024-12-17 01:53:38,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,388][root][INFO] - Training Epoch: 1/2, step 2356/7134 completed (loss: 4.963048934936523, acc: 0.21739129722118378)
[2024-12-17 01:53:38,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:38,743][root][INFO] - Training Epoch: 1/2, step 2357/7134 completed (loss: 4.388574123382568, acc: 0.2222222238779068)
[2024-12-17 01:53:38,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,112][root][INFO] - Training Epoch: 1/2, step 2358/7134 completed (loss: 4.1814422607421875, acc: 0.31122449040412903)
[2024-12-17 01:53:39,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,466][root][INFO] - Training Epoch: 1/2, step 2359/7134 completed (loss: 3.8724911212921143, acc: 0.33125001192092896)
[2024-12-17 01:53:39,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:39,846][root][INFO] - Training Epoch: 1/2, step 2360/7134 completed (loss: 3.77728533744812, acc: 0.3417721390724182)
[2024-12-17 01:53:39,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,230][root][INFO] - Training Epoch: 1/2, step 2361/7134 completed (loss: 3.9777209758758545, acc: 0.244047611951828)
[2024-12-17 01:53:40,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:40,614][root][INFO] - Training Epoch: 1/2, step 2362/7134 completed (loss: 4.000489234924316, acc: 0.315315306186676)
[2024-12-17 01:53:40,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,030][root][INFO] - Training Epoch: 1/2, step 2363/7134 completed (loss: 3.9902710914611816, acc: 0.3403141498565674)
[2024-12-17 01:53:41,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,389][root][INFO] - Training Epoch: 1/2, step 2364/7134 completed (loss: 3.739780902862549, acc: 0.33986929059028625)
[2024-12-17 01:53:41,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:41,733][root][INFO] - Training Epoch: 1/2, step 2365/7134 completed (loss: 3.6908459663391113, acc: 0.31976744532585144)
[2024-12-17 01:53:41,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,124][root][INFO] - Training Epoch: 1/2, step 2366/7134 completed (loss: 3.47621750831604, acc: 0.35384616255760193)
[2024-12-17 01:53:42,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,515][root][INFO] - Training Epoch: 1/2, step 2367/7134 completed (loss: 3.526414155960083, acc: 0.3333333432674408)
[2024-12-17 01:53:42,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:42,916][root][INFO] - Training Epoch: 1/2, step 2368/7134 completed (loss: 3.8921167850494385, acc: 0.28140702843666077)
[2024-12-17 01:53:43,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,328][root][INFO] - Training Epoch: 1/2, step 2369/7134 completed (loss: 3.5304982662200928, acc: 0.3113207519054413)
[2024-12-17 01:53:43,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:43,706][root][INFO] - Training Epoch: 1/2, step 2370/7134 completed (loss: 3.760561227798462, acc: 0.30000001192092896)
[2024-12-17 01:53:43,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,101][root][INFO] - Training Epoch: 1/2, step 2371/7134 completed (loss: 3.899848222732544, acc: 0.29192546010017395)
[2024-12-17 01:53:44,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,467][root][INFO] - Training Epoch: 1/2, step 2372/7134 completed (loss: 3.2907521724700928, acc: 0.33000001311302185)
[2024-12-17 01:53:44,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:44,826][root][INFO] - Training Epoch: 1/2, step 2373/7134 completed (loss: 3.4151806831359863, acc: 0.33678755164146423)
[2024-12-17 01:53:44,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,259][root][INFO] - Training Epoch: 1/2, step 2374/7134 completed (loss: 3.843278169631958, acc: 0.2983425557613373)
[2024-12-17 01:53:45,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:45,629][root][INFO] - Training Epoch: 1/2, step 2375/7134 completed (loss: 4.198976039886475, acc: 0.31515151262283325)
[2024-12-17 01:53:45,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,001][root][INFO] - Training Epoch: 1/2, step 2376/7134 completed (loss: 4.579593658447266, acc: 0.24183006584644318)
[2024-12-17 01:53:46,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,376][root][INFO] - Training Epoch: 1/2, step 2377/7134 completed (loss: 5.230594158172607, acc: 0.16355140507221222)
[2024-12-17 01:53:46,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:46,742][root][INFO] - Training Epoch: 1/2, step 2378/7134 completed (loss: 5.019558906555176, acc: 0.20297029614448547)
[2024-12-17 01:53:46,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,118][root][INFO] - Training Epoch: 1/2, step 2379/7134 completed (loss: 5.217075347900391, acc: 0.15816326439380646)
[2024-12-17 01:53:47,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,487][root][INFO] - Training Epoch: 1/2, step 2380/7134 completed (loss: 5.7150774002075195, acc: 0.16304348409175873)
[2024-12-17 01:53:47,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:47,826][root][INFO] - Training Epoch: 1/2, step 2381/7134 completed (loss: 5.51346492767334, acc: 0.21118012070655823)
[2024-12-17 01:53:47,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,172][root][INFO] - Training Epoch: 1/2, step 2382/7134 completed (loss: 4.6751298904418945, acc: 0.1666666716337204)
[2024-12-17 01:53:48,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,528][root][INFO] - Training Epoch: 1/2, step 2383/7134 completed (loss: 4.766302585601807, acc: 0.19672131538391113)
[2024-12-17 01:53:48,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:48,895][root][INFO] - Training Epoch: 1/2, step 2384/7134 completed (loss: 5.424083709716797, acc: 0.17241379618644714)
[2024-12-17 01:53:49,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,344][root][INFO] - Training Epoch: 1/2, step 2385/7134 completed (loss: 4.85357141494751, acc: 0.18681319057941437)
[2024-12-17 01:53:49,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:49,718][root][INFO] - Training Epoch: 1/2, step 2386/7134 completed (loss: 4.869348049163818, acc: 0.24338623881340027)
[2024-12-17 01:53:49,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,110][root][INFO] - Training Epoch: 1/2, step 2387/7134 completed (loss: 4.8072004318237305, acc: 0.19523809850215912)
[2024-12-17 01:53:50,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,462][root][INFO] - Training Epoch: 1/2, step 2388/7134 completed (loss: 4.591549873352051, acc: 0.2211538404226303)
[2024-12-17 01:53:50,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:50,895][root][INFO] - Training Epoch: 1/2, step 2389/7134 completed (loss: 4.836374759674072, acc: 0.19431279599666595)
[2024-12-17 01:53:51,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,280][root][INFO] - Training Epoch: 1/2, step 2390/7134 completed (loss: 4.955705165863037, acc: 0.22274881601333618)
[2024-12-17 01:53:51,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:51,695][root][INFO] - Training Epoch: 1/2, step 2391/7134 completed (loss: 5.0930495262146, acc: 0.16756756603717804)
[2024-12-17 01:53:51,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,102][root][INFO] - Training Epoch: 1/2, step 2392/7134 completed (loss: 4.845423221588135, acc: 0.24043716490268707)
[2024-12-17 01:53:52,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,485][root][INFO] - Training Epoch: 1/2, step 2393/7134 completed (loss: 4.730733871459961, acc: 0.2227979302406311)
[2024-12-17 01:53:52,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:52,874][root][INFO] - Training Epoch: 1/2, step 2394/7134 completed (loss: 4.972692489624023, acc: 0.18367347121238708)
[2024-12-17 01:53:52,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,272][root][INFO] - Training Epoch: 1/2, step 2395/7134 completed (loss: 4.8131608963012695, acc: 0.21142856776714325)
[2024-12-17 01:53:53,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:53,640][root][INFO] - Training Epoch: 1/2, step 2396/7134 completed (loss: 5.08846378326416, acc: 0.21717171370983124)
[2024-12-17 01:53:53,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,000][root][INFO] - Training Epoch: 1/2, step 2397/7134 completed (loss: 5.036611080169678, acc: 0.19512194395065308)
[2024-12-17 01:53:54,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,386][root][INFO] - Training Epoch: 1/2, step 2398/7134 completed (loss: 4.497142791748047, acc: 0.23783783614635468)
[2024-12-17 01:53:54,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:54,752][root][INFO] - Training Epoch: 1/2, step 2399/7134 completed (loss: 5.11757230758667, acc: 0.22797927260398865)
[2024-12-17 01:53:54,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,154][root][INFO] - Training Epoch: 1/2, step 2400/7134 completed (loss: 4.850554943084717, acc: 0.19597989320755005)
[2024-12-17 01:53:55,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,547][root][INFO] - Training Epoch: 1/2, step 2401/7134 completed (loss: 5.444915294647217, acc: 0.20192307233810425)
[2024-12-17 01:53:55,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:55,928][root][INFO] - Training Epoch: 1/2, step 2402/7134 completed (loss: 5.245858669281006, acc: 0.18840579688549042)
[2024-12-17 01:53:56,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,332][root][INFO] - Training Epoch: 1/2, step 2403/7134 completed (loss: 4.6968865394592285, acc: 0.23952095210552216)
[2024-12-17 01:53:56,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:56,735][root][INFO] - Training Epoch: 1/2, step 2404/7134 completed (loss: 4.3474249839782715, acc: 0.28947368264198303)
[2024-12-17 01:53:56,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,135][root][INFO] - Training Epoch: 1/2, step 2405/7134 completed (loss: 4.257023334503174, acc: 0.29936304688453674)
[2024-12-17 01:53:57,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,515][root][INFO] - Training Epoch: 1/2, step 2406/7134 completed (loss: 4.290767669677734, acc: 0.21301774680614471)
[2024-12-17 01:53:57,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:57,884][root][INFO] - Training Epoch: 1/2, step 2407/7134 completed (loss: 4.21004581451416, acc: 0.3006536066532135)
[2024-12-17 01:53:58,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,254][root][INFO] - Training Epoch: 1/2, step 2408/7134 completed (loss: 3.7983779907226562, acc: 0.28176796436309814)
[2024-12-17 01:53:58,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,620][root][INFO] - Training Epoch: 1/2, step 2409/7134 completed (loss: 4.297097206115723, acc: 0.2562499940395355)
[2024-12-17 01:53:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:58,964][root][INFO] - Training Epoch: 1/2, step 2410/7134 completed (loss: 4.768311500549316, acc: 0.2042253464460373)
[2024-12-17 01:53:59,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,333][root][INFO] - Training Epoch: 1/2, step 2411/7134 completed (loss: 4.03804874420166, acc: 0.2596684992313385)
[2024-12-17 01:53:59,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:53:59,715][root][INFO] - Training Epoch: 1/2, step 2412/7134 completed (loss: 4.008325576782227, acc: 0.27840909361839294)
[2024-12-17 01:53:59,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,102][root][INFO] - Training Epoch: 1/2, step 2413/7134 completed (loss: 4.358458518981934, acc: 0.3181818127632141)
[2024-12-17 01:54:00,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,495][root][INFO] - Training Epoch: 1/2, step 2414/7134 completed (loss: 4.098027229309082, acc: 0.3060109317302704)
[2024-12-17 01:54:00,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:00,892][root][INFO] - Training Epoch: 1/2, step 2415/7134 completed (loss: 4.700610160827637, acc: 0.2621951103210449)
[2024-12-17 01:54:01,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,304][root][INFO] - Training Epoch: 1/2, step 2416/7134 completed (loss: 4.4279866218566895, acc: 0.28930819034576416)
[2024-12-17 01:54:01,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:01,694][root][INFO] - Training Epoch: 1/2, step 2417/7134 completed (loss: 3.7947678565979004, acc: 0.3707317113876343)
[2024-12-17 01:54:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,028][root][INFO] - Training Epoch: 1/2, step 2418/7134 completed (loss: 4.565864562988281, acc: 0.24475523829460144)
[2024-12-17 01:54:02,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,380][root][INFO] - Training Epoch: 1/2, step 2419/7134 completed (loss: 4.270143508911133, acc: 0.23926380276679993)
[2024-12-17 01:54:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:02,754][root][INFO] - Training Epoch: 1/2, step 2420/7134 completed (loss: 3.764492988586426, acc: 0.2986111044883728)
[2024-12-17 01:54:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,131][root][INFO] - Training Epoch: 1/2, step 2421/7134 completed (loss: 3.8226137161254883, acc: 0.318918913602829)
[2024-12-17 01:54:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,543][root][INFO] - Training Epoch: 1/2, step 2422/7134 completed (loss: 4.171045303344727, acc: 0.23999999463558197)
[2024-12-17 01:54:03,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:03,910][root][INFO] - Training Epoch: 1/2, step 2423/7134 completed (loss: 3.4521713256835938, acc: 0.3571428656578064)
[2024-12-17 01:54:04,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,270][root][INFO] - Training Epoch: 1/2, step 2424/7134 completed (loss: 3.7431745529174805, acc: 0.3181818127632141)
[2024-12-17 01:54:04,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:04,642][root][INFO] - Training Epoch: 1/2, step 2425/7134 completed (loss: 3.8515279293060303, acc: 0.3483146131038666)
[2024-12-17 01:54:04,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,036][root][INFO] - Training Epoch: 1/2, step 2426/7134 completed (loss: 4.066209316253662, acc: 0.2816092073917389)
[2024-12-17 01:54:05,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,378][root][INFO] - Training Epoch: 1/2, step 2427/7134 completed (loss: 3.5602025985717773, acc: 0.3385416567325592)
[2024-12-17 01:54:05,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:05,761][root][INFO] - Training Epoch: 1/2, step 2428/7134 completed (loss: 3.744469165802002, acc: 0.28421053290367126)
[2024-12-17 01:54:05,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,164][root][INFO] - Training Epoch: 1/2, step 2429/7134 completed (loss: 3.917949914932251, acc: 0.2848101258277893)
[2024-12-17 01:54:06,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,551][root][INFO] - Training Epoch: 1/2, step 2430/7134 completed (loss: 3.7280526161193848, acc: 0.30666667222976685)
[2024-12-17 01:54:06,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:06,935][root][INFO] - Training Epoch: 1/2, step 2431/7134 completed (loss: 3.467202663421631, acc: 0.3916083872318268)
[2024-12-17 01:54:07,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,302][root][INFO] - Training Epoch: 1/2, step 2432/7134 completed (loss: 4.007497787475586, acc: 0.32231405377388)
[2024-12-17 01:54:07,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:07,678][root][INFO] - Training Epoch: 1/2, step 2433/7134 completed (loss: 4.024352073669434, acc: 0.28057554364204407)
[2024-12-17 01:54:07,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,041][root][INFO] - Training Epoch: 1/2, step 2434/7134 completed (loss: 3.9976463317871094, acc: 0.3288590610027313)
[2024-12-17 01:54:08,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,409][root][INFO] - Training Epoch: 1/2, step 2435/7134 completed (loss: 4.153829097747803, acc: 0.33774834871292114)
[2024-12-17 01:54:08,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:08,765][root][INFO] - Training Epoch: 1/2, step 2436/7134 completed (loss: 3.32027530670166, acc: 0.39593908190727234)
[2024-12-17 01:54:08,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,141][root][INFO] - Training Epoch: 1/2, step 2437/7134 completed (loss: 3.778029203414917, acc: 0.3661971688270569)
[2024-12-17 01:54:09,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,522][root][INFO] - Training Epoch: 1/2, step 2438/7134 completed (loss: 3.6374964714050293, acc: 0.3580246865749359)
[2024-12-17 01:54:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:09,960][root][INFO] - Training Epoch: 1/2, step 2439/7134 completed (loss: 3.7325854301452637, acc: 0.34224599599838257)
[2024-12-17 01:54:10,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,331][root][INFO] - Training Epoch: 1/2, step 2440/7134 completed (loss: 4.43812894821167, acc: 0.3068181872367859)
[2024-12-17 01:54:10,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:10,731][root][INFO] - Training Epoch: 1/2, step 2441/7134 completed (loss: 4.474747180938721, acc: 0.30399999022483826)
[2024-12-17 01:54:10,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,115][root][INFO] - Training Epoch: 1/2, step 2442/7134 completed (loss: 3.9262571334838867, acc: 0.37278106808662415)
[2024-12-17 01:54:11,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,517][root][INFO] - Training Epoch: 1/2, step 2443/7134 completed (loss: 4.159054756164551, acc: 0.25766870379447937)
[2024-12-17 01:54:11,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:11,922][root][INFO] - Training Epoch: 1/2, step 2444/7134 completed (loss: 3.640824317932129, acc: 0.3720930218696594)
[2024-12-17 01:54:12,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,329][root][INFO] - Training Epoch: 1/2, step 2445/7134 completed (loss: 3.9250142574310303, acc: 0.30573248863220215)
[2024-12-17 01:54:12,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:12,725][root][INFO] - Training Epoch: 1/2, step 2446/7134 completed (loss: 4.307075023651123, acc: 0.2792207896709442)
[2024-12-17 01:54:12,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,108][root][INFO] - Training Epoch: 1/2, step 2447/7134 completed (loss: 4.032560348510742, acc: 0.2584269642829895)
[2024-12-17 01:54:13,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,462][root][INFO] - Training Epoch: 1/2, step 2448/7134 completed (loss: 3.612908124923706, acc: 0.38926175236701965)
[2024-12-17 01:54:13,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:13,804][root][INFO] - Training Epoch: 1/2, step 2449/7134 completed (loss: 4.120602130889893, acc: 0.29651162028312683)
[2024-12-17 01:54:13,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,175][root][INFO] - Training Epoch: 1/2, step 2450/7134 completed (loss: 3.805293560028076, acc: 0.33529412746429443)
[2024-12-17 01:54:14,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,528][root][INFO] - Training Epoch: 1/2, step 2451/7134 completed (loss: 4.006040096282959, acc: 0.2245989292860031)
[2024-12-17 01:54:14,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:14,902][root][INFO] - Training Epoch: 1/2, step 2452/7134 completed (loss: 4.081079959869385, acc: 0.24193547666072845)
[2024-12-17 01:54:15,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,282][root][INFO] - Training Epoch: 1/2, step 2453/7134 completed (loss: 4.09623384475708, acc: 0.29015544056892395)
[2024-12-17 01:54:15,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:15,654][root][INFO] - Training Epoch: 1/2, step 2454/7134 completed (loss: 4.282989025115967, acc: 0.24822695553302765)
[2024-12-17 01:54:15,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,032][root][INFO] - Training Epoch: 1/2, step 2455/7134 completed (loss: 4.223695755004883, acc: 0.25766870379447937)
[2024-12-17 01:54:16,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,385][root][INFO] - Training Epoch: 1/2, step 2456/7134 completed (loss: 3.8055601119995117, acc: 0.2953367829322815)
[2024-12-17 01:54:16,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:16,766][root][INFO] - Training Epoch: 1/2, step 2457/7134 completed (loss: 4.082839488983154, acc: 0.23529411852359772)
[2024-12-17 01:54:16,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,133][root][INFO] - Training Epoch: 1/2, step 2458/7134 completed (loss: 4.356980323791504, acc: 0.2562499940395355)
[2024-12-17 01:54:17,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,501][root][INFO] - Training Epoch: 1/2, step 2459/7134 completed (loss: 4.000957012176514, acc: 0.2514619827270508)
[2024-12-17 01:54:17,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:17,875][root][INFO] - Training Epoch: 1/2, step 2460/7134 completed (loss: 3.4933741092681885, acc: 0.3131868243217468)
[2024-12-17 01:54:17,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,228][root][INFO] - Training Epoch: 1/2, step 2461/7134 completed (loss: 3.622157335281372, acc: 0.2704402506351471)
[2024-12-17 01:54:18,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,595][root][INFO] - Training Epoch: 1/2, step 2462/7134 completed (loss: 3.937091588973999, acc: 0.290909081697464)
[2024-12-17 01:54:18,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:18,964][root][INFO] - Training Epoch: 1/2, step 2463/7134 completed (loss: 3.268129825592041, acc: 0.3375000059604645)
[2024-12-17 01:54:19,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,324][root][INFO] - Training Epoch: 1/2, step 2464/7134 completed (loss: 4.013499736785889, acc: 0.2750000059604645)
[2024-12-17 01:54:19,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:19,698][root][INFO] - Training Epoch: 1/2, step 2465/7134 completed (loss: 3.757965326309204, acc: 0.3240223526954651)
[2024-12-17 01:54:19,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,085][root][INFO] - Training Epoch: 1/2, step 2466/7134 completed (loss: 4.01002311706543, acc: 0.257485032081604)
[2024-12-17 01:54:20,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,454][root][INFO] - Training Epoch: 1/2, step 2467/7134 completed (loss: 4.207852840423584, acc: 0.2921348214149475)
[2024-12-17 01:54:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:20,817][root][INFO] - Training Epoch: 1/2, step 2468/7134 completed (loss: 3.7106664180755615, acc: 0.2906976640224457)
[2024-12-17 01:54:20,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,196][root][INFO] - Training Epoch: 1/2, step 2469/7134 completed (loss: 3.496931314468384, acc: 0.302325576543808)
[2024-12-17 01:54:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:21,613][root][INFO] - Training Epoch: 1/2, step 2470/7134 completed (loss: 3.8789873123168945, acc: 0.304964542388916)
[2024-12-17 01:54:21,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,034][root][INFO] - Training Epoch: 1/2, step 2471/7134 completed (loss: 3.644645929336548, acc: 0.3191489279270172)
[2024-12-17 01:54:22,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,421][root][INFO] - Training Epoch: 1/2, step 2472/7134 completed (loss: 3.521918296813965, acc: 0.28378379344940186)
[2024-12-17 01:54:22,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:22,803][root][INFO] - Training Epoch: 1/2, step 2473/7134 completed (loss: 4.143752098083496, acc: 0.30841121077537537)
[2024-12-17 01:54:22,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,182][root][INFO] - Training Epoch: 1/2, step 2474/7134 completed (loss: 3.818906784057617, acc: 0.2969697117805481)
[2024-12-17 01:54:23,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,542][root][INFO] - Training Epoch: 1/2, step 2475/7134 completed (loss: 3.484621047973633, acc: 0.2950819730758667)
[2024-12-17 01:54:23,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:23,912][root][INFO] - Training Epoch: 1/2, step 2476/7134 completed (loss: 3.741920232772827, acc: 0.28654971718788147)
[2024-12-17 01:54:24,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,311][root][INFO] - Training Epoch: 1/2, step 2477/7134 completed (loss: 3.319854736328125, acc: 0.327160507440567)
[2024-12-17 01:54:24,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:24,698][root][INFO] - Training Epoch: 1/2, step 2478/7134 completed (loss: 3.3962528705596924, acc: 0.28859061002731323)
[2024-12-17 01:54:24,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,102][root][INFO] - Training Epoch: 1/2, step 2479/7134 completed (loss: 4.212911605834961, acc: 0.2789115607738495)
[2024-12-17 01:54:25,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,484][root][INFO] - Training Epoch: 1/2, step 2480/7134 completed (loss: 3.144960641860962, acc: 0.39423078298568726)
[2024-12-17 01:54:25,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:25,851][root][INFO] - Training Epoch: 1/2, step 2481/7134 completed (loss: 3.5357751846313477, acc: 0.32692307233810425)
[2024-12-17 01:54:25,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,231][root][INFO] - Training Epoch: 1/2, step 2482/7134 completed (loss: 3.8482553958892822, acc: 0.2857142984867096)
[2024-12-17 01:54:26,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:26,622][root][INFO] - Training Epoch: 1/2, step 2483/7134 completed (loss: 3.468095541000366, acc: 0.31736525893211365)
[2024-12-17 01:54:26,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,001][root][INFO] - Training Epoch: 1/2, step 2484/7134 completed (loss: 3.4715235233306885, acc: 0.33734938502311707)
[2024-12-17 01:54:27,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,367][root][INFO] - Training Epoch: 1/2, step 2485/7134 completed (loss: 3.2299814224243164, acc: 0.3777777850627899)
[2024-12-17 01:54:27,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:27,784][root][INFO] - Training Epoch: 1/2, step 2486/7134 completed (loss: 3.602309465408325, acc: 0.30136987566947937)
[2024-12-17 01:54:27,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,189][root][INFO] - Training Epoch: 1/2, step 2487/7134 completed (loss: 3.647355794906616, acc: 0.3680555522441864)
[2024-12-17 01:54:28,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,561][root][INFO] - Training Epoch: 1/2, step 2488/7134 completed (loss: 3.859313488006592, acc: 0.290909081697464)
[2024-12-17 01:54:28,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:28,925][root][INFO] - Training Epoch: 1/2, step 2489/7134 completed (loss: 3.324087381362915, acc: 0.34319525957107544)
[2024-12-17 01:54:29,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,302][root][INFO] - Training Epoch: 1/2, step 2490/7134 completed (loss: 3.9143130779266357, acc: 0.26623377203941345)
[2024-12-17 01:54:29,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:29,663][root][INFO] - Training Epoch: 1/2, step 2491/7134 completed (loss: 3.5851314067840576, acc: 0.31343284249305725)
[2024-12-17 01:54:29,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,045][root][INFO] - Training Epoch: 1/2, step 2492/7134 completed (loss: 3.6040146350860596, acc: 0.36477985978126526)
[2024-12-17 01:54:30,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,421][root][INFO] - Training Epoch: 1/2, step 2493/7134 completed (loss: 4.071719169616699, acc: 0.2976190447807312)
[2024-12-17 01:54:30,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:30,842][root][INFO] - Training Epoch: 1/2, step 2494/7134 completed (loss: 3.8181562423706055, acc: 0.2839506268501282)
[2024-12-17 01:54:30,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,213][root][INFO] - Training Epoch: 1/2, step 2495/7134 completed (loss: 3.850619077682495, acc: 0.34705883264541626)
[2024-12-17 01:54:31,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,579][root][INFO] - Training Epoch: 1/2, step 2496/7134 completed (loss: 3.857118606567383, acc: 0.29113924503326416)
[2024-12-17 01:54:31,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:31,954][root][INFO] - Training Epoch: 1/2, step 2497/7134 completed (loss: 3.810190200805664, acc: 0.3045977056026459)
[2024-12-17 01:54:32,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,327][root][INFO] - Training Epoch: 1/2, step 2498/7134 completed (loss: 3.736713409423828, acc: 0.2857142984867096)
[2024-12-17 01:54:32,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:32,690][root][INFO] - Training Epoch: 1/2, step 2499/7134 completed (loss: 3.71317195892334, acc: 0.379518061876297)
[2024-12-17 01:54:32,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,050][root][INFO] - Training Epoch: 1/2, step 2500/7134 completed (loss: 3.8219215869903564, acc: 0.28378379344940186)
[2024-12-17 01:54:33,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,406][root][INFO] - Training Epoch: 1/2, step 2501/7134 completed (loss: 3.9619624614715576, acc: 0.2977527976036072)
[2024-12-17 01:54:33,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:33,773][root][INFO] - Training Epoch: 1/2, step 2502/7134 completed (loss: 3.4052698612213135, acc: 0.34188035130500793)
[2024-12-17 01:54:33,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,118][root][INFO] - Training Epoch: 1/2, step 2503/7134 completed (loss: 3.612630844116211, acc: 0.3115941882133484)
[2024-12-17 01:54:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,485][root][INFO] - Training Epoch: 1/2, step 2504/7134 completed (loss: 3.6680545806884766, acc: 0.3987341821193695)
[2024-12-17 01:54:34,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:34,849][root][INFO] - Training Epoch: 1/2, step 2505/7134 completed (loss: 3.6958086490631104, acc: 0.30813953280448914)
[2024-12-17 01:54:34,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,240][root][INFO] - Training Epoch: 1/2, step 2506/7134 completed (loss: 3.992403984069824, acc: 0.32786884903907776)
[2024-12-17 01:54:35,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,616][root][INFO] - Training Epoch: 1/2, step 2507/7134 completed (loss: 2.8332040309906006, acc: 0.4055555462837219)
[2024-12-17 01:54:35,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:35,989][root][INFO] - Training Epoch: 1/2, step 2508/7134 completed (loss: 3.2639243602752686, acc: 0.38418078422546387)
[2024-12-17 01:54:36,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,341][root][INFO] - Training Epoch: 1/2, step 2509/7134 completed (loss: 3.179570436477661, acc: 0.4058823585510254)
[2024-12-17 01:54:36,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:36,700][root][INFO] - Training Epoch: 1/2, step 2510/7134 completed (loss: 2.8515379428863525, acc: 0.44285714626312256)
[2024-12-17 01:54:36,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,079][root][INFO] - Training Epoch: 1/2, step 2511/7134 completed (loss: 3.481699228286743, acc: 0.3715847134590149)
[2024-12-17 01:54:37,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,452][root][INFO] - Training Epoch: 1/2, step 2512/7134 completed (loss: 3.6263086795806885, acc: 0.3176470696926117)
[2024-12-17 01:54:37,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:37,820][root][INFO] - Training Epoch: 1/2, step 2513/7134 completed (loss: 2.9868006706237793, acc: 0.4516128897666931)
[2024-12-17 01:54:37,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,185][root][INFO] - Training Epoch: 1/2, step 2514/7134 completed (loss: 3.3888018131256104, acc: 0.42038217186927795)
[2024-12-17 01:54:38,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,548][root][INFO] - Training Epoch: 1/2, step 2515/7134 completed (loss: 3.354348659515381, acc: 0.37012988328933716)
[2024-12-17 01:54:38,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:38,946][root][INFO] - Training Epoch: 1/2, step 2516/7134 completed (loss: 3.282452344894409, acc: 0.31843575835227966)
[2024-12-17 01:54:39,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,333][root][INFO] - Training Epoch: 1/2, step 2517/7134 completed (loss: 3.136827230453491, acc: 0.4055555462837219)
[2024-12-17 01:54:39,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:39,666][root][INFO] - Training Epoch: 1/2, step 2518/7134 completed (loss: 3.848176956176758, acc: 0.2875817120075226)
[2024-12-17 01:54:39,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,038][root][INFO] - Training Epoch: 1/2, step 2519/7134 completed (loss: 3.975613594055176, acc: 0.23870967328548431)
[2024-12-17 01:54:40,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,409][root][INFO] - Training Epoch: 1/2, step 2520/7134 completed (loss: 4.563388824462891, acc: 0.25)
[2024-12-17 01:54:40,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:40,779][root][INFO] - Training Epoch: 1/2, step 2521/7134 completed (loss: 3.9675796031951904, acc: 0.3351648449897766)
[2024-12-17 01:54:40,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,134][root][INFO] - Training Epoch: 1/2, step 2522/7134 completed (loss: 4.217256546020508, acc: 0.2344827651977539)
[2024-12-17 01:54:41,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,493][root][INFO] - Training Epoch: 1/2, step 2523/7134 completed (loss: 4.037938594818115, acc: 0.29447853565216064)
[2024-12-17 01:54:41,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:41,860][root][INFO] - Training Epoch: 1/2, step 2524/7134 completed (loss: 3.9706168174743652, acc: 0.2926829159259796)
[2024-12-17 01:54:41,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,244][root][INFO] - Training Epoch: 1/2, step 2525/7134 completed (loss: 4.184778690338135, acc: 0.232876718044281)
[2024-12-17 01:54:42,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,571][root][INFO] - Training Epoch: 1/2, step 2526/7134 completed (loss: 3.765211820602417, acc: 0.27272728085517883)
[2024-12-17 01:54:42,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:42,934][root][INFO] - Training Epoch: 1/2, step 2527/7134 completed (loss: 3.9080679416656494, acc: 0.3060109317302704)
[2024-12-17 01:54:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,299][root][INFO] - Training Epoch: 1/2, step 2528/7134 completed (loss: 3.8679397106170654, acc: 0.29518070816993713)
[2024-12-17 01:54:43,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:43,680][root][INFO] - Training Epoch: 1/2, step 2529/7134 completed (loss: 3.8793153762817383, acc: 0.255952388048172)
[2024-12-17 01:54:43,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,058][root][INFO] - Training Epoch: 1/2, step 2530/7134 completed (loss: 3.636894941329956, acc: 0.2921348214149475)
[2024-12-17 01:54:44,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,415][root][INFO] - Training Epoch: 1/2, step 2531/7134 completed (loss: 3.608814239501953, acc: 0.3192771077156067)
[2024-12-17 01:54:44,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:44,772][root][INFO] - Training Epoch: 1/2, step 2532/7134 completed (loss: 3.781822443008423, acc: 0.273333340883255)
[2024-12-17 01:54:44,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,146][root][INFO] - Training Epoch: 1/2, step 2533/7134 completed (loss: 4.271860599517822, acc: 0.2884615361690521)
[2024-12-17 01:54:45,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,502][root][INFO] - Training Epoch: 1/2, step 2534/7134 completed (loss: 3.6095595359802246, acc: 0.2402234673500061)
[2024-12-17 01:54:45,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:45,869][root][INFO] - Training Epoch: 1/2, step 2535/7134 completed (loss: 3.607513189315796, acc: 0.347457617521286)
[2024-12-17 01:54:45,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,233][root][INFO] - Training Epoch: 1/2, step 2536/7134 completed (loss: 3.8171987533569336, acc: 0.3056994676589966)
[2024-12-17 01:54:46,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:46,592][root][INFO] - Training Epoch: 1/2, step 2537/7134 completed (loss: 4.2881951332092285, acc: 0.25342464447021484)
[2024-12-17 01:54:46,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,004][root][INFO] - Training Epoch: 1/2, step 2538/7134 completed (loss: 4.1844868659973145, acc: 0.3218390941619873)
[2024-12-17 01:54:47,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,367][root][INFO] - Training Epoch: 1/2, step 2539/7134 completed (loss: 4.00051736831665, acc: 0.30075186491012573)
[2024-12-17 01:54:47,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:47,731][root][INFO] - Training Epoch: 1/2, step 2540/7134 completed (loss: 4.111974239349365, acc: 0.251655638217926)
[2024-12-17 01:54:47,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,092][root][INFO] - Training Epoch: 1/2, step 2541/7134 completed (loss: 4.191715240478516, acc: 0.29411765933036804)
[2024-12-17 01:54:48,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,475][root][INFO] - Training Epoch: 1/2, step 2542/7134 completed (loss: 3.6901779174804688, acc: 0.29374998807907104)
[2024-12-17 01:54:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:48,848][root][INFO] - Training Epoch: 1/2, step 2543/7134 completed (loss: 4.426154136657715, acc: 0.22012577950954437)
[2024-12-17 01:54:48,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,212][root][INFO] - Training Epoch: 1/2, step 2544/7134 completed (loss: 3.902599811553955, acc: 0.3392857015132904)
[2024-12-17 01:54:49,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,581][root][INFO] - Training Epoch: 1/2, step 2545/7134 completed (loss: 3.8808979988098145, acc: 0.28358209133148193)
[2024-12-17 01:54:49,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:49,977][root][INFO] - Training Epoch: 1/2, step 2546/7134 completed (loss: 3.701559543609619, acc: 0.34183672070503235)
[2024-12-17 01:54:50,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,339][root][INFO] - Training Epoch: 1/2, step 2547/7134 completed (loss: 3.5861198902130127, acc: 0.3381294906139374)
[2024-12-17 01:54:50,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:50,698][root][INFO] - Training Epoch: 1/2, step 2548/7134 completed (loss: 3.4025189876556396, acc: 0.3097345232963562)
[2024-12-17 01:54:50,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,050][root][INFO] - Training Epoch: 1/2, step 2549/7134 completed (loss: 3.4946985244750977, acc: 0.3252032399177551)
[2024-12-17 01:54:51,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,409][root][INFO] - Training Epoch: 1/2, step 2550/7134 completed (loss: 3.2301807403564453, acc: 0.2876712381839752)
[2024-12-17 01:54:51,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:51,767][root][INFO] - Training Epoch: 1/2, step 2551/7134 completed (loss: 3.840519905090332, acc: 0.2971014380455017)
[2024-12-17 01:54:51,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,143][root][INFO] - Training Epoch: 1/2, step 2552/7134 completed (loss: 3.288400411605835, acc: 0.3544303774833679)
[2024-12-17 01:54:52,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,530][root][INFO] - Training Epoch: 1/2, step 2553/7134 completed (loss: 4.04034423828125, acc: 0.2763157784938812)
[2024-12-17 01:54:52,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:52,930][root][INFO] - Training Epoch: 1/2, step 2554/7134 completed (loss: 3.940232038497925, acc: 0.31496062874794006)
[2024-12-17 01:54:53,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,281][root][INFO] - Training Epoch: 1/2, step 2555/7134 completed (loss: 3.9632678031921387, acc: 0.315315306186676)
[2024-12-17 01:54:53,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,644][root][INFO] - Training Epoch: 1/2, step 2556/7134 completed (loss: 3.6089823246002197, acc: 0.36000001430511475)
[2024-12-17 01:54:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:53,991][root][INFO] - Training Epoch: 1/2, step 2557/7134 completed (loss: 3.621509313583374, acc: 0.3265306055545807)
[2024-12-17 01:54:54,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,346][root][INFO] - Training Epoch: 1/2, step 2558/7134 completed (loss: 3.64616060256958, acc: 0.32846716046333313)
[2024-12-17 01:54:54,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:54,706][root][INFO] - Training Epoch: 1/2, step 2559/7134 completed (loss: 3.6542372703552246, acc: 0.3062500059604645)
[2024-12-17 01:54:54,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,083][root][INFO] - Training Epoch: 1/2, step 2560/7134 completed (loss: 3.571932792663574, acc: 0.29729729890823364)
[2024-12-17 01:54:55,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,434][root][INFO] - Training Epoch: 1/2, step 2561/7134 completed (loss: 4.003716945648193, acc: 0.2395833283662796)
[2024-12-17 01:54:55,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:55,776][root][INFO] - Training Epoch: 1/2, step 2562/7134 completed (loss: 3.6859445571899414, acc: 0.24799999594688416)
[2024-12-17 01:54:55,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,145][root][INFO] - Training Epoch: 1/2, step 2563/7134 completed (loss: 3.6276049613952637, acc: 0.2662721872329712)
[2024-12-17 01:54:56,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,515][root][INFO] - Training Epoch: 1/2, step 2564/7134 completed (loss: 3.5857114791870117, acc: 0.28776979446411133)
[2024-12-17 01:54:56,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:56,871][root][INFO] - Training Epoch: 1/2, step 2565/7134 completed (loss: 3.676262617111206, acc: 0.3381294906139374)
[2024-12-17 01:54:56,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,244][root][INFO] - Training Epoch: 1/2, step 2566/7134 completed (loss: 3.6649367809295654, acc: 0.3132530152797699)
[2024-12-17 01:54:57,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,568][root][INFO] - Training Epoch: 1/2, step 2567/7134 completed (loss: 3.5019631385803223, acc: 0.2857142984867096)
[2024-12-17 01:54:57,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:57,928][root][INFO] - Training Epoch: 1/2, step 2568/7134 completed (loss: 3.8463306427001953, acc: 0.3076923191547394)
[2024-12-17 01:54:58,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,301][root][INFO] - Training Epoch: 1/2, step 2569/7134 completed (loss: 3.587090015411377, acc: 0.30985915660858154)
[2024-12-17 01:54:58,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:58,682][root][INFO] - Training Epoch: 1/2, step 2570/7134 completed (loss: 3.2427680492401123, acc: 0.3973509967327118)
[2024-12-17 01:54:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,047][root][INFO] - Training Epoch: 1/2, step 2571/7134 completed (loss: 3.9072859287261963, acc: 0.28688523173332214)
[2024-12-17 01:54:59,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,415][root][INFO] - Training Epoch: 1/2, step 2572/7134 completed (loss: 3.4864847660064697, acc: 0.3469387888908386)
[2024-12-17 01:54:59,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:54:59,783][root][INFO] - Training Epoch: 1/2, step 2573/7134 completed (loss: 3.21891713142395, acc: 0.3741007149219513)
[2024-12-17 01:54:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,131][root][INFO] - Training Epoch: 1/2, step 2574/7134 completed (loss: 3.822108507156372, acc: 0.19191919267177582)
[2024-12-17 01:55:00,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,492][root][INFO] - Training Epoch: 1/2, step 2575/7134 completed (loss: 3.4648590087890625, acc: 0.3852458894252777)
[2024-12-17 01:55:00,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:00,850][root][INFO] - Training Epoch: 1/2, step 2576/7134 completed (loss: 3.4128894805908203, acc: 0.3333333432674408)
[2024-12-17 01:55:00,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,208][root][INFO] - Training Epoch: 1/2, step 2577/7134 completed (loss: 3.8068008422851562, acc: 0.33070865273475647)
[2024-12-17 01:55:01,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,569][root][INFO] - Training Epoch: 1/2, step 2578/7134 completed (loss: 4.556376934051514, acc: 0.2810457646846771)
[2024-12-17 01:55:01,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:01,904][root][INFO] - Training Epoch: 1/2, step 2579/7134 completed (loss: 4.447645664215088, acc: 0.29487180709838867)
[2024-12-17 01:55:02,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,285][root][INFO] - Training Epoch: 1/2, step 2580/7134 completed (loss: 4.694101810455322, acc: 0.2774566411972046)
[2024-12-17 01:55:02,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:02,671][root][INFO] - Training Epoch: 1/2, step 2581/7134 completed (loss: 4.6584601402282715, acc: 0.29378530383110046)
[2024-12-17 01:55:02,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,057][root][INFO] - Training Epoch: 1/2, step 2582/7134 completed (loss: 4.338193893432617, acc: 0.2881355881690979)
[2024-12-17 01:55:03,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,443][root][INFO] - Training Epoch: 1/2, step 2583/7134 completed (loss: 4.581892013549805, acc: 0.2586206793785095)
[2024-12-17 01:55:03,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:03,822][root][INFO] - Training Epoch: 1/2, step 2584/7134 completed (loss: 4.271067142486572, acc: 0.29078012704849243)
[2024-12-17 01:55:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,193][root][INFO] - Training Epoch: 1/2, step 2585/7134 completed (loss: 4.259768009185791, acc: 0.29801324009895325)
[2024-12-17 01:55:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,573][root][INFO] - Training Epoch: 1/2, step 2586/7134 completed (loss: 3.9529061317443848, acc: 0.32307693362236023)
[2024-12-17 01:55:04,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:04,984][root][INFO] - Training Epoch: 1/2, step 2587/7134 completed (loss: 4.213200569152832, acc: 0.30000001192092896)
[2024-12-17 01:55:05,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,353][root][INFO] - Training Epoch: 1/2, step 2588/7134 completed (loss: 4.045877456665039, acc: 0.2925170063972473)
[2024-12-17 01:55:05,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:05,707][root][INFO] - Training Epoch: 1/2, step 2589/7134 completed (loss: 4.5212321281433105, acc: 0.2857142984867096)
[2024-12-17 01:55:05,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,050][root][INFO] - Training Epoch: 1/2, step 2590/7134 completed (loss: 4.1738715171813965, acc: 0.25925925374031067)
[2024-12-17 01:55:06,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,412][root][INFO] - Training Epoch: 1/2, step 2591/7134 completed (loss: 4.728976249694824, acc: 0.2923976480960846)
[2024-12-17 01:55:06,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:06,774][root][INFO] - Training Epoch: 1/2, step 2592/7134 completed (loss: 4.296108245849609, acc: 0.2849161922931671)
[2024-12-17 01:55:06,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,144][root][INFO] - Training Epoch: 1/2, step 2593/7134 completed (loss: 4.092146873474121, acc: 0.31707316637039185)
[2024-12-17 01:55:07,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,506][root][INFO] - Training Epoch: 1/2, step 2594/7134 completed (loss: 4.30348014831543, acc: 0.3464052379131317)
[2024-12-17 01:55:07,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:07,873][root][INFO] - Training Epoch: 1/2, step 2595/7134 completed (loss: 4.044313430786133, acc: 0.28658536076545715)
[2024-12-17 01:55:07,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,256][root][INFO] - Training Epoch: 1/2, step 2596/7134 completed (loss: 4.2870564460754395, acc: 0.2647058963775635)
[2024-12-17 01:55:08,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,620][root][INFO] - Training Epoch: 1/2, step 2597/7134 completed (loss: 4.037440299987793, acc: 0.31073445081710815)
[2024-12-17 01:55:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:08,975][root][INFO] - Training Epoch: 1/2, step 2598/7134 completed (loss: 3.956272840499878, acc: 0.3509933650493622)
[2024-12-17 01:55:09,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,318][root][INFO] - Training Epoch: 1/2, step 2599/7134 completed (loss: 4.026432514190674, acc: 0.2704402506351471)
[2024-12-17 01:55:09,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:09,671][root][INFO] - Training Epoch: 1/2, step 2600/7134 completed (loss: 3.3695943355560303, acc: 0.4157303273677826)
[2024-12-17 01:55:09,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,044][root][INFO] - Training Epoch: 1/2, step 2601/7134 completed (loss: 4.055304527282715, acc: 0.2967741787433624)
[2024-12-17 01:55:10,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,407][root][INFO] - Training Epoch: 1/2, step 2602/7134 completed (loss: 4.093988418579102, acc: 0.2797619104385376)
[2024-12-17 01:55:10,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:10,785][root][INFO] - Training Epoch: 1/2, step 2603/7134 completed (loss: 3.957066059112549, acc: 0.3202614486217499)
[2024-12-17 01:55:10,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,156][root][INFO] - Training Epoch: 1/2, step 2604/7134 completed (loss: 4.124975681304932, acc: 0.27513226866722107)
[2024-12-17 01:55:11,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,511][root][INFO] - Training Epoch: 1/2, step 2605/7134 completed (loss: 4.029534816741943, acc: 0.3008849620819092)
[2024-12-17 01:55:11,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:11,872][root][INFO] - Training Epoch: 1/2, step 2606/7134 completed (loss: 4.1501665115356445, acc: 0.23333333432674408)
[2024-12-17 01:55:11,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,241][root][INFO] - Training Epoch: 1/2, step 2607/7134 completed (loss: 3.671095609664917, acc: 0.3314606845378876)
[2024-12-17 01:55:12,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,607][root][INFO] - Training Epoch: 1/2, step 2608/7134 completed (loss: 4.071328639984131, acc: 0.30158731341362)
[2024-12-17 01:55:12,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:12,973][root][INFO] - Training Epoch: 1/2, step 2609/7134 completed (loss: 4.288995265960693, acc: 0.26143792271614075)
[2024-12-17 01:55:13,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,313][root][INFO] - Training Epoch: 1/2, step 2610/7134 completed (loss: 4.539012432098389, acc: 0.28057554364204407)
[2024-12-17 01:55:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:13,688][root][INFO] - Training Epoch: 1/2, step 2611/7134 completed (loss: 4.237647533416748, acc: 0.2849161922931671)
[2024-12-17 01:55:13,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,067][root][INFO] - Training Epoch: 1/2, step 2612/7134 completed (loss: 4.237055778503418, acc: 0.27000001072883606)
[2024-12-17 01:55:14,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,452][root][INFO] - Training Epoch: 1/2, step 2613/7134 completed (loss: 4.0238165855407715, acc: 0.3035714328289032)
[2024-12-17 01:55:14,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:14,824][root][INFO] - Training Epoch: 1/2, step 2614/7134 completed (loss: 4.625942707061768, acc: 0.23404255509376526)
[2024-12-17 01:55:14,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,171][root][INFO] - Training Epoch: 1/2, step 2615/7134 completed (loss: 4.003306865692139, acc: 0.3314606845378876)
[2024-12-17 01:55:15,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,525][root][INFO] - Training Epoch: 1/2, step 2616/7134 completed (loss: 4.22670841217041, acc: 0.29411765933036804)
[2024-12-17 01:55:15,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:15,905][root][INFO] - Training Epoch: 1/2, step 2617/7134 completed (loss: 4.514978408813477, acc: 0.24873095750808716)
[2024-12-17 01:55:16,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,227][root][INFO] - Training Epoch: 1/2, step 2618/7134 completed (loss: 4.2192840576171875, acc: 0.2905983030796051)
[2024-12-17 01:55:16,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,601][root][INFO] - Training Epoch: 1/2, step 2619/7134 completed (loss: 3.7607903480529785, acc: 0.34057971835136414)
[2024-12-17 01:55:16,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:16,957][root][INFO] - Training Epoch: 1/2, step 2620/7134 completed (loss: 3.78717303276062, acc: 0.3650793731212616)
[2024-12-17 01:55:17,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,320][root][INFO] - Training Epoch: 1/2, step 2621/7134 completed (loss: 4.167377471923828, acc: 0.3636363744735718)
[2024-12-17 01:55:17,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:17,680][root][INFO] - Training Epoch: 1/2, step 2622/7134 completed (loss: 4.24542760848999, acc: 0.3287671208381653)
[2024-12-17 01:55:17,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,057][root][INFO] - Training Epoch: 1/2, step 2623/7134 completed (loss: 3.690317153930664, acc: 0.3302752375602722)
[2024-12-17 01:55:18,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,425][root][INFO] - Training Epoch: 1/2, step 2624/7134 completed (loss: 3.996821403503418, acc: 0.3333333432674408)
[2024-12-17 01:55:18,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:18,786][root][INFO] - Training Epoch: 1/2, step 2625/7134 completed (loss: 4.29701042175293, acc: 0.255952388048172)
[2024-12-17 01:55:18,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,146][root][INFO] - Training Epoch: 1/2, step 2626/7134 completed (loss: 4.351977825164795, acc: 0.22413793206214905)
[2024-12-17 01:55:19,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,512][root][INFO] - Training Epoch: 1/2, step 2627/7134 completed (loss: 4.159774303436279, acc: 0.33742332458496094)
[2024-12-17 01:55:19,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:19,856][root][INFO] - Training Epoch: 1/2, step 2628/7134 completed (loss: 3.941866397857666, acc: 0.33888888359069824)
[2024-12-17 01:55:20,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,312][root][INFO] - Training Epoch: 1/2, step 2629/7134 completed (loss: 3.844984292984009, acc: 0.34730538725852966)
[2024-12-17 01:55:20,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:20,670][root][INFO] - Training Epoch: 1/2, step 2630/7134 completed (loss: 4.2231316566467285, acc: 0.32608696818351746)
[2024-12-17 01:55:20,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,028][root][INFO] - Training Epoch: 1/2, step 2631/7134 completed (loss: 3.772449254989624, acc: 0.36548224091529846)
[2024-12-17 01:55:21,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,407][root][INFO] - Training Epoch: 1/2, step 2632/7134 completed (loss: 4.341569900512695, acc: 0.2869565188884735)
[2024-12-17 01:55:21,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:21,787][root][INFO] - Training Epoch: 1/2, step 2633/7134 completed (loss: 4.290760517120361, acc: 0.24725274741649628)
[2024-12-17 01:55:21,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,135][root][INFO] - Training Epoch: 1/2, step 2634/7134 completed (loss: 3.729124069213867, acc: 0.33136093616485596)
[2024-12-17 01:55:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,522][root][INFO] - Training Epoch: 1/2, step 2635/7134 completed (loss: 4.441542625427246, acc: 0.27222222089767456)
[2024-12-17 01:55:22,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:22,903][root][INFO] - Training Epoch: 1/2, step 2636/7134 completed (loss: 4.293261528015137, acc: 0.27374300360679626)
[2024-12-17 01:55:23,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,330][root][INFO] - Training Epoch: 1/2, step 2637/7134 completed (loss: 4.251101970672607, acc: 0.30674847960472107)
[2024-12-17 01:55:23,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:23,710][root][INFO] - Training Epoch: 1/2, step 2638/7134 completed (loss: 4.512662887573242, acc: 0.2537313401699066)
[2024-12-17 01:55:23,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,074][root][INFO] - Training Epoch: 1/2, step 2639/7134 completed (loss: 4.308431148529053, acc: 0.27067670226097107)
[2024-12-17 01:55:24,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,445][root][INFO] - Training Epoch: 1/2, step 2640/7134 completed (loss: 4.1420979499816895, acc: 0.30845770239830017)
[2024-12-17 01:55:24,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:24,812][root][INFO] - Training Epoch: 1/2, step 2641/7134 completed (loss: 4.161452770233154, acc: 0.2857142984867096)
[2024-12-17 01:55:24,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,171][root][INFO] - Training Epoch: 1/2, step 2642/7134 completed (loss: 5.022855281829834, acc: 0.2202380895614624)
[2024-12-17 01:55:25,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,544][root][INFO] - Training Epoch: 1/2, step 2643/7134 completed (loss: 4.43467903137207, acc: 0.21511627733707428)
[2024-12-17 01:55:25,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:25,954][root][INFO] - Training Epoch: 1/2, step 2644/7134 completed (loss: 4.030980587005615, acc: 0.3174603283405304)
[2024-12-17 01:55:26,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,319][root][INFO] - Training Epoch: 1/2, step 2645/7134 completed (loss: 4.207790851593018, acc: 0.2628571391105652)
[2024-12-17 01:55:26,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:26,720][root][INFO] - Training Epoch: 1/2, step 2646/7134 completed (loss: 4.420648574829102, acc: 0.260869562625885)
[2024-12-17 01:55:26,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,127][root][INFO] - Training Epoch: 1/2, step 2647/7134 completed (loss: 4.071274280548096, acc: 0.29891303181648254)
[2024-12-17 01:55:27,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,518][root][INFO] - Training Epoch: 1/2, step 2648/7134 completed (loss: 4.239377021789551, acc: 0.2574257552623749)
[2024-12-17 01:55:27,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:27,956][root][INFO] - Training Epoch: 1/2, step 2649/7134 completed (loss: 4.781811237335205, acc: 0.227027028799057)
[2024-12-17 01:55:28,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,360][root][INFO] - Training Epoch: 1/2, step 2650/7134 completed (loss: 4.835628509521484, acc: 0.21176470816135406)
[2024-12-17 01:55:28,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:28,730][root][INFO] - Training Epoch: 1/2, step 2651/7134 completed (loss: 3.988567352294922, acc: 0.27317073941230774)
[2024-12-17 01:55:28,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,102][root][INFO] - Training Epoch: 1/2, step 2652/7134 completed (loss: 4.167755126953125, acc: 0.3258427083492279)
[2024-12-17 01:55:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,469][root][INFO] - Training Epoch: 1/2, step 2653/7134 completed (loss: 4.623043060302734, acc: 0.19607843458652496)
[2024-12-17 01:55:29,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:29,833][root][INFO] - Training Epoch: 1/2, step 2654/7134 completed (loss: 4.694676876068115, acc: 0.20000000298023224)
[2024-12-17 01:55:29,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,188][root][INFO] - Training Epoch: 1/2, step 2655/7134 completed (loss: 4.215200424194336, acc: 0.2732919156551361)
[2024-12-17 01:55:30,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,554][root][INFO] - Training Epoch: 1/2, step 2656/7134 completed (loss: 4.289184093475342, acc: 0.24418604373931885)
[2024-12-17 01:55:30,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:30,928][root][INFO] - Training Epoch: 1/2, step 2657/7134 completed (loss: 4.168474197387695, acc: 0.26582279801368713)
[2024-12-17 01:55:31,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,292][root][INFO] - Training Epoch: 1/2, step 2658/7134 completed (loss: 4.011817455291748, acc: 0.3333333432674408)
[2024-12-17 01:55:31,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,636][root][INFO] - Training Epoch: 1/2, step 2659/7134 completed (loss: 4.018484592437744, acc: 0.29104477167129517)
[2024-12-17 01:55:31,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:31,992][root][INFO] - Training Epoch: 1/2, step 2660/7134 completed (loss: 4.743399143218994, acc: 0.25641027092933655)
[2024-12-17 01:55:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,357][root][INFO] - Training Epoch: 1/2, step 2661/7134 completed (loss: 3.672506332397461, acc: 0.2958579957485199)
[2024-12-17 01:55:32,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:32,730][root][INFO] - Training Epoch: 1/2, step 2662/7134 completed (loss: 4.133215427398682, acc: 0.2530864179134369)
[2024-12-17 01:55:32,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,109][root][INFO] - Training Epoch: 1/2, step 2663/7134 completed (loss: 3.976534366607666, acc: 0.32642486691474915)
[2024-12-17 01:55:33,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,478][root][INFO] - Training Epoch: 1/2, step 2664/7134 completed (loss: 4.5289106369018555, acc: 0.3139534890651703)
[2024-12-17 01:55:33,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:33,833][root][INFO] - Training Epoch: 1/2, step 2665/7134 completed (loss: 4.073113918304443, acc: 0.2530120611190796)
[2024-12-17 01:55:33,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,212][root][INFO] - Training Epoch: 1/2, step 2666/7134 completed (loss: 4.007666110992432, acc: 0.23255814611911774)
[2024-12-17 01:55:34,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,577][root][INFO] - Training Epoch: 1/2, step 2667/7134 completed (loss: 3.8111298084259033, acc: 0.27848100662231445)
[2024-12-17 01:55:34,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:34,939][root][INFO] - Training Epoch: 1/2, step 2668/7134 completed (loss: 3.3511931896209717, acc: 0.35428571701049805)
[2024-12-17 01:55:35,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,311][root][INFO] - Training Epoch: 1/2, step 2669/7134 completed (loss: 3.2308804988861084, acc: 0.3333333432674408)
[2024-12-17 01:55:35,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:35,680][root][INFO] - Training Epoch: 1/2, step 2670/7134 completed (loss: 4.08720064163208, acc: 0.35428571701049805)
[2024-12-17 01:55:35,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,048][root][INFO] - Training Epoch: 1/2, step 2671/7134 completed (loss: 4.150716781616211, acc: 0.2857142984867096)
[2024-12-17 01:55:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,417][root][INFO] - Training Epoch: 1/2, step 2672/7134 completed (loss: 3.5468077659606934, acc: 0.29518070816993713)
[2024-12-17 01:55:36,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:36,794][root][INFO] - Training Epoch: 1/2, step 2673/7134 completed (loss: 3.8384392261505127, acc: 0.3038673996925354)
[2024-12-17 01:55:36,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,146][root][INFO] - Training Epoch: 1/2, step 2674/7134 completed (loss: 4.129026889801025, acc: 0.2469135820865631)
[2024-12-17 01:55:37,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,522][root][INFO] - Training Epoch: 1/2, step 2675/7134 completed (loss: 3.4920766353607178, acc: 0.31515151262283325)
[2024-12-17 01:55:37,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:37,879][root][INFO] - Training Epoch: 1/2, step 2676/7134 completed (loss: 3.651184320449829, acc: 0.3238636255264282)
[2024-12-17 01:55:37,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,253][root][INFO] - Training Epoch: 1/2, step 2677/7134 completed (loss: 3.3478734493255615, acc: 0.34355828166007996)
[2024-12-17 01:55:38,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:38,635][root][INFO] - Training Epoch: 1/2, step 2678/7134 completed (loss: 3.2847859859466553, acc: 0.38983049988746643)
[2024-12-17 01:55:38,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,008][root][INFO] - Training Epoch: 1/2, step 2679/7134 completed (loss: 3.56852388381958, acc: 0.29797980189323425)
[2024-12-17 01:55:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,374][root][INFO] - Training Epoch: 1/2, step 2680/7134 completed (loss: 3.7373697757720947, acc: 0.3186813294887543)
[2024-12-17 01:55:39,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:39,728][root][INFO] - Training Epoch: 1/2, step 2681/7134 completed (loss: 3.1490769386291504, acc: 0.39240506291389465)
[2024-12-17 01:55:39,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,075][root][INFO] - Training Epoch: 1/2, step 2682/7134 completed (loss: 3.617058515548706, acc: 0.30201342701911926)
[2024-12-17 01:55:40,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,417][root][INFO] - Training Epoch: 1/2, step 2683/7134 completed (loss: 3.804187536239624, acc: 0.33774834871292114)
[2024-12-17 01:55:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:40,768][root][INFO] - Training Epoch: 1/2, step 2684/7134 completed (loss: 4.007453918457031, acc: 0.328125)
[2024-12-17 01:55:40,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,140][root][INFO] - Training Epoch: 1/2, step 2685/7134 completed (loss: 4.017067909240723, acc: 0.2662721872329712)
[2024-12-17 01:55:41,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,521][root][INFO] - Training Epoch: 1/2, step 2686/7134 completed (loss: 3.7358627319335938, acc: 0.3199999928474426)
[2024-12-17 01:55:41,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:41,874][root][INFO] - Training Epoch: 1/2, step 2687/7134 completed (loss: 3.8610522747039795, acc: 0.36974790692329407)
[2024-12-17 01:55:41,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,230][root][INFO] - Training Epoch: 1/2, step 2688/7134 completed (loss: 4.360570430755615, acc: 0.29323309659957886)
[2024-12-17 01:55:42,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,551][root][INFO] - Training Epoch: 1/2, step 2689/7134 completed (loss: 3.6707417964935303, acc: 0.30894309282302856)
[2024-12-17 01:55:42,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:42,905][root][INFO] - Training Epoch: 1/2, step 2690/7134 completed (loss: 3.9387974739074707, acc: 0.3093525171279907)
[2024-12-17 01:55:43,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,246][root][INFO] - Training Epoch: 1/2, step 2691/7134 completed (loss: 4.071481227874756, acc: 0.2743362784385681)
[2024-12-17 01:55:43,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,606][root][INFO] - Training Epoch: 1/2, step 2692/7134 completed (loss: 4.128402233123779, acc: 0.28925618529319763)
[2024-12-17 01:55:43,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:43,946][root][INFO] - Training Epoch: 1/2, step 2693/7134 completed (loss: 3.8350870609283447, acc: 0.3539822995662689)
[2024-12-17 01:55:44,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,290][root][INFO] - Training Epoch: 1/2, step 2694/7134 completed (loss: 3.8627870082855225, acc: 0.3576158881187439)
[2024-12-17 01:55:44,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:44,663][root][INFO] - Training Epoch: 1/2, step 2695/7134 completed (loss: 3.4582161903381348, acc: 0.3333333432674408)
[2024-12-17 01:55:44,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,028][root][INFO] - Training Epoch: 1/2, step 2696/7134 completed (loss: 3.869211196899414, acc: 0.2571428716182709)
[2024-12-17 01:55:45,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,375][root][INFO] - Training Epoch: 1/2, step 2697/7134 completed (loss: 4.255043029785156, acc: 0.25974026322364807)
[2024-12-17 01:55:45,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:45,744][root][INFO] - Training Epoch: 1/2, step 2698/7134 completed (loss: 3.725304126739502, acc: 0.3333333432674408)
[2024-12-17 01:55:45,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,116][root][INFO] - Training Epoch: 1/2, step 2699/7134 completed (loss: 3.8629231452941895, acc: 0.3103448152542114)
[2024-12-17 01:55:46,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,433][root][INFO] - Training Epoch: 1/2, step 2700/7134 completed (loss: 4.496511936187744, acc: 0.24285714328289032)
[2024-12-17 01:55:46,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:46,770][root][INFO] - Training Epoch: 1/2, step 2701/7134 completed (loss: 3.919651985168457, acc: 0.2857142984867096)
[2024-12-17 01:55:46,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,064][root][INFO] - Training Epoch: 1/2, step 2702/7134 completed (loss: 3.8935961723327637, acc: 0.25925925374031067)
[2024-12-17 01:55:47,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,417][root][INFO] - Training Epoch: 1/2, step 2703/7134 completed (loss: 3.5555529594421387, acc: 0.3466666638851166)
[2024-12-17 01:55:47,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:47,789][root][INFO] - Training Epoch: 1/2, step 2704/7134 completed (loss: 3.8197929859161377, acc: 0.2738095223903656)
[2024-12-17 01:55:47,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,173][root][INFO] - Training Epoch: 1/2, step 2705/7134 completed (loss: 4.336026668548584, acc: 0.22535210847854614)
[2024-12-17 01:55:48,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,546][root][INFO] - Training Epoch: 1/2, step 2706/7134 completed (loss: 3.98258113861084, acc: 0.33561643958091736)
[2024-12-17 01:55:48,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:48,928][root][INFO] - Training Epoch: 1/2, step 2707/7134 completed (loss: 3.9334938526153564, acc: 0.3166666626930237)
[2024-12-17 01:55:49,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,310][root][INFO] - Training Epoch: 1/2, step 2708/7134 completed (loss: 4.364797115325928, acc: 0.2514285743236542)
[2024-12-17 01:55:49,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:49,699][root][INFO] - Training Epoch: 1/2, step 2709/7134 completed (loss: 3.737698793411255, acc: 0.2887323796749115)
[2024-12-17 01:55:49,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,059][root][INFO] - Training Epoch: 1/2, step 2710/7134 completed (loss: 3.738530158996582, acc: 0.3199999928474426)
[2024-12-17 01:55:50,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,417][root][INFO] - Training Epoch: 1/2, step 2711/7134 completed (loss: 3.673541307449341, acc: 0.27835050225257874)
[2024-12-17 01:55:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:50,784][root][INFO] - Training Epoch: 1/2, step 2712/7134 completed (loss: 4.088653087615967, acc: 0.26595744490623474)
[2024-12-17 01:55:50,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,162][root][INFO] - Training Epoch: 1/2, step 2713/7134 completed (loss: 3.7095584869384766, acc: 0.32499998807907104)
[2024-12-17 01:55:51,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,550][root][INFO] - Training Epoch: 1/2, step 2714/7134 completed (loss: 3.6471450328826904, acc: 0.31617647409439087)
[2024-12-17 01:55:51,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:51,938][root][INFO] - Training Epoch: 1/2, step 2715/7134 completed (loss: 4.026601791381836, acc: 0.32413792610168457)
[2024-12-17 01:55:52,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,314][root][INFO] - Training Epoch: 1/2, step 2716/7134 completed (loss: 3.757723808288574, acc: 0.3139534890651703)
[2024-12-17 01:55:52,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:52,671][root][INFO] - Training Epoch: 1/2, step 2717/7134 completed (loss: 4.301054000854492, acc: 0.28205129504203796)
[2024-12-17 01:55:52,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,066][root][INFO] - Training Epoch: 1/2, step 2718/7134 completed (loss: 3.6921205520629883, acc: 0.3402777910232544)
[2024-12-17 01:55:53,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,439][root][INFO] - Training Epoch: 1/2, step 2719/7134 completed (loss: 3.8880615234375, acc: 0.32374101877212524)
[2024-12-17 01:55:53,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:53,807][root][INFO] - Training Epoch: 1/2, step 2720/7134 completed (loss: 4.377601623535156, acc: 0.31386861205101013)
[2024-12-17 01:55:53,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,139][root][INFO] - Training Epoch: 1/2, step 2721/7134 completed (loss: 3.5943760871887207, acc: 0.33112582564353943)
[2024-12-17 01:55:54,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,439][root][INFO] - Training Epoch: 1/2, step 2722/7134 completed (loss: 4.241523742675781, acc: 0.27659574151039124)
[2024-12-17 01:55:54,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:54,790][root][INFO] - Training Epoch: 1/2, step 2723/7134 completed (loss: 3.943814754486084, acc: 0.269461065530777)
[2024-12-17 01:55:54,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,145][root][INFO] - Training Epoch: 1/2, step 2724/7134 completed (loss: 3.484095573425293, acc: 0.31073445081710815)
[2024-12-17 01:55:55,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,505][root][INFO] - Training Epoch: 1/2, step 2725/7134 completed (loss: 3.8663389682769775, acc: 0.2985074520111084)
[2024-12-17 01:55:55,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:55,863][root][INFO] - Training Epoch: 1/2, step 2726/7134 completed (loss: 3.967010974884033, acc: 0.26829269528388977)
[2024-12-17 01:55:55,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,251][root][INFO] - Training Epoch: 1/2, step 2727/7134 completed (loss: 4.286281585693359, acc: 0.2719298303127289)
[2024-12-17 01:55:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,613][root][INFO] - Training Epoch: 1/2, step 2728/7134 completed (loss: 4.316861152648926, acc: 0.32592591643333435)
[2024-12-17 01:55:56,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:56,983][root][INFO] - Training Epoch: 1/2, step 2729/7134 completed (loss: 4.2201619148254395, acc: 0.33571428060531616)
[2024-12-17 01:55:57,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,341][root][INFO] - Training Epoch: 1/2, step 2730/7134 completed (loss: 4.348152160644531, acc: 0.2654867172241211)
[2024-12-17 01:55:57,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:57,701][root][INFO] - Training Epoch: 1/2, step 2731/7134 completed (loss: 3.808759927749634, acc: 0.40776699781417847)
[2024-12-17 01:55:57,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,069][root][INFO] - Training Epoch: 1/2, step 2732/7134 completed (loss: 3.973841667175293, acc: 0.3186274468898773)
[2024-12-17 01:55:58,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,442][root][INFO] - Training Epoch: 1/2, step 2733/7134 completed (loss: 3.699951410293579, acc: 0.39444443583488464)
[2024-12-17 01:55:58,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:58,812][root][INFO] - Training Epoch: 1/2, step 2734/7134 completed (loss: 4.80056619644165, acc: 0.19834710657596588)
[2024-12-17 01:55:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,219][root][INFO] - Training Epoch: 1/2, step 2735/7134 completed (loss: 3.97752046585083, acc: 0.3109756112098694)
[2024-12-17 01:55:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,598][root][INFO] - Training Epoch: 1/2, step 2736/7134 completed (loss: 3.8972325325012207, acc: 0.3207547068595886)
[2024-12-17 01:55:59,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:55:59,955][root][INFO] - Training Epoch: 1/2, step 2737/7134 completed (loss: 3.7080447673797607, acc: 0.3499999940395355)
[2024-12-17 01:56:00,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,307][root][INFO] - Training Epoch: 1/2, step 2738/7134 completed (loss: 3.8344666957855225, acc: 0.35329341888427734)
[2024-12-17 01:56:00,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:00,671][root][INFO] - Training Epoch: 1/2, step 2739/7134 completed (loss: 4.2264227867126465, acc: 0.30434781312942505)
[2024-12-17 01:56:00,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,039][root][INFO] - Training Epoch: 1/2, step 2740/7134 completed (loss: 3.8255200386047363, acc: 0.36734694242477417)
[2024-12-17 01:56:01,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,385][root][INFO] - Training Epoch: 1/2, step 2741/7134 completed (loss: 2.9404332637786865, acc: 0.4137931168079376)
[2024-12-17 01:56:01,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:01,757][root][INFO] - Training Epoch: 1/2, step 2742/7134 completed (loss: 3.5350193977355957, acc: 0.36974790692329407)
[2024-12-17 01:56:01,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,101][root][INFO] - Training Epoch: 1/2, step 2743/7134 completed (loss: 3.1696553230285645, acc: 0.38297873735427856)
[2024-12-17 01:56:02,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,400][root][INFO] - Training Epoch: 1/2, step 2744/7134 completed (loss: 3.280968189239502, acc: 0.4032258093357086)
[2024-12-17 01:56:02,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:02,750][root][INFO] - Training Epoch: 1/2, step 2745/7134 completed (loss: 3.942758560180664, acc: 0.3154761791229248)
[2024-12-17 01:56:02,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,089][root][INFO] - Training Epoch: 1/2, step 2746/7134 completed (loss: 4.255561351776123, acc: 0.35227271914482117)
[2024-12-17 01:56:03,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,438][root][INFO] - Training Epoch: 1/2, step 2747/7134 completed (loss: 3.3517727851867676, acc: 0.4166666567325592)
[2024-12-17 01:56:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:03,749][root][INFO] - Training Epoch: 1/2, step 2748/7134 completed (loss: 3.2218587398529053, acc: 0.33766233921051025)
[2024-12-17 01:56:03,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,080][root][INFO] - Training Epoch: 1/2, step 2749/7134 completed (loss: 3.2888243198394775, acc: 0.3814432919025421)
[2024-12-17 01:56:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,442][root][INFO] - Training Epoch: 1/2, step 2750/7134 completed (loss: 3.0311334133148193, acc: 0.3734939694404602)
[2024-12-17 01:56:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:04,785][root][INFO] - Training Epoch: 1/2, step 2751/7134 completed (loss: 2.741560220718384, acc: 0.4864864945411682)
[2024-12-17 01:56:04,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,139][root][INFO] - Training Epoch: 1/2, step 2752/7134 completed (loss: 4.135340213775635, acc: 0.262773722410202)
[2024-12-17 01:56:05,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,496][root][INFO] - Training Epoch: 1/2, step 2753/7134 completed (loss: 3.653834581375122, acc: 0.3529411852359772)
[2024-12-17 01:56:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:05,865][root][INFO] - Training Epoch: 1/2, step 2754/7134 completed (loss: 3.737165927886963, acc: 0.375)
[2024-12-17 01:56:05,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,214][root][INFO] - Training Epoch: 1/2, step 2755/7134 completed (loss: 3.1501901149749756, acc: 0.3984375)
[2024-12-17 01:56:06,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,604][root][INFO] - Training Epoch: 1/2, step 2756/7134 completed (loss: 3.035536527633667, acc: 0.4189189076423645)
[2024-12-17 01:56:06,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:06,944][root][INFO] - Training Epoch: 1/2, step 2757/7134 completed (loss: 3.260948419570923, acc: 0.43478259444236755)
[2024-12-17 01:56:07,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,356][root][INFO] - Training Epoch: 1/2, step 2758/7134 completed (loss: 3.7332820892333984, acc: 0.3688524663448334)
[2024-12-17 01:56:07,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:07,750][root][INFO] - Training Epoch: 1/2, step 2759/7134 completed (loss: 3.8519370555877686, acc: 0.3571428656578064)
[2024-12-17 01:56:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,106][root][INFO] - Training Epoch: 1/2, step 2760/7134 completed (loss: 2.9986050128936768, acc: 0.41111111640930176)
[2024-12-17 01:56:08,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,467][root][INFO] - Training Epoch: 1/2, step 2761/7134 completed (loss: 4.834052085876465, acc: 0.21578946709632874)
[2024-12-17 01:56:08,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:08,842][root][INFO] - Training Epoch: 1/2, step 2762/7134 completed (loss: 4.072131156921387, acc: 0.2660098373889923)
[2024-12-17 01:56:08,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,208][root][INFO] - Training Epoch: 1/2, step 2763/7134 completed (loss: 4.3209052085876465, acc: 0.32786884903907776)
[2024-12-17 01:56:09,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,577][root][INFO] - Training Epoch: 1/2, step 2764/7134 completed (loss: 3.657456159591675, acc: 0.34375)
[2024-12-17 01:56:09,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:09,950][root][INFO] - Training Epoch: 1/2, step 2765/7134 completed (loss: 4.016608238220215, acc: 0.28823530673980713)
[2024-12-17 01:56:10,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,333][root][INFO] - Training Epoch: 1/2, step 2766/7134 completed (loss: 3.7557356357574463, acc: 0.331210196018219)
[2024-12-17 01:56:10,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:10,700][root][INFO] - Training Epoch: 1/2, step 2767/7134 completed (loss: 3.856466293334961, acc: 0.33500000834465027)
[2024-12-17 01:56:10,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,057][root][INFO] - Training Epoch: 1/2, step 2768/7134 completed (loss: 3.9385592937469482, acc: 0.3192771077156067)
[2024-12-17 01:56:11,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,422][root][INFO] - Training Epoch: 1/2, step 2769/7134 completed (loss: 3.7294678688049316, acc: 0.3105263113975525)
[2024-12-17 01:56:11,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:11,791][root][INFO] - Training Epoch: 1/2, step 2770/7134 completed (loss: 3.607614040374756, acc: 0.3086419701576233)
[2024-12-17 01:56:11,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,188][root][INFO] - Training Epoch: 1/2, step 2771/7134 completed (loss: 3.445352792739868, acc: 0.35545024275779724)
[2024-12-17 01:56:12,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,571][root][INFO] - Training Epoch: 1/2, step 2772/7134 completed (loss: 3.5489728450775146, acc: 0.4050000011920929)
[2024-12-17 01:56:12,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:12,947][root][INFO] - Training Epoch: 1/2, step 2773/7134 completed (loss: 3.6231017112731934, acc: 0.3065326511859894)
[2024-12-17 01:56:13,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,316][root][INFO] - Training Epoch: 1/2, step 2774/7134 completed (loss: 3.6709866523742676, acc: 0.31707316637039185)
[2024-12-17 01:56:13,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:13,678][root][INFO] - Training Epoch: 1/2, step 2775/7134 completed (loss: 3.8861637115478516, acc: 0.35519126057624817)
[2024-12-17 01:56:13,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,068][root][INFO] - Training Epoch: 1/2, step 2776/7134 completed (loss: 3.1170737743377686, acc: 0.380952388048172)
[2024-12-17 01:56:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,425][root][INFO] - Training Epoch: 1/2, step 2777/7134 completed (loss: 3.3889501094818115, acc: 0.3028571307659149)
[2024-12-17 01:56:14,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:14,806][root][INFO] - Training Epoch: 1/2, step 2778/7134 completed (loss: 3.472574472427368, acc: 0.33838382363319397)
[2024-12-17 01:56:14,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,186][root][INFO] - Training Epoch: 1/2, step 2779/7134 completed (loss: 3.3961117267608643, acc: 0.3835616409778595)
[2024-12-17 01:56:15,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:15,595][root][INFO] - Training Epoch: 1/2, step 2780/7134 completed (loss: 3.9914674758911133, acc: 0.3053097426891327)
[2024-12-17 01:56:15,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,010][root][INFO] - Training Epoch: 1/2, step 2781/7134 completed (loss: 4.064284324645996, acc: 0.28804346919059753)
[2024-12-17 01:56:16,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,410][root][INFO] - Training Epoch: 1/2, step 2782/7134 completed (loss: 3.4459891319274902, acc: 0.3616071343421936)
[2024-12-17 01:56:16,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:16,786][root][INFO] - Training Epoch: 1/2, step 2783/7134 completed (loss: 3.758648633956909, acc: 0.30612245202064514)
[2024-12-17 01:56:16,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,183][root][INFO] - Training Epoch: 1/2, step 2784/7134 completed (loss: 3.3122050762176514, acc: 0.36231884360313416)
[2024-12-17 01:56:17,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,569][root][INFO] - Training Epoch: 1/2, step 2785/7134 completed (loss: 3.272871255874634, acc: 0.35922330617904663)
[2024-12-17 01:56:17,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:17,942][root][INFO] - Training Epoch: 1/2, step 2786/7134 completed (loss: 3.5981974601745605, acc: 0.36444443464279175)
[2024-12-17 01:56:18,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,332][root][INFO] - Training Epoch: 1/2, step 2787/7134 completed (loss: 3.2988955974578857, acc: 0.39306357502937317)
[2024-12-17 01:56:18,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:18,746][root][INFO] - Training Epoch: 1/2, step 2788/7134 completed (loss: 4.572848320007324, acc: 0.24840764701366425)
[2024-12-17 01:56:18,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,125][root][INFO] - Training Epoch: 1/2, step 2789/7134 completed (loss: 4.991762638092041, acc: 0.2571428716182709)
[2024-12-17 01:56:19,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,504][root][INFO] - Training Epoch: 1/2, step 2790/7134 completed (loss: 4.616724967956543, acc: 0.25833332538604736)
[2024-12-17 01:56:19,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:19,890][root][INFO] - Training Epoch: 1/2, step 2791/7134 completed (loss: 4.335404872894287, acc: 0.26490065455436707)
[2024-12-17 01:56:19,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,269][root][INFO] - Training Epoch: 1/2, step 2792/7134 completed (loss: 4.12561559677124, acc: 0.26744186878204346)
[2024-12-17 01:56:20,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:20,677][root][INFO] - Training Epoch: 1/2, step 2793/7134 completed (loss: 4.08647346496582, acc: 0.31137725710868835)
[2024-12-17 01:56:20,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,064][root][INFO] - Training Epoch: 1/2, step 2794/7134 completed (loss: 3.715378999710083, acc: 0.24242424964904785)
[2024-12-17 01:56:21,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,433][root][INFO] - Training Epoch: 1/2, step 2795/7134 completed (loss: 3.7665679454803467, acc: 0.3055555522441864)
[2024-12-17 01:56:21,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:21,776][root][INFO] - Training Epoch: 1/2, step 2796/7134 completed (loss: 3.7507922649383545, acc: 0.23577235639095306)
[2024-12-17 01:56:21,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,102][root][INFO] - Training Epoch: 1/2, step 2797/7134 completed (loss: 3.980424404144287, acc: 0.3414634168148041)
[2024-12-17 01:56:22,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,511][root][INFO] - Training Epoch: 1/2, step 2798/7134 completed (loss: 3.8790619373321533, acc: 0.23333333432674408)
[2024-12-17 01:56:22,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:22,894][root][INFO] - Training Epoch: 1/2, step 2799/7134 completed (loss: 4.00739049911499, acc: 0.296875)
[2024-12-17 01:56:22,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,233][root][INFO] - Training Epoch: 1/2, step 2800/7134 completed (loss: 4.077592849731445, acc: 0.30656933784484863)
[2024-12-17 01:56:23,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:23,662][root][INFO] - Training Epoch: 1/2, step 2801/7134 completed (loss: 4.041203498840332, acc: 0.3060109317302704)
[2024-12-17 01:56:23,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,069][root][INFO] - Training Epoch: 1/2, step 2802/7134 completed (loss: 4.212227821350098, acc: 0.3316583037376404)
[2024-12-17 01:56:24,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,517][root][INFO] - Training Epoch: 1/2, step 2803/7134 completed (loss: 3.872941732406616, acc: 0.3086419701576233)
[2024-12-17 01:56:24,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:24,943][root][INFO] - Training Epoch: 1/2, step 2804/7134 completed (loss: 4.46966552734375, acc: 0.2543352544307709)
[2024-12-17 01:56:25,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,335][root][INFO] - Training Epoch: 1/2, step 2805/7134 completed (loss: 4.529996871948242, acc: 0.2383720874786377)
[2024-12-17 01:56:25,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:25,715][root][INFO] - Training Epoch: 1/2, step 2806/7134 completed (loss: 3.696593999862671, acc: 0.40441176295280457)
[2024-12-17 01:56:25,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,103][root][INFO] - Training Epoch: 1/2, step 2807/7134 completed (loss: 3.566495180130005, acc: 0.27184465527534485)
[2024-12-17 01:56:26,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,488][root][INFO] - Training Epoch: 1/2, step 2808/7134 completed (loss: 3.5682713985443115, acc: 0.35175880789756775)
[2024-12-17 01:56:26,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:26,889][root][INFO] - Training Epoch: 1/2, step 2809/7134 completed (loss: 3.9685075283050537, acc: 0.29133859276771545)
[2024-12-17 01:56:27,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,288][root][INFO] - Training Epoch: 1/2, step 2810/7134 completed (loss: 3.67472505569458, acc: 0.2677595615386963)
[2024-12-17 01:56:27,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:27,689][root][INFO] - Training Epoch: 1/2, step 2811/7134 completed (loss: 3.5600664615631104, acc: 0.3535911738872528)
[2024-12-17 01:56:27,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,072][root][INFO] - Training Epoch: 1/2, step 2812/7134 completed (loss: 3.2864999771118164, acc: 0.3642384111881256)
[2024-12-17 01:56:28,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,466][root][INFO] - Training Epoch: 1/2, step 2813/7134 completed (loss: 3.4140686988830566, acc: 0.37931033968925476)
[2024-12-17 01:56:28,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:28,899][root][INFO] - Training Epoch: 1/2, step 2814/7134 completed (loss: 3.738445520401001, acc: 0.302325576543808)
[2024-12-17 01:56:29,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,273][root][INFO] - Training Epoch: 1/2, step 2815/7134 completed (loss: 3.4752438068389893, acc: 0.3681318759918213)
[2024-12-17 01:56:29,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:29,686][root][INFO] - Training Epoch: 1/2, step 2816/7134 completed (loss: 3.6632511615753174, acc: 0.32679739594459534)
[2024-12-17 01:56:29,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,122][root][INFO] - Training Epoch: 1/2, step 2817/7134 completed (loss: 3.5924220085144043, acc: 0.3502538204193115)
[2024-12-17 01:56:30,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,515][root][INFO] - Training Epoch: 1/2, step 2818/7134 completed (loss: 3.84112548828125, acc: 0.3191489279270172)
[2024-12-17 01:56:30,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:30,933][root][INFO] - Training Epoch: 1/2, step 2819/7134 completed (loss: 3.47690486907959, acc: 0.33561643958091736)
[2024-12-17 01:56:31,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,309][root][INFO] - Training Epoch: 1/2, step 2820/7134 completed (loss: 3.5569088459014893, acc: 0.349693238735199)
[2024-12-17 01:56:31,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:31,708][root][INFO] - Training Epoch: 1/2, step 2821/7134 completed (loss: 3.894359588623047, acc: 0.3575129508972168)
[2024-12-17 01:56:31,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,076][root][INFO] - Training Epoch: 1/2, step 2822/7134 completed (loss: 3.893871307373047, acc: 0.2918919026851654)
[2024-12-17 01:56:32,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,485][root][INFO] - Training Epoch: 1/2, step 2823/7134 completed (loss: 3.986218214035034, acc: 0.3105590045452118)
[2024-12-17 01:56:32,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:32,867][root][INFO] - Training Epoch: 1/2, step 2824/7134 completed (loss: 4.378276824951172, acc: 0.30817610025405884)
[2024-12-17 01:56:32,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,235][root][INFO] - Training Epoch: 1/2, step 2825/7134 completed (loss: 4.038554668426514, acc: 0.24444444477558136)
[2024-12-17 01:56:33,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,610][root][INFO] - Training Epoch: 1/2, step 2826/7134 completed (loss: 3.711529493331909, acc: 0.3448275923728943)
[2024-12-17 01:56:33,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:33,979][root][INFO] - Training Epoch: 1/2, step 2827/7134 completed (loss: 3.5878994464874268, acc: 0.3014354109764099)
[2024-12-17 01:56:34,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,354][root][INFO] - Training Epoch: 1/2, step 2828/7134 completed (loss: 4.090928554534912, acc: 0.2721518874168396)
[2024-12-17 01:56:34,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:34,749][root][INFO] - Training Epoch: 1/2, step 2829/7134 completed (loss: 3.8612775802612305, acc: 0.2976190447807312)
[2024-12-17 01:56:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,145][root][INFO] - Training Epoch: 1/2, step 2830/7134 completed (loss: 3.611388921737671, acc: 0.28358209133148193)
[2024-12-17 01:56:35,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,515][root][INFO] - Training Epoch: 1/2, step 2831/7134 completed (loss: 3.736525774002075, acc: 0.23648647964000702)
[2024-12-17 01:56:35,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:35,923][root][INFO] - Training Epoch: 1/2, step 2832/7134 completed (loss: 3.5046820640563965, acc: 0.34408602118492126)
[2024-12-17 01:56:36,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,311][root][INFO] - Training Epoch: 1/2, step 2833/7134 completed (loss: 3.6152870655059814, acc: 0.33862432837486267)
[2024-12-17 01:56:36,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:36,696][root][INFO] - Training Epoch: 1/2, step 2834/7134 completed (loss: 4.107188701629639, acc: 0.30000001192092896)
[2024-12-17 01:56:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,069][root][INFO] - Training Epoch: 1/2, step 2835/7134 completed (loss: 3.733349084854126, acc: 0.2697368562221527)
[2024-12-17 01:56:37,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,464][root][INFO] - Training Epoch: 1/2, step 2836/7134 completed (loss: 3.893270254135132, acc: 0.27000001072883606)
[2024-12-17 01:56:37,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:37,838][root][INFO] - Training Epoch: 1/2, step 2837/7134 completed (loss: 3.9707109928131104, acc: 0.2631579041481018)
[2024-12-17 01:56:37,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,237][root][INFO] - Training Epoch: 1/2, step 2838/7134 completed (loss: 3.935080051422119, acc: 0.32019704580307007)
[2024-12-17 01:56:38,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:38,600][root][INFO] - Training Epoch: 1/2, step 2839/7134 completed (loss: 4.1893486976623535, acc: 0.2761194109916687)
[2024-12-17 01:56:38,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,042][root][INFO] - Training Epoch: 1/2, step 2840/7134 completed (loss: 3.6220386028289795, acc: 0.364705890417099)
[2024-12-17 01:56:39,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,433][root][INFO] - Training Epoch: 1/2, step 2841/7134 completed (loss: 4.235752582550049, acc: 0.2075471729040146)
[2024-12-17 01:56:39,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:39,837][root][INFO] - Training Epoch: 1/2, step 2842/7134 completed (loss: 3.6859958171844482, acc: 0.2916666567325592)
[2024-12-17 01:56:39,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,227][root][INFO] - Training Epoch: 1/2, step 2843/7134 completed (loss: 4.289017200469971, acc: 0.28930819034576416)
[2024-12-17 01:56:40,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,621][root][INFO] - Training Epoch: 1/2, step 2844/7134 completed (loss: 4.055319786071777, acc: 0.32065218687057495)
[2024-12-17 01:56:40,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:40,990][root][INFO] - Training Epoch: 1/2, step 2845/7134 completed (loss: 3.7451064586639404, acc: 0.3378378450870514)
[2024-12-17 01:56:41,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,373][root][INFO] - Training Epoch: 1/2, step 2846/7134 completed (loss: 4.059171199798584, acc: 0.29411765933036804)
[2024-12-17 01:56:41,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:41,772][root][INFO] - Training Epoch: 1/2, step 2847/7134 completed (loss: 4.343044757843018, acc: 0.2802547812461853)
[2024-12-17 01:56:41,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,132][root][INFO] - Training Epoch: 1/2, step 2848/7134 completed (loss: 4.152458667755127, acc: 0.3211009204387665)
[2024-12-17 01:56:42,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,500][root][INFO] - Training Epoch: 1/2, step 2849/7134 completed (loss: 3.4444730281829834, acc: 0.36571428179740906)
[2024-12-17 01:56:42,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:42,890][root][INFO] - Training Epoch: 1/2, step 2850/7134 completed (loss: 3.8678250312805176, acc: 0.24786324799060822)
[2024-12-17 01:56:43,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,298][root][INFO] - Training Epoch: 1/2, step 2851/7134 completed (loss: 3.85870361328125, acc: 0.3185185194015503)
[2024-12-17 01:56:43,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:43,667][root][INFO] - Training Epoch: 1/2, step 2852/7134 completed (loss: 4.172123908996582, acc: 0.3008130192756653)
[2024-12-17 01:56:43,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,027][root][INFO] - Training Epoch: 1/2, step 2853/7134 completed (loss: 3.725903034210205, acc: 0.33673468232154846)
[2024-12-17 01:56:44,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,426][root][INFO] - Training Epoch: 1/2, step 2854/7134 completed (loss: 4.071386337280273, acc: 0.2925170063972473)
[2024-12-17 01:56:44,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:44,817][root][INFO] - Training Epoch: 1/2, step 2855/7134 completed (loss: 3.762383222579956, acc: 0.31081080436706543)
[2024-12-17 01:56:44,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,234][root][INFO] - Training Epoch: 1/2, step 2856/7134 completed (loss: 3.819392442703247, acc: 0.2732919156551361)
[2024-12-17 01:56:45,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:45,641][root][INFO] - Training Epoch: 1/2, step 2857/7134 completed (loss: 3.984339475631714, acc: 0.27544909715652466)
[2024-12-17 01:56:45,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,009][root][INFO] - Training Epoch: 1/2, step 2858/7134 completed (loss: 4.133765697479248, acc: 0.280303031206131)
[2024-12-17 01:56:46,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,395][root][INFO] - Training Epoch: 1/2, step 2859/7134 completed (loss: 3.909052610397339, acc: 0.3273809552192688)
[2024-12-17 01:56:46,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:46,770][root][INFO] - Training Epoch: 1/2, step 2860/7134 completed (loss: 4.176290988922119, acc: 0.3125)
[2024-12-17 01:56:46,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,172][root][INFO] - Training Epoch: 1/2, step 2861/7134 completed (loss: 4.054546356201172, acc: 0.3035714328289032)
[2024-12-17 01:56:47,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,556][root][INFO] - Training Epoch: 1/2, step 2862/7134 completed (loss: 4.5104475021362305, acc: 0.25563910603523254)
[2024-12-17 01:56:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:47,958][root][INFO] - Training Epoch: 1/2, step 2863/7134 completed (loss: 3.737661361694336, acc: 0.3038673996925354)
[2024-12-17 01:56:48,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,321][root][INFO] - Training Epoch: 1/2, step 2864/7134 completed (loss: 3.656329870223999, acc: 0.3263157904148102)
[2024-12-17 01:56:48,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:48,765][root][INFO] - Training Epoch: 1/2, step 2865/7134 completed (loss: 3.5038022994995117, acc: 0.38260868191719055)
[2024-12-17 01:56:48,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,175][root][INFO] - Training Epoch: 1/2, step 2866/7134 completed (loss: 3.7532927989959717, acc: 0.3032258152961731)
[2024-12-17 01:56:49,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,565][root][INFO] - Training Epoch: 1/2, step 2867/7134 completed (loss: 4.079793930053711, acc: 0.25925925374031067)
[2024-12-17 01:56:49,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:49,941][root][INFO] - Training Epoch: 1/2, step 2868/7134 completed (loss: 3.657282590866089, acc: 0.23529411852359772)
[2024-12-17 01:56:50,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,299][root][INFO] - Training Epoch: 1/2, step 2869/7134 completed (loss: 3.649773597717285, acc: 0.30344828963279724)
[2024-12-17 01:56:50,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:50,671][root][INFO] - Training Epoch: 1/2, step 2870/7134 completed (loss: 3.6540799140930176, acc: 0.34545454382896423)
[2024-12-17 01:56:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,030][root][INFO] - Training Epoch: 1/2, step 2871/7134 completed (loss: 3.887143135070801, acc: 0.2620689570903778)
[2024-12-17 01:56:51,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,401][root][INFO] - Training Epoch: 1/2, step 2872/7134 completed (loss: 3.8409132957458496, acc: 0.32743361592292786)
[2024-12-17 01:56:51,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:51,808][root][INFO] - Training Epoch: 1/2, step 2873/7134 completed (loss: 3.7397713661193848, acc: 0.3333333432674408)
[2024-12-17 01:56:51,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,180][root][INFO] - Training Epoch: 1/2, step 2874/7134 completed (loss: 3.57488751411438, acc: 0.3402777910232544)
[2024-12-17 01:56:52,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,567][root][INFO] - Training Epoch: 1/2, step 2875/7134 completed (loss: 3.528285026550293, acc: 0.3452380895614624)
[2024-12-17 01:56:52,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:52,943][root][INFO] - Training Epoch: 1/2, step 2876/7134 completed (loss: 3.8495166301727295, acc: 0.3207547068595886)
[2024-12-17 01:56:53,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,310][root][INFO] - Training Epoch: 1/2, step 2877/7134 completed (loss: 3.4688215255737305, acc: 0.3760683834552765)
[2024-12-17 01:56:53,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:53,679][root][INFO] - Training Epoch: 1/2, step 2878/7134 completed (loss: 3.674077033996582, acc: 0.3070175349712372)
[2024-12-17 01:56:53,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,034][root][INFO] - Training Epoch: 1/2, step 2879/7134 completed (loss: 3.9764392375946045, acc: 0.2789115607738495)
[2024-12-17 01:56:54,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,401][root][INFO] - Training Epoch: 1/2, step 2880/7134 completed (loss: 3.8489973545074463, acc: 0.2876712381839752)
[2024-12-17 01:56:54,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:54,744][root][INFO] - Training Epoch: 1/2, step 2881/7134 completed (loss: 3.924583673477173, acc: 0.30158731341362)
[2024-12-17 01:56:54,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,131][root][INFO] - Training Epoch: 1/2, step 2882/7134 completed (loss: 3.950038433074951, acc: 0.323699414730072)
[2024-12-17 01:56:55,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,497][root][INFO] - Training Epoch: 1/2, step 2883/7134 completed (loss: 4.553221702575684, acc: 0.2634730637073517)
[2024-12-17 01:56:55,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:55,850][root][INFO] - Training Epoch: 1/2, step 2884/7134 completed (loss: 4.584799289703369, acc: 0.2242424190044403)
[2024-12-17 01:56:55,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,201][root][INFO] - Training Epoch: 1/2, step 2885/7134 completed (loss: 5.3065972328186035, acc: 0.17575757205486298)
[2024-12-17 01:56:56,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,547][root][INFO] - Training Epoch: 1/2, step 2886/7134 completed (loss: 4.2968549728393555, acc: 0.30000001192092896)
[2024-12-17 01:56:56,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:56,928][root][INFO] - Training Epoch: 1/2, step 2887/7134 completed (loss: 4.0730719566345215, acc: 0.3013100326061249)
[2024-12-17 01:56:57,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,306][root][INFO] - Training Epoch: 1/2, step 2888/7134 completed (loss: 3.9411463737487793, acc: 0.30000001192092896)
[2024-12-17 01:56:57,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:57,690][root][INFO] - Training Epoch: 1/2, step 2889/7134 completed (loss: 4.413845062255859, acc: 0.22905027866363525)
[2024-12-17 01:56:57,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,063][root][INFO] - Training Epoch: 1/2, step 2890/7134 completed (loss: 3.727128505706787, acc: 0.28205129504203796)
[2024-12-17 01:56:58,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,430][root][INFO] - Training Epoch: 1/2, step 2891/7134 completed (loss: 4.255416393280029, acc: 0.2666666805744171)
[2024-12-17 01:56:58,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:58,805][root][INFO] - Training Epoch: 1/2, step 2892/7134 completed (loss: 4.081417083740234, acc: 0.2958579957485199)
[2024-12-17 01:56:58,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,194][root][INFO] - Training Epoch: 1/2, step 2893/7134 completed (loss: 4.210940361022949, acc: 0.2950819730758667)
[2024-12-17 01:56:59,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,570][root][INFO] - Training Epoch: 1/2, step 2894/7134 completed (loss: 4.4264116287231445, acc: 0.25925925374031067)
[2024-12-17 01:56:59,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:56:59,912][root][INFO] - Training Epoch: 1/2, step 2895/7134 completed (loss: 4.188509464263916, acc: 0.29661017656326294)
[2024-12-17 01:57:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,282][root][INFO] - Training Epoch: 1/2, step 2896/7134 completed (loss: 4.513672828674316, acc: 0.21556885540485382)
[2024-12-17 01:57:00,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,652][root][INFO] - Training Epoch: 1/2, step 2897/7134 completed (loss: 4.51782751083374, acc: 0.25563910603523254)
[2024-12-17 01:57:00,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:00,989][root][INFO] - Training Epoch: 1/2, step 2898/7134 completed (loss: 3.677110195159912, acc: 0.260869562625885)
[2024-12-17 01:57:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,346][root][INFO] - Training Epoch: 1/2, step 2899/7134 completed (loss: 3.8398945331573486, acc: 0.3353293538093567)
[2024-12-17 01:57:01,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:01,717][root][INFO] - Training Epoch: 1/2, step 2900/7134 completed (loss: 3.8030123710632324, acc: 0.2819148898124695)
[2024-12-17 01:57:01,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,086][root][INFO] - Training Epoch: 1/2, step 2901/7134 completed (loss: 3.881025552749634, acc: 0.2702702581882477)
[2024-12-17 01:57:02,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,445][root][INFO] - Training Epoch: 1/2, step 2902/7134 completed (loss: 4.193508625030518, acc: 0.28205129504203796)
[2024-12-17 01:57:02,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:02,811][root][INFO] - Training Epoch: 1/2, step 2903/7134 completed (loss: 3.7984299659729004, acc: 0.2977527976036072)
[2024-12-17 01:57:02,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,168][root][INFO] - Training Epoch: 1/2, step 2904/7134 completed (loss: 3.6669180393218994, acc: 0.2864864766597748)
[2024-12-17 01:57:03,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,535][root][INFO] - Training Epoch: 1/2, step 2905/7134 completed (loss: 4.156601905822754, acc: 0.2032085508108139)
[2024-12-17 01:57:03,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:03,910][root][INFO] - Training Epoch: 1/2, step 2906/7134 completed (loss: 4.2360053062438965, acc: 0.2408376932144165)
[2024-12-17 01:57:04,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,282][root][INFO] - Training Epoch: 1/2, step 2907/7134 completed (loss: 4.3449296951293945, acc: 0.227544903755188)
[2024-12-17 01:57:04,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:04,650][root][INFO] - Training Epoch: 1/2, step 2908/7134 completed (loss: 3.7248833179473877, acc: 0.2816092073917389)
[2024-12-17 01:57:04,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,035][root][INFO] - Training Epoch: 1/2, step 2909/7134 completed (loss: 3.7713422775268555, acc: 0.30054643750190735)
[2024-12-17 01:57:05,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,391][root][INFO] - Training Epoch: 1/2, step 2910/7134 completed (loss: 3.99503493309021, acc: 0.30481284856796265)
[2024-12-17 01:57:05,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:05,768][root][INFO] - Training Epoch: 1/2, step 2911/7134 completed (loss: 3.8075528144836426, acc: 0.37062937021255493)
[2024-12-17 01:57:05,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,146][root][INFO] - Training Epoch: 1/2, step 2912/7134 completed (loss: 3.8383405208587646, acc: 0.3219178020954132)
[2024-12-17 01:57:06,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,511][root][INFO] - Training Epoch: 1/2, step 2913/7134 completed (loss: 3.957993745803833, acc: 0.30215826630592346)
[2024-12-17 01:57:06,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:06,889][root][INFO] - Training Epoch: 1/2, step 2914/7134 completed (loss: 3.9267311096191406, acc: 0.35757574439048767)
[2024-12-17 01:57:06,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,249][root][INFO] - Training Epoch: 1/2, step 2915/7134 completed (loss: 4.116976261138916, acc: 0.27586206793785095)
[2024-12-17 01:57:07,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,601][root][INFO] - Training Epoch: 1/2, step 2916/7134 completed (loss: 3.8457090854644775, acc: 0.2631579041481018)
[2024-12-17 01:57:07,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:07,966][root][INFO] - Training Epoch: 1/2, step 2917/7134 completed (loss: 3.676692247390747, acc: 0.31578946113586426)
[2024-12-17 01:57:08,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,323][root][INFO] - Training Epoch: 1/2, step 2918/7134 completed (loss: 3.4971530437469482, acc: 0.3801169693470001)
[2024-12-17 01:57:08,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:08,698][root][INFO] - Training Epoch: 1/2, step 2919/7134 completed (loss: 3.718653678894043, acc: 0.3313252925872803)
[2024-12-17 01:57:08,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,081][root][INFO] - Training Epoch: 1/2, step 2920/7134 completed (loss: 3.713357448577881, acc: 0.31446540355682373)
[2024-12-17 01:57:09,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,438][root][INFO] - Training Epoch: 1/2, step 2921/7134 completed (loss: 4.240122318267822, acc: 0.2857142984867096)
[2024-12-17 01:57:09,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:09,789][root][INFO] - Training Epoch: 1/2, step 2922/7134 completed (loss: 4.3179192543029785, acc: 0.3128834366798401)
[2024-12-17 01:57:09,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,164][root][INFO] - Training Epoch: 1/2, step 2923/7134 completed (loss: 3.9631400108337402, acc: 0.30985915660858154)
[2024-12-17 01:57:10,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,528][root][INFO] - Training Epoch: 1/2, step 2924/7134 completed (loss: 3.851517915725708, acc: 0.2926829159259796)
[2024-12-17 01:57:10,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:10,914][root][INFO] - Training Epoch: 1/2, step 2925/7134 completed (loss: 3.3970768451690674, acc: 0.38823530077934265)
[2024-12-17 01:57:11,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,289][root][INFO] - Training Epoch: 1/2, step 2926/7134 completed (loss: 3.640068292617798, acc: 0.3668341636657715)
[2024-12-17 01:57:11,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:11,666][root][INFO] - Training Epoch: 1/2, step 2927/7134 completed (loss: 4.049644470214844, acc: 0.2658959627151489)
[2024-12-17 01:57:11,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,039][root][INFO] - Training Epoch: 1/2, step 2928/7134 completed (loss: 3.683429718017578, acc: 0.3541666567325592)
[2024-12-17 01:57:12,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,436][root][INFO] - Training Epoch: 1/2, step 2929/7134 completed (loss: 3.818882465362549, acc: 0.3511904776096344)
[2024-12-17 01:57:12,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:12,804][root][INFO] - Training Epoch: 1/2, step 2930/7134 completed (loss: 3.6161141395568848, acc: 0.3401360511779785)
[2024-12-17 01:57:12,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,165][root][INFO] - Training Epoch: 1/2, step 2931/7134 completed (loss: 3.719270706176758, acc: 0.3333333432674408)
[2024-12-17 01:57:13,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,515][root][INFO] - Training Epoch: 1/2, step 2932/7134 completed (loss: 3.8540420532226562, acc: 0.28877004981040955)
[2024-12-17 01:57:13,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:13,888][root][INFO] - Training Epoch: 1/2, step 2933/7134 completed (loss: 4.15670108795166, acc: 0.2700729966163635)
[2024-12-17 01:57:13,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,273][root][INFO] - Training Epoch: 1/2, step 2934/7134 completed (loss: 3.691826105117798, acc: 0.33571428060531616)
[2024-12-17 01:57:14,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:14,635][root][INFO] - Training Epoch: 1/2, step 2935/7134 completed (loss: 3.8527140617370605, acc: 0.3174603283405304)
[2024-12-17 01:57:14,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,047][root][INFO] - Training Epoch: 1/2, step 2936/7134 completed (loss: 3.6181130409240723, acc: 0.3539822995662689)
[2024-12-17 01:57:15,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,410][root][INFO] - Training Epoch: 1/2, step 2937/7134 completed (loss: 4.303063869476318, acc: 0.27941176295280457)
[2024-12-17 01:57:15,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:15,793][root][INFO] - Training Epoch: 1/2, step 2938/7134 completed (loss: 3.9961471557617188, acc: 0.25136610865592957)
[2024-12-17 01:57:15,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,152][root][INFO] - Training Epoch: 1/2, step 2939/7134 completed (loss: 4.437145233154297, acc: 0.2384105920791626)
[2024-12-17 01:57:16,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,529][root][INFO] - Training Epoch: 1/2, step 2940/7134 completed (loss: 4.435781478881836, acc: 0.2295081913471222)
[2024-12-17 01:57:16,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:16,907][root][INFO] - Training Epoch: 1/2, step 2941/7134 completed (loss: 4.4751691818237305, acc: 0.26966291666030884)
[2024-12-17 01:57:16,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,250][root][INFO] - Training Epoch: 1/2, step 2942/7134 completed (loss: 4.483306884765625, acc: 0.2545454502105713)
[2024-12-17 01:57:17,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,612][root][INFO] - Training Epoch: 1/2, step 2943/7134 completed (loss: 4.41826057434082, acc: 0.28378379344940186)
[2024-12-17 01:57:17,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:17,977][root][INFO] - Training Epoch: 1/2, step 2944/7134 completed (loss: 4.142495632171631, acc: 0.28915661573410034)
[2024-12-17 01:57:18,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,344][root][INFO] - Training Epoch: 1/2, step 2945/7134 completed (loss: 3.9849817752838135, acc: 0.3221476376056671)
[2024-12-17 01:57:18,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:18,707][root][INFO] - Training Epoch: 1/2, step 2946/7134 completed (loss: 3.985954761505127, acc: 0.3086419701576233)
[2024-12-17 01:57:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,075][root][INFO] - Training Epoch: 1/2, step 2947/7134 completed (loss: 4.251799583435059, acc: 0.2750000059604645)
[2024-12-17 01:57:19,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,435][root][INFO] - Training Epoch: 1/2, step 2948/7134 completed (loss: 4.055102825164795, acc: 0.3055555522441864)
[2024-12-17 01:57:19,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:19,781][root][INFO] - Training Epoch: 1/2, step 2949/7134 completed (loss: 3.893819570541382, acc: 0.2549019753932953)
[2024-12-17 01:57:19,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,162][root][INFO] - Training Epoch: 1/2, step 2950/7134 completed (loss: 3.7274274826049805, acc: 0.3296089470386505)
[2024-12-17 01:57:20,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,527][root][INFO] - Training Epoch: 1/2, step 2951/7134 completed (loss: 3.8780105113983154, acc: 0.30434781312942505)
[2024-12-17 01:57:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:20,891][root][INFO] - Training Epoch: 1/2, step 2952/7134 completed (loss: 4.305087566375732, acc: 0.2165605127811432)
[2024-12-17 01:57:20,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,237][root][INFO] - Training Epoch: 1/2, step 2953/7134 completed (loss: 4.115911483764648, acc: 0.29931971430778503)
[2024-12-17 01:57:21,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,603][root][INFO] - Training Epoch: 1/2, step 2954/7134 completed (loss: 3.7247414588928223, acc: 0.3350515365600586)
[2024-12-17 01:57:21,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:21,947][root][INFO] - Training Epoch: 1/2, step 2955/7134 completed (loss: 3.9474520683288574, acc: 0.27878788113594055)
[2024-12-17 01:57:22,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,362][root][INFO] - Training Epoch: 1/2, step 2956/7134 completed (loss: 3.637803077697754, acc: 0.2822085916996002)
[2024-12-17 01:57:22,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:22,739][root][INFO] - Training Epoch: 1/2, step 2957/7134 completed (loss: 4.007669925689697, acc: 0.2816092073917389)
[2024-12-17 01:57:22,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,099][root][INFO] - Training Epoch: 1/2, step 2958/7134 completed (loss: 3.7119359970092773, acc: 0.3194444477558136)
[2024-12-17 01:57:23,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,462][root][INFO] - Training Epoch: 1/2, step 2959/7134 completed (loss: 4.057950019836426, acc: 0.2531645596027374)
[2024-12-17 01:57:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:23,832][root][INFO] - Training Epoch: 1/2, step 2960/7134 completed (loss: 3.95060133934021, acc: 0.29120880365371704)
[2024-12-17 01:57:23,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,218][root][INFO] - Training Epoch: 1/2, step 2961/7134 completed (loss: 3.549647569656372, acc: 0.371257483959198)
[2024-12-17 01:57:24,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,582][root][INFO] - Training Epoch: 1/2, step 2962/7134 completed (loss: 3.742908239364624, acc: 0.3452380895614624)
[2024-12-17 01:57:24,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:24,959][root][INFO] - Training Epoch: 1/2, step 2963/7134 completed (loss: 3.7457869052886963, acc: 0.3016759753227234)
[2024-12-17 01:57:25,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,322][root][INFO] - Training Epoch: 1/2, step 2964/7134 completed (loss: 3.8344180583953857, acc: 0.30666667222976685)
[2024-12-17 01:57:25,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:25,684][root][INFO] - Training Epoch: 1/2, step 2965/7134 completed (loss: 4.079871654510498, acc: 0.28977271914482117)
[2024-12-17 01:57:25,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,047][root][INFO] - Training Epoch: 1/2, step 2966/7134 completed (loss: 3.627244472503662, acc: 0.3076923191547394)
[2024-12-17 01:57:26,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,412][root][INFO] - Training Epoch: 1/2, step 2967/7134 completed (loss: 4.258474349975586, acc: 0.28961747884750366)
[2024-12-17 01:57:26,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:26,826][root][INFO] - Training Epoch: 1/2, step 2968/7134 completed (loss: 4.940308570861816, acc: 0.21250000596046448)
[2024-12-17 01:57:26,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,177][root][INFO] - Training Epoch: 1/2, step 2969/7134 completed (loss: 4.8670220375061035, acc: 0.21359223127365112)
[2024-12-17 01:57:27,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,556][root][INFO] - Training Epoch: 1/2, step 2970/7134 completed (loss: 5.114563941955566, acc: 0.24626865983009338)
[2024-12-17 01:57:27,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:27,973][root][INFO] - Training Epoch: 1/2, step 2971/7134 completed (loss: 3.893157482147217, acc: 0.37569060921669006)
[2024-12-17 01:57:28,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,344][root][INFO] - Training Epoch: 1/2, step 2972/7134 completed (loss: 4.647303581237793, acc: 0.25999999046325684)
[2024-12-17 01:57:28,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:28,745][root][INFO] - Training Epoch: 1/2, step 2973/7134 completed (loss: 4.14723539352417, acc: 0.30909091234207153)
[2024-12-17 01:57:28,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,147][root][INFO] - Training Epoch: 1/2, step 2974/7134 completed (loss: 4.110136985778809, acc: 0.3801169693470001)
[2024-12-17 01:57:29,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,521][root][INFO] - Training Epoch: 1/2, step 2975/7134 completed (loss: 4.107694625854492, acc: 0.2732558250427246)
[2024-12-17 01:57:29,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:29,900][root][INFO] - Training Epoch: 1/2, step 2976/7134 completed (loss: 3.697092056274414, acc: 0.34433960914611816)
[2024-12-17 01:57:29,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,254][root][INFO] - Training Epoch: 1/2, step 2977/7134 completed (loss: 4.179354667663574, acc: 0.24137930572032928)
[2024-12-17 01:57:30,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,617][root][INFO] - Training Epoch: 1/2, step 2978/7134 completed (loss: 3.8349671363830566, acc: 0.3012048304080963)
[2024-12-17 01:57:30,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:30,968][root][INFO] - Training Epoch: 1/2, step 2979/7134 completed (loss: 3.928632974624634, acc: 0.37931033968925476)
[2024-12-17 01:57:31,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,344][root][INFO] - Training Epoch: 1/2, step 2980/7134 completed (loss: 4.395417213439941, acc: 0.2742857038974762)
[2024-12-17 01:57:31,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:31,726][root][INFO] - Training Epoch: 1/2, step 2981/7134 completed (loss: 4.136936187744141, acc: 0.28735631704330444)
[2024-12-17 01:57:31,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,091][root][INFO] - Training Epoch: 1/2, step 2982/7134 completed (loss: 4.346291542053223, acc: 0.30219781398773193)
[2024-12-17 01:57:32,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,451][root][INFO] - Training Epoch: 1/2, step 2983/7134 completed (loss: 4.233692169189453, acc: 0.2699386477470398)
[2024-12-17 01:57:32,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:32,849][root][INFO] - Training Epoch: 1/2, step 2984/7134 completed (loss: 3.8656723499298096, acc: 0.3186813294887543)
[2024-12-17 01:57:32,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,226][root][INFO] - Training Epoch: 1/2, step 2985/7134 completed (loss: 3.6126766204833984, acc: 0.31707316637039185)
[2024-12-17 01:57:33,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,600][root][INFO] - Training Epoch: 1/2, step 2986/7134 completed (loss: 3.9245405197143555, acc: 0.27319586277008057)
[2024-12-17 01:57:33,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:33,967][root][INFO] - Training Epoch: 1/2, step 2987/7134 completed (loss: 3.8045074939727783, acc: 0.30434781312942505)
[2024-12-17 01:57:34,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,332][root][INFO] - Training Epoch: 1/2, step 2988/7134 completed (loss: 4.017570972442627, acc: 0.2864864766597748)
[2024-12-17 01:57:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:34,698][root][INFO] - Training Epoch: 1/2, step 2989/7134 completed (loss: 4.112723350524902, acc: 0.32335329055786133)
[2024-12-17 01:57:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,067][root][INFO] - Training Epoch: 1/2, step 2990/7134 completed (loss: 4.2497735023498535, acc: 0.2635135054588318)
[2024-12-17 01:57:35,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,448][root][INFO] - Training Epoch: 1/2, step 2991/7134 completed (loss: 4.841257572174072, acc: 0.2239583283662796)
[2024-12-17 01:57:35,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:35,811][root][INFO] - Training Epoch: 1/2, step 2992/7134 completed (loss: 4.32593297958374, acc: 0.276729553937912)
[2024-12-17 01:57:35,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,208][root][INFO] - Training Epoch: 1/2, step 2993/7134 completed (loss: 3.6519505977630615, acc: 0.311557799577713)
[2024-12-17 01:57:36,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,577][root][INFO] - Training Epoch: 1/2, step 2994/7134 completed (loss: 3.900211811065674, acc: 0.30158731341362)
[2024-12-17 01:57:36,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:36,972][root][INFO] - Training Epoch: 1/2, step 2995/7134 completed (loss: 3.9105734825134277, acc: 0.31553396582603455)
[2024-12-17 01:57:37,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,349][root][INFO] - Training Epoch: 1/2, step 2996/7134 completed (loss: 3.855919361114502, acc: 0.3041236996650696)
[2024-12-17 01:57:37,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:37,727][root][INFO] - Training Epoch: 1/2, step 2997/7134 completed (loss: 3.838995933532715, acc: 0.27358490228652954)
[2024-12-17 01:57:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,089][root][INFO] - Training Epoch: 1/2, step 2998/7134 completed (loss: 3.9268686771392822, acc: 0.2857142984867096)
[2024-12-17 01:57:38,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,491][root][INFO] - Training Epoch: 1/2, step 2999/7134 completed (loss: 3.972210645675659, acc: 0.30000001192092896)
[2024-12-17 01:57:38,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:38,871][root][INFO] - Training Epoch: 1/2, step 3000/7134 completed (loss: 4.10023307800293, acc: 0.32870370149612427)
[2024-12-17 01:57:38,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,307][root][INFO] - Training Epoch: 1/2, step 3001/7134 completed (loss: 3.7717936038970947, acc: 0.3502538204193115)
[2024-12-17 01:57:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:39,681][root][INFO] - Training Epoch: 1/2, step 3002/7134 completed (loss: 3.7370028495788574, acc: 0.3271889388561249)
[2024-12-17 01:57:39,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,050][root][INFO] - Training Epoch: 1/2, step 3003/7134 completed (loss: 3.6863040924072266, acc: 0.3299492299556732)
[2024-12-17 01:57:40,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,415][root][INFO] - Training Epoch: 1/2, step 3004/7134 completed (loss: 3.6667392253875732, acc: 0.3465346395969391)
[2024-12-17 01:57:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:40,794][root][INFO] - Training Epoch: 1/2, step 3005/7134 completed (loss: 3.9027163982391357, acc: 0.2953367829322815)
[2024-12-17 01:57:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,167][root][INFO] - Training Epoch: 1/2, step 3006/7134 completed (loss: 3.3544814586639404, acc: 0.33714285492897034)
[2024-12-17 01:57:41,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,526][root][INFO] - Training Epoch: 1/2, step 3007/7134 completed (loss: 4.122559070587158, acc: 0.2848837077617645)
[2024-12-17 01:57:41,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:41,928][root][INFO] - Training Epoch: 1/2, step 3008/7134 completed (loss: 4.439610958099365, acc: 0.31972789764404297)
[2024-12-17 01:57:42,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,295][root][INFO] - Training Epoch: 1/2, step 3009/7134 completed (loss: 3.9698750972747803, acc: 0.3452380895614624)
[2024-12-17 01:57:42,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:42,683][root][INFO] - Training Epoch: 1/2, step 3010/7134 completed (loss: 3.8679397106170654, acc: 0.3942857086658478)
[2024-12-17 01:57:42,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,057][root][INFO] - Training Epoch: 1/2, step 3011/7134 completed (loss: 4.216290473937988, acc: 0.34545454382896423)
[2024-12-17 01:57:43,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,426][root][INFO] - Training Epoch: 1/2, step 3012/7134 completed (loss: 4.2671356201171875, acc: 0.32374101877212524)
[2024-12-17 01:57:43,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:43,835][root][INFO] - Training Epoch: 1/2, step 3013/7134 completed (loss: 4.0223069190979, acc: 0.3139534890651703)
[2024-12-17 01:57:43,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,203][root][INFO] - Training Epoch: 1/2, step 3014/7134 completed (loss: 4.06856632232666, acc: 0.297468364238739)
[2024-12-17 01:57:44,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,570][root][INFO] - Training Epoch: 1/2, step 3015/7134 completed (loss: 4.408562660217285, acc: 0.27464789152145386)
[2024-12-17 01:57:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:44,965][root][INFO] - Training Epoch: 1/2, step 3016/7134 completed (loss: 4.1746296882629395, acc: 0.30136987566947937)
[2024-12-17 01:57:45,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,329][root][INFO] - Training Epoch: 1/2, step 3017/7134 completed (loss: 3.7134487628936768, acc: 0.35537189245224)
[2024-12-17 01:57:45,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:45,690][root][INFO] - Training Epoch: 1/2, step 3018/7134 completed (loss: 3.983227014541626, acc: 0.2748091518878937)
[2024-12-17 01:57:45,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,087][root][INFO] - Training Epoch: 1/2, step 3019/7134 completed (loss: 3.7719101905822754, acc: 0.2867647111415863)
[2024-12-17 01:57:46,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,465][root][INFO] - Training Epoch: 1/2, step 3020/7134 completed (loss: 3.9420385360717773, acc: 0.3309352397918701)
[2024-12-17 01:57:46,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:46,844][root][INFO] - Training Epoch: 1/2, step 3021/7134 completed (loss: 3.472428798675537, acc: 0.3484848439693451)
[2024-12-17 01:57:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,235][root][INFO] - Training Epoch: 1/2, step 3022/7134 completed (loss: 3.6007602214813232, acc: 0.29323309659957886)
[2024-12-17 01:57:47,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:47,606][root][INFO] - Training Epoch: 1/2, step 3023/7134 completed (loss: 3.6829516887664795, acc: 0.3461538553237915)
[2024-12-17 01:57:47,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,001][root][INFO] - Training Epoch: 1/2, step 3024/7134 completed (loss: 3.7089409828186035, acc: 0.28333333134651184)
[2024-12-17 01:57:48,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,388][root][INFO] - Training Epoch: 1/2, step 3025/7134 completed (loss: 4.223380088806152, acc: 0.2846153974533081)
[2024-12-17 01:57:48,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:48,771][root][INFO] - Training Epoch: 1/2, step 3026/7134 completed (loss: 3.65974497795105, acc: 0.3196721374988556)
[2024-12-17 01:57:48,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,168][root][INFO] - Training Epoch: 1/2, step 3027/7134 completed (loss: 4.327988147735596, acc: 0.2708333432674408)
[2024-12-17 01:57:49,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,598][root][INFO] - Training Epoch: 1/2, step 3028/7134 completed (loss: 3.7358720302581787, acc: 0.27835050225257874)
[2024-12-17 01:57:49,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:49,970][root][INFO] - Training Epoch: 1/2, step 3029/7134 completed (loss: 3.6525068283081055, acc: 0.30136987566947937)
[2024-12-17 01:57:50,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,358][root][INFO] - Training Epoch: 1/2, step 3030/7134 completed (loss: 3.88200044631958, acc: 0.29054054617881775)
[2024-12-17 01:57:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:50,723][root][INFO] - Training Epoch: 1/2, step 3031/7134 completed (loss: 4.027994155883789, acc: 0.28282827138900757)
[2024-12-17 01:57:50,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,099][root][INFO] - Training Epoch: 1/2, step 3032/7134 completed (loss: 3.6910665035247803, acc: 0.33870968222618103)
[2024-12-17 01:57:51,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,454][root][INFO] - Training Epoch: 1/2, step 3033/7134 completed (loss: 4.15763521194458, acc: 0.234375)
[2024-12-17 01:57:51,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:51,871][root][INFO] - Training Epoch: 1/2, step 3034/7134 completed (loss: 4.329827308654785, acc: 0.2522522509098053)
[2024-12-17 01:57:51,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,249][root][INFO] - Training Epoch: 1/2, step 3035/7134 completed (loss: 3.9158287048339844, acc: 0.31292515993118286)
[2024-12-17 01:57:52,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:52,644][root][INFO] - Training Epoch: 1/2, step 3036/7134 completed (loss: 4.354081630706787, acc: 0.3199999928474426)
[2024-12-17 01:57:52,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,037][root][INFO] - Training Epoch: 1/2, step 3037/7134 completed (loss: 3.9106931686401367, acc: 0.34228187799453735)
[2024-12-17 01:57:53,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,446][root][INFO] - Training Epoch: 1/2, step 3038/7134 completed (loss: 4.142373085021973, acc: 0.29104477167129517)
[2024-12-17 01:57:53,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:53,837][root][INFO] - Training Epoch: 1/2, step 3039/7134 completed (loss: 3.8472211360931396, acc: 0.28378379344940186)
[2024-12-17 01:57:53,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,194][root][INFO] - Training Epoch: 1/2, step 3040/7134 completed (loss: 3.643549919128418, acc: 0.3333333432674408)
[2024-12-17 01:57:54,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,575][root][INFO] - Training Epoch: 1/2, step 3041/7134 completed (loss: 3.5034570693969727, acc: 0.40714284777641296)
[2024-12-17 01:57:54,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:54,963][root][INFO] - Training Epoch: 1/2, step 3042/7134 completed (loss: 4.05453634262085, acc: 0.2371794879436493)
[2024-12-17 01:57:55,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,336][root][INFO] - Training Epoch: 1/2, step 3043/7134 completed (loss: 4.338238716125488, acc: 0.1785714328289032)
[2024-12-17 01:57:55,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:55,750][root][INFO] - Training Epoch: 1/2, step 3044/7134 completed (loss: 4.040717601776123, acc: 0.27819550037384033)
[2024-12-17 01:57:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,148][root][INFO] - Training Epoch: 1/2, step 3045/7134 completed (loss: 3.5555808544158936, acc: 0.27906978130340576)
[2024-12-17 01:57:56,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,531][root][INFO] - Training Epoch: 1/2, step 3046/7134 completed (loss: 3.9152543544769287, acc: 0.26035502552986145)
[2024-12-17 01:57:56,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:56,898][root][INFO] - Training Epoch: 1/2, step 3047/7134 completed (loss: 3.9591317176818848, acc: 0.299435019493103)
[2024-12-17 01:57:57,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,312][root][INFO] - Training Epoch: 1/2, step 3048/7134 completed (loss: 3.8987491130828857, acc: 0.28421053290367126)
[2024-12-17 01:57:57,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:57,698][root][INFO] - Training Epoch: 1/2, step 3049/7134 completed (loss: 4.2740020751953125, acc: 0.23749999701976776)
[2024-12-17 01:57:57,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,074][root][INFO] - Training Epoch: 1/2, step 3050/7134 completed (loss: 3.7384893894195557, acc: 0.3350253701210022)
[2024-12-17 01:57:58,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,436][root][INFO] - Training Epoch: 1/2, step 3051/7134 completed (loss: 4.454927444458008, acc: 0.261904776096344)
[2024-12-17 01:57:58,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:58,805][root][INFO] - Training Epoch: 1/2, step 3052/7134 completed (loss: 3.7634828090667725, acc: 0.3567567467689514)
[2024-12-17 01:57:58,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,170][root][INFO] - Training Epoch: 1/2, step 3053/7134 completed (loss: 3.380204677581787, acc: 0.3333333432674408)
[2024-12-17 01:57:59,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,541][root][INFO] - Training Epoch: 1/2, step 3054/7134 completed (loss: 3.3293163776397705, acc: 0.35638296604156494)
[2024-12-17 01:57:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:57:59,909][root][INFO] - Training Epoch: 1/2, step 3055/7134 completed (loss: 3.5535295009613037, acc: 0.3513513505458832)
[2024-12-17 01:58:00,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,279][root][INFO] - Training Epoch: 1/2, step 3056/7134 completed (loss: 4.02449369430542, acc: 0.3351351320743561)
[2024-12-17 01:58:00,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:00,682][root][INFO] - Training Epoch: 1/2, step 3057/7134 completed (loss: 3.5338127613067627, acc: 0.3190183937549591)
[2024-12-17 01:58:00,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,105][root][INFO] - Training Epoch: 1/2, step 3058/7134 completed (loss: 3.5325207710266113, acc: 0.3263157904148102)
[2024-12-17 01:58:01,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,474][root][INFO] - Training Epoch: 1/2, step 3059/7134 completed (loss: 3.347703695297241, acc: 0.3199999928474426)
[2024-12-17 01:58:01,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:01,863][root][INFO] - Training Epoch: 1/2, step 3060/7134 completed (loss: 3.765981912612915, acc: 0.2670156955718994)
[2024-12-17 01:58:02,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,273][root][INFO] - Training Epoch: 1/2, step 3061/7134 completed (loss: 3.987093687057495, acc: 0.26249998807907104)
[2024-12-17 01:58:02,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:02,684][root][INFO] - Training Epoch: 1/2, step 3062/7134 completed (loss: 3.530073881149292, acc: 0.3396226465702057)
[2024-12-17 01:58:02,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,041][root][INFO] - Training Epoch: 1/2, step 3063/7134 completed (loss: 3.7015035152435303, acc: 0.39772728085517883)
[2024-12-17 01:58:03,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,442][root][INFO] - Training Epoch: 1/2, step 3064/7134 completed (loss: 3.5837998390197754, acc: 0.3254437744617462)
[2024-12-17 01:58:03,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:03,822][root][INFO] - Training Epoch: 1/2, step 3065/7134 completed (loss: 3.2393500804901123, acc: 0.3595505654811859)
[2024-12-17 01:58:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,182][root][INFO] - Training Epoch: 1/2, step 3066/7134 completed (loss: 3.537149429321289, acc: 0.3509933650493622)
[2024-12-17 01:58:04,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,539][root][INFO] - Training Epoch: 1/2, step 3067/7134 completed (loss: 3.349012613296509, acc: 0.34558823704719543)
[2024-12-17 01:58:04,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:04,913][root][INFO] - Training Epoch: 1/2, step 3068/7134 completed (loss: 3.5768940448760986, acc: 0.29608938097953796)
[2024-12-17 01:58:05,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,275][root][INFO] - Training Epoch: 1/2, step 3069/7134 completed (loss: 3.3736166954040527, acc: 0.30612245202064514)
[2024-12-17 01:58:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:05,654][root][INFO] - Training Epoch: 1/2, step 3070/7134 completed (loss: 3.3322112560272217, acc: 0.3684210479259491)
[2024-12-17 01:58:05,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,026][root][INFO] - Training Epoch: 1/2, step 3071/7134 completed (loss: 3.341993570327759, acc: 0.3777777850627899)
[2024-12-17 01:58:06,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,399][root][INFO] - Training Epoch: 1/2, step 3072/7134 completed (loss: 3.115464210510254, acc: 0.4131455421447754)
[2024-12-17 01:58:06,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:06,758][root][INFO] - Training Epoch: 1/2, step 3073/7134 completed (loss: 3.6701228618621826, acc: 0.31073445081710815)
[2024-12-17 01:58:06,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,124][root][INFO] - Training Epoch: 1/2, step 3074/7134 completed (loss: 3.231126308441162, acc: 0.33112582564353943)
[2024-12-17 01:58:07,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,486][root][INFO] - Training Epoch: 1/2, step 3075/7134 completed (loss: 3.1729040145874023, acc: 0.37654322385787964)
[2024-12-17 01:58:07,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:07,861][root][INFO] - Training Epoch: 1/2, step 3076/7134 completed (loss: 3.6403563022613525, acc: 0.33870968222618103)
[2024-12-17 01:58:07,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,242][root][INFO] - Training Epoch: 1/2, step 3077/7134 completed (loss: 3.3754477500915527, acc: 0.3560209572315216)
[2024-12-17 01:58:08,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,617][root][INFO] - Training Epoch: 1/2, step 3078/7134 completed (loss: 3.9041833877563477, acc: 0.3229166567325592)
[2024-12-17 01:58:08,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:08,991][root][INFO] - Training Epoch: 1/2, step 3079/7134 completed (loss: 3.4880764484405518, acc: 0.35978835821151733)
[2024-12-17 01:58:09,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,370][root][INFO] - Training Epoch: 1/2, step 3080/7134 completed (loss: 3.873385429382324, acc: 0.32407405972480774)
[2024-12-17 01:58:09,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:09,764][root][INFO] - Training Epoch: 1/2, step 3081/7134 completed (loss: 4.587896823883057, acc: 0.20792078971862793)
[2024-12-17 01:58:09,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,134][root][INFO] - Training Epoch: 1/2, step 3082/7134 completed (loss: 4.089226722717285, acc: 0.3333333432674408)
[2024-12-17 01:58:10,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,508][root][INFO] - Training Epoch: 1/2, step 3083/7134 completed (loss: 3.834449529647827, acc: 0.2864864766597748)
[2024-12-17 01:58:10,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:10,907][root][INFO] - Training Epoch: 1/2, step 3084/7134 completed (loss: 4.1959638595581055, acc: 0.30890053510665894)
[2024-12-17 01:58:11,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,371][root][INFO] - Training Epoch: 1/2, step 3085/7134 completed (loss: 4.419161796569824, acc: 0.28387096524238586)
[2024-12-17 01:58:11,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:11,765][root][INFO] - Training Epoch: 1/2, step 3086/7134 completed (loss: 3.9134063720703125, acc: 0.3561643958091736)
[2024-12-17 01:58:11,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,158][root][INFO] - Training Epoch: 1/2, step 3087/7134 completed (loss: 3.8534786701202393, acc: 0.30177515745162964)
[2024-12-17 01:58:12,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,546][root][INFO] - Training Epoch: 1/2, step 3088/7134 completed (loss: 4.109742164611816, acc: 0.2757009267807007)
[2024-12-17 01:58:12,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:12,952][root][INFO] - Training Epoch: 1/2, step 3089/7134 completed (loss: 3.8203463554382324, acc: 0.302325576543808)
[2024-12-17 01:58:13,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,337][root][INFO] - Training Epoch: 1/2, step 3090/7134 completed (loss: 4.4276227951049805, acc: 0.2429378479719162)
[2024-12-17 01:58:13,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:13,777][root][INFO] - Training Epoch: 1/2, step 3091/7134 completed (loss: 4.460134029388428, acc: 0.248927041888237)
[2024-12-17 01:58:13,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,143][root][INFO] - Training Epoch: 1/2, step 3092/7134 completed (loss: 4.414792537689209, acc: 0.30534350872039795)
[2024-12-17 01:58:14,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,518][root][INFO] - Training Epoch: 1/2, step 3093/7134 completed (loss: 4.114138126373291, acc: 0.2957746386528015)
[2024-12-17 01:58:14,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:14,902][root][INFO] - Training Epoch: 1/2, step 3094/7134 completed (loss: 4.185920715332031, acc: 0.2774566411972046)
[2024-12-17 01:58:14,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,257][root][INFO] - Training Epoch: 1/2, step 3095/7134 completed (loss: 3.7211430072784424, acc: 0.3333333432674408)
[2024-12-17 01:58:15,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,620][root][INFO] - Training Epoch: 1/2, step 3096/7134 completed (loss: 4.326588153839111, acc: 0.28272250294685364)
[2024-12-17 01:58:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:15,991][root][INFO] - Training Epoch: 1/2, step 3097/7134 completed (loss: 4.160158157348633, acc: 0.2804878056049347)
[2024-12-17 01:58:16,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,399][root][INFO] - Training Epoch: 1/2, step 3098/7134 completed (loss: 4.391995906829834, acc: 0.26143792271614075)
[2024-12-17 01:58:16,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:16,770][root][INFO] - Training Epoch: 1/2, step 3099/7134 completed (loss: 4.37332010269165, acc: 0.24087591469287872)
[2024-12-17 01:58:16,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,170][root][INFO] - Training Epoch: 1/2, step 3100/7134 completed (loss: 3.609046220779419, acc: 0.340807169675827)
[2024-12-17 01:58:17,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,539][root][INFO] - Training Epoch: 1/2, step 3101/7134 completed (loss: 4.093874454498291, acc: 0.3045685291290283)
[2024-12-17 01:58:17,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:17,920][root][INFO] - Training Epoch: 1/2, step 3102/7134 completed (loss: 3.606062173843384, acc: 0.349693238735199)
[2024-12-17 01:58:18,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,284][root][INFO] - Training Epoch: 1/2, step 3103/7134 completed (loss: 3.7038984298706055, acc: 0.3318965435028076)
[2024-12-17 01:58:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:18,639][root][INFO] - Training Epoch: 1/2, step 3104/7134 completed (loss: 3.6357102394104004, acc: 0.27906978130340576)
[2024-12-17 01:58:18,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,005][root][INFO] - Training Epoch: 1/2, step 3105/7134 completed (loss: 3.8809077739715576, acc: 0.2956521809101105)
[2024-12-17 01:58:19,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,385][root][INFO] - Training Epoch: 1/2, step 3106/7134 completed (loss: 3.7104828357696533, acc: 0.25503355264663696)
[2024-12-17 01:58:19,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:19,752][root][INFO] - Training Epoch: 1/2, step 3107/7134 completed (loss: 3.871595621109009, acc: 0.3139534890651703)
[2024-12-17 01:58:19,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,117][root][INFO] - Training Epoch: 1/2, step 3108/7134 completed (loss: 3.85170578956604, acc: 0.2925170063972473)
[2024-12-17 01:58:20,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,487][root][INFO] - Training Epoch: 1/2, step 3109/7134 completed (loss: 4.5930938720703125, acc: 0.23846153914928436)
[2024-12-17 01:58:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:20,865][root][INFO] - Training Epoch: 1/2, step 3110/7134 completed (loss: 4.0613322257995605, acc: 0.2330097109079361)
[2024-12-17 01:58:20,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,227][root][INFO] - Training Epoch: 1/2, step 3111/7134 completed (loss: 4.974118709564209, acc: 0.21739129722118378)
[2024-12-17 01:58:21,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,573][root][INFO] - Training Epoch: 1/2, step 3112/7134 completed (loss: 5.166066646575928, acc: 0.262773722410202)
[2024-12-17 01:58:21,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:21,968][root][INFO] - Training Epoch: 1/2, step 3113/7134 completed (loss: 4.740109920501709, acc: 0.29878050088882446)
[2024-12-17 01:58:22,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,352][root][INFO] - Training Epoch: 1/2, step 3114/7134 completed (loss: 4.383619785308838, acc: 0.21804511547088623)
[2024-12-17 01:58:22,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:22,716][root][INFO] - Training Epoch: 1/2, step 3115/7134 completed (loss: 4.331596374511719, acc: 0.31578946113586426)
[2024-12-17 01:58:22,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,136][root][INFO] - Training Epoch: 1/2, step 3116/7134 completed (loss: 4.620090961456299, acc: 0.28248587250709534)
[2024-12-17 01:58:23,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,520][root][INFO] - Training Epoch: 1/2, step 3117/7134 completed (loss: 4.483667373657227, acc: 0.2584269642829895)
[2024-12-17 01:58:23,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:23,905][root][INFO] - Training Epoch: 1/2, step 3118/7134 completed (loss: 4.588128566741943, acc: 0.24861878156661987)
[2024-12-17 01:58:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,287][root][INFO] - Training Epoch: 1/2, step 3119/7134 completed (loss: 4.175933837890625, acc: 0.35978835821151733)
[2024-12-17 01:58:24,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:24,663][root][INFO] - Training Epoch: 1/2, step 3120/7134 completed (loss: 4.140174865722656, acc: 0.31481480598449707)
[2024-12-17 01:58:24,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,045][root][INFO] - Training Epoch: 1/2, step 3121/7134 completed (loss: 4.463125228881836, acc: 0.27840909361839294)
[2024-12-17 01:58:25,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,477][root][INFO] - Training Epoch: 1/2, step 3122/7134 completed (loss: 4.432353973388672, acc: 0.2947368323802948)
[2024-12-17 01:58:25,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:25,879][root][INFO] - Training Epoch: 1/2, step 3123/7134 completed (loss: 4.5341315269470215, acc: 0.22162161767482758)
[2024-12-17 01:58:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,248][root][INFO] - Training Epoch: 1/2, step 3124/7134 completed (loss: 4.571778774261475, acc: 0.25555557012557983)
[2024-12-17 01:58:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:26,626][root][INFO] - Training Epoch: 1/2, step 3125/7134 completed (loss: 4.429471969604492, acc: 0.190476194024086)
[2024-12-17 01:58:26,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,026][root][INFO] - Training Epoch: 1/2, step 3126/7134 completed (loss: 4.50543737411499, acc: 0.2569832503795624)
[2024-12-17 01:58:27,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,428][root][INFO] - Training Epoch: 1/2, step 3127/7134 completed (loss: 3.939570665359497, acc: 0.30985915660858154)
[2024-12-17 01:58:27,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:27,789][root][INFO] - Training Epoch: 1/2, step 3128/7134 completed (loss: 4.044191837310791, acc: 0.29946523904800415)
[2024-12-17 01:58:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,160][root][INFO] - Training Epoch: 1/2, step 3129/7134 completed (loss: 4.6887946128845215, acc: 0.19886364042758942)
[2024-12-17 01:58:28,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,569][root][INFO] - Training Epoch: 1/2, step 3130/7134 completed (loss: 4.122274398803711, acc: 0.29949238896369934)
[2024-12-17 01:58:28,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:28,982][root][INFO] - Training Epoch: 1/2, step 3131/7134 completed (loss: 4.019081115722656, acc: 0.29378530383110046)
[2024-12-17 01:58:29,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,364][root][INFO] - Training Epoch: 1/2, step 3132/7134 completed (loss: 4.157873153686523, acc: 0.2743362784385681)
[2024-12-17 01:58:29,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:29,757][root][INFO] - Training Epoch: 1/2, step 3133/7134 completed (loss: 4.06835412979126, acc: 0.25)
[2024-12-17 01:58:29,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,140][root][INFO] - Training Epoch: 1/2, step 3134/7134 completed (loss: 3.641144275665283, acc: 0.3828125)
[2024-12-17 01:58:30,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,527][root][INFO] - Training Epoch: 1/2, step 3135/7134 completed (loss: 3.7628862857818604, acc: 0.2886597812175751)
[2024-12-17 01:58:30,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:30,905][root][INFO] - Training Epoch: 1/2, step 3136/7134 completed (loss: 4.0828704833984375, acc: 0.290076345205307)
[2024-12-17 01:58:31,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,291][root][INFO] - Training Epoch: 1/2, step 3137/7134 completed (loss: 4.041826248168945, acc: 0.3191489279270172)
[2024-12-17 01:58:31,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:31,666][root][INFO] - Training Epoch: 1/2, step 3138/7134 completed (loss: 3.9508283138275146, acc: 0.24444444477558136)
[2024-12-17 01:58:31,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,051][root][INFO] - Training Epoch: 1/2, step 3139/7134 completed (loss: 4.040405750274658, acc: 0.2517985701560974)
[2024-12-17 01:58:32,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,421][root][INFO] - Training Epoch: 1/2, step 3140/7134 completed (loss: 3.6369223594665527, acc: 0.30821916460990906)
[2024-12-17 01:58:32,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:32,800][root][INFO] - Training Epoch: 1/2, step 3141/7134 completed (loss: 4.044124126434326, acc: 0.29054054617881775)
[2024-12-17 01:58:32,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,175][root][INFO] - Training Epoch: 1/2, step 3142/7134 completed (loss: 4.038662433624268, acc: 0.299401193857193)
[2024-12-17 01:58:33,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,554][root][INFO] - Training Epoch: 1/2, step 3143/7134 completed (loss: 3.9663023948669434, acc: 0.2451612949371338)
[2024-12-17 01:58:33,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:33,942][root][INFO] - Training Epoch: 1/2, step 3144/7134 completed (loss: 4.0448408126831055, acc: 0.32692307233810425)
[2024-12-17 01:58:34,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,330][root][INFO] - Training Epoch: 1/2, step 3145/7134 completed (loss: 3.9947621822357178, acc: 0.28828829526901245)
[2024-12-17 01:58:34,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:34,723][root][INFO] - Training Epoch: 1/2, step 3146/7134 completed (loss: 3.4905765056610107, acc: 0.3737373650074005)
[2024-12-17 01:58:34,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,115][root][INFO] - Training Epoch: 1/2, step 3147/7134 completed (loss: 3.7050249576568604, acc: 0.31506848335266113)
[2024-12-17 01:58:35,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,512][root][INFO] - Training Epoch: 1/2, step 3148/7134 completed (loss: 3.8513753414154053, acc: 0.29608938097953796)
[2024-12-17 01:58:35,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:35,889][root][INFO] - Training Epoch: 1/2, step 3149/7134 completed (loss: 4.081676006317139, acc: 0.28387096524238586)
[2024-12-17 01:58:35,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,232][root][INFO] - Training Epoch: 1/2, step 3150/7134 completed (loss: 4.573962688446045, acc: 0.24285714328289032)
[2024-12-17 01:58:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,586][root][INFO] - Training Epoch: 1/2, step 3151/7134 completed (loss: 4.602080345153809, acc: 0.290076345205307)
[2024-12-17 01:58:36,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:36,951][root][INFO] - Training Epoch: 1/2, step 3152/7134 completed (loss: 4.600836277008057, acc: 0.28169015049934387)
[2024-12-17 01:58:37,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,313][root][INFO] - Training Epoch: 1/2, step 3153/7134 completed (loss: 4.04947566986084, acc: 0.37078651785850525)
[2024-12-17 01:58:37,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:37,687][root][INFO] - Training Epoch: 1/2, step 3154/7134 completed (loss: 4.139097213745117, acc: 0.2857142984867096)
[2024-12-17 01:58:37,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,058][root][INFO] - Training Epoch: 1/2, step 3155/7134 completed (loss: 3.692978858947754, acc: 0.3233082592487335)
[2024-12-17 01:58:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,427][root][INFO] - Training Epoch: 1/2, step 3156/7134 completed (loss: 4.444165229797363, acc: 0.302325576543808)
[2024-12-17 01:58:38,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:38,849][root][INFO] - Training Epoch: 1/2, step 3157/7134 completed (loss: 4.1093339920043945, acc: 0.30434781312942505)
[2024-12-17 01:58:38,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,222][root][INFO] - Training Epoch: 1/2, step 3158/7134 completed (loss: 3.529798746109009, acc: 0.38297873735427856)
[2024-12-17 01:58:39,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,600][root][INFO] - Training Epoch: 1/2, step 3159/7134 completed (loss: 4.19464635848999, acc: 0.2989690601825714)
[2024-12-17 01:58:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:39,994][root][INFO] - Training Epoch: 1/2, step 3160/7134 completed (loss: 4.152616024017334, acc: 0.2884615361690521)
[2024-12-17 01:58:40,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,377][root][INFO] - Training Epoch: 1/2, step 3161/7134 completed (loss: 4.045733451843262, acc: 0.35031846165657043)
[2024-12-17 01:58:40,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:40,753][root][INFO] - Training Epoch: 1/2, step 3162/7134 completed (loss: 3.7997918128967285, acc: 0.31506848335266113)
[2024-12-17 01:58:40,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,123][root][INFO] - Training Epoch: 1/2, step 3163/7134 completed (loss: 3.8658721446990967, acc: 0.2540983557701111)
[2024-12-17 01:58:41,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,504][root][INFO] - Training Epoch: 1/2, step 3164/7134 completed (loss: 4.437887191772461, acc: 0.25362318754196167)
[2024-12-17 01:58:41,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:41,907][root][INFO] - Training Epoch: 1/2, step 3165/7134 completed (loss: 4.345122337341309, acc: 0.28671327233314514)
[2024-12-17 01:58:42,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,327][root][INFO] - Training Epoch: 1/2, step 3166/7134 completed (loss: 4.320320129394531, acc: 0.31012657284736633)
[2024-12-17 01:58:42,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:42,709][root][INFO] - Training Epoch: 1/2, step 3167/7134 completed (loss: 4.859561443328857, acc: 0.21604938805103302)
[2024-12-17 01:58:42,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,100][root][INFO] - Training Epoch: 1/2, step 3168/7134 completed (loss: 4.3430891036987305, acc: 0.2875817120075226)
[2024-12-17 01:58:43,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,463][root][INFO] - Training Epoch: 1/2, step 3169/7134 completed (loss: 4.200100898742676, acc: 0.3606557250022888)
[2024-12-17 01:58:43,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:43,850][root][INFO] - Training Epoch: 1/2, step 3170/7134 completed (loss: 3.8859150409698486, acc: 0.33088234066963196)
[2024-12-17 01:58:43,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,200][root][INFO] - Training Epoch: 1/2, step 3171/7134 completed (loss: 4.0156731605529785, acc: 0.3076923191547394)
[2024-12-17 01:58:44,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,578][root][INFO] - Training Epoch: 1/2, step 3172/7134 completed (loss: 3.749669075012207, acc: 0.2539682686328888)
[2024-12-17 01:58:44,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:44,940][root][INFO] - Training Epoch: 1/2, step 3173/7134 completed (loss: 4.519755840301514, acc: 0.2525252401828766)
[2024-12-17 01:58:45,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,308][root][INFO] - Training Epoch: 1/2, step 3174/7134 completed (loss: 3.776909112930298, acc: 0.3313252925872803)
[2024-12-17 01:58:45,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:45,677][root][INFO] - Training Epoch: 1/2, step 3175/7134 completed (loss: 3.908315896987915, acc: 0.34302327036857605)
[2024-12-17 01:58:45,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,063][root][INFO] - Training Epoch: 1/2, step 3176/7134 completed (loss: 4.463873386383057, acc: 0.22674418985843658)
[2024-12-17 01:58:46,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,443][root][INFO] - Training Epoch: 1/2, step 3177/7134 completed (loss: 4.214047908782959, acc: 0.2469135820865631)
[2024-12-17 01:58:46,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:46,788][root][INFO] - Training Epoch: 1/2, step 3178/7134 completed (loss: 3.6896300315856934, acc: 0.3199999928474426)
[2024-12-17 01:58:46,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,182][root][INFO] - Training Epoch: 1/2, step 3179/7134 completed (loss: 3.7339437007904053, acc: 0.3273809552192688)
[2024-12-17 01:58:47,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,568][root][INFO] - Training Epoch: 1/2, step 3180/7134 completed (loss: 4.109382152557373, acc: 0.24074074625968933)
[2024-12-17 01:58:47,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:47,984][root][INFO] - Training Epoch: 1/2, step 3181/7134 completed (loss: 4.288694381713867, acc: 0.2928176820278168)
[2024-12-17 01:58:48,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,382][root][INFO] - Training Epoch: 1/2, step 3182/7134 completed (loss: 3.624940872192383, acc: 0.35975611209869385)
[2024-12-17 01:58:48,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:48,724][root][INFO] - Training Epoch: 1/2, step 3183/7134 completed (loss: 4.4461445808410645, acc: 0.23357664048671722)
[2024-12-17 01:58:48,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,143][root][INFO] - Training Epoch: 1/2, step 3184/7134 completed (loss: 4.1490888595581055, acc: 0.3187499940395355)
[2024-12-17 01:58:49,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,551][root][INFO] - Training Epoch: 1/2, step 3185/7134 completed (loss: 3.9522976875305176, acc: 0.24528302252292633)
[2024-12-17 01:58:49,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:49,946][root][INFO] - Training Epoch: 1/2, step 3186/7134 completed (loss: 3.300424337387085, acc: 0.3782051205635071)
[2024-12-17 01:58:50,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,339][root][INFO] - Training Epoch: 1/2, step 3187/7134 completed (loss: 3.730198383331299, acc: 0.3499999940395355)
[2024-12-17 01:58:50,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:50,724][root][INFO] - Training Epoch: 1/2, step 3188/7134 completed (loss: 3.3741519451141357, acc: 0.3743016719818115)
[2024-12-17 01:58:50,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,094][root][INFO] - Training Epoch: 1/2, step 3189/7134 completed (loss: 3.4346086978912354, acc: 0.37654322385787964)
[2024-12-17 01:58:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,471][root][INFO] - Training Epoch: 1/2, step 3190/7134 completed (loss: 4.096039772033691, acc: 0.28125)
[2024-12-17 01:58:51,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:51,824][root][INFO] - Training Epoch: 1/2, step 3191/7134 completed (loss: 3.537872552871704, acc: 0.3726707994937897)
[2024-12-17 01:58:51,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,180][root][INFO] - Training Epoch: 1/2, step 3192/7134 completed (loss: 4.113831996917725, acc: 0.30656933784484863)
[2024-12-17 01:58:52,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,541][root][INFO] - Training Epoch: 1/2, step 3193/7134 completed (loss: 3.756359577178955, acc: 0.3351351320743561)
[2024-12-17 01:58:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:52,949][root][INFO] - Training Epoch: 1/2, step 3194/7134 completed (loss: 4.4091386795043945, acc: 0.2666666805744171)
[2024-12-17 01:58:53,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,384][root][INFO] - Training Epoch: 1/2, step 3195/7134 completed (loss: 4.338634967803955, acc: 0.2732919156551361)
[2024-12-17 01:58:53,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:53,739][root][INFO] - Training Epoch: 1/2, step 3196/7134 completed (loss: 3.8136038780212402, acc: 0.3550724685192108)
[2024-12-17 01:58:53,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,093][root][INFO] - Training Epoch: 1/2, step 3197/7134 completed (loss: 3.9202330112457275, acc: 0.3053892254829407)
[2024-12-17 01:58:54,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,463][root][INFO] - Training Epoch: 1/2, step 3198/7134 completed (loss: 4.226887226104736, acc: 0.28125)
[2024-12-17 01:58:54,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:54,820][root][INFO] - Training Epoch: 1/2, step 3199/7134 completed (loss: 3.5549957752227783, acc: 0.3488371968269348)
[2024-12-17 01:58:54,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,183][root][INFO] - Training Epoch: 1/2, step 3200/7134 completed (loss: 3.8598010540008545, acc: 0.347517728805542)
[2024-12-17 01:58:55,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,560][root][INFO] - Training Epoch: 1/2, step 3201/7134 completed (loss: 4.519923210144043, acc: 0.25984251499176025)
[2024-12-17 01:58:55,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:55,934][root][INFO] - Training Epoch: 1/2, step 3202/7134 completed (loss: 4.258610248565674, acc: 0.23595505952835083)
[2024-12-17 01:58:56,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,291][root][INFO] - Training Epoch: 1/2, step 3203/7134 completed (loss: 3.9140803813934326, acc: 0.3062500059604645)
[2024-12-17 01:58:56,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:56,654][root][INFO] - Training Epoch: 1/2, step 3204/7134 completed (loss: 3.7557144165039062, acc: 0.2876712381839752)
[2024-12-17 01:58:56,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,051][root][INFO] - Training Epoch: 1/2, step 3205/7134 completed (loss: 3.7643866539001465, acc: 0.3120567500591278)
[2024-12-17 01:58:57,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,445][root][INFO] - Training Epoch: 1/2, step 3206/7134 completed (loss: 3.698272228240967, acc: 0.31515151262283325)
[2024-12-17 01:58:57,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:57,829][root][INFO] - Training Epoch: 1/2, step 3207/7134 completed (loss: 3.3796286582946777, acc: 0.3251533806324005)
[2024-12-17 01:58:57,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,223][root][INFO] - Training Epoch: 1/2, step 3208/7134 completed (loss: 4.0033721923828125, acc: 0.2589927911758423)
[2024-12-17 01:58:58,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,585][root][INFO] - Training Epoch: 1/2, step 3209/7134 completed (loss: 3.671213150024414, acc: 0.34375)
[2024-12-17 01:58:58,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:58,989][root][INFO] - Training Epoch: 1/2, step 3210/7134 completed (loss: 3.8731799125671387, acc: 0.3096774220466614)
[2024-12-17 01:58:59,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,341][root][INFO] - Training Epoch: 1/2, step 3211/7134 completed (loss: 3.576137065887451, acc: 0.3025210201740265)
[2024-12-17 01:58:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:58:59,705][root][INFO] - Training Epoch: 1/2, step 3212/7134 completed (loss: 3.48481822013855, acc: 0.31578946113586426)
[2024-12-17 01:58:59,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,055][root][INFO] - Training Epoch: 1/2, step 3213/7134 completed (loss: 3.919485092163086, acc: 0.2678571343421936)
[2024-12-17 01:59:00,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,430][root][INFO] - Training Epoch: 1/2, step 3214/7134 completed (loss: 3.6420347690582275, acc: 0.3040935695171356)
[2024-12-17 01:59:00,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:00,810][root][INFO] - Training Epoch: 1/2, step 3215/7134 completed (loss: 3.8450591564178467, acc: 0.2840236723423004)
[2024-12-17 01:59:00,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,191][root][INFO] - Training Epoch: 1/2, step 3216/7134 completed (loss: 3.7347326278686523, acc: 0.2777777910232544)
[2024-12-17 01:59:01,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,570][root][INFO] - Training Epoch: 1/2, step 3217/7134 completed (loss: 3.5869178771972656, acc: 0.3314606845378876)
[2024-12-17 01:59:01,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:01,928][root][INFO] - Training Epoch: 1/2, step 3218/7134 completed (loss: 3.6391685009002686, acc: 0.34838709235191345)
[2024-12-17 01:59:02,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,299][root][INFO] - Training Epoch: 1/2, step 3219/7134 completed (loss: 3.7647788524627686, acc: 0.2916666567325592)
[2024-12-17 01:59:02,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:02,662][root][INFO] - Training Epoch: 1/2, step 3220/7134 completed (loss: 4.021988391876221, acc: 0.29378530383110046)
[2024-12-17 01:59:02,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,065][root][INFO] - Training Epoch: 1/2, step 3221/7134 completed (loss: 3.609590530395508, acc: 0.29032257199287415)
[2024-12-17 01:59:03,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,437][root][INFO] - Training Epoch: 1/2, step 3222/7134 completed (loss: 4.047346115112305, acc: 0.3034825921058655)
[2024-12-17 01:59:03,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:03,817][root][INFO] - Training Epoch: 1/2, step 3223/7134 completed (loss: 3.747333526611328, acc: 0.33128833770751953)
[2024-12-17 01:59:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,195][root][INFO] - Training Epoch: 1/2, step 3224/7134 completed (loss: 3.9667887687683105, acc: 0.30635836720466614)
[2024-12-17 01:59:04,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,574][root][INFO] - Training Epoch: 1/2, step 3225/7134 completed (loss: 3.873532772064209, acc: 0.2800000011920929)
[2024-12-17 01:59:04,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:04,933][root][INFO] - Training Epoch: 1/2, step 3226/7134 completed (loss: 4.576222896575928, acc: 0.21854305267333984)
[2024-12-17 01:59:05,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,324][root][INFO] - Training Epoch: 1/2, step 3227/7134 completed (loss: 4.121480464935303, acc: 0.23868313431739807)
[2024-12-17 01:59:05,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:05,705][root][INFO] - Training Epoch: 1/2, step 3228/7134 completed (loss: 3.9352807998657227, acc: 0.28282827138900757)
[2024-12-17 01:59:05,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,078][root][INFO] - Training Epoch: 1/2, step 3229/7134 completed (loss: 3.8046631813049316, acc: 0.33838382363319397)
[2024-12-17 01:59:06,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,438][root][INFO] - Training Epoch: 1/2, step 3230/7134 completed (loss: 3.8821823596954346, acc: 0.35624998807907104)
[2024-12-17 01:59:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:06,809][root][INFO] - Training Epoch: 1/2, step 3231/7134 completed (loss: 3.9160966873168945, acc: 0.3351648449897766)
[2024-12-17 01:59:06,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,178][root][INFO] - Training Epoch: 1/2, step 3232/7134 completed (loss: 3.534486770629883, acc: 0.2777777910232544)
[2024-12-17 01:59:07,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,551][root][INFO] - Training Epoch: 1/2, step 3233/7134 completed (loss: 3.8630542755126953, acc: 0.30708661675453186)
[2024-12-17 01:59:07,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:07,919][root][INFO] - Training Epoch: 1/2, step 3234/7134 completed (loss: 3.921353816986084, acc: 0.28930819034576416)
[2024-12-17 01:59:08,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,354][root][INFO] - Training Epoch: 1/2, step 3235/7134 completed (loss: 3.719372034072876, acc: 0.283687949180603)
[2024-12-17 01:59:08,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:08,741][root][INFO] - Training Epoch: 1/2, step 3236/7134 completed (loss: 3.9882616996765137, acc: 0.26553672552108765)
[2024-12-17 01:59:08,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,127][root][INFO] - Training Epoch: 1/2, step 3237/7134 completed (loss: 4.327105522155762, acc: 0.2467532455921173)
[2024-12-17 01:59:09,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,509][root][INFO] - Training Epoch: 1/2, step 3238/7134 completed (loss: 3.579542398452759, acc: 0.36666667461395264)
[2024-12-17 01:59:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:09,893][root][INFO] - Training Epoch: 1/2, step 3239/7134 completed (loss: 3.9100022315979004, acc: 0.24390244483947754)
[2024-12-17 01:59:09,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,277][root][INFO] - Training Epoch: 1/2, step 3240/7134 completed (loss: 3.4246833324432373, acc: 0.3743016719818115)
[2024-12-17 01:59:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:10,651][root][INFO] - Training Epoch: 1/2, step 3241/7134 completed (loss: 3.823579788208008, acc: 0.2647058963775635)
[2024-12-17 01:59:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,020][root][INFO] - Training Epoch: 1/2, step 3242/7134 completed (loss: 3.801764488220215, acc: 0.31168830394744873)
[2024-12-17 01:59:11,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,417][root][INFO] - Training Epoch: 1/2, step 3243/7134 completed (loss: 3.430953025817871, acc: 0.34224599599838257)
[2024-12-17 01:59:11,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:11,786][root][INFO] - Training Epoch: 1/2, step 3244/7134 completed (loss: 3.8655195236206055, acc: 0.2774566411972046)
[2024-12-17 01:59:11,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,177][root][INFO] - Training Epoch: 1/2, step 3245/7134 completed (loss: 3.7931442260742188, acc: 0.35384616255760193)
[2024-12-17 01:59:12,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,551][root][INFO] - Training Epoch: 1/2, step 3246/7134 completed (loss: 4.004698276519775, acc: 0.2717948853969574)
[2024-12-17 01:59:12,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:12,915][root][INFO] - Training Epoch: 1/2, step 3247/7134 completed (loss: 3.78143048286438, acc: 0.2628205120563507)
[2024-12-17 01:59:13,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,307][root][INFO] - Training Epoch: 1/2, step 3248/7134 completed (loss: 4.053525924682617, acc: 0.24087591469287872)
[2024-12-17 01:59:13,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:13,686][root][INFO] - Training Epoch: 1/2, step 3249/7134 completed (loss: 3.7189395427703857, acc: 0.3254437744617462)
[2024-12-17 01:59:13,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,083][root][INFO] - Training Epoch: 1/2, step 3250/7134 completed (loss: 3.3809196949005127, acc: 0.3772455155849457)
[2024-12-17 01:59:14,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,458][root][INFO] - Training Epoch: 1/2, step 3251/7134 completed (loss: 3.8461248874664307, acc: 0.2884615361690521)
[2024-12-17 01:59:14,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:14,844][root][INFO] - Training Epoch: 1/2, step 3252/7134 completed (loss: 3.8077168464660645, acc: 0.3253012001514435)
[2024-12-17 01:59:14,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,239][root][INFO] - Training Epoch: 1/2, step 3253/7134 completed (loss: 3.552283525466919, acc: 0.3486842215061188)
[2024-12-17 01:59:15,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:15,624][root][INFO] - Training Epoch: 1/2, step 3254/7134 completed (loss: 3.434509754180908, acc: 0.350649356842041)
[2024-12-17 01:59:15,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,001][root][INFO] - Training Epoch: 1/2, step 3255/7134 completed (loss: 3.4211013317108154, acc: 0.40340909361839294)
[2024-12-17 01:59:16,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,387][root][INFO] - Training Epoch: 1/2, step 3256/7134 completed (loss: 3.6469547748565674, acc: 0.3229813575744629)
[2024-12-17 01:59:16,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:16,758][root][INFO] - Training Epoch: 1/2, step 3257/7134 completed (loss: 3.9542036056518555, acc: 0.31515151262283325)
[2024-12-17 01:59:16,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,158][root][INFO] - Training Epoch: 1/2, step 3258/7134 completed (loss: 4.459631443023682, acc: 0.31707316637039185)
[2024-12-17 01:59:17,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,548][root][INFO] - Training Epoch: 1/2, step 3259/7134 completed (loss: 3.6688027381896973, acc: 0.35403725504875183)
[2024-12-17 01:59:17,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:17,924][root][INFO] - Training Epoch: 1/2, step 3260/7134 completed (loss: 4.129129409790039, acc: 0.32413792610168457)
[2024-12-17 01:59:18,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,304][root][INFO] - Training Epoch: 1/2, step 3261/7134 completed (loss: 4.257894039154053, acc: 0.35036495327949524)
[2024-12-17 01:59:18,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:18,685][root][INFO] - Training Epoch: 1/2, step 3262/7134 completed (loss: 4.171494483947754, acc: 0.2777777910232544)
[2024-12-17 01:59:18,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,073][root][INFO] - Training Epoch: 1/2, step 3263/7134 completed (loss: 4.014626502990723, acc: 0.3136094808578491)
[2024-12-17 01:59:19,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,445][root][INFO] - Training Epoch: 1/2, step 3264/7134 completed (loss: 3.8103396892547607, acc: 0.3353658616542816)
[2024-12-17 01:59:19,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:19,843][root][INFO] - Training Epoch: 1/2, step 3265/7134 completed (loss: 4.114974498748779, acc: 0.2738853394985199)
[2024-12-17 01:59:19,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,227][root][INFO] - Training Epoch: 1/2, step 3266/7134 completed (loss: 4.248617649078369, acc: 0.2827586233615875)
[2024-12-17 01:59:20,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,620][root][INFO] - Training Epoch: 1/2, step 3267/7134 completed (loss: 4.090298175811768, acc: 0.27878788113594055)
[2024-12-17 01:59:20,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:20,988][root][INFO] - Training Epoch: 1/2, step 3268/7134 completed (loss: 2.938034772872925, acc: 0.3767123222351074)
[2024-12-17 01:59:21,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,368][root][INFO] - Training Epoch: 1/2, step 3269/7134 completed (loss: 3.4799857139587402, acc: 0.34574466943740845)
[2024-12-17 01:59:21,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:21,759][root][INFO] - Training Epoch: 1/2, step 3270/7134 completed (loss: 3.6403110027313232, acc: 0.3567567467689514)
[2024-12-17 01:59:21,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,122][root][INFO] - Training Epoch: 1/2, step 3271/7134 completed (loss: 3.956554651260376, acc: 0.3239436745643616)
[2024-12-17 01:59:22,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,494][root][INFO] - Training Epoch: 1/2, step 3272/7134 completed (loss: 3.9176199436187744, acc: 0.25999999046325684)
[2024-12-17 01:59:22,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:22,875][root][INFO] - Training Epoch: 1/2, step 3273/7134 completed (loss: 3.631986618041992, acc: 0.3142857253551483)
[2024-12-17 01:59:22,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,248][root][INFO] - Training Epoch: 1/2, step 3274/7134 completed (loss: 3.7415647506713867, acc: 0.3478260934352875)
[2024-12-17 01:59:23,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:23,643][root][INFO] - Training Epoch: 1/2, step 3275/7134 completed (loss: 4.355533599853516, acc: 0.257485032081604)
[2024-12-17 01:59:23,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,028][root][INFO] - Training Epoch: 1/2, step 3276/7134 completed (loss: 4.151316165924072, acc: 0.29411765933036804)
[2024-12-17 01:59:24,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,428][root][INFO] - Training Epoch: 1/2, step 3277/7134 completed (loss: 4.227739334106445, acc: 0.2733812928199768)
[2024-12-17 01:59:24,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:24,792][root][INFO] - Training Epoch: 1/2, step 3278/7134 completed (loss: 3.9131932258605957, acc: 0.35483869910240173)
[2024-12-17 01:59:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,179][root][INFO] - Training Epoch: 1/2, step 3279/7134 completed (loss: 3.916930675506592, acc: 0.33529412746429443)
[2024-12-17 01:59:25,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,595][root][INFO] - Training Epoch: 1/2, step 3280/7134 completed (loss: 4.544093132019043, acc: 0.26923078298568726)
[2024-12-17 01:59:25,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:25,984][root][INFO] - Training Epoch: 1/2, step 3281/7134 completed (loss: 4.012729167938232, acc: 0.31292515993118286)
[2024-12-17 01:59:26,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,359][root][INFO] - Training Epoch: 1/2, step 3282/7134 completed (loss: 3.8088743686676025, acc: 0.35877862572669983)
[2024-12-17 01:59:26,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:26,738][root][INFO] - Training Epoch: 1/2, step 3283/7134 completed (loss: 4.180715084075928, acc: 0.2647058963775635)
[2024-12-17 01:59:26,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,109][root][INFO] - Training Epoch: 1/2, step 3284/7134 completed (loss: 3.6773252487182617, acc: 0.33103448152542114)
[2024-12-17 01:59:27,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,488][root][INFO] - Training Epoch: 1/2, step 3285/7134 completed (loss: 4.227048397064209, acc: 0.2647058963775635)
[2024-12-17 01:59:27,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:27,864][root][INFO] - Training Epoch: 1/2, step 3286/7134 completed (loss: 4.023293972015381, acc: 0.30000001192092896)
[2024-12-17 01:59:27,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,236][root][INFO] - Training Epoch: 1/2, step 3287/7134 completed (loss: 4.135744571685791, acc: 0.2666666805744171)
[2024-12-17 01:59:28,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,623][root][INFO] - Training Epoch: 1/2, step 3288/7134 completed (loss: 4.098871231079102, acc: 0.3093525171279907)
[2024-12-17 01:59:28,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:28,982][root][INFO] - Training Epoch: 1/2, step 3289/7134 completed (loss: 4.649814605712891, acc: 0.25)
[2024-12-17 01:59:29,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,353][root][INFO] - Training Epoch: 1/2, step 3290/7134 completed (loss: 4.395442485809326, acc: 0.23529411852359772)
[2024-12-17 01:59:29,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:29,736][root][INFO] - Training Epoch: 1/2, step 3291/7134 completed (loss: 4.4198126792907715, acc: 0.30693069100379944)
[2024-12-17 01:59:29,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,135][root][INFO] - Training Epoch: 1/2, step 3292/7134 completed (loss: 4.206789493560791, acc: 0.22689075767993927)
[2024-12-17 01:59:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,527][root][INFO] - Training Epoch: 1/2, step 3293/7134 completed (loss: 4.314505100250244, acc: 0.25757575035095215)
[2024-12-17 01:59:30,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:30,908][root][INFO] - Training Epoch: 1/2, step 3294/7134 completed (loss: 4.256083965301514, acc: 0.28787878155708313)
[2024-12-17 01:59:30,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,247][root][INFO] - Training Epoch: 1/2, step 3295/7134 completed (loss: 3.851943016052246, acc: 0.27419355511665344)
[2024-12-17 01:59:31,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,605][root][INFO] - Training Epoch: 1/2, step 3296/7134 completed (loss: 4.037286281585693, acc: 0.35384616255760193)
[2024-12-17 01:59:31,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:31,955][root][INFO] - Training Epoch: 1/2, step 3297/7134 completed (loss: 4.612268447875977, acc: 0.24528302252292633)
[2024-12-17 01:59:32,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,383][root][INFO] - Training Epoch: 1/2, step 3298/7134 completed (loss: 4.074646472930908, acc: 0.308270663022995)
[2024-12-17 01:59:32,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:32,755][root][INFO] - Training Epoch: 1/2, step 3299/7134 completed (loss: 4.1775221824646, acc: 0.27559053897857666)
[2024-12-17 01:59:32,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,110][root][INFO] - Training Epoch: 1/2, step 3300/7134 completed (loss: 3.7807538509368896, acc: 0.3909774422645569)
[2024-12-17 01:59:33,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,460][root][INFO] - Training Epoch: 1/2, step 3301/7134 completed (loss: 3.8208956718444824, acc: 0.291262149810791)
[2024-12-17 01:59:33,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:33,808][root][INFO] - Training Epoch: 1/2, step 3302/7134 completed (loss: 3.741015911102295, acc: 0.251748263835907)
[2024-12-17 01:59:33,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,135][root][INFO] - Training Epoch: 1/2, step 3303/7134 completed (loss: 3.930724859237671, acc: 0.2574257552623749)
[2024-12-17 01:59:34,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,505][root][INFO] - Training Epoch: 1/2, step 3304/7134 completed (loss: 3.7332968711853027, acc: 0.31192660331726074)
[2024-12-17 01:59:34,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:34,863][root][INFO] - Training Epoch: 1/2, step 3305/7134 completed (loss: 3.693787097930908, acc: 0.28930819034576416)
[2024-12-17 01:59:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,249][root][INFO] - Training Epoch: 1/2, step 3306/7134 completed (loss: 3.970808744430542, acc: 0.28735631704330444)
[2024-12-17 01:59:35,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,597][root][INFO] - Training Epoch: 1/2, step 3307/7134 completed (loss: 3.7083723545074463, acc: 0.2888889014720917)
[2024-12-17 01:59:35,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:35,952][root][INFO] - Training Epoch: 1/2, step 3308/7134 completed (loss: 3.865464925765991, acc: 0.3117647171020508)
[2024-12-17 01:59:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,300][root][INFO] - Training Epoch: 1/2, step 3309/7134 completed (loss: 4.060996055603027, acc: 0.3333333432674408)
[2024-12-17 01:59:36,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:36,672][root][INFO] - Training Epoch: 1/2, step 3310/7134 completed (loss: 3.9178617000579834, acc: 0.290909081697464)
[2024-12-17 01:59:36,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,016][root][INFO] - Training Epoch: 1/2, step 3311/7134 completed (loss: 4.152625560760498, acc: 0.30693069100379944)
[2024-12-17 01:59:37,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,379][root][INFO] - Training Epoch: 1/2, step 3312/7134 completed (loss: 3.720275402069092, acc: 0.33834585547447205)
[2024-12-17 01:59:37,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:37,744][root][INFO] - Training Epoch: 1/2, step 3313/7134 completed (loss: 4.948756694793701, acc: 0.18367347121238708)
[2024-12-17 01:59:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,140][root][INFO] - Training Epoch: 1/2, step 3314/7134 completed (loss: 4.68924617767334, acc: 0.2293577939271927)
[2024-12-17 01:59:38,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,538][root][INFO] - Training Epoch: 1/2, step 3315/7134 completed (loss: 4.204470634460449, acc: 0.23668639361858368)
[2024-12-17 01:59:38,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:38,945][root][INFO] - Training Epoch: 1/2, step 3316/7134 completed (loss: 4.070911884307861, acc: 0.3283582031726837)
[2024-12-17 01:59:39,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,321][root][INFO] - Training Epoch: 1/2, step 3317/7134 completed (loss: 3.5010106563568115, acc: 0.3801652789115906)
[2024-12-17 01:59:39,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:39,632][root][INFO] - Training Epoch: 1/2, step 3318/7134 completed (loss: 3.8814754486083984, acc: 0.33898305892944336)
[2024-12-17 01:59:39,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,000][root][INFO] - Training Epoch: 1/2, step 3319/7134 completed (loss: 3.9882543087005615, acc: 0.2753623127937317)
[2024-12-17 01:59:40,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,372][root][INFO] - Training Epoch: 1/2, step 3320/7134 completed (loss: 3.530919075012207, acc: 0.3672316372394562)
[2024-12-17 01:59:40,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:40,734][root][INFO] - Training Epoch: 1/2, step 3321/7134 completed (loss: 4.093742847442627, acc: 0.2857142984867096)
[2024-12-17 01:59:40,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,117][root][INFO] - Training Epoch: 1/2, step 3322/7134 completed (loss: 4.049473762512207, acc: 0.28947368264198303)
[2024-12-17 01:59:41,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,486][root][INFO] - Training Epoch: 1/2, step 3323/7134 completed (loss: 3.972496271133423, acc: 0.2982456088066101)
[2024-12-17 01:59:41,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:41,881][root][INFO] - Training Epoch: 1/2, step 3324/7134 completed (loss: 4.297752380371094, acc: 0.26424869894981384)
[2024-12-17 01:59:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,252][root][INFO] - Training Epoch: 1/2, step 3325/7134 completed (loss: 4.129894733428955, acc: 0.299401193857193)
[2024-12-17 01:59:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,608][root][INFO] - Training Epoch: 1/2, step 3326/7134 completed (loss: 3.7846364974975586, acc: 0.32121211290359497)
[2024-12-17 01:59:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:42,964][root][INFO] - Training Epoch: 1/2, step 3327/7134 completed (loss: 3.493361234664917, acc: 0.3480663001537323)
[2024-12-17 01:59:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,342][root][INFO] - Training Epoch: 1/2, step 3328/7134 completed (loss: 3.6644904613494873, acc: 0.3723404109477997)
[2024-12-17 01:59:43,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:43,766][root][INFO] - Training Epoch: 1/2, step 3329/7134 completed (loss: 4.236521244049072, acc: 0.2708333432674408)
[2024-12-17 01:59:43,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,136][root][INFO] - Training Epoch: 1/2, step 3330/7134 completed (loss: 3.7278385162353516, acc: 0.31794872879981995)
[2024-12-17 01:59:44,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,507][root][INFO] - Training Epoch: 1/2, step 3331/7134 completed (loss: 4.166162490844727, acc: 0.3372780978679657)
[2024-12-17 01:59:44,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:44,876][root][INFO] - Training Epoch: 1/2, step 3332/7134 completed (loss: 4.092909336090088, acc: 0.2666666805744171)
[2024-12-17 01:59:44,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,221][root][INFO] - Training Epoch: 1/2, step 3333/7134 completed (loss: 4.51436710357666, acc: 0.260869562625885)
[2024-12-17 01:59:45,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,584][root][INFO] - Training Epoch: 1/2, step 3334/7134 completed (loss: 4.00768518447876, acc: 0.31521740555763245)
[2024-12-17 01:59:45,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:45,958][root][INFO] - Training Epoch: 1/2, step 3335/7134 completed (loss: 3.3675007820129395, acc: 0.2933333218097687)
[2024-12-17 01:59:46,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,296][root][INFO] - Training Epoch: 1/2, step 3336/7134 completed (loss: 3.223863124847412, acc: 0.41916167736053467)
[2024-12-17 01:59:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:46,661][root][INFO] - Training Epoch: 1/2, step 3337/7134 completed (loss: 3.304401159286499, acc: 0.3361344635486603)
[2024-12-17 01:59:46,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,029][root][INFO] - Training Epoch: 1/2, step 3338/7134 completed (loss: 3.2281484603881836, acc: 0.31606218218803406)
[2024-12-17 01:59:47,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,399][root][INFO] - Training Epoch: 1/2, step 3339/7134 completed (loss: 3.26088547706604, acc: 0.3719806671142578)
[2024-12-17 01:59:47,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:47,760][root][INFO] - Training Epoch: 1/2, step 3340/7134 completed (loss: 4.256432056427002, acc: 0.2797619104385376)
[2024-12-17 01:59:47,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,130][root][INFO] - Training Epoch: 1/2, step 3341/7134 completed (loss: 3.8427629470825195, acc: 0.3353293538093567)
[2024-12-17 01:59:48,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,495][root][INFO] - Training Epoch: 1/2, step 3342/7134 completed (loss: 3.7114830017089844, acc: 0.36986300349235535)
[2024-12-17 01:59:48,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:48,884][root][INFO] - Training Epoch: 1/2, step 3343/7134 completed (loss: 3.9853851795196533, acc: 0.3534482717514038)
[2024-12-17 01:59:48,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,267][root][INFO] - Training Epoch: 1/2, step 3344/7134 completed (loss: 3.64855694770813, acc: 0.2867647111415863)
[2024-12-17 01:59:49,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:49,662][root][INFO] - Training Epoch: 1/2, step 3345/7134 completed (loss: 3.9085628986358643, acc: 0.3076923191547394)
[2024-12-17 01:59:49,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,045][root][INFO] - Training Epoch: 1/2, step 3346/7134 completed (loss: 3.9057412147521973, acc: 0.29878050088882446)
[2024-12-17 01:59:50,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,422][root][INFO] - Training Epoch: 1/2, step 3347/7134 completed (loss: 4.482484817504883, acc: 0.20915032923221588)
[2024-12-17 01:59:50,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:50,788][root][INFO] - Training Epoch: 1/2, step 3348/7134 completed (loss: 4.210000038146973, acc: 0.2405063360929489)
[2024-12-17 01:59:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,178][root][INFO] - Training Epoch: 1/2, step 3349/7134 completed (loss: 4.101898193359375, acc: 0.2945736348628998)
[2024-12-17 01:59:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,597][root][INFO] - Training Epoch: 1/2, step 3350/7134 completed (loss: 3.650434970855713, acc: 0.28925618529319763)
[2024-12-17 01:59:51,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:51,976][root][INFO] - Training Epoch: 1/2, step 3351/7134 completed (loss: 4.336667537689209, acc: 0.26595744490623474)
[2024-12-17 01:59:52,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,394][root][INFO] - Training Epoch: 1/2, step 3352/7134 completed (loss: 3.9914352893829346, acc: 0.2888889014720917)
[2024-12-17 01:59:52,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:52,763][root][INFO] - Training Epoch: 1/2, step 3353/7134 completed (loss: 3.659487009048462, acc: 0.3008130192756653)
[2024-12-17 01:59:52,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,130][root][INFO] - Training Epoch: 1/2, step 3354/7134 completed (loss: 3.751807928085327, acc: 0.3164556920528412)
[2024-12-17 01:59:53,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,527][root][INFO] - Training Epoch: 1/2, step 3355/7134 completed (loss: 3.5789589881896973, acc: 0.35975611209869385)
[2024-12-17 01:59:53,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:53,932][root][INFO] - Training Epoch: 1/2, step 3356/7134 completed (loss: 3.7720582485198975, acc: 0.3185185194015503)
[2024-12-17 01:59:54,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,320][root][INFO] - Training Epoch: 1/2, step 3357/7134 completed (loss: 3.6520261764526367, acc: 0.329341322183609)
[2024-12-17 01:59:54,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:54,712][root][INFO] - Training Epoch: 1/2, step 3358/7134 completed (loss: 4.7958502769470215, acc: 0.25)
[2024-12-17 01:59:54,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,097][root][INFO] - Training Epoch: 1/2, step 3359/7134 completed (loss: 3.942803382873535, acc: 0.3287671208381653)
[2024-12-17 01:59:55,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,487][root][INFO] - Training Epoch: 1/2, step 3360/7134 completed (loss: 3.8372926712036133, acc: 0.2869565188884735)
[2024-12-17 01:59:55,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:55,835][root][INFO] - Training Epoch: 1/2, step 3361/7134 completed (loss: 4.210216045379639, acc: 0.3482142984867096)
[2024-12-17 01:59:55,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,198][root][INFO] - Training Epoch: 1/2, step 3362/7134 completed (loss: 4.316364288330078, acc: 0.290909081697464)
[2024-12-17 01:59:56,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,542][root][INFO] - Training Epoch: 1/2, step 3363/7134 completed (loss: 4.06033992767334, acc: 0.3177570104598999)
[2024-12-17 01:59:56,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:56,947][root][INFO] - Training Epoch: 1/2, step 3364/7134 completed (loss: 4.4687089920043945, acc: 0.3137255012989044)
[2024-12-17 01:59:57,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,314][root][INFO] - Training Epoch: 1/2, step 3365/7134 completed (loss: 3.877190351486206, acc: 0.29203540086746216)
[2024-12-17 01:59:57,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:57,676][root][INFO] - Training Epoch: 1/2, step 3366/7134 completed (loss: 4.082045555114746, acc: 0.2777777910232544)
[2024-12-17 01:59:57,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,072][root][INFO] - Training Epoch: 1/2, step 3367/7134 completed (loss: 3.7371535301208496, acc: 0.30481284856796265)
[2024-12-17 01:59:58,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,460][root][INFO] - Training Epoch: 1/2, step 3368/7134 completed (loss: 3.8640317916870117, acc: 0.27950310707092285)
[2024-12-17 01:59:58,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:58,841][root][INFO] - Training Epoch: 1/2, step 3369/7134 completed (loss: 3.901524782180786, acc: 0.3243243098258972)
[2024-12-17 01:59:58,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,221][root][INFO] - Training Epoch: 1/2, step 3370/7134 completed (loss: 3.6930320262908936, acc: 0.33128833770751953)
[2024-12-17 01:59:59,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,583][root][INFO] - Training Epoch: 1/2, step 3371/7134 completed (loss: 3.444096803665161, acc: 0.3472222089767456)
[2024-12-17 01:59:59,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 01:59:59,950][root][INFO] - Training Epoch: 1/2, step 3372/7134 completed (loss: 4.054692268371582, acc: 0.2448979616165161)
[2024-12-17 02:00:00,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,313][root][INFO] - Training Epoch: 1/2, step 3373/7134 completed (loss: 3.705165386199951, acc: 0.32679739594459534)
[2024-12-17 02:00:00,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:00,699][root][INFO] - Training Epoch: 1/2, step 3374/7134 completed (loss: 3.6590981483459473, acc: 0.36000001430511475)
[2024-12-17 02:00:00,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,085][root][INFO] - Training Epoch: 1/2, step 3375/7134 completed (loss: 3.850745677947998, acc: 0.3353293538093567)
[2024-12-17 02:00:01,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,470][root][INFO] - Training Epoch: 1/2, step 3376/7134 completed (loss: 3.2920119762420654, acc: 0.3650793731212616)
[2024-12-17 02:00:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:01,867][root][INFO] - Training Epoch: 1/2, step 3377/7134 completed (loss: 3.3999528884887695, acc: 0.30150753259658813)
[2024-12-17 02:00:01,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,230][root][INFO] - Training Epoch: 1/2, step 3378/7134 completed (loss: 2.9841010570526123, acc: 0.43421053886413574)
[2024-12-17 02:00:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,601][root][INFO] - Training Epoch: 1/2, step 3379/7134 completed (loss: 3.51814341545105, acc: 0.3581081032752991)
[2024-12-17 02:00:02,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:02,995][root][INFO] - Training Epoch: 1/2, step 3380/7134 completed (loss: 3.580387830734253, acc: 0.3695652186870575)
[2024-12-17 02:00:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,376][root][INFO] - Training Epoch: 1/2, step 3381/7134 completed (loss: 3.501474618911743, acc: 0.31707316637039185)
[2024-12-17 02:00:03,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:03,755][root][INFO] - Training Epoch: 1/2, step 3382/7134 completed (loss: 3.3666768074035645, acc: 0.3359375)
[2024-12-17 02:00:03,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,139][root][INFO] - Training Epoch: 1/2, step 3383/7134 completed (loss: 3.7352943420410156, acc: 0.31468531489372253)
[2024-12-17 02:00:04,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,489][root][INFO] - Training Epoch: 1/2, step 3384/7134 completed (loss: 3.846646785736084, acc: 0.34306567907333374)
[2024-12-17 02:00:04,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:04,850][root][INFO] - Training Epoch: 1/2, step 3385/7134 completed (loss: 3.0032248497009277, acc: 0.4027777910232544)
[2024-12-17 02:00:04,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,215][root][INFO] - Training Epoch: 1/2, step 3386/7134 completed (loss: 3.7019588947296143, acc: 0.30177515745162964)
[2024-12-17 02:00:05,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,583][root][INFO] - Training Epoch: 1/2, step 3387/7134 completed (loss: 3.928846836090088, acc: 0.2848837077617645)
[2024-12-17 02:00:05,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:05,956][root][INFO] - Training Epoch: 1/2, step 3388/7134 completed (loss: 4.087650299072266, acc: 0.29914531111717224)
[2024-12-17 02:00:06,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,327][root][INFO] - Training Epoch: 1/2, step 3389/7134 completed (loss: 3.4952850341796875, acc: 0.30054643750190735)
[2024-12-17 02:00:06,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:06,699][root][INFO] - Training Epoch: 1/2, step 3390/7134 completed (loss: 4.194192409515381, acc: 0.23863635957241058)
[2024-12-17 02:00:06,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,056][root][INFO] - Training Epoch: 1/2, step 3391/7134 completed (loss: 4.00717306137085, acc: 0.29878050088882446)
[2024-12-17 02:00:07,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,403][root][INFO] - Training Epoch: 1/2, step 3392/7134 completed (loss: 3.9431869983673096, acc: 0.3206106722354889)
[2024-12-17 02:00:07,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:07,748][root][INFO] - Training Epoch: 1/2, step 3393/7134 completed (loss: 4.279245376586914, acc: 0.31468531489372253)
[2024-12-17 02:00:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,118][root][INFO] - Training Epoch: 1/2, step 3394/7134 completed (loss: 4.767570495605469, acc: 0.24285714328289032)
[2024-12-17 02:00:08,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,480][root][INFO] - Training Epoch: 1/2, step 3395/7134 completed (loss: 4.247612953186035, acc: 0.32236841320991516)
[2024-12-17 02:00:08,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:08,879][root][INFO] - Training Epoch: 1/2, step 3396/7134 completed (loss: 3.6629929542541504, acc: 0.3365384638309479)
[2024-12-17 02:00:08,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,263][root][INFO] - Training Epoch: 1/2, step 3397/7134 completed (loss: 3.873047113418579, acc: 0.27860695123672485)
[2024-12-17 02:00:09,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:09,641][root][INFO] - Training Epoch: 1/2, step 3398/7134 completed (loss: 4.153853416442871, acc: 0.239130437374115)
[2024-12-17 02:00:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,021][root][INFO] - Training Epoch: 1/2, step 3399/7134 completed (loss: 4.109270095825195, acc: 0.2569444477558136)
[2024-12-17 02:00:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,434][root][INFO] - Training Epoch: 1/2, step 3400/7134 completed (loss: 4.193437099456787, acc: 0.23622047901153564)
[2024-12-17 02:00:10,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:10,831][root][INFO] - Training Epoch: 1/2, step 3401/7134 completed (loss: 3.8015012741088867, acc: 0.2857142984867096)
[2024-12-17 02:00:10,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,232][root][INFO] - Training Epoch: 1/2, step 3402/7134 completed (loss: 4.030773162841797, acc: 0.29411765933036804)
[2024-12-17 02:00:11,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:11,690][root][INFO] - Training Epoch: 1/2, step 3403/7134 completed (loss: 3.939469575881958, acc: 0.28282827138900757)
[2024-12-17 02:00:11,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,062][root][INFO] - Training Epoch: 1/2, step 3404/7134 completed (loss: 4.0279035568237305, acc: 0.2515723407268524)
[2024-12-17 02:00:12,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,449][root][INFO] - Training Epoch: 1/2, step 3405/7134 completed (loss: 4.033423900604248, acc: 0.3014705777168274)
[2024-12-17 02:00:12,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:12,825][root][INFO] - Training Epoch: 1/2, step 3406/7134 completed (loss: 4.1520609855651855, acc: 0.27000001072883606)
[2024-12-17 02:00:12,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,174][root][INFO] - Training Epoch: 1/2, step 3407/7134 completed (loss: 3.7191083431243896, acc: 0.29447853565216064)
[2024-12-17 02:00:13,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,538][root][INFO] - Training Epoch: 1/2, step 3408/7134 completed (loss: 3.9048359394073486, acc: 0.3207547068595886)
[2024-12-17 02:00:13,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:13,931][root][INFO] - Training Epoch: 1/2, step 3409/7134 completed (loss: 4.0676116943359375, acc: 0.2931034564971924)
[2024-12-17 02:00:14,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,305][root][INFO] - Training Epoch: 1/2, step 3410/7134 completed (loss: 4.363344192504883, acc: 0.29878050088882446)
[2024-12-17 02:00:14,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:14,693][root][INFO] - Training Epoch: 1/2, step 3411/7134 completed (loss: 3.533729314804077, acc: 0.35164836049079895)
[2024-12-17 02:00:14,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,060][root][INFO] - Training Epoch: 1/2, step 3412/7134 completed (loss: 4.1598029136657715, acc: 0.34166666865348816)
[2024-12-17 02:00:15,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,446][root][INFO] - Training Epoch: 1/2, step 3413/7134 completed (loss: 3.6938838958740234, acc: 0.2649572789669037)
[2024-12-17 02:00:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:15,815][root][INFO] - Training Epoch: 1/2, step 3414/7134 completed (loss: 3.6731491088867188, acc: 0.3194444477558136)
[2024-12-17 02:00:15,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,207][root][INFO] - Training Epoch: 1/2, step 3415/7134 completed (loss: 4.048610687255859, acc: 0.30000001192092896)
[2024-12-17 02:00:16,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,596][root][INFO] - Training Epoch: 1/2, step 3416/7134 completed (loss: 4.0092902183532715, acc: 0.2950819730758667)
[2024-12-17 02:00:16,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:16,963][root][INFO] - Training Epoch: 1/2, step 3417/7134 completed (loss: 4.053586006164551, acc: 0.269461065530777)
[2024-12-17 02:00:17,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,377][root][INFO] - Training Epoch: 1/2, step 3418/7134 completed (loss: 4.061636924743652, acc: 0.23312883079051971)
[2024-12-17 02:00:17,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:17,756][root][INFO] - Training Epoch: 1/2, step 3419/7134 completed (loss: 3.7816433906555176, acc: 0.3132530152797699)
[2024-12-17 02:00:17,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,152][root][INFO] - Training Epoch: 1/2, step 3420/7134 completed (loss: 3.770761728286743, acc: 0.2847682237625122)
[2024-12-17 02:00:18,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,553][root][INFO] - Training Epoch: 1/2, step 3421/7134 completed (loss: 3.999422550201416, acc: 0.3076923191547394)
[2024-12-17 02:00:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:18,931][root][INFO] - Training Epoch: 1/2, step 3422/7134 completed (loss: 3.667344093322754, acc: 0.2867647111415863)
[2024-12-17 02:00:19,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,329][root][INFO] - Training Epoch: 1/2, step 3423/7134 completed (loss: 3.486936092376709, acc: 0.40789473056793213)
[2024-12-17 02:00:19,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:19,720][root][INFO] - Training Epoch: 1/2, step 3424/7134 completed (loss: 3.6370487213134766, acc: 0.3733333349227905)
[2024-12-17 02:00:19,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,123][root][INFO] - Training Epoch: 1/2, step 3425/7134 completed (loss: 3.8353676795959473, acc: 0.3263157904148102)
[2024-12-17 02:00:20,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,502][root][INFO] - Training Epoch: 1/2, step 3426/7134 completed (loss: 3.5693893432617188, acc: 0.2797619104385376)
[2024-12-17 02:00:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:20,892][root][INFO] - Training Epoch: 1/2, step 3427/7134 completed (loss: 3.556546688079834, acc: 0.31168830394744873)
[2024-12-17 02:00:20,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,276][root][INFO] - Training Epoch: 1/2, step 3428/7134 completed (loss: 3.477419137954712, acc: 0.25882354378700256)
[2024-12-17 02:00:21,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:21,670][root][INFO] - Training Epoch: 1/2, step 3429/7134 completed (loss: 3.6716995239257812, acc: 0.3732394278049469)
[2024-12-17 02:00:21,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,073][root][INFO] - Training Epoch: 1/2, step 3430/7134 completed (loss: 3.8403286933898926, acc: 0.3219178020954132)
[2024-12-17 02:00:22,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,454][root][INFO] - Training Epoch: 1/2, step 3431/7134 completed (loss: 3.7485523223876953, acc: 0.28985506296157837)
[2024-12-17 02:00:22,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:22,847][root][INFO] - Training Epoch: 1/2, step 3432/7134 completed (loss: 3.3566055297851562, acc: 0.38650307059288025)
[2024-12-17 02:00:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,256][root][INFO] - Training Epoch: 1/2, step 3433/7134 completed (loss: 4.0232133865356445, acc: 0.30882352590560913)
[2024-12-17 02:00:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:23,649][root][INFO] - Training Epoch: 1/2, step 3434/7134 completed (loss: 3.439096212387085, acc: 0.3499999940395355)
[2024-12-17 02:00:23,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,045][root][INFO] - Training Epoch: 1/2, step 3435/7134 completed (loss: 4.436427116394043, acc: 0.19310344755649567)
[2024-12-17 02:00:24,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,436][root][INFO] - Training Epoch: 1/2, step 3436/7134 completed (loss: 4.613446235656738, acc: 0.20437955856323242)
[2024-12-17 02:00:24,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:24,816][root][INFO] - Training Epoch: 1/2, step 3437/7134 completed (loss: 4.811499118804932, acc: 0.21487602591514587)
[2024-12-17 02:00:24,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,206][root][INFO] - Training Epoch: 1/2, step 3438/7134 completed (loss: 4.627606391906738, acc: 0.2368421107530594)
[2024-12-17 02:00:25,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,588][root][INFO] - Training Epoch: 1/2, step 3439/7134 completed (loss: 4.668922424316406, acc: 0.2936508059501648)
[2024-12-17 02:00:25,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:25,990][root][INFO] - Training Epoch: 1/2, step 3440/7134 completed (loss: 4.302845478057861, acc: 0.2844827473163605)
[2024-12-17 02:00:26,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,370][root][INFO] - Training Epoch: 1/2, step 3441/7134 completed (loss: 3.932330846786499, acc: 0.39534884691238403)
[2024-12-17 02:00:26,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:26,759][root][INFO] - Training Epoch: 1/2, step 3442/7134 completed (loss: 3.819936752319336, acc: 0.326241135597229)
[2024-12-17 02:00:26,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,137][root][INFO] - Training Epoch: 1/2, step 3443/7134 completed (loss: 3.9235618114471436, acc: 0.3820224702358246)
[2024-12-17 02:00:27,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,525][root][INFO] - Training Epoch: 1/2, step 3444/7134 completed (loss: 3.9766414165496826, acc: 0.25477707386016846)
[2024-12-17 02:00:27,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:27,903][root][INFO] - Training Epoch: 1/2, step 3445/7134 completed (loss: 3.757128953933716, acc: 0.27819550037384033)
[2024-12-17 02:00:28,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,303][root][INFO] - Training Epoch: 1/2, step 3446/7134 completed (loss: 4.162576675415039, acc: 0.273333340883255)
[2024-12-17 02:00:28,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:28,704][root][INFO] - Training Epoch: 1/2, step 3447/7134 completed (loss: 4.407782077789307, acc: 0.3086419701576233)
[2024-12-17 02:00:28,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,193][root][INFO] - Training Epoch: 1/2, step 3448/7134 completed (loss: 3.9948596954345703, acc: 0.3179190754890442)
[2024-12-17 02:00:29,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:29,620][root][INFO] - Training Epoch: 1/2, step 3449/7134 completed (loss: 4.410750389099121, acc: 0.24752475321292877)
[2024-12-17 02:00:29,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,005][root][INFO] - Training Epoch: 1/2, step 3450/7134 completed (loss: 4.901014804840088, acc: 0.19607843458652496)
[2024-12-17 02:00:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,392][root][INFO] - Training Epoch: 1/2, step 3451/7134 completed (loss: 5.183219909667969, acc: 0.1702127605676651)
[2024-12-17 02:00:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:30,777][root][INFO] - Training Epoch: 1/2, step 3452/7134 completed (loss: 5.419644832611084, acc: 0.1869918704032898)
[2024-12-17 02:00:30,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,160][root][INFO] - Training Epoch: 1/2, step 3453/7134 completed (loss: 4.0546979904174805, acc: 0.2847222089767456)
[2024-12-17 02:00:31,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,567][root][INFO] - Training Epoch: 1/2, step 3454/7134 completed (loss: 4.437445640563965, acc: 0.2650602459907532)
[2024-12-17 02:00:31,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:31,958][root][INFO] - Training Epoch: 1/2, step 3455/7134 completed (loss: 3.325643301010132, acc: 0.32919254899024963)
[2024-12-17 02:00:32,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,356][root][INFO] - Training Epoch: 1/2, step 3456/7134 completed (loss: 3.25734281539917, acc: 0.34170854091644287)
[2024-12-17 02:00:32,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:32,742][root][INFO] - Training Epoch: 1/2, step 3457/7134 completed (loss: 3.7030200958251953, acc: 0.31690141558647156)
[2024-12-17 02:00:32,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,140][root][INFO] - Training Epoch: 1/2, step 3458/7134 completed (loss: 3.6291306018829346, acc: 0.32967033982276917)
[2024-12-17 02:00:33,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,510][root][INFO] - Training Epoch: 1/2, step 3459/7134 completed (loss: 3.787209987640381, acc: 0.29559749364852905)
[2024-12-17 02:00:33,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:33,889][root][INFO] - Training Epoch: 1/2, step 3460/7134 completed (loss: 4.278034210205078, acc: 0.2525252401828766)
[2024-12-17 02:00:34,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,301][root][INFO] - Training Epoch: 1/2, step 3461/7134 completed (loss: 4.596721649169922, acc: 0.23076923191547394)
[2024-12-17 02:00:34,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:34,674][root][INFO] - Training Epoch: 1/2, step 3462/7134 completed (loss: 3.912952184677124, acc: 0.2982456088066101)
[2024-12-17 02:00:34,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,082][root][INFO] - Training Epoch: 1/2, step 3463/7134 completed (loss: 3.5812294483184814, acc: 0.32098764181137085)
[2024-12-17 02:00:35,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,486][root][INFO] - Training Epoch: 1/2, step 3464/7134 completed (loss: 4.172077178955078, acc: 0.2808988690376282)
[2024-12-17 02:00:35,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:35,858][root][INFO] - Training Epoch: 1/2, step 3465/7134 completed (loss: 3.698021173477173, acc: 0.3037036955356598)
[2024-12-17 02:00:35,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,216][root][INFO] - Training Epoch: 1/2, step 3466/7134 completed (loss: 4.024864196777344, acc: 0.29012346267700195)
[2024-12-17 02:00:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:36,614][root][INFO] - Training Epoch: 1/2, step 3467/7134 completed (loss: 3.6355528831481934, acc: 0.3050847351551056)
[2024-12-17 02:00:36,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,008][root][INFO] - Training Epoch: 1/2, step 3468/7134 completed (loss: 4.0946760177612305, acc: 0.21710526943206787)
[2024-12-17 02:00:37,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,384][root][INFO] - Training Epoch: 1/2, step 3469/7134 completed (loss: 4.232320308685303, acc: 0.30075186491012573)
[2024-12-17 02:00:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:37,795][root][INFO] - Training Epoch: 1/2, step 3470/7134 completed (loss: 3.837047815322876, acc: 0.29629629850387573)
[2024-12-17 02:00:37,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,191][root][INFO] - Training Epoch: 1/2, step 3471/7134 completed (loss: 3.9069488048553467, acc: 0.25555557012557983)
[2024-12-17 02:00:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:38,583][root][INFO] - Training Epoch: 1/2, step 3472/7134 completed (loss: 4.025311470031738, acc: 0.24203822016716003)
[2024-12-17 02:00:38,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,022][root][INFO] - Training Epoch: 1/2, step 3473/7134 completed (loss: 3.932884693145752, acc: 0.2697368562221527)
[2024-12-17 02:00:39,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,382][root][INFO] - Training Epoch: 1/2, step 3474/7134 completed (loss: 3.7764902114868164, acc: 0.3115941882133484)
[2024-12-17 02:00:39,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:39,743][root][INFO] - Training Epoch: 1/2, step 3475/7134 completed (loss: 3.445805072784424, acc: 0.2954545319080353)
[2024-12-17 02:00:39,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,123][root][INFO] - Training Epoch: 1/2, step 3476/7134 completed (loss: 3.5282492637634277, acc: 0.3904109597206116)
[2024-12-17 02:00:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,495][root][INFO] - Training Epoch: 1/2, step 3477/7134 completed (loss: 3.6249983310699463, acc: 0.31081080436706543)
[2024-12-17 02:00:40,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:40,875][root][INFO] - Training Epoch: 1/2, step 3478/7134 completed (loss: 3.10844349861145, acc: 0.32335329055786133)
[2024-12-17 02:00:40,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,239][root][INFO] - Training Epoch: 1/2, step 3479/7134 completed (loss: 3.2956669330596924, acc: 0.35256409645080566)
[2024-12-17 02:00:41,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:41,653][root][INFO] - Training Epoch: 1/2, step 3480/7134 completed (loss: 3.3212108612060547, acc: 0.3131868243217468)
[2024-12-17 02:00:41,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,024][root][INFO] - Training Epoch: 1/2, step 3481/7134 completed (loss: 3.623800039291382, acc: 0.2631579041481018)
[2024-12-17 02:00:42,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,383][root][INFO] - Training Epoch: 1/2, step 3482/7134 completed (loss: 3.3174514770507812, acc: 0.328125)
[2024-12-17 02:00:42,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:42,760][root][INFO] - Training Epoch: 1/2, step 3483/7134 completed (loss: 3.106015205383301, acc: 0.34193548560142517)
[2024-12-17 02:00:42,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,117][root][INFO] - Training Epoch: 1/2, step 3484/7134 completed (loss: 3.083456516265869, acc: 0.3452380895614624)
[2024-12-17 02:00:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,452][root][INFO] - Training Epoch: 1/2, step 3485/7134 completed (loss: 3.7510528564453125, acc: 0.32121211290359497)
[2024-12-17 02:00:43,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:43,829][root][INFO] - Training Epoch: 1/2, step 3486/7134 completed (loss: 5.2510600090026855, acc: 0.23931623995304108)
[2024-12-17 02:00:43,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,228][root][INFO] - Training Epoch: 1/2, step 3487/7134 completed (loss: 4.543218612670898, acc: 0.2409638613462448)
[2024-12-17 02:00:44,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:44,609][root][INFO] - Training Epoch: 1/2, step 3488/7134 completed (loss: 4.361456871032715, acc: 0.22142857313156128)
[2024-12-17 02:00:44,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,032][root][INFO] - Training Epoch: 1/2, step 3489/7134 completed (loss: 4.806532859802246, acc: 0.2222222238779068)
[2024-12-17 02:00:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,420][root][INFO] - Training Epoch: 1/2, step 3490/7134 completed (loss: 4.728907108306885, acc: 0.279720276594162)
[2024-12-17 02:00:45,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:45,792][root][INFO] - Training Epoch: 1/2, step 3491/7134 completed (loss: 4.083942413330078, acc: 0.29936304688453674)
[2024-12-17 02:00:45,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,191][root][INFO] - Training Epoch: 1/2, step 3492/7134 completed (loss: 4.2763166427612305, acc: 0.26605504751205444)
[2024-12-17 02:00:46,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,599][root][INFO] - Training Epoch: 1/2, step 3493/7134 completed (loss: 4.210649490356445, acc: 0.2839506268501282)
[2024-12-17 02:00:46,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:46,999][root][INFO] - Training Epoch: 1/2, step 3494/7134 completed (loss: 4.128367900848389, acc: 0.31081080436706543)
[2024-12-17 02:00:47,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,369][root][INFO] - Training Epoch: 1/2, step 3495/7134 completed (loss: 4.215079307556152, acc: 0.27835050225257874)
[2024-12-17 02:00:47,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:47,731][root][INFO] - Training Epoch: 1/2, step 3496/7134 completed (loss: 3.7969815731048584, acc: 0.28431373834609985)
[2024-12-17 02:00:47,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,116][root][INFO] - Training Epoch: 1/2, step 3497/7134 completed (loss: 4.055650234222412, acc: 0.3670886158943176)
[2024-12-17 02:00:48,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,567][root][INFO] - Training Epoch: 1/2, step 3498/7134 completed (loss: 4.151084899902344, acc: 0.3037974536418915)
[2024-12-17 02:00:48,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:48,946][root][INFO] - Training Epoch: 1/2, step 3499/7134 completed (loss: 4.274263858795166, acc: 0.2549019753932953)
[2024-12-17 02:00:49,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,339][root][INFO] - Training Epoch: 1/2, step 3500/7134 completed (loss: 4.0789475440979, acc: 0.2982456088066101)
[2024-12-17 02:00:49,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:49,721][root][INFO] - Training Epoch: 1/2, step 3501/7134 completed (loss: 4.0398969650268555, acc: 0.3333333432674408)
[2024-12-17 02:00:49,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,083][root][INFO] - Training Epoch: 1/2, step 3502/7134 completed (loss: 4.486059188842773, acc: 0.29054054617881775)
[2024-12-17 02:00:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,495][root][INFO] - Training Epoch: 1/2, step 3503/7134 completed (loss: 4.392262935638428, acc: 0.3093525171279907)
[2024-12-17 02:00:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:50,872][root][INFO] - Training Epoch: 1/2, step 3504/7134 completed (loss: 3.8782711029052734, acc: 0.3400000035762787)
[2024-12-17 02:00:50,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,246][root][INFO] - Training Epoch: 1/2, step 3505/7134 completed (loss: 4.069493770599365, acc: 0.2698412835597992)
[2024-12-17 02:00:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:51,638][root][INFO] - Training Epoch: 1/2, step 3506/7134 completed (loss: 3.8674652576446533, acc: 0.3100775182247162)
[2024-12-17 02:00:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,013][root][INFO] - Training Epoch: 1/2, step 3507/7134 completed (loss: 3.770724296569824, acc: 0.2986111044883728)
[2024-12-17 02:00:52,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,401][root][INFO] - Training Epoch: 1/2, step 3508/7134 completed (loss: 4.108344078063965, acc: 0.251655638217926)
[2024-12-17 02:00:52,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:52,778][root][INFO] - Training Epoch: 1/2, step 3509/7134 completed (loss: 4.40090274810791, acc: 0.30674847960472107)
[2024-12-17 02:00:52,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,146][root][INFO] - Training Epoch: 1/2, step 3510/7134 completed (loss: 4.3480544090271, acc: 0.24812030792236328)
[2024-12-17 02:00:53,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,527][root][INFO] - Training Epoch: 1/2, step 3511/7134 completed (loss: 3.3605618476867676, acc: 0.34558823704719543)
[2024-12-17 02:00:53,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:53,902][root][INFO] - Training Epoch: 1/2, step 3512/7134 completed (loss: 3.4907495975494385, acc: 0.3333333432674408)
[2024-12-17 02:00:53,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,324][root][INFO] - Training Epoch: 1/2, step 3513/7134 completed (loss: 3.6075873374938965, acc: 0.2971014380455017)
[2024-12-17 02:00:54,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:54,715][root][INFO] - Training Epoch: 1/2, step 3514/7134 completed (loss: 3.818434953689575, acc: 0.27272728085517883)
[2024-12-17 02:00:54,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,103][root][INFO] - Training Epoch: 1/2, step 3515/7134 completed (loss: 3.666013479232788, acc: 0.23163841664791107)
[2024-12-17 02:00:55,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,512][root][INFO] - Training Epoch: 1/2, step 3516/7134 completed (loss: 3.2537479400634766, acc: 0.3245614171028137)
[2024-12-17 02:00:55,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:55,930][root][INFO] - Training Epoch: 1/2, step 3517/7134 completed (loss: 3.532198429107666, acc: 0.3181818127632141)
[2024-12-17 02:00:56,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,334][root][INFO] - Training Epoch: 1/2, step 3518/7134 completed (loss: 3.501783847808838, acc: 0.3185185194015503)
[2024-12-17 02:00:56,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:56,733][root][INFO] - Training Epoch: 1/2, step 3519/7134 completed (loss: 3.5729689598083496, acc: 0.30666667222976685)
[2024-12-17 02:00:56,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,124][root][INFO] - Training Epoch: 1/2, step 3520/7134 completed (loss: 3.88991117477417, acc: 0.23232322931289673)
[2024-12-17 02:00:57,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,568][root][INFO] - Training Epoch: 1/2, step 3521/7134 completed (loss: 3.33766508102417, acc: 0.38922154903411865)
[2024-12-17 02:00:57,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:57,936][root][INFO] - Training Epoch: 1/2, step 3522/7134 completed (loss: 4.146121025085449, acc: 0.2888889014720917)
[2024-12-17 02:00:58,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,309][root][INFO] - Training Epoch: 1/2, step 3523/7134 completed (loss: 3.8100521564483643, acc: 0.2715231776237488)
[2024-12-17 02:00:58,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:58,702][root][INFO] - Training Epoch: 1/2, step 3524/7134 completed (loss: 3.5319535732269287, acc: 0.2857142984867096)
[2024-12-17 02:00:58,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,129][root][INFO] - Training Epoch: 1/2, step 3525/7134 completed (loss: 3.6825523376464844, acc: 0.29729729890823364)
[2024-12-17 02:00:59,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,505][root][INFO] - Training Epoch: 1/2, step 3526/7134 completed (loss: 4.009796619415283, acc: 0.2777777910232544)
[2024-12-17 02:00:59,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:00:59,898][root][INFO] - Training Epoch: 1/2, step 3527/7134 completed (loss: 4.248121738433838, acc: 0.23404255509376526)
[2024-12-17 02:01:00,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,330][root][INFO] - Training Epoch: 1/2, step 3528/7134 completed (loss: 3.564248561859131, acc: 0.25961539149284363)
[2024-12-17 02:01:00,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:00,706][root][INFO] - Training Epoch: 1/2, step 3529/7134 completed (loss: 3.4962165355682373, acc: 0.3909091055393219)
[2024-12-17 02:01:00,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,104][root][INFO] - Training Epoch: 1/2, step 3530/7134 completed (loss: 3.5943825244903564, acc: 0.3362831771373749)
[2024-12-17 02:01:01,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,490][root][INFO] - Training Epoch: 1/2, step 3531/7134 completed (loss: 3.1498351097106934, acc: 0.3812499940395355)
[2024-12-17 02:01:01,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:01,885][root][INFO] - Training Epoch: 1/2, step 3532/7134 completed (loss: 3.595675468444824, acc: 0.27702704071998596)
[2024-12-17 02:01:01,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,259][root][INFO] - Training Epoch: 1/2, step 3533/7134 completed (loss: 3.3723838329315186, acc: 0.3199999928474426)
[2024-12-17 02:01:02,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:02,647][root][INFO] - Training Epoch: 1/2, step 3534/7134 completed (loss: 3.8839809894561768, acc: 0.28070175647735596)
[2024-12-17 02:01:02,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,025][root][INFO] - Training Epoch: 1/2, step 3535/7134 completed (loss: 3.966961622238159, acc: 0.2733812928199768)
[2024-12-17 02:01:03,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,403][root][INFO] - Training Epoch: 1/2, step 3536/7134 completed (loss: 3.952348232269287, acc: 0.29629629850387573)
[2024-12-17 02:01:03,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:03,755][root][INFO] - Training Epoch: 1/2, step 3537/7134 completed (loss: 3.995723247528076, acc: 0.21875)
[2024-12-17 02:01:03,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,119][root][INFO] - Training Epoch: 1/2, step 3538/7134 completed (loss: 3.5354151725769043, acc: 0.29411765933036804)
[2024-12-17 02:01:04,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,449][root][INFO] - Training Epoch: 1/2, step 3539/7134 completed (loss: 4.641480445861816, acc: 0.3333333432674408)
[2024-12-17 02:01:04,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:04,810][root][INFO] - Training Epoch: 1/2, step 3540/7134 completed (loss: 4.340090274810791, acc: 0.26923078298568726)
[2024-12-17 02:01:04,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,188][root][INFO] - Training Epoch: 1/2, step 3541/7134 completed (loss: 4.298830986022949, acc: 0.2800000011920929)
[2024-12-17 02:01:05,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,565][root][INFO] - Training Epoch: 1/2, step 3542/7134 completed (loss: 3.7890896797180176, acc: 0.28082191944122314)
[2024-12-17 02:01:05,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:05,923][root][INFO] - Training Epoch: 1/2, step 3543/7134 completed (loss: 3.8582420349121094, acc: 0.30985915660858154)
[2024-12-17 02:01:06,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,297][root][INFO] - Training Epoch: 1/2, step 3544/7134 completed (loss: 3.486849546432495, acc: 0.41721853613853455)
[2024-12-17 02:01:06,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:06,679][root][INFO] - Training Epoch: 1/2, step 3545/7134 completed (loss: 3.838434934616089, acc: 0.2777777910232544)
[2024-12-17 02:01:06,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,079][root][INFO] - Training Epoch: 1/2, step 3546/7134 completed (loss: 3.857583999633789, acc: 0.316546767950058)
[2024-12-17 02:01:07,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,466][root][INFO] - Training Epoch: 1/2, step 3547/7134 completed (loss: 3.9460864067077637, acc: 0.3333333432674408)
[2024-12-17 02:01:07,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:07,847][root][INFO] - Training Epoch: 1/2, step 3548/7134 completed (loss: 4.04999303817749, acc: 0.31192660331726074)
[2024-12-17 02:01:07,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,217][root][INFO] - Training Epoch: 1/2, step 3549/7134 completed (loss: 4.2661871910095215, acc: 0.27819550037384033)
[2024-12-17 02:01:08,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,585][root][INFO] - Training Epoch: 1/2, step 3550/7134 completed (loss: 4.173857688903809, acc: 0.262773722410202)
[2024-12-17 02:01:08,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:08,960][root][INFO] - Training Epoch: 1/2, step 3551/7134 completed (loss: 4.502041339874268, acc: 0.25170066952705383)
[2024-12-17 02:01:09,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,358][root][INFO] - Training Epoch: 1/2, step 3552/7134 completed (loss: 4.174346446990967, acc: 0.33070865273475647)
[2024-12-17 02:01:09,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:09,804][root][INFO] - Training Epoch: 1/2, step 3553/7134 completed (loss: 4.091846466064453, acc: 0.29411765933036804)
[2024-12-17 02:01:09,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,173][root][INFO] - Training Epoch: 1/2, step 3554/7134 completed (loss: 4.400223731994629, acc: 0.25766870379447937)
[2024-12-17 02:01:10,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,543][root][INFO] - Training Epoch: 1/2, step 3555/7134 completed (loss: 4.357509136199951, acc: 0.20645160973072052)
[2024-12-17 02:01:10,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:10,902][root][INFO] - Training Epoch: 1/2, step 3556/7134 completed (loss: 3.620716094970703, acc: 0.32575756311416626)
[2024-12-17 02:01:10,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,276][root][INFO] - Training Epoch: 1/2, step 3557/7134 completed (loss: 4.286500453948975, acc: 0.24822695553302765)
[2024-12-17 02:01:11,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:11,668][root][INFO] - Training Epoch: 1/2, step 3558/7134 completed (loss: 4.293069362640381, acc: 0.328000009059906)
[2024-12-17 02:01:11,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,038][root][INFO] - Training Epoch: 1/2, step 3559/7134 completed (loss: 4.630784034729004, acc: 0.2380952388048172)
[2024-12-17 02:01:12,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,402][root][INFO] - Training Epoch: 1/2, step 3560/7134 completed (loss: 4.15643310546875, acc: 0.28961747884750366)
[2024-12-17 02:01:12,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:12,780][root][INFO] - Training Epoch: 1/2, step 3561/7134 completed (loss: 3.4942080974578857, acc: 0.35593220591545105)
[2024-12-17 02:01:12,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,145][root][INFO] - Training Epoch: 1/2, step 3562/7134 completed (loss: 3.6910011768341064, acc: 0.34558823704719543)
[2024-12-17 02:01:13,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,499][root][INFO] - Training Epoch: 1/2, step 3563/7134 completed (loss: 4.544858455657959, acc: 0.21985815465450287)
[2024-12-17 02:01:13,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:13,865][root][INFO] - Training Epoch: 1/2, step 3564/7134 completed (loss: 4.443535327911377, acc: 0.2698412835597992)
[2024-12-17 02:01:13,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:14,221][root][INFO] - Training Epoch: 1/2, step 3565/7134 completed (loss: 4.860830783843994, acc: 0.22794117033481598)
[2024-12-17 02:01:14,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:15,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:17,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:18,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:19,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:20,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:22,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:23,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:24,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:26,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:27,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:28,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:29,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:31,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:32,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:35,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:36,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:37,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:38,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:39,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:40,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:41,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:42,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:43,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:44,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:45,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:46,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:47,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:48,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:49,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:50,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:52,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:53,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:54,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:57,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:58,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:01:59,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:00,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:01,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:02,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:03,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:04,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:05,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:07,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:08,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:09,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:10,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:11,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:12,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:13,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:14,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:15,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:16,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:17,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:18,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:19,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:21,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:22,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:23,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:24,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:25,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:27,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:28,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:29,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:30,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:31,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:32,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:33,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:34,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:35,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:36,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:37,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:38,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:39,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:40,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:41,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:42,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:43,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:44,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:45,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:46,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:47,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:49,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:50,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:51,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:52,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:53,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:54,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:55,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:56,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:57,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:58,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:02:59,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:00,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:01,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:02,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:04,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:05,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:06,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:07,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:08,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:09,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:10,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:11,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:12,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:13,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:14,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:15,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:17,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:18,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:19,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:20,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:21,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:22,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:23,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:24,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:25,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:26,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:27,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:28,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:29,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:30,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:31,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:32,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:33,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:34,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:35,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:36,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:39,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:40,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:41,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:42,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:44,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:45,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:47,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:49,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:50,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:51,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:52,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:53,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:54,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:55,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:56,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:57,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:03:59,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:00,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:01,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:03,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:05,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:06,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:07,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:08,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:09,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:10,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:11,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:12,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:13,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:14,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:15,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:16,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:18,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:19,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:20,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:22,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:25,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:27,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:28,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:29,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:30,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:31,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:32,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:33,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:34,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:35,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:36,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:37,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:38,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:41,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:43,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:44,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:45,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:46,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:47,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:48,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:49,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:50,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:52,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:53,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:54,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:56,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:57,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:04:59,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:00,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:01,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:02,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:03,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:04,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:05,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:06,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:07,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:08,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:09,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:10,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:11,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:13,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:14,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:15,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:16,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:17,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:18,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:19,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:20,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:21,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:22,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,184][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(52.0037, device='cuda:0') eval_epoch_loss=tensor(3.9513, device='cuda:0') eval_epoch_acc=tensor(0.3042, device='cuda:0')
[2024-12-17 02:05:23,185][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 02:05:23,186][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:05:23,514][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_3566_loss_3.951315402984619/model.pt
[2024-12-17 02:05:23,526][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 02:05:23,528][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.951315402984619
[2024-12-17 02:05:23,529][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.3042420446872711
[2024-12-17 02:05:23,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:23,998][root][INFO] - Training Epoch: 1/2, step 3566/7134 completed (loss: 4.861502170562744, acc: 0.21848739683628082)
[2024-12-17 02:05:24,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,367][root][INFO] - Training Epoch: 1/2, step 3567/7134 completed (loss: 3.8180923461914062, acc: 0.3258427083492279)
[2024-12-17 02:05:24,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:24,784][root][INFO] - Training Epoch: 1/2, step 3568/7134 completed (loss: 4.035707950592041, acc: 0.2978723347187042)
[2024-12-17 02:05:24,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,192][root][INFO] - Training Epoch: 1/2, step 3569/7134 completed (loss: 4.112353801727295, acc: 0.25)
[2024-12-17 02:05:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,584][root][INFO] - Training Epoch: 1/2, step 3570/7134 completed (loss: 4.524929046630859, acc: 0.3382352888584137)
[2024-12-17 02:05:25,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:25,999][root][INFO] - Training Epoch: 1/2, step 3571/7134 completed (loss: 4.7349114418029785, acc: 0.2584269642829895)
[2024-12-17 02:05:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,380][root][INFO] - Training Epoch: 1/2, step 3572/7134 completed (loss: 4.209839820861816, acc: 0.3095238208770752)
[2024-12-17 02:05:26,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:26,753][root][INFO] - Training Epoch: 1/2, step 3573/7134 completed (loss: 4.696465015411377, acc: 0.2697368562221527)
[2024-12-17 02:05:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,114][root][INFO] - Training Epoch: 1/2, step 3574/7134 completed (loss: 4.714494228363037, acc: 0.20661157369613647)
[2024-12-17 02:05:27,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,483][root][INFO] - Training Epoch: 1/2, step 3575/7134 completed (loss: 4.815937042236328, acc: 0.20394736528396606)
[2024-12-17 02:05:27,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:27,841][root][INFO] - Training Epoch: 1/2, step 3576/7134 completed (loss: 4.184465408325195, acc: 0.305970162153244)
[2024-12-17 02:05:27,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,245][root][INFO] - Training Epoch: 1/2, step 3577/7134 completed (loss: 4.3382248878479, acc: 0.3041236996650696)
[2024-12-17 02:05:28,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,622][root][INFO] - Training Epoch: 1/2, step 3578/7134 completed (loss: 4.547691822052002, acc: 0.23493975400924683)
[2024-12-17 02:05:28,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:28,999][root][INFO] - Training Epoch: 1/2, step 3579/7134 completed (loss: 4.47236442565918, acc: 0.23255814611911774)
[2024-12-17 02:05:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,369][root][INFO] - Training Epoch: 1/2, step 3580/7134 completed (loss: 4.274102687835693, acc: 0.2947976887226105)
[2024-12-17 02:05:29,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:29,753][root][INFO] - Training Epoch: 1/2, step 3581/7134 completed (loss: 4.511763095855713, acc: 0.21764706075191498)
[2024-12-17 02:05:29,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,120][root][INFO] - Training Epoch: 1/2, step 3582/7134 completed (loss: 4.844067573547363, acc: 0.2222222238779068)
[2024-12-17 02:05:30,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,495][root][INFO] - Training Epoch: 1/2, step 3583/7134 completed (loss: 4.054973125457764, acc: 0.31137725710868835)
[2024-12-17 02:05:30,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:30,867][root][INFO] - Training Epoch: 1/2, step 3584/7134 completed (loss: 4.527778148651123, acc: 0.21276596188545227)
[2024-12-17 02:05:30,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,246][root][INFO] - Training Epoch: 1/2, step 3585/7134 completed (loss: 4.575139999389648, acc: 0.25766870379447937)
[2024-12-17 02:05:31,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,619][root][INFO] - Training Epoch: 1/2, step 3586/7134 completed (loss: 4.250886917114258, acc: 0.29936304688453674)
[2024-12-17 02:05:31,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:31,988][root][INFO] - Training Epoch: 1/2, step 3587/7134 completed (loss: 4.353869915008545, acc: 0.25874125957489014)
[2024-12-17 02:05:32,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,402][root][INFO] - Training Epoch: 1/2, step 3588/7134 completed (loss: 4.327358722686768, acc: 0.2947976887226105)
[2024-12-17 02:05:32,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:32,874][root][INFO] - Training Epoch: 1/2, step 3589/7134 completed (loss: 3.79297137260437, acc: 0.32786884903907776)
[2024-12-17 02:05:33,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,273][root][INFO] - Training Epoch: 1/2, step 3590/7134 completed (loss: 3.936699390411377, acc: 0.25)
[2024-12-17 02:05:33,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:33,650][root][INFO] - Training Epoch: 1/2, step 3591/7134 completed (loss: 4.033258438110352, acc: 0.24561403691768646)
[2024-12-17 02:05:33,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,058][root][INFO] - Training Epoch: 1/2, step 3592/7134 completed (loss: 3.6395883560180664, acc: 0.2928571403026581)
[2024-12-17 02:05:34,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,460][root][INFO] - Training Epoch: 1/2, step 3593/7134 completed (loss: 4.25454044342041, acc: 0.26056337356567383)
[2024-12-17 02:05:34,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:34,875][root][INFO] - Training Epoch: 1/2, step 3594/7134 completed (loss: 4.231449604034424, acc: 0.33774834871292114)
[2024-12-17 02:05:35,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,349][root][INFO] - Training Epoch: 1/2, step 3595/7134 completed (loss: 4.264386177062988, acc: 0.3006536066532135)
[2024-12-17 02:05:35,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:35,725][root][INFO] - Training Epoch: 1/2, step 3596/7134 completed (loss: 4.464780330657959, acc: 0.25294119119644165)
[2024-12-17 02:05:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,095][root][INFO] - Training Epoch: 1/2, step 3597/7134 completed (loss: 4.430579662322998, acc: 0.2697368562221527)
[2024-12-17 02:05:36,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,483][root][INFO] - Training Epoch: 1/2, step 3598/7134 completed (loss: 4.2424421310424805, acc: 0.27014216780662537)
[2024-12-17 02:05:36,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:36,896][root][INFO] - Training Epoch: 1/2, step 3599/7134 completed (loss: 4.024713516235352, acc: 0.3027026951313019)
[2024-12-17 02:05:37,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,278][root][INFO] - Training Epoch: 1/2, step 3600/7134 completed (loss: 4.062591552734375, acc: 0.2849740982055664)
[2024-12-17 02:05:37,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:37,672][root][INFO] - Training Epoch: 1/2, step 3601/7134 completed (loss: 4.7929558753967285, acc: 0.25280898809432983)
[2024-12-17 02:05:37,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,104][root][INFO] - Training Epoch: 1/2, step 3602/7134 completed (loss: 4.297913074493408, acc: 0.31162789463996887)
[2024-12-17 02:05:38,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:38,582][root][INFO] - Training Epoch: 1/2, step 3603/7134 completed (loss: 4.740668296813965, acc: 0.2515723407268524)
[2024-12-17 02:05:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,000][root][INFO] - Training Epoch: 1/2, step 3604/7134 completed (loss: 4.517966270446777, acc: 0.28346458077430725)
[2024-12-17 02:05:39,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,381][root][INFO] - Training Epoch: 1/2, step 3605/7134 completed (loss: 3.8178951740264893, acc: 0.30493274331092834)
[2024-12-17 02:05:39,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:39,755][root][INFO] - Training Epoch: 1/2, step 3606/7134 completed (loss: 4.568048000335693, acc: 0.2602739632129669)
[2024-12-17 02:05:39,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,143][root][INFO] - Training Epoch: 1/2, step 3607/7134 completed (loss: 4.559179306030273, acc: 0.232876718044281)
[2024-12-17 02:05:40,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,528][root][INFO] - Training Epoch: 1/2, step 3608/7134 completed (loss: 4.041075229644775, acc: 0.3106796145439148)
[2024-12-17 02:05:40,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:40,881][root][INFO] - Training Epoch: 1/2, step 3609/7134 completed (loss: 4.153547286987305, acc: 0.28421053290367126)
[2024-12-17 02:05:40,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,272][root][INFO] - Training Epoch: 1/2, step 3610/7134 completed (loss: 4.3646697998046875, acc: 0.2747252881526947)
[2024-12-17 02:05:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:41,736][root][INFO] - Training Epoch: 1/2, step 3611/7134 completed (loss: 4.445135116577148, acc: 0.2800000011920929)
[2024-12-17 02:05:41,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,103][root][INFO] - Training Epoch: 1/2, step 3612/7134 completed (loss: 4.099863529205322, acc: 0.3103448152542114)
[2024-12-17 02:05:42,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,474][root][INFO] - Training Epoch: 1/2, step 3613/7134 completed (loss: 4.390417575836182, acc: 0.26229506731033325)
[2024-12-17 02:05:42,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:42,819][root][INFO] - Training Epoch: 1/2, step 3614/7134 completed (loss: 4.392611980438232, acc: 0.2819148898124695)
[2024-12-17 02:05:42,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,191][root][INFO] - Training Epoch: 1/2, step 3615/7134 completed (loss: 4.435792446136475, acc: 0.27702704071998596)
[2024-12-17 02:05:43,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,576][root][INFO] - Training Epoch: 1/2, step 3616/7134 completed (loss: 4.322824478149414, acc: 0.2857142984867096)
[2024-12-17 02:05:43,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:43,970][root][INFO] - Training Epoch: 1/2, step 3617/7134 completed (loss: 3.9817686080932617, acc: 0.3405405282974243)
[2024-12-17 02:05:44,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,362][root][INFO] - Training Epoch: 1/2, step 3618/7134 completed (loss: 4.425504207611084, acc: 0.30061349272727966)
[2024-12-17 02:05:44,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:44,771][root][INFO] - Training Epoch: 1/2, step 3619/7134 completed (loss: 4.481132984161377, acc: 0.29694321751594543)
[2024-12-17 02:05:44,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,160][root][INFO] - Training Epoch: 1/2, step 3620/7134 completed (loss: 4.399178504943848, acc: 0.32335329055786133)
[2024-12-17 02:05:45,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,541][root][INFO] - Training Epoch: 1/2, step 3621/7134 completed (loss: 4.616069793701172, acc: 0.2866241931915283)
[2024-12-17 02:05:45,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:45,921][root][INFO] - Training Epoch: 1/2, step 3622/7134 completed (loss: 3.8259527683258057, acc: 0.3961038887500763)
[2024-12-17 02:05:46,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,302][root][INFO] - Training Epoch: 1/2, step 3623/7134 completed (loss: 4.371385097503662, acc: 0.2678571343421936)
[2024-12-17 02:05:46,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:46,709][root][INFO] - Training Epoch: 1/2, step 3624/7134 completed (loss: 4.1786346435546875, acc: 0.2949640154838562)
[2024-12-17 02:05:46,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,101][root][INFO] - Training Epoch: 1/2, step 3625/7134 completed (loss: 5.028432846069336, acc: 0.2521008551120758)
[2024-12-17 02:05:47,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,513][root][INFO] - Training Epoch: 1/2, step 3626/7134 completed (loss: 4.3928093910217285, acc: 0.3258427083492279)
[2024-12-17 02:05:47,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:47,892][root][INFO] - Training Epoch: 1/2, step 3627/7134 completed (loss: 4.425572395324707, acc: 0.2924528419971466)
[2024-12-17 02:05:47,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,296][root][INFO] - Training Epoch: 1/2, step 3628/7134 completed (loss: 5.080482006072998, acc: 0.20952381193637848)
[2024-12-17 02:05:48,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:48,701][root][INFO] - Training Epoch: 1/2, step 3629/7134 completed (loss: 4.306501865386963, acc: 0.2822580635547638)
[2024-12-17 02:05:48,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,090][root][INFO] - Training Epoch: 1/2, step 3630/7134 completed (loss: 5.439077854156494, acc: 0.2150537669658661)
[2024-12-17 02:05:49,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,463][root][INFO] - Training Epoch: 1/2, step 3631/7134 completed (loss: 4.731595516204834, acc: 0.22857142984867096)
[2024-12-17 02:05:49,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:49,865][root][INFO] - Training Epoch: 1/2, step 3632/7134 completed (loss: 4.470317840576172, acc: 0.26229506731033325)
[2024-12-17 02:05:49,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,243][root][INFO] - Training Epoch: 1/2, step 3633/7134 completed (loss: 4.1672868728637695, acc: 0.23566879332065582)
[2024-12-17 02:05:50,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:50,630][root][INFO] - Training Epoch: 1/2, step 3634/7134 completed (loss: 4.324319362640381, acc: 0.32710281014442444)
[2024-12-17 02:05:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,011][root][INFO] - Training Epoch: 1/2, step 3635/7134 completed (loss: 4.150803089141846, acc: 0.3017241358757019)
[2024-12-17 02:05:51,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,430][root][INFO] - Training Epoch: 1/2, step 3636/7134 completed (loss: 4.104315280914307, acc: 0.2830188572406769)
[2024-12-17 02:05:51,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:51,836][root][INFO] - Training Epoch: 1/2, step 3637/7134 completed (loss: 4.209929943084717, acc: 0.2818181812763214)
[2024-12-17 02:05:51,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,212][root][INFO] - Training Epoch: 1/2, step 3638/7134 completed (loss: 4.343466281890869, acc: 0.3186813294887543)
[2024-12-17 02:05:52,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:52,610][root][INFO] - Training Epoch: 1/2, step 3639/7134 completed (loss: 4.168172359466553, acc: 0.19148936867713928)
[2024-12-17 02:05:52,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,015][root][INFO] - Training Epoch: 1/2, step 3640/7134 completed (loss: 4.582818984985352, acc: 0.23966942727565765)
[2024-12-17 02:05:53,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,371][root][INFO] - Training Epoch: 1/2, step 3641/7134 completed (loss: 3.90948486328125, acc: 0.2822580635547638)
[2024-12-17 02:05:53,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:53,723][root][INFO] - Training Epoch: 1/2, step 3642/7134 completed (loss: 3.9396660327911377, acc: 0.281879186630249)
[2024-12-17 02:05:53,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,092][root][INFO] - Training Epoch: 1/2, step 3643/7134 completed (loss: 4.166308879852295, acc: 0.2265625)
[2024-12-17 02:05:54,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,510][root][INFO] - Training Epoch: 1/2, step 3644/7134 completed (loss: 3.781243324279785, acc: 0.3243243098258972)
[2024-12-17 02:05:54,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:54,910][root][INFO] - Training Epoch: 1/2, step 3645/7134 completed (loss: 4.136432647705078, acc: 0.21875)
[2024-12-17 02:05:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,311][root][INFO] - Training Epoch: 1/2, step 3646/7134 completed (loss: 3.441153049468994, acc: 0.3484848439693451)
[2024-12-17 02:05:55,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:55,689][root][INFO] - Training Epoch: 1/2, step 3647/7134 completed (loss: 3.9289627075195312, acc: 0.21348313987255096)
[2024-12-17 02:05:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,104][root][INFO] - Training Epoch: 1/2, step 3648/7134 completed (loss: 4.129207134246826, acc: 0.3491124212741852)
[2024-12-17 02:05:56,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,503][root][INFO] - Training Epoch: 1/2, step 3649/7134 completed (loss: 4.0017008781433105, acc: 0.33557048439979553)
[2024-12-17 02:05:56,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:56,884][root][INFO] - Training Epoch: 1/2, step 3650/7134 completed (loss: 4.075248718261719, acc: 0.27218934893608093)
[2024-12-17 02:05:56,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,292][root][INFO] - Training Epoch: 1/2, step 3651/7134 completed (loss: 4.463247776031494, acc: 0.3132530152797699)
[2024-12-17 02:05:57,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:57,686][root][INFO] - Training Epoch: 1/2, step 3652/7134 completed (loss: 4.006851673126221, acc: 0.30612245202064514)
[2024-12-17 02:05:57,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,071][root][INFO] - Training Epoch: 1/2, step 3653/7134 completed (loss: 4.275975704193115, acc: 0.25153374671936035)
[2024-12-17 02:05:58,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,451][root][INFO] - Training Epoch: 1/2, step 3654/7134 completed (loss: 4.1955342292785645, acc: 0.30399999022483826)
[2024-12-17 02:05:58,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:58,808][root][INFO] - Training Epoch: 1/2, step 3655/7134 completed (loss: 4.321127891540527, acc: 0.28143712878227234)
[2024-12-17 02:05:58,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,209][root][INFO] - Training Epoch: 1/2, step 3656/7134 completed (loss: 4.473626613616943, acc: 0.2246376872062683)
[2024-12-17 02:05:59,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:05:59,602][root][INFO] - Training Epoch: 1/2, step 3657/7134 completed (loss: 3.6884090900421143, acc: 0.251748263835907)
[2024-12-17 02:05:59,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,001][root][INFO] - Training Epoch: 1/2, step 3658/7134 completed (loss: 4.510232448577881, acc: 0.2638888955116272)
[2024-12-17 02:06:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,359][root][INFO] - Training Epoch: 1/2, step 3659/7134 completed (loss: 4.695032596588135, acc: 0.27210885286331177)
[2024-12-17 02:06:00,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:00,727][root][INFO] - Training Epoch: 1/2, step 3660/7134 completed (loss: 4.732711315155029, acc: 0.25925925374031067)
[2024-12-17 02:06:00,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,077][root][INFO] - Training Epoch: 1/2, step 3661/7134 completed (loss: 4.722151279449463, acc: 0.20000000298023224)
[2024-12-17 02:06:01,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,451][root][INFO] - Training Epoch: 1/2, step 3662/7134 completed (loss: 5.058714389801025, acc: 0.26708075404167175)
[2024-12-17 02:06:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:01,791][root][INFO] - Training Epoch: 1/2, step 3663/7134 completed (loss: 5.094548225402832, acc: 0.1953125)
[2024-12-17 02:06:01,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,164][root][INFO] - Training Epoch: 1/2, step 3664/7134 completed (loss: 4.790031433105469, acc: 0.2142857164144516)
[2024-12-17 02:06:02,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,504][root][INFO] - Training Epoch: 1/2, step 3665/7134 completed (loss: 4.511140823364258, acc: 0.22972972691059113)
[2024-12-17 02:06:02,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:02,868][root][INFO] - Training Epoch: 1/2, step 3666/7134 completed (loss: 4.943599224090576, acc: 0.17123287916183472)
[2024-12-17 02:06:02,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,264][root][INFO] - Training Epoch: 1/2, step 3667/7134 completed (loss: 5.003722190856934, acc: 0.27906978130340576)
[2024-12-17 02:06:03,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:03,665][root][INFO] - Training Epoch: 1/2, step 3668/7134 completed (loss: 4.626961708068848, acc: 0.24137930572032928)
[2024-12-17 02:06:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,047][root][INFO] - Training Epoch: 1/2, step 3669/7134 completed (loss: 3.794768810272217, acc: 0.3140496015548706)
[2024-12-17 02:06:04,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,411][root][INFO] - Training Epoch: 1/2, step 3670/7134 completed (loss: 3.8523755073547363, acc: 0.3072289228439331)
[2024-12-17 02:06:04,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:04,748][root][INFO] - Training Epoch: 1/2, step 3671/7134 completed (loss: 4.27937650680542, acc: 0.2405063360929489)
[2024-12-17 02:06:04,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,118][root][INFO] - Training Epoch: 1/2, step 3672/7134 completed (loss: 4.6232523918151855, acc: 0.24309392273426056)
[2024-12-17 02:06:05,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,546][root][INFO] - Training Epoch: 1/2, step 3673/7134 completed (loss: 4.355536460876465, acc: 0.29655173420906067)
[2024-12-17 02:06:05,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:05,958][root][INFO] - Training Epoch: 1/2, step 3674/7134 completed (loss: 3.900592803955078, acc: 0.28378379344940186)
[2024-12-17 02:06:06,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,359][root][INFO] - Training Epoch: 1/2, step 3675/7134 completed (loss: 4.06704044342041, acc: 0.3093922734260559)
[2024-12-17 02:06:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:06,734][root][INFO] - Training Epoch: 1/2, step 3676/7134 completed (loss: 4.628096580505371, acc: 0.21153846383094788)
[2024-12-17 02:06:06,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,110][root][INFO] - Training Epoch: 1/2, step 3677/7134 completed (loss: 4.145159721374512, acc: 0.3011363744735718)
[2024-12-17 02:06:07,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,481][root][INFO] - Training Epoch: 1/2, step 3678/7134 completed (loss: 4.54703950881958, acc: 0.24683544039726257)
[2024-12-17 02:06:07,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:07,907][root][INFO] - Training Epoch: 1/2, step 3679/7134 completed (loss: 4.372042179107666, acc: 0.23846153914928436)
[2024-12-17 02:06:08,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,313][root][INFO] - Training Epoch: 1/2, step 3680/7134 completed (loss: 3.9500203132629395, acc: 0.35333332419395447)
[2024-12-17 02:06:08,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:08,686][root][INFO] - Training Epoch: 1/2, step 3681/7134 completed (loss: 3.97717022895813, acc: 0.3187499940395355)
[2024-12-17 02:06:08,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,055][root][INFO] - Training Epoch: 1/2, step 3682/7134 completed (loss: 3.9440758228302, acc: 0.3095238208770752)
[2024-12-17 02:06:09,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,423][root][INFO] - Training Epoch: 1/2, step 3683/7134 completed (loss: 4.024909973144531, acc: 0.3235294222831726)
[2024-12-17 02:06:09,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:09,779][root][INFO] - Training Epoch: 1/2, step 3684/7134 completed (loss: 4.218409538269043, acc: 0.2631579041481018)
[2024-12-17 02:06:09,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,138][root][INFO] - Training Epoch: 1/2, step 3685/7134 completed (loss: 4.0322394371032715, acc: 0.3008130192756653)
[2024-12-17 02:06:10,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,526][root][INFO] - Training Epoch: 1/2, step 3686/7134 completed (loss: 3.999451160430908, acc: 0.30985915660858154)
[2024-12-17 02:06:10,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:10,914][root][INFO] - Training Epoch: 1/2, step 3687/7134 completed (loss: 3.897552967071533, acc: 0.31677019596099854)
[2024-12-17 02:06:11,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,317][root][INFO] - Training Epoch: 1/2, step 3688/7134 completed (loss: 3.4971487522125244, acc: 0.28333333134651184)
[2024-12-17 02:06:11,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:11,689][root][INFO] - Training Epoch: 1/2, step 3689/7134 completed (loss: 3.7575666904449463, acc: 0.283687949180603)
[2024-12-17 02:06:11,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,084][root][INFO] - Training Epoch: 1/2, step 3690/7134 completed (loss: 3.8975000381469727, acc: 0.2848101258277893)
[2024-12-17 02:06:12,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,465][root][INFO] - Training Epoch: 1/2, step 3691/7134 completed (loss: 3.3359341621398926, acc: 0.3762376308441162)
[2024-12-17 02:06:12,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:12,889][root][INFO] - Training Epoch: 1/2, step 3692/7134 completed (loss: 3.629359722137451, acc: 0.3190183937549591)
[2024-12-17 02:06:13,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,337][root][INFO] - Training Epoch: 1/2, step 3693/7134 completed (loss: 3.8555426597595215, acc: 0.280303031206131)
[2024-12-17 02:06:13,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:13,730][root][INFO] - Training Epoch: 1/2, step 3694/7134 completed (loss: 3.756441116333008, acc: 0.32499998807907104)
[2024-12-17 02:06:13,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,125][root][INFO] - Training Epoch: 1/2, step 3695/7134 completed (loss: 3.91076397895813, acc: 0.30573248863220215)
[2024-12-17 02:06:14,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,487][root][INFO] - Training Epoch: 1/2, step 3696/7134 completed (loss: 3.706014394760132, acc: 0.2931034564971924)
[2024-12-17 02:06:14,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:14,861][root][INFO] - Training Epoch: 1/2, step 3697/7134 completed (loss: 3.460179090499878, acc: 0.3109756112098694)
[2024-12-17 02:06:14,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,246][root][INFO] - Training Epoch: 1/2, step 3698/7134 completed (loss: 3.764343738555908, acc: 0.2896551787853241)
[2024-12-17 02:06:15,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,606][root][INFO] - Training Epoch: 1/2, step 3699/7134 completed (loss: 3.819040060043335, acc: 0.28346458077430725)
[2024-12-17 02:06:15,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:15,989][root][INFO] - Training Epoch: 1/2, step 3700/7134 completed (loss: 3.487701654434204, acc: 0.31446540355682373)
[2024-12-17 02:06:16,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,384][root][INFO] - Training Epoch: 1/2, step 3701/7134 completed (loss: 3.834045886993408, acc: 0.30656933784484863)
[2024-12-17 02:06:16,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:16,777][root][INFO] - Training Epoch: 1/2, step 3702/7134 completed (loss: 3.880382537841797, acc: 0.27272728085517883)
[2024-12-17 02:06:16,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,169][root][INFO] - Training Epoch: 1/2, step 3703/7134 completed (loss: 3.3414785861968994, acc: 0.33522728085517883)
[2024-12-17 02:06:17,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,556][root][INFO] - Training Epoch: 1/2, step 3704/7134 completed (loss: 4.103641510009766, acc: 0.2871287167072296)
[2024-12-17 02:06:17,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:17,926][root][INFO] - Training Epoch: 1/2, step 3705/7134 completed (loss: 3.926689386367798, acc: 0.3558282256126404)
[2024-12-17 02:06:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,296][root][INFO] - Training Epoch: 1/2, step 3706/7134 completed (loss: 3.801875114440918, acc: 0.3316831588745117)
[2024-12-17 02:06:18,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:18,660][root][INFO] - Training Epoch: 1/2, step 3707/7134 completed (loss: 3.644317626953125, acc: 0.31333333253860474)
[2024-12-17 02:06:18,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,041][root][INFO] - Training Epoch: 1/2, step 3708/7134 completed (loss: 4.059196949005127, acc: 0.2974359095096588)
[2024-12-17 02:06:19,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,430][root][INFO] - Training Epoch: 1/2, step 3709/7134 completed (loss: 3.8729259967803955, acc: 0.32407405972480774)
[2024-12-17 02:06:19,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:19,837][root][INFO] - Training Epoch: 1/2, step 3710/7134 completed (loss: 4.076948642730713, acc: 0.25925925374031067)
[2024-12-17 02:06:19,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,227][root][INFO] - Training Epoch: 1/2, step 3711/7134 completed (loss: 3.884509325027466, acc: 0.3076923191547394)
[2024-12-17 02:06:20,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,614][root][INFO] - Training Epoch: 1/2, step 3712/7134 completed (loss: 4.5947089195251465, acc: 0.29891303181648254)
[2024-12-17 02:06:20,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:20,967][root][INFO] - Training Epoch: 1/2, step 3713/7134 completed (loss: 4.015162467956543, acc: 0.3093525171279907)
[2024-12-17 02:06:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,318][root][INFO] - Training Epoch: 1/2, step 3714/7134 completed (loss: 3.8242886066436768, acc: 0.3056994676589966)
[2024-12-17 02:06:21,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:21,714][root][INFO] - Training Epoch: 1/2, step 3715/7134 completed (loss: 3.7769479751586914, acc: 0.3404255211353302)
[2024-12-17 02:06:21,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,081][root][INFO] - Training Epoch: 1/2, step 3716/7134 completed (loss: 3.6531105041503906, acc: 0.3604061007499695)
[2024-12-17 02:06:22,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,447][root][INFO] - Training Epoch: 1/2, step 3717/7134 completed (loss: 3.7576816082000732, acc: 0.35975611209869385)
[2024-12-17 02:06:22,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:22,839][root][INFO] - Training Epoch: 1/2, step 3718/7134 completed (loss: 3.9283721446990967, acc: 0.3229166567325592)
[2024-12-17 02:06:22,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,228][root][INFO] - Training Epoch: 1/2, step 3719/7134 completed (loss: 3.4812917709350586, acc: 0.3391812741756439)
[2024-12-17 02:06:23,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:23,632][root][INFO] - Training Epoch: 1/2, step 3720/7134 completed (loss: 3.601311445236206, acc: 0.34810125827789307)
[2024-12-17 02:06:23,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,057][root][INFO] - Training Epoch: 1/2, step 3721/7134 completed (loss: 3.942274570465088, acc: 0.3410404622554779)
[2024-12-17 02:06:24,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,417][root][INFO] - Training Epoch: 1/2, step 3722/7134 completed (loss: 4.03776216506958, acc: 0.26424869894981384)
[2024-12-17 02:06:24,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:24,772][root][INFO] - Training Epoch: 1/2, step 3723/7134 completed (loss: 3.7771341800689697, acc: 0.34838709235191345)
[2024-12-17 02:06:24,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,164][root][INFO] - Training Epoch: 1/2, step 3724/7134 completed (loss: 3.8398215770721436, acc: 0.3192771077156067)
[2024-12-17 02:06:25,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,520][root][INFO] - Training Epoch: 1/2, step 3725/7134 completed (loss: 3.9093635082244873, acc: 0.31707316637039185)
[2024-12-17 02:06:25,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:25,896][root][INFO] - Training Epoch: 1/2, step 3726/7134 completed (loss: 3.7486510276794434, acc: 0.3216080367565155)
[2024-12-17 02:06:25,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,285][root][INFO] - Training Epoch: 1/2, step 3727/7134 completed (loss: 3.6207289695739746, acc: 0.3583815097808838)
[2024-12-17 02:06:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:26,679][root][INFO] - Training Epoch: 1/2, step 3728/7134 completed (loss: 4.21729850769043, acc: 0.23645320534706116)
[2024-12-17 02:06:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,050][root][INFO] - Training Epoch: 1/2, step 3729/7134 completed (loss: 3.811628818511963, acc: 0.31603774428367615)
[2024-12-17 02:06:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,435][root][INFO] - Training Epoch: 1/2, step 3730/7134 completed (loss: 4.069246768951416, acc: 0.2545454502105713)
[2024-12-17 02:06:27,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:27,836][root][INFO] - Training Epoch: 1/2, step 3731/7134 completed (loss: 3.933060884475708, acc: 0.2931034564971924)
[2024-12-17 02:06:27,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,222][root][INFO] - Training Epoch: 1/2, step 3732/7134 completed (loss: 4.2148051261901855, acc: 0.26153847575187683)
[2024-12-17 02:06:28,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,609][root][INFO] - Training Epoch: 1/2, step 3733/7134 completed (loss: 3.686086654663086, acc: 0.35403725504875183)
[2024-12-17 02:06:28,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:28,990][root][INFO] - Training Epoch: 1/2, step 3734/7134 completed (loss: 4.182572364807129, acc: 0.26923078298568726)
[2024-12-17 02:06:29,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,350][root][INFO] - Training Epoch: 1/2, step 3735/7134 completed (loss: 4.240942001342773, acc: 0.31168830394744873)
[2024-12-17 02:06:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:29,735][root][INFO] - Training Epoch: 1/2, step 3736/7134 completed (loss: 4.36964750289917, acc: 0.29411765933036804)
[2024-12-17 02:06:29,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,131][root][INFO] - Training Epoch: 1/2, step 3737/7134 completed (loss: 3.682832956314087, acc: 0.35151514410972595)
[2024-12-17 02:06:30,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,497][root][INFO] - Training Epoch: 1/2, step 3738/7134 completed (loss: 4.014952659606934, acc: 0.2847222089767456)
[2024-12-17 02:06:30,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:30,873][root][INFO] - Training Epoch: 1/2, step 3739/7134 completed (loss: 3.836134910583496, acc: 0.27659574151039124)
[2024-12-17 02:06:30,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,236][root][INFO] - Training Epoch: 1/2, step 3740/7134 completed (loss: 3.6263933181762695, acc: 0.30573248863220215)
[2024-12-17 02:06:31,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,594][root][INFO] - Training Epoch: 1/2, step 3741/7134 completed (loss: 3.940107583999634, acc: 0.28735631704330444)
[2024-12-17 02:06:31,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:31,963][root][INFO] - Training Epoch: 1/2, step 3742/7134 completed (loss: 3.977280378341675, acc: 0.2789115607738495)
[2024-12-17 02:06:32,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,314][root][INFO] - Training Epoch: 1/2, step 3743/7134 completed (loss: 3.997960329055786, acc: 0.29411765933036804)
[2024-12-17 02:06:32,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:32,678][root][INFO] - Training Epoch: 1/2, step 3744/7134 completed (loss: 4.3730597496032715, acc: 0.1860465109348297)
[2024-12-17 02:06:32,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,061][root][INFO] - Training Epoch: 1/2, step 3745/7134 completed (loss: 4.163168430328369, acc: 0.2380952388048172)
[2024-12-17 02:06:33,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,468][root][INFO] - Training Epoch: 1/2, step 3746/7134 completed (loss: 3.8594295978546143, acc: 0.2881355881690979)
[2024-12-17 02:06:33,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:33,884][root][INFO] - Training Epoch: 1/2, step 3747/7134 completed (loss: 3.7246835231781006, acc: 0.3055555522441864)
[2024-12-17 02:06:34,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,301][root][INFO] - Training Epoch: 1/2, step 3748/7134 completed (loss: 3.334780216217041, acc: 0.3933333456516266)
[2024-12-17 02:06:34,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:34,715][root][INFO] - Training Epoch: 1/2, step 3749/7134 completed (loss: 3.6301236152648926, acc: 0.369047611951828)
[2024-12-17 02:06:34,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,125][root][INFO] - Training Epoch: 1/2, step 3750/7134 completed (loss: 3.522735834121704, acc: 0.3742331266403198)
[2024-12-17 02:06:35,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,519][root][INFO] - Training Epoch: 1/2, step 3751/7134 completed (loss: 3.4393012523651123, acc: 0.3674698770046234)
[2024-12-17 02:06:35,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:35,903][root][INFO] - Training Epoch: 1/2, step 3752/7134 completed (loss: 3.8781309127807617, acc: 0.2830188572406769)
[2024-12-17 02:06:36,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,284][root][INFO] - Training Epoch: 1/2, step 3753/7134 completed (loss: 4.1961188316345215, acc: 0.2638036906719208)
[2024-12-17 02:06:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:36,662][root][INFO] - Training Epoch: 1/2, step 3754/7134 completed (loss: 3.88767671585083, acc: 0.2967741787433624)
[2024-12-17 02:06:36,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,039][root][INFO] - Training Epoch: 1/2, step 3755/7134 completed (loss: 4.000298500061035, acc: 0.24793387949466705)
[2024-12-17 02:06:37,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,407][root][INFO] - Training Epoch: 1/2, step 3756/7134 completed (loss: 3.731827735900879, acc: 0.323699414730072)
[2024-12-17 02:06:37,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:37,793][root][INFO] - Training Epoch: 1/2, step 3757/7134 completed (loss: 4.16459321975708, acc: 0.29870128631591797)
[2024-12-17 02:06:37,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,177][root][INFO] - Training Epoch: 1/2, step 3758/7134 completed (loss: 3.9509329795837402, acc: 0.28346458077430725)
[2024-12-17 02:06:38,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,529][root][INFO] - Training Epoch: 1/2, step 3759/7134 completed (loss: 3.8994972705841064, acc: 0.3356643319129944)
[2024-12-17 02:06:38,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:38,929][root][INFO] - Training Epoch: 1/2, step 3760/7134 completed (loss: 3.4257960319519043, acc: 0.3353658616542816)
[2024-12-17 02:06:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,283][root][INFO] - Training Epoch: 1/2, step 3761/7134 completed (loss: 4.346189022064209, acc: 0.280303031206131)
[2024-12-17 02:06:39,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:39,643][root][INFO] - Training Epoch: 1/2, step 3762/7134 completed (loss: 4.26654577255249, acc: 0.28289473056793213)
[2024-12-17 02:06:39,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,015][root][INFO] - Training Epoch: 1/2, step 3763/7134 completed (loss: 4.087881088256836, acc: 0.2571428716182709)
[2024-12-17 02:06:40,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,443][root][INFO] - Training Epoch: 1/2, step 3764/7134 completed (loss: 4.453145980834961, acc: 0.299401193857193)
[2024-12-17 02:06:40,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:40,863][root][INFO] - Training Epoch: 1/2, step 3765/7134 completed (loss: 3.890547275543213, acc: 0.3238636255264282)
[2024-12-17 02:06:40,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,193][root][INFO] - Training Epoch: 1/2, step 3766/7134 completed (loss: 3.993366003036499, acc: 0.281879186630249)
[2024-12-17 02:06:41,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,573][root][INFO] - Training Epoch: 1/2, step 3767/7134 completed (loss: 3.9632813930511475, acc: 0.2793295979499817)
[2024-12-17 02:06:41,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:41,934][root][INFO] - Training Epoch: 1/2, step 3768/7134 completed (loss: 4.674422740936279, acc: 0.2211538404226303)
[2024-12-17 02:06:42,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,312][root][INFO] - Training Epoch: 1/2, step 3769/7134 completed (loss: 4.006912708282471, acc: 0.28823530673980713)
[2024-12-17 02:06:42,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:42,692][root][INFO] - Training Epoch: 1/2, step 3770/7134 completed (loss: 3.8706295490264893, acc: 0.2751677930355072)
[2024-12-17 02:06:42,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,062][root][INFO] - Training Epoch: 1/2, step 3771/7134 completed (loss: 4.190242767333984, acc: 0.22368420660495758)
[2024-12-17 02:06:43,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,432][root][INFO] - Training Epoch: 1/2, step 3772/7134 completed (loss: 4.484062194824219, acc: 0.25)
[2024-12-17 02:06:43,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:43,817][root][INFO] - Training Epoch: 1/2, step 3773/7134 completed (loss: 3.9915947914123535, acc: 0.2978723347187042)
[2024-12-17 02:06:43,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,215][root][INFO] - Training Epoch: 1/2, step 3774/7134 completed (loss: 4.38606595993042, acc: 0.24725274741649628)
[2024-12-17 02:06:44,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,610][root][INFO] - Training Epoch: 1/2, step 3775/7134 completed (loss: 3.9930312633514404, acc: 0.2857142984867096)
[2024-12-17 02:06:44,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:44,995][root][INFO] - Training Epoch: 1/2, step 3776/7134 completed (loss: 4.5446295738220215, acc: 0.23076923191547394)
[2024-12-17 02:06:45,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,369][root][INFO] - Training Epoch: 1/2, step 3777/7134 completed (loss: 3.8267288208007812, acc: 0.3176470696926117)
[2024-12-17 02:06:45,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:45,765][root][INFO] - Training Epoch: 1/2, step 3778/7134 completed (loss: 4.157314300537109, acc: 0.2848837077617645)
[2024-12-17 02:06:45,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,143][root][INFO] - Training Epoch: 1/2, step 3779/7134 completed (loss: 4.319821834564209, acc: 0.3062500059604645)
[2024-12-17 02:06:46,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,518][root][INFO] - Training Epoch: 1/2, step 3780/7134 completed (loss: 3.6771976947784424, acc: 0.3393939435482025)
[2024-12-17 02:06:46,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:46,861][root][INFO] - Training Epoch: 1/2, step 3781/7134 completed (loss: 3.762970209121704, acc: 0.34161490201950073)
[2024-12-17 02:06:46,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,219][root][INFO] - Training Epoch: 1/2, step 3782/7134 completed (loss: 4.017948150634766, acc: 0.3207547068595886)
[2024-12-17 02:06:47,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,585][root][INFO] - Training Epoch: 1/2, step 3783/7134 completed (loss: 4.1903276443481445, acc: 0.3195266127586365)
[2024-12-17 02:06:47,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:47,963][root][INFO] - Training Epoch: 1/2, step 3784/7134 completed (loss: 4.373371601104736, acc: 0.28859061002731323)
[2024-12-17 02:06:48,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,359][root][INFO] - Training Epoch: 1/2, step 3785/7134 completed (loss: 3.927844762802124, acc: 0.2978723347187042)
[2024-12-17 02:06:48,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:48,719][root][INFO] - Training Epoch: 1/2, step 3786/7134 completed (loss: 3.9887821674346924, acc: 0.2678571343421936)
[2024-12-17 02:06:48,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,078][root][INFO] - Training Epoch: 1/2, step 3787/7134 completed (loss: 4.27910852432251, acc: 0.2846153974533081)
[2024-12-17 02:06:49,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,458][root][INFO] - Training Epoch: 1/2, step 3788/7134 completed (loss: 4.37753438949585, acc: 0.2638036906719208)
[2024-12-17 02:06:49,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:49,821][root][INFO] - Training Epoch: 1/2, step 3789/7134 completed (loss: 4.122679233551025, acc: 0.3117647171020508)
[2024-12-17 02:06:49,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,214][root][INFO] - Training Epoch: 1/2, step 3790/7134 completed (loss: 4.66532039642334, acc: 0.2647058963775635)
[2024-12-17 02:06:50,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,614][root][INFO] - Training Epoch: 1/2, step 3791/7134 completed (loss: 3.650214910507202, acc: 0.3410404622554779)
[2024-12-17 02:06:50,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:50,998][root][INFO] - Training Epoch: 1/2, step 3792/7134 completed (loss: 4.2506422996521, acc: 0.29323309659957886)
[2024-12-17 02:06:51,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,379][root][INFO] - Training Epoch: 1/2, step 3793/7134 completed (loss: 3.9867842197418213, acc: 0.29885056614875793)
[2024-12-17 02:06:51,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:51,782][root][INFO] - Training Epoch: 1/2, step 3794/7134 completed (loss: 4.084057807922363, acc: 0.2944444417953491)
[2024-12-17 02:06:51,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,178][root][INFO] - Training Epoch: 1/2, step 3795/7134 completed (loss: 4.411879062652588, acc: 0.2888889014720917)
[2024-12-17 02:06:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,551][root][INFO] - Training Epoch: 1/2, step 3796/7134 completed (loss: 4.485938549041748, acc: 0.22807016968727112)
[2024-12-17 02:06:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:52,929][root][INFO] - Training Epoch: 1/2, step 3797/7134 completed (loss: 4.100794792175293, acc: 0.3030303120613098)
[2024-12-17 02:06:53,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,344][root][INFO] - Training Epoch: 1/2, step 3798/7134 completed (loss: 4.61176872253418, acc: 0.2515723407268524)
[2024-12-17 02:06:53,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:53,736][root][INFO] - Training Epoch: 1/2, step 3799/7134 completed (loss: 4.321488857269287, acc: 0.2881355881690979)
[2024-12-17 02:06:53,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,154][root][INFO] - Training Epoch: 1/2, step 3800/7134 completed (loss: 4.243405818939209, acc: 0.3379310369491577)
[2024-12-17 02:06:54,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,522][root][INFO] - Training Epoch: 1/2, step 3801/7134 completed (loss: 4.325327396392822, acc: 0.28176796436309814)
[2024-12-17 02:06:54,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:54,911][root][INFO] - Training Epoch: 1/2, step 3802/7134 completed (loss: 4.485311031341553, acc: 0.2760416567325592)
[2024-12-17 02:06:55,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,293][root][INFO] - Training Epoch: 1/2, step 3803/7134 completed (loss: 3.727511405944824, acc: 0.36305731534957886)
[2024-12-17 02:06:55,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:55,670][root][INFO] - Training Epoch: 1/2, step 3804/7134 completed (loss: 4.346224308013916, acc: 0.3239436745643616)
[2024-12-17 02:06:55,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,059][root][INFO] - Training Epoch: 1/2, step 3805/7134 completed (loss: 3.9474260807037354, acc: 0.3199999928474426)
[2024-12-17 02:06:56,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,414][root][INFO] - Training Epoch: 1/2, step 3806/7134 completed (loss: 4.211693286895752, acc: 0.32407405972480774)
[2024-12-17 02:06:56,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:56,789][root][INFO] - Training Epoch: 1/2, step 3807/7134 completed (loss: 4.08546257019043, acc: 0.31506848335266113)
[2024-12-17 02:06:56,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,183][root][INFO] - Training Epoch: 1/2, step 3808/7134 completed (loss: 3.780838966369629, acc: 0.31521740555763245)
[2024-12-17 02:06:57,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,550][root][INFO] - Training Epoch: 1/2, step 3809/7134 completed (loss: 4.384533405303955, acc: 0.302325576543808)
[2024-12-17 02:06:57,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:57,936][root][INFO] - Training Epoch: 1/2, step 3810/7134 completed (loss: 3.6233832836151123, acc: 0.3181818127632141)
[2024-12-17 02:06:58,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,325][root][INFO] - Training Epoch: 1/2, step 3811/7134 completed (loss: 3.760629892349243, acc: 0.3652694523334503)
[2024-12-17 02:06:58,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:58,771][root][INFO] - Training Epoch: 1/2, step 3812/7134 completed (loss: 4.27864933013916, acc: 0.2925170063972473)
[2024-12-17 02:06:58,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,191][root][INFO] - Training Epoch: 1/2, step 3813/7134 completed (loss: 4.037985324859619, acc: 0.29729729890823364)
[2024-12-17 02:06:59,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,575][root][INFO] - Training Epoch: 1/2, step 3814/7134 completed (loss: 4.0275678634643555, acc: 0.3028571307659149)
[2024-12-17 02:06:59,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:06:59,956][root][INFO] - Training Epoch: 1/2, step 3815/7134 completed (loss: 4.289148330688477, acc: 0.2697368562221527)
[2024-12-17 02:07:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,338][root][INFO] - Training Epoch: 1/2, step 3816/7134 completed (loss: 4.582182884216309, acc: 0.26865673065185547)
[2024-12-17 02:07:00,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:00,701][root][INFO] - Training Epoch: 1/2, step 3817/7134 completed (loss: 4.33301305770874, acc: 0.33707866072654724)
[2024-12-17 02:07:00,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,079][root][INFO] - Training Epoch: 1/2, step 3818/7134 completed (loss: 4.416010856628418, acc: 0.28947368264198303)
[2024-12-17 02:07:01,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,409][root][INFO] - Training Epoch: 1/2, step 3819/7134 completed (loss: 4.692171573638916, acc: 0.20000000298023224)
[2024-12-17 02:07:01,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:01,745][root][INFO] - Training Epoch: 1/2, step 3820/7134 completed (loss: 4.62877893447876, acc: 0.29629629850387573)
[2024-12-17 02:07:01,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,127][root][INFO] - Training Epoch: 1/2, step 3821/7134 completed (loss: 3.8510942459106445, acc: 0.267123281955719)
[2024-12-17 02:07:02,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:02,584][root][INFO] - Training Epoch: 1/2, step 3822/7134 completed (loss: 4.219918727874756, acc: 0.30188679695129395)
[2024-12-17 02:07:02,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,001][root][INFO] - Training Epoch: 1/2, step 3823/7134 completed (loss: 4.318541049957275, acc: 0.29530200362205505)
[2024-12-17 02:07:03,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,398][root][INFO] - Training Epoch: 1/2, step 3824/7134 completed (loss: 3.9477899074554443, acc: 0.3125)
[2024-12-17 02:07:03,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:03,792][root][INFO] - Training Epoch: 1/2, step 3825/7134 completed (loss: 4.22321081161499, acc: 0.3055555522441864)
[2024-12-17 02:07:03,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,187][root][INFO] - Training Epoch: 1/2, step 3826/7134 completed (loss: 4.064233779907227, acc: 0.3309859037399292)
[2024-12-17 02:07:04,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:04,615][root][INFO] - Training Epoch: 1/2, step 3827/7134 completed (loss: 4.035781383514404, acc: 0.3248407542705536)
[2024-12-17 02:07:04,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,029][root][INFO] - Training Epoch: 1/2, step 3828/7134 completed (loss: 4.175306797027588, acc: 0.32499998807907104)
[2024-12-17 02:07:05,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,388][root][INFO] - Training Epoch: 1/2, step 3829/7134 completed (loss: 4.469600677490234, acc: 0.2734375)
[2024-12-17 02:07:05,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:05,753][root][INFO] - Training Epoch: 1/2, step 3830/7134 completed (loss: 4.0681304931640625, acc: 0.28148147463798523)
[2024-12-17 02:07:05,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,117][root][INFO] - Training Epoch: 1/2, step 3831/7134 completed (loss: 3.889214277267456, acc: 0.2434210479259491)
[2024-12-17 02:07:06,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,491][root][INFO] - Training Epoch: 1/2, step 3832/7134 completed (loss: 3.2999656200408936, acc: 0.3035714328289032)
[2024-12-17 02:07:06,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:06,878][root][INFO] - Training Epoch: 1/2, step 3833/7134 completed (loss: 3.216014862060547, acc: 0.4098360538482666)
[2024-12-17 02:07:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,241][root][INFO] - Training Epoch: 1/2, step 3834/7134 completed (loss: 3.435786485671997, acc: 0.2804878056049347)
[2024-12-17 02:07:07,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:07,607][root][INFO] - Training Epoch: 1/2, step 3835/7134 completed (loss: 3.436366319656372, acc: 0.328125)
[2024-12-17 02:07:07,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,022][root][INFO] - Training Epoch: 1/2, step 3836/7134 completed (loss: 3.496048927307129, acc: 0.2716049253940582)
[2024-12-17 02:07:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,386][root][INFO] - Training Epoch: 1/2, step 3837/7134 completed (loss: 3.2619473934173584, acc: 0.3757961690425873)
[2024-12-17 02:07:08,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:08,768][root][INFO] - Training Epoch: 1/2, step 3838/7134 completed (loss: 3.393665075302124, acc: 0.3258427083492279)
[2024-12-17 02:07:08,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,204][root][INFO] - Training Epoch: 1/2, step 3839/7134 completed (loss: 3.2910664081573486, acc: 0.3664596378803253)
[2024-12-17 02:07:09,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,584][root][INFO] - Training Epoch: 1/2, step 3840/7134 completed (loss: 3.432030200958252, acc: 0.290909081697464)
[2024-12-17 02:07:09,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:09,989][root][INFO] - Training Epoch: 1/2, step 3841/7134 completed (loss: 4.057380676269531, acc: 0.286432147026062)
[2024-12-17 02:07:10,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,345][root][INFO] - Training Epoch: 1/2, step 3842/7134 completed (loss: 3.554612874984741, acc: 0.27835050225257874)
[2024-12-17 02:07:10,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:10,781][root][INFO] - Training Epoch: 1/2, step 3843/7134 completed (loss: 3.5256705284118652, acc: 0.3378378450870514)
[2024-12-17 02:07:10,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,160][root][INFO] - Training Epoch: 1/2, step 3844/7134 completed (loss: 3.7378571033477783, acc: 0.32460734248161316)
[2024-12-17 02:07:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,525][root][INFO] - Training Epoch: 1/2, step 3845/7134 completed (loss: 3.3695425987243652, acc: 0.3499999940395355)
[2024-12-17 02:07:11,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:11,936][root][INFO] - Training Epoch: 1/2, step 3846/7134 completed (loss: 3.3272011280059814, acc: 0.37226277589797974)
[2024-12-17 02:07:12,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,290][root][INFO] - Training Epoch: 1/2, step 3847/7134 completed (loss: 3.591789484024048, acc: 0.347517728805542)
[2024-12-17 02:07:12,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:12,670][root][INFO] - Training Epoch: 1/2, step 3848/7134 completed (loss: 3.3210389614105225, acc: 0.34090909361839294)
[2024-12-17 02:07:12,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,037][root][INFO] - Training Epoch: 1/2, step 3849/7134 completed (loss: 3.2180275917053223, acc: 0.3629629611968994)
[2024-12-17 02:07:13,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,369][root][INFO] - Training Epoch: 1/2, step 3850/7134 completed (loss: 4.17470121383667, acc: 0.3060109317302704)
[2024-12-17 02:07:13,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:13,755][root][INFO] - Training Epoch: 1/2, step 3851/7134 completed (loss: 3.738616466522217, acc: 0.3214285671710968)
[2024-12-17 02:07:13,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,127][root][INFO] - Training Epoch: 1/2, step 3852/7134 completed (loss: 3.3079793453216553, acc: 0.34532374143600464)
[2024-12-17 02:07:14,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,488][root][INFO] - Training Epoch: 1/2, step 3853/7134 completed (loss: 3.845987558364868, acc: 0.3687150776386261)
[2024-12-17 02:07:14,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:14,853][root][INFO] - Training Epoch: 1/2, step 3854/7134 completed (loss: 3.6998143196105957, acc: 0.3248407542705536)
[2024-12-17 02:07:14,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,239][root][INFO] - Training Epoch: 1/2, step 3855/7134 completed (loss: 4.108908176422119, acc: 0.27544909715652466)
[2024-12-17 02:07:15,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:15,620][root][INFO] - Training Epoch: 1/2, step 3856/7134 completed (loss: 3.5047497749328613, acc: 0.41401273012161255)
[2024-12-17 02:07:15,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,003][root][INFO] - Training Epoch: 1/2, step 3857/7134 completed (loss: 3.8578407764434814, acc: 0.2567567527294159)
[2024-12-17 02:07:16,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,397][root][INFO] - Training Epoch: 1/2, step 3858/7134 completed (loss: 3.7203879356384277, acc: 0.3375000059604645)
[2024-12-17 02:07:16,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:16,758][root][INFO] - Training Epoch: 1/2, step 3859/7134 completed (loss: 3.634049654006958, acc: 0.35593220591545105)
[2024-12-17 02:07:16,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,117][root][INFO] - Training Epoch: 1/2, step 3860/7134 completed (loss: 3.3342766761779785, acc: 0.3560209572315216)
[2024-12-17 02:07:17,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,472][root][INFO] - Training Epoch: 1/2, step 3861/7134 completed (loss: 4.18646764755249, acc: 0.2549019753932953)
[2024-12-17 02:07:17,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:17,849][root][INFO] - Training Epoch: 1/2, step 3862/7134 completed (loss: 3.7813594341278076, acc: 0.3076923191547394)
[2024-12-17 02:07:17,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,230][root][INFO] - Training Epoch: 1/2, step 3863/7134 completed (loss: 3.790743112564087, acc: 0.26744186878204346)
[2024-12-17 02:07:18,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,598][root][INFO] - Training Epoch: 1/2, step 3864/7134 completed (loss: 4.467040538787842, acc: 0.31168830394744873)
[2024-12-17 02:07:18,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:18,977][root][INFO] - Training Epoch: 1/2, step 3865/7134 completed (loss: 4.607899188995361, acc: 0.2232142835855484)
[2024-12-17 02:07:19,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,354][root][INFO] - Training Epoch: 1/2, step 3866/7134 completed (loss: 3.5421226024627686, acc: 0.3199999928474426)
[2024-12-17 02:07:19,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:19,740][root][INFO] - Training Epoch: 1/2, step 3867/7134 completed (loss: 4.1891045570373535, acc: 0.23636363446712494)
[2024-12-17 02:07:19,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,103][root][INFO] - Training Epoch: 1/2, step 3868/7134 completed (loss: 3.7503018379211426, acc: 0.34558823704719543)
[2024-12-17 02:07:20,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,464][root][INFO] - Training Epoch: 1/2, step 3869/7134 completed (loss: 4.084280014038086, acc: 0.25874125957489014)
[2024-12-17 02:07:20,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:20,844][root][INFO] - Training Epoch: 1/2, step 3870/7134 completed (loss: 4.16102409362793, acc: 0.27450981736183167)
[2024-12-17 02:07:20,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,244][root][INFO] - Training Epoch: 1/2, step 3871/7134 completed (loss: 3.5888783931732178, acc: 0.3735632300376892)
[2024-12-17 02:07:21,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,612][root][INFO] - Training Epoch: 1/2, step 3872/7134 completed (loss: 3.5684781074523926, acc: 0.33838382363319397)
[2024-12-17 02:07:21,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:21,952][root][INFO] - Training Epoch: 1/2, step 3873/7134 completed (loss: 3.72967267036438, acc: 0.3030303120613098)
[2024-12-17 02:07:22,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,291][root][INFO] - Training Epoch: 1/2, step 3874/7134 completed (loss: 3.7015509605407715, acc: 0.3742690086364746)
[2024-12-17 02:07:22,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:22,658][root][INFO] - Training Epoch: 1/2, step 3875/7134 completed (loss: 3.882904529571533, acc: 0.31012657284736633)
[2024-12-17 02:07:22,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,040][root][INFO] - Training Epoch: 1/2, step 3876/7134 completed (loss: 3.7599990367889404, acc: 0.29600000381469727)
[2024-12-17 02:07:23,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,398][root][INFO] - Training Epoch: 1/2, step 3877/7134 completed (loss: 3.6631317138671875, acc: 0.31976744532585144)
[2024-12-17 02:07:23,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:23,764][root][INFO] - Training Epoch: 1/2, step 3878/7134 completed (loss: 4.849857807159424, acc: 0.22093023359775543)
[2024-12-17 02:07:23,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,165][root][INFO] - Training Epoch: 1/2, step 3879/7134 completed (loss: 3.6218862533569336, acc: 0.35820895433425903)
[2024-12-17 02:07:24,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,555][root][INFO] - Training Epoch: 1/2, step 3880/7134 completed (loss: 3.9543676376342773, acc: 0.28205129504203796)
[2024-12-17 02:07:24,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:24,922][root][INFO] - Training Epoch: 1/2, step 3881/7134 completed (loss: 4.398390293121338, acc: 0.25668448209762573)
[2024-12-17 02:07:25,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,291][root][INFO] - Training Epoch: 1/2, step 3882/7134 completed (loss: 4.1519455909729, acc: 0.3298968970775604)
[2024-12-17 02:07:25,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:25,652][root][INFO] - Training Epoch: 1/2, step 3883/7134 completed (loss: 4.244016647338867, acc: 0.3137255012989044)
[2024-12-17 02:07:25,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,042][root][INFO] - Training Epoch: 1/2, step 3884/7134 completed (loss: 3.744029998779297, acc: 0.3199999928474426)
[2024-12-17 02:07:26,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,451][root][INFO] - Training Epoch: 1/2, step 3885/7134 completed (loss: 3.9277265071868896, acc: 0.331210196018219)
[2024-12-17 02:07:26,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:26,842][root][INFO] - Training Epoch: 1/2, step 3886/7134 completed (loss: 3.7232394218444824, acc: 0.3333333432674408)
[2024-12-17 02:07:26,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,193][root][INFO] - Training Epoch: 1/2, step 3887/7134 completed (loss: 3.571307897567749, acc: 0.2830188572406769)
[2024-12-17 02:07:27,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,580][root][INFO] - Training Epoch: 1/2, step 3888/7134 completed (loss: 4.195333957672119, acc: 0.25)
[2024-12-17 02:07:27,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:27,979][root][INFO] - Training Epoch: 1/2, step 3889/7134 completed (loss: 3.592423677444458, acc: 0.3672316372394562)
[2024-12-17 02:07:28,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,374][root][INFO] - Training Epoch: 1/2, step 3890/7134 completed (loss: 3.5735464096069336, acc: 0.3298968970775604)
[2024-12-17 02:07:28,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:28,752][root][INFO] - Training Epoch: 1/2, step 3891/7134 completed (loss: 3.5201995372772217, acc: 0.3583815097808838)
[2024-12-17 02:07:28,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,125][root][INFO] - Training Epoch: 1/2, step 3892/7134 completed (loss: 4.026163101196289, acc: 0.30000001192092896)
[2024-12-17 02:07:29,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,503][root][INFO] - Training Epoch: 1/2, step 3893/7134 completed (loss: 3.8805410861968994, acc: 0.30927833914756775)
[2024-12-17 02:07:29,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:29,859][root][INFO] - Training Epoch: 1/2, step 3894/7134 completed (loss: 4.325023174285889, acc: 0.29113924503326416)
[2024-12-17 02:07:29,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,233][root][INFO] - Training Epoch: 1/2, step 3895/7134 completed (loss: 3.8509929180145264, acc: 0.36464089155197144)
[2024-12-17 02:07:30,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:30,621][root][INFO] - Training Epoch: 1/2, step 3896/7134 completed (loss: 3.6602954864501953, acc: 0.34597155451774597)
[2024-12-17 02:07:30,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,003][root][INFO] - Training Epoch: 1/2, step 3897/7134 completed (loss: 3.9385762214660645, acc: 0.29651162028312683)
[2024-12-17 02:07:31,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,377][root][INFO] - Training Epoch: 1/2, step 3898/7134 completed (loss: 3.9191441535949707, acc: 0.32758620381355286)
[2024-12-17 02:07:31,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:31,739][root][INFO] - Training Epoch: 1/2, step 3899/7134 completed (loss: 4.057301044464111, acc: 0.323699414730072)
[2024-12-17 02:07:31,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,123][root][INFO] - Training Epoch: 1/2, step 3900/7134 completed (loss: 3.7467634677886963, acc: 0.3711340129375458)
[2024-12-17 02:07:32,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,479][root][INFO] - Training Epoch: 1/2, step 3901/7134 completed (loss: 4.505096912384033, acc: 0.33734938502311707)
[2024-12-17 02:07:32,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:32,848][root][INFO] - Training Epoch: 1/2, step 3902/7134 completed (loss: 4.4803032875061035, acc: 0.2447916716337204)
[2024-12-17 02:07:32,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,241][root][INFO] - Training Epoch: 1/2, step 3903/7134 completed (loss: 4.548105239868164, acc: 0.30051812529563904)
[2024-12-17 02:07:33,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,598][root][INFO] - Training Epoch: 1/2, step 3904/7134 completed (loss: 4.453792572021484, acc: 0.23976607620716095)
[2024-12-17 02:07:33,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:33,984][root][INFO] - Training Epoch: 1/2, step 3905/7134 completed (loss: 3.895846128463745, acc: 0.2888889014720917)
[2024-12-17 02:07:34,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,357][root][INFO] - Training Epoch: 1/2, step 3906/7134 completed (loss: 3.6678316593170166, acc: 0.30337077379226685)
[2024-12-17 02:07:34,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:34,709][root][INFO] - Training Epoch: 1/2, step 3907/7134 completed (loss: 3.9607040882110596, acc: 0.3195876181125641)
[2024-12-17 02:07:34,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,107][root][INFO] - Training Epoch: 1/2, step 3908/7134 completed (loss: 4.2473273277282715, acc: 0.2658959627151489)
[2024-12-17 02:07:35,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,487][root][INFO] - Training Epoch: 1/2, step 3909/7134 completed (loss: 4.129618167877197, acc: 0.24528302252292633)
[2024-12-17 02:07:35,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:35,875][root][INFO] - Training Epoch: 1/2, step 3910/7134 completed (loss: 4.202988624572754, acc: 0.23295454680919647)
[2024-12-17 02:07:35,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,245][root][INFO] - Training Epoch: 1/2, step 3911/7134 completed (loss: 3.663633346557617, acc: 0.276729553937912)
[2024-12-17 02:07:36,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:36,626][root][INFO] - Training Epoch: 1/2, step 3912/7134 completed (loss: 3.5008602142333984, acc: 0.30588236451148987)
[2024-12-17 02:07:36,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,021][root][INFO] - Training Epoch: 1/2, step 3913/7134 completed (loss: 3.758991003036499, acc: 0.26767677068710327)
[2024-12-17 02:07:37,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,374][root][INFO] - Training Epoch: 1/2, step 3914/7134 completed (loss: 3.8187036514282227, acc: 0.3396226465702057)
[2024-12-17 02:07:37,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:37,736][root][INFO] - Training Epoch: 1/2, step 3915/7134 completed (loss: 3.5736091136932373, acc: 0.36206895112991333)
[2024-12-17 02:07:37,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,103][root][INFO] - Training Epoch: 1/2, step 3916/7134 completed (loss: 3.6205334663391113, acc: 0.38265305757522583)
[2024-12-17 02:07:38,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,461][root][INFO] - Training Epoch: 1/2, step 3917/7134 completed (loss: 3.3407278060913086, acc: 0.3813953399658203)
[2024-12-17 02:07:38,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:38,837][root][INFO] - Training Epoch: 1/2, step 3918/7134 completed (loss: 3.720604419708252, acc: 0.34761905670166016)
[2024-12-17 02:07:38,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,212][root][INFO] - Training Epoch: 1/2, step 3919/7134 completed (loss: 4.106754302978516, acc: 0.26035502552986145)
[2024-12-17 02:07:39,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,633][root][INFO] - Training Epoch: 1/2, step 3920/7134 completed (loss: 4.469047546386719, acc: 0.2514970004558563)
[2024-12-17 02:07:39,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:39,999][root][INFO] - Training Epoch: 1/2, step 3921/7134 completed (loss: 4.073752403259277, acc: 0.2887323796749115)
[2024-12-17 02:07:40,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,364][root][INFO] - Training Epoch: 1/2, step 3922/7134 completed (loss: 4.26230525970459, acc: 0.2922077775001526)
[2024-12-17 02:07:40,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:40,727][root][INFO] - Training Epoch: 1/2, step 3923/7134 completed (loss: 4.3225836753845215, acc: 0.2797619104385376)
[2024-12-17 02:07:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,108][root][INFO] - Training Epoch: 1/2, step 3924/7134 completed (loss: 3.946688652038574, acc: 0.2680412232875824)
[2024-12-17 02:07:41,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,486][root][INFO] - Training Epoch: 1/2, step 3925/7134 completed (loss: 3.7062811851501465, acc: 0.3038673996925354)
[2024-12-17 02:07:41,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:41,850][root][INFO] - Training Epoch: 1/2, step 3926/7134 completed (loss: 4.265841484069824, acc: 0.26582279801368713)
[2024-12-17 02:07:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,239][root][INFO] - Training Epoch: 1/2, step 3927/7134 completed (loss: 4.306099891662598, acc: 0.24242424964904785)
[2024-12-17 02:07:42,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:42,656][root][INFO] - Training Epoch: 1/2, step 3928/7134 completed (loss: 4.180271625518799, acc: 0.27544909715652466)
[2024-12-17 02:07:42,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,016][root][INFO] - Training Epoch: 1/2, step 3929/7134 completed (loss: 4.124206066131592, acc: 0.2922077775001526)
[2024-12-17 02:07:43,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,412][root][INFO] - Training Epoch: 1/2, step 3930/7134 completed (loss: 4.298217296600342, acc: 0.29661017656326294)
[2024-12-17 02:07:43,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:43,780][root][INFO] - Training Epoch: 1/2, step 3931/7134 completed (loss: 3.8138115406036377, acc: 0.27848100662231445)
[2024-12-17 02:07:43,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,177][root][INFO] - Training Epoch: 1/2, step 3932/7134 completed (loss: 4.134765148162842, acc: 0.2818181812763214)
[2024-12-17 02:07:44,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,527][root][INFO] - Training Epoch: 1/2, step 3933/7134 completed (loss: 4.3889946937561035, acc: 0.22857142984867096)
[2024-12-17 02:07:44,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:44,884][root][INFO] - Training Epoch: 1/2, step 3934/7134 completed (loss: 3.991607427597046, acc: 0.2777777910232544)
[2024-12-17 02:07:45,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,274][root][INFO] - Training Epoch: 1/2, step 3935/7134 completed (loss: 3.753061294555664, acc: 0.21917808055877686)
[2024-12-17 02:07:45,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:45,653][root][INFO] - Training Epoch: 1/2, step 3936/7134 completed (loss: 4.067448139190674, acc: 0.25)
[2024-12-17 02:07:45,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,043][root][INFO] - Training Epoch: 1/2, step 3937/7134 completed (loss: 3.941246747970581, acc: 0.26271185278892517)
[2024-12-17 02:07:46,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,390][root][INFO] - Training Epoch: 1/2, step 3938/7134 completed (loss: 3.9135115146636963, acc: 0.3243243098258972)
[2024-12-17 02:07:46,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:46,737][root][INFO] - Training Epoch: 1/2, step 3939/7134 completed (loss: 3.9255876541137695, acc: 0.3333333432674408)
[2024-12-17 02:07:46,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,060][root][INFO] - Training Epoch: 1/2, step 3940/7134 completed (loss: 3.620192527770996, acc: 0.3804347813129425)
[2024-12-17 02:07:47,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,400][root][INFO] - Training Epoch: 1/2, step 3941/7134 completed (loss: 4.102102279663086, acc: 0.3048780560493469)
[2024-12-17 02:07:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:47,803][root][INFO] - Training Epoch: 1/2, step 3942/7134 completed (loss: 3.8977744579315186, acc: 0.3440000116825104)
[2024-12-17 02:07:47,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,209][root][INFO] - Training Epoch: 1/2, step 3943/7134 completed (loss: 3.7369229793548584, acc: 0.30985915660858154)
[2024-12-17 02:07:48,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,610][root][INFO] - Training Epoch: 1/2, step 3944/7134 completed (loss: 3.971590518951416, acc: 0.305970162153244)
[2024-12-17 02:07:48,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:48,996][root][INFO] - Training Epoch: 1/2, step 3945/7134 completed (loss: 3.7607409954071045, acc: 0.31578946113586426)
[2024-12-17 02:07:49,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,378][root][INFO] - Training Epoch: 1/2, step 3946/7134 completed (loss: 3.8121273517608643, acc: 0.3482142984867096)
[2024-12-17 02:07:49,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:49,777][root][INFO] - Training Epoch: 1/2, step 3947/7134 completed (loss: 3.6255807876586914, acc: 0.2967033088207245)
[2024-12-17 02:07:49,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,151][root][INFO] - Training Epoch: 1/2, step 3948/7134 completed (loss: 3.7316901683807373, acc: 0.23999999463558197)
[2024-12-17 02:07:50,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,538][root][INFO] - Training Epoch: 1/2, step 3949/7134 completed (loss: 3.323279857635498, acc: 0.359375)
[2024-12-17 02:07:50,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:50,885][root][INFO] - Training Epoch: 1/2, step 3950/7134 completed (loss: 3.544975519180298, acc: 0.35087719559669495)
[2024-12-17 02:07:50,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,246][root][INFO] - Training Epoch: 1/2, step 3951/7134 completed (loss: 3.6179354190826416, acc: 0.3195876181125641)
[2024-12-17 02:07:51,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,601][root][INFO] - Training Epoch: 1/2, step 3952/7134 completed (loss: 4.008627414703369, acc: 0.2857142984867096)
[2024-12-17 02:07:51,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:51,980][root][INFO] - Training Epoch: 1/2, step 3953/7134 completed (loss: 3.406604766845703, acc: 0.3695652186870575)
[2024-12-17 02:07:52,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,344][root][INFO] - Training Epoch: 1/2, step 3954/7134 completed (loss: 3.9473824501037598, acc: 0.25773194432258606)
[2024-12-17 02:07:52,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:52,713][root][INFO] - Training Epoch: 1/2, step 3955/7134 completed (loss: 4.027869701385498, acc: 0.28346458077430725)
[2024-12-17 02:07:52,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,100][root][INFO] - Training Epoch: 1/2, step 3956/7134 completed (loss: 3.4784274101257324, acc: 0.3464052379131317)
[2024-12-17 02:07:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,487][root][INFO] - Training Epoch: 1/2, step 3957/7134 completed (loss: 3.5613818168640137, acc: 0.3076923191547394)
[2024-12-17 02:07:53,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:53,838][root][INFO] - Training Epoch: 1/2, step 3958/7134 completed (loss: 4.2480573654174805, acc: 0.3452380895614624)
[2024-12-17 02:07:53,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,209][root][INFO] - Training Epoch: 1/2, step 3959/7134 completed (loss: 3.4218783378601074, acc: 0.37931033968925476)
[2024-12-17 02:07:54,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,581][root][INFO] - Training Epoch: 1/2, step 3960/7134 completed (loss: 3.4885711669921875, acc: 0.3631284832954407)
[2024-12-17 02:07:54,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:54,948][root][INFO] - Training Epoch: 1/2, step 3961/7134 completed (loss: 3.558852195739746, acc: 0.29629629850387573)
[2024-12-17 02:07:55,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,339][root][INFO] - Training Epoch: 1/2, step 3962/7134 completed (loss: 3.70001220703125, acc: 0.28859061002731323)
[2024-12-17 02:07:55,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:55,720][root][INFO] - Training Epoch: 1/2, step 3963/7134 completed (loss: 3.730222225189209, acc: 0.260869562625885)
[2024-12-17 02:07:55,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,077][root][INFO] - Training Epoch: 1/2, step 3964/7134 completed (loss: 4.00196647644043, acc: 0.2230769246816635)
[2024-12-17 02:07:56,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,446][root][INFO] - Training Epoch: 1/2, step 3965/7134 completed (loss: 3.570178985595703, acc: 0.3030303120613098)
[2024-12-17 02:07:56,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:56,785][root][INFO] - Training Epoch: 1/2, step 3966/7134 completed (loss: 4.313624382019043, acc: 0.203125)
[2024-12-17 02:07:56,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,165][root][INFO] - Training Epoch: 1/2, step 3967/7134 completed (loss: 4.298556327819824, acc: 0.24637681245803833)
[2024-12-17 02:07:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,585][root][INFO] - Training Epoch: 1/2, step 3968/7134 completed (loss: 3.7424967288970947, acc: 0.3072625696659088)
[2024-12-17 02:07:57,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:57,946][root][INFO] - Training Epoch: 1/2, step 3969/7134 completed (loss: 4.163115501403809, acc: 0.25471699237823486)
[2024-12-17 02:07:58,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,308][root][INFO] - Training Epoch: 1/2, step 3970/7134 completed (loss: 3.7033162117004395, acc: 0.27167630195617676)
[2024-12-17 02:07:58,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:58,690][root][INFO] - Training Epoch: 1/2, step 3971/7134 completed (loss: 4.543001174926758, acc: 0.23589743673801422)
[2024-12-17 02:07:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,090][root][INFO] - Training Epoch: 1/2, step 3972/7134 completed (loss: 4.563963890075684, acc: 0.25)
[2024-12-17 02:07:59,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,493][root][INFO] - Training Epoch: 1/2, step 3973/7134 completed (loss: 4.36953592300415, acc: 0.23943662643432617)
[2024-12-17 02:07:59,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:07:59,868][root][INFO] - Training Epoch: 1/2, step 3974/7134 completed (loss: 3.8632702827453613, acc: 0.34871795773506165)
[2024-12-17 02:07:59,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,255][root][INFO] - Training Epoch: 1/2, step 3975/7134 completed (loss: 3.7388856410980225, acc: 0.2914285659790039)
[2024-12-17 02:08:00,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:00,627][root][INFO] - Training Epoch: 1/2, step 3976/7134 completed (loss: 3.91018009185791, acc: 0.2530120611190796)
[2024-12-17 02:08:00,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,005][root][INFO] - Training Epoch: 1/2, step 3977/7134 completed (loss: 3.8833675384521484, acc: 0.28985506296157837)
[2024-12-17 02:08:01,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,369][root][INFO] - Training Epoch: 1/2, step 3978/7134 completed (loss: 3.712721586227417, acc: 0.31343284249305725)
[2024-12-17 02:08:01,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:01,734][root][INFO] - Training Epoch: 1/2, step 3979/7134 completed (loss: 3.5339744091033936, acc: 0.31386861205101013)
[2024-12-17 02:08:01,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,118][root][INFO] - Training Epoch: 1/2, step 3980/7134 completed (loss: 3.7386505603790283, acc: 0.34193548560142517)
[2024-12-17 02:08:02,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,523][root][INFO] - Training Epoch: 1/2, step 3981/7134 completed (loss: 3.907726526260376, acc: 0.28313252329826355)
[2024-12-17 02:08:02,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:02,909][root][INFO] - Training Epoch: 1/2, step 3982/7134 completed (loss: 3.7880706787109375, acc: 0.2732558250427246)
[2024-12-17 02:08:03,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,290][root][INFO] - Training Epoch: 1/2, step 3983/7134 completed (loss: 5.439756870269775, acc: 0.19379845261573792)
[2024-12-17 02:08:03,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:03,669][root][INFO] - Training Epoch: 1/2, step 3984/7134 completed (loss: 4.253681659698486, acc: 0.27659574151039124)
[2024-12-17 02:08:03,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,022][root][INFO] - Training Epoch: 1/2, step 3985/7134 completed (loss: 4.4966583251953125, acc: 0.19230769574642181)
[2024-12-17 02:08:04,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,381][root][INFO] - Training Epoch: 1/2, step 3986/7134 completed (loss: 4.273258686065674, acc: 0.2613636255264282)
[2024-12-17 02:08:04,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:04,728][root][INFO] - Training Epoch: 1/2, step 3987/7134 completed (loss: 4.436068534851074, acc: 0.2380952388048172)
[2024-12-17 02:08:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,086][root][INFO] - Training Epoch: 1/2, step 3988/7134 completed (loss: 3.828463077545166, acc: 0.32057416439056396)
[2024-12-17 02:08:05,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,469][root][INFO] - Training Epoch: 1/2, step 3989/7134 completed (loss: 3.9942209720611572, acc: 0.2975206673145294)
[2024-12-17 02:08:05,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:05,847][root][INFO] - Training Epoch: 1/2, step 3990/7134 completed (loss: 4.046186447143555, acc: 0.2847682237625122)
[2024-12-17 02:08:06,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,241][root][INFO] - Training Epoch: 1/2, step 3991/7134 completed (loss: 5.269973278045654, acc: 0.20000000298023224)
[2024-12-17 02:08:06,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,600][root][INFO] - Training Epoch: 1/2, step 3992/7134 completed (loss: 4.871271133422852, acc: 0.17582418024539948)
[2024-12-17 02:08:06,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:06,945][root][INFO] - Training Epoch: 1/2, step 3993/7134 completed (loss: 4.979860782623291, acc: 0.20370370149612427)
[2024-12-17 02:08:07,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,356][root][INFO] - Training Epoch: 1/2, step 3994/7134 completed (loss: 4.949790000915527, acc: 0.23529411852359772)
[2024-12-17 02:08:07,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:07,720][root][INFO] - Training Epoch: 1/2, step 3995/7134 completed (loss: 5.3255228996276855, acc: 0.1782945692539215)
[2024-12-17 02:08:07,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,078][root][INFO] - Training Epoch: 1/2, step 3996/7134 completed (loss: 5.056970596313477, acc: 0.23140496015548706)
[2024-12-17 02:08:08,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,461][root][INFO] - Training Epoch: 1/2, step 3997/7134 completed (loss: 4.816224098205566, acc: 0.18965516984462738)
[2024-12-17 02:08:08,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:08,822][root][INFO] - Training Epoch: 1/2, step 3998/7134 completed (loss: 5.281953811645508, acc: 0.21153846383094788)
[2024-12-17 02:08:08,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,196][root][INFO] - Training Epoch: 1/2, step 3999/7134 completed (loss: 5.144305229187012, acc: 0.2177419364452362)
[2024-12-17 02:08:09,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,548][root][INFO] - Training Epoch: 1/2, step 4000/7134 completed (loss: 5.170194625854492, acc: 0.17886178195476532)
[2024-12-17 02:08:09,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:09,895][root][INFO] - Training Epoch: 1/2, step 4001/7134 completed (loss: 6.017792224884033, acc: 0.10483870655298233)
[2024-12-17 02:08:10,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,301][root][INFO] - Training Epoch: 1/2, step 4002/7134 completed (loss: 5.142300128936768, acc: 0.1682243049144745)
[2024-12-17 02:08:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:10,675][root][INFO] - Training Epoch: 1/2, step 4003/7134 completed (loss: 5.257680892944336, acc: 0.18045112490653992)
[2024-12-17 02:08:10,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,009][root][INFO] - Training Epoch: 1/2, step 4004/7134 completed (loss: 5.201555252075195, acc: 0.20000000298023224)
[2024-12-17 02:08:11,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,332][root][INFO] - Training Epoch: 1/2, step 4005/7134 completed (loss: 3.8350675106048584, acc: 0.2679738700389862)
[2024-12-17 02:08:11,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:11,708][root][INFO] - Training Epoch: 1/2, step 4006/7134 completed (loss: 3.8562588691711426, acc: 0.31081080436706543)
[2024-12-17 02:08:11,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,034][root][INFO] - Training Epoch: 1/2, step 4007/7134 completed (loss: 3.7440638542175293, acc: 0.25)
[2024-12-17 02:08:12,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,396][root][INFO] - Training Epoch: 1/2, step 4008/7134 completed (loss: 3.5993738174438477, acc: 0.3139013350009918)
[2024-12-17 02:08:12,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:12,766][root][INFO] - Training Epoch: 1/2, step 4009/7134 completed (loss: 3.7234978675842285, acc: 0.29050278663635254)
[2024-12-17 02:08:12,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,142][root][INFO] - Training Epoch: 1/2, step 4010/7134 completed (loss: 3.6277883052825928, acc: 0.31100478768348694)
[2024-12-17 02:08:13,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,497][root][INFO] - Training Epoch: 1/2, step 4011/7134 completed (loss: 3.7314884662628174, acc: 0.2857142984867096)
[2024-12-17 02:08:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:13,867][root][INFO] - Training Epoch: 1/2, step 4012/7134 completed (loss: 3.32234787940979, acc: 0.3855421543121338)
[2024-12-17 02:08:13,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,236][root][INFO] - Training Epoch: 1/2, step 4013/7134 completed (loss: 3.5227890014648438, acc: 0.3356643319129944)
[2024-12-17 02:08:14,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,602][root][INFO] - Training Epoch: 1/2, step 4014/7134 completed (loss: 3.3676555156707764, acc: 0.31333333253860474)
[2024-12-17 02:08:14,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:14,968][root][INFO] - Training Epoch: 1/2, step 4015/7134 completed (loss: 3.667619466781616, acc: 0.3103448152542114)
[2024-12-17 02:08:15,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,357][root][INFO] - Training Epoch: 1/2, step 4016/7134 completed (loss: 4.15750789642334, acc: 0.24870465695858002)
[2024-12-17 02:08:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:15,736][root][INFO] - Training Epoch: 1/2, step 4017/7134 completed (loss: 4.3061323165893555, acc: 0.2319587618112564)
[2024-12-17 02:08:15,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,145][root][INFO] - Training Epoch: 1/2, step 4018/7134 completed (loss: 3.8310649394989014, acc: 0.3188405930995941)
[2024-12-17 02:08:16,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,520][root][INFO] - Training Epoch: 1/2, step 4019/7134 completed (loss: 4.247103691101074, acc: 0.20555555820465088)
[2024-12-17 02:08:16,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:16,896][root][INFO] - Training Epoch: 1/2, step 4020/7134 completed (loss: 4.124740123748779, acc: 0.33522728085517883)
[2024-12-17 02:08:17,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,313][root][INFO] - Training Epoch: 1/2, step 4021/7134 completed (loss: 4.2682294845581055, acc: 0.22794117033481598)
[2024-12-17 02:08:17,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:17,685][root][INFO] - Training Epoch: 1/2, step 4022/7134 completed (loss: 4.26182746887207, acc: 0.2836538553237915)
[2024-12-17 02:08:17,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,090][root][INFO] - Training Epoch: 1/2, step 4023/7134 completed (loss: 4.428624629974365, acc: 0.3085714280605316)
[2024-12-17 02:08:18,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,470][root][INFO] - Training Epoch: 1/2, step 4024/7134 completed (loss: 3.8921890258789062, acc: 0.3333333432674408)
[2024-12-17 02:08:18,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:18,826][root][INFO] - Training Epoch: 1/2, step 4025/7134 completed (loss: 3.9174129962921143, acc: 0.28272250294685364)
[2024-12-17 02:08:18,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,175][root][INFO] - Training Epoch: 1/2, step 4026/7134 completed (loss: 4.139701843261719, acc: 0.2484472095966339)
[2024-12-17 02:08:19,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,534][root][INFO] - Training Epoch: 1/2, step 4027/7134 completed (loss: 3.9415667057037354, acc: 0.31460675597190857)
[2024-12-17 02:08:19,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:19,908][root][INFO] - Training Epoch: 1/2, step 4028/7134 completed (loss: 3.7846968173980713, acc: 0.3858267664909363)
[2024-12-17 02:08:20,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,277][root][INFO] - Training Epoch: 1/2, step 4029/7134 completed (loss: 3.824774742126465, acc: 0.3351351320743561)
[2024-12-17 02:08:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:20,629][root][INFO] - Training Epoch: 1/2, step 4030/7134 completed (loss: 3.815448760986328, acc: 0.32692307233810425)
[2024-12-17 02:08:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,003][root][INFO] - Training Epoch: 1/2, step 4031/7134 completed (loss: 3.4935901165008545, acc: 0.32919254899024963)
[2024-12-17 02:08:21,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,342][root][INFO] - Training Epoch: 1/2, step 4032/7134 completed (loss: 3.482229232788086, acc: 0.3720930218696594)
[2024-12-17 02:08:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:21,698][root][INFO] - Training Epoch: 1/2, step 4033/7134 completed (loss: 3.141592502593994, acc: 0.3957219123840332)
[2024-12-17 02:08:21,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,072][root][INFO] - Training Epoch: 1/2, step 4034/7134 completed (loss: 3.5225961208343506, acc: 0.29591837525367737)
[2024-12-17 02:08:22,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,505][root][INFO] - Training Epoch: 1/2, step 4035/7134 completed (loss: 3.6566073894500732, acc: 0.34634146094322205)
[2024-12-17 02:08:22,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:22,850][root][INFO] - Training Epoch: 1/2, step 4036/7134 completed (loss: 3.5932748317718506, acc: 0.3076923191547394)
[2024-12-17 02:08:23,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,292][root][INFO] - Training Epoch: 1/2, step 4037/7134 completed (loss: 3.927006721496582, acc: 0.3177083432674408)
[2024-12-17 02:08:23,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:23,672][root][INFO] - Training Epoch: 1/2, step 4038/7134 completed (loss: 4.05369758605957, acc: 0.28409090638160706)
[2024-12-17 02:08:23,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,021][root][INFO] - Training Epoch: 1/2, step 4039/7134 completed (loss: 3.98823618888855, acc: 0.3254437744617462)
[2024-12-17 02:08:24,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,394][root][INFO] - Training Epoch: 1/2, step 4040/7134 completed (loss: 3.5948994159698486, acc: 0.32786884903907776)
[2024-12-17 02:08:24,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:24,772][root][INFO] - Training Epoch: 1/2, step 4041/7134 completed (loss: 3.734403133392334, acc: 0.28901734948158264)
[2024-12-17 02:08:24,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,137][root][INFO] - Training Epoch: 1/2, step 4042/7134 completed (loss: 3.7815771102905273, acc: 0.29054054617881775)
[2024-12-17 02:08:25,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,502][root][INFO] - Training Epoch: 1/2, step 4043/7134 completed (loss: 3.575892210006714, acc: 0.3670886158943176)
[2024-12-17 02:08:25,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:25,870][root][INFO] - Training Epoch: 1/2, step 4044/7134 completed (loss: 3.6563498973846436, acc: 0.3351648449897766)
[2024-12-17 02:08:25,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,245][root][INFO] - Training Epoch: 1/2, step 4045/7134 completed (loss: 4.139955520629883, acc: 0.2685714364051819)
[2024-12-17 02:08:26,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,604][root][INFO] - Training Epoch: 1/2, step 4046/7134 completed (loss: 3.826408863067627, acc: 0.3333333432674408)
[2024-12-17 02:08:26,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:26,977][root][INFO] - Training Epoch: 1/2, step 4047/7134 completed (loss: 3.604968786239624, acc: 0.3169398903846741)
[2024-12-17 02:08:27,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,352][root][INFO] - Training Epoch: 1/2, step 4048/7134 completed (loss: 3.7562925815582275, acc: 0.2791878283023834)
[2024-12-17 02:08:27,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:27,753][root][INFO] - Training Epoch: 1/2, step 4049/7134 completed (loss: 3.887063503265381, acc: 0.2985074520111084)
[2024-12-17 02:08:27,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,125][root][INFO] - Training Epoch: 1/2, step 4050/7134 completed (loss: 3.7897725105285645, acc: 0.29374998807907104)
[2024-12-17 02:08:28,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,501][root][INFO] - Training Epoch: 1/2, step 4051/7134 completed (loss: 4.206234931945801, acc: 0.2402234673500061)
[2024-12-17 02:08:28,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:28,857][root][INFO] - Training Epoch: 1/2, step 4052/7134 completed (loss: 3.9099197387695312, acc: 0.29378530383110046)
[2024-12-17 02:08:28,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,236][root][INFO] - Training Epoch: 1/2, step 4053/7134 completed (loss: 3.98504376411438, acc: 0.3273809552192688)
[2024-12-17 02:08:29,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,608][root][INFO] - Training Epoch: 1/2, step 4054/7134 completed (loss: 3.896409511566162, acc: 0.3391304314136505)
[2024-12-17 02:08:29,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:29,980][root][INFO] - Training Epoch: 1/2, step 4055/7134 completed (loss: 3.668710947036743, acc: 0.32446807622909546)
[2024-12-17 02:08:30,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,365][root][INFO] - Training Epoch: 1/2, step 4056/7134 completed (loss: 3.3821818828582764, acc: 0.38947367668151855)
[2024-12-17 02:08:30,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:30,751][root][INFO] - Training Epoch: 1/2, step 4057/7134 completed (loss: 3.8798749446868896, acc: 0.24705882370471954)
[2024-12-17 02:08:30,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,153][root][INFO] - Training Epoch: 1/2, step 4058/7134 completed (loss: 4.3490753173828125, acc: 0.31060606241226196)
[2024-12-17 02:08:31,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,520][root][INFO] - Training Epoch: 1/2, step 4059/7134 completed (loss: 3.8025686740875244, acc: 0.2761194109916687)
[2024-12-17 02:08:31,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:31,864][root][INFO] - Training Epoch: 1/2, step 4060/7134 completed (loss: 3.827547311782837, acc: 0.3581081032752991)
[2024-12-17 02:08:31,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,250][root][INFO] - Training Epoch: 1/2, step 4061/7134 completed (loss: 3.3106448650360107, acc: 0.29651162028312683)
[2024-12-17 02:08:32,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,613][root][INFO] - Training Epoch: 1/2, step 4062/7134 completed (loss: 3.796491861343384, acc: 0.30263158679008484)
[2024-12-17 02:08:32,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:32,983][root][INFO] - Training Epoch: 1/2, step 4063/7134 completed (loss: 4.2234015464782715, acc: 0.23308271169662476)
[2024-12-17 02:08:33,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,356][root][INFO] - Training Epoch: 1/2, step 4064/7134 completed (loss: 3.602144479751587, acc: 0.3202614486217499)
[2024-12-17 02:08:33,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:33,731][root][INFO] - Training Epoch: 1/2, step 4065/7134 completed (loss: 3.8704113960266113, acc: 0.3032258152961731)
[2024-12-17 02:08:33,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,113][root][INFO] - Training Epoch: 1/2, step 4066/7134 completed (loss: 4.099857330322266, acc: 0.2679738700389862)
[2024-12-17 02:08:34,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,514][root][INFO] - Training Epoch: 1/2, step 4067/7134 completed (loss: 4.369762420654297, acc: 0.2602739632129669)
[2024-12-17 02:08:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:34,908][root][INFO] - Training Epoch: 1/2, step 4068/7134 completed (loss: 4.047850131988525, acc: 0.3057851195335388)
[2024-12-17 02:08:35,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,311][root][INFO] - Training Epoch: 1/2, step 4069/7134 completed (loss: 4.1075897216796875, acc: 0.30281689763069153)
[2024-12-17 02:08:35,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:35,707][root][INFO] - Training Epoch: 1/2, step 4070/7134 completed (loss: 4.119054794311523, acc: 0.2715231776237488)
[2024-12-17 02:08:35,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,121][root][INFO] - Training Epoch: 1/2, step 4071/7134 completed (loss: 3.839381456375122, acc: 0.3287671208381653)
[2024-12-17 02:08:36,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,538][root][INFO] - Training Epoch: 1/2, step 4072/7134 completed (loss: 3.4754574298858643, acc: 0.3414634168148041)
[2024-12-17 02:08:36,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:36,935][root][INFO] - Training Epoch: 1/2, step 4073/7134 completed (loss: 3.5403761863708496, acc: 0.33734938502311707)
[2024-12-17 02:08:37,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,312][root][INFO] - Training Epoch: 1/2, step 4074/7134 completed (loss: 3.866276502609253, acc: 0.33112582564353943)
[2024-12-17 02:08:37,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:37,673][root][INFO] - Training Epoch: 1/2, step 4075/7134 completed (loss: 3.9040441513061523, acc: 0.25999999046325684)
[2024-12-17 02:08:37,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,030][root][INFO] - Training Epoch: 1/2, step 4076/7134 completed (loss: 3.5225181579589844, acc: 0.28658536076545715)
[2024-12-17 02:08:38,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,430][root][INFO] - Training Epoch: 1/2, step 4077/7134 completed (loss: 3.448636531829834, acc: 0.35374149680137634)
[2024-12-17 02:08:38,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:38,797][root][INFO] - Training Epoch: 1/2, step 4078/7134 completed (loss: 3.8692538738250732, acc: 0.3459119498729706)
[2024-12-17 02:08:38,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,139][root][INFO] - Training Epoch: 1/2, step 4079/7134 completed (loss: 3.4648540019989014, acc: 0.3435114622116089)
[2024-12-17 02:08:39,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,522][root][INFO] - Training Epoch: 1/2, step 4080/7134 completed (loss: 3.348853826522827, acc: 0.317241370677948)
[2024-12-17 02:08:39,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:39,879][root][INFO] - Training Epoch: 1/2, step 4081/7134 completed (loss: 3.0751302242279053, acc: 0.3194444477558136)
[2024-12-17 02:08:40,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,260][root][INFO] - Training Epoch: 1/2, step 4082/7134 completed (loss: 3.6753904819488525, acc: 0.33552631735801697)
[2024-12-17 02:08:40,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,624][root][INFO] - Training Epoch: 1/2, step 4083/7134 completed (loss: 4.4918999671936035, acc: 0.28654971718788147)
[2024-12-17 02:08:40,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:40,982][root][INFO] - Training Epoch: 1/2, step 4084/7134 completed (loss: 4.826225757598877, acc: 0.25503355264663696)
[2024-12-17 02:08:41,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,331][root][INFO] - Training Epoch: 1/2, step 4085/7134 completed (loss: 3.9082188606262207, acc: 0.33157894015312195)
[2024-12-17 02:08:41,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:41,703][root][INFO] - Training Epoch: 1/2, step 4086/7134 completed (loss: 4.574038982391357, acc: 0.21153846383094788)
[2024-12-17 02:08:41,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,090][root][INFO] - Training Epoch: 1/2, step 4087/7134 completed (loss: 3.667185068130493, acc: 0.32258063554763794)
[2024-12-17 02:08:42,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,459][root][INFO] - Training Epoch: 1/2, step 4088/7134 completed (loss: 4.216009140014648, acc: 0.2385786771774292)
[2024-12-17 02:08:42,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:42,841][root][INFO] - Training Epoch: 1/2, step 4089/7134 completed (loss: 4.47544002532959, acc: 0.21969696879386902)
[2024-12-17 02:08:42,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,212][root][INFO] - Training Epoch: 1/2, step 4090/7134 completed (loss: 4.262910842895508, acc: 0.2870813310146332)
[2024-12-17 02:08:43,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:43,593][root][INFO] - Training Epoch: 1/2, step 4091/7134 completed (loss: 4.529963970184326, acc: 0.21910113096237183)
[2024-12-17 02:08:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,042][root][INFO] - Training Epoch: 1/2, step 4092/7134 completed (loss: 3.629309892654419, acc: 0.32460734248161316)
[2024-12-17 02:08:44,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,456][root][INFO] - Training Epoch: 1/2, step 4093/7134 completed (loss: 4.0959391593933105, acc: 0.2639999985694885)
[2024-12-17 02:08:44,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:44,827][root][INFO] - Training Epoch: 1/2, step 4094/7134 completed (loss: 3.9759202003479004, acc: 0.28658536076545715)
[2024-12-17 02:08:44,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,217][root][INFO] - Training Epoch: 1/2, step 4095/7134 completed (loss: 3.944927930831909, acc: 0.2802547812461853)
[2024-12-17 02:08:45,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,566][root][INFO] - Training Epoch: 1/2, step 4096/7134 completed (loss: 4.9169602394104, acc: 0.20779220759868622)
[2024-12-17 02:08:45,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:45,949][root][INFO] - Training Epoch: 1/2, step 4097/7134 completed (loss: 4.477023601531982, acc: 0.2666666805744171)
[2024-12-17 02:08:46,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,327][root][INFO] - Training Epoch: 1/2, step 4098/7134 completed (loss: 3.7312285900115967, acc: 0.33908045291900635)
[2024-12-17 02:08:46,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:46,711][root][INFO] - Training Epoch: 1/2, step 4099/7134 completed (loss: 4.566499710083008, acc: 0.25)
[2024-12-17 02:08:46,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,109][root][INFO] - Training Epoch: 1/2, step 4100/7134 completed (loss: 3.814725160598755, acc: 0.2549019753932953)
[2024-12-17 02:08:47,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,485][root][INFO] - Training Epoch: 1/2, step 4101/7134 completed (loss: 4.252417087554932, acc: 0.335999995470047)
[2024-12-17 02:08:47,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:47,873][root][INFO] - Training Epoch: 1/2, step 4102/7134 completed (loss: 3.8369333744049072, acc: 0.3333333432674408)
[2024-12-17 02:08:47,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,244][root][INFO] - Training Epoch: 1/2, step 4103/7134 completed (loss: 3.2477846145629883, acc: 0.32679739594459534)
[2024-12-17 02:08:48,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,612][root][INFO] - Training Epoch: 1/2, step 4104/7134 completed (loss: 4.019015312194824, acc: 0.28260868787765503)
[2024-12-17 02:08:48,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:48,981][root][INFO] - Training Epoch: 1/2, step 4105/7134 completed (loss: 3.9098660945892334, acc: 0.2866666615009308)
[2024-12-17 02:08:49,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,354][root][INFO] - Training Epoch: 1/2, step 4106/7134 completed (loss: 3.6770668029785156, acc: 0.35374149680137634)
[2024-12-17 02:08:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:49,725][root][INFO] - Training Epoch: 1/2, step 4107/7134 completed (loss: 3.536855697631836, acc: 0.34558823704719543)
[2024-12-17 02:08:49,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,120][root][INFO] - Training Epoch: 1/2, step 4108/7134 completed (loss: 3.876793384552002, acc: 0.29931971430778503)
[2024-12-17 02:08:50,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,606][root][INFO] - Training Epoch: 1/2, step 4109/7134 completed (loss: 3.6305549144744873, acc: 0.36054420471191406)
[2024-12-17 02:08:50,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:50,972][root][INFO] - Training Epoch: 1/2, step 4110/7134 completed (loss: 3.800095558166504, acc: 0.2868216931819916)
[2024-12-17 02:08:51,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,365][root][INFO] - Training Epoch: 1/2, step 4111/7134 completed (loss: 4.094870567321777, acc: 0.3103448152542114)
[2024-12-17 02:08:51,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:51,726][root][INFO] - Training Epoch: 1/2, step 4112/7134 completed (loss: 3.619204521179199, acc: 0.3488371968269348)
[2024-12-17 02:08:51,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,116][root][INFO] - Training Epoch: 1/2, step 4113/7134 completed (loss: 3.633995294570923, acc: 0.3496503531932831)
[2024-12-17 02:08:52,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,500][root][INFO] - Training Epoch: 1/2, step 4114/7134 completed (loss: 3.7912986278533936, acc: 0.3391304314136505)
[2024-12-17 02:08:52,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:52,896][root][INFO] - Training Epoch: 1/2, step 4115/7134 completed (loss: 4.6729230880737305, acc: 0.2711864411830902)
[2024-12-17 02:08:53,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,298][root][INFO] - Training Epoch: 1/2, step 4116/7134 completed (loss: 4.2944817543029785, acc: 0.290076345205307)
[2024-12-17 02:08:53,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:53,668][root][INFO] - Training Epoch: 1/2, step 4117/7134 completed (loss: 4.483524322509766, acc: 0.2569444477558136)
[2024-12-17 02:08:53,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,041][root][INFO] - Training Epoch: 1/2, step 4118/7134 completed (loss: 3.915677785873413, acc: 0.2916666567325592)
[2024-12-17 02:08:54,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,421][root][INFO] - Training Epoch: 1/2, step 4119/7134 completed (loss: 4.053508758544922, acc: 0.2635135054588318)
[2024-12-17 02:08:54,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:54,807][root][INFO] - Training Epoch: 1/2, step 4120/7134 completed (loss: 3.9567508697509766, acc: 0.29323309659957886)
[2024-12-17 02:08:54,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,183][root][INFO] - Training Epoch: 1/2, step 4121/7134 completed (loss: 3.625612258911133, acc: 0.3231707215309143)
[2024-12-17 02:08:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,583][root][INFO] - Training Epoch: 1/2, step 4122/7134 completed (loss: 3.8156630992889404, acc: 0.2521008551120758)
[2024-12-17 02:08:55,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:55,981][root][INFO] - Training Epoch: 1/2, step 4123/7134 completed (loss: 3.861300468444824, acc: 0.3311688303947449)
[2024-12-17 02:08:56,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,360][root][INFO] - Training Epoch: 1/2, step 4124/7134 completed (loss: 4.011199951171875, acc: 0.29374998807907104)
[2024-12-17 02:08:56,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:56,737][root][INFO] - Training Epoch: 1/2, step 4125/7134 completed (loss: 3.8729443550109863, acc: 0.29559749364852905)
[2024-12-17 02:08:56,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,099][root][INFO] - Training Epoch: 1/2, step 4126/7134 completed (loss: 4.02996301651001, acc: 0.25)
[2024-12-17 02:08:57,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,495][root][INFO] - Training Epoch: 1/2, step 4127/7134 completed (loss: 3.6042611598968506, acc: 0.3087248206138611)
[2024-12-17 02:08:57,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:57,886][root][INFO] - Training Epoch: 1/2, step 4128/7134 completed (loss: 4.173757553100586, acc: 0.21052631735801697)
[2024-12-17 02:08:58,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,265][root][INFO] - Training Epoch: 1/2, step 4129/7134 completed (loss: 3.8530194759368896, acc: 0.3221476376056671)
[2024-12-17 02:08:58,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:58,680][root][INFO] - Training Epoch: 1/2, step 4130/7134 completed (loss: 4.005932807922363, acc: 0.2931034564971924)
[2024-12-17 02:08:58,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,072][root][INFO] - Training Epoch: 1/2, step 4131/7134 completed (loss: 3.082491159439087, acc: 0.3629629611968994)
[2024-12-17 02:08:59,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,435][root][INFO] - Training Epoch: 1/2, step 4132/7134 completed (loss: 3.8153467178344727, acc: 0.24074074625968933)
[2024-12-17 02:08:59,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:08:59,798][root][INFO] - Training Epoch: 1/2, step 4133/7134 completed (loss: 3.5449976921081543, acc: 0.35664334893226624)
[2024-12-17 02:08:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,163][root][INFO] - Training Epoch: 1/2, step 4134/7134 completed (loss: 4.160212993621826, acc: 0.3272727131843567)
[2024-12-17 02:09:00,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,569][root][INFO] - Training Epoch: 1/2, step 4135/7134 completed (loss: 3.752768039703369, acc: 0.33571428060531616)
[2024-12-17 02:09:00,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:00,972][root][INFO] - Training Epoch: 1/2, step 4136/7134 completed (loss: 3.6846578121185303, acc: 0.308270663022995)
[2024-12-17 02:09:01,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,372][root][INFO] - Training Epoch: 1/2, step 4137/7134 completed (loss: 3.9510345458984375, acc: 0.3235294222831726)
[2024-12-17 02:09:01,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:01,752][root][INFO] - Training Epoch: 1/2, step 4138/7134 completed (loss: 3.844420909881592, acc: 0.3137255012989044)
[2024-12-17 02:09:01,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,063][root][INFO] - Training Epoch: 1/2, step 4139/7134 completed (loss: 4.088236331939697, acc: 0.3523809611797333)
[2024-12-17 02:09:02,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,419][root][INFO] - Training Epoch: 1/2, step 4140/7134 completed (loss: 3.743680715560913, acc: 0.28248587250709534)
[2024-12-17 02:09:02,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:02,801][root][INFO] - Training Epoch: 1/2, step 4141/7134 completed (loss: 4.070204734802246, acc: 0.2884615361690521)
[2024-12-17 02:09:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,175][root][INFO] - Training Epoch: 1/2, step 4142/7134 completed (loss: 3.855928659439087, acc: 0.27000001072883606)
[2024-12-17 02:09:03,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,543][root][INFO] - Training Epoch: 1/2, step 4143/7134 completed (loss: 3.2143638134002686, acc: 0.36681222915649414)
[2024-12-17 02:09:03,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:03,917][root][INFO] - Training Epoch: 1/2, step 4144/7134 completed (loss: 3.564584970474243, acc: 0.3384615480899811)
[2024-12-17 02:09:04,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,307][root][INFO] - Training Epoch: 1/2, step 4145/7134 completed (loss: 4.698076248168945, acc: 0.2711864411830902)
[2024-12-17 02:09:04,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:04,654][root][INFO] - Training Epoch: 1/2, step 4146/7134 completed (loss: 6.206996917724609, acc: 0.1785714328289032)
[2024-12-17 02:09:04,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,024][root][INFO] - Training Epoch: 1/2, step 4147/7134 completed (loss: 5.769425392150879, acc: 0.22033898532390594)
[2024-12-17 02:09:05,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,382][root][INFO] - Training Epoch: 1/2, step 4148/7134 completed (loss: 4.997536659240723, acc: 0.25503355264663696)
[2024-12-17 02:09:05,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:05,806][root][INFO] - Training Epoch: 1/2, step 4149/7134 completed (loss: 5.037594318389893, acc: 0.302325576543808)
[2024-12-17 02:09:05,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,163][root][INFO] - Training Epoch: 1/2, step 4150/7134 completed (loss: 5.292145252227783, acc: 0.2735042870044708)
[2024-12-17 02:09:06,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,555][root][INFO] - Training Epoch: 1/2, step 4151/7134 completed (loss: 4.513501167297363, acc: 0.28099173307418823)
[2024-12-17 02:09:06,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:06,934][root][INFO] - Training Epoch: 1/2, step 4152/7134 completed (loss: 4.495973110198975, acc: 0.20408163964748383)
[2024-12-17 02:09:07,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,300][root][INFO] - Training Epoch: 1/2, step 4153/7134 completed (loss: 4.371750354766846, acc: 0.27142858505249023)
[2024-12-17 02:09:07,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:07,698][root][INFO] - Training Epoch: 1/2, step 4154/7134 completed (loss: 4.216622829437256, acc: 0.2631579041481018)
[2024-12-17 02:09:07,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,087][root][INFO] - Training Epoch: 1/2, step 4155/7134 completed (loss: 3.9494125843048096, acc: 0.23489932715892792)
[2024-12-17 02:09:08,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,452][root][INFO] - Training Epoch: 1/2, step 4156/7134 completed (loss: 4.146584987640381, acc: 0.26900583505630493)
[2024-12-17 02:09:08,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:08,807][root][INFO] - Training Epoch: 1/2, step 4157/7134 completed (loss: 4.924034118652344, acc: 0.1764705926179886)
[2024-12-17 02:09:08,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,215][root][INFO] - Training Epoch: 1/2, step 4158/7134 completed (loss: 4.224485874176025, acc: 0.2857142984867096)
[2024-12-17 02:09:09,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,594][root][INFO] - Training Epoch: 1/2, step 4159/7134 completed (loss: 4.427668571472168, acc: 0.2857142984867096)
[2024-12-17 02:09:09,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:09,983][root][INFO] - Training Epoch: 1/2, step 4160/7134 completed (loss: 3.922355890274048, acc: 0.31092438101768494)
[2024-12-17 02:09:10,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,341][root][INFO] - Training Epoch: 1/2, step 4161/7134 completed (loss: 4.415194988250732, acc: 0.17241379618644714)
[2024-12-17 02:09:10,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:10,719][root][INFO] - Training Epoch: 1/2, step 4162/7134 completed (loss: 4.174909591674805, acc: 0.28143712878227234)
[2024-12-17 02:09:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,073][root][INFO] - Training Epoch: 1/2, step 4163/7134 completed (loss: 4.314460277557373, acc: 0.268456369638443)
[2024-12-17 02:09:11,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,456][root][INFO] - Training Epoch: 1/2, step 4164/7134 completed (loss: 4.029338359832764, acc: 0.29192546010017395)
[2024-12-17 02:09:11,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:11,859][root][INFO] - Training Epoch: 1/2, step 4165/7134 completed (loss: 4.506834030151367, acc: 0.25806450843811035)
[2024-12-17 02:09:11,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,230][root][INFO] - Training Epoch: 1/2, step 4166/7134 completed (loss: 4.212621212005615, acc: 0.2756410241127014)
[2024-12-17 02:09:12,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,608][root][INFO] - Training Epoch: 1/2, step 4167/7134 completed (loss: 4.387945175170898, acc: 0.2926829159259796)
[2024-12-17 02:09:12,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:12,977][root][INFO] - Training Epoch: 1/2, step 4168/7134 completed (loss: 4.205813884735107, acc: 0.2857142984867096)
[2024-12-17 02:09:13,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,366][root][INFO] - Training Epoch: 1/2, step 4169/7134 completed (loss: 3.905364751815796, acc: 0.26728111505508423)
[2024-12-17 02:09:13,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:13,736][root][INFO] - Training Epoch: 1/2, step 4170/7134 completed (loss: 3.7501368522644043, acc: 0.37142857909202576)
[2024-12-17 02:09:13,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,107][root][INFO] - Training Epoch: 1/2, step 4171/7134 completed (loss: 3.6207363605499268, acc: 0.3497537076473236)
[2024-12-17 02:09:14,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,486][root][INFO] - Training Epoch: 1/2, step 4172/7134 completed (loss: 4.072131156921387, acc: 0.3333333432674408)
[2024-12-17 02:09:14,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:14,871][root][INFO] - Training Epoch: 1/2, step 4173/7134 completed (loss: 4.625835418701172, acc: 0.25)
[2024-12-17 02:09:14,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,225][root][INFO] - Training Epoch: 1/2, step 4174/7134 completed (loss: 3.666029453277588, acc: 0.3174603283405304)
[2024-12-17 02:09:15,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,593][root][INFO] - Training Epoch: 1/2, step 4175/7134 completed (loss: 4.11289119720459, acc: 0.19718310236930847)
[2024-12-17 02:09:15,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:15,965][root][INFO] - Training Epoch: 1/2, step 4176/7134 completed (loss: 3.973513603210449, acc: 0.22580644488334656)
[2024-12-17 02:09:16,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,338][root][INFO] - Training Epoch: 1/2, step 4177/7134 completed (loss: 4.345577239990234, acc: 0.19883041083812714)
[2024-12-17 02:09:16,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:16,703][root][INFO] - Training Epoch: 1/2, step 4178/7134 completed (loss: 4.381997585296631, acc: 0.31578946113586426)
[2024-12-17 02:09:16,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,157][root][INFO] - Training Epoch: 1/2, step 4179/7134 completed (loss: 4.048696517944336, acc: 0.25)
[2024-12-17 02:09:17,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,548][root][INFO] - Training Epoch: 1/2, step 4180/7134 completed (loss: 3.720755100250244, acc: 0.30000001192092896)
[2024-12-17 02:09:17,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:17,935][root][INFO] - Training Epoch: 1/2, step 4181/7134 completed (loss: 3.6460022926330566, acc: 0.3188405930995941)
[2024-12-17 02:09:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,294][root][INFO] - Training Epoch: 1/2, step 4182/7134 completed (loss: 3.6291885375976562, acc: 0.30519479513168335)
[2024-12-17 02:09:18,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:18,686][root][INFO] - Training Epoch: 1/2, step 4183/7134 completed (loss: 3.7827417850494385, acc: 0.2638036906719208)
[2024-12-17 02:09:18,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,069][root][INFO] - Training Epoch: 1/2, step 4184/7134 completed (loss: 3.7769365310668945, acc: 0.30000001192092896)
[2024-12-17 02:09:19,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,455][root][INFO] - Training Epoch: 1/2, step 4185/7134 completed (loss: 3.4200332164764404, acc: 0.3142857253551483)
[2024-12-17 02:09:19,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:19,817][root][INFO] - Training Epoch: 1/2, step 4186/7134 completed (loss: 3.3025777339935303, acc: 0.34020617604255676)
[2024-12-17 02:09:19,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,159][root][INFO] - Training Epoch: 1/2, step 4187/7134 completed (loss: 4.02855920791626, acc: 0.25806450843811035)
[2024-12-17 02:09:20,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,524][root][INFO] - Training Epoch: 1/2, step 4188/7134 completed (loss: 3.5883185863494873, acc: 0.27368420362472534)
[2024-12-17 02:09:20,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:20,881][root][INFO] - Training Epoch: 1/2, step 4189/7134 completed (loss: 3.4414830207824707, acc: 0.3053892254829407)
[2024-12-17 02:09:20,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,237][root][INFO] - Training Epoch: 1/2, step 4190/7134 completed (loss: 3.4582290649414062, acc: 0.3274853825569153)
[2024-12-17 02:09:21,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,548][root][INFO] - Training Epoch: 1/2, step 4191/7134 completed (loss: 3.643584728240967, acc: 0.2788461446762085)
[2024-12-17 02:09:21,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:21,895][root][INFO] - Training Epoch: 1/2, step 4192/7134 completed (loss: 3.488905191421509, acc: 0.30136987566947937)
[2024-12-17 02:09:22,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,258][root][INFO] - Training Epoch: 1/2, step 4193/7134 completed (loss: 3.2717411518096924, acc: 0.3296089470386505)
[2024-12-17 02:09:22,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,629][root][INFO] - Training Epoch: 1/2, step 4194/7134 completed (loss: 3.2574033737182617, acc: 0.3076923191547394)
[2024-12-17 02:09:22,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:22,991][root][INFO] - Training Epoch: 1/2, step 4195/7134 completed (loss: 3.6511123180389404, acc: 0.2742857038974762)
[2024-12-17 02:09:23,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,359][root][INFO] - Training Epoch: 1/2, step 4196/7134 completed (loss: 3.437638282775879, acc: 0.28776979446411133)
[2024-12-17 02:09:23,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:23,726][root][INFO] - Training Epoch: 1/2, step 4197/7134 completed (loss: 3.5344204902648926, acc: 0.28260868787765503)
[2024-12-17 02:09:23,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,092][root][INFO] - Training Epoch: 1/2, step 4198/7134 completed (loss: 3.32684326171875, acc: 0.35428571701049805)
[2024-12-17 02:09:24,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,477][root][INFO] - Training Epoch: 1/2, step 4199/7134 completed (loss: 4.392875671386719, acc: 0.246478870511055)
[2024-12-17 02:09:24,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:24,846][root][INFO] - Training Epoch: 1/2, step 4200/7134 completed (loss: 4.149998188018799, acc: 0.24827586114406586)
[2024-12-17 02:09:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,216][root][INFO] - Training Epoch: 1/2, step 4201/7134 completed (loss: 4.120661735534668, acc: 0.19148936867713928)
[2024-12-17 02:09:25,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,617][root][INFO] - Training Epoch: 1/2, step 4202/7134 completed (loss: 4.345465660095215, acc: 0.24060150980949402)
[2024-12-17 02:09:25,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:25,988][root][INFO] - Training Epoch: 1/2, step 4203/7134 completed (loss: 3.8523871898651123, acc: 0.2848101258277893)
[2024-12-17 02:09:26,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,363][root][INFO] - Training Epoch: 1/2, step 4204/7134 completed (loss: 4.1772780418396, acc: 0.3199999928474426)
[2024-12-17 02:09:26,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:26,746][root][INFO] - Training Epoch: 1/2, step 4205/7134 completed (loss: 4.170003414154053, acc: 0.2823529541492462)
[2024-12-17 02:09:26,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,114][root][INFO] - Training Epoch: 1/2, step 4206/7134 completed (loss: 4.142807483673096, acc: 0.27419355511665344)
[2024-12-17 02:09:27,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,507][root][INFO] - Training Epoch: 1/2, step 4207/7134 completed (loss: 3.5838565826416016, acc: 0.276729553937912)
[2024-12-17 02:09:27,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:27,870][root][INFO] - Training Epoch: 1/2, step 4208/7134 completed (loss: 4.251316070556641, acc: 0.24137930572032928)
[2024-12-17 02:09:27,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,236][root][INFO] - Training Epoch: 1/2, step 4209/7134 completed (loss: 3.632175922393799, acc: 0.31491711735725403)
[2024-12-17 02:09:28,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,597][root][INFO] - Training Epoch: 1/2, step 4210/7134 completed (loss: 3.986661672592163, acc: 0.31578946113586426)
[2024-12-17 02:09:28,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:28,943][root][INFO] - Training Epoch: 1/2, step 4211/7134 completed (loss: 4.168341159820557, acc: 0.3606557250022888)
[2024-12-17 02:09:29,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,276][root][INFO] - Training Epoch: 1/2, step 4212/7134 completed (loss: 3.8669729232788086, acc: 0.3032258152961731)
[2024-12-17 02:09:29,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:29,657][root][INFO] - Training Epoch: 1/2, step 4213/7134 completed (loss: 3.3189585208892822, acc: 0.4137931168079376)
[2024-12-17 02:09:29,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,031][root][INFO] - Training Epoch: 1/2, step 4214/7134 completed (loss: 3.8289105892181396, acc: 0.3391812741756439)
[2024-12-17 02:09:30,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,364][root][INFO] - Training Epoch: 1/2, step 4215/7134 completed (loss: 3.1603939533233643, acc: 0.3700787425041199)
[2024-12-17 02:09:30,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:30,740][root][INFO] - Training Epoch: 1/2, step 4216/7134 completed (loss: 3.7967514991760254, acc: 0.2461538463830948)
[2024-12-17 02:09:30,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,098][root][INFO] - Training Epoch: 1/2, step 4217/7134 completed (loss: 3.2736730575561523, acc: 0.39444443583488464)
[2024-12-17 02:09:31,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,488][root][INFO] - Training Epoch: 1/2, step 4218/7134 completed (loss: 3.7041854858398438, acc: 0.3283582031726837)
[2024-12-17 02:09:31,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:31,798][root][INFO] - Training Epoch: 1/2, step 4219/7134 completed (loss: 3.601088523864746, acc: 0.23188406229019165)
[2024-12-17 02:09:31,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,164][root][INFO] - Training Epoch: 1/2, step 4220/7134 completed (loss: 3.599125862121582, acc: 0.2613636255264282)
[2024-12-17 02:09:32,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,533][root][INFO] - Training Epoch: 1/2, step 4221/7134 completed (loss: 3.8311219215393066, acc: 0.27702704071998596)
[2024-12-17 02:09:32,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:32,898][root][INFO] - Training Epoch: 1/2, step 4222/7134 completed (loss: 4.2066569328308105, acc: 0.31578946113586426)
[2024-12-17 02:09:33,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,250][root][INFO] - Training Epoch: 1/2, step 4223/7134 completed (loss: 4.46234655380249, acc: 0.25628140568733215)
[2024-12-17 02:09:33,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:33,622][root][INFO] - Training Epoch: 1/2, step 4224/7134 completed (loss: 3.916332721710205, acc: 0.32258063554763794)
[2024-12-17 02:09:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,006][root][INFO] - Training Epoch: 1/2, step 4225/7134 completed (loss: 4.069112300872803, acc: 0.3461538553237915)
[2024-12-17 02:09:34,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,380][root][INFO] - Training Epoch: 1/2, step 4226/7134 completed (loss: 4.253431797027588, acc: 0.27411168813705444)
[2024-12-17 02:09:34,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:34,731][root][INFO] - Training Epoch: 1/2, step 4227/7134 completed (loss: 4.556169509887695, acc: 0.24528302252292633)
[2024-12-17 02:09:34,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,113][root][INFO] - Training Epoch: 1/2, step 4228/7134 completed (loss: 4.393647193908691, acc: 0.22435897588729858)
[2024-12-17 02:09:35,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,460][root][INFO] - Training Epoch: 1/2, step 4229/7134 completed (loss: 4.143843650817871, acc: 0.2800000011920929)
[2024-12-17 02:09:35,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:35,837][root][INFO] - Training Epoch: 1/2, step 4230/7134 completed (loss: 4.626766681671143, acc: 0.24418604373931885)
[2024-12-17 02:09:35,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,219][root][INFO] - Training Epoch: 1/2, step 4231/7134 completed (loss: 4.195624828338623, acc: 0.30201342701911926)
[2024-12-17 02:09:36,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,595][root][INFO] - Training Epoch: 1/2, step 4232/7134 completed (loss: 3.9765334129333496, acc: 0.2611111104488373)
[2024-12-17 02:09:36,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:36,970][root][INFO] - Training Epoch: 1/2, step 4233/7134 completed (loss: 3.891453504562378, acc: 0.29078012704849243)
[2024-12-17 02:09:37,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,359][root][INFO] - Training Epoch: 1/2, step 4234/7134 completed (loss: 4.064765930175781, acc: 0.26241135597229004)
[2024-12-17 02:09:37,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:37,760][root][INFO] - Training Epoch: 1/2, step 4235/7134 completed (loss: 3.784611463546753, acc: 0.36231884360313416)
[2024-12-17 02:09:37,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,142][root][INFO] - Training Epoch: 1/2, step 4236/7134 completed (loss: 4.2351460456848145, acc: 0.2150537669658661)
[2024-12-17 02:09:38,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,506][root][INFO] - Training Epoch: 1/2, step 4237/7134 completed (loss: 3.8367366790771484, acc: 0.2429906576871872)
[2024-12-17 02:09:38,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:38,898][root][INFO] - Training Epoch: 1/2, step 4238/7134 completed (loss: 3.7809174060821533, acc: 0.26153847575187683)
[2024-12-17 02:09:39,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,309][root][INFO] - Training Epoch: 1/2, step 4239/7134 completed (loss: 4.07313346862793, acc: 0.328000009059906)
[2024-12-17 02:09:39,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:39,673][root][INFO] - Training Epoch: 1/2, step 4240/7134 completed (loss: 4.0904765129089355, acc: 0.3309859037399292)
[2024-12-17 02:09:39,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,081][root][INFO] - Training Epoch: 1/2, step 4241/7134 completed (loss: 4.288878440856934, acc: 0.25999999046325684)
[2024-12-17 02:09:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,495][root][INFO] - Training Epoch: 1/2, step 4242/7134 completed (loss: 4.58488655090332, acc: 0.22448979318141937)
[2024-12-17 02:09:40,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:40,894][root][INFO] - Training Epoch: 1/2, step 4243/7134 completed (loss: 3.7656688690185547, acc: 0.28925618529319763)
[2024-12-17 02:09:40,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,255][root][INFO] - Training Epoch: 1/2, step 4244/7134 completed (loss: 4.0212836265563965, acc: 0.3113207519054413)
[2024-12-17 02:09:41,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:41,621][root][INFO] - Training Epoch: 1/2, step 4245/7134 completed (loss: 3.8025312423706055, acc: 0.34736841917037964)
[2024-12-17 02:09:41,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,015][root][INFO] - Training Epoch: 1/2, step 4246/7134 completed (loss: 3.676941394805908, acc: 0.31506848335266113)
[2024-12-17 02:09:42,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,364][root][INFO] - Training Epoch: 1/2, step 4247/7134 completed (loss: 4.045844554901123, acc: 0.31200000643730164)
[2024-12-17 02:09:42,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:42,746][root][INFO] - Training Epoch: 1/2, step 4248/7134 completed (loss: 3.9432311058044434, acc: 0.2876712381839752)
[2024-12-17 02:09:42,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,191][root][INFO] - Training Epoch: 1/2, step 4249/7134 completed (loss: 4.26201868057251, acc: 0.2647058963775635)
[2024-12-17 02:09:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,587][root][INFO] - Training Epoch: 1/2, step 4250/7134 completed (loss: 3.943450450897217, acc: 0.2454545497894287)
[2024-12-17 02:09:43,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:43,965][root][INFO] - Training Epoch: 1/2, step 4251/7134 completed (loss: 3.8697702884674072, acc: 0.25563910603523254)
[2024-12-17 02:09:44,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,336][root][INFO] - Training Epoch: 1/2, step 4252/7134 completed (loss: 4.410614967346191, acc: 0.2338709682226181)
[2024-12-17 02:09:44,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:44,686][root][INFO] - Training Epoch: 1/2, step 4253/7134 completed (loss: 3.6271746158599854, acc: 0.321739137172699)
[2024-12-17 02:09:44,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,040][root][INFO] - Training Epoch: 1/2, step 4254/7134 completed (loss: 4.004833221435547, acc: 0.3295454680919647)
[2024-12-17 02:09:45,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,426][root][INFO] - Training Epoch: 1/2, step 4255/7134 completed (loss: 3.8351097106933594, acc: 0.2846153974533081)
[2024-12-17 02:09:45,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:45,811][root][INFO] - Training Epoch: 1/2, step 4256/7134 completed (loss: 3.6387948989868164, acc: 0.29914531111717224)
[2024-12-17 02:09:45,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,206][root][INFO] - Training Epoch: 1/2, step 4257/7134 completed (loss: 3.7747788429260254, acc: 0.34090909361839294)
[2024-12-17 02:09:46,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:46,630][root][INFO] - Training Epoch: 1/2, step 4258/7134 completed (loss: 3.703948974609375, acc: 0.3017241358757019)
[2024-12-17 02:09:46,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,015][root][INFO] - Training Epoch: 1/2, step 4259/7134 completed (loss: 3.7780585289001465, acc: 0.3687500059604645)
[2024-12-17 02:09:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,419][root][INFO] - Training Epoch: 1/2, step 4260/7134 completed (loss: 3.8431262969970703, acc: 0.38532111048698425)
[2024-12-17 02:09:47,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:47,798][root][INFO] - Training Epoch: 1/2, step 4261/7134 completed (loss: 3.867600202560425, acc: 0.27826085686683655)
[2024-12-17 02:09:47,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,175][root][INFO] - Training Epoch: 1/2, step 4262/7134 completed (loss: 4.190983772277832, acc: 0.30069929361343384)
[2024-12-17 02:09:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,576][root][INFO] - Training Epoch: 1/2, step 4263/7134 completed (loss: 3.973308563232422, acc: 0.27407407760620117)
[2024-12-17 02:09:48,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:48,938][root][INFO] - Training Epoch: 1/2, step 4264/7134 completed (loss: 4.331242084503174, acc: 0.2752808928489685)
[2024-12-17 02:09:49,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,293][root][INFO] - Training Epoch: 1/2, step 4265/7134 completed (loss: 4.053374767303467, acc: 0.31976744532585144)
[2024-12-17 02:09:49,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:49,710][root][INFO] - Training Epoch: 1/2, step 4266/7134 completed (loss: 3.86877703666687, acc: 0.3403141498565674)
[2024-12-17 02:09:49,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,095][root][INFO] - Training Epoch: 1/2, step 4267/7134 completed (loss: 3.79732084274292, acc: 0.3333333432674408)
[2024-12-17 02:09:50,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,501][root][INFO] - Training Epoch: 1/2, step 4268/7134 completed (loss: 4.105524063110352, acc: 0.27642276883125305)
[2024-12-17 02:09:50,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:50,889][root][INFO] - Training Epoch: 1/2, step 4269/7134 completed (loss: 4.074259281158447, acc: 0.2774566411972046)
[2024-12-17 02:09:50,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,229][root][INFO] - Training Epoch: 1/2, step 4270/7134 completed (loss: 4.199561595916748, acc: 0.2760416567325592)
[2024-12-17 02:09:51,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,593][root][INFO] - Training Epoch: 1/2, step 4271/7134 completed (loss: 4.124989986419678, acc: 0.26486486196517944)
[2024-12-17 02:09:51,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:51,965][root][INFO] - Training Epoch: 1/2, step 4272/7134 completed (loss: 4.226174831390381, acc: 0.26865673065185547)
[2024-12-17 02:09:52,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,356][root][INFO] - Training Epoch: 1/2, step 4273/7134 completed (loss: 4.090052604675293, acc: 0.2063492089509964)
[2024-12-17 02:09:52,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:52,741][root][INFO] - Training Epoch: 1/2, step 4274/7134 completed (loss: 3.9993107318878174, acc: 0.3578431308269501)
[2024-12-17 02:09:52,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,167][root][INFO] - Training Epoch: 1/2, step 4275/7134 completed (loss: 4.082597732543945, acc: 0.2402234673500061)
[2024-12-17 02:09:53,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,545][root][INFO] - Training Epoch: 1/2, step 4276/7134 completed (loss: 3.667257785797119, acc: 0.3351351320743561)
[2024-12-17 02:09:53,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:53,910][root][INFO] - Training Epoch: 1/2, step 4277/7134 completed (loss: 3.959991455078125, acc: 0.23239436745643616)
[2024-12-17 02:09:54,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,278][root][INFO] - Training Epoch: 1/2, step 4278/7134 completed (loss: 3.3256072998046875, acc: 0.38265305757522583)
[2024-12-17 02:09:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:54,648][root][INFO] - Training Epoch: 1/2, step 4279/7134 completed (loss: 3.640042304992676, acc: 0.3105590045452118)
[2024-12-17 02:09:54,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,033][root][INFO] - Training Epoch: 1/2, step 4280/7134 completed (loss: 3.5183489322662354, acc: 0.304964542388916)
[2024-12-17 02:09:55,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,481][root][INFO] - Training Epoch: 1/2, step 4281/7134 completed (loss: 4.056158065795898, acc: 0.2634408473968506)
[2024-12-17 02:09:55,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:55,868][root][INFO] - Training Epoch: 1/2, step 4282/7134 completed (loss: 3.4610254764556885, acc: 0.36206895112991333)
[2024-12-17 02:09:55,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,320][root][INFO] - Training Epoch: 1/2, step 4283/7134 completed (loss: 3.426740884780884, acc: 0.29591837525367737)
[2024-12-17 02:09:56,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:56,680][root][INFO] - Training Epoch: 1/2, step 4284/7134 completed (loss: 3.842167615890503, acc: 0.3100775182247162)
[2024-12-17 02:09:56,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,056][root][INFO] - Training Epoch: 1/2, step 4285/7134 completed (loss: 4.294963836669922, acc: 0.26356589794158936)
[2024-12-17 02:09:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,413][root][INFO] - Training Epoch: 1/2, step 4286/7134 completed (loss: 3.6119086742401123, acc: 0.3193277418613434)
[2024-12-17 02:09:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:57,777][root][INFO] - Training Epoch: 1/2, step 4287/7134 completed (loss: 3.7622172832489014, acc: 0.32608696818351746)
[2024-12-17 02:09:57,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,148][root][INFO] - Training Epoch: 1/2, step 4288/7134 completed (loss: 3.9206435680389404, acc: 0.29411765933036804)
[2024-12-17 02:09:58,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,525][root][INFO] - Training Epoch: 1/2, step 4289/7134 completed (loss: 3.8459558486938477, acc: 0.33128833770751953)
[2024-12-17 02:09:58,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:58,889][root][INFO] - Training Epoch: 1/2, step 4290/7134 completed (loss: 3.920954942703247, acc: 0.3005780279636383)
[2024-12-17 02:09:59,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,275][root][INFO] - Training Epoch: 1/2, step 4291/7134 completed (loss: 3.9535207748413086, acc: 0.3410404622554779)
[2024-12-17 02:09:59,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:09:59,697][root][INFO] - Training Epoch: 1/2, step 4292/7134 completed (loss: 3.5664637088775635, acc: 0.3677419424057007)
[2024-12-17 02:09:59,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,094][root][INFO] - Training Epoch: 1/2, step 4293/7134 completed (loss: 4.099806308746338, acc: 0.2916666567325592)
[2024-12-17 02:10:00,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,479][root][INFO] - Training Epoch: 1/2, step 4294/7134 completed (loss: 3.4407286643981934, acc: 0.35428571701049805)
[2024-12-17 02:10:00,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:00,852][root][INFO] - Training Epoch: 1/2, step 4295/7134 completed (loss: 3.8386940956115723, acc: 0.3499999940395355)
[2024-12-17 02:10:00,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,249][root][INFO] - Training Epoch: 1/2, step 4296/7134 completed (loss: 4.113919734954834, acc: 0.2673267424106598)
[2024-12-17 02:10:01,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,592][root][INFO] - Training Epoch: 1/2, step 4297/7134 completed (loss: 3.6217687129974365, acc: 0.3047619163990021)
[2024-12-17 02:10:01,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:01,957][root][INFO] - Training Epoch: 1/2, step 4298/7134 completed (loss: 3.682267904281616, acc: 0.3125)
[2024-12-17 02:10:02,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,350][root][INFO] - Training Epoch: 1/2, step 4299/7134 completed (loss: 3.663212537765503, acc: 0.34408602118492126)
[2024-12-17 02:10:02,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:02,713][root][INFO] - Training Epoch: 1/2, step 4300/7134 completed (loss: 3.9093968868255615, acc: 0.36974790692329407)
[2024-12-17 02:10:02,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,104][root][INFO] - Training Epoch: 1/2, step 4301/7134 completed (loss: 3.693444013595581, acc: 0.34507042169570923)
[2024-12-17 02:10:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,482][root][INFO] - Training Epoch: 1/2, step 4302/7134 completed (loss: 3.8756258487701416, acc: 0.3439490497112274)
[2024-12-17 02:10:03,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:03,865][root][INFO] - Training Epoch: 1/2, step 4303/7134 completed (loss: 3.476933479309082, acc: 0.32673266530036926)
[2024-12-17 02:10:03,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,256][root][INFO] - Training Epoch: 1/2, step 4304/7134 completed (loss: 3.6705636978149414, acc: 0.33136093616485596)
[2024-12-17 02:10:04,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:04,659][root][INFO] - Training Epoch: 1/2, step 4305/7134 completed (loss: 3.687985420227051, acc: 0.29499998688697815)
[2024-12-17 02:10:04,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,072][root][INFO] - Training Epoch: 1/2, step 4306/7134 completed (loss: 3.8806774616241455, acc: 0.3403141498565674)
[2024-12-17 02:10:05,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,433][root][INFO] - Training Epoch: 1/2, step 4307/7134 completed (loss: 4.114723205566406, acc: 0.26143792271614075)
[2024-12-17 02:10:05,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:05,803][root][INFO] - Training Epoch: 1/2, step 4308/7134 completed (loss: 3.710088014602661, acc: 0.31550800800323486)
[2024-12-17 02:10:05,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,204][root][INFO] - Training Epoch: 1/2, step 4309/7134 completed (loss: 3.9142045974731445, acc: 0.2556818127632141)
[2024-12-17 02:10:06,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,603][root][INFO] - Training Epoch: 1/2, step 4310/7134 completed (loss: 4.105921745300293, acc: 0.29441624879837036)
[2024-12-17 02:10:06,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:06,970][root][INFO] - Training Epoch: 1/2, step 4311/7134 completed (loss: 4.423250675201416, acc: 0.24822695553302765)
[2024-12-17 02:10:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,378][root][INFO] - Training Epoch: 1/2, step 4312/7134 completed (loss: 4.297666072845459, acc: 0.3128834366798401)
[2024-12-17 02:10:07,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:07,773][root][INFO] - Training Epoch: 1/2, step 4313/7134 completed (loss: 4.162563323974609, acc: 0.24242424964904785)
[2024-12-17 02:10:07,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,177][root][INFO] - Training Epoch: 1/2, step 4314/7134 completed (loss: 4.129741668701172, acc: 0.32679739594459534)
[2024-12-17 02:10:08,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,549][root][INFO] - Training Epoch: 1/2, step 4315/7134 completed (loss: 3.836876392364502, acc: 0.2976190447807312)
[2024-12-17 02:10:08,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:08,927][root][INFO] - Training Epoch: 1/2, step 4316/7134 completed (loss: 4.161967754364014, acc: 0.329341322183609)
[2024-12-17 02:10:09,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,298][root][INFO] - Training Epoch: 1/2, step 4317/7134 completed (loss: 4.146553039550781, acc: 0.2906976640224457)
[2024-12-17 02:10:09,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:09,664][root][INFO] - Training Epoch: 1/2, step 4318/7134 completed (loss: 4.12421178817749, acc: 0.3622449040412903)
[2024-12-17 02:10:09,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,042][root][INFO] - Training Epoch: 1/2, step 4319/7134 completed (loss: 3.921564817428589, acc: 0.33990147709846497)
[2024-12-17 02:10:10,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,419][root][INFO] - Training Epoch: 1/2, step 4320/7134 completed (loss: 3.7871031761169434, acc: 0.3205128312110901)
[2024-12-17 02:10:10,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:10,745][root][INFO] - Training Epoch: 1/2, step 4321/7134 completed (loss: 4.182478427886963, acc: 0.2673267424106598)
[2024-12-17 02:10:10,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,091][root][INFO] - Training Epoch: 1/2, step 4322/7134 completed (loss: 4.257172584533691, acc: 0.21383647620677948)
[2024-12-17 02:10:11,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,446][root][INFO] - Training Epoch: 1/2, step 4323/7134 completed (loss: 3.4351401329040527, acc: 0.3308270573616028)
[2024-12-17 02:10:11,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:11,800][root][INFO] - Training Epoch: 1/2, step 4324/7134 completed (loss: 4.328987121582031, acc: 0.2956521809101105)
[2024-12-17 02:10:11,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,168][root][INFO] - Training Epoch: 1/2, step 4325/7134 completed (loss: 3.8074562549591064, acc: 0.3493150770664215)
[2024-12-17 02:10:12,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,553][root][INFO] - Training Epoch: 1/2, step 4326/7134 completed (loss: 4.0273566246032715, acc: 0.3484848439693451)
[2024-12-17 02:10:12,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:12,929][root][INFO] - Training Epoch: 1/2, step 4327/7134 completed (loss: 3.6849348545074463, acc: 0.33576643466949463)
[2024-12-17 02:10:13,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,321][root][INFO] - Training Epoch: 1/2, step 4328/7134 completed (loss: 3.467970609664917, acc: 0.3125)
[2024-12-17 02:10:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:13,701][root][INFO] - Training Epoch: 1/2, step 4329/7134 completed (loss: 3.4662928581237793, acc: 0.3040935695171356)
[2024-12-17 02:10:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,087][root][INFO] - Training Epoch: 1/2, step 4330/7134 completed (loss: 3.5630242824554443, acc: 0.28828829526901245)
[2024-12-17 02:10:14,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,454][root][INFO] - Training Epoch: 1/2, step 4331/7134 completed (loss: 3.8512487411499023, acc: 0.3086419701576233)
[2024-12-17 02:10:14,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:14,841][root][INFO] - Training Epoch: 1/2, step 4332/7134 completed (loss: 3.7700929641723633, acc: 0.3333333432674408)
[2024-12-17 02:10:14,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,230][root][INFO] - Training Epoch: 1/2, step 4333/7134 completed (loss: 3.512063503265381, acc: 0.3062500059604645)
[2024-12-17 02:10:15,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,607][root][INFO] - Training Epoch: 1/2, step 4334/7134 completed (loss: 3.717068672180176, acc: 0.3619631826877594)
[2024-12-17 02:10:15,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:15,967][root][INFO] - Training Epoch: 1/2, step 4335/7134 completed (loss: 4.298095226287842, acc: 0.28099173307418823)
[2024-12-17 02:10:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,303][root][INFO] - Training Epoch: 1/2, step 4336/7134 completed (loss: 3.801042079925537, acc: 0.30215826630592346)
[2024-12-17 02:10:16,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:16,688][root][INFO] - Training Epoch: 1/2, step 4337/7134 completed (loss: 3.5863583087921143, acc: 0.2937062978744507)
[2024-12-17 02:10:16,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,080][root][INFO] - Training Epoch: 1/2, step 4338/7134 completed (loss: 3.355315685272217, acc: 0.38181817531585693)
[2024-12-17 02:10:17,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,465][root][INFO] - Training Epoch: 1/2, step 4339/7134 completed (loss: 3.352445363998413, acc: 0.364705890417099)
[2024-12-17 02:10:17,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:17,860][root][INFO] - Training Epoch: 1/2, step 4340/7134 completed (loss: 2.9370574951171875, acc: 0.4000000059604645)
[2024-12-17 02:10:17,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,219][root][INFO] - Training Epoch: 1/2, step 4341/7134 completed (loss: 3.752370834350586, acc: 0.3265306055545807)
[2024-12-17 02:10:18,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,603][root][INFO] - Training Epoch: 1/2, step 4342/7134 completed (loss: 3.488281726837158, acc: 0.33774834871292114)
[2024-12-17 02:10:18,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:18,977][root][INFO] - Training Epoch: 1/2, step 4343/7134 completed (loss: 3.4215543270111084, acc: 0.3333333432674408)
[2024-12-17 02:10:19,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,366][root][INFO] - Training Epoch: 1/2, step 4344/7134 completed (loss: 3.814195156097412, acc: 0.2869565188884735)
[2024-12-17 02:10:19,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:19,726][root][INFO] - Training Epoch: 1/2, step 4345/7134 completed (loss: 3.7203798294067383, acc: 0.315315306186676)
[2024-12-17 02:10:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,068][root][INFO] - Training Epoch: 1/2, step 4346/7134 completed (loss: 3.769387722015381, acc: 0.2702702581882477)
[2024-12-17 02:10:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,402][root][INFO] - Training Epoch: 1/2, step 4347/7134 completed (loss: 3.72318434715271, acc: 0.2662721872329712)
[2024-12-17 02:10:20,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:20,745][root][INFO] - Training Epoch: 1/2, step 4348/7134 completed (loss: 3.287602424621582, acc: 0.36734694242477417)
[2024-12-17 02:10:20,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,129][root][INFO] - Training Epoch: 1/2, step 4349/7134 completed (loss: 3.6998140811920166, acc: 0.3020833432674408)
[2024-12-17 02:10:21,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,506][root][INFO] - Training Epoch: 1/2, step 4350/7134 completed (loss: 3.5769259929656982, acc: 0.33707866072654724)
[2024-12-17 02:10:21,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:21,886][root][INFO] - Training Epoch: 1/2, step 4351/7134 completed (loss: 4.026974201202393, acc: 0.31410256028175354)
[2024-12-17 02:10:21,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,253][root][INFO] - Training Epoch: 1/2, step 4352/7134 completed (loss: 3.8542885780334473, acc: 0.34161490201950073)
[2024-12-17 02:10:22,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:22,638][root][INFO] - Training Epoch: 1/2, step 4353/7134 completed (loss: 4.13725471496582, acc: 0.2634730637073517)
[2024-12-17 02:10:22,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,008][root][INFO] - Training Epoch: 1/2, step 4354/7134 completed (loss: 3.8813836574554443, acc: 0.30061349272727966)
[2024-12-17 02:10:23,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,380][root][INFO] - Training Epoch: 1/2, step 4355/7134 completed (loss: 3.9676547050476074, acc: 0.31677019596099854)
[2024-12-17 02:10:23,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:23,757][root][INFO] - Training Epoch: 1/2, step 4356/7134 completed (loss: 3.87861704826355, acc: 0.3604651093482971)
[2024-12-17 02:10:23,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,134][root][INFO] - Training Epoch: 1/2, step 4357/7134 completed (loss: 3.9752755165100098, acc: 0.2751677930355072)
[2024-12-17 02:10:24,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,521][root][INFO] - Training Epoch: 1/2, step 4358/7134 completed (loss: 4.130129337310791, acc: 0.31707316637039185)
[2024-12-17 02:10:24,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:24,884][root][INFO] - Training Epoch: 1/2, step 4359/7134 completed (loss: 4.501530170440674, acc: 0.2380952388048172)
[2024-12-17 02:10:25,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,249][root][INFO] - Training Epoch: 1/2, step 4360/7134 completed (loss: 4.035406112670898, acc: 0.3248407542705536)
[2024-12-17 02:10:25,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:25,631][root][INFO] - Training Epoch: 1/2, step 4361/7134 completed (loss: 3.548701524734497, acc: 0.3907284736633301)
[2024-12-17 02:10:25,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,015][root][INFO] - Training Epoch: 1/2, step 4362/7134 completed (loss: 3.7071518898010254, acc: 0.32608696818351746)
[2024-12-17 02:10:26,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,402][root][INFO] - Training Epoch: 1/2, step 4363/7134 completed (loss: 3.690056800842285, acc: 0.39393940567970276)
[2024-12-17 02:10:26,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:26,754][root][INFO] - Training Epoch: 1/2, step 4364/7134 completed (loss: 4.032470703125, acc: 0.24806201457977295)
[2024-12-17 02:10:26,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,136][root][INFO] - Training Epoch: 1/2, step 4365/7134 completed (loss: 3.656446933746338, acc: 0.38129496574401855)
[2024-12-17 02:10:27,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,515][root][INFO] - Training Epoch: 1/2, step 4366/7134 completed (loss: 3.667494297027588, acc: 0.3488371968269348)
[2024-12-17 02:10:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:27,858][root][INFO] - Training Epoch: 1/2, step 4367/7134 completed (loss: 4.194523811340332, acc: 0.3087248206138611)
[2024-12-17 02:10:27,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,238][root][INFO] - Training Epoch: 1/2, step 4368/7134 completed (loss: 3.7249269485473633, acc: 0.2934131622314453)
[2024-12-17 02:10:28,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,619][root][INFO] - Training Epoch: 1/2, step 4369/7134 completed (loss: 3.815626382827759, acc: 0.2926829159259796)
[2024-12-17 02:10:28,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:28,995][root][INFO] - Training Epoch: 1/2, step 4370/7134 completed (loss: 3.6646947860717773, acc: 0.33139535784721375)
[2024-12-17 02:10:29,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,362][root][INFO] - Training Epoch: 1/2, step 4371/7134 completed (loss: 3.7214958667755127, acc: 0.353658527135849)
[2024-12-17 02:10:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:29,713][root][INFO] - Training Epoch: 1/2, step 4372/7134 completed (loss: 3.536123514175415, acc: 0.3442623019218445)
[2024-12-17 02:10:29,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,076][root][INFO] - Training Epoch: 1/2, step 4373/7134 completed (loss: 3.854111433029175, acc: 0.3093922734260559)
[2024-12-17 02:10:30,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,459][root][INFO] - Training Epoch: 1/2, step 4374/7134 completed (loss: 3.8482699394226074, acc: 0.3109756112098694)
[2024-12-17 02:10:30,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:30,831][root][INFO] - Training Epoch: 1/2, step 4375/7134 completed (loss: 3.7207398414611816, acc: 0.2976190447807312)
[2024-12-17 02:10:30,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,161][root][INFO] - Training Epoch: 1/2, step 4376/7134 completed (loss: 3.534100294113159, acc: 0.3645833432674408)
[2024-12-17 02:10:31,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,524][root][INFO] - Training Epoch: 1/2, step 4377/7134 completed (loss: 4.116014003753662, acc: 0.30000001192092896)
[2024-12-17 02:10:31,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:31,857][root][INFO] - Training Epoch: 1/2, step 4378/7134 completed (loss: 4.1005682945251465, acc: 0.25563910603523254)
[2024-12-17 02:10:31,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,246][root][INFO] - Training Epoch: 1/2, step 4379/7134 completed (loss: 3.9897541999816895, acc: 0.29411765933036804)
[2024-12-17 02:10:32,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,618][root][INFO] - Training Epoch: 1/2, step 4380/7134 completed (loss: 4.036099910736084, acc: 0.3076923191547394)
[2024-12-17 02:10:32,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:32,980][root][INFO] - Training Epoch: 1/2, step 4381/7134 completed (loss: 4.07427453994751, acc: 0.38922154903411865)
[2024-12-17 02:10:33,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,349][root][INFO] - Training Epoch: 1/2, step 4382/7134 completed (loss: 4.163449287414551, acc: 0.3290322721004486)
[2024-12-17 02:10:33,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:33,724][root][INFO] - Training Epoch: 1/2, step 4383/7134 completed (loss: 3.919358968734741, acc: 0.32487308979034424)
[2024-12-17 02:10:33,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,068][root][INFO] - Training Epoch: 1/2, step 4384/7134 completed (loss: 4.030608654022217, acc: 0.33522728085517883)
[2024-12-17 02:10:34,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,463][root][INFO] - Training Epoch: 1/2, step 4385/7134 completed (loss: 4.1951985359191895, acc: 0.26424869894981384)
[2024-12-17 02:10:34,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:34,863][root][INFO] - Training Epoch: 1/2, step 4386/7134 completed (loss: 3.9503440856933594, acc: 0.3252427279949188)
[2024-12-17 02:10:34,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,296][root][INFO] - Training Epoch: 1/2, step 4387/7134 completed (loss: 4.0471930503845215, acc: 0.34117648005485535)
[2024-12-17 02:10:35,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:35,691][root][INFO] - Training Epoch: 1/2, step 4388/7134 completed (loss: 4.588345050811768, acc: 0.29870128631591797)
[2024-12-17 02:10:35,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,086][root][INFO] - Training Epoch: 1/2, step 4389/7134 completed (loss: 4.563263416290283, acc: 0.2971014380455017)
[2024-12-17 02:10:36,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,462][root][INFO] - Training Epoch: 1/2, step 4390/7134 completed (loss: 4.329453945159912, acc: 0.25766870379447937)
[2024-12-17 02:10:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:36,851][root][INFO] - Training Epoch: 1/2, step 4391/7134 completed (loss: 4.065586566925049, acc: 0.30821916460990906)
[2024-12-17 02:10:36,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,213][root][INFO] - Training Epoch: 1/2, step 4392/7134 completed (loss: 4.1047749519348145, acc: 0.30158731341362)
[2024-12-17 02:10:37,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,584][root][INFO] - Training Epoch: 1/2, step 4393/7134 completed (loss: 3.9456286430358887, acc: 0.31333333253860474)
[2024-12-17 02:10:37,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:37,976][root][INFO] - Training Epoch: 1/2, step 4394/7134 completed (loss: 3.9760444164276123, acc: 0.34228187799453735)
[2024-12-17 02:10:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,354][root][INFO] - Training Epoch: 1/2, step 4395/7134 completed (loss: 4.698554992675781, acc: 0.29192546010017395)
[2024-12-17 02:10:38,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:38,726][root][INFO] - Training Epoch: 1/2, step 4396/7134 completed (loss: 3.607840061187744, acc: 0.34391534328460693)
[2024-12-17 02:10:38,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,119][root][INFO] - Training Epoch: 1/2, step 4397/7134 completed (loss: 4.7108893394470215, acc: 0.27927929162979126)
[2024-12-17 02:10:39,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,536][root][INFO] - Training Epoch: 1/2, step 4398/7134 completed (loss: 4.128881454467773, acc: 0.2888889014720917)
[2024-12-17 02:10:39,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:39,936][root][INFO] - Training Epoch: 1/2, step 4399/7134 completed (loss: 3.7308452129364014, acc: 0.3958333432674408)
[2024-12-17 02:10:40,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,328][root][INFO] - Training Epoch: 1/2, step 4400/7134 completed (loss: 3.450918674468994, acc: 0.35789474844932556)
[2024-12-17 02:10:40,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:40,686][root][INFO] - Training Epoch: 1/2, step 4401/7134 completed (loss: 4.146718502044678, acc: 0.25161290168762207)
[2024-12-17 02:10:40,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,065][root][INFO] - Training Epoch: 1/2, step 4402/7134 completed (loss: 4.598460674285889, acc: 0.29012346267700195)
[2024-12-17 02:10:41,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,439][root][INFO] - Training Epoch: 1/2, step 4403/7134 completed (loss: 4.1824140548706055, acc: 0.2454545497894287)
[2024-12-17 02:10:41,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:41,833][root][INFO] - Training Epoch: 1/2, step 4404/7134 completed (loss: 4.455674648284912, acc: 0.24742268025875092)
[2024-12-17 02:10:41,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,236][root][INFO] - Training Epoch: 1/2, step 4405/7134 completed (loss: 4.46039342880249, acc: 0.22772277891635895)
[2024-12-17 02:10:42,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:42,644][root][INFO] - Training Epoch: 1/2, step 4406/7134 completed (loss: 3.9653782844543457, acc: 0.28780487179756165)
[2024-12-17 02:10:42,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,017][root][INFO] - Training Epoch: 1/2, step 4407/7134 completed (loss: 3.992300271987915, acc: 0.33673468232154846)
[2024-12-17 02:10:43,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,409][root][INFO] - Training Epoch: 1/2, step 4408/7134 completed (loss: 4.093241214752197, acc: 0.24038460850715637)
[2024-12-17 02:10:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:43,797][root][INFO] - Training Epoch: 1/2, step 4409/7134 completed (loss: 3.9774863719940186, acc: 0.265625)
[2024-12-17 02:10:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,165][root][INFO] - Training Epoch: 1/2, step 4410/7134 completed (loss: 4.172131538391113, acc: 0.279720276594162)
[2024-12-17 02:10:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,527][root][INFO] - Training Epoch: 1/2, step 4411/7134 completed (loss: 4.202402591705322, acc: 0.20430107414722443)
[2024-12-17 02:10:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:44,917][root][INFO] - Training Epoch: 1/2, step 4412/7134 completed (loss: 4.80555534362793, acc: 0.20603014528751373)
[2024-12-17 02:10:45,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,318][root][INFO] - Training Epoch: 1/2, step 4413/7134 completed (loss: 4.346753120422363, acc: 0.2953367829322815)
[2024-12-17 02:10:45,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:45,704][root][INFO] - Training Epoch: 1/2, step 4414/7134 completed (loss: 3.8902840614318848, acc: 0.3172042965888977)
[2024-12-17 02:10:45,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,091][root][INFO] - Training Epoch: 1/2, step 4415/7134 completed (loss: 3.821211814880371, acc: 0.26966291666030884)
[2024-12-17 02:10:46,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,482][root][INFO] - Training Epoch: 1/2, step 4416/7134 completed (loss: 3.627903699874878, acc: 0.32642486691474915)
[2024-12-17 02:10:46,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:46,878][root][INFO] - Training Epoch: 1/2, step 4417/7134 completed (loss: 4.0339274406433105, acc: 0.28787878155708313)
[2024-12-17 02:10:46,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,251][root][INFO] - Training Epoch: 1/2, step 4418/7134 completed (loss: 4.123166084289551, acc: 0.2554347813129425)
[2024-12-17 02:10:47,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,611][root][INFO] - Training Epoch: 1/2, step 4419/7134 completed (loss: 3.8570380210876465, acc: 0.30243903398513794)
[2024-12-17 02:10:47,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:47,991][root][INFO] - Training Epoch: 1/2, step 4420/7134 completed (loss: 4.344977378845215, acc: 0.27979275584220886)
[2024-12-17 02:10:48,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,365][root][INFO] - Training Epoch: 1/2, step 4421/7134 completed (loss: 3.791574239730835, acc: 0.2706421911716461)
[2024-12-17 02:10:48,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:48,743][root][INFO] - Training Epoch: 1/2, step 4422/7134 completed (loss: 4.046693801879883, acc: 0.257485032081604)
[2024-12-17 02:10:48,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,110][root][INFO] - Training Epoch: 1/2, step 4423/7134 completed (loss: 3.7645390033721924, acc: 0.2901785671710968)
[2024-12-17 02:10:49,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,475][root][INFO] - Training Epoch: 1/2, step 4424/7134 completed (loss: 3.57119083404541, acc: 0.3181818127632141)
[2024-12-17 02:10:49,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:49,858][root][INFO] - Training Epoch: 1/2, step 4425/7134 completed (loss: 3.6163768768310547, acc: 0.28217822313308716)
[2024-12-17 02:10:49,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,261][root][INFO] - Training Epoch: 1/2, step 4426/7134 completed (loss: 3.78320050239563, acc: 0.3160000145435333)
[2024-12-17 02:10:50,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:50,648][root][INFO] - Training Epoch: 1/2, step 4427/7134 completed (loss: 4.621812343597412, acc: 0.24137930572032928)
[2024-12-17 02:10:50,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,036][root][INFO] - Training Epoch: 1/2, step 4428/7134 completed (loss: 3.676678419113159, acc: 0.28901734948158264)
[2024-12-17 02:10:51,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,394][root][INFO] - Training Epoch: 1/2, step 4429/7134 completed (loss: 3.758237600326538, acc: 0.3142857253551483)
[2024-12-17 02:10:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:51,780][root][INFO] - Training Epoch: 1/2, step 4430/7134 completed (loss: 3.8169994354248047, acc: 0.2808988690376282)
[2024-12-17 02:10:51,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,158][root][INFO] - Training Epoch: 1/2, step 4431/7134 completed (loss: 3.7149832248687744, acc: 0.27906978130340576)
[2024-12-17 02:10:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,523][root][INFO] - Training Epoch: 1/2, step 4432/7134 completed (loss: 4.139035224914551, acc: 0.20382165908813477)
[2024-12-17 02:10:52,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:52,895][root][INFO] - Training Epoch: 1/2, step 4433/7134 completed (loss: 3.624892234802246, acc: 0.31904762983322144)
[2024-12-17 02:10:52,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,275][root][INFO] - Training Epoch: 1/2, step 4434/7134 completed (loss: 4.509291648864746, acc: 0.24571429193019867)
[2024-12-17 02:10:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:53,651][root][INFO] - Training Epoch: 1/2, step 4435/7134 completed (loss: 3.8900833129882812, acc: 0.2777777910232544)
[2024-12-17 02:10:53,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,050][root][INFO] - Training Epoch: 1/2, step 4436/7134 completed (loss: 4.047470569610596, acc: 0.3076923191547394)
[2024-12-17 02:10:54,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,437][root][INFO] - Training Epoch: 1/2, step 4437/7134 completed (loss: 3.5660367012023926, acc: 0.30054643750190735)
[2024-12-17 02:10:54,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:54,811][root][INFO] - Training Epoch: 1/2, step 4438/7134 completed (loss: 4.457216739654541, acc: 0.2014925330877304)
[2024-12-17 02:10:54,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,192][root][INFO] - Training Epoch: 1/2, step 4439/7134 completed (loss: 3.792848825454712, acc: 0.2978723347187042)
[2024-12-17 02:10:55,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,555][root][INFO] - Training Epoch: 1/2, step 4440/7134 completed (loss: 4.0055131912231445, acc: 0.2590361535549164)
[2024-12-17 02:10:55,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:55,945][root][INFO] - Training Epoch: 1/2, step 4441/7134 completed (loss: 4.0173139572143555, acc: 0.2704402506351471)
[2024-12-17 02:10:56,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,335][root][INFO] - Training Epoch: 1/2, step 4442/7134 completed (loss: 4.124159812927246, acc: 0.2808988690376282)
[2024-12-17 02:10:56,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:56,708][root][INFO] - Training Epoch: 1/2, step 4443/7134 completed (loss: 4.33368444442749, acc: 0.3176470696926117)
[2024-12-17 02:10:56,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,051][root][INFO] - Training Epoch: 1/2, step 4444/7134 completed (loss: 4.472485542297363, acc: 0.2554744482040405)
[2024-12-17 02:10:57,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,415][root][INFO] - Training Epoch: 1/2, step 4445/7134 completed (loss: 4.36852502822876, acc: 0.2781065106391907)
[2024-12-17 02:10:57,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:57,803][root][INFO] - Training Epoch: 1/2, step 4446/7134 completed (loss: 4.514787673950195, acc: 0.24806201457977295)
[2024-12-17 02:10:57,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,194][root][INFO] - Training Epoch: 1/2, step 4447/7134 completed (loss: 4.355257034301758, acc: 0.2931034564971924)
[2024-12-17 02:10:58,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,587][root][INFO] - Training Epoch: 1/2, step 4448/7134 completed (loss: 4.232091426849365, acc: 0.3178294599056244)
[2024-12-17 02:10:58,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:58,945][root][INFO] - Training Epoch: 1/2, step 4449/7134 completed (loss: 4.3347063064575195, acc: 0.29661017656326294)
[2024-12-17 02:10:59,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,352][root][INFO] - Training Epoch: 1/2, step 4450/7134 completed (loss: 4.335839748382568, acc: 0.22340425848960876)
[2024-12-17 02:10:59,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:10:59,713][root][INFO] - Training Epoch: 1/2, step 4451/7134 completed (loss: 4.520467281341553, acc: 0.2929936349391937)
[2024-12-17 02:10:59,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,071][root][INFO] - Training Epoch: 1/2, step 4452/7134 completed (loss: 4.591590881347656, acc: 0.24444444477558136)
[2024-12-17 02:11:00,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,461][root][INFO] - Training Epoch: 1/2, step 4453/7134 completed (loss: 4.382652759552002, acc: 0.2810457646846771)
[2024-12-17 02:11:00,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:00,872][root][INFO] - Training Epoch: 1/2, step 4454/7134 completed (loss: 4.813933849334717, acc: 0.21739129722118378)
[2024-12-17 02:11:01,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,240][root][INFO] - Training Epoch: 1/2, step 4455/7134 completed (loss: 3.9263687133789062, acc: 0.3333333432674408)
[2024-12-17 02:11:01,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:01,628][root][INFO] - Training Epoch: 1/2, step 4456/7134 completed (loss: 3.637040853500366, acc: 0.3333333432674408)
[2024-12-17 02:11:01,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,002][root][INFO] - Training Epoch: 1/2, step 4457/7134 completed (loss: 3.8570024967193604, acc: 0.33766233921051025)
[2024-12-17 02:11:02,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,406][root][INFO] - Training Epoch: 1/2, step 4458/7134 completed (loss: 3.4349677562713623, acc: 0.32867133617401123)
[2024-12-17 02:11:02,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:02,788][root][INFO] - Training Epoch: 1/2, step 4459/7134 completed (loss: 3.470524549484253, acc: 0.29651162028312683)
[2024-12-17 02:11:02,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,178][root][INFO] - Training Epoch: 1/2, step 4460/7134 completed (loss: 3.4996941089630127, acc: 0.33497536182403564)
[2024-12-17 02:11:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,560][root][INFO] - Training Epoch: 1/2, step 4461/7134 completed (loss: 3.7207515239715576, acc: 0.2864583432674408)
[2024-12-17 02:11:03,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:03,938][root][INFO] - Training Epoch: 1/2, step 4462/7134 completed (loss: 3.462745428085327, acc: 0.3142857253551483)
[2024-12-17 02:11:04,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,321][root][INFO] - Training Epoch: 1/2, step 4463/7134 completed (loss: 3.7774057388305664, acc: 0.2857142984867096)
[2024-12-17 02:11:04,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:04,715][root][INFO] - Training Epoch: 1/2, step 4464/7134 completed (loss: 3.434831142425537, acc: 0.34246575832366943)
[2024-12-17 02:11:04,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,095][root][INFO] - Training Epoch: 1/2, step 4465/7134 completed (loss: 3.4834718704223633, acc: 0.27272728085517883)
[2024-12-17 02:11:05,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,457][root][INFO] - Training Epoch: 1/2, step 4466/7134 completed (loss: 3.5303456783294678, acc: 0.33838382363319397)
[2024-12-17 02:11:05,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:05,868][root][INFO] - Training Epoch: 1/2, step 4467/7134 completed (loss: 3.786916494369507, acc: 0.27272728085517883)
[2024-12-17 02:11:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,237][root][INFO] - Training Epoch: 1/2, step 4468/7134 completed (loss: 3.363734245300293, acc: 0.30481284856796265)
[2024-12-17 02:11:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:06,636][root][INFO] - Training Epoch: 1/2, step 4469/7134 completed (loss: 3.2801828384399414, acc: 0.3217821717262268)
[2024-12-17 02:11:06,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,032][root][INFO] - Training Epoch: 1/2, step 4470/7134 completed (loss: 3.5668981075286865, acc: 0.3461538553237915)
[2024-12-17 02:11:07,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,406][root][INFO] - Training Epoch: 1/2, step 4471/7134 completed (loss: 3.538727045059204, acc: 0.35353535413742065)
[2024-12-17 02:11:07,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:07,765][root][INFO] - Training Epoch: 1/2, step 4472/7134 completed (loss: 3.5925967693328857, acc: 0.32777777314186096)
[2024-12-17 02:11:07,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,169][root][INFO] - Training Epoch: 1/2, step 4473/7134 completed (loss: 3.7205123901367188, acc: 0.3491124212741852)
[2024-12-17 02:11:08,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,540][root][INFO] - Training Epoch: 1/2, step 4474/7134 completed (loss: 3.951526403427124, acc: 0.3229813575744629)
[2024-12-17 02:11:08,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:08,915][root][INFO] - Training Epoch: 1/2, step 4475/7134 completed (loss: 3.857776165008545, acc: 0.33510637283325195)
[2024-12-17 02:11:09,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,302][root][INFO] - Training Epoch: 1/2, step 4476/7134 completed (loss: 3.872346878051758, acc: 0.3186813294887543)
[2024-12-17 02:11:09,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:09,690][root][INFO] - Training Epoch: 1/2, step 4477/7134 completed (loss: 3.690894365310669, acc: 0.2448979616165161)
[2024-12-17 02:11:09,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,082][root][INFO] - Training Epoch: 1/2, step 4478/7134 completed (loss: 3.3376879692077637, acc: 0.33507853746414185)
[2024-12-17 02:11:10,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,449][root][INFO] - Training Epoch: 1/2, step 4479/7134 completed (loss: 4.102826118469238, acc: 0.2666666805744171)
[2024-12-17 02:11:10,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:10,852][root][INFO] - Training Epoch: 1/2, step 4480/7134 completed (loss: 3.8617568016052246, acc: 0.3316831588745117)
[2024-12-17 02:11:10,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,232][root][INFO] - Training Epoch: 1/2, step 4481/7134 completed (loss: 3.6292428970336914, acc: 0.25999999046325684)
[2024-12-17 02:11:11,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,608][root][INFO] - Training Epoch: 1/2, step 4482/7134 completed (loss: 3.5031542778015137, acc: 0.31683167815208435)
[2024-12-17 02:11:11,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:11,987][root][INFO] - Training Epoch: 1/2, step 4483/7134 completed (loss: 4.056024551391602, acc: 0.31677019596099854)
[2024-12-17 02:11:12,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,365][root][INFO] - Training Epoch: 1/2, step 4484/7134 completed (loss: 4.040773868560791, acc: 0.2556818127632141)
[2024-12-17 02:11:12,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:12,732][root][INFO] - Training Epoch: 1/2, step 4485/7134 completed (loss: 4.048293590545654, acc: 0.26143792271614075)
[2024-12-17 02:11:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,069][root][INFO] - Training Epoch: 1/2, step 4486/7134 completed (loss: 3.5351085662841797, acc: 0.3478260934352875)
[2024-12-17 02:11:13,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,424][root][INFO] - Training Epoch: 1/2, step 4487/7134 completed (loss: 3.5668222904205322, acc: 0.33128833770751953)
[2024-12-17 02:11:13,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:13,802][root][INFO] - Training Epoch: 1/2, step 4488/7134 completed (loss: 3.863722562789917, acc: 0.3333333432674408)
[2024-12-17 02:11:13,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,171][root][INFO] - Training Epoch: 1/2, step 4489/7134 completed (loss: 3.363898515701294, acc: 0.38620689511299133)
[2024-12-17 02:11:14,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,577][root][INFO] - Training Epoch: 1/2, step 4490/7134 completed (loss: 3.9410383701324463, acc: 0.2720000147819519)
[2024-12-17 02:11:14,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:14,982][root][INFO] - Training Epoch: 1/2, step 4491/7134 completed (loss: 4.167827129364014, acc: 0.290076345205307)
[2024-12-17 02:11:15,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,340][root][INFO] - Training Epoch: 1/2, step 4492/7134 completed (loss: 3.4567394256591797, acc: 0.3684210479259491)
[2024-12-17 02:11:15,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:15,695][root][INFO] - Training Epoch: 1/2, step 4493/7134 completed (loss: 3.519019842147827, acc: 0.35465115308761597)
[2024-12-17 02:11:15,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,066][root][INFO] - Training Epoch: 1/2, step 4494/7134 completed (loss: 3.7499969005584717, acc: 0.32022473216056824)
[2024-12-17 02:11:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,447][root][INFO] - Training Epoch: 1/2, step 4495/7134 completed (loss: 3.424091339111328, acc: 0.32474225759506226)
[2024-12-17 02:11:16,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:16,826][root][INFO] - Training Epoch: 1/2, step 4496/7134 completed (loss: 3.7607479095458984, acc: 0.27485379576683044)
[2024-12-17 02:11:16,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,220][root][INFO] - Training Epoch: 1/2, step 4497/7134 completed (loss: 3.1367435455322266, acc: 0.33862432837486267)
[2024-12-17 02:11:17,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,601][root][INFO] - Training Epoch: 1/2, step 4498/7134 completed (loss: 3.6479742527008057, acc: 0.3005780279636383)
[2024-12-17 02:11:17,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:17,970][root][INFO] - Training Epoch: 1/2, step 4499/7134 completed (loss: 4.030207633972168, acc: 0.23404255509376526)
[2024-12-17 02:11:18,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,349][root][INFO] - Training Epoch: 1/2, step 4500/7134 completed (loss: 3.3606626987457275, acc: 0.3636363744735718)
[2024-12-17 02:11:18,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:18,691][root][INFO] - Training Epoch: 1/2, step 4501/7134 completed (loss: 3.4294564723968506, acc: 0.33149170875549316)
[2024-12-17 02:11:18,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,029][root][INFO] - Training Epoch: 1/2, step 4502/7134 completed (loss: 3.339909553527832, acc: 0.39411765336990356)
[2024-12-17 02:11:19,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,366][root][INFO] - Training Epoch: 1/2, step 4503/7134 completed (loss: 3.38010311126709, acc: 0.3207547068595886)
[2024-12-17 02:11:19,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:19,732][root][INFO] - Training Epoch: 1/2, step 4504/7134 completed (loss: 4.055957317352295, acc: 0.26708075404167175)
[2024-12-17 02:11:19,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,097][root][INFO] - Training Epoch: 1/2, step 4505/7134 completed (loss: 3.7107086181640625, acc: 0.36216217279434204)
[2024-12-17 02:11:20,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,454][root][INFO] - Training Epoch: 1/2, step 4506/7134 completed (loss: 3.9284229278564453, acc: 0.2699386477470398)
[2024-12-17 02:11:20,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:20,803][root][INFO] - Training Epoch: 1/2, step 4507/7134 completed (loss: 3.6658260822296143, acc: 0.3571428656578064)
[2024-12-17 02:11:20,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,185][root][INFO] - Training Epoch: 1/2, step 4508/7134 completed (loss: 3.8342084884643555, acc: 0.4037266969680786)
[2024-12-17 02:11:21,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,545][root][INFO] - Training Epoch: 1/2, step 4509/7134 completed (loss: 3.9385342597961426, acc: 0.290909081697464)
[2024-12-17 02:11:21,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:21,923][root][INFO] - Training Epoch: 1/2, step 4510/7134 completed (loss: 3.858179807662964, acc: 0.3154761791229248)
[2024-12-17 02:11:22,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,288][root][INFO] - Training Epoch: 1/2, step 4511/7134 completed (loss: 3.9759438037872314, acc: 0.3181818127632141)
[2024-12-17 02:11:22,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:22,657][root][INFO] - Training Epoch: 1/2, step 4512/7134 completed (loss: 4.058010578155518, acc: 0.29629629850387573)
[2024-12-17 02:11:22,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,036][root][INFO] - Training Epoch: 1/2, step 4513/7134 completed (loss: 3.661947011947632, acc: 0.3040935695171356)
[2024-12-17 02:11:23,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,425][root][INFO] - Training Epoch: 1/2, step 4514/7134 completed (loss: 3.8614444732666016, acc: 0.3005780279636383)
[2024-12-17 02:11:23,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:23,793][root][INFO] - Training Epoch: 1/2, step 4515/7134 completed (loss: 3.7573490142822266, acc: 0.34210526943206787)
[2024-12-17 02:11:23,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,167][root][INFO] - Training Epoch: 1/2, step 4516/7134 completed (loss: 3.976555585861206, acc: 0.27272728085517883)
[2024-12-17 02:11:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,536][root][INFO] - Training Epoch: 1/2, step 4517/7134 completed (loss: 3.9834046363830566, acc: 0.3149999976158142)
[2024-12-17 02:11:24,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:24,898][root][INFO] - Training Epoch: 1/2, step 4518/7134 completed (loss: 3.7942614555358887, acc: 0.34536081552505493)
[2024-12-17 02:11:25,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,249][root][INFO] - Training Epoch: 1/2, step 4519/7134 completed (loss: 3.748878002166748, acc: 0.31343284249305725)
[2024-12-17 02:11:25,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,609][root][INFO] - Training Epoch: 1/2, step 4520/7134 completed (loss: 3.878413677215576, acc: 0.2513369023799896)
[2024-12-17 02:11:25,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:25,980][root][INFO] - Training Epoch: 1/2, step 4521/7134 completed (loss: 3.753716468811035, acc: 0.2849999964237213)
[2024-12-17 02:11:26,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,356][root][INFO] - Training Epoch: 1/2, step 4522/7134 completed (loss: 3.547805070877075, acc: 0.31753554940223694)
[2024-12-17 02:11:26,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:26,744][root][INFO] - Training Epoch: 1/2, step 4523/7134 completed (loss: 3.610689640045166, acc: 0.2863849699497223)
[2024-12-17 02:11:26,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,116][root][INFO] - Training Epoch: 1/2, step 4524/7134 completed (loss: 3.5330193042755127, acc: 0.36125653982162476)
[2024-12-17 02:11:27,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,475][root][INFO] - Training Epoch: 1/2, step 4525/7134 completed (loss: 3.767674684524536, acc: 0.3645320236682892)
[2024-12-17 02:11:27,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:27,868][root][INFO] - Training Epoch: 1/2, step 4526/7134 completed (loss: 3.81610369682312, acc: 0.3351648449897766)
[2024-12-17 02:11:27,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,241][root][INFO] - Training Epoch: 1/2, step 4527/7134 completed (loss: 3.559971809387207, acc: 0.36771300435066223)
[2024-12-17 02:11:28,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,595][root][INFO] - Training Epoch: 1/2, step 4528/7134 completed (loss: 3.668823480606079, acc: 0.29556649923324585)
[2024-12-17 02:11:28,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:28,969][root][INFO] - Training Epoch: 1/2, step 4529/7134 completed (loss: 3.878183126449585, acc: 0.33507853746414185)
[2024-12-17 02:11:29,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,354][root][INFO] - Training Epoch: 1/2, step 4530/7134 completed (loss: 3.5020718574523926, acc: 0.3109756112098694)
[2024-12-17 02:11:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:29,735][root][INFO] - Training Epoch: 1/2, step 4531/7134 completed (loss: 3.8102428913116455, acc: 0.34375)
[2024-12-17 02:11:29,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,114][root][INFO] - Training Epoch: 1/2, step 4532/7134 completed (loss: 3.8730461597442627, acc: 0.3206751048564911)
[2024-12-17 02:11:30,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,471][root][INFO] - Training Epoch: 1/2, step 4533/7134 completed (loss: 3.750218629837036, acc: 0.3472222089767456)
[2024-12-17 02:11:30,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:30,839][root][INFO] - Training Epoch: 1/2, step 4534/7134 completed (loss: 3.652080774307251, acc: 0.3401015102863312)
[2024-12-17 02:11:30,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,221][root][INFO] - Training Epoch: 1/2, step 4535/7134 completed (loss: 4.025805473327637, acc: 0.29326921701431274)
[2024-12-17 02:11:31,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,594][root][INFO] - Training Epoch: 1/2, step 4536/7134 completed (loss: 3.3260657787323, acc: 0.3413654565811157)
[2024-12-17 02:11:31,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:31,956][root][INFO] - Training Epoch: 1/2, step 4537/7134 completed (loss: 3.3790225982666016, acc: 0.31674209237098694)
[2024-12-17 02:11:32,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,328][root][INFO] - Training Epoch: 1/2, step 4538/7134 completed (loss: 3.5385231971740723, acc: 0.27053138613700867)
[2024-12-17 02:11:32,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:32,710][root][INFO] - Training Epoch: 1/2, step 4539/7134 completed (loss: 3.7256834506988525, acc: 0.31455397605895996)
[2024-12-17 02:11:32,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,094][root][INFO] - Training Epoch: 1/2, step 4540/7134 completed (loss: 4.265610694885254, acc: 0.2976190447807312)
[2024-12-17 02:11:33,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,464][root][INFO] - Training Epoch: 1/2, step 4541/7134 completed (loss: 4.687273025512695, acc: 0.26229506731033325)
[2024-12-17 02:11:33,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:33,839][root][INFO] - Training Epoch: 1/2, step 4542/7134 completed (loss: 4.837809085845947, acc: 0.2368421107530594)
[2024-12-17 02:11:33,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,216][root][INFO] - Training Epoch: 1/2, step 4543/7134 completed (loss: 4.269048690795898, acc: 0.3181818127632141)
[2024-12-17 02:11:34,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,604][root][INFO] - Training Epoch: 1/2, step 4544/7134 completed (loss: 4.4018659591674805, acc: 0.30405405163764954)
[2024-12-17 02:11:34,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:34,978][root][INFO] - Training Epoch: 1/2, step 4545/7134 completed (loss: 4.129327774047852, acc: 0.25925925374031067)
[2024-12-17 02:11:35,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,384][root][INFO] - Training Epoch: 1/2, step 4546/7134 completed (loss: 4.551821231842041, acc: 0.23622047901153564)
[2024-12-17 02:11:35,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:35,779][root][INFO] - Training Epoch: 1/2, step 4547/7134 completed (loss: 4.26930046081543, acc: 0.29661017656326294)
[2024-12-17 02:11:35,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,173][root][INFO] - Training Epoch: 1/2, step 4548/7134 completed (loss: 4.462226867675781, acc: 0.24409449100494385)
[2024-12-17 02:11:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,562][root][INFO] - Training Epoch: 1/2, step 4549/7134 completed (loss: 4.8071722984313965, acc: 0.2368421107530594)
[2024-12-17 02:11:36,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:36,980][root][INFO] - Training Epoch: 1/2, step 4550/7134 completed (loss: 4.2779436111450195, acc: 0.21052631735801697)
[2024-12-17 02:11:37,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,330][root][INFO] - Training Epoch: 1/2, step 4551/7134 completed (loss: 3.858837127685547, acc: 0.3513513505458832)
[2024-12-17 02:11:37,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:37,702][root][INFO] - Training Epoch: 1/2, step 4552/7134 completed (loss: 3.996352434158325, acc: 0.3070175349712372)
[2024-12-17 02:11:37,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,089][root][INFO] - Training Epoch: 1/2, step 4553/7134 completed (loss: 4.200459957122803, acc: 0.2651515007019043)
[2024-12-17 02:11:38,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,457][root][INFO] - Training Epoch: 1/2, step 4554/7134 completed (loss: 4.2549662590026855, acc: 0.32116788625717163)
[2024-12-17 02:11:38,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:38,827][root][INFO] - Training Epoch: 1/2, step 4555/7134 completed (loss: 4.544946193695068, acc: 0.2708333432674408)
[2024-12-17 02:11:38,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,199][root][INFO] - Training Epoch: 1/2, step 4556/7134 completed (loss: 4.2983574867248535, acc: 0.3290322721004486)
[2024-12-17 02:11:39,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,548][root][INFO] - Training Epoch: 1/2, step 4557/7134 completed (loss: 4.034826755523682, acc: 0.35820895433425903)
[2024-12-17 02:11:39,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:39,941][root][INFO] - Training Epoch: 1/2, step 4558/7134 completed (loss: 4.092781066894531, acc: 0.3100775182247162)
[2024-12-17 02:11:40,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,356][root][INFO] - Training Epoch: 1/2, step 4559/7134 completed (loss: 4.024750232696533, acc: 0.34090909361839294)
[2024-12-17 02:11:40,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:40,817][root][INFO] - Training Epoch: 1/2, step 4560/7134 completed (loss: 4.273730278015137, acc: 0.2661290466785431)
[2024-12-17 02:11:40,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,208][root][INFO] - Training Epoch: 1/2, step 4561/7134 completed (loss: 4.399389266967773, acc: 0.2704918086528778)
[2024-12-17 02:11:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:41,634][root][INFO] - Training Epoch: 1/2, step 4562/7134 completed (loss: 4.231848239898682, acc: 0.26829269528388977)
[2024-12-17 02:11:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,041][root][INFO] - Training Epoch: 1/2, step 4563/7134 completed (loss: 3.9054529666900635, acc: 0.3120567500591278)
[2024-12-17 02:11:42,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,461][root][INFO] - Training Epoch: 1/2, step 4564/7134 completed (loss: 4.2177629470825195, acc: 0.2922077775001526)
[2024-12-17 02:11:42,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:42,844][root][INFO] - Training Epoch: 1/2, step 4565/7134 completed (loss: 4.30772590637207, acc: 0.3008849620819092)
[2024-12-17 02:11:42,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,212][root][INFO] - Training Epoch: 1/2, step 4566/7134 completed (loss: 4.16441011428833, acc: 0.24060150980949402)
[2024-12-17 02:11:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,560][root][INFO] - Training Epoch: 1/2, step 4567/7134 completed (loss: 3.898390531539917, acc: 0.2612612545490265)
[2024-12-17 02:11:43,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:43,936][root][INFO] - Training Epoch: 1/2, step 4568/7134 completed (loss: 4.916487693786621, acc: 0.11578947305679321)
[2024-12-17 02:11:44,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,323][root][INFO] - Training Epoch: 1/2, step 4569/7134 completed (loss: 4.371251583099365, acc: 0.3097345232963562)
[2024-12-17 02:11:44,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:44,708][root][INFO] - Training Epoch: 1/2, step 4570/7134 completed (loss: 4.365752220153809, acc: 0.29870128631591797)
[2024-12-17 02:11:44,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,095][root][INFO] - Training Epoch: 1/2, step 4571/7134 completed (loss: 4.248043537139893, acc: 0.24712643027305603)
[2024-12-17 02:11:45,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,457][root][INFO] - Training Epoch: 1/2, step 4572/7134 completed (loss: 4.106288909912109, acc: 0.30263158679008484)
[2024-12-17 02:11:45,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:45,855][root][INFO] - Training Epoch: 1/2, step 4573/7134 completed (loss: 4.229658603668213, acc: 0.30128204822540283)
[2024-12-17 02:11:45,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,198][root][INFO] - Training Epoch: 1/2, step 4574/7134 completed (loss: 4.142861366271973, acc: 0.27272728085517883)
[2024-12-17 02:11:46,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,583][root][INFO] - Training Epoch: 1/2, step 4575/7134 completed (loss: 4.245036602020264, acc: 0.2928176820278168)
[2024-12-17 02:11:46,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:46,999][root][INFO] - Training Epoch: 1/2, step 4576/7134 completed (loss: 3.828031063079834, acc: 0.3199999928474426)
[2024-12-17 02:11:47,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,384][root][INFO] - Training Epoch: 1/2, step 4577/7134 completed (loss: 4.370183944702148, acc: 0.25581395626068115)
[2024-12-17 02:11:47,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:47,744][root][INFO] - Training Epoch: 1/2, step 4578/7134 completed (loss: 3.9797451496124268, acc: 0.30909091234207153)
[2024-12-17 02:11:47,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,097][root][INFO] - Training Epoch: 1/2, step 4579/7134 completed (loss: 4.2025556564331055, acc: 0.2594936788082123)
[2024-12-17 02:11:48,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,454][root][INFO] - Training Epoch: 1/2, step 4580/7134 completed (loss: 4.443782329559326, acc: 0.2531645596027374)
[2024-12-17 02:11:48,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:48,830][root][INFO] - Training Epoch: 1/2, step 4581/7134 completed (loss: 3.509868860244751, acc: 0.3216783106327057)
[2024-12-17 02:11:48,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,233][root][INFO] - Training Epoch: 1/2, step 4582/7134 completed (loss: 4.116641044616699, acc: 0.25)
[2024-12-17 02:11:49,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:49,608][root][INFO] - Training Epoch: 1/2, step 4583/7134 completed (loss: 3.4732604026794434, acc: 0.3199999928474426)
[2024-12-17 02:11:49,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,020][root][INFO] - Training Epoch: 1/2, step 4584/7134 completed (loss: 4.13099479675293, acc: 0.2689655125141144)
[2024-12-17 02:11:50,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,400][root][INFO] - Training Epoch: 1/2, step 4585/7134 completed (loss: 3.644413471221924, acc: 0.29487180709838867)
[2024-12-17 02:11:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:50,776][root][INFO] - Training Epoch: 1/2, step 4586/7134 completed (loss: 3.9773812294006348, acc: 0.33136093616485596)
[2024-12-17 02:11:50,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,163][root][INFO] - Training Epoch: 1/2, step 4587/7134 completed (loss: 4.4906768798828125, acc: 0.19767442345619202)
[2024-12-17 02:11:51,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,546][root][INFO] - Training Epoch: 1/2, step 4588/7134 completed (loss: 3.837996244430542, acc: 0.2874999940395355)
[2024-12-17 02:11:51,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:51,919][root][INFO] - Training Epoch: 1/2, step 4589/7134 completed (loss: 4.168734550476074, acc: 0.2816092073917389)
[2024-12-17 02:11:52,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,309][root][INFO] - Training Epoch: 1/2, step 4590/7134 completed (loss: 4.551268577575684, acc: 0.3095238208770752)
[2024-12-17 02:11:52,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:52,709][root][INFO] - Training Epoch: 1/2, step 4591/7134 completed (loss: 4.619657039642334, acc: 0.25)
[2024-12-17 02:11:52,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,078][root][INFO] - Training Epoch: 1/2, step 4592/7134 completed (loss: 4.3238348960876465, acc: 0.3414634168148041)
[2024-12-17 02:11:53,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,444][root][INFO] - Training Epoch: 1/2, step 4593/7134 completed (loss: 4.381363391876221, acc: 0.2763157784938812)
[2024-12-17 02:11:53,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:53,827][root][INFO] - Training Epoch: 1/2, step 4594/7134 completed (loss: 4.471439838409424, acc: 0.2857142984867096)
[2024-12-17 02:11:53,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,217][root][INFO] - Training Epoch: 1/2, step 4595/7134 completed (loss: 4.483835697174072, acc: 0.3164556920528412)
[2024-12-17 02:11:54,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:54,625][root][INFO] - Training Epoch: 1/2, step 4596/7134 completed (loss: 3.6814796924591064, acc: 0.33125001192092896)
[2024-12-17 02:11:54,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,040][root][INFO] - Training Epoch: 1/2, step 4597/7134 completed (loss: 3.842088222503662, acc: 0.28205129504203796)
[2024-12-17 02:11:55,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,419][root][INFO] - Training Epoch: 1/2, step 4598/7134 completed (loss: 4.375830173492432, acc: 0.28108108043670654)
[2024-12-17 02:11:55,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:55,780][root][INFO] - Training Epoch: 1/2, step 4599/7134 completed (loss: 4.12747049331665, acc: 0.2971014380455017)
[2024-12-17 02:11:55,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,171][root][INFO] - Training Epoch: 1/2, step 4600/7134 completed (loss: 4.594470024108887, acc: 0.2515723407268524)
[2024-12-17 02:11:56,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,561][root][INFO] - Training Epoch: 1/2, step 4601/7134 completed (loss: 3.919015407562256, acc: 0.31073445081710815)
[2024-12-17 02:11:56,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:56,951][root][INFO] - Training Epoch: 1/2, step 4602/7134 completed (loss: 4.290318965911865, acc: 0.22777777910232544)
[2024-12-17 02:11:57,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,327][root][INFO] - Training Epoch: 1/2, step 4603/7134 completed (loss: 3.9618427753448486, acc: 0.3139534890651703)
[2024-12-17 02:11:57,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:57,724][root][INFO] - Training Epoch: 1/2, step 4604/7134 completed (loss: 4.092218399047852, acc: 0.28671327233314514)
[2024-12-17 02:11:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,108][root][INFO] - Training Epoch: 1/2, step 4605/7134 completed (loss: 4.344522476196289, acc: 0.2818181812763214)
[2024-12-17 02:11:58,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,492][root][INFO] - Training Epoch: 1/2, step 4606/7134 completed (loss: 4.069302558898926, acc: 0.2830188572406769)
[2024-12-17 02:11:58,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:58,892][root][INFO] - Training Epoch: 1/2, step 4607/7134 completed (loss: 4.047122478485107, acc: 0.26950353384017944)
[2024-12-17 02:11:59,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,246][root][INFO] - Training Epoch: 1/2, step 4608/7134 completed (loss: 3.4789276123046875, acc: 0.3274853825569153)
[2024-12-17 02:11:59,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,610][root][INFO] - Training Epoch: 1/2, step 4609/7134 completed (loss: 4.239766597747803, acc: 0.19847328960895538)
[2024-12-17 02:11:59,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:11:59,962][root][INFO] - Training Epoch: 1/2, step 4610/7134 completed (loss: 3.6219635009765625, acc: 0.3519552946090698)
[2024-12-17 02:12:00,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,302][root][INFO] - Training Epoch: 1/2, step 4611/7134 completed (loss: 4.021652698516846, acc: 0.2620689570903778)
[2024-12-17 02:12:00,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:00,648][root][INFO] - Training Epoch: 1/2, step 4612/7134 completed (loss: 4.092234134674072, acc: 0.2888889014720917)
[2024-12-17 02:12:00,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,052][root][INFO] - Training Epoch: 1/2, step 4613/7134 completed (loss: 3.3005850315093994, acc: 0.3395061790943146)
[2024-12-17 02:12:01,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,534][root][INFO] - Training Epoch: 1/2, step 4614/7134 completed (loss: 4.2086005210876465, acc: 0.23076923191547394)
[2024-12-17 02:12:01,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:01,929][root][INFO] - Training Epoch: 1/2, step 4615/7134 completed (loss: 4.212074279785156, acc: 0.2934131622314453)
[2024-12-17 02:12:02,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,317][root][INFO] - Training Epoch: 1/2, step 4616/7134 completed (loss: 4.347228527069092, acc: 0.2848837077617645)
[2024-12-17 02:12:02,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:02,692][root][INFO] - Training Epoch: 1/2, step 4617/7134 completed (loss: 4.531035900115967, acc: 0.2634730637073517)
[2024-12-17 02:12:02,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,106][root][INFO] - Training Epoch: 1/2, step 4618/7134 completed (loss: 4.5502095222473145, acc: 0.24031007289886475)
[2024-12-17 02:12:03,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,483][root][INFO] - Training Epoch: 1/2, step 4619/7134 completed (loss: 4.313971042633057, acc: 0.30000001192092896)
[2024-12-17 02:12:03,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:03,895][root][INFO] - Training Epoch: 1/2, step 4620/7134 completed (loss: 3.7602739334106445, acc: 0.3117647171020508)
[2024-12-17 02:12:04,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,284][root][INFO] - Training Epoch: 1/2, step 4621/7134 completed (loss: 3.833771228790283, acc: 0.3353658616542816)
[2024-12-17 02:12:04,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:04,670][root][INFO] - Training Epoch: 1/2, step 4622/7134 completed (loss: 4.262596607208252, acc: 0.27222222089767456)
[2024-12-17 02:12:04,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,033][root][INFO] - Training Epoch: 1/2, step 4623/7134 completed (loss: 4.3912153244018555, acc: 0.2823529541492462)
[2024-12-17 02:12:05,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,430][root][INFO] - Training Epoch: 1/2, step 4624/7134 completed (loss: 4.24303674697876, acc: 0.3176470696926117)
[2024-12-17 02:12:05,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:05,814][root][INFO] - Training Epoch: 1/2, step 4625/7134 completed (loss: 4.7114386558532715, acc: 0.24539877474308014)
[2024-12-17 02:12:05,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,195][root][INFO] - Training Epoch: 1/2, step 4626/7134 completed (loss: 4.338546276092529, acc: 0.2554347813129425)
[2024-12-17 02:12:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,589][root][INFO] - Training Epoch: 1/2, step 4627/7134 completed (loss: 4.416168212890625, acc: 0.22580644488334656)
[2024-12-17 02:12:06,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:06,958][root][INFO] - Training Epoch: 1/2, step 4628/7134 completed (loss: 4.327362060546875, acc: 0.28658536076545715)
[2024-12-17 02:12:07,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,309][root][INFO] - Training Epoch: 1/2, step 4629/7134 completed (loss: 3.9837653636932373, acc: 0.2792207896709442)
[2024-12-17 02:12:07,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:07,698][root][INFO] - Training Epoch: 1/2, step 4630/7134 completed (loss: 3.5834832191467285, acc: 0.33888888359069824)
[2024-12-17 02:12:07,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,071][root][INFO] - Training Epoch: 1/2, step 4631/7134 completed (loss: 3.887371301651001, acc: 0.2697674334049225)
[2024-12-17 02:12:08,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,469][root][INFO] - Training Epoch: 1/2, step 4632/7134 completed (loss: 3.678189992904663, acc: 0.3132530152797699)
[2024-12-17 02:12:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:08,842][root][INFO] - Training Epoch: 1/2, step 4633/7134 completed (loss: 4.142265796661377, acc: 0.3059360682964325)
[2024-12-17 02:12:08,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,238][root][INFO] - Training Epoch: 1/2, step 4634/7134 completed (loss: 3.6899914741516113, acc: 0.32592591643333435)
[2024-12-17 02:12:09,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,614][root][INFO] - Training Epoch: 1/2, step 4635/7134 completed (loss: 3.8030011653900146, acc: 0.28658536076545715)
[2024-12-17 02:12:09,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:09,941][root][INFO] - Training Epoch: 1/2, step 4636/7134 completed (loss: 3.762432098388672, acc: 0.24468085169792175)
[2024-12-17 02:12:10,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,320][root][INFO] - Training Epoch: 1/2, step 4637/7134 completed (loss: 3.6486711502075195, acc: 0.3095238208770752)
[2024-12-17 02:12:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:10,695][root][INFO] - Training Epoch: 1/2, step 4638/7134 completed (loss: 3.9928455352783203, acc: 0.32947975397109985)
[2024-12-17 02:12:10,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,050][root][INFO] - Training Epoch: 1/2, step 4639/7134 completed (loss: 3.7396912574768066, acc: 0.3027026951313019)
[2024-12-17 02:12:11,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,442][root][INFO] - Training Epoch: 1/2, step 4640/7134 completed (loss: 3.9458179473876953, acc: 0.29629629850387573)
[2024-12-17 02:12:11,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:11,807][root][INFO] - Training Epoch: 1/2, step 4641/7134 completed (loss: 4.542949199676514, acc: 0.2430555522441864)
[2024-12-17 02:12:11,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,175][root][INFO] - Training Epoch: 1/2, step 4642/7134 completed (loss: 3.696998357772827, acc: 0.3050847351551056)
[2024-12-17 02:12:12,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,569][root][INFO] - Training Epoch: 1/2, step 4643/7134 completed (loss: 3.9188036918640137, acc: 0.28780487179756165)
[2024-12-17 02:12:12,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:12,951][root][INFO] - Training Epoch: 1/2, step 4644/7134 completed (loss: 3.5780537128448486, acc: 0.33497536182403564)
[2024-12-17 02:12:13,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,323][root][INFO] - Training Epoch: 1/2, step 4645/7134 completed (loss: 3.7397964000701904, acc: 0.29878050088882446)
[2024-12-17 02:12:13,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:13,709][root][INFO] - Training Epoch: 1/2, step 4646/7134 completed (loss: 3.8988025188446045, acc: 0.26428571343421936)
[2024-12-17 02:12:13,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,100][root][INFO] - Training Epoch: 1/2, step 4647/7134 completed (loss: 3.8605144023895264, acc: 0.2950819730758667)
[2024-12-17 02:12:14,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,460][root][INFO] - Training Epoch: 1/2, step 4648/7134 completed (loss: 3.707671642303467, acc: 0.2866241931915283)
[2024-12-17 02:12:14,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:14,828][root][INFO] - Training Epoch: 1/2, step 4649/7134 completed (loss: 3.8616256713867188, acc: 0.3333333432674408)
[2024-12-17 02:12:14,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,212][root][INFO] - Training Epoch: 1/2, step 4650/7134 completed (loss: 3.9296581745147705, acc: 0.29729729890823364)
[2024-12-17 02:12:15,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,579][root][INFO] - Training Epoch: 1/2, step 4651/7134 completed (loss: 4.0062031745910645, acc: 0.2793295979499817)
[2024-12-17 02:12:15,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:15,952][root][INFO] - Training Epoch: 1/2, step 4652/7134 completed (loss: 3.801664113998413, acc: 0.29012346267700195)
[2024-12-17 02:12:16,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,321][root][INFO] - Training Epoch: 1/2, step 4653/7134 completed (loss: 3.649512767791748, acc: 0.38164252042770386)
[2024-12-17 02:12:16,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:16,693][root][INFO] - Training Epoch: 1/2, step 4654/7134 completed (loss: 4.298439025878906, acc: 0.2594594657421112)
[2024-12-17 02:12:16,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,073][root][INFO] - Training Epoch: 1/2, step 4655/7134 completed (loss: 3.705040216445923, acc: 0.34857141971588135)
[2024-12-17 02:12:17,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,460][root][INFO] - Training Epoch: 1/2, step 4656/7134 completed (loss: 4.459271430969238, acc: 0.26271185278892517)
[2024-12-17 02:12:17,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:17,819][root][INFO] - Training Epoch: 1/2, step 4657/7134 completed (loss: 4.161287307739258, acc: 0.3045977056026459)
[2024-12-17 02:12:17,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,218][root][INFO] - Training Epoch: 1/2, step 4658/7134 completed (loss: 3.9789748191833496, acc: 0.3579545319080353)
[2024-12-17 02:12:18,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,603][root][INFO] - Training Epoch: 1/2, step 4659/7134 completed (loss: 4.083080291748047, acc: 0.29629629850387573)
[2024-12-17 02:12:18,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:18,983][root][INFO] - Training Epoch: 1/2, step 4660/7134 completed (loss: 4.5533766746521, acc: 0.26923078298568726)
[2024-12-17 02:12:19,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,348][root][INFO] - Training Epoch: 1/2, step 4661/7134 completed (loss: 4.703370094299316, acc: 0.20245398581027985)
[2024-12-17 02:12:19,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:19,703][root][INFO] - Training Epoch: 1/2, step 4662/7134 completed (loss: 4.505275249481201, acc: 0.29078012704849243)
[2024-12-17 02:12:19,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,070][root][INFO] - Training Epoch: 1/2, step 4663/7134 completed (loss: 3.9992129802703857, acc: 0.3333333432674408)
[2024-12-17 02:12:20,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,455][root][INFO] - Training Epoch: 1/2, step 4664/7134 completed (loss: 4.303095817565918, acc: 0.20000000298023224)
[2024-12-17 02:12:20,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:20,817][root][INFO] - Training Epoch: 1/2, step 4665/7134 completed (loss: 3.9573051929473877, acc: 0.2637362778186798)
[2024-12-17 02:12:20,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,193][root][INFO] - Training Epoch: 1/2, step 4666/7134 completed (loss: 4.257390022277832, acc: 0.2590673565864563)
[2024-12-17 02:12:21,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,564][root][INFO] - Training Epoch: 1/2, step 4667/7134 completed (loss: 4.3071393966674805, acc: 0.23648647964000702)
[2024-12-17 02:12:21,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:21,921][root][INFO] - Training Epoch: 1/2, step 4668/7134 completed (loss: 3.9284605979919434, acc: 0.2751677930355072)
[2024-12-17 02:12:22,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,319][root][INFO] - Training Epoch: 1/2, step 4669/7134 completed (loss: 4.176246166229248, acc: 0.2711864411830902)
[2024-12-17 02:12:22,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:22,695][root][INFO] - Training Epoch: 1/2, step 4670/7134 completed (loss: 4.198014259338379, acc: 0.26119402050971985)
[2024-12-17 02:12:22,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,080][root][INFO] - Training Epoch: 1/2, step 4671/7134 completed (loss: 3.7376983165740967, acc: 0.35519126057624817)
[2024-12-17 02:12:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,436][root][INFO] - Training Epoch: 1/2, step 4672/7134 completed (loss: 4.042806625366211, acc: 0.30344828963279724)
[2024-12-17 02:12:23,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:23,852][root][INFO] - Training Epoch: 1/2, step 4673/7134 completed (loss: 4.050323009490967, acc: 0.30817610025405884)
[2024-12-17 02:12:23,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,236][root][INFO] - Training Epoch: 1/2, step 4674/7134 completed (loss: 3.7068228721618652, acc: 0.2792207896709442)
[2024-12-17 02:12:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:24,651][root][INFO] - Training Epoch: 1/2, step 4675/7134 completed (loss: 3.713322877883911, acc: 0.28717949986457825)
[2024-12-17 02:12:24,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,017][root][INFO] - Training Epoch: 1/2, step 4676/7134 completed (loss: 4.1818742752075195, acc: 0.22727273404598236)
[2024-12-17 02:12:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,408][root][INFO] - Training Epoch: 1/2, step 4677/7134 completed (loss: 3.4869329929351807, acc: 0.32773110270500183)
[2024-12-17 02:12:25,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:25,795][root][INFO] - Training Epoch: 1/2, step 4678/7134 completed (loss: 3.727031707763672, acc: 0.28143712878227234)
[2024-12-17 02:12:25,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,184][root][INFO] - Training Epoch: 1/2, step 4679/7134 completed (loss: 4.235878944396973, acc: 0.2774566411972046)
[2024-12-17 02:12:26,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,540][root][INFO] - Training Epoch: 1/2, step 4680/7134 completed (loss: 4.242621898651123, acc: 0.26363635063171387)
[2024-12-17 02:12:26,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:26,921][root][INFO] - Training Epoch: 1/2, step 4681/7134 completed (loss: 4.043491840362549, acc: 0.2467532455921173)
[2024-12-17 02:12:27,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,306][root][INFO] - Training Epoch: 1/2, step 4682/7134 completed (loss: 3.9260292053222656, acc: 0.32044199109077454)
[2024-12-17 02:12:27,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:27,668][root][INFO] - Training Epoch: 1/2, step 4683/7134 completed (loss: 4.155483245849609, acc: 0.2800000011920929)
[2024-12-17 02:12:27,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,040][root][INFO] - Training Epoch: 1/2, step 4684/7134 completed (loss: 4.0181965827941895, acc: 0.27319586277008057)
[2024-12-17 02:12:28,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,464][root][INFO] - Training Epoch: 1/2, step 4685/7134 completed (loss: 3.795740842819214, acc: 0.3054187297821045)
[2024-12-17 02:12:28,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:28,850][root][INFO] - Training Epoch: 1/2, step 4686/7134 completed (loss: 3.8518683910369873, acc: 0.27513226866722107)
[2024-12-17 02:12:28,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,219][root][INFO] - Training Epoch: 1/2, step 4687/7134 completed (loss: 4.806244850158691, acc: 0.20652173459529877)
[2024-12-17 02:12:29,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,582][root][INFO] - Training Epoch: 1/2, step 4688/7134 completed (loss: 4.415881156921387, acc: 0.2578125)
[2024-12-17 02:12:29,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:29,961][root][INFO] - Training Epoch: 1/2, step 4689/7134 completed (loss: 3.924215793609619, acc: 0.24137930572032928)
[2024-12-17 02:12:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,334][root][INFO] - Training Epoch: 1/2, step 4690/7134 completed (loss: 4.1837158203125, acc: 0.28947368264198303)
[2024-12-17 02:12:30,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:30,710][root][INFO] - Training Epoch: 1/2, step 4691/7134 completed (loss: 4.037169933319092, acc: 0.23076923191547394)
[2024-12-17 02:12:30,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,082][root][INFO] - Training Epoch: 1/2, step 4692/7134 completed (loss: 4.153504371643066, acc: 0.2857142984867096)
[2024-12-17 02:12:31,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,453][root][INFO] - Training Epoch: 1/2, step 4693/7134 completed (loss: 4.414326190948486, acc: 0.2685714364051819)
[2024-12-17 02:12:31,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:31,822][root][INFO] - Training Epoch: 1/2, step 4694/7134 completed (loss: 4.333252906799316, acc: 0.261904776096344)
[2024-12-17 02:12:31,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,205][root][INFO] - Training Epoch: 1/2, step 4695/7134 completed (loss: 4.329553604125977, acc: 0.2666666805744171)
[2024-12-17 02:12:32,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,573][root][INFO] - Training Epoch: 1/2, step 4696/7134 completed (loss: 3.470306634902954, acc: 0.3636363744735718)
[2024-12-17 02:12:32,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:32,932][root][INFO] - Training Epoch: 1/2, step 4697/7134 completed (loss: 3.894505262374878, acc: 0.3253968358039856)
[2024-12-17 02:12:33,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,259][root][INFO] - Training Epoch: 1/2, step 4698/7134 completed (loss: 4.345489501953125, acc: 0.2142857164144516)
[2024-12-17 02:12:33,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:33,645][root][INFO] - Training Epoch: 1/2, step 4699/7134 completed (loss: 4.3151164054870605, acc: 0.30215826630592346)
[2024-12-17 02:12:33,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,024][root][INFO] - Training Epoch: 1/2, step 4700/7134 completed (loss: 3.786048650741577, acc: 0.2840236723423004)
[2024-12-17 02:12:34,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,433][root][INFO] - Training Epoch: 1/2, step 4701/7134 completed (loss: 4.395539283752441, acc: 0.2750000059604645)
[2024-12-17 02:12:34,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:34,901][root][INFO] - Training Epoch: 1/2, step 4702/7134 completed (loss: 4.16141939163208, acc: 0.29032257199287415)
[2024-12-17 02:12:35,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,272][root][INFO] - Training Epoch: 1/2, step 4703/7134 completed (loss: 3.5921268463134766, acc: 0.3588235378265381)
[2024-12-17 02:12:35,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:35,621][root][INFO] - Training Epoch: 1/2, step 4704/7134 completed (loss: 3.5237958431243896, acc: 0.2974359095096588)
[2024-12-17 02:12:35,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,006][root][INFO] - Training Epoch: 1/2, step 4705/7134 completed (loss: 3.92242693901062, acc: 0.29556649923324585)
[2024-12-17 02:12:36,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,364][root][INFO] - Training Epoch: 1/2, step 4706/7134 completed (loss: 4.012175559997559, acc: 0.31410256028175354)
[2024-12-17 02:12:36,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:36,697][root][INFO] - Training Epoch: 1/2, step 4707/7134 completed (loss: 4.199676513671875, acc: 0.23270440101623535)
[2024-12-17 02:12:36,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,053][root][INFO] - Training Epoch: 1/2, step 4708/7134 completed (loss: 3.6452183723449707, acc: 0.31658291816711426)
[2024-12-17 02:12:37,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,431][root][INFO] - Training Epoch: 1/2, step 4709/7134 completed (loss: 3.7231009006500244, acc: 0.3081081211566925)
[2024-12-17 02:12:37,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:37,791][root][INFO] - Training Epoch: 1/2, step 4710/7134 completed (loss: 3.6243183612823486, acc: 0.30909091234207153)
[2024-12-17 02:12:37,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,179][root][INFO] - Training Epoch: 1/2, step 4711/7134 completed (loss: 3.349306106567383, acc: 0.29054054617881775)
[2024-12-17 02:12:38,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,570][root][INFO] - Training Epoch: 1/2, step 4712/7134 completed (loss: 3.89070725440979, acc: 0.24183006584644318)
[2024-12-17 02:12:38,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:38,926][root][INFO] - Training Epoch: 1/2, step 4713/7134 completed (loss: 3.7998807430267334, acc: 0.2985074520111084)
[2024-12-17 02:12:39,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,274][root][INFO] - Training Epoch: 1/2, step 4714/7134 completed (loss: 3.7846901416778564, acc: 0.2977099120616913)
[2024-12-17 02:12:39,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:39,720][root][INFO] - Training Epoch: 1/2, step 4715/7134 completed (loss: 3.93384051322937, acc: 0.3083333373069763)
[2024-12-17 02:12:39,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,126][root][INFO] - Training Epoch: 1/2, step 4716/7134 completed (loss: 4.227297306060791, acc: 0.2709677517414093)
[2024-12-17 02:12:40,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,498][root][INFO] - Training Epoch: 1/2, step 4717/7134 completed (loss: 4.1432600021362305, acc: 0.25999999046325684)
[2024-12-17 02:12:40,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:40,880][root][INFO] - Training Epoch: 1/2, step 4718/7134 completed (loss: 3.779900550842285, acc: 0.2949640154838562)
[2024-12-17 02:12:40,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,251][root][INFO] - Training Epoch: 1/2, step 4719/7134 completed (loss: 3.436671495437622, acc: 0.34319525957107544)
[2024-12-17 02:12:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,597][root][INFO] - Training Epoch: 1/2, step 4720/7134 completed (loss: 3.611300230026245, acc: 0.3375000059604645)
[2024-12-17 02:12:41,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:41,950][root][INFO] - Training Epoch: 1/2, step 4721/7134 completed (loss: 3.5032854080200195, acc: 0.31481480598449707)
[2024-12-17 02:12:42,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,313][root][INFO] - Training Epoch: 1/2, step 4722/7134 completed (loss: 3.9420053958892822, acc: 0.2830188572406769)
[2024-12-17 02:12:42,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:42,673][root][INFO] - Training Epoch: 1/2, step 4723/7134 completed (loss: 3.953848123550415, acc: 0.2866241931915283)
[2024-12-17 02:12:42,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,048][root][INFO] - Training Epoch: 1/2, step 4724/7134 completed (loss: 3.919208526611328, acc: 0.2804878056049347)
[2024-12-17 02:12:43,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,412][root][INFO] - Training Epoch: 1/2, step 4725/7134 completed (loss: 4.476790904998779, acc: 0.22674418985843658)
[2024-12-17 02:12:43,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:43,799][root][INFO] - Training Epoch: 1/2, step 4726/7134 completed (loss: 4.314589500427246, acc: 0.2586206793785095)
[2024-12-17 02:12:43,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,177][root][INFO] - Training Epoch: 1/2, step 4727/7134 completed (loss: 4.63913106918335, acc: 0.23178808391094208)
[2024-12-17 02:12:44,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,555][root][INFO] - Training Epoch: 1/2, step 4728/7134 completed (loss: 4.420857906341553, acc: 0.20529800653457642)
[2024-12-17 02:12:44,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:44,911][root][INFO] - Training Epoch: 1/2, step 4729/7134 completed (loss: 3.940023899078369, acc: 0.27167630195617676)
[2024-12-17 02:12:45,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,275][root][INFO] - Training Epoch: 1/2, step 4730/7134 completed (loss: 4.4335103034973145, acc: 0.22807016968727112)
[2024-12-17 02:12:45,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:45,668][root][INFO] - Training Epoch: 1/2, step 4731/7134 completed (loss: 4.800549507141113, acc: 0.19310344755649567)
[2024-12-17 02:12:45,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,066][root][INFO] - Training Epoch: 1/2, step 4732/7134 completed (loss: 4.663368225097656, acc: 0.1985294073820114)
[2024-12-17 02:12:46,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,438][root][INFO] - Training Epoch: 1/2, step 4733/7134 completed (loss: 4.4123382568359375, acc: 0.18115942180156708)
[2024-12-17 02:12:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:46,810][root][INFO] - Training Epoch: 1/2, step 4734/7134 completed (loss: 4.169441223144531, acc: 0.276729553937912)
[2024-12-17 02:12:46,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,205][root][INFO] - Training Epoch: 1/2, step 4735/7134 completed (loss: 4.17125940322876, acc: 0.2830188572406769)
[2024-12-17 02:12:47,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,591][root][INFO] - Training Epoch: 1/2, step 4736/7134 completed (loss: 4.6960039138793945, acc: 0.20000000298023224)
[2024-12-17 02:12:47,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:47,980][root][INFO] - Training Epoch: 1/2, step 4737/7134 completed (loss: 4.151375770568848, acc: 0.32413792610168457)
[2024-12-17 02:12:48,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,333][root][INFO] - Training Epoch: 1/2, step 4738/7134 completed (loss: 4.522651672363281, acc: 0.2562499940395355)
[2024-12-17 02:12:48,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:48,738][root][INFO] - Training Epoch: 1/2, step 4739/7134 completed (loss: 4.7364983558654785, acc: 0.21348313987255096)
[2024-12-17 02:12:48,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,119][root][INFO] - Training Epoch: 1/2, step 4740/7134 completed (loss: 4.391036510467529, acc: 0.22777777910232544)
[2024-12-17 02:12:49,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,466][root][INFO] - Training Epoch: 1/2, step 4741/7134 completed (loss: 4.819675922393799, acc: 0.2571428716182709)
[2024-12-17 02:12:49,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:49,828][root][INFO] - Training Epoch: 1/2, step 4742/7134 completed (loss: 4.32589864730835, acc: 0.24848484992980957)
[2024-12-17 02:12:49,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,189][root][INFO] - Training Epoch: 1/2, step 4743/7134 completed (loss: 3.499464750289917, acc: 0.42763158679008484)
[2024-12-17 02:12:50,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,578][root][INFO] - Training Epoch: 1/2, step 4744/7134 completed (loss: 4.136120796203613, acc: 0.29357796907424927)
[2024-12-17 02:12:50,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:50,951][root][INFO] - Training Epoch: 1/2, step 4745/7134 completed (loss: 4.184698104858398, acc: 0.2222222238779068)
[2024-12-17 02:12:51,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,348][root][INFO] - Training Epoch: 1/2, step 4746/7134 completed (loss: 3.5773980617523193, acc: 0.3488371968269348)
[2024-12-17 02:12:51,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:51,757][root][INFO] - Training Epoch: 1/2, step 4747/7134 completed (loss: 3.454364061355591, acc: 0.3604651093482971)
[2024-12-17 02:12:51,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,172][root][INFO] - Training Epoch: 1/2, step 4748/7134 completed (loss: 4.125460624694824, acc: 0.27218934893608093)
[2024-12-17 02:12:52,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,563][root][INFO] - Training Epoch: 1/2, step 4749/7134 completed (loss: 3.372654438018799, acc: 0.3139534890651703)
[2024-12-17 02:12:52,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:52,931][root][INFO] - Training Epoch: 1/2, step 4750/7134 completed (loss: 3.690833806991577, acc: 0.28455284237861633)
[2024-12-17 02:12:53,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,307][root][INFO] - Training Epoch: 1/2, step 4751/7134 completed (loss: 3.512784004211426, acc: 0.3658536672592163)
[2024-12-17 02:12:53,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:53,690][root][INFO] - Training Epoch: 1/2, step 4752/7134 completed (loss: 3.9141619205474854, acc: 0.30434781312942505)
[2024-12-17 02:12:53,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,068][root][INFO] - Training Epoch: 1/2, step 4753/7134 completed (loss: 4.1208014488220215, acc: 0.27218934893608093)
[2024-12-17 02:12:54,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,441][root][INFO] - Training Epoch: 1/2, step 4754/7134 completed (loss: 3.8267385959625244, acc: 0.2532467544078827)
[2024-12-17 02:12:54,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:54,801][root][INFO] - Training Epoch: 1/2, step 4755/7134 completed (loss: 3.77823543548584, acc: 0.3131868243217468)
[2024-12-17 02:12:54,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,160][root][INFO] - Training Epoch: 1/2, step 4756/7134 completed (loss: 3.9902303218841553, acc: 0.25)
[2024-12-17 02:12:55,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,561][root][INFO] - Training Epoch: 1/2, step 4757/7134 completed (loss: 3.6441376209259033, acc: 0.3199999928474426)
[2024-12-17 02:12:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:55,927][root][INFO] - Training Epoch: 1/2, step 4758/7134 completed (loss: 3.5428130626678467, acc: 0.3093922734260559)
[2024-12-17 02:12:56,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,301][root][INFO] - Training Epoch: 1/2, step 4759/7134 completed (loss: 3.340141534805298, acc: 0.3546099364757538)
[2024-12-17 02:12:56,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:56,657][root][INFO] - Training Epoch: 1/2, step 4760/7134 completed (loss: 3.81466007232666, acc: 0.29411765933036804)
[2024-12-17 02:12:56,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,005][root][INFO] - Training Epoch: 1/2, step 4761/7134 completed (loss: 3.2196643352508545, acc: 0.47560974955558777)
[2024-12-17 02:12:57,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,373][root][INFO] - Training Epoch: 1/2, step 4762/7134 completed (loss: 3.398205041885376, acc: 0.38461539149284363)
[2024-12-17 02:12:57,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:57,735][root][INFO] - Training Epoch: 1/2, step 4763/7134 completed (loss: 3.902006149291992, acc: 0.2781457006931305)
[2024-12-17 02:12:57,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,112][root][INFO] - Training Epoch: 1/2, step 4764/7134 completed (loss: 3.661283493041992, acc: 0.3298968970775604)
[2024-12-17 02:12:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,475][root][INFO] - Training Epoch: 1/2, step 4765/7134 completed (loss: 3.677924394607544, acc: 0.3466666638851166)
[2024-12-17 02:12:58,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:58,847][root][INFO] - Training Epoch: 1/2, step 4766/7134 completed (loss: 3.9605915546417236, acc: 0.2777777910232544)
[2024-12-17 02:12:58,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,232][root][INFO] - Training Epoch: 1/2, step 4767/7134 completed (loss: 3.444906711578369, acc: 0.37755101919174194)
[2024-12-17 02:12:59,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,616][root][INFO] - Training Epoch: 1/2, step 4768/7134 completed (loss: 3.734102487564087, acc: 0.34705883264541626)
[2024-12-17 02:12:59,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:12:59,962][root][INFO] - Training Epoch: 1/2, step 4769/7134 completed (loss: 3.700068473815918, acc: 0.31578946113586426)
[2024-12-17 02:13:00,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,322][root][INFO] - Training Epoch: 1/2, step 4770/7134 completed (loss: 3.3416361808776855, acc: 0.41600000858306885)
[2024-12-17 02:13:00,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:00,701][root][INFO] - Training Epoch: 1/2, step 4771/7134 completed (loss: 3.4059815406799316, acc: 0.3558282256126404)
[2024-12-17 02:13:00,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,093][root][INFO] - Training Epoch: 1/2, step 4772/7134 completed (loss: 3.553679943084717, acc: 0.34193548560142517)
[2024-12-17 02:13:01,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,444][root][INFO] - Training Epoch: 1/2, step 4773/7134 completed (loss: 4.110022068023682, acc: 0.2628205120563507)
[2024-12-17 02:13:01,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:01,798][root][INFO] - Training Epoch: 1/2, step 4774/7134 completed (loss: 3.8329999446868896, acc: 0.3372780978679657)
[2024-12-17 02:13:01,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,173][root][INFO] - Training Epoch: 1/2, step 4775/7134 completed (loss: 3.355609178543091, acc: 0.36477985978126526)
[2024-12-17 02:13:02,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,544][root][INFO] - Training Epoch: 1/2, step 4776/7134 completed (loss: 4.662219047546387, acc: 0.2887323796749115)
[2024-12-17 02:13:02,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:02,915][root][INFO] - Training Epoch: 1/2, step 4777/7134 completed (loss: 4.238903522491455, acc: 0.21232876181602478)
[2024-12-17 02:13:03,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,283][root][INFO] - Training Epoch: 1/2, step 4778/7134 completed (loss: 3.5946755409240723, acc: 0.2946428656578064)
[2024-12-17 02:13:03,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:03,662][root][INFO] - Training Epoch: 1/2, step 4779/7134 completed (loss: 3.2861413955688477, acc: 0.3333333432674408)
[2024-12-17 02:13:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,049][root][INFO] - Training Epoch: 1/2, step 4780/7134 completed (loss: 3.4022669792175293, acc: 0.3333333432674408)
[2024-12-17 02:13:04,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,437][root][INFO] - Training Epoch: 1/2, step 4781/7134 completed (loss: 4.010049343109131, acc: 0.25806450843811035)
[2024-12-17 02:13:04,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:04,797][root][INFO] - Training Epoch: 1/2, step 4782/7134 completed (loss: 3.7701046466827393, acc: 0.30000001192092896)
[2024-12-17 02:13:04,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,193][root][INFO] - Training Epoch: 1/2, step 4783/7134 completed (loss: 4.258663654327393, acc: 0.3115941882133484)
[2024-12-17 02:13:05,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,585][root][INFO] - Training Epoch: 1/2, step 4784/7134 completed (loss: 3.538093090057373, acc: 0.2944444417953491)
[2024-12-17 02:13:05,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:05,968][root][INFO] - Training Epoch: 1/2, step 4785/7134 completed (loss: 3.586883783340454, acc: 0.29104477167129517)
[2024-12-17 02:13:06,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,371][root][INFO] - Training Epoch: 1/2, step 4786/7134 completed (loss: 3.5486016273498535, acc: 0.37654322385787964)
[2024-12-17 02:13:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:06,757][root][INFO] - Training Epoch: 1/2, step 4787/7134 completed (loss: 3.1589646339416504, acc: 0.3836477994918823)
[2024-12-17 02:13:06,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,146][root][INFO] - Training Epoch: 1/2, step 4788/7134 completed (loss: 3.5855581760406494, acc: 0.3692307770252228)
[2024-12-17 02:13:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,527][root][INFO] - Training Epoch: 1/2, step 4789/7134 completed (loss: 3.65702223777771, acc: 0.3589743673801422)
[2024-12-17 02:13:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:07,898][root][INFO] - Training Epoch: 1/2, step 4790/7134 completed (loss: 3.4293580055236816, acc: 0.3089887499809265)
[2024-12-17 02:13:08,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,256][root][INFO] - Training Epoch: 1/2, step 4791/7134 completed (loss: 3.616682767868042, acc: 0.24626865983009338)
[2024-12-17 02:13:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,618][root][INFO] - Training Epoch: 1/2, step 4792/7134 completed (loss: 3.516209840774536, acc: 0.3310810923576355)
[2024-12-17 02:13:08,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:08,976][root][INFO] - Training Epoch: 1/2, step 4793/7134 completed (loss: 4.304598808288574, acc: 0.3052631616592407)
[2024-12-17 02:13:09,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,319][root][INFO] - Training Epoch: 1/2, step 4794/7134 completed (loss: 4.078693866729736, acc: 0.3333333432674408)
[2024-12-17 02:13:09,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:09,699][root][INFO] - Training Epoch: 1/2, step 4795/7134 completed (loss: 3.914430618286133, acc: 0.2638036906719208)
[2024-12-17 02:13:09,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,042][root][INFO] - Training Epoch: 1/2, step 4796/7134 completed (loss: 3.8591468334198, acc: 0.28947368264198303)
[2024-12-17 02:13:10,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,398][root][INFO] - Training Epoch: 1/2, step 4797/7134 completed (loss: 3.817326545715332, acc: 0.28961747884750366)
[2024-12-17 02:13:10,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:10,787][root][INFO] - Training Epoch: 1/2, step 4798/7134 completed (loss: 4.069015979766846, acc: 0.28143712878227234)
[2024-12-17 02:13:10,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,159][root][INFO] - Training Epoch: 1/2, step 4799/7134 completed (loss: 3.7093076705932617, acc: 0.3295454680919647)
[2024-12-17 02:13:11,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,521][root][INFO] - Training Epoch: 1/2, step 4800/7134 completed (loss: 3.1775288581848145, acc: 0.42105263471603394)
[2024-12-17 02:13:11,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:11,906][root][INFO] - Training Epoch: 1/2, step 4801/7134 completed (loss: 3.2913601398468018, acc: 0.3877550959587097)
[2024-12-17 02:13:12,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,291][root][INFO] - Training Epoch: 1/2, step 4802/7134 completed (loss: 3.589492082595825, acc: 0.3505154550075531)
[2024-12-17 02:13:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:12,644][root][INFO] - Training Epoch: 1/2, step 4803/7134 completed (loss: 3.9858391284942627, acc: 0.3030303120613098)
[2024-12-17 02:13:12,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,009][root][INFO] - Training Epoch: 1/2, step 4804/7134 completed (loss: 3.7504003047943115, acc: 0.3253012001514435)
[2024-12-17 02:13:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,353][root][INFO] - Training Epoch: 1/2, step 4805/7134 completed (loss: 2.9894516468048096, acc: 0.3642384111881256)
[2024-12-17 02:13:13,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:13,724][root][INFO] - Training Epoch: 1/2, step 4806/7134 completed (loss: 3.5435752868652344, acc: 0.279720276594162)
[2024-12-17 02:13:13,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,067][root][INFO] - Training Epoch: 1/2, step 4807/7134 completed (loss: 3.975731134414673, acc: 0.3037974536418915)
[2024-12-17 02:13:14,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,439][root][INFO] - Training Epoch: 1/2, step 4808/7134 completed (loss: 3.3117642402648926, acc: 0.34090909361839294)
[2024-12-17 02:13:14,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:14,807][root][INFO] - Training Epoch: 1/2, step 4809/7134 completed (loss: 3.5000522136688232, acc: 0.3448275923728943)
[2024-12-17 02:13:14,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,211][root][INFO] - Training Epoch: 1/2, step 4810/7134 completed (loss: 3.3219988346099854, acc: 0.34117648005485535)
[2024-12-17 02:13:15,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:15,633][root][INFO] - Training Epoch: 1/2, step 4811/7134 completed (loss: 3.2984588146209717, acc: 0.4098360538482666)
[2024-12-17 02:13:15,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,022][root][INFO] - Training Epoch: 1/2, step 4812/7134 completed (loss: 3.4291298389434814, acc: 0.29378530383110046)
[2024-12-17 02:13:16,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,373][root][INFO] - Training Epoch: 1/2, step 4813/7134 completed (loss: 3.4815762042999268, acc: 0.3229166567325592)
[2024-12-17 02:13:16,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:16,729][root][INFO] - Training Epoch: 1/2, step 4814/7134 completed (loss: 3.21272873878479, acc: 0.3478260934352875)
[2024-12-17 02:13:16,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,106][root][INFO] - Training Epoch: 1/2, step 4815/7134 completed (loss: 3.191432237625122, acc: 0.3417721390724182)
[2024-12-17 02:13:17,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,447][root][INFO] - Training Epoch: 1/2, step 4816/7134 completed (loss: 3.0117549896240234, acc: 0.41206029057502747)
[2024-12-17 02:13:17,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:17,791][root][INFO] - Training Epoch: 1/2, step 4817/7134 completed (loss: 3.6446499824523926, acc: 0.39393940567970276)
[2024-12-17 02:13:17,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,164][root][INFO] - Training Epoch: 1/2, step 4818/7134 completed (loss: 3.478543281555176, acc: 0.3333333432674408)
[2024-12-17 02:13:18,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,521][root][INFO] - Training Epoch: 1/2, step 4819/7134 completed (loss: 3.4911465644836426, acc: 0.3166666626930237)
[2024-12-17 02:13:18,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:18,882][root][INFO] - Training Epoch: 1/2, step 4820/7134 completed (loss: 3.3152287006378174, acc: 0.34224599599838257)
[2024-12-17 02:13:19,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,284][root][INFO] - Training Epoch: 1/2, step 4821/7134 completed (loss: 2.737095355987549, acc: 0.41040462255477905)
[2024-12-17 02:13:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:19,646][root][INFO] - Training Epoch: 1/2, step 4822/7134 completed (loss: 3.319420576095581, acc: 0.3382352888584137)
[2024-12-17 02:13:19,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,022][root][INFO] - Training Epoch: 1/2, step 4823/7134 completed (loss: 3.7665865421295166, acc: 0.28930819034576416)
[2024-12-17 02:13:20,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,357][root][INFO] - Training Epoch: 1/2, step 4824/7134 completed (loss: 3.7363178730010986, acc: 0.24576270580291748)
[2024-12-17 02:13:20,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:20,713][root][INFO] - Training Epoch: 1/2, step 4825/7134 completed (loss: 3.478580951690674, acc: 0.36764705181121826)
[2024-12-17 02:13:20,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,113][root][INFO] - Training Epoch: 1/2, step 4826/7134 completed (loss: 4.203503131866455, acc: 0.23140496015548706)
[2024-12-17 02:13:21,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,475][root][INFO] - Training Epoch: 1/2, step 4827/7134 completed (loss: 3.948111057281494, acc: 0.2451612949371338)
[2024-12-17 02:13:21,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:21,863][root][INFO] - Training Epoch: 1/2, step 4828/7134 completed (loss: 3.210894823074341, acc: 0.3265306055545807)
[2024-12-17 02:13:21,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,240][root][INFO] - Training Epoch: 1/2, step 4829/7134 completed (loss: 2.8498265743255615, acc: 0.35148516297340393)
[2024-12-17 02:13:22,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,609][root][INFO] - Training Epoch: 1/2, step 4830/7134 completed (loss: 2.923056125640869, acc: 0.41818180680274963)
[2024-12-17 02:13:22,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:22,977][root][INFO] - Training Epoch: 1/2, step 4831/7134 completed (loss: 2.7292327880859375, acc: 0.4000000059604645)
[2024-12-17 02:13:23,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,351][root][INFO] - Training Epoch: 1/2, step 4832/7134 completed (loss: 2.814419746398926, acc: 0.3986928164958954)
[2024-12-17 02:13:23,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:23,714][root][INFO] - Training Epoch: 1/2, step 4833/7134 completed (loss: 3.2292966842651367, acc: 0.3502538204193115)
[2024-12-17 02:13:23,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,088][root][INFO] - Training Epoch: 1/2, step 4834/7134 completed (loss: 2.9394381046295166, acc: 0.35348838567733765)
[2024-12-17 02:13:24,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,451][root][INFO] - Training Epoch: 1/2, step 4835/7134 completed (loss: 3.098388671875, acc: 0.4000000059604645)
[2024-12-17 02:13:24,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:24,839][root][INFO] - Training Epoch: 1/2, step 4836/7134 completed (loss: 3.295975685119629, acc: 0.327160507440567)
[2024-12-17 02:13:24,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,186][root][INFO] - Training Epoch: 1/2, step 4837/7134 completed (loss: 3.3122549057006836, acc: 0.3499999940395355)
[2024-12-17 02:13:25,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,569][root][INFO] - Training Epoch: 1/2, step 4838/7134 completed (loss: 4.062599182128906, acc: 0.3309352397918701)
[2024-12-17 02:13:25,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:25,934][root][INFO] - Training Epoch: 1/2, step 4839/7134 completed (loss: 4.447546005249023, acc: 0.19379845261573792)
[2024-12-17 02:13:26,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,290][root][INFO] - Training Epoch: 1/2, step 4840/7134 completed (loss: 4.740871429443359, acc: 0.18421052396297455)
[2024-12-17 02:13:26,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,606][root][INFO] - Training Epoch: 1/2, step 4841/7134 completed (loss: 4.6180806159973145, acc: 0.2777777910232544)
[2024-12-17 02:13:26,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:26,977][root][INFO] - Training Epoch: 1/2, step 4842/7134 completed (loss: 4.37174129486084, acc: 0.2777777910232544)
[2024-12-17 02:13:27,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,347][root][INFO] - Training Epoch: 1/2, step 4843/7134 completed (loss: 4.387458324432373, acc: 0.29559749364852905)
[2024-12-17 02:13:27,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:27,691][root][INFO] - Training Epoch: 1/2, step 4844/7134 completed (loss: 4.505157947540283, acc: 0.2230769246816635)
[2024-12-17 02:13:27,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,064][root][INFO] - Training Epoch: 1/2, step 4845/7134 completed (loss: 4.534655570983887, acc: 0.2750000059604645)
[2024-12-17 02:13:28,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,442][root][INFO] - Training Epoch: 1/2, step 4846/7134 completed (loss: 4.192337989807129, acc: 0.28125)
[2024-12-17 02:13:28,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:28,801][root][INFO] - Training Epoch: 1/2, step 4847/7134 completed (loss: 4.017919540405273, acc: 0.2958579957485199)
[2024-12-17 02:13:28,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,153][root][INFO] - Training Epoch: 1/2, step 4848/7134 completed (loss: 4.314609050750732, acc: 0.2777777910232544)
[2024-12-17 02:13:29,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,502][root][INFO] - Training Epoch: 1/2, step 4849/7134 completed (loss: 3.7627789974212646, acc: 0.31506848335266113)
[2024-12-17 02:13:29,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:29,888][root][INFO] - Training Epoch: 1/2, step 4850/7134 completed (loss: 4.156407356262207, acc: 0.3296089470386505)
[2024-12-17 02:13:30,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,268][root][INFO] - Training Epoch: 1/2, step 4851/7134 completed (loss: 3.655565023422241, acc: 0.3081081211566925)
[2024-12-17 02:13:30,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:30,645][root][INFO] - Training Epoch: 1/2, step 4852/7134 completed (loss: 3.3964271545410156, acc: 0.3779069781303406)
[2024-12-17 02:13:30,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,013][root][INFO] - Training Epoch: 1/2, step 4853/7134 completed (loss: 3.43300461769104, acc: 0.38922154903411865)
[2024-12-17 02:13:31,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,377][root][INFO] - Training Epoch: 1/2, step 4854/7134 completed (loss: 3.3067548274993896, acc: 0.4026845693588257)
[2024-12-17 02:13:31,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:31,739][root][INFO] - Training Epoch: 1/2, step 4855/7134 completed (loss: 3.647230386734009, acc: 0.3448275923728943)
[2024-12-17 02:13:31,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,099][root][INFO] - Training Epoch: 1/2, step 4856/7134 completed (loss: 4.129311561584473, acc: 0.261904776096344)
[2024-12-17 02:13:32,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,461][root][INFO] - Training Epoch: 1/2, step 4857/7134 completed (loss: 4.435244560241699, acc: 0.26543208956718445)
[2024-12-17 02:13:32,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:32,839][root][INFO] - Training Epoch: 1/2, step 4858/7134 completed (loss: 4.848504066467285, acc: 0.23456789553165436)
[2024-12-17 02:13:32,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,204][root][INFO] - Training Epoch: 1/2, step 4859/7134 completed (loss: 4.381462574005127, acc: 0.244047611951828)
[2024-12-17 02:13:33,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,561][root][INFO] - Training Epoch: 1/2, step 4860/7134 completed (loss: 4.247649192810059, acc: 0.24561403691768646)
[2024-12-17 02:13:33,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:33,919][root][INFO] - Training Epoch: 1/2, step 4861/7134 completed (loss: 4.015902996063232, acc: 0.24260355532169342)
[2024-12-17 02:13:34,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,289][root][INFO] - Training Epoch: 1/2, step 4862/7134 completed (loss: 4.389512538909912, acc: 0.2368421107530594)
[2024-12-17 02:13:34,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:34,646][root][INFO] - Training Epoch: 1/2, step 4863/7134 completed (loss: 4.035741806030273, acc: 0.25581395626068115)
[2024-12-17 02:13:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,004][root][INFO] - Training Epoch: 1/2, step 4864/7134 completed (loss: 4.102739334106445, acc: 0.2866241931915283)
[2024-12-17 02:13:35,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,388][root][INFO] - Training Epoch: 1/2, step 4865/7134 completed (loss: 4.305658340454102, acc: 0.3172042965888977)
[2024-12-17 02:13:35,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:35,757][root][INFO] - Training Epoch: 1/2, step 4866/7134 completed (loss: 3.756556272506714, acc: 0.302325576543808)
[2024-12-17 02:13:35,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,102][root][INFO] - Training Epoch: 1/2, step 4867/7134 completed (loss: 3.805680751800537, acc: 0.3296089470386505)
[2024-12-17 02:13:36,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,462][root][INFO] - Training Epoch: 1/2, step 4868/7134 completed (loss: 4.254178047180176, acc: 0.21848739683628082)
[2024-12-17 02:13:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:36,860][root][INFO] - Training Epoch: 1/2, step 4869/7134 completed (loss: 4.545626640319824, acc: 0.27551019191741943)
[2024-12-17 02:13:36,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,219][root][INFO] - Training Epoch: 1/2, step 4870/7134 completed (loss: 4.028036117553711, acc: 0.3243243098258972)
[2024-12-17 02:13:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,579][root][INFO] - Training Epoch: 1/2, step 4871/7134 completed (loss: 3.709855794906616, acc: 0.31578946113586426)
[2024-12-17 02:13:37,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:37,946][root][INFO] - Training Epoch: 1/2, step 4872/7134 completed (loss: 3.5938735008239746, acc: 0.2916666567325592)
[2024-12-17 02:13:38,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,315][root][INFO] - Training Epoch: 1/2, step 4873/7134 completed (loss: 3.3809971809387207, acc: 0.32786884903907776)
[2024-12-17 02:13:38,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:38,674][root][INFO] - Training Epoch: 1/2, step 4874/7134 completed (loss: 3.744793653488159, acc: 0.31707316637039185)
[2024-12-17 02:13:38,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,073][root][INFO] - Training Epoch: 1/2, step 4875/7134 completed (loss: 3.932774543762207, acc: 0.23602484166622162)
[2024-12-17 02:13:39,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,404][root][INFO] - Training Epoch: 1/2, step 4876/7134 completed (loss: 4.159438133239746, acc: 0.2777777910232544)
[2024-12-17 02:13:39,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:39,762][root][INFO] - Training Epoch: 1/2, step 4877/7134 completed (loss: 4.011419296264648, acc: 0.3282051384449005)
[2024-12-17 02:13:39,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,111][root][INFO] - Training Epoch: 1/2, step 4878/7134 completed (loss: 4.346776485443115, acc: 0.29870128631591797)
[2024-12-17 02:13:40,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,478][root][INFO] - Training Epoch: 1/2, step 4879/7134 completed (loss: 3.797661781311035, acc: 0.25641027092933655)
[2024-12-17 02:13:40,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:40,861][root][INFO] - Training Epoch: 1/2, step 4880/7134 completed (loss: 4.003992080688477, acc: 0.3117647171020508)
[2024-12-17 02:13:40,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,248][root][INFO] - Training Epoch: 1/2, step 4881/7134 completed (loss: 3.5306942462921143, acc: 0.3557046949863434)
[2024-12-17 02:13:41,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,612][root][INFO] - Training Epoch: 1/2, step 4882/7134 completed (loss: 3.873166561126709, acc: 0.2774193584918976)
[2024-12-17 02:13:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:41,972][root][INFO] - Training Epoch: 1/2, step 4883/7134 completed (loss: 3.6544320583343506, acc: 0.3400000035762787)
[2024-12-17 02:13:42,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,322][root][INFO] - Training Epoch: 1/2, step 4884/7134 completed (loss: 3.5297069549560547, acc: 0.3333333432674408)
[2024-12-17 02:13:42,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:42,711][root][INFO] - Training Epoch: 1/2, step 4885/7134 completed (loss: 4.258974552154541, acc: 0.31182795763015747)
[2024-12-17 02:13:42,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,083][root][INFO] - Training Epoch: 1/2, step 4886/7134 completed (loss: 3.8573355674743652, acc: 0.32692307233810425)
[2024-12-17 02:13:43,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,463][root][INFO] - Training Epoch: 1/2, step 4887/7134 completed (loss: 3.8753294944763184, acc: 0.28272250294685364)
[2024-12-17 02:13:43,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:43,823][root][INFO] - Training Epoch: 1/2, step 4888/7134 completed (loss: 3.298891544342041, acc: 0.3681318759918213)
[2024-12-17 02:13:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,190][root][INFO] - Training Epoch: 1/2, step 4889/7134 completed (loss: 3.7930808067321777, acc: 0.27272728085517883)
[2024-12-17 02:13:44,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,530][root][INFO] - Training Epoch: 1/2, step 4890/7134 completed (loss: 3.6914546489715576, acc: 0.30188679695129395)
[2024-12-17 02:13:44,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:44,907][root][INFO] - Training Epoch: 1/2, step 4891/7134 completed (loss: 3.413665533065796, acc: 0.33673468232154846)
[2024-12-17 02:13:45,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,234][root][INFO] - Training Epoch: 1/2, step 4892/7134 completed (loss: 3.3986330032348633, acc: 0.3571428656578064)
[2024-12-17 02:13:45,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,613][root][INFO] - Training Epoch: 1/2, step 4893/7134 completed (loss: 4.2523369789123535, acc: 0.26724138855934143)
[2024-12-17 02:13:45,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:45,980][root][INFO] - Training Epoch: 1/2, step 4894/7134 completed (loss: 3.4439351558685303, acc: 0.34705883264541626)
[2024-12-17 02:13:46,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,346][root][INFO] - Training Epoch: 1/2, step 4895/7134 completed (loss: 3.1883394718170166, acc: 0.3316326439380646)
[2024-12-17 02:13:46,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:46,710][root][INFO] - Training Epoch: 1/2, step 4896/7134 completed (loss: 3.409374952316284, acc: 0.34078213572502136)
[2024-12-17 02:13:46,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,089][root][INFO] - Training Epoch: 1/2, step 4897/7134 completed (loss: 3.7153677940368652, acc: 0.29556649923324585)
[2024-12-17 02:13:47,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,466][root][INFO] - Training Epoch: 1/2, step 4898/7134 completed (loss: 3.4098124504089355, acc: 0.3172042965888977)
[2024-12-17 02:13:47,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:47,820][root][INFO] - Training Epoch: 1/2, step 4899/7134 completed (loss: 3.5918033123016357, acc: 0.35975611209869385)
[2024-12-17 02:13:47,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,171][root][INFO] - Training Epoch: 1/2, step 4900/7134 completed (loss: 3.254153251647949, acc: 0.3582887649536133)
[2024-12-17 02:13:48,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,519][root][INFO] - Training Epoch: 1/2, step 4901/7134 completed (loss: 3.2940409183502197, acc: 0.3414634168148041)
[2024-12-17 02:13:48,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:48,887][root][INFO] - Training Epoch: 1/2, step 4902/7134 completed (loss: 3.318279266357422, acc: 0.2974359095096588)
[2024-12-17 02:13:48,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,250][root][INFO] - Training Epoch: 1/2, step 4903/7134 completed (loss: 3.4879157543182373, acc: 0.32846716046333313)
[2024-12-17 02:13:49,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,619][root][INFO] - Training Epoch: 1/2, step 4904/7134 completed (loss: 3.0637049674987793, acc: 0.3588235378265381)
[2024-12-17 02:13:49,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:49,986][root][INFO] - Training Epoch: 1/2, step 4905/7134 completed (loss: 3.1260716915130615, acc: 0.3464052379131317)
[2024-12-17 02:13:50,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,347][root][INFO] - Training Epoch: 1/2, step 4906/7134 completed (loss: 3.394766330718994, acc: 0.308270663022995)
[2024-12-17 02:13:50,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:50,733][root][INFO] - Training Epoch: 1/2, step 4907/7134 completed (loss: 3.3038039207458496, acc: 0.36734694242477417)
[2024-12-17 02:13:50,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,116][root][INFO] - Training Epoch: 1/2, step 4908/7134 completed (loss: 3.150139093399048, acc: 0.3571428656578064)
[2024-12-17 02:13:51,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,493][root][INFO] - Training Epoch: 1/2, step 4909/7134 completed (loss: 2.991828441619873, acc: 0.4093959629535675)
[2024-12-17 02:13:51,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:51,837][root][INFO] - Training Epoch: 1/2, step 4910/7134 completed (loss: 3.525459051132202, acc: 0.34193548560142517)
[2024-12-17 02:13:51,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,187][root][INFO] - Training Epoch: 1/2, step 4911/7134 completed (loss: 3.2087032794952393, acc: 0.3957219123840332)
[2024-12-17 02:13:52,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,564][root][INFO] - Training Epoch: 1/2, step 4912/7134 completed (loss: 3.0246329307556152, acc: 0.38805970549583435)
[2024-12-17 02:13:52,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:52,936][root][INFO] - Training Epoch: 1/2, step 4913/7134 completed (loss: 3.432769298553467, acc: 0.3076923191547394)
[2024-12-17 02:13:53,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,303][root][INFO] - Training Epoch: 1/2, step 4914/7134 completed (loss: 3.5348281860351562, acc: 0.34838709235191345)
[2024-12-17 02:13:53,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:53,686][root][INFO] - Training Epoch: 1/2, step 4915/7134 completed (loss: 3.1304101943969727, acc: 0.2839506268501282)
[2024-12-17 02:13:53,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,080][root][INFO] - Training Epoch: 1/2, step 4916/7134 completed (loss: 3.967663526535034, acc: 0.21739129722118378)
[2024-12-17 02:13:54,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,450][root][INFO] - Training Epoch: 1/2, step 4917/7134 completed (loss: 3.6563899517059326, acc: 0.35668790340423584)
[2024-12-17 02:13:54,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:54,818][root][INFO] - Training Epoch: 1/2, step 4918/7134 completed (loss: 3.367126941680908, acc: 0.37654322385787964)
[2024-12-17 02:13:54,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,234][root][INFO] - Training Epoch: 1/2, step 4919/7134 completed (loss: 3.7107229232788086, acc: 0.26553672552108765)
[2024-12-17 02:13:55,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,628][root][INFO] - Training Epoch: 1/2, step 4920/7134 completed (loss: 3.6447150707244873, acc: 0.34161490201950073)
[2024-12-17 02:13:55,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:55,979][root][INFO] - Training Epoch: 1/2, step 4921/7134 completed (loss: 3.8467822074890137, acc: 0.31386861205101013)
[2024-12-17 02:13:56,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,346][root][INFO] - Training Epoch: 1/2, step 4922/7134 completed (loss: 3.8174290657043457, acc: 0.2857142984867096)
[2024-12-17 02:13:56,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:56,720][root][INFO] - Training Epoch: 1/2, step 4923/7134 completed (loss: 3.941242218017578, acc: 0.3115941882133484)
[2024-12-17 02:13:56,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,101][root][INFO] - Training Epoch: 1/2, step 4924/7134 completed (loss: 4.140411853790283, acc: 0.3203883469104767)
[2024-12-17 02:13:57,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,471][root][INFO] - Training Epoch: 1/2, step 4925/7134 completed (loss: 4.007915019989014, acc: 0.2751677930355072)
[2024-12-17 02:13:57,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:57,813][root][INFO] - Training Epoch: 1/2, step 4926/7134 completed (loss: 3.789771556854248, acc: 0.3154362440109253)
[2024-12-17 02:13:57,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,174][root][INFO] - Training Epoch: 1/2, step 4927/7134 completed (loss: 3.687648057937622, acc: 0.2709677517414093)
[2024-12-17 02:13:58,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,557][root][INFO] - Training Epoch: 1/2, step 4928/7134 completed (loss: 3.2325265407562256, acc: 0.3684210479259491)
[2024-12-17 02:13:58,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:58,913][root][INFO] - Training Epoch: 1/2, step 4929/7134 completed (loss: 3.2689082622528076, acc: 0.3947368562221527)
[2024-12-17 02:13:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,284][root][INFO] - Training Epoch: 1/2, step 4930/7134 completed (loss: 3.3877453804016113, acc: 0.3445945978164673)
[2024-12-17 02:13:59,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:13:59,670][root][INFO] - Training Epoch: 1/2, step 4931/7134 completed (loss: 3.9754834175109863, acc: 0.29447853565216064)
[2024-12-17 02:13:59,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,040][root][INFO] - Training Epoch: 1/2, step 4932/7134 completed (loss: 3.5513293743133545, acc: 0.28823530673980713)
[2024-12-17 02:14:00,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,388][root][INFO] - Training Epoch: 1/2, step 4933/7134 completed (loss: 3.9152746200561523, acc: 0.3141361176967621)
[2024-12-17 02:14:00,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:00,761][root][INFO] - Training Epoch: 1/2, step 4934/7134 completed (loss: 3.460383176803589, acc: 0.33529412746429443)
[2024-12-17 02:14:00,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,126][root][INFO] - Training Epoch: 1/2, step 4935/7134 completed (loss: 3.8052291870117188, acc: 0.30588236451148987)
[2024-12-17 02:14:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,498][root][INFO] - Training Epoch: 1/2, step 4936/7134 completed (loss: 3.2036468982696533, acc: 0.3333333432674408)
[2024-12-17 02:14:01,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:01,857][root][INFO] - Training Epoch: 1/2, step 4937/7134 completed (loss: 3.818344831466675, acc: 0.35664334893226624)
[2024-12-17 02:14:01,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,223][root][INFO] - Training Epoch: 1/2, step 4938/7134 completed (loss: 3.4665164947509766, acc: 0.3641975224018097)
[2024-12-17 02:14:02,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,585][root][INFO] - Training Epoch: 1/2, step 4939/7134 completed (loss: 3.5596539974212646, acc: 0.33571428060531616)
[2024-12-17 02:14:02,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:02,948][root][INFO] - Training Epoch: 1/2, step 4940/7134 completed (loss: 3.9916088581085205, acc: 0.3100775182247162)
[2024-12-17 02:14:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,317][root][INFO] - Training Epoch: 1/2, step 4941/7134 completed (loss: 3.6660380363464355, acc: 0.341317355632782)
[2024-12-17 02:14:03,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:03,695][root][INFO] - Training Epoch: 1/2, step 4942/7134 completed (loss: 3.8034417629241943, acc: 0.3037974536418915)
[2024-12-17 02:14:03,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,047][root][INFO] - Training Epoch: 1/2, step 4943/7134 completed (loss: 3.7154128551483154, acc: 0.36250001192092896)
[2024-12-17 02:14:04,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,438][root][INFO] - Training Epoch: 1/2, step 4944/7134 completed (loss: 4.220998764038086, acc: 0.2857142984867096)
[2024-12-17 02:14:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:04,796][root][INFO] - Training Epoch: 1/2, step 4945/7134 completed (loss: 4.225447177886963, acc: 0.31060606241226196)
[2024-12-17 02:14:04,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,172][root][INFO] - Training Epoch: 1/2, step 4946/7134 completed (loss: 3.8824357986450195, acc: 0.2890625)
[2024-12-17 02:14:05,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,543][root][INFO] - Training Epoch: 1/2, step 4947/7134 completed (loss: 4.309993743896484, acc: 0.33043476939201355)
[2024-12-17 02:14:05,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:05,905][root][INFO] - Training Epoch: 1/2, step 4948/7134 completed (loss: 4.114930152893066, acc: 0.3619047701358795)
[2024-12-17 02:14:06,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,281][root][INFO] - Training Epoch: 1/2, step 4949/7134 completed (loss: 3.4191460609436035, acc: 0.3086419701576233)
[2024-12-17 02:14:06,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:06,653][root][INFO] - Training Epoch: 1/2, step 4950/7134 completed (loss: 4.275414943695068, acc: 0.20408163964748383)
[2024-12-17 02:14:06,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,047][root][INFO] - Training Epoch: 1/2, step 4951/7134 completed (loss: 3.6251423358917236, acc: 0.3820224702358246)
[2024-12-17 02:14:07,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,458][root][INFO] - Training Epoch: 1/2, step 4952/7134 completed (loss: 3.270942449569702, acc: 0.37837839126586914)
[2024-12-17 02:14:07,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:07,839][root][INFO] - Training Epoch: 1/2, step 4953/7134 completed (loss: 4.147880554199219, acc: 0.2702702581882477)
[2024-12-17 02:14:07,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,208][root][INFO] - Training Epoch: 1/2, step 4954/7134 completed (loss: 4.321430206298828, acc: 0.22448979318141937)
[2024-12-17 02:14:08,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,568][root][INFO] - Training Epoch: 1/2, step 4955/7134 completed (loss: 4.521058559417725, acc: 0.2291666716337204)
[2024-12-17 02:14:08,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:08,932][root][INFO] - Training Epoch: 1/2, step 4956/7134 completed (loss: 4.0104756355285645, acc: 0.34117648005485535)
[2024-12-17 02:14:09,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,322][root][INFO] - Training Epoch: 1/2, step 4957/7134 completed (loss: 3.8854544162750244, acc: 0.29078012704849243)
[2024-12-17 02:14:09,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:09,707][root][INFO] - Training Epoch: 1/2, step 4958/7134 completed (loss: 4.117711544036865, acc: 0.276729553937912)
[2024-12-17 02:14:09,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,067][root][INFO] - Training Epoch: 1/2, step 4959/7134 completed (loss: 3.9416627883911133, acc: 0.22891566157341003)
[2024-12-17 02:14:10,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,417][root][INFO] - Training Epoch: 1/2, step 4960/7134 completed (loss: 3.8735759258270264, acc: 0.27941176295280457)
[2024-12-17 02:14:10,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:10,796][root][INFO] - Training Epoch: 1/2, step 4961/7134 completed (loss: 3.7354142665863037, acc: 0.296875)
[2024-12-17 02:14:10,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,154][root][INFO] - Training Epoch: 1/2, step 4962/7134 completed (loss: 3.606760263442993, acc: 0.3231707215309143)
[2024-12-17 02:14:11,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,518][root][INFO] - Training Epoch: 1/2, step 4963/7134 completed (loss: 3.5669822692871094, acc: 0.3032258152961731)
[2024-12-17 02:14:11,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:11,910][root][INFO] - Training Epoch: 1/2, step 4964/7134 completed (loss: 3.8599836826324463, acc: 0.2733812928199768)
[2024-12-17 02:14:12,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,265][root][INFO] - Training Epoch: 1/2, step 4965/7134 completed (loss: 3.8447303771972656, acc: 0.313043475151062)
[2024-12-17 02:14:12,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,601][root][INFO] - Training Epoch: 1/2, step 4966/7134 completed (loss: 4.3438849449157715, acc: 0.2637362778186798)
[2024-12-17 02:14:12,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:12,975][root][INFO] - Training Epoch: 1/2, step 4967/7134 completed (loss: 3.635653257369995, acc: 0.3333333432674408)
[2024-12-17 02:14:13,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,357][root][INFO] - Training Epoch: 1/2, step 4968/7134 completed (loss: 4.515401363372803, acc: 0.27659574151039124)
[2024-12-17 02:14:13,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:13,745][root][INFO] - Training Epoch: 1/2, step 4969/7134 completed (loss: 4.446831703186035, acc: 0.2689655125141144)
[2024-12-17 02:14:13,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,102][root][INFO] - Training Epoch: 1/2, step 4970/7134 completed (loss: 3.4202728271484375, acc: 0.3724137842655182)
[2024-12-17 02:14:14,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,444][root][INFO] - Training Epoch: 1/2, step 4971/7134 completed (loss: 3.6193296909332275, acc: 0.34437087178230286)
[2024-12-17 02:14:14,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:14,838][root][INFO] - Training Epoch: 1/2, step 4972/7134 completed (loss: 3.8586411476135254, acc: 0.3375000059604645)
[2024-12-17 02:14:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,236][root][INFO] - Training Epoch: 1/2, step 4973/7134 completed (loss: 3.5957610607147217, acc: 0.3636363744735718)
[2024-12-17 02:14:15,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,595][root][INFO] - Training Epoch: 1/2, step 4974/7134 completed (loss: 4.003274440765381, acc: 0.3333333432674408)
[2024-12-17 02:14:15,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:15,967][root][INFO] - Training Epoch: 1/2, step 4975/7134 completed (loss: 3.772223472595215, acc: 0.27586206793785095)
[2024-12-17 02:14:16,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,333][root][INFO] - Training Epoch: 1/2, step 4976/7134 completed (loss: 3.6349008083343506, acc: 0.34736841917037964)
[2024-12-17 02:14:16,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:16,706][root][INFO] - Training Epoch: 1/2, step 4977/7134 completed (loss: 3.8681983947753906, acc: 0.3786407709121704)
[2024-12-17 02:14:16,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,060][root][INFO] - Training Epoch: 1/2, step 4978/7134 completed (loss: 3.7205848693847656, acc: 0.29885056614875793)
[2024-12-17 02:14:17,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,437][root][INFO] - Training Epoch: 1/2, step 4979/7134 completed (loss: 3.7057619094848633, acc: 0.3076923191547394)
[2024-12-17 02:14:17,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:17,817][root][INFO] - Training Epoch: 1/2, step 4980/7134 completed (loss: 3.9170589447021484, acc: 0.3499999940395355)
[2024-12-17 02:14:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,165][root][INFO] - Training Epoch: 1/2, step 4981/7134 completed (loss: 3.629808187484741, acc: 0.3214285671710968)
[2024-12-17 02:14:18,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,533][root][INFO] - Training Epoch: 1/2, step 4982/7134 completed (loss: 4.265196800231934, acc: 0.29729729890823364)
[2024-12-17 02:14:18,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:18,924][root][INFO] - Training Epoch: 1/2, step 4983/7134 completed (loss: 3.9257826805114746, acc: 0.30215826630592346)
[2024-12-17 02:14:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,297][root][INFO] - Training Epoch: 1/2, step 4984/7134 completed (loss: 4.378310680389404, acc: 0.22641509771347046)
[2024-12-17 02:14:19,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:19,676][root][INFO] - Training Epoch: 1/2, step 4985/7134 completed (loss: 3.9593911170959473, acc: 0.28378379344940186)
[2024-12-17 02:14:19,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,046][root][INFO] - Training Epoch: 1/2, step 4986/7134 completed (loss: 3.5519280433654785, acc: 0.3356643319129944)
[2024-12-17 02:14:20,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,396][root][INFO] - Training Epoch: 1/2, step 4987/7134 completed (loss: 4.078856468200684, acc: 0.3113207519054413)
[2024-12-17 02:14:20,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:20,735][root][INFO] - Training Epoch: 1/2, step 4988/7134 completed (loss: 3.7366533279418945, acc: 0.3103448152542114)
[2024-12-17 02:14:20,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,074][root][INFO] - Training Epoch: 1/2, step 4989/7134 completed (loss: 3.393587112426758, acc: 0.38823530077934265)
[2024-12-17 02:14:21,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,422][root][INFO] - Training Epoch: 1/2, step 4990/7134 completed (loss: 3.290865182876587, acc: 0.4017094075679779)
[2024-12-17 02:14:21,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:21,776][root][INFO] - Training Epoch: 1/2, step 4991/7134 completed (loss: 4.013137340545654, acc: 0.3233082592487335)
[2024-12-17 02:14:21,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,142][root][INFO] - Training Epoch: 1/2, step 4992/7134 completed (loss: 3.336121082305908, acc: 0.36206895112991333)
[2024-12-17 02:14:22,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,451][root][INFO] - Training Epoch: 1/2, step 4993/7134 completed (loss: 3.4978528022766113, acc: 0.4000000059604645)
[2024-12-17 02:14:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:22,819][root][INFO] - Training Epoch: 1/2, step 4994/7134 completed (loss: 3.6624302864074707, acc: 0.2847682237625122)
[2024-12-17 02:14:22,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,111][root][INFO] - Training Epoch: 1/2, step 4995/7134 completed (loss: 4.147294044494629, acc: 0.3333333432674408)
[2024-12-17 02:14:23,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,467][root][INFO] - Training Epoch: 1/2, step 4996/7134 completed (loss: 3.562825918197632, acc: 0.375)
[2024-12-17 02:14:23,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:23,851][root][INFO] - Training Epoch: 1/2, step 4997/7134 completed (loss: 3.5703020095825195, acc: 0.3664122223854065)
[2024-12-17 02:14:23,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,186][root][INFO] - Training Epoch: 1/2, step 4998/7134 completed (loss: 3.990902900695801, acc: 0.36000001430511475)
[2024-12-17 02:14:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,517][root][INFO] - Training Epoch: 1/2, step 4999/7134 completed (loss: 3.714263677597046, acc: 0.3937007784843445)
[2024-12-17 02:14:24,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:24,899][root][INFO] - Training Epoch: 1/2, step 5000/7134 completed (loss: 3.5131375789642334, acc: 0.3298968970775604)
[2024-12-17 02:14:25,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,247][root][INFO] - Training Epoch: 1/2, step 5001/7134 completed (loss: 3.4622230529785156, acc: 0.36734694242477417)
[2024-12-17 02:14:25,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,594][root][INFO] - Training Epoch: 1/2, step 5002/7134 completed (loss: 3.5383031368255615, acc: 0.3539822995662689)
[2024-12-17 02:14:25,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:25,904][root][INFO] - Training Epoch: 1/2, step 5003/7134 completed (loss: 3.3808188438415527, acc: 0.385185182094574)
[2024-12-17 02:14:26,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,253][root][INFO] - Training Epoch: 1/2, step 5004/7134 completed (loss: 2.9572982788085938, acc: 0.4392523467540741)
[2024-12-17 02:14:26,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,598][root][INFO] - Training Epoch: 1/2, step 5005/7134 completed (loss: 3.3498194217681885, acc: 0.35164836049079895)
[2024-12-17 02:14:26,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:26,981][root][INFO] - Training Epoch: 1/2, step 5006/7134 completed (loss: 3.1780238151550293, acc: 0.3881579041481018)
[2024-12-17 02:14:27,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,358][root][INFO] - Training Epoch: 1/2, step 5007/7134 completed (loss: 3.4658145904541016, acc: 0.29629629850387573)
[2024-12-17 02:14:27,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:27,756][root][INFO] - Training Epoch: 1/2, step 5008/7134 completed (loss: 3.6061995029449463, acc: 0.3499999940395355)
[2024-12-17 02:14:27,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,123][root][INFO] - Training Epoch: 1/2, step 5009/7134 completed (loss: 3.737226963043213, acc: 0.27835050225257874)
[2024-12-17 02:14:28,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,483][root][INFO] - Training Epoch: 1/2, step 5010/7134 completed (loss: 3.6719424724578857, acc: 0.32478633522987366)
[2024-12-17 02:14:28,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:28,859][root][INFO] - Training Epoch: 1/2, step 5011/7134 completed (loss: 2.9651596546173096, acc: 0.33103448152542114)
[2024-12-17 02:14:28,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,152][root][INFO] - Training Epoch: 1/2, step 5012/7134 completed (loss: 3.2080702781677246, acc: 0.4000000059604645)
[2024-12-17 02:14:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,499][root][INFO] - Training Epoch: 1/2, step 5013/7134 completed (loss: 2.977060317993164, acc: 0.3504273593425751)
[2024-12-17 02:14:29,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:29,879][root][INFO] - Training Epoch: 1/2, step 5014/7134 completed (loss: 3.30070161819458, acc: 0.42307692766189575)
[2024-12-17 02:14:30,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,259][root][INFO] - Training Epoch: 1/2, step 5015/7134 completed (loss: 3.2140908241271973, acc: 0.3680981695652008)
[2024-12-17 02:14:30,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,606][root][INFO] - Training Epoch: 1/2, step 5016/7134 completed (loss: 4.071662425994873, acc: 0.3206106722354889)
[2024-12-17 02:14:30,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:30,958][root][INFO] - Training Epoch: 1/2, step 5017/7134 completed (loss: 3.8161044120788574, acc: 0.280303031206131)
[2024-12-17 02:14:31,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,330][root][INFO] - Training Epoch: 1/2, step 5018/7134 completed (loss: 4.009802341461182, acc: 0.2631579041481018)
[2024-12-17 02:14:31,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:31,720][root][INFO] - Training Epoch: 1/2, step 5019/7134 completed (loss: 3.730611801147461, acc: 0.28248587250709534)
[2024-12-17 02:14:31,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,089][root][INFO] - Training Epoch: 1/2, step 5020/7134 completed (loss: 3.7417709827423096, acc: 0.33862432837486267)
[2024-12-17 02:14:32,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,480][root][INFO] - Training Epoch: 1/2, step 5021/7134 completed (loss: 3.435141086578369, acc: 0.3333333432674408)
[2024-12-17 02:14:32,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:32,860][root][INFO] - Training Epoch: 1/2, step 5022/7134 completed (loss: 3.6961562633514404, acc: 0.3115941882133484)
[2024-12-17 02:14:32,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,211][root][INFO] - Training Epoch: 1/2, step 5023/7134 completed (loss: 3.077221632003784, acc: 0.3677419424057007)
[2024-12-17 02:14:33,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,576][root][INFO] - Training Epoch: 1/2, step 5024/7134 completed (loss: 3.2878804206848145, acc: 0.3313252925872803)
[2024-12-17 02:14:33,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:33,943][root][INFO] - Training Epoch: 1/2, step 5025/7134 completed (loss: 3.7961485385894775, acc: 0.26153847575187683)
[2024-12-17 02:14:34,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,294][root][INFO] - Training Epoch: 1/2, step 5026/7134 completed (loss: 3.5717644691467285, acc: 0.3358778655529022)
[2024-12-17 02:14:34,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:34,715][root][INFO] - Training Epoch: 1/2, step 5027/7134 completed (loss: 3.1602489948272705, acc: 0.43410852551460266)
[2024-12-17 02:14:34,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,107][root][INFO] - Training Epoch: 1/2, step 5028/7134 completed (loss: 3.2684717178344727, acc: 0.3802816867828369)
[2024-12-17 02:14:35,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,490][root][INFO] - Training Epoch: 1/2, step 5029/7134 completed (loss: 3.5579538345336914, acc: 0.3384615480899811)
[2024-12-17 02:14:35,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:35,898][root][INFO] - Training Epoch: 1/2, step 5030/7134 completed (loss: 3.8168575763702393, acc: 0.3053892254829407)
[2024-12-17 02:14:36,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,276][root][INFO] - Training Epoch: 1/2, step 5031/7134 completed (loss: 3.8815431594848633, acc: 0.28985506296157837)
[2024-12-17 02:14:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:36,653][root][INFO] - Training Epoch: 1/2, step 5032/7134 completed (loss: 3.3564090728759766, acc: 0.30985915660858154)
[2024-12-17 02:14:36,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,030][root][INFO] - Training Epoch: 1/2, step 5033/7134 completed (loss: 3.597022533416748, acc: 0.2887323796749115)
[2024-12-17 02:14:37,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,384][root][INFO] - Training Epoch: 1/2, step 5034/7134 completed (loss: 3.374075174331665, acc: 0.308270663022995)
[2024-12-17 02:14:37,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:37,732][root][INFO] - Training Epoch: 1/2, step 5035/7134 completed (loss: 3.2288458347320557, acc: 0.3583333194255829)
[2024-12-17 02:14:37,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,113][root][INFO] - Training Epoch: 1/2, step 5036/7134 completed (loss: 3.8909122943878174, acc: 0.29807692766189575)
[2024-12-17 02:14:38,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,471][root][INFO] - Training Epoch: 1/2, step 5037/7134 completed (loss: 3.531497001647949, acc: 0.30000001192092896)
[2024-12-17 02:14:38,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:38,829][root][INFO] - Training Epoch: 1/2, step 5038/7134 completed (loss: 3.7372169494628906, acc: 0.3913043439388275)
[2024-12-17 02:14:38,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,169][root][INFO] - Training Epoch: 1/2, step 5039/7134 completed (loss: 3.5392203330993652, acc: 0.3120567500591278)
[2024-12-17 02:14:39,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,567][root][INFO] - Training Epoch: 1/2, step 5040/7134 completed (loss: 3.456942558288574, acc: 0.3083333373069763)
[2024-12-17 02:14:39,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:39,928][root][INFO] - Training Epoch: 1/2, step 5041/7134 completed (loss: 3.1671142578125, acc: 0.33139535784721375)
[2024-12-17 02:14:40,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,314][root][INFO] - Training Epoch: 1/2, step 5042/7134 completed (loss: 3.2482028007507324, acc: 0.3980582654476166)
[2024-12-17 02:14:40,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:40,656][root][INFO] - Training Epoch: 1/2, step 5043/7134 completed (loss: 3.393542766571045, acc: 0.3185840845108032)
[2024-12-17 02:14:40,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,027][root][INFO] - Training Epoch: 1/2, step 5044/7134 completed (loss: 3.5709381103515625, acc: 0.29936304688453674)
[2024-12-17 02:14:41,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,398][root][INFO] - Training Epoch: 1/2, step 5045/7134 completed (loss: 3.432446241378784, acc: 0.3405405282974243)
[2024-12-17 02:14:41,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:41,766][root][INFO] - Training Epoch: 1/2, step 5046/7134 completed (loss: 4.205765247344971, acc: 0.25806450843811035)
[2024-12-17 02:14:41,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,154][root][INFO] - Training Epoch: 1/2, step 5047/7134 completed (loss: 4.498689651489258, acc: 0.32846716046333313)
[2024-12-17 02:14:42,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,526][root][INFO] - Training Epoch: 1/2, step 5048/7134 completed (loss: 3.8936731815338135, acc: 0.3142857253551483)
[2024-12-17 02:14:42,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:42,887][root][INFO] - Training Epoch: 1/2, step 5049/7134 completed (loss: 4.722675800323486, acc: 0.23566879332065582)
[2024-12-17 02:14:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,292][root][INFO] - Training Epoch: 1/2, step 5050/7134 completed (loss: 4.336382865905762, acc: 0.26249998807907104)
[2024-12-17 02:14:43,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:43,677][root][INFO] - Training Epoch: 1/2, step 5051/7134 completed (loss: 4.435146808624268, acc: 0.20408163964748383)
[2024-12-17 02:14:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,043][root][INFO] - Training Epoch: 1/2, step 5052/7134 completed (loss: 3.7437098026275635, acc: 0.3205128312110901)
[2024-12-17 02:14:44,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,399][root][INFO] - Training Epoch: 1/2, step 5053/7134 completed (loss: 3.9802567958831787, acc: 0.3166666626930237)
[2024-12-17 02:14:44,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:44,772][root][INFO] - Training Epoch: 1/2, step 5054/7134 completed (loss: 3.9572293758392334, acc: 0.29629629850387573)
[2024-12-17 02:14:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,107][root][INFO] - Training Epoch: 1/2, step 5055/7134 completed (loss: 3.732365369796753, acc: 0.3097345232963562)
[2024-12-17 02:14:45,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,460][root][INFO] - Training Epoch: 1/2, step 5056/7134 completed (loss: 4.0594892501831055, acc: 0.268456369638443)
[2024-12-17 02:14:45,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:45,840][root][INFO] - Training Epoch: 1/2, step 5057/7134 completed (loss: 3.9801087379455566, acc: 0.2802547812461853)
[2024-12-17 02:14:45,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,219][root][INFO] - Training Epoch: 1/2, step 5058/7134 completed (loss: 3.340336561203003, acc: 0.3414634168148041)
[2024-12-17 02:14:46,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,586][root][INFO] - Training Epoch: 1/2, step 5059/7134 completed (loss: 3.90321683883667, acc: 0.2634730637073517)
[2024-12-17 02:14:46,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:46,948][root][INFO] - Training Epoch: 1/2, step 5060/7134 completed (loss: 3.626223087310791, acc: 0.3333333432674408)
[2024-12-17 02:14:47,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,281][root][INFO] - Training Epoch: 1/2, step 5061/7134 completed (loss: 3.705352783203125, acc: 0.3619047701358795)
[2024-12-17 02:14:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:47,656][root][INFO] - Training Epoch: 1/2, step 5062/7134 completed (loss: 4.109371662139893, acc: 0.2888889014720917)
[2024-12-17 02:14:47,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,042][root][INFO] - Training Epoch: 1/2, step 5063/7134 completed (loss: 4.663681507110596, acc: 0.2097902148962021)
[2024-12-17 02:14:48,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,412][root][INFO] - Training Epoch: 1/2, step 5064/7134 completed (loss: 3.2074594497680664, acc: 0.34285715222358704)
[2024-12-17 02:14:48,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:48,797][root][INFO] - Training Epoch: 1/2, step 5065/7134 completed (loss: 4.278468132019043, acc: 0.29559749364852905)
[2024-12-17 02:14:48,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,157][root][INFO] - Training Epoch: 1/2, step 5066/7134 completed (loss: 3.77528715133667, acc: 0.27586206793785095)
[2024-12-17 02:14:49,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,555][root][INFO] - Training Epoch: 1/2, step 5067/7134 completed (loss: 3.313377857208252, acc: 0.3196721374988556)
[2024-12-17 02:14:49,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:49,933][root][INFO] - Training Epoch: 1/2, step 5068/7134 completed (loss: 3.7213478088378906, acc: 0.30281689763069153)
[2024-12-17 02:14:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,312][root][INFO] - Training Epoch: 1/2, step 5069/7134 completed (loss: 3.7395951747894287, acc: 0.31081080436706543)
[2024-12-17 02:14:50,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:50,715][root][INFO] - Training Epoch: 1/2, step 5070/7134 completed (loss: 3.5321245193481445, acc: 0.23170731961727142)
[2024-12-17 02:14:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,095][root][INFO] - Training Epoch: 1/2, step 5071/7134 completed (loss: 4.035284996032715, acc: 0.3176470696926117)
[2024-12-17 02:14:51,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,459][root][INFO] - Training Epoch: 1/2, step 5072/7134 completed (loss: 3.4269514083862305, acc: 0.3351648449897766)
[2024-12-17 02:14:51,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:51,830][root][INFO] - Training Epoch: 1/2, step 5073/7134 completed (loss: 3.267763376235962, acc: 0.3358778655529022)
[2024-12-17 02:14:51,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,182][root][INFO] - Training Epoch: 1/2, step 5074/7134 completed (loss: 4.063680171966553, acc: 0.27906978130340576)
[2024-12-17 02:14:52,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,528][root][INFO] - Training Epoch: 1/2, step 5075/7134 completed (loss: 3.6837480068206787, acc: 0.2869565188884735)
[2024-12-17 02:14:52,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:52,907][root][INFO] - Training Epoch: 1/2, step 5076/7134 completed (loss: 3.8345770835876465, acc: 0.34408602118492126)
[2024-12-17 02:14:53,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,273][root][INFO] - Training Epoch: 1/2, step 5077/7134 completed (loss: 3.642679452896118, acc: 0.3529411852359772)
[2024-12-17 02:14:53,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:53,637][root][INFO] - Training Epoch: 1/2, step 5078/7134 completed (loss: 4.1032023429870605, acc: 0.28333333134651184)
[2024-12-17 02:14:53,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,012][root][INFO] - Training Epoch: 1/2, step 5079/7134 completed (loss: 3.697221517562866, acc: 0.28333333134651184)
[2024-12-17 02:14:54,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,400][root][INFO] - Training Epoch: 1/2, step 5080/7134 completed (loss: 3.7030303478240967, acc: 0.29901960492134094)
[2024-12-17 02:14:54,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:54,786][root][INFO] - Training Epoch: 1/2, step 5081/7134 completed (loss: 3.633183717727661, acc: 0.3352601230144501)
[2024-12-17 02:14:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,184][root][INFO] - Training Epoch: 1/2, step 5082/7134 completed (loss: 3.4717302322387695, acc: 0.33103448152542114)
[2024-12-17 02:14:55,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,594][root][INFO] - Training Epoch: 1/2, step 5083/7134 completed (loss: 4.358222961425781, acc: 0.23076923191547394)
[2024-12-17 02:14:55,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:55,972][root][INFO] - Training Epoch: 1/2, step 5084/7134 completed (loss: 4.040122032165527, acc: 0.22772277891635895)
[2024-12-17 02:14:56,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,378][root][INFO] - Training Epoch: 1/2, step 5085/7134 completed (loss: 3.925806760787964, acc: 0.3144329786300659)
[2024-12-17 02:14:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:56,769][root][INFO] - Training Epoch: 1/2, step 5086/7134 completed (loss: 4.195089340209961, acc: 0.23756906390190125)
[2024-12-17 02:14:56,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,167][root][INFO] - Training Epoch: 1/2, step 5087/7134 completed (loss: 3.2507333755493164, acc: 0.32972973585128784)
[2024-12-17 02:14:57,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,520][root][INFO] - Training Epoch: 1/2, step 5088/7134 completed (loss: 3.3969979286193848, acc: 0.3550295829772949)
[2024-12-17 02:14:57,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:57,888][root][INFO] - Training Epoch: 1/2, step 5089/7134 completed (loss: 3.5642731189727783, acc: 0.3469387888908386)
[2024-12-17 02:14:57,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,266][root][INFO] - Training Epoch: 1/2, step 5090/7134 completed (loss: 3.7009787559509277, acc: 0.2864077687263489)
[2024-12-17 02:14:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:58,679][root][INFO] - Training Epoch: 1/2, step 5091/7134 completed (loss: 3.7382543087005615, acc: 0.34065935015678406)
[2024-12-17 02:14:58,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,037][root][INFO] - Training Epoch: 1/2, step 5092/7134 completed (loss: 3.4571404457092285, acc: 0.30434781312942505)
[2024-12-17 02:14:59,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,414][root][INFO] - Training Epoch: 1/2, step 5093/7134 completed (loss: 3.6058664321899414, acc: 0.2954545319080353)
[2024-12-17 02:14:59,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:14:59,774][root][INFO] - Training Epoch: 1/2, step 5094/7134 completed (loss: 3.4795875549316406, acc: 0.2846153974533081)
[2024-12-17 02:14:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,109][root][INFO] - Training Epoch: 1/2, step 5095/7134 completed (loss: 3.2938177585601807, acc: 0.35668790340423584)
[2024-12-17 02:15:00,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,489][root][INFO] - Training Epoch: 1/2, step 5096/7134 completed (loss: 3.230905294418335, acc: 0.4095744788646698)
[2024-12-17 02:15:00,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:00,860][root][INFO] - Training Epoch: 1/2, step 5097/7134 completed (loss: 3.79602313041687, acc: 0.32085561752319336)
[2024-12-17 02:15:00,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,239][root][INFO] - Training Epoch: 1/2, step 5098/7134 completed (loss: 3.7550437450408936, acc: 0.31122449040412903)
[2024-12-17 02:15:01,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,608][root][INFO] - Training Epoch: 1/2, step 5099/7134 completed (loss: 3.5841307640075684, acc: 0.3492063581943512)
[2024-12-17 02:15:01,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:01,978][root][INFO] - Training Epoch: 1/2, step 5100/7134 completed (loss: 3.357125997543335, acc: 0.3578431308269501)
[2024-12-17 02:15:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,347][root][INFO] - Training Epoch: 1/2, step 5101/7134 completed (loss: 3.1119019985198975, acc: 0.3664921522140503)
[2024-12-17 02:15:02,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:02,731][root][INFO] - Training Epoch: 1/2, step 5102/7134 completed (loss: 3.3538877964019775, acc: 0.32926830649375916)
[2024-12-17 02:15:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,110][root][INFO] - Training Epoch: 1/2, step 5103/7134 completed (loss: 3.515716791152954, acc: 0.3857142925262451)
[2024-12-17 02:15:03,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,497][root][INFO] - Training Epoch: 1/2, step 5104/7134 completed (loss: 3.3825767040252686, acc: 0.410526305437088)
[2024-12-17 02:15:03,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:03,852][root][INFO] - Training Epoch: 1/2, step 5105/7134 completed (loss: 3.5724904537200928, acc: 0.3708609342575073)
[2024-12-17 02:15:03,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,187][root][INFO] - Training Epoch: 1/2, step 5106/7134 completed (loss: 4.243357181549072, acc: 0.30136987566947937)
[2024-12-17 02:15:04,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,575][root][INFO] - Training Epoch: 1/2, step 5107/7134 completed (loss: 4.095687389373779, acc: 0.29931971430778503)
[2024-12-17 02:15:04,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:04,948][root][INFO] - Training Epoch: 1/2, step 5108/7134 completed (loss: 4.4753804206848145, acc: 0.29078012704849243)
[2024-12-17 02:15:05,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,336][root][INFO] - Training Epoch: 1/2, step 5109/7134 completed (loss: 4.422408103942871, acc: 0.3065326511859894)
[2024-12-17 02:15:05,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:05,722][root][INFO] - Training Epoch: 1/2, step 5110/7134 completed (loss: 3.7115113735198975, acc: 0.37362638115882874)
[2024-12-17 02:15:05,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,080][root][INFO] - Training Epoch: 1/2, step 5111/7134 completed (loss: 3.727776527404785, acc: 0.3103448152542114)
[2024-12-17 02:15:06,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,461][root][INFO] - Training Epoch: 1/2, step 5112/7134 completed (loss: 3.6110684871673584, acc: 0.29729729890823364)
[2024-12-17 02:15:06,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:06,832][root][INFO] - Training Epoch: 1/2, step 5113/7134 completed (loss: 3.76106595993042, acc: 0.29801324009895325)
[2024-12-17 02:15:06,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,203][root][INFO] - Training Epoch: 1/2, step 5114/7134 completed (loss: 3.6319119930267334, acc: 0.33112582564353943)
[2024-12-17 02:15:07,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,570][root][INFO] - Training Epoch: 1/2, step 5115/7134 completed (loss: 3.291504144668579, acc: 0.380952388048172)
[2024-12-17 02:15:07,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:07,953][root][INFO] - Training Epoch: 1/2, step 5116/7134 completed (loss: 3.507038116455078, acc: 0.37037035822868347)
[2024-12-17 02:15:08,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,319][root][INFO] - Training Epoch: 1/2, step 5117/7134 completed (loss: 3.401033401489258, acc: 0.37569060921669006)
[2024-12-17 02:15:08,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:08,669][root][INFO] - Training Epoch: 1/2, step 5118/7134 completed (loss: 3.5370213985443115, acc: 0.3072289228439331)
[2024-12-17 02:15:08,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,022][root][INFO] - Training Epoch: 1/2, step 5119/7134 completed (loss: 3.5387706756591797, acc: 0.3218390941619873)
[2024-12-17 02:15:09,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,400][root][INFO] - Training Epoch: 1/2, step 5120/7134 completed (loss: 3.494891881942749, acc: 0.32804232835769653)
[2024-12-17 02:15:09,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:09,778][root][INFO] - Training Epoch: 1/2, step 5121/7134 completed (loss: 3.8590853214263916, acc: 0.3272727131843567)
[2024-12-17 02:15:09,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,144][root][INFO] - Training Epoch: 1/2, step 5122/7134 completed (loss: 3.630058526992798, acc: 0.30813953280448914)
[2024-12-17 02:15:10,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,508][root][INFO] - Training Epoch: 1/2, step 5123/7134 completed (loss: 3.2094566822052, acc: 0.3465346395969391)
[2024-12-17 02:15:10,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:10,876][root][INFO] - Training Epoch: 1/2, step 5124/7134 completed (loss: 3.3933873176574707, acc: 0.39408865571022034)
[2024-12-17 02:15:10,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,263][root][INFO] - Training Epoch: 1/2, step 5125/7134 completed (loss: 3.3139448165893555, acc: 0.3137255012989044)
[2024-12-17 02:15:11,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,645][root][INFO] - Training Epoch: 1/2, step 5126/7134 completed (loss: 3.489140510559082, acc: 0.3379310369491577)
[2024-12-17 02:15:11,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:11,998][root][INFO] - Training Epoch: 1/2, step 5127/7134 completed (loss: 3.6390509605407715, acc: 0.29885056614875793)
[2024-12-17 02:15:12,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,351][root][INFO] - Training Epoch: 1/2, step 5128/7134 completed (loss: 3.6781487464904785, acc: 0.26293104887008667)
[2024-12-17 02:15:12,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:12,716][root][INFO] - Training Epoch: 1/2, step 5129/7134 completed (loss: 3.18407940864563, acc: 0.39534884691238403)
[2024-12-17 02:15:12,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,100][root][INFO] - Training Epoch: 1/2, step 5130/7134 completed (loss: 3.303438663482666, acc: 0.4220779240131378)
[2024-12-17 02:15:13,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,481][root][INFO] - Training Epoch: 1/2, step 5131/7134 completed (loss: 3.5324652194976807, acc: 0.29487180709838867)
[2024-12-17 02:15:13,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:13,824][root][INFO] - Training Epoch: 1/2, step 5132/7134 completed (loss: 3.903911590576172, acc: 0.2734375)
[2024-12-17 02:15:13,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,154][root][INFO] - Training Epoch: 1/2, step 5133/7134 completed (loss: 3.992168426513672, acc: 0.29878050088882446)
[2024-12-17 02:15:14,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,532][root][INFO] - Training Epoch: 1/2, step 5134/7134 completed (loss: 3.3731276988983154, acc: 0.3695652186870575)
[2024-12-17 02:15:14,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:14,891][root][INFO] - Training Epoch: 1/2, step 5135/7134 completed (loss: 3.467365264892578, acc: 0.38728323578834534)
[2024-12-17 02:15:15,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,244][root][INFO] - Training Epoch: 1/2, step 5136/7134 completed (loss: 3.6781439781188965, acc: 0.31182795763015747)
[2024-12-17 02:15:15,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,609][root][INFO] - Training Epoch: 1/2, step 5137/7134 completed (loss: 3.245166778564453, acc: 0.3695652186870575)
[2024-12-17 02:15:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:15,964][root][INFO] - Training Epoch: 1/2, step 5138/7134 completed (loss: 3.9079015254974365, acc: 0.3085106313228607)
[2024-12-17 02:15:16,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,313][root][INFO] - Training Epoch: 1/2, step 5139/7134 completed (loss: 3.3067572116851807, acc: 0.3764705955982208)
[2024-12-17 02:15:16,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:16,703][root][INFO] - Training Epoch: 1/2, step 5140/7134 completed (loss: 3.7755932807922363, acc: 0.27916666865348816)
[2024-12-17 02:15:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,091][root][INFO] - Training Epoch: 1/2, step 5141/7134 completed (loss: 3.564908027648926, acc: 0.32786884903907776)
[2024-12-17 02:15:17,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,476][root][INFO] - Training Epoch: 1/2, step 5142/7134 completed (loss: 3.3403213024139404, acc: 0.323383092880249)
[2024-12-17 02:15:17,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:17,841][root][INFO] - Training Epoch: 1/2, step 5143/7134 completed (loss: 3.411214828491211, acc: 0.35820895433425903)
[2024-12-17 02:15:17,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,252][root][INFO] - Training Epoch: 1/2, step 5144/7134 completed (loss: 4.0035014152526855, acc: 0.30158731341362)
[2024-12-17 02:15:18,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:18,644][root][INFO] - Training Epoch: 1/2, step 5145/7134 completed (loss: 3.846827507019043, acc: 0.296875)
[2024-12-17 02:15:18,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,009][root][INFO] - Training Epoch: 1/2, step 5146/7134 completed (loss: 4.131006240844727, acc: 0.30054643750190735)
[2024-12-17 02:15:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,384][root][INFO] - Training Epoch: 1/2, step 5147/7134 completed (loss: 4.123988151550293, acc: 0.3333333432674408)
[2024-12-17 02:15:19,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:19,739][root][INFO] - Training Epoch: 1/2, step 5148/7134 completed (loss: 4.414324760437012, acc: 0.26249998807907104)
[2024-12-17 02:15:19,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,112][root][INFO] - Training Epoch: 1/2, step 5149/7134 completed (loss: 3.870298147201538, acc: 0.3031674325466156)
[2024-12-17 02:15:20,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,490][root][INFO] - Training Epoch: 1/2, step 5150/7134 completed (loss: 3.837460517883301, acc: 0.31736525893211365)
[2024-12-17 02:15:20,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:20,898][root][INFO] - Training Epoch: 1/2, step 5151/7134 completed (loss: 4.402260780334473, acc: 0.2800000011920929)
[2024-12-17 02:15:21,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,286][root][INFO] - Training Epoch: 1/2, step 5152/7134 completed (loss: 4.172230243682861, acc: 0.2764706015586853)
[2024-12-17 02:15:21,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:21,682][root][INFO] - Training Epoch: 1/2, step 5153/7134 completed (loss: 4.8417463302612305, acc: 0.26143792271614075)
[2024-12-17 02:15:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,051][root][INFO] - Training Epoch: 1/2, step 5154/7134 completed (loss: 4.016874313354492, acc: 0.25999999046325684)
[2024-12-17 02:15:22,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,416][root][INFO] - Training Epoch: 1/2, step 5155/7134 completed (loss: 4.123302936553955, acc: 0.31386861205101013)
[2024-12-17 02:15:22,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:22,811][root][INFO] - Training Epoch: 1/2, step 5156/7134 completed (loss: 3.7869350910186768, acc: 0.31481480598449707)
[2024-12-17 02:15:22,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,186][root][INFO] - Training Epoch: 1/2, step 5157/7134 completed (loss: 4.177149295806885, acc: 0.27840909361839294)
[2024-12-17 02:15:23,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,573][root][INFO] - Training Epoch: 1/2, step 5158/7134 completed (loss: 3.894150972366333, acc: 0.2371794879436493)
[2024-12-17 02:15:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:23,945][root][INFO] - Training Epoch: 1/2, step 5159/7134 completed (loss: 4.192763328552246, acc: 0.21212121844291687)
[2024-12-17 02:15:24,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,309][root][INFO] - Training Epoch: 1/2, step 5160/7134 completed (loss: 4.055091857910156, acc: 0.2611111104488373)
[2024-12-17 02:15:24,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:24,681][root][INFO] - Training Epoch: 1/2, step 5161/7134 completed (loss: 3.8237767219543457, acc: 0.301075279712677)
[2024-12-17 02:15:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,052][root][INFO] - Training Epoch: 1/2, step 5162/7134 completed (loss: 3.6271047592163086, acc: 0.36571428179740906)
[2024-12-17 02:15:25,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,417][root][INFO] - Training Epoch: 1/2, step 5163/7134 completed (loss: 3.5024490356445312, acc: 0.3333333432674408)
[2024-12-17 02:15:25,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:25,800][root][INFO] - Training Epoch: 1/2, step 5164/7134 completed (loss: 3.5449042320251465, acc: 0.3290322721004486)
[2024-12-17 02:15:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,173][root][INFO] - Training Epoch: 1/2, step 5165/7134 completed (loss: 3.7937254905700684, acc: 0.27878788113594055)
[2024-12-17 02:15:26,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,523][root][INFO] - Training Epoch: 1/2, step 5166/7134 completed (loss: 3.9862592220306396, acc: 0.31481480598449707)
[2024-12-17 02:15:26,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:26,876][root][INFO] - Training Epoch: 1/2, step 5167/7134 completed (loss: 3.576077699661255, acc: 0.31491711735725403)
[2024-12-17 02:15:26,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,250][root][INFO] - Training Epoch: 1/2, step 5168/7134 completed (loss: 3.9041266441345215, acc: 0.3372093141078949)
[2024-12-17 02:15:27,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:27,633][root][INFO] - Training Epoch: 1/2, step 5169/7134 completed (loss: 3.649146795272827, acc: 0.2926829159259796)
[2024-12-17 02:15:27,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,001][root][INFO] - Training Epoch: 1/2, step 5170/7134 completed (loss: 3.6913363933563232, acc: 0.3212435245513916)
[2024-12-17 02:15:28,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,337][root][INFO] - Training Epoch: 1/2, step 5171/7134 completed (loss: 3.624621868133545, acc: 0.28455284237861633)
[2024-12-17 02:15:28,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:28,722][root][INFO] - Training Epoch: 1/2, step 5172/7134 completed (loss: 3.735255479812622, acc: 0.353658527135849)
[2024-12-17 02:15:28,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,102][root][INFO] - Training Epoch: 1/2, step 5173/7134 completed (loss: 3.5161361694335938, acc: 0.4110429584980011)
[2024-12-17 02:15:29,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,479][root][INFO] - Training Epoch: 1/2, step 5174/7134 completed (loss: 3.733062505722046, acc: 0.2774566411972046)
[2024-12-17 02:15:29,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:29,855][root][INFO] - Training Epoch: 1/2, step 5175/7134 completed (loss: 4.027070999145508, acc: 0.257485032081604)
[2024-12-17 02:15:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,201][root][INFO] - Training Epoch: 1/2, step 5176/7134 completed (loss: 3.892443895339966, acc: 0.29605263471603394)
[2024-12-17 02:15:30,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,592][root][INFO] - Training Epoch: 1/2, step 5177/7134 completed (loss: 3.775364875793457, acc: 0.3199999928474426)
[2024-12-17 02:15:30,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:30,952][root][INFO] - Training Epoch: 1/2, step 5178/7134 completed (loss: 3.3464953899383545, acc: 0.3866666555404663)
[2024-12-17 02:15:31,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,330][root][INFO] - Training Epoch: 1/2, step 5179/7134 completed (loss: 4.200681209564209, acc: 0.2976190447807312)
[2024-12-17 02:15:31,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:31,698][root][INFO] - Training Epoch: 1/2, step 5180/7134 completed (loss: 4.452986717224121, acc: 0.26950353384017944)
[2024-12-17 02:15:31,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,052][root][INFO] - Training Epoch: 1/2, step 5181/7134 completed (loss: 4.601772785186768, acc: 0.17977528274059296)
[2024-12-17 02:15:32,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,421][root][INFO] - Training Epoch: 1/2, step 5182/7134 completed (loss: 4.755887508392334, acc: 0.22834645211696625)
[2024-12-17 02:15:32,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:32,779][root][INFO] - Training Epoch: 1/2, step 5183/7134 completed (loss: 3.6671509742736816, acc: 0.3014705777168274)
[2024-12-17 02:15:32,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,127][root][INFO] - Training Epoch: 1/2, step 5184/7134 completed (loss: 3.200596809387207, acc: 0.375)
[2024-12-17 02:15:33,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,478][root][INFO] - Training Epoch: 1/2, step 5185/7134 completed (loss: 3.2541065216064453, acc: 0.3366336524486542)
[2024-12-17 02:15:33,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:33,853][root][INFO] - Training Epoch: 1/2, step 5186/7134 completed (loss: 3.4726366996765137, acc: 0.3779527544975281)
[2024-12-17 02:15:33,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,233][root][INFO] - Training Epoch: 1/2, step 5187/7134 completed (loss: 3.8378944396972656, acc: 0.24799999594688416)
[2024-12-17 02:15:34,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,615][root][INFO] - Training Epoch: 1/2, step 5188/7134 completed (loss: 3.481724500656128, acc: 0.37681159377098083)
[2024-12-17 02:15:34,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:34,995][root][INFO] - Training Epoch: 1/2, step 5189/7134 completed (loss: 3.20766544342041, acc: 0.3861386179924011)
[2024-12-17 02:15:35,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,387][root][INFO] - Training Epoch: 1/2, step 5190/7134 completed (loss: 3.2997922897338867, acc: 0.38181817531585693)
[2024-12-17 02:15:35,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:35,765][root][INFO] - Training Epoch: 1/2, step 5191/7134 completed (loss: 3.8089704513549805, acc: 0.3641975224018097)
[2024-12-17 02:15:35,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,182][root][INFO] - Training Epoch: 1/2, step 5192/7134 completed (loss: 3.6229865550994873, acc: 0.34343433380126953)
[2024-12-17 02:15:36,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,521][root][INFO] - Training Epoch: 1/2, step 5193/7134 completed (loss: 3.370708703994751, acc: 0.4000000059604645)
[2024-12-17 02:15:36,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:36,886][root][INFO] - Training Epoch: 1/2, step 5194/7134 completed (loss: 3.436570167541504, acc: 0.4394904375076294)
[2024-12-17 02:15:36,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,229][root][INFO] - Training Epoch: 1/2, step 5195/7134 completed (loss: 4.455490589141846, acc: 0.2222222238779068)
[2024-12-17 02:15:37,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,585][root][INFO] - Training Epoch: 1/2, step 5196/7134 completed (loss: 3.673405408859253, acc: 0.3100000023841858)
[2024-12-17 02:15:37,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:37,951][root][INFO] - Training Epoch: 1/2, step 5197/7134 completed (loss: 3.950897455215454, acc: 0.3174603283405304)
[2024-12-17 02:15:38,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,289][root][INFO] - Training Epoch: 1/2, step 5198/7134 completed (loss: 4.4653143882751465, acc: 0.2704918086528778)
[2024-12-17 02:15:38,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:38,677][root][INFO] - Training Epoch: 1/2, step 5199/7134 completed (loss: 4.073070049285889, acc: 0.302325576543808)
[2024-12-17 02:15:38,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,063][root][INFO] - Training Epoch: 1/2, step 5200/7134 completed (loss: 3.484095573425293, acc: 0.3571428656578064)
[2024-12-17 02:15:39,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,444][root][INFO] - Training Epoch: 1/2, step 5201/7134 completed (loss: 3.616337537765503, acc: 0.3864734172821045)
[2024-12-17 02:15:39,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:39,822][root][INFO] - Training Epoch: 1/2, step 5202/7134 completed (loss: 3.901667594909668, acc: 0.2916666567325592)
[2024-12-17 02:15:39,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,191][root][INFO] - Training Epoch: 1/2, step 5203/7134 completed (loss: 3.1942567825317383, acc: 0.3956044018268585)
[2024-12-17 02:15:40,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,510][root][INFO] - Training Epoch: 1/2, step 5204/7134 completed (loss: 3.755859851837158, acc: 0.3360655605792999)
[2024-12-17 02:15:40,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:40,864][root][INFO] - Training Epoch: 1/2, step 5205/7134 completed (loss: 3.433781385421753, acc: 0.3253012001514435)
[2024-12-17 02:15:40,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,247][root][INFO] - Training Epoch: 1/2, step 5206/7134 completed (loss: 3.3297343254089355, acc: 0.3684210479259491)
[2024-12-17 02:15:41,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,578][root][INFO] - Training Epoch: 1/2, step 5207/7134 completed (loss: 3.7972612380981445, acc: 0.3571428656578064)
[2024-12-17 02:15:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:41,963][root][INFO] - Training Epoch: 1/2, step 5208/7134 completed (loss: 3.3866586685180664, acc: 0.3850574791431427)
[2024-12-17 02:15:42,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,343][root][INFO] - Training Epoch: 1/2, step 5209/7134 completed (loss: 3.7581310272216797, acc: 0.36090224981307983)
[2024-12-17 02:15:42,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:42,719][root][INFO] - Training Epoch: 1/2, step 5210/7134 completed (loss: 3.6875462532043457, acc: 0.34319525957107544)
[2024-12-17 02:15:42,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,079][root][INFO] - Training Epoch: 1/2, step 5211/7134 completed (loss: 3.353658437728882, acc: 0.3650793731212616)
[2024-12-17 02:15:43,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,468][root][INFO] - Training Epoch: 1/2, step 5212/7134 completed (loss: 3.1744368076324463, acc: 0.37662336230278015)
[2024-12-17 02:15:43,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:43,831][root][INFO] - Training Epoch: 1/2, step 5213/7134 completed (loss: 3.404829263687134, acc: 0.395061731338501)
[2024-12-17 02:15:43,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,185][root][INFO] - Training Epoch: 1/2, step 5214/7134 completed (loss: 4.089145183563232, acc: 0.31092438101768494)
[2024-12-17 02:15:44,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,549][root][INFO] - Training Epoch: 1/2, step 5215/7134 completed (loss: 3.8589701652526855, acc: 0.2970297038555145)
[2024-12-17 02:15:44,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:44,911][root][INFO] - Training Epoch: 1/2, step 5216/7134 completed (loss: 3.834787130355835, acc: 0.4027777910232544)
[2024-12-17 02:15:45,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,329][root][INFO] - Training Epoch: 1/2, step 5217/7134 completed (loss: 3.668440818786621, acc: 0.42391303181648254)
[2024-12-17 02:15:45,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,634][root][INFO] - Training Epoch: 1/2, step 5218/7134 completed (loss: 3.967287540435791, acc: 0.3861386179924011)
[2024-12-17 02:15:45,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:45,968][root][INFO] - Training Epoch: 1/2, step 5219/7134 completed (loss: 3.519303321838379, acc: 0.4166666567325592)
[2024-12-17 02:15:46,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,365][root][INFO] - Training Epoch: 1/2, step 5220/7134 completed (loss: 3.3963582515716553, acc: 0.34246575832366943)
[2024-12-17 02:15:46,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:46,735][root][INFO] - Training Epoch: 1/2, step 5221/7134 completed (loss: 3.5712032318115234, acc: 0.34567901492118835)
[2024-12-17 02:15:46,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,105][root][INFO] - Training Epoch: 1/2, step 5222/7134 completed (loss: 3.402284860610962, acc: 0.3214285671710968)
[2024-12-17 02:15:47,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,493][root][INFO] - Training Epoch: 1/2, step 5223/7134 completed (loss: 2.9701390266418457, acc: 0.36283186078071594)
[2024-12-17 02:15:47,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:47,824][root][INFO] - Training Epoch: 1/2, step 5224/7134 completed (loss: 3.403233289718628, acc: 0.3629629611968994)
[2024-12-17 02:15:47,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,192][root][INFO] - Training Epoch: 1/2, step 5225/7134 completed (loss: 3.536376476287842, acc: 0.28947368264198303)
[2024-12-17 02:15:48,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,605][root][INFO] - Training Epoch: 1/2, step 5226/7134 completed (loss: 3.344022750854492, acc: 0.3589743673801422)
[2024-12-17 02:15:48,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:48,989][root][INFO] - Training Epoch: 1/2, step 5227/7134 completed (loss: 3.693387031555176, acc: 0.2974359095096588)
[2024-12-17 02:15:49,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,354][root][INFO] - Training Epoch: 1/2, step 5228/7134 completed (loss: 3.999858856201172, acc: 0.2685714364051819)
[2024-12-17 02:15:49,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:49,749][root][INFO] - Training Epoch: 1/2, step 5229/7134 completed (loss: 3.770392894744873, acc: 0.2774193584918976)
[2024-12-17 02:15:49,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,121][root][INFO] - Training Epoch: 1/2, step 5230/7134 completed (loss: 3.9043822288513184, acc: 0.2596684992313385)
[2024-12-17 02:15:50,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,501][root][INFO] - Training Epoch: 1/2, step 5231/7134 completed (loss: 3.676525115966797, acc: 0.24226804077625275)
[2024-12-17 02:15:50,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:50,863][root][INFO] - Training Epoch: 1/2, step 5232/7134 completed (loss: 3.4660444259643555, acc: 0.31073445081710815)
[2024-12-17 02:15:50,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,303][root][INFO] - Training Epoch: 1/2, step 5233/7134 completed (loss: 3.745656728744507, acc: 0.26605504751205444)
[2024-12-17 02:15:51,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:51,677][root][INFO] - Training Epoch: 1/2, step 5234/7134 completed (loss: 3.9931280612945557, acc: 0.2684210538864136)
[2024-12-17 02:15:51,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,051][root][INFO] - Training Epoch: 1/2, step 5235/7134 completed (loss: 3.796471357345581, acc: 0.23648647964000702)
[2024-12-17 02:15:52,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,416][root][INFO] - Training Epoch: 1/2, step 5236/7134 completed (loss: 3.108856201171875, acc: 0.32116788625717163)
[2024-12-17 02:15:52,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:52,813][root][INFO] - Training Epoch: 1/2, step 5237/7134 completed (loss: 3.6534996032714844, acc: 0.26760563254356384)
[2024-12-17 02:15:52,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,199][root][INFO] - Training Epoch: 1/2, step 5238/7134 completed (loss: 3.723735809326172, acc: 0.2761194109916687)
[2024-12-17 02:15:53,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,549][root][INFO] - Training Epoch: 1/2, step 5239/7134 completed (loss: 3.2235732078552246, acc: 0.3361344635486603)
[2024-12-17 02:15:53,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:53,931][root][INFO] - Training Epoch: 1/2, step 5240/7134 completed (loss: 3.9724326133728027, acc: 0.27906978130340576)
[2024-12-17 02:15:54,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,348][root][INFO] - Training Epoch: 1/2, step 5241/7134 completed (loss: 3.8381600379943848, acc: 0.28387096524238586)
[2024-12-17 02:15:54,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:54,731][root][INFO] - Training Epoch: 1/2, step 5242/7134 completed (loss: 3.5206151008605957, acc: 0.31578946113586426)
[2024-12-17 02:15:54,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,091][root][INFO] - Training Epoch: 1/2, step 5243/7134 completed (loss: 3.427713632583618, acc: 0.27142858505249023)
[2024-12-17 02:15:55,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,424][root][INFO] - Training Epoch: 1/2, step 5244/7134 completed (loss: 3.7891974449157715, acc: 0.29651162028312683)
[2024-12-17 02:15:55,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:55,802][root][INFO] - Training Epoch: 1/2, step 5245/7134 completed (loss: 4.105472087860107, acc: 0.3253968358039856)
[2024-12-17 02:15:55,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,168][root][INFO] - Training Epoch: 1/2, step 5246/7134 completed (loss: 4.031717300415039, acc: 0.29113924503326416)
[2024-12-17 02:15:56,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,541][root][INFO] - Training Epoch: 1/2, step 5247/7134 completed (loss: 3.7462241649627686, acc: 0.27407407760620117)
[2024-12-17 02:15:56,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:56,901][root][INFO] - Training Epoch: 1/2, step 5248/7134 completed (loss: 3.872011423110962, acc: 0.28244274854660034)
[2024-12-17 02:15:57,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,262][root][INFO] - Training Epoch: 1/2, step 5249/7134 completed (loss: 3.5893402099609375, acc: 0.35031846165657043)
[2024-12-17 02:15:57,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:57,638][root][INFO] - Training Epoch: 1/2, step 5250/7134 completed (loss: 3.9695191383361816, acc: 0.2663043439388275)
[2024-12-17 02:15:57,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,022][root][INFO] - Training Epoch: 1/2, step 5251/7134 completed (loss: 4.1994452476501465, acc: 0.2864583432674408)
[2024-12-17 02:15:58,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,366][root][INFO] - Training Epoch: 1/2, step 5252/7134 completed (loss: 3.697488784790039, acc: 0.38053098320961)
[2024-12-17 02:15:58,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:58,752][root][INFO] - Training Epoch: 1/2, step 5253/7134 completed (loss: 3.4957025051116943, acc: 0.3333333432674408)
[2024-12-17 02:15:58,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,142][root][INFO] - Training Epoch: 1/2, step 5254/7134 completed (loss: 4.167318344116211, acc: 0.279720276594162)
[2024-12-17 02:15:59,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,504][root][INFO] - Training Epoch: 1/2, step 5255/7134 completed (loss: 3.67935848236084, acc: 0.2931034564971924)
[2024-12-17 02:15:59,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:15:59,907][root][INFO] - Training Epoch: 1/2, step 5256/7134 completed (loss: 3.9306559562683105, acc: 0.25999999046325684)
[2024-12-17 02:16:00,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,298][root][INFO] - Training Epoch: 1/2, step 5257/7134 completed (loss: 3.9938669204711914, acc: 0.329341322183609)
[2024-12-17 02:16:00,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:00,669][root][INFO] - Training Epoch: 1/2, step 5258/7134 completed (loss: 4.204423427581787, acc: 0.24867725372314453)
[2024-12-17 02:16:00,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,062][root][INFO] - Training Epoch: 1/2, step 5259/7134 completed (loss: 4.452110290527344, acc: 0.28057554364204407)
[2024-12-17 02:16:01,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,426][root][INFO] - Training Epoch: 1/2, step 5260/7134 completed (loss: 4.208781719207764, acc: 0.25925925374031067)
[2024-12-17 02:16:01,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:01,789][root][INFO] - Training Epoch: 1/2, step 5261/7134 completed (loss: 4.432542324066162, acc: 0.25874125957489014)
[2024-12-17 02:16:01,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,155][root][INFO] - Training Epoch: 1/2, step 5262/7134 completed (loss: 4.18949556350708, acc: 0.2530120611190796)
[2024-12-17 02:16:02,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,518][root][INFO] - Training Epoch: 1/2, step 5263/7134 completed (loss: 4.093886852264404, acc: 0.30281689763069153)
[2024-12-17 02:16:02,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:02,905][root][INFO] - Training Epoch: 1/2, step 5264/7134 completed (loss: 3.8750362396240234, acc: 0.2908163368701935)
[2024-12-17 02:16:03,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,268][root][INFO] - Training Epoch: 1/2, step 5265/7134 completed (loss: 4.003628253936768, acc: 0.284153014421463)
[2024-12-17 02:16:03,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,629][root][INFO] - Training Epoch: 1/2, step 5266/7134 completed (loss: 3.817645788192749, acc: 0.2839506268501282)
[2024-12-17 02:16:03,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:03,997][root][INFO] - Training Epoch: 1/2, step 5267/7134 completed (loss: 4.469452857971191, acc: 0.25925925374031067)
[2024-12-17 02:16:04,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,370][root][INFO] - Training Epoch: 1/2, step 5268/7134 completed (loss: 4.322017192840576, acc: 0.2945736348628998)
[2024-12-17 02:16:04,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:04,739][root][INFO] - Training Epoch: 1/2, step 5269/7134 completed (loss: 4.213245868682861, acc: 0.27142858505249023)
[2024-12-17 02:16:04,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,133][root][INFO] - Training Epoch: 1/2, step 5270/7134 completed (loss: 3.9538893699645996, acc: 0.2586206793785095)
[2024-12-17 02:16:05,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,519][root][INFO] - Training Epoch: 1/2, step 5271/7134 completed (loss: 3.867760181427002, acc: 0.3309352397918701)
[2024-12-17 02:16:05,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:05,875][root][INFO] - Training Epoch: 1/2, step 5272/7134 completed (loss: 4.273410797119141, acc: 0.2947976887226105)
[2024-12-17 02:16:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,221][root][INFO] - Training Epoch: 1/2, step 5273/7134 completed (loss: 3.6627421379089355, acc: 0.3194444477558136)
[2024-12-17 02:16:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,590][root][INFO] - Training Epoch: 1/2, step 5274/7134 completed (loss: 4.140117645263672, acc: 0.26923078298568726)
[2024-12-17 02:16:06,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:06,946][root][INFO] - Training Epoch: 1/2, step 5275/7134 completed (loss: 3.5196778774261475, acc: 0.39024388790130615)
[2024-12-17 02:16:07,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,310][root][INFO] - Training Epoch: 1/2, step 5276/7134 completed (loss: 4.413308143615723, acc: 0.28947368264198303)
[2024-12-17 02:16:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:07,729][root][INFO] - Training Epoch: 1/2, step 5277/7134 completed (loss: 4.001977443695068, acc: 0.2802547812461853)
[2024-12-17 02:16:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,094][root][INFO] - Training Epoch: 1/2, step 5278/7134 completed (loss: 4.246323585510254, acc: 0.2969697117805481)
[2024-12-17 02:16:08,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,488][root][INFO] - Training Epoch: 1/2, step 5279/7134 completed (loss: 4.11577033996582, acc: 0.2520325183868408)
[2024-12-17 02:16:08,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:08,851][root][INFO] - Training Epoch: 1/2, step 5280/7134 completed (loss: 3.8942039012908936, acc: 0.30714285373687744)
[2024-12-17 02:16:08,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,218][root][INFO] - Training Epoch: 1/2, step 5281/7134 completed (loss: 3.9566030502319336, acc: 0.260869562625885)
[2024-12-17 02:16:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,587][root][INFO] - Training Epoch: 1/2, step 5282/7134 completed (loss: 4.017688274383545, acc: 0.302325576543808)
[2024-12-17 02:16:09,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:09,968][root][INFO] - Training Epoch: 1/2, step 5283/7134 completed (loss: 3.4205775260925293, acc: 0.37704917788505554)
[2024-12-17 02:16:10,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,337][root][INFO] - Training Epoch: 1/2, step 5284/7134 completed (loss: 3.8726871013641357, acc: 0.3187499940395355)
[2024-12-17 02:16:10,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:10,731][root][INFO] - Training Epoch: 1/2, step 5285/7134 completed (loss: 3.9113173484802246, acc: 0.30645161867141724)
[2024-12-17 02:16:10,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,103][root][INFO] - Training Epoch: 1/2, step 5286/7134 completed (loss: 3.883920192718506, acc: 0.3288590610027313)
[2024-12-17 02:16:11,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,497][root][INFO] - Training Epoch: 1/2, step 5287/7134 completed (loss: 3.6663880348205566, acc: 0.28787878155708313)
[2024-12-17 02:16:11,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:11,856][root][INFO] - Training Epoch: 1/2, step 5288/7134 completed (loss: 3.6697990894317627, acc: 0.33125001192092896)
[2024-12-17 02:16:11,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,233][root][INFO] - Training Epoch: 1/2, step 5289/7134 completed (loss: 3.8385984897613525, acc: 0.3011363744735718)
[2024-12-17 02:16:12,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,608][root][INFO] - Training Epoch: 1/2, step 5290/7134 completed (loss: 4.017426490783691, acc: 0.31216931343078613)
[2024-12-17 02:16:12,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:12,994][root][INFO] - Training Epoch: 1/2, step 5291/7134 completed (loss: 3.125500440597534, acc: 0.3567567467689514)
[2024-12-17 02:16:13,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,347][root][INFO] - Training Epoch: 1/2, step 5292/7134 completed (loss: 3.5994832515716553, acc: 0.3446327745914459)
[2024-12-17 02:16:13,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:13,708][root][INFO] - Training Epoch: 1/2, step 5293/7134 completed (loss: 3.5719099044799805, acc: 0.35031846165657043)
[2024-12-17 02:16:13,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,087][root][INFO] - Training Epoch: 1/2, step 5294/7134 completed (loss: 3.836599826812744, acc: 0.34319525957107544)
[2024-12-17 02:16:14,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,443][root][INFO] - Training Epoch: 1/2, step 5295/7134 completed (loss: 4.041835308074951, acc: 0.2868216931819916)
[2024-12-17 02:16:14,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:14,814][root][INFO] - Training Epoch: 1/2, step 5296/7134 completed (loss: 3.721280336380005, acc: 0.3163841664791107)
[2024-12-17 02:16:14,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,173][root][INFO] - Training Epoch: 1/2, step 5297/7134 completed (loss: 3.9972188472747803, acc: 0.28313252329826355)
[2024-12-17 02:16:15,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,540][root][INFO] - Training Epoch: 1/2, step 5298/7134 completed (loss: 4.019199371337891, acc: 0.283687949180603)
[2024-12-17 02:16:15,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:15,888][root][INFO] - Training Epoch: 1/2, step 5299/7134 completed (loss: 3.6641411781311035, acc: 0.27397260069847107)
[2024-12-17 02:16:15,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,242][root][INFO] - Training Epoch: 1/2, step 5300/7134 completed (loss: 3.6368532180786133, acc: 0.34337350726127625)
[2024-12-17 02:16:16,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,606][root][INFO] - Training Epoch: 1/2, step 5301/7134 completed (loss: 3.167614459991455, acc: 0.34756097197532654)
[2024-12-17 02:16:16,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:16,979][root][INFO] - Training Epoch: 1/2, step 5302/7134 completed (loss: 3.2390365600585938, acc: 0.3854748606681824)
[2024-12-17 02:16:17,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,378][root][INFO] - Training Epoch: 1/2, step 5303/7134 completed (loss: 4.668941497802734, acc: 0.27272728085517883)
[2024-12-17 02:16:17,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:17,764][root][INFO] - Training Epoch: 1/2, step 5304/7134 completed (loss: 4.333661079406738, acc: 0.3219178020954132)
[2024-12-17 02:16:17,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,142][root][INFO] - Training Epoch: 1/2, step 5305/7134 completed (loss: 4.313939094543457, acc: 0.3062500059604645)
[2024-12-17 02:16:18,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,506][root][INFO] - Training Epoch: 1/2, step 5306/7134 completed (loss: 3.9634897708892822, acc: 0.2944444417953491)
[2024-12-17 02:16:18,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:18,887][root][INFO] - Training Epoch: 1/2, step 5307/7134 completed (loss: 4.530280590057373, acc: 0.27485379576683044)
[2024-12-17 02:16:19,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,255][root][INFO] - Training Epoch: 1/2, step 5308/7134 completed (loss: 4.182403087615967, acc: 0.23456789553165436)
[2024-12-17 02:16:19,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,616][root][INFO] - Training Epoch: 1/2, step 5309/7134 completed (loss: 5.110392093658447, acc: 0.20279720425605774)
[2024-12-17 02:16:19,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:19,983][root][INFO] - Training Epoch: 1/2, step 5310/7134 completed (loss: 4.437828540802002, acc: 0.2954545319080353)
[2024-12-17 02:16:20,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,330][root][INFO] - Training Epoch: 1/2, step 5311/7134 completed (loss: 3.9270262718200684, acc: 0.3602484464645386)
[2024-12-17 02:16:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:20,695][root][INFO] - Training Epoch: 1/2, step 5312/7134 completed (loss: 4.304428577423096, acc: 0.2777777910232544)
[2024-12-17 02:16:20,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,082][root][INFO] - Training Epoch: 1/2, step 5313/7134 completed (loss: 4.761750221252441, acc: 0.2704918086528778)
[2024-12-17 02:16:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,444][root][INFO] - Training Epoch: 1/2, step 5314/7134 completed (loss: 4.532675266265869, acc: 0.27142858505249023)
[2024-12-17 02:16:21,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:21,825][root][INFO] - Training Epoch: 1/2, step 5315/7134 completed (loss: 4.0408406257629395, acc: 0.2517985701560974)
[2024-12-17 02:16:21,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,199][root][INFO] - Training Epoch: 1/2, step 5316/7134 completed (loss: 3.674623966217041, acc: 0.35333332419395447)
[2024-12-17 02:16:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,567][root][INFO] - Training Epoch: 1/2, step 5317/7134 completed (loss: 4.233162879943848, acc: 0.2539682686328888)
[2024-12-17 02:16:22,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:22,921][root][INFO] - Training Epoch: 1/2, step 5318/7134 completed (loss: 2.9989287853240967, acc: 0.3949044644832611)
[2024-12-17 02:16:23,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,297][root][INFO] - Training Epoch: 1/2, step 5319/7134 completed (loss: 4.143492221832275, acc: 0.27067670226097107)
[2024-12-17 02:16:23,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:23,677][root][INFO] - Training Epoch: 1/2, step 5320/7134 completed (loss: 3.86592698097229, acc: 0.35849055647850037)
[2024-12-17 02:16:23,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,042][root][INFO] - Training Epoch: 1/2, step 5321/7134 completed (loss: 4.14456033706665, acc: 0.27272728085517883)
[2024-12-17 02:16:24,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,405][root][INFO] - Training Epoch: 1/2, step 5322/7134 completed (loss: 3.6263012886047363, acc: 0.3733333349227905)
[2024-12-17 02:16:24,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:24,774][root][INFO] - Training Epoch: 1/2, step 5323/7134 completed (loss: 4.480966567993164, acc: 0.21476510167121887)
[2024-12-17 02:16:24,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,131][root][INFO] - Training Epoch: 1/2, step 5324/7134 completed (loss: 3.902250289916992, acc: 0.2763157784938812)
[2024-12-17 02:16:25,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,485][root][INFO] - Training Epoch: 1/2, step 5325/7134 completed (loss: 3.661534309387207, acc: 0.3333333432674408)
[2024-12-17 02:16:25,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:25,830][root][INFO] - Training Epoch: 1/2, step 5326/7134 completed (loss: 4.759347438812256, acc: 0.24137930572032928)
[2024-12-17 02:16:25,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,193][root][INFO] - Training Epoch: 1/2, step 5327/7134 completed (loss: 4.327015399932861, acc: 0.26451611518859863)
[2024-12-17 02:16:26,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,561][root][INFO] - Training Epoch: 1/2, step 5328/7134 completed (loss: 4.1442389488220215, acc: 0.31578946113586426)
[2024-12-17 02:16:26,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:26,906][root][INFO] - Training Epoch: 1/2, step 5329/7134 completed (loss: 4.479064464569092, acc: 0.25333333015441895)
[2024-12-17 02:16:27,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,284][root][INFO] - Training Epoch: 1/2, step 5330/7134 completed (loss: 4.381933689117432, acc: 0.23417721688747406)
[2024-12-17 02:16:27,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:27,664][root][INFO] - Training Epoch: 1/2, step 5331/7134 completed (loss: 4.614664554595947, acc: 0.2666666805744171)
[2024-12-17 02:16:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,050][root][INFO] - Training Epoch: 1/2, step 5332/7134 completed (loss: 4.265692710876465, acc: 0.2876712381839752)
[2024-12-17 02:16:28,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,426][root][INFO] - Training Epoch: 1/2, step 5333/7134 completed (loss: 4.3869853019714355, acc: 0.22368420660495758)
[2024-12-17 02:16:28,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:28,808][root][INFO] - Training Epoch: 1/2, step 5334/7134 completed (loss: 4.725232124328613, acc: 0.2571428716182709)
[2024-12-17 02:16:28,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,163][root][INFO] - Training Epoch: 1/2, step 5335/7134 completed (loss: 4.2437543869018555, acc: 0.281879186630249)
[2024-12-17 02:16:29,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,521][root][INFO] - Training Epoch: 1/2, step 5336/7134 completed (loss: 4.324570178985596, acc: 0.34507042169570923)
[2024-12-17 02:16:29,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:29,884][root][INFO] - Training Epoch: 1/2, step 5337/7134 completed (loss: 4.101303577423096, acc: 0.26635512709617615)
[2024-12-17 02:16:29,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,278][root][INFO] - Training Epoch: 1/2, step 5338/7134 completed (loss: 3.622189521789551, acc: 0.2890995144844055)
[2024-12-17 02:16:30,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:30,651][root][INFO] - Training Epoch: 1/2, step 5339/7134 completed (loss: 4.318665504455566, acc: 0.2142857164144516)
[2024-12-17 02:16:30,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,033][root][INFO] - Training Epoch: 1/2, step 5340/7134 completed (loss: 3.772435426712036, acc: 0.3557046949863434)
[2024-12-17 02:16:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,409][root][INFO] - Training Epoch: 1/2, step 5341/7134 completed (loss: 4.308401107788086, acc: 0.22499999403953552)
[2024-12-17 02:16:31,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:31,800][root][INFO] - Training Epoch: 1/2, step 5342/7134 completed (loss: 4.887318134307861, acc: 0.23157894611358643)
[2024-12-17 02:16:31,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,178][root][INFO] - Training Epoch: 1/2, step 5343/7134 completed (loss: 4.211664199829102, acc: 0.28108108043670654)
[2024-12-17 02:16:32,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,546][root][INFO] - Training Epoch: 1/2, step 5344/7134 completed (loss: 3.8980979919433594, acc: 0.33771929144859314)
[2024-12-17 02:16:32,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:32,957][root][INFO] - Training Epoch: 1/2, step 5345/7134 completed (loss: 3.8439056873321533, acc: 0.2929292917251587)
[2024-12-17 02:16:33,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,325][root][INFO] - Training Epoch: 1/2, step 5346/7134 completed (loss: 4.024877071380615, acc: 0.27981650829315186)
[2024-12-17 02:16:33,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:33,691][root][INFO] - Training Epoch: 1/2, step 5347/7134 completed (loss: 3.825782299041748, acc: 0.3709677457809448)
[2024-12-17 02:16:33,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:34,079][root][INFO] - Training Epoch: 1/2, step 5348/7134 completed (loss: 4.492408275604248, acc: 0.28313252329826355)
[2024-12-17 02:16:34,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:35,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:36,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:37,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:38,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:39,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:40,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:41,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:42,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:43,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:44,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:45,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:46,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:48,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:50,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:51,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:52,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:53,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:54,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:56,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:57,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:16:59,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:00,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:01,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:02,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:03,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:06,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:07,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:08,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:10,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:11,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:13,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:14,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:15,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:16,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:18,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:22,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:23,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:24,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:25,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:26,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:27,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:28,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:29,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:30,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:31,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:32,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:33,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:36,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:37,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:38,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:39,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:40,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:41,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:43,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:44,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:45,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:46,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:47,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:48,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:49,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:50,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:51,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:52,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:53,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:55,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:56,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:57,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:58,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:17:59,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:00,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:01,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:02,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:03,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:05,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:06,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:07,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:08,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:09,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:10,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:11,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:13,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:14,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:17,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:19,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:20,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:21,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:22,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:23,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:25,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:27,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:29,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:30,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:31,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:32,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:33,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:34,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:35,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:36,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:37,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:38,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:39,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:40,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:41,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:42,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:43,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:44,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:45,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:46,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:47,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:48,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:49,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:50,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:51,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:52,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:55,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:56,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:57,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:58,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:18:59,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:00,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:01,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:02,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:03,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:04,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:05,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:06,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:07,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:08,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:09,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:10,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:11,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:12,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:13,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:14,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:15,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:16,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:18,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:19,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:20,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:21,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:22,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:23,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:24,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:25,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:26,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:27,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:28,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:29,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:30,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:31,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:32,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:33,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:34,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:36,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:37,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:38,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:39,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:40,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:41,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:43,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:44,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:45,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:46,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:47,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:49,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:50,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:51,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:52,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:53,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:54,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:55,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:56,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:57,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:58,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:19:59,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:00,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:01,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:02,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:03,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:04,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:05,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:06,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:07,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:08,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:09,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:10,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:11,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:12,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:14,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:15,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:16,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:17,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:18,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:19,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:20,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:21,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:22,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:23,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:24,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:26,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:27,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:28,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:29,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:30,621][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(49.8412, device='cuda:0') eval_epoch_loss=tensor(3.9088, device='cuda:0') eval_epoch_acc=tensor(0.3119, device='cuda:0')
[2024-12-17 02:20:30,623][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 02:20:30,624][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:20:30,861][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_5349_loss_3.9088425636291504/model.pt
[2024-12-17 02:20:30,865][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 02:20:30,866][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.9088425636291504
[2024-12-17 02:20:30,866][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.31186443567276
[2024-12-17 02:20:31,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,293][root][INFO] - Training Epoch: 1/2, step 5349/7134 completed (loss: 3.8508458137512207, acc: 0.34857141971588135)
[2024-12-17 02:20:31,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:31,669][root][INFO] - Training Epoch: 1/2, step 5350/7134 completed (loss: 3.494002342224121, acc: 0.364705890417099)
[2024-12-17 02:20:31,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,035][root][INFO] - Training Epoch: 1/2, step 5351/7134 completed (loss: 4.1645426750183105, acc: 0.3027026951313019)
[2024-12-17 02:20:32,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,354][root][INFO] - Training Epoch: 1/2, step 5352/7134 completed (loss: 4.265284538269043, acc: 0.269461065530777)
[2024-12-17 02:20:32,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:32,715][root][INFO] - Training Epoch: 1/2, step 5353/7134 completed (loss: 4.277929306030273, acc: 0.3181818127632141)
[2024-12-17 02:20:32,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,095][root][INFO] - Training Epoch: 1/2, step 5354/7134 completed (loss: 4.150843620300293, acc: 0.30092594027519226)
[2024-12-17 02:20:33,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,452][root][INFO] - Training Epoch: 1/2, step 5355/7134 completed (loss: 4.253209590911865, acc: 0.2916666567325592)
[2024-12-17 02:20:33,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:33,831][root][INFO] - Training Epoch: 1/2, step 5356/7134 completed (loss: 4.457247734069824, acc: 0.31382977962493896)
[2024-12-17 02:20:33,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,205][root][INFO] - Training Epoch: 1/2, step 5357/7134 completed (loss: 4.136964321136475, acc: 0.27659574151039124)
[2024-12-17 02:20:34,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,573][root][INFO] - Training Epoch: 1/2, step 5358/7134 completed (loss: 4.513972759246826, acc: 0.2967033088207245)
[2024-12-17 02:20:34,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:34,939][root][INFO] - Training Epoch: 1/2, step 5359/7134 completed (loss: 4.161598205566406, acc: 0.25615763664245605)
[2024-12-17 02:20:35,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,319][root][INFO] - Training Epoch: 1/2, step 5360/7134 completed (loss: 3.8167433738708496, acc: 0.33908045291900635)
[2024-12-17 02:20:35,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:35,707][root][INFO] - Training Epoch: 1/2, step 5361/7134 completed (loss: 4.0857391357421875, acc: 0.2690355181694031)
[2024-12-17 02:20:35,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,097][root][INFO] - Training Epoch: 1/2, step 5362/7134 completed (loss: 4.154356002807617, acc: 0.2567567527294159)
[2024-12-17 02:20:36,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,471][root][INFO] - Training Epoch: 1/2, step 5363/7134 completed (loss: 4.155637264251709, acc: 0.32926830649375916)
[2024-12-17 02:20:36,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:36,848][root][INFO] - Training Epoch: 1/2, step 5364/7134 completed (loss: 4.256645202636719, acc: 0.2658959627151489)
[2024-12-17 02:20:36,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,210][root][INFO] - Training Epoch: 1/2, step 5365/7134 completed (loss: 3.8273277282714844, acc: 0.35606059432029724)
[2024-12-17 02:20:37,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,578][root][INFO] - Training Epoch: 1/2, step 5366/7134 completed (loss: 3.9575536251068115, acc: 0.2761194109916687)
[2024-12-17 02:20:37,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:37,947][root][INFO] - Training Epoch: 1/2, step 5367/7134 completed (loss: 4.019903659820557, acc: 0.33152174949645996)
[2024-12-17 02:20:38,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,317][root][INFO] - Training Epoch: 1/2, step 5368/7134 completed (loss: 4.038212776184082, acc: 0.3100775182247162)
[2024-12-17 02:20:38,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:38,677][root][INFO] - Training Epoch: 1/2, step 5369/7134 completed (loss: 4.013352870941162, acc: 0.2711864411830902)
[2024-12-17 02:20:38,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,039][root][INFO] - Training Epoch: 1/2, step 5370/7134 completed (loss: 3.7585222721099854, acc: 0.30519479513168335)
[2024-12-17 02:20:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,415][root][INFO] - Training Epoch: 1/2, step 5371/7134 completed (loss: 3.6931533813476562, acc: 0.3400000035762787)
[2024-12-17 02:20:39,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:39,778][root][INFO] - Training Epoch: 1/2, step 5372/7134 completed (loss: 3.3999974727630615, acc: 0.30817610025405884)
[2024-12-17 02:20:39,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,156][root][INFO] - Training Epoch: 1/2, step 5373/7134 completed (loss: 3.5729541778564453, acc: 0.3174603283405304)
[2024-12-17 02:20:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,518][root][INFO] - Training Epoch: 1/2, step 5374/7134 completed (loss: 3.81622576713562, acc: 0.3214285671710968)
[2024-12-17 02:20:40,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:40,900][root][INFO] - Training Epoch: 1/2, step 5375/7134 completed (loss: 4.074861526489258, acc: 0.25581395626068115)
[2024-12-17 02:20:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,262][root][INFO] - Training Epoch: 1/2, step 5376/7134 completed (loss: 3.3950772285461426, acc: 0.29729729890823364)
[2024-12-17 02:20:41,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:41,640][root][INFO] - Training Epoch: 1/2, step 5377/7134 completed (loss: 3.868075132369995, acc: 0.327160507440567)
[2024-12-17 02:20:41,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,009][root][INFO] - Training Epoch: 1/2, step 5378/7134 completed (loss: 3.4941534996032715, acc: 0.36315789818763733)
[2024-12-17 02:20:42,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,370][root][INFO] - Training Epoch: 1/2, step 5379/7134 completed (loss: 3.269071578979492, acc: 0.3541666567325592)
[2024-12-17 02:20:42,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:42,737][root][INFO] - Training Epoch: 1/2, step 5380/7134 completed (loss: 3.8343045711517334, acc: 0.2888889014720917)
[2024-12-17 02:20:42,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,093][root][INFO] - Training Epoch: 1/2, step 5381/7134 completed (loss: 3.4702258110046387, acc: 0.3333333432674408)
[2024-12-17 02:20:43,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,463][root][INFO] - Training Epoch: 1/2, step 5382/7134 completed (loss: 3.4833266735076904, acc: 0.3913043439388275)
[2024-12-17 02:20:43,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:43,840][root][INFO] - Training Epoch: 1/2, step 5383/7134 completed (loss: 3.0736875534057617, acc: 0.41129031777381897)
[2024-12-17 02:20:43,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,216][root][INFO] - Training Epoch: 1/2, step 5384/7134 completed (loss: 3.4238009452819824, acc: 0.32487308979034424)
[2024-12-17 02:20:44,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,578][root][INFO] - Training Epoch: 1/2, step 5385/7134 completed (loss: 3.846698045730591, acc: 0.27906978130340576)
[2024-12-17 02:20:44,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:44,966][root][INFO] - Training Epoch: 1/2, step 5386/7134 completed (loss: 3.058236837387085, acc: 0.450549453496933)
[2024-12-17 02:20:45,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,346][root][INFO] - Training Epoch: 1/2, step 5387/7134 completed (loss: 3.2912068367004395, acc: 0.35245901346206665)
[2024-12-17 02:20:45,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:45,738][root][INFO] - Training Epoch: 1/2, step 5388/7134 completed (loss: 3.526470899581909, acc: 0.33519554138183594)
[2024-12-17 02:20:45,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,114][root][INFO] - Training Epoch: 1/2, step 5389/7134 completed (loss: 3.2547683715820312, acc: 0.3945578336715698)
[2024-12-17 02:20:46,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,490][root][INFO] - Training Epoch: 1/2, step 5390/7134 completed (loss: 3.7213947772979736, acc: 0.31446540355682373)
[2024-12-17 02:20:46,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:46,844][root][INFO] - Training Epoch: 1/2, step 5391/7134 completed (loss: 3.3256916999816895, acc: 0.3741007149219513)
[2024-12-17 02:20:46,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,194][root][INFO] - Training Epoch: 1/2, step 5392/7134 completed (loss: 3.9089417457580566, acc: 0.2954545319080353)
[2024-12-17 02:20:47,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,566][root][INFO] - Training Epoch: 1/2, step 5393/7134 completed (loss: 4.127130508422852, acc: 0.28333333134651184)
[2024-12-17 02:20:47,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:47,922][root][INFO] - Training Epoch: 1/2, step 5394/7134 completed (loss: 4.522754669189453, acc: 0.3125)
[2024-12-17 02:20:48,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,281][root][INFO] - Training Epoch: 1/2, step 5395/7134 completed (loss: 4.297321319580078, acc: 0.2567567527294159)
[2024-12-17 02:20:48,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:48,666][root][INFO] - Training Epoch: 1/2, step 5396/7134 completed (loss: 4.403141975402832, acc: 0.2434210479259491)
[2024-12-17 02:20:48,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,027][root][INFO] - Training Epoch: 1/2, step 5397/7134 completed (loss: 3.598200559616089, acc: 0.3617021143436432)
[2024-12-17 02:20:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,418][root][INFO] - Training Epoch: 1/2, step 5398/7134 completed (loss: 3.9656784534454346, acc: 0.27710843086242676)
[2024-12-17 02:20:49,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:49,790][root][INFO] - Training Epoch: 1/2, step 5399/7134 completed (loss: 4.1840009689331055, acc: 0.17714285850524902)
[2024-12-17 02:20:49,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,155][root][INFO] - Training Epoch: 1/2, step 5400/7134 completed (loss: 4.272608757019043, acc: 0.2620689570903778)
[2024-12-17 02:20:50,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,537][root][INFO] - Training Epoch: 1/2, step 5401/7134 completed (loss: 3.9225950241088867, acc: 0.2708333432674408)
[2024-12-17 02:20:50,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:50,918][root][INFO] - Training Epoch: 1/2, step 5402/7134 completed (loss: 3.579793930053711, acc: 0.3493150770664215)
[2024-12-17 02:20:51,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,256][root][INFO] - Training Epoch: 1/2, step 5403/7134 completed (loss: 4.268589019775391, acc: 0.2540983557701111)
[2024-12-17 02:20:51,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:51,617][root][INFO] - Training Epoch: 1/2, step 5404/7134 completed (loss: 4.098642826080322, acc: 0.3154362440109253)
[2024-12-17 02:20:51,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,028][root][INFO] - Training Epoch: 1/2, step 5405/7134 completed (loss: 3.904304027557373, acc: 0.33043476939201355)
[2024-12-17 02:20:52,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,438][root][INFO] - Training Epoch: 1/2, step 5406/7134 completed (loss: 3.642641544342041, acc: 0.315315306186676)
[2024-12-17 02:20:52,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:52,791][root][INFO] - Training Epoch: 1/2, step 5407/7134 completed (loss: 3.839757204055786, acc: 0.3076923191547394)
[2024-12-17 02:20:52,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,163][root][INFO] - Training Epoch: 1/2, step 5408/7134 completed (loss: 4.410123348236084, acc: 0.23404255509376526)
[2024-12-17 02:20:53,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,538][root][INFO] - Training Epoch: 1/2, step 5409/7134 completed (loss: 3.8023622035980225, acc: 0.2657342553138733)
[2024-12-17 02:20:53,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:53,944][root][INFO] - Training Epoch: 1/2, step 5410/7134 completed (loss: 3.986142873764038, acc: 0.2530120611190796)
[2024-12-17 02:20:54,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,288][root][INFO] - Training Epoch: 1/2, step 5411/7134 completed (loss: 3.9489660263061523, acc: 0.2887323796749115)
[2024-12-17 02:20:54,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:54,688][root][INFO] - Training Epoch: 1/2, step 5412/7134 completed (loss: 4.118936538696289, acc: 0.3097345232963562)
[2024-12-17 02:20:54,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,078][root][INFO] - Training Epoch: 1/2, step 5413/7134 completed (loss: 4.193222999572754, acc: 0.2430555522441864)
[2024-12-17 02:20:55,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,451][root][INFO] - Training Epoch: 1/2, step 5414/7134 completed (loss: 4.203426361083984, acc: 0.28143712878227234)
[2024-12-17 02:20:55,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:55,803][root][INFO] - Training Epoch: 1/2, step 5415/7134 completed (loss: 4.1350626945495605, acc: 0.2857142984867096)
[2024-12-17 02:20:55,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,190][root][INFO] - Training Epoch: 1/2, step 5416/7134 completed (loss: 4.093047142028809, acc: 0.28342247009277344)
[2024-12-17 02:20:56,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,573][root][INFO] - Training Epoch: 1/2, step 5417/7134 completed (loss: 4.171807765960693, acc: 0.2628205120563507)
[2024-12-17 02:20:56,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:56,938][root][INFO] - Training Epoch: 1/2, step 5418/7134 completed (loss: 4.142799377441406, acc: 0.25)
[2024-12-17 02:20:57,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,316][root][INFO] - Training Epoch: 1/2, step 5419/7134 completed (loss: 4.37782096862793, acc: 0.23357664048671722)
[2024-12-17 02:20:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:57,689][root][INFO] - Training Epoch: 1/2, step 5420/7134 completed (loss: 4.214388847351074, acc: 0.31578946113586426)
[2024-12-17 02:20:57,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,074][root][INFO] - Training Epoch: 1/2, step 5421/7134 completed (loss: 4.052818775177002, acc: 0.26875001192092896)
[2024-12-17 02:20:58,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,447][root][INFO] - Training Epoch: 1/2, step 5422/7134 completed (loss: 3.558130979537964, acc: 0.3888888955116272)
[2024-12-17 02:20:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:58,803][root][INFO] - Training Epoch: 1/2, step 5423/7134 completed (loss: 3.8521931171417236, acc: 0.32499998807907104)
[2024-12-17 02:20:58,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,172][root][INFO] - Training Epoch: 1/2, step 5424/7134 completed (loss: 4.870553970336914, acc: 0.26153847575187683)
[2024-12-17 02:20:59,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,523][root][INFO] - Training Epoch: 1/2, step 5425/7134 completed (loss: 4.648201942443848, acc: 0.2109375)
[2024-12-17 02:20:59,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:20:59,890][root][INFO] - Training Epoch: 1/2, step 5426/7134 completed (loss: 4.716416835784912, acc: 0.2049180269241333)
[2024-12-17 02:21:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,299][root][INFO] - Training Epoch: 1/2, step 5427/7134 completed (loss: 4.677744388580322, acc: 0.19607843458652496)
[2024-12-17 02:21:00,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:00,684][root][INFO] - Training Epoch: 1/2, step 5428/7134 completed (loss: 4.530402183532715, acc: 0.22758620977401733)
[2024-12-17 02:21:00,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,015][root][INFO] - Training Epoch: 1/2, step 5429/7134 completed (loss: 4.166109561920166, acc: 0.2751677930355072)
[2024-12-17 02:21:01,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,388][root][INFO] - Training Epoch: 1/2, step 5430/7134 completed (loss: 4.619510173797607, acc: 0.2142857164144516)
[2024-12-17 02:21:01,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:01,738][root][INFO] - Training Epoch: 1/2, step 5431/7134 completed (loss: 4.593747615814209, acc: 0.25563910603523254)
[2024-12-17 02:21:01,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,093][root][INFO] - Training Epoch: 1/2, step 5432/7134 completed (loss: 4.2663068771362305, acc: 0.2734375)
[2024-12-17 02:21:02,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,449][root][INFO] - Training Epoch: 1/2, step 5433/7134 completed (loss: 4.806779384613037, acc: 0.20168067514896393)
[2024-12-17 02:21:02,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:02,820][root][INFO] - Training Epoch: 1/2, step 5434/7134 completed (loss: 4.284658908843994, acc: 0.2177419364452362)
[2024-12-17 02:21:02,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,197][root][INFO] - Training Epoch: 1/2, step 5435/7134 completed (loss: 4.471451282501221, acc: 0.20800000429153442)
[2024-12-17 02:21:03,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,573][root][INFO] - Training Epoch: 1/2, step 5436/7134 completed (loss: 3.9619569778442383, acc: 0.3290322721004486)
[2024-12-17 02:21:03,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:03,936][root][INFO] - Training Epoch: 1/2, step 5437/7134 completed (loss: 4.34792423248291, acc: 0.2857142984867096)
[2024-12-17 02:21:04,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,301][root][INFO] - Training Epoch: 1/2, step 5438/7134 completed (loss: 4.072739601135254, acc: 0.3166666626930237)
[2024-12-17 02:21:04,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:04,676][root][INFO] - Training Epoch: 1/2, step 5439/7134 completed (loss: 4.35878849029541, acc: 0.290909081697464)
[2024-12-17 02:21:04,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,075][root][INFO] - Training Epoch: 1/2, step 5440/7134 completed (loss: 4.5773844718933105, acc: 0.23888888955116272)
[2024-12-17 02:21:05,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,479][root][INFO] - Training Epoch: 1/2, step 5441/7134 completed (loss: 4.498370170593262, acc: 0.28108108043670654)
[2024-12-17 02:21:05,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:05,856][root][INFO] - Training Epoch: 1/2, step 5442/7134 completed (loss: 4.584370136260986, acc: 0.2380952388048172)
[2024-12-17 02:21:05,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,224][root][INFO] - Training Epoch: 1/2, step 5443/7134 completed (loss: 4.085794925689697, acc: 0.29878050088882446)
[2024-12-17 02:21:06,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:06,600][root][INFO] - Training Epoch: 1/2, step 5444/7134 completed (loss: 4.299839019775391, acc: 0.31617647409439087)
[2024-12-17 02:21:06,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,033][root][INFO] - Training Epoch: 1/2, step 5445/7134 completed (loss: 4.436634063720703, acc: 0.22794117033481598)
[2024-12-17 02:21:07,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,416][root][INFO] - Training Epoch: 1/2, step 5446/7134 completed (loss: 4.158420562744141, acc: 0.2822085916996002)
[2024-12-17 02:21:07,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:07,772][root][INFO] - Training Epoch: 1/2, step 5447/7134 completed (loss: 4.0493998527526855, acc: 0.33561643958091736)
[2024-12-17 02:21:07,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,145][root][INFO] - Training Epoch: 1/2, step 5448/7134 completed (loss: 3.959040641784668, acc: 0.2967033088207245)
[2024-12-17 02:21:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,473][root][INFO] - Training Epoch: 1/2, step 5449/7134 completed (loss: 3.9686686992645264, acc: 0.2950819730758667)
[2024-12-17 02:21:08,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:08,836][root][INFO] - Training Epoch: 1/2, step 5450/7134 completed (loss: 4.333348751068115, acc: 0.2777777910232544)
[2024-12-17 02:21:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,194][root][INFO] - Training Epoch: 1/2, step 5451/7134 completed (loss: 4.165961265563965, acc: 0.21301774680614471)
[2024-12-17 02:21:09,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,570][root][INFO] - Training Epoch: 1/2, step 5452/7134 completed (loss: 4.385518550872803, acc: 0.26035502552986145)
[2024-12-17 02:21:09,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:09,944][root][INFO] - Training Epoch: 1/2, step 5453/7134 completed (loss: 4.318394660949707, acc: 0.25)
[2024-12-17 02:21:10,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,323][root][INFO] - Training Epoch: 1/2, step 5454/7134 completed (loss: 3.9247848987579346, acc: 0.33695653080940247)
[2024-12-17 02:21:10,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:10,698][root][INFO] - Training Epoch: 1/2, step 5455/7134 completed (loss: 4.032537460327148, acc: 0.31016042828559875)
[2024-12-17 02:21:10,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,062][root][INFO] - Training Epoch: 1/2, step 5456/7134 completed (loss: 4.260495185852051, acc: 0.27419355511665344)
[2024-12-17 02:21:11,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,446][root][INFO] - Training Epoch: 1/2, step 5457/7134 completed (loss: 4.068923473358154, acc: 0.3218390941619873)
[2024-12-17 02:21:11,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:11,816][root][INFO] - Training Epoch: 1/2, step 5458/7134 completed (loss: 4.359169006347656, acc: 0.28176796436309814)
[2024-12-17 02:21:11,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,186][root][INFO] - Training Epoch: 1/2, step 5459/7134 completed (loss: 3.864287853240967, acc: 0.2699386477470398)
[2024-12-17 02:21:12,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,521][root][INFO] - Training Epoch: 1/2, step 5460/7134 completed (loss: 4.178930759429932, acc: 0.2248520702123642)
[2024-12-17 02:21:12,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:12,883][root][INFO] - Training Epoch: 1/2, step 5461/7134 completed (loss: 3.9473440647125244, acc: 0.3302752375602722)
[2024-12-17 02:21:13,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,264][root][INFO] - Training Epoch: 1/2, step 5462/7134 completed (loss: 3.881394386291504, acc: 0.349693238735199)
[2024-12-17 02:21:13,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,625][root][INFO] - Training Epoch: 1/2, step 5463/7134 completed (loss: 3.8349380493164062, acc: 0.37037035822868347)
[2024-12-17 02:21:13,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:13,992][root][INFO] - Training Epoch: 1/2, step 5464/7134 completed (loss: 4.170103549957275, acc: 0.23497267067432404)
[2024-12-17 02:21:14,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,360][root][INFO] - Training Epoch: 1/2, step 5465/7134 completed (loss: 3.597909450531006, acc: 0.28125)
[2024-12-17 02:21:14,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:14,735][root][INFO] - Training Epoch: 1/2, step 5466/7134 completed (loss: 3.6684458255767822, acc: 0.30845770239830017)
[2024-12-17 02:21:14,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,139][root][INFO] - Training Epoch: 1/2, step 5467/7134 completed (loss: 3.597928285598755, acc: 0.2587064802646637)
[2024-12-17 02:21:15,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,520][root][INFO] - Training Epoch: 1/2, step 5468/7134 completed (loss: 3.833298683166504, acc: 0.3141361176967621)
[2024-12-17 02:21:15,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:15,917][root][INFO] - Training Epoch: 1/2, step 5469/7134 completed (loss: 4.1810688972473145, acc: 0.2698412835597992)
[2024-12-17 02:21:16,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,302][root][INFO] - Training Epoch: 1/2, step 5470/7134 completed (loss: 3.648340940475464, acc: 0.28358209133148193)
[2024-12-17 02:21:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:16,756][root][INFO] - Training Epoch: 1/2, step 5471/7134 completed (loss: 3.863945722579956, acc: 0.2764706015586853)
[2024-12-17 02:21:16,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,139][root][INFO] - Training Epoch: 1/2, step 5472/7134 completed (loss: 3.95363450050354, acc: 0.2681564390659332)
[2024-12-17 02:21:17,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,511][root][INFO] - Training Epoch: 1/2, step 5473/7134 completed (loss: 3.6133615970611572, acc: 0.3030303120613098)
[2024-12-17 02:21:17,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:17,880][root][INFO] - Training Epoch: 1/2, step 5474/7134 completed (loss: 3.8143906593322754, acc: 0.27878788113594055)
[2024-12-17 02:21:17,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,252][root][INFO] - Training Epoch: 1/2, step 5475/7134 completed (loss: 3.727264881134033, acc: 0.31481480598449707)
[2024-12-17 02:21:18,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,615][root][INFO] - Training Epoch: 1/2, step 5476/7134 completed (loss: 3.607661247253418, acc: 0.3181818127632141)
[2024-12-17 02:21:18,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:18,979][root][INFO] - Training Epoch: 1/2, step 5477/7134 completed (loss: 3.4718565940856934, acc: 0.38265305757522583)
[2024-12-17 02:21:19,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,369][root][INFO] - Training Epoch: 1/2, step 5478/7134 completed (loss: 3.626493453979492, acc: 0.32592591643333435)
[2024-12-17 02:21:19,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:19,742][root][INFO] - Training Epoch: 1/2, step 5479/7134 completed (loss: 4.083662986755371, acc: 0.3310810923576355)
[2024-12-17 02:21:19,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,110][root][INFO] - Training Epoch: 1/2, step 5480/7134 completed (loss: 3.8133432865142822, acc: 0.3511904776096344)
[2024-12-17 02:21:20,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:20,498][root][INFO] - Training Epoch: 1/2, step 5481/7134 completed (loss: 3.318445920944214, acc: 0.4344262182712555)
[2024-12-17 02:21:20,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,143][root][INFO] - Training Epoch: 1/2, step 5482/7134 completed (loss: 3.8275887966156006, acc: 0.3505154550075531)
[2024-12-17 02:21:21,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,593][root][INFO] - Training Epoch: 1/2, step 5483/7134 completed (loss: 3.826552152633667, acc: 0.39393940567970276)
[2024-12-17 02:21:21,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:21,968][root][INFO] - Training Epoch: 1/2, step 5484/7134 completed (loss: 3.542947292327881, acc: 0.34567901492118835)
[2024-12-17 02:21:22,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,334][root][INFO] - Training Epoch: 1/2, step 5485/7134 completed (loss: 4.322347164154053, acc: 0.25)
[2024-12-17 02:21:22,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:22,710][root][INFO] - Training Epoch: 1/2, step 5486/7134 completed (loss: 3.804518461227417, acc: 0.3712121248245239)
[2024-12-17 02:21:22,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,072][root][INFO] - Training Epoch: 1/2, step 5487/7134 completed (loss: 3.7380387783050537, acc: 0.2857142984867096)
[2024-12-17 02:21:23,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,503][root][INFO] - Training Epoch: 1/2, step 5488/7134 completed (loss: 3.3310678005218506, acc: 0.43113771080970764)
[2024-12-17 02:21:23,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:23,905][root][INFO] - Training Epoch: 1/2, step 5489/7134 completed (loss: 4.400002479553223, acc: 0.25609755516052246)
[2024-12-17 02:21:24,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,307][root][INFO] - Training Epoch: 1/2, step 5490/7134 completed (loss: 3.9871983528137207, acc: 0.3333333432674408)
[2024-12-17 02:21:24,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:24,701][root][INFO] - Training Epoch: 1/2, step 5491/7134 completed (loss: 3.389199733734131, acc: 0.3742690086364746)
[2024-12-17 02:21:24,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,036][root][INFO] - Training Epoch: 1/2, step 5492/7134 completed (loss: 3.58640456199646, acc: 0.4029850661754608)
[2024-12-17 02:21:25,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,391][root][INFO] - Training Epoch: 1/2, step 5493/7134 completed (loss: 3.8864195346832275, acc: 0.3697916567325592)
[2024-12-17 02:21:25,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:25,755][root][INFO] - Training Epoch: 1/2, step 5494/7134 completed (loss: 3.567721366882324, acc: 0.3333333432674408)
[2024-12-17 02:21:25,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,143][root][INFO] - Training Epoch: 1/2, step 5495/7134 completed (loss: 3.7325689792633057, acc: 0.3684210479259491)
[2024-12-17 02:21:26,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,507][root][INFO] - Training Epoch: 1/2, step 5496/7134 completed (loss: 3.204267740249634, acc: 0.4444444477558136)
[2024-12-17 02:21:26,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:26,875][root][INFO] - Training Epoch: 1/2, step 5497/7134 completed (loss: 3.5638179779052734, acc: 0.3117647171020508)
[2024-12-17 02:21:27,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,255][root][INFO] - Training Epoch: 1/2, step 5498/7134 completed (loss: 3.6019575595855713, acc: 0.3085106313228607)
[2024-12-17 02:21:27,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:27,651][root][INFO] - Training Epoch: 1/2, step 5499/7134 completed (loss: 3.6483218669891357, acc: 0.36936935782432556)
[2024-12-17 02:21:27,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,048][root][INFO] - Training Epoch: 1/2, step 5500/7134 completed (loss: 3.582545757293701, acc: 0.36269429326057434)
[2024-12-17 02:21:28,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,418][root][INFO] - Training Epoch: 1/2, step 5501/7134 completed (loss: 3.5949318408966064, acc: 0.3787878751754761)
[2024-12-17 02:21:28,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:28,786][root][INFO] - Training Epoch: 1/2, step 5502/7134 completed (loss: 3.4776418209075928, acc: 0.35593220591545105)
[2024-12-17 02:21:28,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,144][root][INFO] - Training Epoch: 1/2, step 5503/7134 completed (loss: 3.9925944805145264, acc: 0.3384615480899811)
[2024-12-17 02:21:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,524][root][INFO] - Training Epoch: 1/2, step 5504/7134 completed (loss: 3.88641095161438, acc: 0.3855421543121338)
[2024-12-17 02:21:29,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:29,910][root][INFO] - Training Epoch: 1/2, step 5505/7134 completed (loss: 3.9279375076293945, acc: 0.3579545319080353)
[2024-12-17 02:21:30,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,271][root][INFO] - Training Epoch: 1/2, step 5506/7134 completed (loss: 4.123002052307129, acc: 0.3232323229312897)
[2024-12-17 02:21:30,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:30,669][root][INFO] - Training Epoch: 1/2, step 5507/7134 completed (loss: 4.409384250640869, acc: 0.2631579041481018)
[2024-12-17 02:21:30,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,032][root][INFO] - Training Epoch: 1/2, step 5508/7134 completed (loss: 3.807307720184326, acc: 0.339712917804718)
[2024-12-17 02:21:31,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,402][root][INFO] - Training Epoch: 1/2, step 5509/7134 completed (loss: 4.41721773147583, acc: 0.27014216780662537)
[2024-12-17 02:21:31,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:31,763][root][INFO] - Training Epoch: 1/2, step 5510/7134 completed (loss: 3.8167812824249268, acc: 0.32258063554763794)
[2024-12-17 02:21:31,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,139][root][INFO] - Training Epoch: 1/2, step 5511/7134 completed (loss: 4.421052932739258, acc: 0.2669903039932251)
[2024-12-17 02:21:32,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,494][root][INFO] - Training Epoch: 1/2, step 5512/7134 completed (loss: 4.250211238861084, acc: 0.2967033088207245)
[2024-12-17 02:21:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:32,872][root][INFO] - Training Epoch: 1/2, step 5513/7134 completed (loss: 4.845966339111328, acc: 0.2840236723423004)
[2024-12-17 02:21:32,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,232][root][INFO] - Training Epoch: 1/2, step 5514/7134 completed (loss: 4.40984582901001, acc: 0.25462964177131653)
[2024-12-17 02:21:33,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,565][root][INFO] - Training Epoch: 1/2, step 5515/7134 completed (loss: 4.432322025299072, acc: 0.25)
[2024-12-17 02:21:33,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:33,914][root][INFO] - Training Epoch: 1/2, step 5516/7134 completed (loss: 4.127075672149658, acc: 0.28735631704330444)
[2024-12-17 02:21:34,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,257][root][INFO] - Training Epoch: 1/2, step 5517/7134 completed (loss: 4.026045799255371, acc: 0.33519554138183594)
[2024-12-17 02:21:34,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:34,647][root][INFO] - Training Epoch: 1/2, step 5518/7134 completed (loss: 3.9819118976593018, acc: 0.2777777910232544)
[2024-12-17 02:21:34,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,018][root][INFO] - Training Epoch: 1/2, step 5519/7134 completed (loss: 4.223069190979004, acc: 0.29629629850387573)
[2024-12-17 02:21:35,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,371][root][INFO] - Training Epoch: 1/2, step 5520/7134 completed (loss: 3.808248281478882, acc: 0.3270142078399658)
[2024-12-17 02:21:35,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:35,732][root][INFO] - Training Epoch: 1/2, step 5521/7134 completed (loss: 4.121606826782227, acc: 0.30890053510665894)
[2024-12-17 02:21:35,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,104][root][INFO] - Training Epoch: 1/2, step 5522/7134 completed (loss: 4.172304630279541, acc: 0.2931937277317047)
[2024-12-17 02:21:36,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,479][root][INFO] - Training Epoch: 1/2, step 5523/7134 completed (loss: 4.156630516052246, acc: 0.2857142984867096)
[2024-12-17 02:21:36,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:36,840][root][INFO] - Training Epoch: 1/2, step 5524/7134 completed (loss: 4.301552772521973, acc: 0.3291139304637909)
[2024-12-17 02:21:36,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,219][root][INFO] - Training Epoch: 1/2, step 5525/7134 completed (loss: 4.046318054199219, acc: 0.29878050088882446)
[2024-12-17 02:21:37,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,594][root][INFO] - Training Epoch: 1/2, step 5526/7134 completed (loss: 3.906768321990967, acc: 0.3354037404060364)
[2024-12-17 02:21:37,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:37,948][root][INFO] - Training Epoch: 1/2, step 5527/7134 completed (loss: 4.558842658996582, acc: 0.2657342553138733)
[2024-12-17 02:21:38,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,307][root][INFO] - Training Epoch: 1/2, step 5528/7134 completed (loss: 3.97170090675354, acc: 0.3333333432674408)
[2024-12-17 02:21:38,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:38,662][root][INFO] - Training Epoch: 1/2, step 5529/7134 completed (loss: 3.849391222000122, acc: 0.3545454442501068)
[2024-12-17 02:21:38,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,036][root][INFO] - Training Epoch: 1/2, step 5530/7134 completed (loss: 3.8438687324523926, acc: 0.31972789764404297)
[2024-12-17 02:21:39,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,401][root][INFO] - Training Epoch: 1/2, step 5531/7134 completed (loss: 4.076660633087158, acc: 0.27108433842658997)
[2024-12-17 02:21:39,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:39,754][root][INFO] - Training Epoch: 1/2, step 5532/7134 completed (loss: 3.6355807781219482, acc: 0.38418078422546387)
[2024-12-17 02:21:39,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,126][root][INFO] - Training Epoch: 1/2, step 5533/7134 completed (loss: 3.910651683807373, acc: 0.3166666626930237)
[2024-12-17 02:21:40,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,549][root][INFO] - Training Epoch: 1/2, step 5534/7134 completed (loss: 4.097563743591309, acc: 0.2921348214149475)
[2024-12-17 02:21:40,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:40,927][root][INFO] - Training Epoch: 1/2, step 5535/7134 completed (loss: 3.8171184062957764, acc: 0.3108808398246765)
[2024-12-17 02:21:41,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,290][root][INFO] - Training Epoch: 1/2, step 5536/7134 completed (loss: 4.172388076782227, acc: 0.2786885201931)
[2024-12-17 02:21:41,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:41,669][root][INFO] - Training Epoch: 1/2, step 5537/7134 completed (loss: 3.5228240489959717, acc: 0.3448275923728943)
[2024-12-17 02:21:41,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,049][root][INFO] - Training Epoch: 1/2, step 5538/7134 completed (loss: 3.8126420974731445, acc: 0.28272250294685364)
[2024-12-17 02:21:42,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,423][root][INFO] - Training Epoch: 1/2, step 5539/7134 completed (loss: 4.284943580627441, acc: 0.2786885201931)
[2024-12-17 02:21:42,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:42,807][root][INFO] - Training Epoch: 1/2, step 5540/7134 completed (loss: 3.719987630844116, acc: 0.3012048304080963)
[2024-12-17 02:21:42,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,156][root][INFO] - Training Epoch: 1/2, step 5541/7134 completed (loss: 3.4353063106536865, acc: 0.3372093141078949)
[2024-12-17 02:21:43,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,504][root][INFO] - Training Epoch: 1/2, step 5542/7134 completed (loss: 3.4941611289978027, acc: 0.34838709235191345)
[2024-12-17 02:21:43,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:43,880][root][INFO] - Training Epoch: 1/2, step 5543/7134 completed (loss: 3.939058542251587, acc: 0.27807486057281494)
[2024-12-17 02:21:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,247][root][INFO] - Training Epoch: 1/2, step 5544/7134 completed (loss: 4.149234771728516, acc: 0.28961747884750366)
[2024-12-17 02:21:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,602][root][INFO] - Training Epoch: 1/2, step 5545/7134 completed (loss: 4.029984474182129, acc: 0.3095238208770752)
[2024-12-17 02:21:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:44,955][root][INFO] - Training Epoch: 1/2, step 5546/7134 completed (loss: 3.9257264137268066, acc: 0.341317355632782)
[2024-12-17 02:21:45,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,340][root][INFO] - Training Epoch: 1/2, step 5547/7134 completed (loss: 3.8414103984832764, acc: 0.32044199109077454)
[2024-12-17 02:21:45,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:45,717][root][INFO] - Training Epoch: 1/2, step 5548/7134 completed (loss: 4.2779998779296875, acc: 0.2705882489681244)
[2024-12-17 02:21:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,081][root][INFO] - Training Epoch: 1/2, step 5549/7134 completed (loss: 4.193742752075195, acc: 0.30201342701911926)
[2024-12-17 02:21:46,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,450][root][INFO] - Training Epoch: 1/2, step 5550/7134 completed (loss: 3.7797935009002686, acc: 0.32022473216056824)
[2024-12-17 02:21:46,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:46,815][root][INFO] - Training Epoch: 1/2, step 5551/7134 completed (loss: 3.7271735668182373, acc: 0.3870967626571655)
[2024-12-17 02:21:46,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,198][root][INFO] - Training Epoch: 1/2, step 5552/7134 completed (loss: 4.147700786590576, acc: 0.29447853565216064)
[2024-12-17 02:21:47,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,554][root][INFO] - Training Epoch: 1/2, step 5553/7134 completed (loss: 3.8293890953063965, acc: 0.33136093616485596)
[2024-12-17 02:21:47,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:47,905][root][INFO] - Training Epoch: 1/2, step 5554/7134 completed (loss: 3.6588728427886963, acc: 0.35668790340423584)
[2024-12-17 02:21:48,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,274][root][INFO] - Training Epoch: 1/2, step 5555/7134 completed (loss: 3.521561861038208, acc: 0.3392857015132904)
[2024-12-17 02:21:48,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:48,628][root][INFO] - Training Epoch: 1/2, step 5556/7134 completed (loss: 3.428455114364624, acc: 0.4078212380409241)
[2024-12-17 02:21:48,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,021][root][INFO] - Training Epoch: 1/2, step 5557/7134 completed (loss: 3.2296977043151855, acc: 0.4285714328289032)
[2024-12-17 02:21:49,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,398][root][INFO] - Training Epoch: 1/2, step 5558/7134 completed (loss: 3.8162434101104736, acc: 0.2944444417953491)
[2024-12-17 02:21:49,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:49,748][root][INFO] - Training Epoch: 1/2, step 5559/7134 completed (loss: 3.099155902862549, acc: 0.37988826632499695)
[2024-12-17 02:21:49,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,114][root][INFO] - Training Epoch: 1/2, step 5560/7134 completed (loss: 4.067148685455322, acc: 0.3444444537162781)
[2024-12-17 02:21:50,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,493][root][INFO] - Training Epoch: 1/2, step 5561/7134 completed (loss: 3.490217685699463, acc: 0.3442623019218445)
[2024-12-17 02:21:50,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:50,882][root][INFO] - Training Epoch: 1/2, step 5562/7134 completed (loss: 3.688135862350464, acc: 0.32374101877212524)
[2024-12-17 02:21:51,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,237][root][INFO] - Training Epoch: 1/2, step 5563/7134 completed (loss: 3.3832552433013916, acc: 0.3472222089767456)
[2024-12-17 02:21:51,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,604][root][INFO] - Training Epoch: 1/2, step 5564/7134 completed (loss: 3.396214723587036, acc: 0.38749998807907104)
[2024-12-17 02:21:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:51,995][root][INFO] - Training Epoch: 1/2, step 5565/7134 completed (loss: 3.029698610305786, acc: 0.3733333349227905)
[2024-12-17 02:21:52,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,358][root][INFO] - Training Epoch: 1/2, step 5566/7134 completed (loss: 3.1462271213531494, acc: 0.39086294174194336)
[2024-12-17 02:21:52,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:52,753][root][INFO] - Training Epoch: 1/2, step 5567/7134 completed (loss: 3.0481762886047363, acc: 0.42288556694984436)
[2024-12-17 02:21:52,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,123][root][INFO] - Training Epoch: 1/2, step 5568/7134 completed (loss: 3.229623556137085, acc: 0.37362638115882874)
[2024-12-17 02:21:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,501][root][INFO] - Training Epoch: 1/2, step 5569/7134 completed (loss: 3.2528648376464844, acc: 0.4010416567325592)
[2024-12-17 02:21:53,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:53,852][root][INFO] - Training Epoch: 1/2, step 5570/7134 completed (loss: 3.383640766143799, acc: 0.3586956560611725)
[2024-12-17 02:21:53,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,203][root][INFO] - Training Epoch: 1/2, step 5571/7134 completed (loss: 3.3455755710601807, acc: 0.3417721390724182)
[2024-12-17 02:21:54,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,544][root][INFO] - Training Epoch: 1/2, step 5572/7134 completed (loss: 3.2927277088165283, acc: 0.3680981695652008)
[2024-12-17 02:21:54,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:54,925][root][INFO] - Training Epoch: 1/2, step 5573/7134 completed (loss: 3.5284855365753174, acc: 0.3529411852359772)
[2024-12-17 02:21:55,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,295][root][INFO] - Training Epoch: 1/2, step 5574/7134 completed (loss: 3.399013042449951, acc: 0.3333333432674408)
[2024-12-17 02:21:55,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:55,713][root][INFO] - Training Epoch: 1/2, step 5575/7134 completed (loss: 3.8679802417755127, acc: 0.3400000035762787)
[2024-12-17 02:21:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,079][root][INFO] - Training Epoch: 1/2, step 5576/7134 completed (loss: 3.363379955291748, acc: 0.4404761791229248)
[2024-12-17 02:21:56,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,461][root][INFO] - Training Epoch: 1/2, step 5577/7134 completed (loss: 4.395739555358887, acc: 0.28148147463798523)
[2024-12-17 02:21:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:56,853][root][INFO] - Training Epoch: 1/2, step 5578/7134 completed (loss: 4.048264980316162, acc: 0.32278481125831604)
[2024-12-17 02:21:56,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,238][root][INFO] - Training Epoch: 1/2, step 5579/7134 completed (loss: 4.148548126220703, acc: 0.33128833770751953)
[2024-12-17 02:21:57,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:57,659][root][INFO] - Training Epoch: 1/2, step 5580/7134 completed (loss: 3.44431209564209, acc: 0.3444444537162781)
[2024-12-17 02:21:57,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,050][root][INFO] - Training Epoch: 1/2, step 5581/7134 completed (loss: 3.870485305786133, acc: 0.2969697117805481)
[2024-12-17 02:21:58,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,441][root][INFO] - Training Epoch: 1/2, step 5582/7134 completed (loss: 3.6820738315582275, acc: 0.31491711735725403)
[2024-12-17 02:21:58,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:58,870][root][INFO] - Training Epoch: 1/2, step 5583/7134 completed (loss: 3.2790756225585938, acc: 0.3819095492362976)
[2024-12-17 02:21:59,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,293][root][INFO] - Training Epoch: 1/2, step 5584/7134 completed (loss: 3.70741605758667, acc: 0.33544304966926575)
[2024-12-17 02:21:59,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:21:59,696][root][INFO] - Training Epoch: 1/2, step 5585/7134 completed (loss: 3.708540439605713, acc: 0.3073170781135559)
[2024-12-17 02:21:59,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,055][root][INFO] - Training Epoch: 1/2, step 5586/7134 completed (loss: 3.7793192863464355, acc: 0.2925170063972473)
[2024-12-17 02:22:00,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,476][root][INFO] - Training Epoch: 1/2, step 5587/7134 completed (loss: 3.647385358810425, acc: 0.2742857038974762)
[2024-12-17 02:22:00,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:00,857][root][INFO] - Training Epoch: 1/2, step 5588/7134 completed (loss: 3.3892529010772705, acc: 0.34567901492118835)
[2024-12-17 02:22:00,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,229][root][INFO] - Training Epoch: 1/2, step 5589/7134 completed (loss: 3.60081148147583, acc: 0.3478260934352875)
[2024-12-17 02:22:01,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:01,618][root][INFO] - Training Epoch: 1/2, step 5590/7134 completed (loss: 4.185917854309082, acc: 0.2601155936717987)
[2024-12-17 02:22:01,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,072][root][INFO] - Training Epoch: 1/2, step 5591/7134 completed (loss: 3.9570319652557373, acc: 0.2658959627151489)
[2024-12-17 02:22:02,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,426][root][INFO] - Training Epoch: 1/2, step 5592/7134 completed (loss: 3.668462038040161, acc: 0.302325576543808)
[2024-12-17 02:22:02,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:02,822][root][INFO] - Training Epoch: 1/2, step 5593/7134 completed (loss: 3.018339157104492, acc: 0.3586956560611725)
[2024-12-17 02:22:02,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,226][root][INFO] - Training Epoch: 1/2, step 5594/7134 completed (loss: 3.451951742172241, acc: 0.3238636255264282)
[2024-12-17 02:22:03,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:03,637][root][INFO] - Training Epoch: 1/2, step 5595/7134 completed (loss: 3.568218231201172, acc: 0.27272728085517883)
[2024-12-17 02:22:03,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,017][root][INFO] - Training Epoch: 1/2, step 5596/7134 completed (loss: 3.8943021297454834, acc: 0.27544909715652466)
[2024-12-17 02:22:04,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,402][root][INFO] - Training Epoch: 1/2, step 5597/7134 completed (loss: 3.971764326095581, acc: 0.3072289228439331)
[2024-12-17 02:22:04,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:04,753][root][INFO] - Training Epoch: 1/2, step 5598/7134 completed (loss: 3.517343521118164, acc: 0.3410404622554779)
[2024-12-17 02:22:04,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,135][root][INFO] - Training Epoch: 1/2, step 5599/7134 completed (loss: 4.341259479522705, acc: 0.2380952388048172)
[2024-12-17 02:22:05,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,517][root][INFO] - Training Epoch: 1/2, step 5600/7134 completed (loss: 4.295023441314697, acc: 0.22857142984867096)
[2024-12-17 02:22:05,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:05,882][root][INFO] - Training Epoch: 1/2, step 5601/7134 completed (loss: 4.408869743347168, acc: 0.2977099120616913)
[2024-12-17 02:22:06,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,275][root][INFO] - Training Epoch: 1/2, step 5602/7134 completed (loss: 4.123713493347168, acc: 0.2887323796749115)
[2024-12-17 02:22:06,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:06,681][root][INFO] - Training Epoch: 1/2, step 5603/7134 completed (loss: 4.307029724121094, acc: 0.28688523173332214)
[2024-12-17 02:22:06,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,050][root][INFO] - Training Epoch: 1/2, step 5604/7134 completed (loss: 4.0842437744140625, acc: 0.3252032399177551)
[2024-12-17 02:22:07,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,439][root][INFO] - Training Epoch: 1/2, step 5605/7134 completed (loss: 4.145196437835693, acc: 0.31496062874794006)
[2024-12-17 02:22:07,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:07,777][root][INFO] - Training Epoch: 1/2, step 5606/7134 completed (loss: 3.9501140117645264, acc: 0.32710281014442444)
[2024-12-17 02:22:07,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,148][root][INFO] - Training Epoch: 1/2, step 5607/7134 completed (loss: 4.251270294189453, acc: 0.3309352397918701)
[2024-12-17 02:22:08,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,524][root][INFO] - Training Epoch: 1/2, step 5608/7134 completed (loss: 4.712973117828369, acc: 0.26356589794158936)
[2024-12-17 02:22:08,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:08,884][root][INFO] - Training Epoch: 1/2, step 5609/7134 completed (loss: 4.050903797149658, acc: 0.3166666626930237)
[2024-12-17 02:22:09,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,259][root][INFO] - Training Epoch: 1/2, step 5610/7134 completed (loss: 4.181188106536865, acc: 0.2454545497894287)
[2024-12-17 02:22:09,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:09,658][root][INFO] - Training Epoch: 1/2, step 5611/7134 completed (loss: 4.38055419921875, acc: 0.26865673065185547)
[2024-12-17 02:22:09,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,039][root][INFO] - Training Epoch: 1/2, step 5612/7134 completed (loss: 4.167490005493164, acc: 0.2957746386528015)
[2024-12-17 02:22:10,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,420][root][INFO] - Training Epoch: 1/2, step 5613/7134 completed (loss: 4.0557756423950195, acc: 0.3214285671710968)
[2024-12-17 02:22:10,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:10,774][root][INFO] - Training Epoch: 1/2, step 5614/7134 completed (loss: 3.694509983062744, acc: 0.38255032896995544)
[2024-12-17 02:22:10,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,151][root][INFO] - Training Epoch: 1/2, step 5615/7134 completed (loss: 4.2766194343566895, acc: 0.27619048953056335)
[2024-12-17 02:22:11,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,536][root][INFO] - Training Epoch: 1/2, step 5616/7134 completed (loss: 4.29835319519043, acc: 0.27407407760620117)
[2024-12-17 02:22:11,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:11,891][root][INFO] - Training Epoch: 1/2, step 5617/7134 completed (loss: 3.968360662460327, acc: 0.27906978130340576)
[2024-12-17 02:22:12,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,281][root][INFO] - Training Epoch: 1/2, step 5618/7134 completed (loss: 4.339370250701904, acc: 0.25735294818878174)
[2024-12-17 02:22:12,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:12,649][root][INFO] - Training Epoch: 1/2, step 5619/7134 completed (loss: 3.880302667617798, acc: 0.3445378243923187)
[2024-12-17 02:22:12,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,042][root][INFO] - Training Epoch: 1/2, step 5620/7134 completed (loss: 4.368233680725098, acc: 0.260869562625885)
[2024-12-17 02:22:13,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,423][root][INFO] - Training Epoch: 1/2, step 5621/7134 completed (loss: 3.789867877960205, acc: 0.34193548560142517)
[2024-12-17 02:22:13,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:13,808][root][INFO] - Training Epoch: 1/2, step 5622/7134 completed (loss: 3.3791186809539795, acc: 0.32085561752319336)
[2024-12-17 02:22:13,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,137][root][INFO] - Training Epoch: 1/2, step 5623/7134 completed (loss: 3.88214373588562, acc: 0.2638888955116272)
[2024-12-17 02:22:14,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,482][root][INFO] - Training Epoch: 1/2, step 5624/7134 completed (loss: 3.321389675140381, acc: 0.3333333432674408)
[2024-12-17 02:22:14,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:14,845][root][INFO] - Training Epoch: 1/2, step 5625/7134 completed (loss: 4.03812313079834, acc: 0.22549019753932953)
[2024-12-17 02:22:14,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,221][root][INFO] - Training Epoch: 1/2, step 5626/7134 completed (loss: 3.3784608840942383, acc: 0.3448275923728943)
[2024-12-17 02:22:15,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,577][root][INFO] - Training Epoch: 1/2, step 5627/7134 completed (loss: 3.719097852706909, acc: 0.3333333432674408)
[2024-12-17 02:22:15,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:15,936][root][INFO] - Training Epoch: 1/2, step 5628/7134 completed (loss: 4.428338050842285, acc: 0.2678571343421936)
[2024-12-17 02:22:16,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,307][root][INFO] - Training Epoch: 1/2, step 5629/7134 completed (loss: 3.837101936340332, acc: 0.30327868461608887)
[2024-12-17 02:22:16,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:16,666][root][INFO] - Training Epoch: 1/2, step 5630/7134 completed (loss: 4.5655035972595215, acc: 0.2549019753932953)
[2024-12-17 02:22:16,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,035][root][INFO] - Training Epoch: 1/2, step 5631/7134 completed (loss: 3.7666573524475098, acc: 0.3739837408065796)
[2024-12-17 02:22:17,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,430][root][INFO] - Training Epoch: 1/2, step 5632/7134 completed (loss: 4.460448265075684, acc: 0.3076923191547394)
[2024-12-17 02:22:17,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:17,814][root][INFO] - Training Epoch: 1/2, step 5633/7134 completed (loss: 4.100835800170898, acc: 0.3035714328289032)
[2024-12-17 02:22:17,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,189][root][INFO] - Training Epoch: 1/2, step 5634/7134 completed (loss: 3.7011702060699463, acc: 0.37168142199516296)
[2024-12-17 02:22:18,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,552][root][INFO] - Training Epoch: 1/2, step 5635/7134 completed (loss: 3.723445415496826, acc: 0.34375)
[2024-12-17 02:22:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:18,907][root][INFO] - Training Epoch: 1/2, step 5636/7134 completed (loss: 3.8524041175842285, acc: 0.3076923191547394)
[2024-12-17 02:22:19,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,279][root][INFO] - Training Epoch: 1/2, step 5637/7134 completed (loss: 4.060843467712402, acc: 0.2954545319080353)
[2024-12-17 02:22:19,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,620][root][INFO] - Training Epoch: 1/2, step 5638/7134 completed (loss: 4.164170265197754, acc: 0.3245614171028137)
[2024-12-17 02:22:19,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:19,989][root][INFO] - Training Epoch: 1/2, step 5639/7134 completed (loss: 3.936343193054199, acc: 0.3311688303947449)
[2024-12-17 02:22:20,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,338][root][INFO] - Training Epoch: 1/2, step 5640/7134 completed (loss: 3.68021559715271, acc: 0.38297873735427856)
[2024-12-17 02:22:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:20,678][root][INFO] - Training Epoch: 1/2, step 5641/7134 completed (loss: 4.256403923034668, acc: 0.2808988690376282)
[2024-12-17 02:22:20,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,051][root][INFO] - Training Epoch: 1/2, step 5642/7134 completed (loss: 4.041605472564697, acc: 0.31468531489372253)
[2024-12-17 02:22:21,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,426][root][INFO] - Training Epoch: 1/2, step 5643/7134 completed (loss: 4.112027645111084, acc: 0.27368420362472534)
[2024-12-17 02:22:21,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:21,817][root][INFO] - Training Epoch: 1/2, step 5644/7134 completed (loss: 4.185184955596924, acc: 0.3333333432674408)
[2024-12-17 02:22:21,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,201][root][INFO] - Training Epoch: 1/2, step 5645/7134 completed (loss: 3.9231083393096924, acc: 0.2916666567325592)
[2024-12-17 02:22:22,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,580][root][INFO] - Training Epoch: 1/2, step 5646/7134 completed (loss: 3.6511294841766357, acc: 0.2785714268684387)
[2024-12-17 02:22:22,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:22,979][root][INFO] - Training Epoch: 1/2, step 5647/7134 completed (loss: 4.050214767456055, acc: 0.2916666567325592)
[2024-12-17 02:22:23,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,433][root][INFO] - Training Epoch: 1/2, step 5648/7134 completed (loss: 3.976046562194824, acc: 0.3266666531562805)
[2024-12-17 02:22:23,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:23,816][root][INFO] - Training Epoch: 1/2, step 5649/7134 completed (loss: 4.1592841148376465, acc: 0.31081080436706543)
[2024-12-17 02:22:23,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,180][root][INFO] - Training Epoch: 1/2, step 5650/7134 completed (loss: 3.9897470474243164, acc: 0.27419355511665344)
[2024-12-17 02:22:24,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,548][root][INFO] - Training Epoch: 1/2, step 5651/7134 completed (loss: 3.9583852291107178, acc: 0.31972789764404297)
[2024-12-17 02:22:24,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:24,965][root][INFO] - Training Epoch: 1/2, step 5652/7134 completed (loss: 3.7528858184814453, acc: 0.36690646409988403)
[2024-12-17 02:22:25,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,353][root][INFO] - Training Epoch: 1/2, step 5653/7134 completed (loss: 4.9453020095825195, acc: 0.1818181872367859)
[2024-12-17 02:22:25,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:25,754][root][INFO] - Training Epoch: 1/2, step 5654/7134 completed (loss: 3.5805749893188477, acc: 0.3125)
[2024-12-17 02:22:25,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,166][root][INFO] - Training Epoch: 1/2, step 5655/7134 completed (loss: 4.272747993469238, acc: 0.2710280418395996)
[2024-12-17 02:22:26,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,617][root][INFO] - Training Epoch: 1/2, step 5656/7134 completed (loss: 4.000929832458496, acc: 0.2540983557701111)
[2024-12-17 02:22:26,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:26,982][root][INFO] - Training Epoch: 1/2, step 5657/7134 completed (loss: 3.6669654846191406, acc: 0.3509933650493622)
[2024-12-17 02:22:27,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,363][root][INFO] - Training Epoch: 1/2, step 5658/7134 completed (loss: 3.860922336578369, acc: 0.3333333432674408)
[2024-12-17 02:22:27,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:27,735][root][INFO] - Training Epoch: 1/2, step 5659/7134 completed (loss: 4.009850978851318, acc: 0.30000001192092896)
[2024-12-17 02:22:27,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,108][root][INFO] - Training Epoch: 1/2, step 5660/7134 completed (loss: 4.076013088226318, acc: 0.296875)
[2024-12-17 02:22:28,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,483][root][INFO] - Training Epoch: 1/2, step 5661/7134 completed (loss: 3.951598882675171, acc: 0.26050421595573425)
[2024-12-17 02:22:28,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:28,858][root][INFO] - Training Epoch: 1/2, step 5662/7134 completed (loss: 3.40726375579834, acc: 0.41726619005203247)
[2024-12-17 02:22:29,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,251][root][INFO] - Training Epoch: 1/2, step 5663/7134 completed (loss: 3.7279937267303467, acc: 0.32608696818351746)
[2024-12-17 02:22:29,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,614][root][INFO] - Training Epoch: 1/2, step 5664/7134 completed (loss: 4.201737880706787, acc: 0.27397260069847107)
[2024-12-17 02:22:29,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:29,956][root][INFO] - Training Epoch: 1/2, step 5665/7134 completed (loss: 4.013558864593506, acc: 0.3469387888908386)
[2024-12-17 02:22:30,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,337][root][INFO] - Training Epoch: 1/2, step 5666/7134 completed (loss: 3.6909008026123047, acc: 0.3333333432674408)
[2024-12-17 02:22:30,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:30,719][root][INFO] - Training Epoch: 1/2, step 5667/7134 completed (loss: 3.80769419670105, acc: 0.35772356390953064)
[2024-12-17 02:22:30,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,091][root][INFO] - Training Epoch: 1/2, step 5668/7134 completed (loss: 4.3461480140686035, acc: 0.29629629850387573)
[2024-12-17 02:22:31,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,433][root][INFO] - Training Epoch: 1/2, step 5669/7134 completed (loss: 3.9016382694244385, acc: 0.35031846165657043)
[2024-12-17 02:22:31,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:31,806][root][INFO] - Training Epoch: 1/2, step 5670/7134 completed (loss: 4.235188007354736, acc: 0.261904776096344)
[2024-12-17 02:22:31,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,191][root][INFO] - Training Epoch: 1/2, step 5671/7134 completed (loss: 3.666656494140625, acc: 0.3764044940471649)
[2024-12-17 02:22:32,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,559][root][INFO] - Training Epoch: 1/2, step 5672/7134 completed (loss: 4.150073051452637, acc: 0.27407407760620117)
[2024-12-17 02:22:32,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:32,893][root][INFO] - Training Epoch: 1/2, step 5673/7134 completed (loss: 4.138052463531494, acc: 0.31506848335266113)
[2024-12-17 02:22:33,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,261][root][INFO] - Training Epoch: 1/2, step 5674/7134 completed (loss: 3.8788106441497803, acc: 0.31292515993118286)
[2024-12-17 02:22:33,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,617][root][INFO] - Training Epoch: 1/2, step 5675/7134 completed (loss: 4.351010799407959, acc: 0.3400000035762787)
[2024-12-17 02:22:33,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:33,995][root][INFO] - Training Epoch: 1/2, step 5676/7134 completed (loss: 4.828333377838135, acc: 0.23563218116760254)
[2024-12-17 02:22:34,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,342][root][INFO] - Training Epoch: 1/2, step 5677/7134 completed (loss: 3.851682186126709, acc: 0.2857142984867096)
[2024-12-17 02:22:34,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:34,728][root][INFO] - Training Epoch: 1/2, step 5678/7134 completed (loss: 4.173348426818848, acc: 0.26543208956718445)
[2024-12-17 02:22:34,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,122][root][INFO] - Training Epoch: 1/2, step 5679/7134 completed (loss: 4.587573528289795, acc: 0.2848101258277893)
[2024-12-17 02:22:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,498][root][INFO] - Training Epoch: 1/2, step 5680/7134 completed (loss: 4.722634792327881, acc: 0.2445652186870575)
[2024-12-17 02:22:35,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:35,865][root][INFO] - Training Epoch: 1/2, step 5681/7134 completed (loss: 4.36415958404541, acc: 0.27878788113594055)
[2024-12-17 02:22:35,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,235][root][INFO] - Training Epoch: 1/2, step 5682/7134 completed (loss: 3.8682591915130615, acc: 0.3253012001514435)
[2024-12-17 02:22:36,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,603][root][INFO] - Training Epoch: 1/2, step 5683/7134 completed (loss: 4.116962909698486, acc: 0.32777777314186096)
[2024-12-17 02:22:36,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:36,984][root][INFO] - Training Epoch: 1/2, step 5684/7134 completed (loss: 3.5224967002868652, acc: 0.40243902802467346)
[2024-12-17 02:22:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,333][root][INFO] - Training Epoch: 1/2, step 5685/7134 completed (loss: 4.770210266113281, acc: 0.22834645211696625)
[2024-12-17 02:22:37,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:37,704][root][INFO] - Training Epoch: 1/2, step 5686/7134 completed (loss: 4.049265384674072, acc: 0.32374101877212524)
[2024-12-17 02:22:37,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,070][root][INFO] - Training Epoch: 1/2, step 5687/7134 completed (loss: 4.2216057777404785, acc: 0.2348484843969345)
[2024-12-17 02:22:38,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,454][root][INFO] - Training Epoch: 1/2, step 5688/7134 completed (loss: 4.189303874969482, acc: 0.2944444417953491)
[2024-12-17 02:22:38,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:38,820][root][INFO] - Training Epoch: 1/2, step 5689/7134 completed (loss: 3.73913836479187, acc: 0.3048780560493469)
[2024-12-17 02:22:38,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,205][root][INFO] - Training Epoch: 1/2, step 5690/7134 completed (loss: 3.8725311756134033, acc: 0.30927833914756775)
[2024-12-17 02:22:39,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,565][root][INFO] - Training Epoch: 1/2, step 5691/7134 completed (loss: 3.642500400543213, acc: 0.3715847134590149)
[2024-12-17 02:22:39,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:39,976][root][INFO] - Training Epoch: 1/2, step 5692/7134 completed (loss: 4.059617519378662, acc: 0.3028571307659149)
[2024-12-17 02:22:40,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,365][root][INFO] - Training Epoch: 1/2, step 5693/7134 completed (loss: 3.4916269779205322, acc: 0.3459119498729706)
[2024-12-17 02:22:40,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:40,726][root][INFO] - Training Epoch: 1/2, step 5694/7134 completed (loss: 3.2835848331451416, acc: 0.34302327036857605)
[2024-12-17 02:22:40,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,110][root][INFO] - Training Epoch: 1/2, step 5695/7134 completed (loss: 3.6058506965637207, acc: 0.3619631826877594)
[2024-12-17 02:22:41,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,474][root][INFO] - Training Epoch: 1/2, step 5696/7134 completed (loss: 3.8953475952148438, acc: 0.2871287167072296)
[2024-12-17 02:22:41,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:41,836][root][INFO] - Training Epoch: 1/2, step 5697/7134 completed (loss: 3.709390640258789, acc: 0.3333333432674408)
[2024-12-17 02:22:41,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,211][root][INFO] - Training Epoch: 1/2, step 5698/7134 completed (loss: 3.643587589263916, acc: 0.2954545319080353)
[2024-12-17 02:22:42,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:42,621][root][INFO] - Training Epoch: 1/2, step 5699/7134 completed (loss: 4.624842643737793, acc: 0.29885056614875793)
[2024-12-17 02:22:42,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,023][root][INFO] - Training Epoch: 1/2, step 5700/7134 completed (loss: 3.9273669719696045, acc: 0.35668790340423584)
[2024-12-17 02:22:43,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,396][root][INFO] - Training Epoch: 1/2, step 5701/7134 completed (loss: 4.154077053070068, acc: 0.2432432472705841)
[2024-12-17 02:22:43,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:43,769][root][INFO] - Training Epoch: 1/2, step 5702/7134 completed (loss: 3.390984535217285, acc: 0.4127906858921051)
[2024-12-17 02:22:43,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,152][root][INFO] - Training Epoch: 1/2, step 5703/7134 completed (loss: 3.230201244354248, acc: 0.3459119498729706)
[2024-12-17 02:22:44,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,499][root][INFO] - Training Epoch: 1/2, step 5704/7134 completed (loss: 3.7223546504974365, acc: 0.30588236451148987)
[2024-12-17 02:22:44,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:44,827][root][INFO] - Training Epoch: 1/2, step 5705/7134 completed (loss: 3.0172176361083984, acc: 0.38235294818878174)
[2024-12-17 02:22:44,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,203][root][INFO] - Training Epoch: 1/2, step 5706/7134 completed (loss: 3.712019920349121, acc: 0.31683167815208435)
[2024-12-17 02:22:45,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,543][root][INFO] - Training Epoch: 1/2, step 5707/7134 completed (loss: 3.8609421253204346, acc: 0.25600001215934753)
[2024-12-17 02:22:45,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:45,895][root][INFO] - Training Epoch: 1/2, step 5708/7134 completed (loss: 3.46899151802063, acc: 0.3205128312110901)
[2024-12-17 02:22:46,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,271][root][INFO] - Training Epoch: 1/2, step 5709/7134 completed (loss: 3.2643399238586426, acc: 0.4037266969680786)
[2024-12-17 02:22:46,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:46,641][root][INFO] - Training Epoch: 1/2, step 5710/7134 completed (loss: 3.6654744148254395, acc: 0.33142855763435364)
[2024-12-17 02:22:46,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,014][root][INFO] - Training Epoch: 1/2, step 5711/7134 completed (loss: 3.9408657550811768, acc: 0.34408602118492126)
[2024-12-17 02:22:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,383][root][INFO] - Training Epoch: 1/2, step 5712/7134 completed (loss: 3.31638240814209, acc: 0.3790322542190552)
[2024-12-17 02:22:47,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:47,741][root][INFO] - Training Epoch: 1/2, step 5713/7134 completed (loss: 3.262814998626709, acc: 0.3764044940471649)
[2024-12-17 02:22:47,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,115][root][INFO] - Training Epoch: 1/2, step 5714/7134 completed (loss: 4.028232574462891, acc: 0.260869562625885)
[2024-12-17 02:22:48,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,465][root][INFO] - Training Epoch: 1/2, step 5715/7134 completed (loss: 4.0071024894714355, acc: 0.29411765933036804)
[2024-12-17 02:22:48,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:48,838][root][INFO] - Training Epoch: 1/2, step 5716/7134 completed (loss: 3.745274066925049, acc: 0.3055555522441864)
[2024-12-17 02:22:48,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,203][root][INFO] - Training Epoch: 1/2, step 5717/7134 completed (loss: 3.9052417278289795, acc: 0.3040935695171356)
[2024-12-17 02:22:49,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,543][root][INFO] - Training Epoch: 1/2, step 5718/7134 completed (loss: 3.910299301147461, acc: 0.28947368264198303)
[2024-12-17 02:22:49,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:49,917][root][INFO] - Training Epoch: 1/2, step 5719/7134 completed (loss: 3.8033971786499023, acc: 0.3235294222831726)
[2024-12-17 02:22:50,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,291][root][INFO] - Training Epoch: 1/2, step 5720/7134 completed (loss: 3.9596691131591797, acc: 0.2884615361690521)
[2024-12-17 02:22:50,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:50,655][root][INFO] - Training Epoch: 1/2, step 5721/7134 completed (loss: 3.810899257659912, acc: 0.3212435245513916)
[2024-12-17 02:22:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,016][root][INFO] - Training Epoch: 1/2, step 5722/7134 completed (loss: 3.667412757873535, acc: 0.34545454382896423)
[2024-12-17 02:22:51,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,379][root][INFO] - Training Epoch: 1/2, step 5723/7134 completed (loss: 3.483868360519409, acc: 0.3650793731212616)
[2024-12-17 02:22:51,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:51,731][root][INFO] - Training Epoch: 1/2, step 5724/7134 completed (loss: 3.4095520973205566, acc: 0.35151514410972595)
[2024-12-17 02:22:51,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,113][root][INFO] - Training Epoch: 1/2, step 5725/7134 completed (loss: 3.662101984024048, acc: 0.2971428632736206)
[2024-12-17 02:22:52,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,502][root][INFO] - Training Epoch: 1/2, step 5726/7134 completed (loss: 3.8616650104522705, acc: 0.2634730637073517)
[2024-12-17 02:22:52,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:52,867][root][INFO] - Training Epoch: 1/2, step 5727/7134 completed (loss: 3.1251845359802246, acc: 0.41206029057502747)
[2024-12-17 02:22:52,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,192][root][INFO] - Training Epoch: 1/2, step 5728/7134 completed (loss: 3.2881131172180176, acc: 0.41911765933036804)
[2024-12-17 02:22:53,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,535][root][INFO] - Training Epoch: 1/2, step 5729/7134 completed (loss: 3.478766441345215, acc: 0.3311688303947449)
[2024-12-17 02:22:53,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:53,903][root][INFO] - Training Epoch: 1/2, step 5730/7134 completed (loss: 3.867220163345337, acc: 0.24444444477558136)
[2024-12-17 02:22:54,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,289][root][INFO] - Training Epoch: 1/2, step 5731/7134 completed (loss: 3.613431930541992, acc: 0.36250001192092896)
[2024-12-17 02:22:54,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,614][root][INFO] - Training Epoch: 1/2, step 5732/7134 completed (loss: 4.552781581878662, acc: 0.2530120611190796)
[2024-12-17 02:22:54,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:54,961][root][INFO] - Training Epoch: 1/2, step 5733/7134 completed (loss: 4.220789432525635, acc: 0.2531645596027374)
[2024-12-17 02:22:55,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,347][root][INFO] - Training Epoch: 1/2, step 5734/7134 completed (loss: 3.513982057571411, acc: 0.3273809552192688)
[2024-12-17 02:22:55,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:55,725][root][INFO] - Training Epoch: 1/2, step 5735/7134 completed (loss: 3.961515188217163, acc: 0.26490065455436707)
[2024-12-17 02:22:55,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,119][root][INFO] - Training Epoch: 1/2, step 5736/7134 completed (loss: 3.5743861198425293, acc: 0.32596686482429504)
[2024-12-17 02:22:56,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,477][root][INFO] - Training Epoch: 1/2, step 5737/7134 completed (loss: 3.2711260318756104, acc: 0.3684210479259491)
[2024-12-17 02:22:56,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:56,842][root][INFO] - Training Epoch: 1/2, step 5738/7134 completed (loss: 3.2546989917755127, acc: 0.3737373650074005)
[2024-12-17 02:22:56,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,207][root][INFO] - Training Epoch: 1/2, step 5739/7134 completed (loss: 3.486222982406616, acc: 0.36666667461395264)
[2024-12-17 02:22:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,575][root][INFO] - Training Epoch: 1/2, step 5740/7134 completed (loss: 3.28737735748291, acc: 0.3489583432674408)
[2024-12-17 02:22:57,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:57,960][root][INFO] - Training Epoch: 1/2, step 5741/7134 completed (loss: 3.928054094314575, acc: 0.33522728085517883)
[2024-12-17 02:22:58,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,317][root][INFO] - Training Epoch: 1/2, step 5742/7134 completed (loss: 3.228895902633667, acc: 0.3932584226131439)
[2024-12-17 02:22:58,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:58,688][root][INFO] - Training Epoch: 1/2, step 5743/7134 completed (loss: 3.5618088245391846, acc: 0.328125)
[2024-12-17 02:22:58,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,051][root][INFO] - Training Epoch: 1/2, step 5744/7134 completed (loss: 3.295866012573242, acc: 0.3185840845108032)
[2024-12-17 02:22:59,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,434][root][INFO] - Training Epoch: 1/2, step 5745/7134 completed (loss: 4.2994818687438965, acc: 0.2584269642829895)
[2024-12-17 02:22:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:22:59,778][root][INFO] - Training Epoch: 1/2, step 5746/7134 completed (loss: 3.9658806324005127, acc: 0.31481480598449707)
[2024-12-17 02:22:59,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,172][root][INFO] - Training Epoch: 1/2, step 5747/7134 completed (loss: 3.8705222606658936, acc: 0.30909091234207153)
[2024-12-17 02:23:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,557][root][INFO] - Training Epoch: 1/2, step 5748/7134 completed (loss: 3.404127597808838, acc: 0.3937007784843445)
[2024-12-17 02:23:00,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:00,948][root][INFO] - Training Epoch: 1/2, step 5749/7134 completed (loss: 3.8505327701568604, acc: 0.33136093616485596)
[2024-12-17 02:23:01,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,373][root][INFO] - Training Epoch: 1/2, step 5750/7134 completed (loss: 3.984757900238037, acc: 0.33519554138183594)
[2024-12-17 02:23:01,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:01,792][root][INFO] - Training Epoch: 1/2, step 5751/7134 completed (loss: 4.472866535186768, acc: 0.26490065455436707)
[2024-12-17 02:23:01,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,217][root][INFO] - Training Epoch: 1/2, step 5752/7134 completed (loss: 4.167185306549072, acc: 0.2671755850315094)
[2024-12-17 02:23:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:02,607][root][INFO] - Training Epoch: 1/2, step 5753/7134 completed (loss: 3.84970760345459, acc: 0.281879186630249)
[2024-12-17 02:23:02,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,014][root][INFO] - Training Epoch: 1/2, step 5754/7134 completed (loss: 4.087148666381836, acc: 0.3045977056026459)
[2024-12-17 02:23:03,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,397][root][INFO] - Training Epoch: 1/2, step 5755/7134 completed (loss: 3.689091205596924, acc: 0.4025973975658417)
[2024-12-17 02:23:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:03,773][root][INFO] - Training Epoch: 1/2, step 5756/7134 completed (loss: 4.01794958114624, acc: 0.31976744532585144)
[2024-12-17 02:23:03,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,127][root][INFO] - Training Epoch: 1/2, step 5757/7134 completed (loss: 4.124040603637695, acc: 0.2415730357170105)
[2024-12-17 02:23:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,470][root][INFO] - Training Epoch: 1/2, step 5758/7134 completed (loss: 3.750676393508911, acc: 0.34567901492118835)
[2024-12-17 02:23:04,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:04,823][root][INFO] - Training Epoch: 1/2, step 5759/7134 completed (loss: 4.594185829162598, acc: 0.26213592290878296)
[2024-12-17 02:23:04,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,181][root][INFO] - Training Epoch: 1/2, step 5760/7134 completed (loss: 3.7657113075256348, acc: 0.2857142984867096)
[2024-12-17 02:23:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,564][root][INFO] - Training Epoch: 1/2, step 5761/7134 completed (loss: 3.905627965927124, acc: 0.31200000643730164)
[2024-12-17 02:23:05,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:05,927][root][INFO] - Training Epoch: 1/2, step 5762/7134 completed (loss: 4.12455940246582, acc: 0.2868216931819916)
[2024-12-17 02:23:06,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,286][root][INFO] - Training Epoch: 1/2, step 5763/7134 completed (loss: 3.7525150775909424, acc: 0.31147539615631104)
[2024-12-17 02:23:06,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:06,651][root][INFO] - Training Epoch: 1/2, step 5764/7134 completed (loss: 3.6384780406951904, acc: 0.32824426889419556)
[2024-12-17 02:23:06,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,004][root][INFO] - Training Epoch: 1/2, step 5765/7134 completed (loss: 3.9358060359954834, acc: 0.30817610025405884)
[2024-12-17 02:23:07,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,353][root][INFO] - Training Epoch: 1/2, step 5766/7134 completed (loss: 3.7292118072509766, acc: 0.2709677517414093)
[2024-12-17 02:23:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:07,714][root][INFO] - Training Epoch: 1/2, step 5767/7134 completed (loss: 3.6187822818756104, acc: 0.2857142984867096)
[2024-12-17 02:23:07,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,085][root][INFO] - Training Epoch: 1/2, step 5768/7134 completed (loss: 3.902892589569092, acc: 0.23749999701976776)
[2024-12-17 02:23:08,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,463][root][INFO] - Training Epoch: 1/2, step 5769/7134 completed (loss: 3.662505626678467, acc: 0.34285715222358704)
[2024-12-17 02:23:08,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:08,843][root][INFO] - Training Epoch: 1/2, step 5770/7134 completed (loss: 3.750507354736328, acc: 0.31351351737976074)
[2024-12-17 02:23:08,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,228][root][INFO] - Training Epoch: 1/2, step 5771/7134 completed (loss: 3.9346096515655518, acc: 0.30674847960472107)
[2024-12-17 02:23:09,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,614][root][INFO] - Training Epoch: 1/2, step 5772/7134 completed (loss: 3.7078030109405518, acc: 0.30000001192092896)
[2024-12-17 02:23:09,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:09,998][root][INFO] - Training Epoch: 1/2, step 5773/7134 completed (loss: 3.774653673171997, acc: 0.31578946113586426)
[2024-12-17 02:23:10,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,354][root][INFO] - Training Epoch: 1/2, step 5774/7134 completed (loss: 3.786515235900879, acc: 0.327160507440567)
[2024-12-17 02:23:10,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:10,723][root][INFO] - Training Epoch: 1/2, step 5775/7134 completed (loss: 3.517779588699341, acc: 0.31333333253860474)
[2024-12-17 02:23:10,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,098][root][INFO] - Training Epoch: 1/2, step 5776/7134 completed (loss: 3.992018461227417, acc: 0.2808988690376282)
[2024-12-17 02:23:11,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,469][root][INFO] - Training Epoch: 1/2, step 5777/7134 completed (loss: 3.61946439743042, acc: 0.2850467264652252)
[2024-12-17 02:23:11,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:11,835][root][INFO] - Training Epoch: 1/2, step 5778/7134 completed (loss: 3.9984614849090576, acc: 0.25609755516052246)
[2024-12-17 02:23:11,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,186][root][INFO] - Training Epoch: 1/2, step 5779/7134 completed (loss: 4.2446088790893555, acc: 0.24705882370471954)
[2024-12-17 02:23:12,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,558][root][INFO] - Training Epoch: 1/2, step 5780/7134 completed (loss: 3.509140729904175, acc: 0.31840795278549194)
[2024-12-17 02:23:12,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:12,925][root][INFO] - Training Epoch: 1/2, step 5781/7134 completed (loss: 4.099839210510254, acc: 0.32947975397109985)
[2024-12-17 02:23:13,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,293][root][INFO] - Training Epoch: 1/2, step 5782/7134 completed (loss: 3.7857909202575684, acc: 0.33149170875549316)
[2024-12-17 02:23:13,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:13,680][root][INFO] - Training Epoch: 1/2, step 5783/7134 completed (loss: 3.422927141189575, acc: 0.3352601230144501)
[2024-12-17 02:23:13,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,057][root][INFO] - Training Epoch: 1/2, step 5784/7134 completed (loss: 3.77203369140625, acc: 0.3785310685634613)
[2024-12-17 02:23:14,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,411][root][INFO] - Training Epoch: 1/2, step 5785/7134 completed (loss: 3.744359016418457, acc: 0.3513513505458832)
[2024-12-17 02:23:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:14,739][root][INFO] - Training Epoch: 1/2, step 5786/7134 completed (loss: 3.691091299057007, acc: 0.3174603283405304)
[2024-12-17 02:23:14,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,081][root][INFO] - Training Epoch: 1/2, step 5787/7134 completed (loss: 4.032504081726074, acc: 0.2565445005893707)
[2024-12-17 02:23:15,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,462][root][INFO] - Training Epoch: 1/2, step 5788/7134 completed (loss: 3.35746169090271, acc: 0.32894736528396606)
[2024-12-17 02:23:15,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:15,809][root][INFO] - Training Epoch: 1/2, step 5789/7134 completed (loss: 4.051294326782227, acc: 0.26767677068710327)
[2024-12-17 02:23:15,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,167][root][INFO] - Training Epoch: 1/2, step 5790/7134 completed (loss: 3.8984522819519043, acc: 0.2738095223903656)
[2024-12-17 02:23:16,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,536][root][INFO] - Training Epoch: 1/2, step 5791/7134 completed (loss: 3.888000011444092, acc: 0.24626865983009338)
[2024-12-17 02:23:16,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:16,908][root][INFO] - Training Epoch: 1/2, step 5792/7134 completed (loss: 4.22039270401001, acc: 0.34228187799453735)
[2024-12-17 02:23:17,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,248][root][INFO] - Training Epoch: 1/2, step 5793/7134 completed (loss: 3.865293502807617, acc: 0.30674847960472107)
[2024-12-17 02:23:17,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,604][root][INFO] - Training Epoch: 1/2, step 5794/7134 completed (loss: 4.367392539978027, acc: 0.31847134232521057)
[2024-12-17 02:23:17,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:17,983][root][INFO] - Training Epoch: 1/2, step 5795/7134 completed (loss: 4.49813985824585, acc: 0.30075186491012573)
[2024-12-17 02:23:18,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,369][root][INFO] - Training Epoch: 1/2, step 5796/7134 completed (loss: 4.679258346557617, acc: 0.2977099120616913)
[2024-12-17 02:23:18,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:18,755][root][INFO] - Training Epoch: 1/2, step 5797/7134 completed (loss: 4.057598114013672, acc: 0.268456369638443)
[2024-12-17 02:23:18,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,129][root][INFO] - Training Epoch: 1/2, step 5798/7134 completed (loss: 4.6403961181640625, acc: 0.25581395626068115)
[2024-12-17 02:23:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,506][root][INFO] - Training Epoch: 1/2, step 5799/7134 completed (loss: 4.1194891929626465, acc: 0.28346458077430725)
[2024-12-17 02:23:19,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:19,886][root][INFO] - Training Epoch: 1/2, step 5800/7134 completed (loss: 4.795494556427002, acc: 0.2158273309469223)
[2024-12-17 02:23:20,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,232][root][INFO] - Training Epoch: 1/2, step 5801/7134 completed (loss: 4.506199359893799, acc: 0.2777777910232544)
[2024-12-17 02:23:20,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,594][root][INFO] - Training Epoch: 1/2, step 5802/7134 completed (loss: 4.086666107177734, acc: 0.34558823704719543)
[2024-12-17 02:23:20,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:20,965][root][INFO] - Training Epoch: 1/2, step 5803/7134 completed (loss: 3.9720423221588135, acc: 0.2586206793785095)
[2024-12-17 02:23:21,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,325][root][INFO] - Training Epoch: 1/2, step 5804/7134 completed (loss: 4.094141960144043, acc: 0.23566879332065582)
[2024-12-17 02:23:21,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:21,684][root][INFO] - Training Epoch: 1/2, step 5805/7134 completed (loss: 4.30478572845459, acc: 0.2781457006931305)
[2024-12-17 02:23:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,052][root][INFO] - Training Epoch: 1/2, step 5806/7134 completed (loss: 3.9024558067321777, acc: 0.31515151262283325)
[2024-12-17 02:23:22,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,438][root][INFO] - Training Epoch: 1/2, step 5807/7134 completed (loss: 4.2218499183654785, acc: 0.3239436745643616)
[2024-12-17 02:23:22,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:22,828][root][INFO] - Training Epoch: 1/2, step 5808/7134 completed (loss: 4.266332626342773, acc: 0.2151898741722107)
[2024-12-17 02:23:22,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,201][root][INFO] - Training Epoch: 1/2, step 5809/7134 completed (loss: 4.54855489730835, acc: 0.28431373834609985)
[2024-12-17 02:23:23,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,584][root][INFO] - Training Epoch: 1/2, step 5810/7134 completed (loss: 3.8196167945861816, acc: 0.26446279883384705)
[2024-12-17 02:23:23,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:23,950][root][INFO] - Training Epoch: 1/2, step 5811/7134 completed (loss: 3.969717264175415, acc: 0.32967033982276917)
[2024-12-17 02:23:24,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,367][root][INFO] - Training Epoch: 1/2, step 5812/7134 completed (loss: 4.006189346313477, acc: 0.33088234066963196)
[2024-12-17 02:23:24,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:24,771][root][INFO] - Training Epoch: 1/2, step 5813/7134 completed (loss: 4.0089826583862305, acc: 0.28688523173332214)
[2024-12-17 02:23:24,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,204][root][INFO] - Training Epoch: 1/2, step 5814/7134 completed (loss: 4.101822853088379, acc: 0.30399999022483826)
[2024-12-17 02:23:25,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,585][root][INFO] - Training Epoch: 1/2, step 5815/7134 completed (loss: 3.961198568344116, acc: 0.27586206793785095)
[2024-12-17 02:23:25,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:25,948][root][INFO] - Training Epoch: 1/2, step 5816/7134 completed (loss: 3.3469460010528564, acc: 0.34224599599838257)
[2024-12-17 02:23:26,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,310][root][INFO] - Training Epoch: 1/2, step 5817/7134 completed (loss: 3.4053924083709717, acc: 0.37142857909202576)
[2024-12-17 02:23:26,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:26,671][root][INFO] - Training Epoch: 1/2, step 5818/7134 completed (loss: 3.803173303604126, acc: 0.3006536066532135)
[2024-12-17 02:23:26,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,019][root][INFO] - Training Epoch: 1/2, step 5819/7134 completed (loss: 3.614298105239868, acc: 0.2887323796749115)
[2024-12-17 02:23:27,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,349][root][INFO] - Training Epoch: 1/2, step 5820/7134 completed (loss: 3.442244529724121, acc: 0.28925618529319763)
[2024-12-17 02:23:27,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:27,709][root][INFO] - Training Epoch: 1/2, step 5821/7134 completed (loss: 3.694124221801758, acc: 0.33103448152542114)
[2024-12-17 02:23:27,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,046][root][INFO] - Training Epoch: 1/2, step 5822/7134 completed (loss: 3.7717249393463135, acc: 0.28859061002731323)
[2024-12-17 02:23:28,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,421][root][INFO] - Training Epoch: 1/2, step 5823/7134 completed (loss: 3.6030285358428955, acc: 0.2925170063972473)
[2024-12-17 02:23:28,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:28,775][root][INFO] - Training Epoch: 1/2, step 5824/7134 completed (loss: 2.980985403060913, acc: 0.38787877559661865)
[2024-12-17 02:23:28,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,155][root][INFO] - Training Epoch: 1/2, step 5825/7134 completed (loss: 3.7770819664001465, acc: 0.35114502906799316)
[2024-12-17 02:23:29,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,513][root][INFO] - Training Epoch: 1/2, step 5826/7134 completed (loss: 3.661681652069092, acc: 0.3100775182247162)
[2024-12-17 02:23:29,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:29,863][root][INFO] - Training Epoch: 1/2, step 5827/7134 completed (loss: 3.3166627883911133, acc: 0.41129031777381897)
[2024-12-17 02:23:29,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,226][root][INFO] - Training Epoch: 1/2, step 5828/7134 completed (loss: 3.656829595565796, acc: 0.32679739594459534)
[2024-12-17 02:23:30,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,610][root][INFO] - Training Epoch: 1/2, step 5829/7134 completed (loss: 3.3781750202178955, acc: 0.32926830649375916)
[2024-12-17 02:23:30,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:30,969][root][INFO] - Training Epoch: 1/2, step 5830/7134 completed (loss: 3.8184361457824707, acc: 0.3440000116825104)
[2024-12-17 02:23:31,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,325][root][INFO] - Training Epoch: 1/2, step 5831/7134 completed (loss: 3.291207790374756, acc: 0.3979591727256775)
[2024-12-17 02:23:31,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:31,687][root][INFO] - Training Epoch: 1/2, step 5832/7134 completed (loss: 4.2184014320373535, acc: 0.22900763154029846)
[2024-12-17 02:23:31,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,034][root][INFO] - Training Epoch: 1/2, step 5833/7134 completed (loss: 3.224641799926758, acc: 0.3909774422645569)
[2024-12-17 02:23:32,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,399][root][INFO] - Training Epoch: 1/2, step 5834/7134 completed (loss: 3.9951300621032715, acc: 0.31578946113586426)
[2024-12-17 02:23:32,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:32,756][root][INFO] - Training Epoch: 1/2, step 5835/7134 completed (loss: 4.335482597351074, acc: 0.25999999046325684)
[2024-12-17 02:23:32,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,133][root][INFO] - Training Epoch: 1/2, step 5836/7134 completed (loss: 4.475066661834717, acc: 0.21019108593463898)
[2024-12-17 02:23:33,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,490][root][INFO] - Training Epoch: 1/2, step 5837/7134 completed (loss: 4.421039581298828, acc: 0.281879186630249)
[2024-12-17 02:23:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:33,855][root][INFO] - Training Epoch: 1/2, step 5838/7134 completed (loss: 4.073892593383789, acc: 0.2158273309469223)
[2024-12-17 02:23:33,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,221][root][INFO] - Training Epoch: 1/2, step 5839/7134 completed (loss: 4.195547103881836, acc: 0.2971014380455017)
[2024-12-17 02:23:34,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,590][root][INFO] - Training Epoch: 1/2, step 5840/7134 completed (loss: 4.277071475982666, acc: 0.23076923191547394)
[2024-12-17 02:23:34,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:34,943][root][INFO] - Training Epoch: 1/2, step 5841/7134 completed (loss: 4.3591461181640625, acc: 0.2562499940395355)
[2024-12-17 02:23:35,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,320][root][INFO] - Training Epoch: 1/2, step 5842/7134 completed (loss: 3.929821014404297, acc: 0.26446279883384705)
[2024-12-17 02:23:35,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:35,684][root][INFO] - Training Epoch: 1/2, step 5843/7134 completed (loss: 3.7031805515289307, acc: 0.3273809552192688)
[2024-12-17 02:23:35,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,050][root][INFO] - Training Epoch: 1/2, step 5844/7134 completed (loss: 3.542905569076538, acc: 0.3192771077156067)
[2024-12-17 02:23:36,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,406][root][INFO] - Training Epoch: 1/2, step 5845/7134 completed (loss: 3.7691729068756104, acc: 0.31168830394744873)
[2024-12-17 02:23:36,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:36,820][root][INFO] - Training Epoch: 1/2, step 5846/7134 completed (loss: 3.787961721420288, acc: 0.3511904776096344)
[2024-12-17 02:23:36,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,180][root][INFO] - Training Epoch: 1/2, step 5847/7134 completed (loss: 3.7203567028045654, acc: 0.28313252329826355)
[2024-12-17 02:23:37,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,562][root][INFO] - Training Epoch: 1/2, step 5848/7134 completed (loss: 3.79742431640625, acc: 0.30405405163764954)
[2024-12-17 02:23:37,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:37,963][root][INFO] - Training Epoch: 1/2, step 5849/7134 completed (loss: 3.9572131633758545, acc: 0.31168830394744873)
[2024-12-17 02:23:38,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,340][root][INFO] - Training Epoch: 1/2, step 5850/7134 completed (loss: 4.268159866333008, acc: 0.31690141558647156)
[2024-12-17 02:23:38,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:38,722][root][INFO] - Training Epoch: 1/2, step 5851/7134 completed (loss: 4.2733659744262695, acc: 0.28082191944122314)
[2024-12-17 02:23:38,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,104][root][INFO] - Training Epoch: 1/2, step 5852/7134 completed (loss: 3.7792465686798096, acc: 0.28671327233314514)
[2024-12-17 02:23:39,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,470][root][INFO] - Training Epoch: 1/2, step 5853/7134 completed (loss: 4.0425944328308105, acc: 0.3258427083492279)
[2024-12-17 02:23:39,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:39,828][root][INFO] - Training Epoch: 1/2, step 5854/7134 completed (loss: 4.0479736328125, acc: 0.30000001192092896)
[2024-12-17 02:23:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,166][root][INFO] - Training Epoch: 1/2, step 5855/7134 completed (loss: 4.164753437042236, acc: 0.27966102957725525)
[2024-12-17 02:23:40,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,500][root][INFO] - Training Epoch: 1/2, step 5856/7134 completed (loss: 3.8980205059051514, acc: 0.3309859037399292)
[2024-12-17 02:23:40,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:40,855][root][INFO] - Training Epoch: 1/2, step 5857/7134 completed (loss: 3.9617295265197754, acc: 0.3308270573616028)
[2024-12-17 02:23:40,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,196][root][INFO] - Training Epoch: 1/2, step 5858/7134 completed (loss: 4.066154479980469, acc: 0.29357796907424927)
[2024-12-17 02:23:41,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,573][root][INFO] - Training Epoch: 1/2, step 5859/7134 completed (loss: 3.783182144165039, acc: 0.3017241358757019)
[2024-12-17 02:23:41,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:41,928][root][INFO] - Training Epoch: 1/2, step 5860/7134 completed (loss: 4.306527614593506, acc: 0.25)
[2024-12-17 02:23:42,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,267][root][INFO] - Training Epoch: 1/2, step 5861/7134 completed (loss: 3.959857940673828, acc: 0.2857142984867096)
[2024-12-17 02:23:42,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,628][root][INFO] - Training Epoch: 1/2, step 5862/7134 completed (loss: 4.0109992027282715, acc: 0.2118644118309021)
[2024-12-17 02:23:42,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:42,932][root][INFO] - Training Epoch: 1/2, step 5863/7134 completed (loss: 4.387723445892334, acc: 0.25806450843811035)
[2024-12-17 02:23:43,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,285][root][INFO] - Training Epoch: 1/2, step 5864/7134 completed (loss: 4.184295654296875, acc: 0.22807016968727112)
[2024-12-17 02:23:43,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:43,654][root][INFO] - Training Epoch: 1/2, step 5865/7134 completed (loss: 3.932339906692505, acc: 0.3125)
[2024-12-17 02:23:43,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,021][root][INFO] - Training Epoch: 1/2, step 5866/7134 completed (loss: 3.9323604106903076, acc: 0.35164836049079895)
[2024-12-17 02:23:44,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,408][root][INFO] - Training Epoch: 1/2, step 5867/7134 completed (loss: 4.138279914855957, acc: 0.29729729890823364)
[2024-12-17 02:23:44,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:44,774][root][INFO] - Training Epoch: 1/2, step 5868/7134 completed (loss: 4.301454067230225, acc: 0.3137255012989044)
[2024-12-17 02:23:44,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,116][root][INFO] - Training Epoch: 1/2, step 5869/7134 completed (loss: 3.262847423553467, acc: 0.38323354721069336)
[2024-12-17 02:23:45,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,482][root][INFO] - Training Epoch: 1/2, step 5870/7134 completed (loss: 3.7774479389190674, acc: 0.2777777910232544)
[2024-12-17 02:23:45,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:45,826][root][INFO] - Training Epoch: 1/2, step 5871/7134 completed (loss: 3.428657293319702, acc: 0.3486238420009613)
[2024-12-17 02:23:45,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,199][root][INFO] - Training Epoch: 1/2, step 5872/7134 completed (loss: 3.8503592014312744, acc: 0.3354037404060364)
[2024-12-17 02:23:46,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,608][root][INFO] - Training Epoch: 1/2, step 5873/7134 completed (loss: 3.747631072998047, acc: 0.3636363744735718)
[2024-12-17 02:23:46,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:46,942][root][INFO] - Training Epoch: 1/2, step 5874/7134 completed (loss: 3.830786943435669, acc: 0.3253968358039856)
[2024-12-17 02:23:47,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,272][root][INFO] - Training Epoch: 1/2, step 5875/7134 completed (loss: 3.2222254276275635, acc: 0.42424243688583374)
[2024-12-17 02:23:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,641][root][INFO] - Training Epoch: 1/2, step 5876/7134 completed (loss: 3.7669198513031006, acc: 0.3932584226131439)
[2024-12-17 02:23:47,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:47,998][root][INFO] - Training Epoch: 1/2, step 5877/7134 completed (loss: 3.444309949874878, acc: 0.34078213572502136)
[2024-12-17 02:23:48,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,379][root][INFO] - Training Epoch: 1/2, step 5878/7134 completed (loss: 3.48876953125, acc: 0.41818180680274963)
[2024-12-17 02:23:48,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:48,727][root][INFO] - Training Epoch: 1/2, step 5879/7134 completed (loss: 3.2757630348205566, acc: 0.4000000059604645)
[2024-12-17 02:23:48,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,058][root][INFO] - Training Epoch: 1/2, step 5880/7134 completed (loss: 3.7211709022521973, acc: 0.3035714328289032)
[2024-12-17 02:23:49,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,376][root][INFO] - Training Epoch: 1/2, step 5881/7134 completed (loss: 3.4304087162017822, acc: 0.36752137541770935)
[2024-12-17 02:23:49,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:49,702][root][INFO] - Training Epoch: 1/2, step 5882/7134 completed (loss: 3.51523494720459, acc: 0.29411765933036804)
[2024-12-17 02:23:49,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,039][root][INFO] - Training Epoch: 1/2, step 5883/7134 completed (loss: 3.696258783340454, acc: 0.29230770468711853)
[2024-12-17 02:23:50,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,399][root][INFO] - Training Epoch: 1/2, step 5884/7134 completed (loss: 3.6413156986236572, acc: 0.3333333432674408)
[2024-12-17 02:23:50,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:50,784][root][INFO] - Training Epoch: 1/2, step 5885/7134 completed (loss: 3.709947109222412, acc: 0.4117647111415863)
[2024-12-17 02:23:50,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,130][root][INFO] - Training Epoch: 1/2, step 5886/7134 completed (loss: 3.8635189533233643, acc: 0.3095238208770752)
[2024-12-17 02:23:51,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,500][root][INFO] - Training Epoch: 1/2, step 5887/7134 completed (loss: 3.1553616523742676, acc: 0.375)
[2024-12-17 02:23:51,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:51,867][root][INFO] - Training Epoch: 1/2, step 5888/7134 completed (loss: 3.4997096061706543, acc: 0.3333333432674408)
[2024-12-17 02:23:51,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,198][root][INFO] - Training Epoch: 1/2, step 5889/7134 completed (loss: 4.388678550720215, acc: 0.26923078298568726)
[2024-12-17 02:23:52,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,573][root][INFO] - Training Epoch: 1/2, step 5890/7134 completed (loss: 3.345837116241455, acc: 0.36486485600471497)
[2024-12-17 02:23:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:52,950][root][INFO] - Training Epoch: 1/2, step 5891/7134 completed (loss: 3.5658438205718994, acc: 0.3214285671710968)
[2024-12-17 02:23:53,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,318][root][INFO] - Training Epoch: 1/2, step 5892/7134 completed (loss: 3.3875579833984375, acc: 0.3255814015865326)
[2024-12-17 02:23:53,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:53,679][root][INFO] - Training Epoch: 1/2, step 5893/7134 completed (loss: 3.186537742614746, acc: 0.39263802766799927)
[2024-12-17 02:23:53,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,037][root][INFO] - Training Epoch: 1/2, step 5894/7134 completed (loss: 4.0261454582214355, acc: 0.28378379344940186)
[2024-12-17 02:23:54,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,398][root][INFO] - Training Epoch: 1/2, step 5895/7134 completed (loss: 3.94852352142334, acc: 0.2708333432674408)
[2024-12-17 02:23:54,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:54,758][root][INFO] - Training Epoch: 1/2, step 5896/7134 completed (loss: 3.8636229038238525, acc: 0.29559749364852905)
[2024-12-17 02:23:54,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,121][root][INFO] - Training Epoch: 1/2, step 5897/7134 completed (loss: 3.7346112728118896, acc: 0.3011363744735718)
[2024-12-17 02:23:55,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,474][root][INFO] - Training Epoch: 1/2, step 5898/7134 completed (loss: 3.998530626296997, acc: 0.2589285671710968)
[2024-12-17 02:23:55,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:55,812][root][INFO] - Training Epoch: 1/2, step 5899/7134 completed (loss: 3.2133102416992188, acc: 0.3076923191547394)
[2024-12-17 02:23:55,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,172][root][INFO] - Training Epoch: 1/2, step 5900/7134 completed (loss: 3.7391138076782227, acc: 0.3827160596847534)
[2024-12-17 02:23:56,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,519][root][INFO] - Training Epoch: 1/2, step 5901/7134 completed (loss: 3.588665723800659, acc: 0.3298968970775604)
[2024-12-17 02:23:56,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:56,887][root][INFO] - Training Epoch: 1/2, step 5902/7134 completed (loss: 3.558295965194702, acc: 0.33673468232154846)
[2024-12-17 02:23:57,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,256][root][INFO] - Training Epoch: 1/2, step 5903/7134 completed (loss: 3.3737738132476807, acc: 0.4247787594795227)
[2024-12-17 02:23:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,641][root][INFO] - Training Epoch: 1/2, step 5904/7134 completed (loss: 4.362384796142578, acc: 0.34507042169570923)
[2024-12-17 02:23:57,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:57,971][root][INFO] - Training Epoch: 1/2, step 5905/7134 completed (loss: 3.85745906829834, acc: 0.36486485600471497)
[2024-12-17 02:23:58,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,347][root][INFO] - Training Epoch: 1/2, step 5906/7134 completed (loss: 3.823945999145508, acc: 0.29411765933036804)
[2024-12-17 02:23:58,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:58,725][root][INFO] - Training Epoch: 1/2, step 5907/7134 completed (loss: 4.066636562347412, acc: 0.4097222089767456)
[2024-12-17 02:23:58,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,123][root][INFO] - Training Epoch: 1/2, step 5908/7134 completed (loss: 3.7600414752960205, acc: 0.3571428656578064)
[2024-12-17 02:23:59,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:23:59,602][root][INFO] - Training Epoch: 1/2, step 5909/7134 completed (loss: 4.01959228515625, acc: 0.29927006363868713)
[2024-12-17 02:23:59,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,001][root][INFO] - Training Epoch: 1/2, step 5910/7134 completed (loss: 3.765707015991211, acc: 0.37748345732688904)
[2024-12-17 02:24:00,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,382][root][INFO] - Training Epoch: 1/2, step 5911/7134 completed (loss: 4.238745212554932, acc: 0.313043475151062)
[2024-12-17 02:24:00,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:00,743][root][INFO] - Training Epoch: 1/2, step 5912/7134 completed (loss: 4.283482551574707, acc: 0.3125)
[2024-12-17 02:24:00,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,133][root][INFO] - Training Epoch: 1/2, step 5913/7134 completed (loss: 3.825698137283325, acc: 0.3195266127586365)
[2024-12-17 02:24:01,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,485][root][INFO] - Training Epoch: 1/2, step 5914/7134 completed (loss: 3.6645307540893555, acc: 0.33571428060531616)
[2024-12-17 02:24:01,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:01,874][root][INFO] - Training Epoch: 1/2, step 5915/7134 completed (loss: 4.002915382385254, acc: 0.290076345205307)
[2024-12-17 02:24:01,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,249][root][INFO] - Training Epoch: 1/2, step 5916/7134 completed (loss: 3.86531925201416, acc: 0.2781457006931305)
[2024-12-17 02:24:02,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,603][root][INFO] - Training Epoch: 1/2, step 5917/7134 completed (loss: 3.9226341247558594, acc: 0.31200000643730164)
[2024-12-17 02:24:02,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:02,985][root][INFO] - Training Epoch: 1/2, step 5918/7134 completed (loss: 4.664515972137451, acc: 0.279720276594162)
[2024-12-17 02:24:03,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,364][root][INFO] - Training Epoch: 1/2, step 5919/7134 completed (loss: 4.267841815948486, acc: 0.3208955228328705)
[2024-12-17 02:24:03,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:03,720][root][INFO] - Training Epoch: 1/2, step 5920/7134 completed (loss: 3.7221012115478516, acc: 0.2985074520111084)
[2024-12-17 02:24:03,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,097][root][INFO] - Training Epoch: 1/2, step 5921/7134 completed (loss: 3.6234564781188965, acc: 0.32758620381355286)
[2024-12-17 02:24:04,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,477][root][INFO] - Training Epoch: 1/2, step 5922/7134 completed (loss: 3.84722638130188, acc: 0.36538460850715637)
[2024-12-17 02:24:04,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:04,848][root][INFO] - Training Epoch: 1/2, step 5923/7134 completed (loss: 3.3667266368865967, acc: 0.3860759437084198)
[2024-12-17 02:24:04,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,221][root][INFO] - Training Epoch: 1/2, step 5924/7134 completed (loss: 4.464621543884277, acc: 0.2884615361690521)
[2024-12-17 02:24:05,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,561][root][INFO] - Training Epoch: 1/2, step 5925/7134 completed (loss: 4.620442867279053, acc: 0.3777777850627899)
[2024-12-17 02:24:05,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:05,916][root][INFO] - Training Epoch: 1/2, step 5926/7134 completed (loss: 4.1586995124816895, acc: 0.31578946113586426)
[2024-12-17 02:24:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,281][root][INFO] - Training Epoch: 1/2, step 5927/7134 completed (loss: 3.92112135887146, acc: 0.375)
[2024-12-17 02:24:06,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:06,643][root][INFO] - Training Epoch: 1/2, step 5928/7134 completed (loss: 4.742443084716797, acc: 0.22972972691059113)
[2024-12-17 02:24:06,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,021][root][INFO] - Training Epoch: 1/2, step 5929/7134 completed (loss: 4.580788612365723, acc: 0.2983871102333069)
[2024-12-17 02:24:07,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,392][root][INFO] - Training Epoch: 1/2, step 5930/7134 completed (loss: 4.341919898986816, acc: 0.23966942727565765)
[2024-12-17 02:24:07,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:07,754][root][INFO] - Training Epoch: 1/2, step 5931/7134 completed (loss: 4.564665794372559, acc: 0.23076923191547394)
[2024-12-17 02:24:07,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,114][root][INFO] - Training Epoch: 1/2, step 5932/7134 completed (loss: 4.67620849609375, acc: 0.30215826630592346)
[2024-12-17 02:24:08,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,474][root][INFO] - Training Epoch: 1/2, step 5933/7134 completed (loss: 4.619276523590088, acc: 0.2647058963775635)
[2024-12-17 02:24:08,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:08,833][root][INFO] - Training Epoch: 1/2, step 5934/7134 completed (loss: 4.282364845275879, acc: 0.30714285373687744)
[2024-12-17 02:24:08,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,183][root][INFO] - Training Epoch: 1/2, step 5935/7134 completed (loss: 3.785487651824951, acc: 0.3196721374988556)
[2024-12-17 02:24:09,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,544][root][INFO] - Training Epoch: 1/2, step 5936/7134 completed (loss: 4.070549011230469, acc: 0.24539877474308014)
[2024-12-17 02:24:09,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:09,915][root][INFO] - Training Epoch: 1/2, step 5937/7134 completed (loss: 4.334625720977783, acc: 0.27464789152145386)
[2024-12-17 02:24:10,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,285][root][INFO] - Training Epoch: 1/2, step 5938/7134 completed (loss: 4.102047920227051, acc: 0.27067670226097107)
[2024-12-17 02:24:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,622][root][INFO] - Training Epoch: 1/2, step 5939/7134 completed (loss: 4.55305814743042, acc: 0.2844827473163605)
[2024-12-17 02:24:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:10,996][root][INFO] - Training Epoch: 1/2, step 5940/7134 completed (loss: 4.323027610778809, acc: 0.22981366515159607)
[2024-12-17 02:24:11,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,341][root][INFO] - Training Epoch: 1/2, step 5941/7134 completed (loss: 3.828303098678589, acc: 0.3095238208770752)
[2024-12-17 02:24:11,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:11,692][root][INFO] - Training Epoch: 1/2, step 5942/7134 completed (loss: 3.6300127506256104, acc: 0.23999999463558197)
[2024-12-17 02:24:11,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,076][root][INFO] - Training Epoch: 1/2, step 5943/7134 completed (loss: 4.280049800872803, acc: 0.20245398581027985)
[2024-12-17 02:24:12,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,452][root][INFO] - Training Epoch: 1/2, step 5944/7134 completed (loss: 3.871814012527466, acc: 0.2806122303009033)
[2024-12-17 02:24:12,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:12,827][root][INFO] - Training Epoch: 1/2, step 5945/7134 completed (loss: 3.3136227130889893, acc: 0.3786982297897339)
[2024-12-17 02:24:12,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,179][root][INFO] - Training Epoch: 1/2, step 5946/7134 completed (loss: 4.0199432373046875, acc: 0.3263888955116272)
[2024-12-17 02:24:13,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,561][root][INFO] - Training Epoch: 1/2, step 5947/7134 completed (loss: 4.0740065574646, acc: 0.26923078298568726)
[2024-12-17 02:24:13,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:13,918][root][INFO] - Training Epoch: 1/2, step 5948/7134 completed (loss: 4.163931369781494, acc: 0.3333333432674408)
[2024-12-17 02:24:14,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,289][root][INFO] - Training Epoch: 1/2, step 5949/7134 completed (loss: 3.811971664428711, acc: 0.3166666626930237)
[2024-12-17 02:24:14,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:14,657][root][INFO] - Training Epoch: 1/2, step 5950/7134 completed (loss: 4.1480584144592285, acc: 0.31683167815208435)
[2024-12-17 02:24:14,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,025][root][INFO] - Training Epoch: 1/2, step 5951/7134 completed (loss: 4.224081993103027, acc: 0.2380952388048172)
[2024-12-17 02:24:15,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,400][root][INFO] - Training Epoch: 1/2, step 5952/7134 completed (loss: 4.21337366104126, acc: 0.2565789520740509)
[2024-12-17 02:24:15,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:15,770][root][INFO] - Training Epoch: 1/2, step 5953/7134 completed (loss: 3.7418110370635986, acc: 0.25471699237823486)
[2024-12-17 02:24:15,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,150][root][INFO] - Training Epoch: 1/2, step 5954/7134 completed (loss: 3.5250966548919678, acc: 0.31683167815208435)
[2024-12-17 02:24:16,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,474][root][INFO] - Training Epoch: 1/2, step 5955/7134 completed (loss: 3.4040346145629883, acc: 0.29629629850387573)
[2024-12-17 02:24:16,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:16,840][root][INFO] - Training Epoch: 1/2, step 5956/7134 completed (loss: 4.055472373962402, acc: 0.25)
[2024-12-17 02:24:16,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,207][root][INFO] - Training Epoch: 1/2, step 5957/7134 completed (loss: 3.5935490131378174, acc: 0.31707316637039185)
[2024-12-17 02:24:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,575][root][INFO] - Training Epoch: 1/2, step 5958/7134 completed (loss: 4.027467727661133, acc: 0.33142855763435364)
[2024-12-17 02:24:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:17,985][root][INFO] - Training Epoch: 1/2, step 5959/7134 completed (loss: 3.6654553413391113, acc: 0.3510638177394867)
[2024-12-17 02:24:18,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,361][root][INFO] - Training Epoch: 1/2, step 5960/7134 completed (loss: 3.6148557662963867, acc: 0.3035714328289032)
[2024-12-17 02:24:18,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:18,713][root][INFO] - Training Epoch: 1/2, step 5961/7134 completed (loss: 4.265645503997803, acc: 0.26851850748062134)
[2024-12-17 02:24:18,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,071][root][INFO] - Training Epoch: 1/2, step 5962/7134 completed (loss: 3.8857054710388184, acc: 0.2620689570903778)
[2024-12-17 02:24:19,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,443][root][INFO] - Training Epoch: 1/2, step 5963/7134 completed (loss: 3.963806390762329, acc: 0.2571428716182709)
[2024-12-17 02:24:19,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:19,821][root][INFO] - Training Epoch: 1/2, step 5964/7134 completed (loss: 3.366926670074463, acc: 0.3779527544975281)
[2024-12-17 02:24:19,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,181][root][INFO] - Training Epoch: 1/2, step 5965/7134 completed (loss: 3.6501996517181396, acc: 0.3205128312110901)
[2024-12-17 02:24:20,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,551][root][INFO] - Training Epoch: 1/2, step 5966/7134 completed (loss: 4.036408424377441, acc: 0.29347825050354004)
[2024-12-17 02:24:20,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:20,918][root][INFO] - Training Epoch: 1/2, step 5967/7134 completed (loss: 4.1673054695129395, acc: 0.2847222089767456)
[2024-12-17 02:24:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,276][root][INFO] - Training Epoch: 1/2, step 5968/7134 completed (loss: 3.9473466873168945, acc: 0.2800000011920929)
[2024-12-17 02:24:21,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,609][root][INFO] - Training Epoch: 1/2, step 5969/7134 completed (loss: 3.5853638648986816, acc: 0.38064515590667725)
[2024-12-17 02:24:21,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:21,959][root][INFO] - Training Epoch: 1/2, step 5970/7134 completed (loss: 3.5098817348480225, acc: 0.28125)
[2024-12-17 02:24:22,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,324][root][INFO] - Training Epoch: 1/2, step 5971/7134 completed (loss: 3.5927088260650635, acc: 0.3210526406764984)
[2024-12-17 02:24:22,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:22,687][root][INFO] - Training Epoch: 1/2, step 5972/7134 completed (loss: 4.135873794555664, acc: 0.25766870379447937)
[2024-12-17 02:24:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,075][root][INFO] - Training Epoch: 1/2, step 5973/7134 completed (loss: 3.703695297241211, acc: 0.2800000011920929)
[2024-12-17 02:24:23,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,453][root][INFO] - Training Epoch: 1/2, step 5974/7134 completed (loss: 3.2739017009735107, acc: 0.31617647409439087)
[2024-12-17 02:24:23,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:23,781][root][INFO] - Training Epoch: 1/2, step 5975/7134 completed (loss: 3.831300973892212, acc: 0.31707316637039185)
[2024-12-17 02:24:23,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,144][root][INFO] - Training Epoch: 1/2, step 5976/7134 completed (loss: 3.753105640411377, acc: 0.24836601316928864)
[2024-12-17 02:24:24,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,489][root][INFO] - Training Epoch: 1/2, step 5977/7134 completed (loss: 3.4944214820861816, acc: 0.375)
[2024-12-17 02:24:24,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:24,853][root][INFO] - Training Epoch: 1/2, step 5978/7134 completed (loss: 3.8379554748535156, acc: 0.2484472095966339)
[2024-12-17 02:24:24,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,203][root][INFO] - Training Epoch: 1/2, step 5979/7134 completed (loss: 3.9727272987365723, acc: 0.2631579041481018)
[2024-12-17 02:24:25,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,571][root][INFO] - Training Epoch: 1/2, step 5980/7134 completed (loss: 3.6123597621917725, acc: 0.32608696818351746)
[2024-12-17 02:24:25,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:25,950][root][INFO] - Training Epoch: 1/2, step 5981/7134 completed (loss: 3.3337669372558594, acc: 0.3096446692943573)
[2024-12-17 02:24:26,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,306][root][INFO] - Training Epoch: 1/2, step 5982/7134 completed (loss: 3.7929739952087402, acc: 0.25)
[2024-12-17 02:24:26,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:26,674][root][INFO] - Training Epoch: 1/2, step 5983/7134 completed (loss: 4.277594089508057, acc: 0.24137930572032928)
[2024-12-17 02:24:26,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,027][root][INFO] - Training Epoch: 1/2, step 5984/7134 completed (loss: 4.01839542388916, acc: 0.23030303418636322)
[2024-12-17 02:24:27,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,386][root][INFO] - Training Epoch: 1/2, step 5985/7134 completed (loss: 3.8597919940948486, acc: 0.26404494047164917)
[2024-12-17 02:24:27,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:27,776][root][INFO] - Training Epoch: 1/2, step 5986/7134 completed (loss: 3.9263389110565186, acc: 0.24867725372314453)
[2024-12-17 02:24:27,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,163][root][INFO] - Training Epoch: 1/2, step 5987/7134 completed (loss: 3.8698465824127197, acc: 0.29756098985671997)
[2024-12-17 02:24:28,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,534][root][INFO] - Training Epoch: 1/2, step 5988/7134 completed (loss: 3.516615152359009, acc: 0.27222222089767456)
[2024-12-17 02:24:28,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:28,893][root][INFO] - Training Epoch: 1/2, step 5989/7134 completed (loss: 3.5159497261047363, acc: 0.30000001192092896)
[2024-12-17 02:24:29,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,270][root][INFO] - Training Epoch: 1/2, step 5990/7134 completed (loss: 3.7625038623809814, acc: 0.27624309062957764)
[2024-12-17 02:24:29,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,587][root][INFO] - Training Epoch: 1/2, step 5991/7134 completed (loss: 3.237042188644409, acc: 0.3295454680919647)
[2024-12-17 02:24:29,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:29,943][root][INFO] - Training Epoch: 1/2, step 5992/7134 completed (loss: 3.186370611190796, acc: 0.38265305757522583)
[2024-12-17 02:24:30,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,285][root][INFO] - Training Epoch: 1/2, step 5993/7134 completed (loss: 3.84019136428833, acc: 0.24719101190567017)
[2024-12-17 02:24:30,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,632][root][INFO] - Training Epoch: 1/2, step 5994/7134 completed (loss: 3.5137670040130615, acc: 0.3305785059928894)
[2024-12-17 02:24:30,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:30,997][root][INFO] - Training Epoch: 1/2, step 5995/7134 completed (loss: 3.4926066398620605, acc: 0.323699414730072)
[2024-12-17 02:24:31,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,365][root][INFO] - Training Epoch: 1/2, step 5996/7134 completed (loss: 3.7943038940429688, acc: 0.30666667222976685)
[2024-12-17 02:24:31,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:31,735][root][INFO] - Training Epoch: 1/2, step 5997/7134 completed (loss: 3.531679630279541, acc: 0.2954545319080353)
[2024-12-17 02:24:31,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,094][root][INFO] - Training Epoch: 1/2, step 5998/7134 completed (loss: 3.5699410438537598, acc: 0.32804232835769653)
[2024-12-17 02:24:32,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,456][root][INFO] - Training Epoch: 1/2, step 5999/7134 completed (loss: 3.0654962062835693, acc: 0.3526569902896881)
[2024-12-17 02:24:32,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:32,773][root][INFO] - Training Epoch: 1/2, step 6000/7134 completed (loss: 3.4695115089416504, acc: 0.3732394278049469)
[2024-12-17 02:24:32,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,154][root][INFO] - Training Epoch: 1/2, step 6001/7134 completed (loss: 3.7703733444213867, acc: 0.3558282256126404)
[2024-12-17 02:24:33,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,514][root][INFO] - Training Epoch: 1/2, step 6002/7134 completed (loss: 3.543290853500366, acc: 0.3305785059928894)
[2024-12-17 02:24:33,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:33,913][root][INFO] - Training Epoch: 1/2, step 6003/7134 completed (loss: 4.090710639953613, acc: 0.33766233921051025)
[2024-12-17 02:24:34,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,279][root][INFO] - Training Epoch: 1/2, step 6004/7134 completed (loss: 3.981215715408325, acc: 0.3641618490219116)
[2024-12-17 02:24:34,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,601][root][INFO] - Training Epoch: 1/2, step 6005/7134 completed (loss: 3.5846500396728516, acc: 0.37748345732688904)
[2024-12-17 02:24:34,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:34,940][root][INFO] - Training Epoch: 1/2, step 6006/7134 completed (loss: 3.4365394115448, acc: 0.3840000033378601)
[2024-12-17 02:24:35,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,322][root][INFO] - Training Epoch: 1/2, step 6007/7134 completed (loss: 3.702105760574341, acc: 0.29411765933036804)
[2024-12-17 02:24:35,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:35,706][root][INFO] - Training Epoch: 1/2, step 6008/7134 completed (loss: 3.6441633701324463, acc: 0.3776223659515381)
[2024-12-17 02:24:35,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,081][root][INFO] - Training Epoch: 1/2, step 6009/7134 completed (loss: 3.5147056579589844, acc: 0.39849624037742615)
[2024-12-17 02:24:36,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,420][root][INFO] - Training Epoch: 1/2, step 6010/7134 completed (loss: 3.6200942993164062, acc: 0.39240506291389465)
[2024-12-17 02:24:36,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:36,805][root][INFO] - Training Epoch: 1/2, step 6011/7134 completed (loss: 3.696566581726074, acc: 0.363095223903656)
[2024-12-17 02:24:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,148][root][INFO] - Training Epoch: 1/2, step 6012/7134 completed (loss: 3.6122777462005615, acc: 0.31515151262283325)
[2024-12-17 02:24:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,516][root][INFO] - Training Epoch: 1/2, step 6013/7134 completed (loss: 3.8080551624298096, acc: 0.3426966369152069)
[2024-12-17 02:24:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:37,875][root][INFO] - Training Epoch: 1/2, step 6014/7134 completed (loss: 3.8406336307525635, acc: 0.31496062874794006)
[2024-12-17 02:24:37,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,262][root][INFO] - Training Epoch: 1/2, step 6015/7134 completed (loss: 3.640688896179199, acc: 0.3243243098258972)
[2024-12-17 02:24:38,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,615][root][INFO] - Training Epoch: 1/2, step 6016/7134 completed (loss: 3.327603578567505, acc: 0.3918918967247009)
[2024-12-17 02:24:38,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:38,986][root][INFO] - Training Epoch: 1/2, step 6017/7134 completed (loss: 3.152848958969116, acc: 0.42307692766189575)
[2024-12-17 02:24:39,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,348][root][INFO] - Training Epoch: 1/2, step 6018/7134 completed (loss: 3.9137380123138428, acc: 0.36538460850715637)
[2024-12-17 02:24:39,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:39,665][root][INFO] - Training Epoch: 1/2, step 6019/7134 completed (loss: 3.345750093460083, acc: 0.4722222089767456)
[2024-12-17 02:24:39,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,010][root][INFO] - Training Epoch: 1/2, step 6020/7134 completed (loss: 2.6538846492767334, acc: 0.5396825671195984)
[2024-12-17 02:24:40,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,351][root][INFO] - Training Epoch: 1/2, step 6021/7134 completed (loss: 3.1601979732513428, acc: 0.39024388790130615)
[2024-12-17 02:24:40,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:40,731][root][INFO] - Training Epoch: 1/2, step 6022/7134 completed (loss: 3.198363780975342, acc: 0.3815789520740509)
[2024-12-17 02:24:40,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,102][root][INFO] - Training Epoch: 1/2, step 6023/7134 completed (loss: 2.7116219997406006, acc: 0.4204545319080353)
[2024-12-17 02:24:41,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,441][root][INFO] - Training Epoch: 1/2, step 6024/7134 completed (loss: 3.0342917442321777, acc: 0.36538460850715637)
[2024-12-17 02:24:41,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:41,805][root][INFO] - Training Epoch: 1/2, step 6025/7134 completed (loss: 3.296790361404419, acc: 0.35245901346206665)
[2024-12-17 02:24:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,189][root][INFO] - Training Epoch: 1/2, step 6026/7134 completed (loss: 3.2343568801879883, acc: 0.37288135290145874)
[2024-12-17 02:24:42,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,542][root][INFO] - Training Epoch: 1/2, step 6027/7134 completed (loss: 3.156137228012085, acc: 0.31460675597190857)
[2024-12-17 02:24:42,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:42,876][root][INFO] - Training Epoch: 1/2, step 6028/7134 completed (loss: 3.3341331481933594, acc: 0.4166666567325592)
[2024-12-17 02:24:43,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,267][root][INFO] - Training Epoch: 1/2, step 6029/7134 completed (loss: 3.318084716796875, acc: 0.35211268067359924)
[2024-12-17 02:24:43,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:43,699][root][INFO] - Training Epoch: 1/2, step 6030/7134 completed (loss: 3.594064235687256, acc: 0.3030303120613098)
[2024-12-17 02:24:43,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,060][root][INFO] - Training Epoch: 1/2, step 6031/7134 completed (loss: 3.259136915206909, acc: 0.3720930218696594)
[2024-12-17 02:24:44,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,401][root][INFO] - Training Epoch: 1/2, step 6032/7134 completed (loss: 3.5080902576446533, acc: 0.3465346395969391)
[2024-12-17 02:24:44,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:44,785][root][INFO] - Training Epoch: 1/2, step 6033/7134 completed (loss: 3.3452956676483154, acc: 0.3484848439693451)
[2024-12-17 02:24:44,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,132][root][INFO] - Training Epoch: 1/2, step 6034/7134 completed (loss: 3.530324697494507, acc: 0.31343284249305725)
[2024-12-17 02:24:45,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,506][root][INFO] - Training Epoch: 1/2, step 6035/7134 completed (loss: 4.7029619216918945, acc: 0.19718310236930847)
[2024-12-17 02:24:45,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:45,902][root][INFO] - Training Epoch: 1/2, step 6036/7134 completed (loss: 4.622375965118408, acc: 0.2247191071510315)
[2024-12-17 02:24:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,279][root][INFO] - Training Epoch: 1/2, step 6037/7134 completed (loss: 5.283571243286133, acc: 0.19148936867713928)
[2024-12-17 02:24:46,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:46,642][root][INFO] - Training Epoch: 1/2, step 6038/7134 completed (loss: 4.545787811279297, acc: 0.2549019753932953)
[2024-12-17 02:24:46,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,004][root][INFO] - Training Epoch: 1/2, step 6039/7134 completed (loss: 4.430334091186523, acc: 0.30243903398513794)
[2024-12-17 02:24:47,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,383][root][INFO] - Training Epoch: 1/2, step 6040/7134 completed (loss: 4.075123310089111, acc: 0.2907488942146301)
[2024-12-17 02:24:47,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:47,752][root][INFO] - Training Epoch: 1/2, step 6041/7134 completed (loss: 4.364439010620117, acc: 0.27419355511665344)
[2024-12-17 02:24:47,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,133][root][INFO] - Training Epoch: 1/2, step 6042/7134 completed (loss: 3.9416050910949707, acc: 0.29816514253616333)
[2024-12-17 02:24:48,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,479][root][INFO] - Training Epoch: 1/2, step 6043/7134 completed (loss: 4.131355285644531, acc: 0.2849462330341339)
[2024-12-17 02:24:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:48,849][root][INFO] - Training Epoch: 1/2, step 6044/7134 completed (loss: 3.7716317176818848, acc: 0.3095238208770752)
[2024-12-17 02:24:48,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,227][root][INFO] - Training Epoch: 1/2, step 6045/7134 completed (loss: 4.25416898727417, acc: 0.31100478768348694)
[2024-12-17 02:24:49,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,588][root][INFO] - Training Epoch: 1/2, step 6046/7134 completed (loss: 4.62617301940918, acc: 0.2945205569267273)
[2024-12-17 02:24:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:49,941][root][INFO] - Training Epoch: 1/2, step 6047/7134 completed (loss: 4.3874101638793945, acc: 0.2857142984867096)
[2024-12-17 02:24:50,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,320][root][INFO] - Training Epoch: 1/2, step 6048/7134 completed (loss: 4.246997833251953, acc: 0.2195121943950653)
[2024-12-17 02:24:50,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:50,706][root][INFO] - Training Epoch: 1/2, step 6049/7134 completed (loss: 4.788782119750977, acc: 0.2097902148962021)
[2024-12-17 02:24:50,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,090][root][INFO] - Training Epoch: 1/2, step 6050/7134 completed (loss: 4.764529705047607, acc: 0.2196531742811203)
[2024-12-17 02:24:51,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,489][root][INFO] - Training Epoch: 1/2, step 6051/7134 completed (loss: 4.523049354553223, acc: 0.23295454680919647)
[2024-12-17 02:24:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:51,857][root][INFO] - Training Epoch: 1/2, step 6052/7134 completed (loss: 4.354834079742432, acc: 0.24666666984558105)
[2024-12-17 02:24:51,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,220][root][INFO] - Training Epoch: 1/2, step 6053/7134 completed (loss: 4.604713439941406, acc: 0.23893804848194122)
[2024-12-17 02:24:52,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,555][root][INFO] - Training Epoch: 1/2, step 6054/7134 completed (loss: 4.560194492340088, acc: 0.2694300413131714)
[2024-12-17 02:24:52,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:52,903][root][INFO] - Training Epoch: 1/2, step 6055/7134 completed (loss: 4.233217239379883, acc: 0.26623377203941345)
[2024-12-17 02:24:53,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,300][root][INFO] - Training Epoch: 1/2, step 6056/7134 completed (loss: 4.331110954284668, acc: 0.20720720291137695)
[2024-12-17 02:24:53,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:53,678][root][INFO] - Training Epoch: 1/2, step 6057/7134 completed (loss: 3.9805681705474854, acc: 0.20779220759868622)
[2024-12-17 02:24:53,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,054][root][INFO] - Training Epoch: 1/2, step 6058/7134 completed (loss: 3.707336902618408, acc: 0.3050847351551056)
[2024-12-17 02:24:54,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,415][root][INFO] - Training Epoch: 1/2, step 6059/7134 completed (loss: 2.8057138919830322, acc: 0.5068492889404297)
[2024-12-17 02:24:54,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:54,778][root][INFO] - Training Epoch: 1/2, step 6060/7134 completed (loss: 4.141438961029053, acc: 0.29629629850387573)
[2024-12-17 02:24:54,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,156][root][INFO] - Training Epoch: 1/2, step 6061/7134 completed (loss: 4.513852119445801, acc: 0.30281689763069153)
[2024-12-17 02:24:55,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,523][root][INFO] - Training Epoch: 1/2, step 6062/7134 completed (loss: 3.9461581707000732, acc: 0.32275131344795227)
[2024-12-17 02:24:55,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:55,872][root][INFO] - Training Epoch: 1/2, step 6063/7134 completed (loss: 4.644542217254639, acc: 0.22033898532390594)
[2024-12-17 02:24:55,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,239][root][INFO] - Training Epoch: 1/2, step 6064/7134 completed (loss: 4.573836803436279, acc: 0.2484472095966339)
[2024-12-17 02:24:56,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,610][root][INFO] - Training Epoch: 1/2, step 6065/7134 completed (loss: 3.832813024520874, acc: 0.2842639684677124)
[2024-12-17 02:24:56,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:56,943][root][INFO] - Training Epoch: 1/2, step 6066/7134 completed (loss: 4.886392593383789, acc: 0.2666666805744171)
[2024-12-17 02:24:57,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,290][root][INFO] - Training Epoch: 1/2, step 6067/7134 completed (loss: 4.799588203430176, acc: 0.28289473056793213)
[2024-12-17 02:24:57,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:57,698][root][INFO] - Training Epoch: 1/2, step 6068/7134 completed (loss: 4.316929817199707, acc: 0.3027026951313019)
[2024-12-17 02:24:57,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,073][root][INFO] - Training Epoch: 1/2, step 6069/7134 completed (loss: 4.0045928955078125, acc: 0.34117648005485535)
[2024-12-17 02:24:58,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,441][root][INFO] - Training Epoch: 1/2, step 6070/7134 completed (loss: 4.321771144866943, acc: 0.2800000011920929)
[2024-12-17 02:24:58,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:58,813][root][INFO] - Training Epoch: 1/2, step 6071/7134 completed (loss: 4.303069114685059, acc: 0.28994083404541016)
[2024-12-17 02:24:58,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,136][root][INFO] - Training Epoch: 1/2, step 6072/7134 completed (loss: 4.553125381469727, acc: 0.3583333194255829)
[2024-12-17 02:24:59,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,503][root][INFO] - Training Epoch: 1/2, step 6073/7134 completed (loss: 4.829057693481445, acc: 0.31847134232521057)
[2024-12-17 02:24:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:24:59,853][root][INFO] - Training Epoch: 1/2, step 6074/7134 completed (loss: 4.4712677001953125, acc: 0.23870967328548431)
[2024-12-17 02:24:59,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,230][root][INFO] - Training Epoch: 1/2, step 6075/7134 completed (loss: 4.3167948722839355, acc: 0.27368420362472534)
[2024-12-17 02:25:00,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,609][root][INFO] - Training Epoch: 1/2, step 6076/7134 completed (loss: 3.885061740875244, acc: 0.33155080676078796)
[2024-12-17 02:25:00,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:00,987][root][INFO] - Training Epoch: 1/2, step 6077/7134 completed (loss: 4.024932861328125, acc: 0.2840236723423004)
[2024-12-17 02:25:01,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,360][root][INFO] - Training Epoch: 1/2, step 6078/7134 completed (loss: 3.957568883895874, acc: 0.3050847351551056)
[2024-12-17 02:25:01,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:01,737][root][INFO] - Training Epoch: 1/2, step 6079/7134 completed (loss: 4.230286121368408, acc: 0.2348484843969345)
[2024-12-17 02:25:01,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,092][root][INFO] - Training Epoch: 1/2, step 6080/7134 completed (loss: 3.994978904724121, acc: 0.2816092073917389)
[2024-12-17 02:25:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,482][root][INFO] - Training Epoch: 1/2, step 6081/7134 completed (loss: 4.323390007019043, acc: 0.29729729890823364)
[2024-12-17 02:25:02,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:02,861][root][INFO] - Training Epoch: 1/2, step 6082/7134 completed (loss: 3.8298888206481934, acc: 0.3154362440109253)
[2024-12-17 02:25:02,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,232][root][INFO] - Training Epoch: 1/2, step 6083/7134 completed (loss: 3.6589086055755615, acc: 0.3316062092781067)
[2024-12-17 02:25:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,584][root][INFO] - Training Epoch: 1/2, step 6084/7134 completed (loss: 3.9145376682281494, acc: 0.3333333432674408)
[2024-12-17 02:25:03,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:03,949][root][INFO] - Training Epoch: 1/2, step 6085/7134 completed (loss: 3.5471887588500977, acc: 0.3611111044883728)
[2024-12-17 02:25:04,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,331][root][INFO] - Training Epoch: 1/2, step 6086/7134 completed (loss: 3.2366106510162354, acc: 0.32786884903907776)
[2024-12-17 02:25:04,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:04,714][root][INFO] - Training Epoch: 1/2, step 6087/7134 completed (loss: 4.144259452819824, acc: 0.29901960492134094)
[2024-12-17 02:25:04,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,084][root][INFO] - Training Epoch: 1/2, step 6088/7134 completed (loss: 3.7718238830566406, acc: 0.3513513505458832)
[2024-12-17 02:25:05,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,437][root][INFO] - Training Epoch: 1/2, step 6089/7134 completed (loss: 3.870840311050415, acc: 0.3142857253551483)
[2024-12-17 02:25:05,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:05,820][root][INFO] - Training Epoch: 1/2, step 6090/7134 completed (loss: 3.5555338859558105, acc: 0.29946523904800415)
[2024-12-17 02:25:05,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,171][root][INFO] - Training Epoch: 1/2, step 6091/7134 completed (loss: 3.8856046199798584, acc: 0.337579607963562)
[2024-12-17 02:25:06,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,538][root][INFO] - Training Epoch: 1/2, step 6092/7134 completed (loss: 3.241199493408203, acc: 0.3272727131843567)
[2024-12-17 02:25:06,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:06,900][root][INFO] - Training Epoch: 1/2, step 6093/7134 completed (loss: 3.6336727142333984, acc: 0.31343284249305725)
[2024-12-17 02:25:07,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,269][root][INFO] - Training Epoch: 1/2, step 6094/7134 completed (loss: 5.01767110824585, acc: 0.22727273404598236)
[2024-12-17 02:25:07,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:07,636][root][INFO] - Training Epoch: 1/2, step 6095/7134 completed (loss: 4.376989841461182, acc: 0.30674847960472107)
[2024-12-17 02:25:07,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,019][root][INFO] - Training Epoch: 1/2, step 6096/7134 completed (loss: 4.712653160095215, acc: 0.2690355181694031)
[2024-12-17 02:25:08,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,361][root][INFO] - Training Epoch: 1/2, step 6097/7134 completed (loss: 4.755434513092041, acc: 0.2484472095966339)
[2024-12-17 02:25:08,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:08,731][root][INFO] - Training Epoch: 1/2, step 6098/7134 completed (loss: 4.292416572570801, acc: 0.27485379576683044)
[2024-12-17 02:25:08,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,075][root][INFO] - Training Epoch: 1/2, step 6099/7134 completed (loss: 4.469539642333984, acc: 0.2448979616165161)
[2024-12-17 02:25:09,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,434][root][INFO] - Training Epoch: 1/2, step 6100/7134 completed (loss: 3.753319025039673, acc: 0.3076923191547394)
[2024-12-17 02:25:09,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:09,805][root][INFO] - Training Epoch: 1/2, step 6101/7134 completed (loss: 4.608035564422607, acc: 0.2222222238779068)
[2024-12-17 02:25:09,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,155][root][INFO] - Training Epoch: 1/2, step 6102/7134 completed (loss: 4.526025295257568, acc: 0.2109375)
[2024-12-17 02:25:10,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,534][root][INFO] - Training Epoch: 1/2, step 6103/7134 completed (loss: 4.335458755493164, acc: 0.33636364340782166)
[2024-12-17 02:25:10,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:10,893][root][INFO] - Training Epoch: 1/2, step 6104/7134 completed (loss: 4.960318088531494, acc: 0.25)
[2024-12-17 02:25:11,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,251][root][INFO] - Training Epoch: 1/2, step 6105/7134 completed (loss: 5.22786808013916, acc: 0.2181818187236786)
[2024-12-17 02:25:11,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,597][root][INFO] - Training Epoch: 1/2, step 6106/7134 completed (loss: 4.309167385101318, acc: 0.36220473051071167)
[2024-12-17 02:25:11,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:11,961][root][INFO] - Training Epoch: 1/2, step 6107/7134 completed (loss: 4.2011260986328125, acc: 0.23076923191547394)
[2024-12-17 02:25:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,332][root][INFO] - Training Epoch: 1/2, step 6108/7134 completed (loss: 4.087996006011963, acc: 0.2975206673145294)
[2024-12-17 02:25:12,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:12,688][root][INFO] - Training Epoch: 1/2, step 6109/7134 completed (loss: 3.7912230491638184, acc: 0.38260868191719055)
[2024-12-17 02:25:12,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,055][root][INFO] - Training Epoch: 1/2, step 6110/7134 completed (loss: 4.057408332824707, acc: 0.3359375)
[2024-12-17 02:25:13,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,404][root][INFO] - Training Epoch: 1/2, step 6111/7134 completed (loss: 3.7571444511413574, acc: 0.3804347813129425)
[2024-12-17 02:25:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:13,769][root][INFO] - Training Epoch: 1/2, step 6112/7134 completed (loss: 4.144757270812988, acc: 0.2875817120075226)
[2024-12-17 02:25:13,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,132][root][INFO] - Training Epoch: 1/2, step 6113/7134 completed (loss: 4.038792133331299, acc: 0.29878050088882446)
[2024-12-17 02:25:14,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,476][root][INFO] - Training Epoch: 1/2, step 6114/7134 completed (loss: 4.02349328994751, acc: 0.2237762212753296)
[2024-12-17 02:25:14,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:14,863][root][INFO] - Training Epoch: 1/2, step 6115/7134 completed (loss: 3.766524076461792, acc: 0.3199999928474426)
[2024-12-17 02:25:14,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,192][root][INFO] - Training Epoch: 1/2, step 6116/7134 completed (loss: 4.005501747131348, acc: 0.29032257199287415)
[2024-12-17 02:25:15,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,565][root][INFO] - Training Epoch: 1/2, step 6117/7134 completed (loss: 3.983705520629883, acc: 0.3053892254829407)
[2024-12-17 02:25:15,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:15,980][root][INFO] - Training Epoch: 1/2, step 6118/7134 completed (loss: 3.706786632537842, acc: 0.3492063581943512)
[2024-12-17 02:25:16,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,370][root][INFO] - Training Epoch: 1/2, step 6119/7134 completed (loss: 4.222016334533691, acc: 0.29729729890823364)
[2024-12-17 02:25:16,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:16,744][root][INFO] - Training Epoch: 1/2, step 6120/7134 completed (loss: 3.746957540512085, acc: 0.3712121248245239)
[2024-12-17 02:25:16,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,123][root][INFO] - Training Epoch: 1/2, step 6121/7134 completed (loss: 3.5274922847747803, acc: 0.4094488322734833)
[2024-12-17 02:25:17,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,481][root][INFO] - Training Epoch: 1/2, step 6122/7134 completed (loss: 4.06415319442749, acc: 0.25806450843811035)
[2024-12-17 02:25:17,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:17,814][root][INFO] - Training Epoch: 1/2, step 6123/7134 completed (loss: 3.6101443767547607, acc: 0.38461539149284363)
[2024-12-17 02:25:17,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,189][root][INFO] - Training Epoch: 1/2, step 6124/7134 completed (loss: 4.12467622756958, acc: 0.27731093764305115)
[2024-12-17 02:25:18,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,574][root][INFO] - Training Epoch: 1/2, step 6125/7134 completed (loss: 3.3600637912750244, acc: 0.336448609828949)
[2024-12-17 02:25:18,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:18,934][root][INFO] - Training Epoch: 1/2, step 6126/7134 completed (loss: 3.836686611175537, acc: 0.3178808093070984)
[2024-12-17 02:25:19,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,310][root][INFO] - Training Epoch: 1/2, step 6127/7134 completed (loss: 4.324265956878662, acc: 0.23529411852359772)
[2024-12-17 02:25:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:19,688][root][INFO] - Training Epoch: 1/2, step 6128/7134 completed (loss: 4.201981067657471, acc: 0.26050421595573425)
[2024-12-17 02:25:19,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,071][root][INFO] - Training Epoch: 1/2, step 6129/7134 completed (loss: 4.471202373504639, acc: 0.27218934893608093)
[2024-12-17 02:25:20,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,440][root][INFO] - Training Epoch: 1/2, step 6130/7134 completed (loss: 4.438965797424316, acc: 0.28358209133148193)
[2024-12-17 02:25:20,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:20,808][root][INFO] - Training Epoch: 1/2, step 6131/7134 completed (loss: 5.0807881355285645, acc: 0.18446601927280426)
[2024-12-17 02:25:20,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,134][root][INFO] - Training Epoch: 1/2, step 6132/7134 completed (loss: 4.789430618286133, acc: 0.18589743971824646)
[2024-12-17 02:25:21,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,515][root][INFO] - Training Epoch: 1/2, step 6133/7134 completed (loss: 4.98386287689209, acc: 0.25)
[2024-12-17 02:25:21,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:21,858][root][INFO] - Training Epoch: 1/2, step 6134/7134 completed (loss: 4.690564155578613, acc: 0.24277456104755402)
[2024-12-17 02:25:21,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,242][root][INFO] - Training Epoch: 1/2, step 6135/7134 completed (loss: 4.701081275939941, acc: 0.1860465109348297)
[2024-12-17 02:25:22,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,613][root][INFO] - Training Epoch: 1/2, step 6136/7134 completed (loss: 4.663277626037598, acc: 0.21556885540485382)
[2024-12-17 02:25:22,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:22,963][root][INFO] - Training Epoch: 1/2, step 6137/7134 completed (loss: 4.440348148345947, acc: 0.22727273404598236)
[2024-12-17 02:25:23,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,329][root][INFO] - Training Epoch: 1/2, step 6138/7134 completed (loss: 4.221595764160156, acc: 0.25766870379447937)
[2024-12-17 02:25:23,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:23,673][root][INFO] - Training Epoch: 1/2, step 6139/7134 completed (loss: 4.317882537841797, acc: 0.31292515993118286)
[2024-12-17 02:25:23,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,059][root][INFO] - Training Epoch: 1/2, step 6140/7134 completed (loss: 4.2126007080078125, acc: 0.2846153974533081)
[2024-12-17 02:25:24,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,410][root][INFO] - Training Epoch: 1/2, step 6141/7134 completed (loss: 5.056342124938965, acc: 0.2753623127937317)
[2024-12-17 02:25:24,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:24,770][root][INFO] - Training Epoch: 1/2, step 6142/7134 completed (loss: 4.44943380355835, acc: 0.23999999463558197)
[2024-12-17 02:25:24,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,141][root][INFO] - Training Epoch: 1/2, step 6143/7134 completed (loss: 4.552007675170898, acc: 0.260606050491333)
[2024-12-17 02:25:25,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,503][root][INFO] - Training Epoch: 1/2, step 6144/7134 completed (loss: 4.564131736755371, acc: 0.2397260218858719)
[2024-12-17 02:25:25,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:25,863][root][INFO] - Training Epoch: 1/2, step 6145/7134 completed (loss: 4.252049446105957, acc: 0.25136610865592957)
[2024-12-17 02:25:25,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,231][root][INFO] - Training Epoch: 1/2, step 6146/7134 completed (loss: 4.168371200561523, acc: 0.2409638613462448)
[2024-12-17 02:25:26,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:26,594][root][INFO] - Training Epoch: 1/2, step 6147/7134 completed (loss: 3.8497378826141357, acc: 0.33070865273475647)
[2024-12-17 02:25:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,013][root][INFO] - Training Epoch: 1/2, step 6148/7134 completed (loss: 4.6478986740112305, acc: 0.2689655125141144)
[2024-12-17 02:25:27,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,401][root][INFO] - Training Epoch: 1/2, step 6149/7134 completed (loss: 4.717762470245361, acc: 0.19205297529697418)
[2024-12-17 02:25:27,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:27,764][root][INFO] - Training Epoch: 1/2, step 6150/7134 completed (loss: 4.249354362487793, acc: 0.25874125957489014)
[2024-12-17 02:25:27,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,114][root][INFO] - Training Epoch: 1/2, step 6151/7134 completed (loss: 4.145925998687744, acc: 0.2866241931915283)
[2024-12-17 02:25:28,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,484][root][INFO] - Training Epoch: 1/2, step 6152/7134 completed (loss: 3.896599054336548, acc: 0.3142857253551483)
[2024-12-17 02:25:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:28,851][root][INFO] - Training Epoch: 1/2, step 6153/7134 completed (loss: 4.145506858825684, acc: 0.25925925374031067)
[2024-12-17 02:25:28,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,231][root][INFO] - Training Epoch: 1/2, step 6154/7134 completed (loss: 4.029910087585449, acc: 0.2983425557613373)
[2024-12-17 02:25:29,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:29,616][root][INFO] - Training Epoch: 1/2, step 6155/7134 completed (loss: 3.9010424613952637, acc: 0.2958579957485199)
[2024-12-17 02:25:29,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,009][root][INFO] - Training Epoch: 1/2, step 6156/7134 completed (loss: 4.4019622802734375, acc: 0.26582279801368713)
[2024-12-17 02:25:30,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,376][root][INFO] - Training Epoch: 1/2, step 6157/7134 completed (loss: 4.145075798034668, acc: 0.2278480976819992)
[2024-12-17 02:25:30,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:30,740][root][INFO] - Training Epoch: 1/2, step 6158/7134 completed (loss: 4.764647483825684, acc: 0.22807016968727112)
[2024-12-17 02:25:30,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,122][root][INFO] - Training Epoch: 1/2, step 6159/7134 completed (loss: 3.8580806255340576, acc: 0.3333333432674408)
[2024-12-17 02:25:31,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,498][root][INFO] - Training Epoch: 1/2, step 6160/7134 completed (loss: 4.2300310134887695, acc: 0.35031846165657043)
[2024-12-17 02:25:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:31,920][root][INFO] - Training Epoch: 1/2, step 6161/7134 completed (loss: 4.405704975128174, acc: 0.29921260476112366)
[2024-12-17 02:25:32,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,298][root][INFO] - Training Epoch: 1/2, step 6162/7134 completed (loss: 3.960550546646118, acc: 0.38461539149284363)
[2024-12-17 02:25:32,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:32,681][root][INFO] - Training Epoch: 1/2, step 6163/7134 completed (loss: 4.159590721130371, acc: 0.341085284948349)
[2024-12-17 02:25:32,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,069][root][INFO] - Training Epoch: 1/2, step 6164/7134 completed (loss: 3.9022202491760254, acc: 0.3841463327407837)
[2024-12-17 02:25:33,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,424][root][INFO] - Training Epoch: 1/2, step 6165/7134 completed (loss: 3.8089733123779297, acc: 0.3358778655529022)
[2024-12-17 02:25:33,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:33,781][root][INFO] - Training Epoch: 1/2, step 6166/7134 completed (loss: 4.067071914672852, acc: 0.29197078943252563)
[2024-12-17 02:25:33,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,170][root][INFO] - Training Epoch: 1/2, step 6167/7134 completed (loss: 3.478325366973877, acc: 0.30813953280448914)
[2024-12-17 02:25:34,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,546][root][INFO] - Training Epoch: 1/2, step 6168/7134 completed (loss: 3.578394651412964, acc: 0.29032257199287415)
[2024-12-17 02:25:34,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:34,897][root][INFO] - Training Epoch: 1/2, step 6169/7134 completed (loss: 3.731635093688965, acc: 0.27108433842658997)
[2024-12-17 02:25:35,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,252][root][INFO] - Training Epoch: 1/2, step 6170/7134 completed (loss: 3.533572196960449, acc: 0.316546767950058)
[2024-12-17 02:25:35,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,625][root][INFO] - Training Epoch: 1/2, step 6171/7134 completed (loss: 3.6475894451141357, acc: 0.3461538553237915)
[2024-12-17 02:25:35,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:35,989][root][INFO] - Training Epoch: 1/2, step 6172/7134 completed (loss: 3.5993449687957764, acc: 0.328125)
[2024-12-17 02:25:36,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,346][root][INFO] - Training Epoch: 1/2, step 6173/7134 completed (loss: 3.802441358566284, acc: 0.3333333432674408)
[2024-12-17 02:25:36,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:36,779][root][INFO] - Training Epoch: 1/2, step 6174/7134 completed (loss: 3.583575963973999, acc: 0.2969697117805481)
[2024-12-17 02:25:36,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,224][root][INFO] - Training Epoch: 1/2, step 6175/7134 completed (loss: 3.746544361114502, acc: 0.327160507440567)
[2024-12-17 02:25:37,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,589][root][INFO] - Training Epoch: 1/2, step 6176/7134 completed (loss: 3.826070547103882, acc: 0.32926830649375916)
[2024-12-17 02:25:37,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:37,997][root][INFO] - Training Epoch: 1/2, step 6177/7134 completed (loss: 3.8387417793273926, acc: 0.24175824224948883)
[2024-12-17 02:25:38,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,348][root][INFO] - Training Epoch: 1/2, step 6178/7134 completed (loss: 3.819681406021118, acc: 0.26143792271614075)
[2024-12-17 02:25:38,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:38,698][root][INFO] - Training Epoch: 1/2, step 6179/7134 completed (loss: 4.57584285736084, acc: 0.25333333015441895)
[2024-12-17 02:25:38,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,044][root][INFO] - Training Epoch: 1/2, step 6180/7134 completed (loss: 4.286844730377197, acc: 0.3085106313228607)
[2024-12-17 02:25:39,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,389][root][INFO] - Training Epoch: 1/2, step 6181/7134 completed (loss: 4.788025379180908, acc: 0.3055555522441864)
[2024-12-17 02:25:39,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:39,766][root][INFO] - Training Epoch: 1/2, step 6182/7134 completed (loss: 4.883251190185547, acc: 0.24806201457977295)
[2024-12-17 02:25:39,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,149][root][INFO] - Training Epoch: 1/2, step 6183/7134 completed (loss: 5.132455825805664, acc: 0.2530864179134369)
[2024-12-17 02:25:40,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,513][root][INFO] - Training Epoch: 1/2, step 6184/7134 completed (loss: 4.881104469299316, acc: 0.24347825348377228)
[2024-12-17 02:25:40,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:40,859][root][INFO] - Training Epoch: 1/2, step 6185/7134 completed (loss: 4.222479820251465, acc: 0.3467741906642914)
[2024-12-17 02:25:40,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,202][root][INFO] - Training Epoch: 1/2, step 6186/7134 completed (loss: 3.996565818786621, acc: 0.32824426889419556)
[2024-12-17 02:25:41,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,582][root][INFO] - Training Epoch: 1/2, step 6187/7134 completed (loss: 3.8841328620910645, acc: 0.35087719559669495)
[2024-12-17 02:25:41,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:41,951][root][INFO] - Training Epoch: 1/2, step 6188/7134 completed (loss: 4.147676467895508, acc: 0.3006536066532135)
[2024-12-17 02:25:42,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,330][root][INFO] - Training Epoch: 1/2, step 6189/7134 completed (loss: 3.955953598022461, acc: 0.28671327233314514)
[2024-12-17 02:25:42,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:42,702][root][INFO] - Training Epoch: 1/2, step 6190/7134 completed (loss: 4.260591983795166, acc: 0.2857142984867096)
[2024-12-17 02:25:42,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,066][root][INFO] - Training Epoch: 1/2, step 6191/7134 completed (loss: 3.3975512981414795, acc: 0.3333333432674408)
[2024-12-17 02:25:43,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,440][root][INFO] - Training Epoch: 1/2, step 6192/7134 completed (loss: 3.545555353164673, acc: 0.33170732855796814)
[2024-12-17 02:25:43,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:43,810][root][INFO] - Training Epoch: 1/2, step 6193/7134 completed (loss: 3.731757164001465, acc: 0.3030303120613098)
[2024-12-17 02:25:43,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,167][root][INFO] - Training Epoch: 1/2, step 6194/7134 completed (loss: 4.407698154449463, acc: 0.24590164422988892)
[2024-12-17 02:25:44,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,528][root][INFO] - Training Epoch: 1/2, step 6195/7134 completed (loss: 4.516356945037842, acc: 0.25471699237823486)
[2024-12-17 02:25:44,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:44,898][root][INFO] - Training Epoch: 1/2, step 6196/7134 completed (loss: 3.510000228881836, acc: 0.35185185074806213)
[2024-12-17 02:25:45,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,265][root][INFO] - Training Epoch: 1/2, step 6197/7134 completed (loss: 3.9294333457946777, acc: 0.27272728085517883)
[2024-12-17 02:25:45,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,619][root][INFO] - Training Epoch: 1/2, step 6198/7134 completed (loss: 3.978971004486084, acc: 0.3097345232963562)
[2024-12-17 02:25:45,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:45,985][root][INFO] - Training Epoch: 1/2, step 6199/7134 completed (loss: 3.6028013229370117, acc: 0.32275131344795227)
[2024-12-17 02:25:46,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,342][root][INFO] - Training Epoch: 1/2, step 6200/7134 completed (loss: 3.7123186588287354, acc: 0.2717948853969574)
[2024-12-17 02:25:46,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:46,711][root][INFO] - Training Epoch: 1/2, step 6201/7134 completed (loss: 3.7956089973449707, acc: 0.31100478768348694)
[2024-12-17 02:25:46,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,069][root][INFO] - Training Epoch: 1/2, step 6202/7134 completed (loss: 3.7326576709747314, acc: 0.3047619163990021)
[2024-12-17 02:25:47,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,428][root][INFO] - Training Epoch: 1/2, step 6203/7134 completed (loss: 4.047974109649658, acc: 0.26744186878204346)
[2024-12-17 02:25:47,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:47,798][root][INFO] - Training Epoch: 1/2, step 6204/7134 completed (loss: 3.7805192470550537, acc: 0.25833332538604736)
[2024-12-17 02:25:47,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,161][root][INFO] - Training Epoch: 1/2, step 6205/7134 completed (loss: 3.864957332611084, acc: 0.3093525171279907)
[2024-12-17 02:25:48,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,514][root][INFO] - Training Epoch: 1/2, step 6206/7134 completed (loss: 3.598356008529663, acc: 0.2981366515159607)
[2024-12-17 02:25:48,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:48,887][root][INFO] - Training Epoch: 1/2, step 6207/7134 completed (loss: 3.9446218013763428, acc: 0.260606050491333)
[2024-12-17 02:25:48,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,251][root][INFO] - Training Epoch: 1/2, step 6208/7134 completed (loss: 3.8720321655273438, acc: 0.2760416567325592)
[2024-12-17 02:25:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:49,616][root][INFO] - Training Epoch: 1/2, step 6209/7134 completed (loss: 3.822028398513794, acc: 0.2916666567325592)
[2024-12-17 02:25:49,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,008][root][INFO] - Training Epoch: 1/2, step 6210/7134 completed (loss: 3.5969812870025635, acc: 0.3475935757160187)
[2024-12-17 02:25:50,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,379][root][INFO] - Training Epoch: 1/2, step 6211/7134 completed (loss: 3.64638090133667, acc: 0.30909091234207153)
[2024-12-17 02:25:50,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:50,737][root][INFO] - Training Epoch: 1/2, step 6212/7134 completed (loss: 3.3677072525024414, acc: 0.38461539149284363)
[2024-12-17 02:25:50,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,110][root][INFO] - Training Epoch: 1/2, step 6213/7134 completed (loss: 3.3177835941314697, acc: 0.30000001192092896)
[2024-12-17 02:25:51,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,487][root][INFO] - Training Epoch: 1/2, step 6214/7134 completed (loss: 3.4654955863952637, acc: 0.33898305892944336)
[2024-12-17 02:25:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:51,851][root][INFO] - Training Epoch: 1/2, step 6215/7134 completed (loss: 3.8173294067382812, acc: 0.2753623127937317)
[2024-12-17 02:25:52,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,203][root][INFO] - Training Epoch: 1/2, step 6216/7134 completed (loss: 4.192355155944824, acc: 0.2551020383834839)
[2024-12-17 02:25:52,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,577][root][INFO] - Training Epoch: 1/2, step 6217/7134 completed (loss: 3.7941360473632812, acc: 0.3164556920528412)
[2024-12-17 02:25:52,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:52,972][root][INFO] - Training Epoch: 1/2, step 6218/7134 completed (loss: 3.9492108821868896, acc: 0.28387096524238586)
[2024-12-17 02:25:53,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,339][root][INFO] - Training Epoch: 1/2, step 6219/7134 completed (loss: 3.574932098388672, acc: 0.37254902720451355)
[2024-12-17 02:25:53,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:53,724][root][INFO] - Training Epoch: 1/2, step 6220/7134 completed (loss: 3.9206387996673584, acc: 0.2298850566148758)
[2024-12-17 02:25:53,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,100][root][INFO] - Training Epoch: 1/2, step 6221/7134 completed (loss: 3.557004451751709, acc: 0.3283582031726837)
[2024-12-17 02:25:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,463][root][INFO] - Training Epoch: 1/2, step 6222/7134 completed (loss: 4.144158363342285, acc: 0.3192771077156067)
[2024-12-17 02:25:54,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:54,846][root][INFO] - Training Epoch: 1/2, step 6223/7134 completed (loss: 3.8036251068115234, acc: 0.3697916567325592)
[2024-12-17 02:25:54,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,270][root][INFO] - Training Epoch: 1/2, step 6224/7134 completed (loss: 3.672341823577881, acc: 0.3581081032752991)
[2024-12-17 02:25:55,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:55,670][root][INFO] - Training Epoch: 1/2, step 6225/7134 completed (loss: 3.3975918292999268, acc: 0.42458099126815796)
[2024-12-17 02:25:55,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,044][root][INFO] - Training Epoch: 1/2, step 6226/7134 completed (loss: 3.914576768875122, acc: 0.3586956560611725)
[2024-12-17 02:25:56,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,408][root][INFO] - Training Epoch: 1/2, step 6227/7134 completed (loss: 3.9048409461975098, acc: 0.2750000059604645)
[2024-12-17 02:25:56,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:56,776][root][INFO] - Training Epoch: 1/2, step 6228/7134 completed (loss: 3.868673086166382, acc: 0.3404255211353302)
[2024-12-17 02:25:56,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,209][root][INFO] - Training Epoch: 1/2, step 6229/7134 completed (loss: 3.788709878921509, acc: 0.3853658437728882)
[2024-12-17 02:25:57,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:57,600][root][INFO] - Training Epoch: 1/2, step 6230/7134 completed (loss: 4.155867576599121, acc: 0.33510637283325195)
[2024-12-17 02:25:57,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,033][root][INFO] - Training Epoch: 1/2, step 6231/7134 completed (loss: 4.066465377807617, acc: 0.3040935695171356)
[2024-12-17 02:25:58,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,423][root][INFO] - Training Epoch: 1/2, step 6232/7134 completed (loss: 4.118953704833984, acc: 0.3131868243217468)
[2024-12-17 02:25:58,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:58,815][root][INFO] - Training Epoch: 1/2, step 6233/7134 completed (loss: 3.909811496734619, acc: 0.31609195470809937)
[2024-12-17 02:25:58,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,206][root][INFO] - Training Epoch: 1/2, step 6234/7134 completed (loss: 4.2179107666015625, acc: 0.28333333134651184)
[2024-12-17 02:25:59,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:25:59,614][root][INFO] - Training Epoch: 1/2, step 6235/7134 completed (loss: 3.8397738933563232, acc: 0.369047611951828)
[2024-12-17 02:25:59,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,008][root][INFO] - Training Epoch: 1/2, step 6236/7134 completed (loss: 3.9932665824890137, acc: 0.31843575835227966)
[2024-12-17 02:26:00,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,391][root][INFO] - Training Epoch: 1/2, step 6237/7134 completed (loss: 4.242698669433594, acc: 0.2711864411830902)
[2024-12-17 02:26:00,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:00,713][root][INFO] - Training Epoch: 1/2, step 6238/7134 completed (loss: 3.7307307720184326, acc: 0.3178808093070984)
[2024-12-17 02:26:00,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,081][root][INFO] - Training Epoch: 1/2, step 6239/7134 completed (loss: 4.010665416717529, acc: 0.34196892380714417)
[2024-12-17 02:26:01,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,447][root][INFO] - Training Epoch: 1/2, step 6240/7134 completed (loss: 3.910297393798828, acc: 0.2530120611190796)
[2024-12-17 02:26:01,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:01,840][root][INFO] - Training Epoch: 1/2, step 6241/7134 completed (loss: 3.7640433311462402, acc: 0.2866666615009308)
[2024-12-17 02:26:01,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,215][root][INFO] - Training Epoch: 1/2, step 6242/7134 completed (loss: 3.292410373687744, acc: 0.3401360511779785)
[2024-12-17 02:26:02,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,561][root][INFO] - Training Epoch: 1/2, step 6243/7134 completed (loss: 3.936602830886841, acc: 0.3221476376056671)
[2024-12-17 02:26:02,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:02,953][root][INFO] - Training Epoch: 1/2, step 6244/7134 completed (loss: 3.8970859050750732, acc: 0.299401193857193)
[2024-12-17 02:26:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,400][root][INFO] - Training Epoch: 1/2, step 6245/7134 completed (loss: 3.6412534713745117, acc: 0.3964497148990631)
[2024-12-17 02:26:03,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:03,835][root][INFO] - Training Epoch: 1/2, step 6246/7134 completed (loss: 3.5697391033172607, acc: 0.3475935757160187)
[2024-12-17 02:26:03,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,244][root][INFO] - Training Epoch: 1/2, step 6247/7134 completed (loss: 3.6677517890930176, acc: 0.364130437374115)
[2024-12-17 02:26:04,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,622][root][INFO] - Training Epoch: 1/2, step 6248/7134 completed (loss: 3.730586051940918, acc: 0.35329341888427734)
[2024-12-17 02:26:04,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:04,948][root][INFO] - Training Epoch: 1/2, step 6249/7134 completed (loss: 3.3219079971313477, acc: 0.3509933650493622)
[2024-12-17 02:26:05,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,349][root][INFO] - Training Epoch: 1/2, step 6250/7134 completed (loss: 3.351954698562622, acc: 0.3695652186870575)
[2024-12-17 02:26:05,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:05,736][root][INFO] - Training Epoch: 1/2, step 6251/7134 completed (loss: 3.090364456176758, acc: 0.41059601306915283)
[2024-12-17 02:26:05,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,109][root][INFO] - Training Epoch: 1/2, step 6252/7134 completed (loss: 3.6239824295043945, acc: 0.3928571343421936)
[2024-12-17 02:26:06,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,480][root][INFO] - Training Epoch: 1/2, step 6253/7134 completed (loss: 3.418544292449951, acc: 0.3426573574542999)
[2024-12-17 02:26:06,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:06,812][root][INFO] - Training Epoch: 1/2, step 6254/7134 completed (loss: 3.10490083694458, acc: 0.3955223858356476)
[2024-12-17 02:26:06,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,161][root][INFO] - Training Epoch: 1/2, step 6255/7134 completed (loss: 3.234919548034668, acc: 0.3806818127632141)
[2024-12-17 02:26:07,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,545][root][INFO] - Training Epoch: 1/2, step 6256/7134 completed (loss: 2.8624536991119385, acc: 0.44632768630981445)
[2024-12-17 02:26:07,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:07,951][root][INFO] - Training Epoch: 1/2, step 6257/7134 completed (loss: 3.543720245361328, acc: 0.33136093616485596)
[2024-12-17 02:26:08,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,306][root][INFO] - Training Epoch: 1/2, step 6258/7134 completed (loss: 3.248993396759033, acc: 0.3733333349227905)
[2024-12-17 02:26:08,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:08,677][root][INFO] - Training Epoch: 1/2, step 6259/7134 completed (loss: 3.5973241329193115, acc: 0.30434781312942505)
[2024-12-17 02:26:08,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,097][root][INFO] - Training Epoch: 1/2, step 6260/7134 completed (loss: 2.993652582168579, acc: 0.3949044644832611)
[2024-12-17 02:26:09,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,529][root][INFO] - Training Epoch: 1/2, step 6261/7134 completed (loss: 3.3530094623565674, acc: 0.31677019596099854)
[2024-12-17 02:26:09,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:09,915][root][INFO] - Training Epoch: 1/2, step 6262/7134 completed (loss: 3.2446677684783936, acc: 0.395061731338501)
[2024-12-17 02:26:10,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,282][root][INFO] - Training Epoch: 1/2, step 6263/7134 completed (loss: 2.809675693511963, acc: 0.42307692766189575)
[2024-12-17 02:26:10,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:10,662][root][INFO] - Training Epoch: 1/2, step 6264/7134 completed (loss: 3.2706503868103027, acc: 0.3287671208381653)
[2024-12-17 02:26:10,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,056][root][INFO] - Training Epoch: 1/2, step 6265/7134 completed (loss: 3.269023895263672, acc: 0.4110429584980011)
[2024-12-17 02:26:11,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,411][root][INFO] - Training Epoch: 1/2, step 6266/7134 completed (loss: 3.331470012664795, acc: 0.39230769872665405)
[2024-12-17 02:26:11,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:11,800][root][INFO] - Training Epoch: 1/2, step 6267/7134 completed (loss: 3.019360303878784, acc: 0.3552631437778473)
[2024-12-17 02:26:11,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,183][root][INFO] - Training Epoch: 1/2, step 6268/7134 completed (loss: 3.3243532180786133, acc: 0.38509318232536316)
[2024-12-17 02:26:12,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,584][root][INFO] - Training Epoch: 1/2, step 6269/7134 completed (loss: 2.7947371006011963, acc: 0.3839285671710968)
[2024-12-17 02:26:12,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:12,972][root][INFO] - Training Epoch: 1/2, step 6270/7134 completed (loss: 3.4967527389526367, acc: 0.34210526943206787)
[2024-12-17 02:26:13,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,346][root][INFO] - Training Epoch: 1/2, step 6271/7134 completed (loss: 3.094773054122925, acc: 0.40340909361839294)
[2024-12-17 02:26:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:13,737][root][INFO] - Training Epoch: 1/2, step 6272/7134 completed (loss: 2.6183207035064697, acc: 0.4601227045059204)
[2024-12-17 02:26:13,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,126][root][INFO] - Training Epoch: 1/2, step 6273/7134 completed (loss: 3.227391242980957, acc: 0.36094674468040466)
[2024-12-17 02:26:14,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,506][root][INFO] - Training Epoch: 1/2, step 6274/7134 completed (loss: 3.270078659057617, acc: 0.3195266127586365)
[2024-12-17 02:26:14,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:14,877][root][INFO] - Training Epoch: 1/2, step 6275/7134 completed (loss: 3.7064967155456543, acc: 0.38255032896995544)
[2024-12-17 02:26:14,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,258][root][INFO] - Training Epoch: 1/2, step 6276/7134 completed (loss: 3.8900387287139893, acc: 0.31707316637039185)
[2024-12-17 02:26:15,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,623][root][INFO] - Training Epoch: 1/2, step 6277/7134 completed (loss: 4.286769866943359, acc: 0.3113207519054413)
[2024-12-17 02:26:15,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:15,979][root][INFO] - Training Epoch: 1/2, step 6278/7134 completed (loss: 3.92385196685791, acc: 0.30882352590560913)
[2024-12-17 02:26:16,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,360][root][INFO] - Training Epoch: 1/2, step 6279/7134 completed (loss: 4.222468376159668, acc: 0.2461538463830948)
[2024-12-17 02:26:16,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:16,701][root][INFO] - Training Epoch: 1/2, step 6280/7134 completed (loss: 4.422049045562744, acc: 0.24626865983009338)
[2024-12-17 02:26:16,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,090][root][INFO] - Training Epoch: 1/2, step 6281/7134 completed (loss: 4.016239643096924, acc: 0.22794117033481598)
[2024-12-17 02:26:17,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,489][root][INFO] - Training Epoch: 1/2, step 6282/7134 completed (loss: 4.267630577087402, acc: 0.2152777761220932)
[2024-12-17 02:26:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:17,936][root][INFO] - Training Epoch: 1/2, step 6283/7134 completed (loss: 3.779219627380371, acc: 0.30434781312942505)
[2024-12-17 02:26:18,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,310][root][INFO] - Training Epoch: 1/2, step 6284/7134 completed (loss: 4.238430976867676, acc: 0.2818181812763214)
[2024-12-17 02:26:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:18,715][root][INFO] - Training Epoch: 1/2, step 6285/7134 completed (loss: 4.124548435211182, acc: 0.2631579041481018)
[2024-12-17 02:26:18,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,088][root][INFO] - Training Epoch: 1/2, step 6286/7134 completed (loss: 3.344841957092285, acc: 0.3263888955116272)
[2024-12-17 02:26:19,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,451][root][INFO] - Training Epoch: 1/2, step 6287/7134 completed (loss: 3.7336513996124268, acc: 0.3030303120613098)
[2024-12-17 02:26:19,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:19,803][root][INFO] - Training Epoch: 1/2, step 6288/7134 completed (loss: 3.38185715675354, acc: 0.3191489279270172)
[2024-12-17 02:26:19,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,177][root][INFO] - Training Epoch: 1/2, step 6289/7134 completed (loss: 3.81966233253479, acc: 0.28787878155708313)
[2024-12-17 02:26:20,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,557][root][INFO] - Training Epoch: 1/2, step 6290/7134 completed (loss: 3.6922783851623535, acc: 0.33582088351249695)
[2024-12-17 02:26:20,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:20,912][root][INFO] - Training Epoch: 1/2, step 6291/7134 completed (loss: 3.300077438354492, acc: 0.3712121248245239)
[2024-12-17 02:26:21,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,246][root][INFO] - Training Epoch: 1/2, step 6292/7134 completed (loss: 3.852067470550537, acc: 0.2946428656578064)
[2024-12-17 02:26:21,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:21,642][root][INFO] - Training Epoch: 1/2, step 6293/7134 completed (loss: 3.959862470626831, acc: 0.24848484992980957)
[2024-12-17 02:26:21,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,021][root][INFO] - Training Epoch: 1/2, step 6294/7134 completed (loss: 3.9031918048858643, acc: 0.32894736528396606)
[2024-12-17 02:26:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,359][root][INFO] - Training Epoch: 1/2, step 6295/7134 completed (loss: 3.6892740726470947, acc: 0.32575756311416626)
[2024-12-17 02:26:22,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:22,771][root][INFO] - Training Epoch: 1/2, step 6296/7134 completed (loss: 4.377902030944824, acc: 0.2517985701560974)
[2024-12-17 02:26:22,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,147][root][INFO] - Training Epoch: 1/2, step 6297/7134 completed (loss: 4.657800674438477, acc: 0.2631579041481018)
[2024-12-17 02:26:23,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,538][root][INFO] - Training Epoch: 1/2, step 6298/7134 completed (loss: 4.177713394165039, acc: 0.25)
[2024-12-17 02:26:23,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:23,912][root][INFO] - Training Epoch: 1/2, step 6299/7134 completed (loss: 4.363016605377197, acc: 0.2368421107530594)
[2024-12-17 02:26:24,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,256][root][INFO] - Training Epoch: 1/2, step 6300/7134 completed (loss: 3.4935550689697266, acc: 0.3618420958518982)
[2024-12-17 02:26:24,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:24,644][root][INFO] - Training Epoch: 1/2, step 6301/7134 completed (loss: 3.4947757720947266, acc: 0.33796295523643494)
[2024-12-17 02:26:24,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,090][root][INFO] - Training Epoch: 1/2, step 6302/7134 completed (loss: 3.111953020095825, acc: 0.31284916400909424)
[2024-12-17 02:26:25,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,480][root][INFO] - Training Epoch: 1/2, step 6303/7134 completed (loss: 2.939748764038086, acc: 0.4260089695453644)
[2024-12-17 02:26:25,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:25,846][root][INFO] - Training Epoch: 1/2, step 6304/7134 completed (loss: 3.202505588531494, acc: 0.3181818127632141)
[2024-12-17 02:26:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,212][root][INFO] - Training Epoch: 1/2, step 6305/7134 completed (loss: 2.9903223514556885, acc: 0.34246575832366943)
[2024-12-17 02:26:26,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:26,633][root][INFO] - Training Epoch: 1/2, step 6306/7134 completed (loss: 3.0184571743011475, acc: 0.379146933555603)
[2024-12-17 02:26:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,018][root][INFO] - Training Epoch: 1/2, step 6307/7134 completed (loss: 2.7927629947662354, acc: 0.4198473393917084)
[2024-12-17 02:26:27,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,417][root][INFO] - Training Epoch: 1/2, step 6308/7134 completed (loss: 3.4192352294921875, acc: 0.35233160853385925)
[2024-12-17 02:26:27,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:27,772][root][INFO] - Training Epoch: 1/2, step 6309/7134 completed (loss: 3.4791383743286133, acc: 0.2840236723423004)
[2024-12-17 02:26:27,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,202][root][INFO] - Training Epoch: 1/2, step 6310/7134 completed (loss: 3.6873271465301514, acc: 0.28947368264198303)
[2024-12-17 02:26:28,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,536][root][INFO] - Training Epoch: 1/2, step 6311/7134 completed (loss: 2.9667656421661377, acc: 0.4322916567325592)
[2024-12-17 02:26:28,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:28,884][root][INFO] - Training Epoch: 1/2, step 6312/7134 completed (loss: 3.2686712741851807, acc: 0.35668790340423584)
[2024-12-17 02:26:29,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,252][root][INFO] - Training Epoch: 1/2, step 6313/7134 completed (loss: 3.0956671237945557, acc: 0.4000000059604645)
[2024-12-17 02:26:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,602][root][INFO] - Training Epoch: 1/2, step 6314/7134 completed (loss: 3.554677963256836, acc: 0.33870968222618103)
[2024-12-17 02:26:29,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:29,990][root][INFO] - Training Epoch: 1/2, step 6315/7134 completed (loss: 3.362668514251709, acc: 0.34228187799453735)
[2024-12-17 02:26:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,357][root][INFO] - Training Epoch: 1/2, step 6316/7134 completed (loss: 3.228738307952881, acc: 0.37931033968925476)
[2024-12-17 02:26:30,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:30,731][root][INFO] - Training Epoch: 1/2, step 6317/7134 completed (loss: 3.1875975131988525, acc: 0.3986486494541168)
[2024-12-17 02:26:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,113][root][INFO] - Training Epoch: 1/2, step 6318/7134 completed (loss: 2.886101007461548, acc: 0.43421053886413574)
[2024-12-17 02:26:31,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,486][root][INFO] - Training Epoch: 1/2, step 6319/7134 completed (loss: 3.002052068710327, acc: 0.3822222352027893)
[2024-12-17 02:26:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:31,872][root][INFO] - Training Epoch: 1/2, step 6320/7134 completed (loss: 4.0379791259765625, acc: 0.28378379344940186)
[2024-12-17 02:26:31,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,255][root][INFO] - Training Epoch: 1/2, step 6321/7134 completed (loss: 3.459946870803833, acc: 0.3619047701358795)
[2024-12-17 02:26:32,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,629][root][INFO] - Training Epoch: 1/2, step 6322/7134 completed (loss: 3.705841541290283, acc: 0.337579607963562)
[2024-12-17 02:26:32,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:32,992][root][INFO] - Training Epoch: 1/2, step 6323/7134 completed (loss: 3.7302842140197754, acc: 0.39375001192092896)
[2024-12-17 02:26:33,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,368][root][INFO] - Training Epoch: 1/2, step 6324/7134 completed (loss: 3.607208013534546, acc: 0.3825136721134186)
[2024-12-17 02:26:33,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:33,723][root][INFO] - Training Epoch: 1/2, step 6325/7134 completed (loss: 4.02074670791626, acc: 0.29032257199287415)
[2024-12-17 02:26:33,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,083][root][INFO] - Training Epoch: 1/2, step 6326/7134 completed (loss: 3.794997215270996, acc: 0.31446540355682373)
[2024-12-17 02:26:34,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,434][root][INFO] - Training Epoch: 1/2, step 6327/7134 completed (loss: 3.441373348236084, acc: 0.3186813294887543)
[2024-12-17 02:26:34,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:34,776][root][INFO] - Training Epoch: 1/2, step 6328/7134 completed (loss: 3.7934865951538086, acc: 0.3105590045452118)
[2024-12-17 02:26:34,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,161][root][INFO] - Training Epoch: 1/2, step 6329/7134 completed (loss: 3.4095301628112793, acc: 0.3205128312110901)
[2024-12-17 02:26:35,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,540][root][INFO] - Training Epoch: 1/2, step 6330/7134 completed (loss: 3.4980435371398926, acc: 0.349056601524353)
[2024-12-17 02:26:35,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:35,895][root][INFO] - Training Epoch: 1/2, step 6331/7134 completed (loss: 3.665194511413574, acc: 0.36567163467407227)
[2024-12-17 02:26:36,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,275][root][INFO] - Training Epoch: 1/2, step 6332/7134 completed (loss: 4.048137664794922, acc: 0.304964542388916)
[2024-12-17 02:26:36,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:36,662][root][INFO] - Training Epoch: 1/2, step 6333/7134 completed (loss: 3.8465218544006348, acc: 0.2931034564971924)
[2024-12-17 02:26:36,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,104][root][INFO] - Training Epoch: 1/2, step 6334/7134 completed (loss: 3.400608539581299, acc: 0.3014705777168274)
[2024-12-17 02:26:37,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,567][root][INFO] - Training Epoch: 1/2, step 6335/7134 completed (loss: 3.394773006439209, acc: 0.3757961690425873)
[2024-12-17 02:26:37,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:37,946][root][INFO] - Training Epoch: 1/2, step 6336/7134 completed (loss: 3.666259527206421, acc: 0.3245614171028137)
[2024-12-17 02:26:38,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,319][root][INFO] - Training Epoch: 1/2, step 6337/7134 completed (loss: 3.2191050052642822, acc: 0.3496503531932831)
[2024-12-17 02:26:38,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:38,671][root][INFO] - Training Epoch: 1/2, step 6338/7134 completed (loss: 3.6222164630889893, acc: 0.31446540355682373)
[2024-12-17 02:26:38,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,005][root][INFO] - Training Epoch: 1/2, step 6339/7134 completed (loss: 3.5663444995880127, acc: 0.32679739594459534)
[2024-12-17 02:26:39,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,368][root][INFO] - Training Epoch: 1/2, step 6340/7134 completed (loss: 3.459693670272827, acc: 0.33742332458496094)
[2024-12-17 02:26:39,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:39,754][root][INFO] - Training Epoch: 1/2, step 6341/7134 completed (loss: 3.8271591663360596, acc: 0.30708661675453186)
[2024-12-17 02:26:39,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,129][root][INFO] - Training Epoch: 1/2, step 6342/7134 completed (loss: 3.892305850982666, acc: 0.28901734948158264)
[2024-12-17 02:26:40,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,501][root][INFO] - Training Epoch: 1/2, step 6343/7134 completed (loss: 3.9386091232299805, acc: 0.3561643958091736)
[2024-12-17 02:26:40,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:40,898][root][INFO] - Training Epoch: 1/2, step 6344/7134 completed (loss: 3.4518625736236572, acc: 0.37016573548316956)
[2024-12-17 02:26:41,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,272][root][INFO] - Training Epoch: 1/2, step 6345/7134 completed (loss: 3.7480010986328125, acc: 0.3586956560611725)
[2024-12-17 02:26:41,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,638][root][INFO] - Training Epoch: 1/2, step 6346/7134 completed (loss: 3.830378770828247, acc: 0.302325576543808)
[2024-12-17 02:26:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:41,999][root][INFO] - Training Epoch: 1/2, step 6347/7134 completed (loss: 3.8908112049102783, acc: 0.32773110270500183)
[2024-12-17 02:26:42,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,360][root][INFO] - Training Epoch: 1/2, step 6348/7134 completed (loss: 3.562622547149658, acc: 0.3402777910232544)
[2024-12-17 02:26:42,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:42,719][root][INFO] - Training Epoch: 1/2, step 6349/7134 completed (loss: 3.5460174083709717, acc: 0.35606059432029724)
[2024-12-17 02:26:42,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,082][root][INFO] - Training Epoch: 1/2, step 6350/7134 completed (loss: 3.7874529361724854, acc: 0.3333333432674408)
[2024-12-17 02:26:43,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,452][root][INFO] - Training Epoch: 1/2, step 6351/7134 completed (loss: 3.860910654067993, acc: 0.31137725710868835)
[2024-12-17 02:26:43,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:43,833][root][INFO] - Training Epoch: 1/2, step 6352/7134 completed (loss: 3.9094760417938232, acc: 0.2947976887226105)
[2024-12-17 02:26:43,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,200][root][INFO] - Training Epoch: 1/2, step 6353/7134 completed (loss: 3.757885456085205, acc: 0.38650307059288025)
[2024-12-17 02:26:44,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,578][root][INFO] - Training Epoch: 1/2, step 6354/7134 completed (loss: 3.434384346008301, acc: 0.32758620381355286)
[2024-12-17 02:26:44,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:44,935][root][INFO] - Training Epoch: 1/2, step 6355/7134 completed (loss: 3.4635543823242188, acc: 0.3466666638851166)
[2024-12-17 02:26:45,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,311][root][INFO] - Training Epoch: 1/2, step 6356/7134 completed (loss: 3.3518178462982178, acc: 0.3885350227355957)
[2024-12-17 02:26:45,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:45,685][root][INFO] - Training Epoch: 1/2, step 6357/7134 completed (loss: 3.657402753829956, acc: 0.35151514410972595)
[2024-12-17 02:26:45,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,070][root][INFO] - Training Epoch: 1/2, step 6358/7134 completed (loss: 3.8559489250183105, acc: 0.35672515630722046)
[2024-12-17 02:26:46,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,447][root][INFO] - Training Epoch: 1/2, step 6359/7134 completed (loss: 3.4489874839782715, acc: 0.3631284832954407)
[2024-12-17 02:26:46,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:46,817][root][INFO] - Training Epoch: 1/2, step 6360/7134 completed (loss: 3.9375734329223633, acc: 0.2448979616165161)
[2024-12-17 02:26:46,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,202][root][INFO] - Training Epoch: 1/2, step 6361/7134 completed (loss: 3.5701937675476074, acc: 0.3956834673881531)
[2024-12-17 02:26:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,578][root][INFO] - Training Epoch: 1/2, step 6362/7134 completed (loss: 3.5576462745666504, acc: 0.3677419424057007)
[2024-12-17 02:26:47,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:47,949][root][INFO] - Training Epoch: 1/2, step 6363/7134 completed (loss: 3.5619113445281982, acc: 0.34319525957107544)
[2024-12-17 02:26:48,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,322][root][INFO] - Training Epoch: 1/2, step 6364/7134 completed (loss: 3.5886118412017822, acc: 0.35668790340423584)
[2024-12-17 02:26:48,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:48,676][root][INFO] - Training Epoch: 1/2, step 6365/7134 completed (loss: 3.6815640926361084, acc: 0.32203391194343567)
[2024-12-17 02:26:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,031][root][INFO] - Training Epoch: 1/2, step 6366/7134 completed (loss: 3.5072598457336426, acc: 0.39053255319595337)
[2024-12-17 02:26:49,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,385][root][INFO] - Training Epoch: 1/2, step 6367/7134 completed (loss: 3.754215717315674, acc: 0.3100775182247162)
[2024-12-17 02:26:49,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:49,754][root][INFO] - Training Epoch: 1/2, step 6368/7134 completed (loss: 3.972851037979126, acc: 0.28313252329826355)
[2024-12-17 02:26:49,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,128][root][INFO] - Training Epoch: 1/2, step 6369/7134 completed (loss: 3.7255802154541016, acc: 0.3095238208770752)
[2024-12-17 02:26:50,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,510][root][INFO] - Training Epoch: 1/2, step 6370/7134 completed (loss: 4.379306793212891, acc: 0.27906978130340576)
[2024-12-17 02:26:50,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:50,866][root][INFO] - Training Epoch: 1/2, step 6371/7134 completed (loss: 4.172945976257324, acc: 0.35947713255882263)
[2024-12-17 02:26:50,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,252][root][INFO] - Training Epoch: 1/2, step 6372/7134 completed (loss: 4.485587120056152, acc: 0.27586206793785095)
[2024-12-17 02:26:51,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:51,611][root][INFO] - Training Epoch: 1/2, step 6373/7134 completed (loss: 3.5084445476531982, acc: 0.33870968222618103)
[2024-12-17 02:26:51,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,003][root][INFO] - Training Epoch: 1/2, step 6374/7134 completed (loss: 3.904942274093628, acc: 0.31092438101768494)
[2024-12-17 02:26:52,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,390][root][INFO] - Training Epoch: 1/2, step 6375/7134 completed (loss: 3.464503049850464, acc: 0.4033149182796478)
[2024-12-17 02:26:52,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:52,735][root][INFO] - Training Epoch: 1/2, step 6376/7134 completed (loss: 3.5844321250915527, acc: 0.38211381435394287)
[2024-12-17 02:26:52,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,101][root][INFO] - Training Epoch: 1/2, step 6377/7134 completed (loss: 3.4882800579071045, acc: 0.4399999976158142)
[2024-12-17 02:26:53,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,473][root][INFO] - Training Epoch: 1/2, step 6378/7134 completed (loss: 4.258195400238037, acc: 0.24186046421527863)
[2024-12-17 02:26:53,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:53,830][root][INFO] - Training Epoch: 1/2, step 6379/7134 completed (loss: 3.904568672180176, acc: 0.2789473831653595)
[2024-12-17 02:26:53,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,215][root][INFO] - Training Epoch: 1/2, step 6380/7134 completed (loss: 3.619610548019409, acc: 0.3062500059604645)
[2024-12-17 02:26:54,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,601][root][INFO] - Training Epoch: 1/2, step 6381/7134 completed (loss: 3.8764500617980957, acc: 0.31081080436706543)
[2024-12-17 02:26:54,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:54,974][root][INFO] - Training Epoch: 1/2, step 6382/7134 completed (loss: 3.71059250831604, acc: 0.2967033088207245)
[2024-12-17 02:26:55,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,374][root][INFO] - Training Epoch: 1/2, step 6383/7134 completed (loss: 4.338847637176514, acc: 0.22543352842330933)
[2024-12-17 02:26:55,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:55,752][root][INFO] - Training Epoch: 1/2, step 6384/7134 completed (loss: 3.6865289211273193, acc: 0.3291139304637909)
[2024-12-17 02:26:55,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,156][root][INFO] - Training Epoch: 1/2, step 6385/7134 completed (loss: 4.144354343414307, acc: 0.2536585330963135)
[2024-12-17 02:26:56,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,536][root][INFO] - Training Epoch: 1/2, step 6386/7134 completed (loss: 3.5266709327697754, acc: 0.2956989109516144)
[2024-12-17 02:26:56,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:56,891][root][INFO] - Training Epoch: 1/2, step 6387/7134 completed (loss: 3.7489638328552246, acc: 0.3636363744735718)
[2024-12-17 02:26:56,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,246][root][INFO] - Training Epoch: 1/2, step 6388/7134 completed (loss: 4.459629535675049, acc: 0.2721518874168396)
[2024-12-17 02:26:57,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,595][root][INFO] - Training Epoch: 1/2, step 6389/7134 completed (loss: 3.630859136581421, acc: 0.3125)
[2024-12-17 02:26:57,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:57,973][root][INFO] - Training Epoch: 1/2, step 6390/7134 completed (loss: 3.686002731323242, acc: 0.269565224647522)
[2024-12-17 02:26:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,327][root][INFO] - Training Epoch: 1/2, step 6391/7134 completed (loss: 3.6257758140563965, acc: 0.302325576543808)
[2024-12-17 02:26:58,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:58,700][root][INFO] - Training Epoch: 1/2, step 6392/7134 completed (loss: 3.9891562461853027, acc: 0.2956521809101105)
[2024-12-17 02:26:58,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,080][root][INFO] - Training Epoch: 1/2, step 6393/7134 completed (loss: 3.729644775390625, acc: 0.31018519401550293)
[2024-12-17 02:26:59,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,421][root][INFO] - Training Epoch: 1/2, step 6394/7134 completed (loss: 3.8937859535217285, acc: 0.3055555522441864)
[2024-12-17 02:26:59,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:26:59,801][root][INFO] - Training Epoch: 1/2, step 6395/7134 completed (loss: 3.5831990242004395, acc: 0.32673266530036926)
[2024-12-17 02:26:59,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,181][root][INFO] - Training Epoch: 1/2, step 6396/7134 completed (loss: 3.372514247894287, acc: 0.35885167121887207)
[2024-12-17 02:27:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,547][root][INFO] - Training Epoch: 1/2, step 6397/7134 completed (loss: 3.519531011581421, acc: 0.3383084535598755)
[2024-12-17 02:27:00,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:00,904][root][INFO] - Training Epoch: 1/2, step 6398/7134 completed (loss: 3.8457040786743164, acc: 0.2689655125141144)
[2024-12-17 02:27:01,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,280][root][INFO] - Training Epoch: 1/2, step 6399/7134 completed (loss: 3.5769307613372803, acc: 0.3483146131038666)
[2024-12-17 02:27:01,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,647][root][INFO] - Training Epoch: 1/2, step 6400/7134 completed (loss: 3.586512804031372, acc: 0.3313252925872803)
[2024-12-17 02:27:01,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:01,999][root][INFO] - Training Epoch: 1/2, step 6401/7134 completed (loss: 3.9106879234313965, acc: 0.2380952388048172)
[2024-12-17 02:27:02,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,346][root][INFO] - Training Epoch: 1/2, step 6402/7134 completed (loss: 3.8315820693969727, acc: 0.2777777910232544)
[2024-12-17 02:27:02,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:02,701][root][INFO] - Training Epoch: 1/2, step 6403/7134 completed (loss: 3.176116466522217, acc: 0.3730570077896118)
[2024-12-17 02:27:02,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,053][root][INFO] - Training Epoch: 1/2, step 6404/7134 completed (loss: 3.9041318893432617, acc: 0.3076923191547394)
[2024-12-17 02:27:03,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,475][root][INFO] - Training Epoch: 1/2, step 6405/7134 completed (loss: 3.6169557571411133, acc: 0.3461538553237915)
[2024-12-17 02:27:03,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:03,866][root][INFO] - Training Epoch: 1/2, step 6406/7134 completed (loss: 3.6810197830200195, acc: 0.36000001430511475)
[2024-12-17 02:27:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,255][root][INFO] - Training Epoch: 1/2, step 6407/7134 completed (loss: 3.6242377758026123, acc: 0.3055555522441864)
[2024-12-17 02:27:04,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,606][root][INFO] - Training Epoch: 1/2, step 6408/7134 completed (loss: 3.9088494777679443, acc: 0.2884615361690521)
[2024-12-17 02:27:04,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:04,975][root][INFO] - Training Epoch: 1/2, step 6409/7134 completed (loss: 3.3294146060943604, acc: 0.3841463327407837)
[2024-12-17 02:27:05,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,342][root][INFO] - Training Epoch: 1/2, step 6410/7134 completed (loss: 4.1864094734191895, acc: 0.3333333432674408)
[2024-12-17 02:27:05,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:05,693][root][INFO] - Training Epoch: 1/2, step 6411/7134 completed (loss: 4.2141828536987305, acc: 0.2868216931819916)
[2024-12-17 02:27:05,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,068][root][INFO] - Training Epoch: 1/2, step 6412/7134 completed (loss: 3.787775754928589, acc: 0.32258063554763794)
[2024-12-17 02:27:06,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,458][root][INFO] - Training Epoch: 1/2, step 6413/7134 completed (loss: 3.7989988327026367, acc: 0.3288590610027313)
[2024-12-17 02:27:06,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:06,831][root][INFO] - Training Epoch: 1/2, step 6414/7134 completed (loss: 4.0563859939575195, acc: 0.28947368264198303)
[2024-12-17 02:27:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,200][root][INFO] - Training Epoch: 1/2, step 6415/7134 completed (loss: 3.6566545963287354, acc: 0.34090909361839294)
[2024-12-17 02:27:07,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,579][root][INFO] - Training Epoch: 1/2, step 6416/7134 completed (loss: 3.3198444843292236, acc: 0.3695652186870575)
[2024-12-17 02:27:07,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:07,945][root][INFO] - Training Epoch: 1/2, step 6417/7134 completed (loss: 4.5149760246276855, acc: 0.23255814611911774)
[2024-12-17 02:27:08,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,309][root][INFO] - Training Epoch: 1/2, step 6418/7134 completed (loss: 4.716273784637451, acc: 0.24161073565483093)
[2024-12-17 02:27:08,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,638][root][INFO] - Training Epoch: 1/2, step 6419/7134 completed (loss: 4.45129919052124, acc: 0.30519479513168335)
[2024-12-17 02:27:08,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:08,999][root][INFO] - Training Epoch: 1/2, step 6420/7134 completed (loss: 3.926985025405884, acc: 0.32278481125831604)
[2024-12-17 02:27:09,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,367][root][INFO] - Training Epoch: 1/2, step 6421/7134 completed (loss: 3.739990711212158, acc: 0.34337350726127625)
[2024-12-17 02:27:09,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:09,720][root][INFO] - Training Epoch: 1/2, step 6422/7134 completed (loss: 3.644866704940796, acc: 0.4134078323841095)
[2024-12-17 02:27:09,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,090][root][INFO] - Training Epoch: 1/2, step 6423/7134 completed (loss: 3.602158784866333, acc: 0.3333333432674408)
[2024-12-17 02:27:10,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,458][root][INFO] - Training Epoch: 1/2, step 6424/7134 completed (loss: 3.7929465770721436, acc: 0.3776595890522003)
[2024-12-17 02:27:10,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:10,838][root][INFO] - Training Epoch: 1/2, step 6425/7134 completed (loss: 3.9008853435516357, acc: 0.31843575835227966)
[2024-12-17 02:27:10,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,225][root][INFO] - Training Epoch: 1/2, step 6426/7134 completed (loss: 3.526332378387451, acc: 0.3519552946090698)
[2024-12-17 02:27:11,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,590][root][INFO] - Training Epoch: 1/2, step 6427/7134 completed (loss: 3.806943416595459, acc: 0.31847134232521057)
[2024-12-17 02:27:11,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:11,961][root][INFO] - Training Epoch: 1/2, step 6428/7134 completed (loss: 3.9191205501556396, acc: 0.31847134232521057)
[2024-12-17 02:27:12,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,323][root][INFO] - Training Epoch: 1/2, step 6429/7134 completed (loss: 4.216790676116943, acc: 0.2709677517414093)
[2024-12-17 02:27:12,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:12,699][root][INFO] - Training Epoch: 1/2, step 6430/7134 completed (loss: 4.126507759094238, acc: 0.26875001192092896)
[2024-12-17 02:27:12,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,071][root][INFO] - Training Epoch: 1/2, step 6431/7134 completed (loss: 3.9770162105560303, acc: 0.3405405282974243)
[2024-12-17 02:27:13,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,427][root][INFO] - Training Epoch: 1/2, step 6432/7134 completed (loss: 4.739482402801514, acc: 0.21935483813285828)
[2024-12-17 02:27:13,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:13,795][root][INFO] - Training Epoch: 1/2, step 6433/7134 completed (loss: 4.046726226806641, acc: 0.2670454680919647)
[2024-12-17 02:27:13,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,180][root][INFO] - Training Epoch: 1/2, step 6434/7134 completed (loss: 3.6426796913146973, acc: 0.32947975397109985)
[2024-12-17 02:27:14,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,573][root][INFO] - Training Epoch: 1/2, step 6435/7134 completed (loss: 3.710644245147705, acc: 0.3695652186870575)
[2024-12-17 02:27:14,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:14,959][root][INFO] - Training Epoch: 1/2, step 6436/7134 completed (loss: 3.525641679763794, acc: 0.3624161183834076)
[2024-12-17 02:27:15,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,330][root][INFO] - Training Epoch: 1/2, step 6437/7134 completed (loss: 3.767289400100708, acc: 0.33552631735801697)
[2024-12-17 02:27:15,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:15,680][root][INFO] - Training Epoch: 1/2, step 6438/7134 completed (loss: 3.711388349533081, acc: 0.31553396582603455)
[2024-12-17 02:27:15,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,057][root][INFO] - Training Epoch: 1/2, step 6439/7134 completed (loss: 3.559898614883423, acc: 0.35403725504875183)
[2024-12-17 02:27:16,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,439][root][INFO] - Training Epoch: 1/2, step 6440/7134 completed (loss: 3.696564197540283, acc: 0.36538460850715637)
[2024-12-17 02:27:16,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:16,788][root][INFO] - Training Epoch: 1/2, step 6441/7134 completed (loss: 3.2697956562042236, acc: 0.42767295241355896)
[2024-12-17 02:27:16,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,150][root][INFO] - Training Epoch: 1/2, step 6442/7134 completed (loss: 3.542127847671509, acc: 0.3543689250946045)
[2024-12-17 02:27:17,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,514][root][INFO] - Training Epoch: 1/2, step 6443/7134 completed (loss: 3.5285067558288574, acc: 0.30882352590560913)
[2024-12-17 02:27:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:17,860][root][INFO] - Training Epoch: 1/2, step 6444/7134 completed (loss: 3.9900338649749756, acc: 0.3166666626930237)
[2024-12-17 02:27:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,248][root][INFO] - Training Epoch: 1/2, step 6445/7134 completed (loss: 3.9653563499450684, acc: 0.3300492465496063)
[2024-12-17 02:27:18,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:18,628][root][INFO] - Training Epoch: 1/2, step 6446/7134 completed (loss: 3.316634178161621, acc: 0.38235294818878174)
[2024-12-17 02:27:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,060][root][INFO] - Training Epoch: 1/2, step 6447/7134 completed (loss: 3.595094919204712, acc: 0.3385416567325592)
[2024-12-17 02:27:19,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,437][root][INFO] - Training Epoch: 1/2, step 6448/7134 completed (loss: 3.9260520935058594, acc: 0.31612902879714966)
[2024-12-17 02:27:19,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:19,813][root][INFO] - Training Epoch: 1/2, step 6449/7134 completed (loss: 3.558657646179199, acc: 0.35233160853385925)
[2024-12-17 02:27:19,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,201][root][INFO] - Training Epoch: 1/2, step 6450/7134 completed (loss: 3.344951629638672, acc: 0.32947975397109985)
[2024-12-17 02:27:20,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:20,646][root][INFO] - Training Epoch: 1/2, step 6451/7134 completed (loss: 3.596848249435425, acc: 0.32773110270500183)
[2024-12-17 02:27:20,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,024][root][INFO] - Training Epoch: 1/2, step 6452/7134 completed (loss: 3.7641611099243164, acc: 0.30612245202064514)
[2024-12-17 02:27:21,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,405][root][INFO] - Training Epoch: 1/2, step 6453/7134 completed (loss: 3.4950199127197266, acc: 0.4049079716205597)
[2024-12-17 02:27:21,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:21,793][root][INFO] - Training Epoch: 1/2, step 6454/7134 completed (loss: 3.6854565143585205, acc: 0.33879780769348145)
[2024-12-17 02:27:21,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,179][root][INFO] - Training Epoch: 1/2, step 6455/7134 completed (loss: 3.8768069744110107, acc: 0.3266666531562805)
[2024-12-17 02:27:22,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,589][root][INFO] - Training Epoch: 1/2, step 6456/7134 completed (loss: 4.159041404724121, acc: 0.31736525893211365)
[2024-12-17 02:27:22,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:22,971][root][INFO] - Training Epoch: 1/2, step 6457/7134 completed (loss: 3.6700520515441895, acc: 0.3302752375602722)
[2024-12-17 02:27:23,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,328][root][INFO] - Training Epoch: 1/2, step 6458/7134 completed (loss: 3.2669780254364014, acc: 0.4121621549129486)
[2024-12-17 02:27:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:23,718][root][INFO] - Training Epoch: 1/2, step 6459/7134 completed (loss: 2.741241931915283, acc: 0.349693238735199)
[2024-12-17 02:27:23,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,118][root][INFO] - Training Epoch: 1/2, step 6460/7134 completed (loss: 3.1248269081115723, acc: 0.3571428656578064)
[2024-12-17 02:27:24,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,502][root][INFO] - Training Epoch: 1/2, step 6461/7134 completed (loss: 3.5094311237335205, acc: 0.35260117053985596)
[2024-12-17 02:27:24,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:24,860][root][INFO] - Training Epoch: 1/2, step 6462/7134 completed (loss: 3.495131254196167, acc: 0.3617021143436432)
[2024-12-17 02:27:24,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,239][root][INFO] - Training Epoch: 1/2, step 6463/7134 completed (loss: 3.6908631324768066, acc: 0.3106796145439148)
[2024-12-17 02:27:25,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,599][root][INFO] - Training Epoch: 1/2, step 6464/7134 completed (loss: 3.5611119270324707, acc: 0.31843575835227966)
[2024-12-17 02:27:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:25,950][root][INFO] - Training Epoch: 1/2, step 6465/7134 completed (loss: 3.309685468673706, acc: 0.3224043846130371)
[2024-12-17 02:27:26,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:26,304][root][INFO] - Training Epoch: 1/2, step 6466/7134 completed (loss: 3.8323471546173096, acc: 0.29100528359413147)
[2024-12-17 02:27:26,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:26,637][root][INFO] - Training Epoch: 1/2, step 6467/7134 completed (loss: 3.666581153869629, acc: 0.3734939694404602)
[2024-12-17 02:27:26,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,006][root][INFO] - Training Epoch: 1/2, step 6468/7134 completed (loss: 3.829632520675659, acc: 0.2867647111415863)
[2024-12-17 02:27:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,411][root][INFO] - Training Epoch: 1/2, step 6469/7134 completed (loss: 3.3839447498321533, acc: 0.38785046339035034)
[2024-12-17 02:27:27,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:27,780][root][INFO] - Training Epoch: 1/2, step 6470/7134 completed (loss: 4.647710800170898, acc: 0.2549019753932953)
[2024-12-17 02:27:27,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,174][root][INFO] - Training Epoch: 1/2, step 6471/7134 completed (loss: 4.227843761444092, acc: 0.26618704199790955)
[2024-12-17 02:27:28,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,581][root][INFO] - Training Epoch: 1/2, step 6472/7134 completed (loss: 3.85823917388916, acc: 0.29499998688697815)
[2024-12-17 02:27:28,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:28,964][root][INFO] - Training Epoch: 1/2, step 6473/7134 completed (loss: 3.638651132583618, acc: 0.3055555522441864)
[2024-12-17 02:27:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,382][root][INFO] - Training Epoch: 1/2, step 6474/7134 completed (loss: 3.6596150398254395, acc: 0.32258063554763794)
[2024-12-17 02:27:29,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:29,744][root][INFO] - Training Epoch: 1/2, step 6475/7134 completed (loss: 3.67383074760437, acc: 0.2785714268684387)
[2024-12-17 02:27:29,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,138][root][INFO] - Training Epoch: 1/2, step 6476/7134 completed (loss: 3.636674404144287, acc: 0.3333333432674408)
[2024-12-17 02:27:30,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,545][root][INFO] - Training Epoch: 1/2, step 6477/7134 completed (loss: 3.612969160079956, acc: 0.30434781312942505)
[2024-12-17 02:27:30,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:30,921][root][INFO] - Training Epoch: 1/2, step 6478/7134 completed (loss: 3.4412827491760254, acc: 0.41304346919059753)
[2024-12-17 02:27:31,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,292][root][INFO] - Training Epoch: 1/2, step 6479/7134 completed (loss: 3.4406914710998535, acc: 0.42953020334243774)
[2024-12-17 02:27:31,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:31,688][root][INFO] - Training Epoch: 1/2, step 6480/7134 completed (loss: 4.064107418060303, acc: 0.26428571343421936)
[2024-12-17 02:27:31,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,050][root][INFO] - Training Epoch: 1/2, step 6481/7134 completed (loss: 3.6239869594573975, acc: 0.3214285671710968)
[2024-12-17 02:27:32,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,502][root][INFO] - Training Epoch: 1/2, step 6482/7134 completed (loss: 3.2371792793273926, acc: 0.3700000047683716)
[2024-12-17 02:27:32,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:32,896][root][INFO] - Training Epoch: 1/2, step 6483/7134 completed (loss: 3.4822816848754883, acc: 0.3541666567325592)
[2024-12-17 02:27:33,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,279][root][INFO] - Training Epoch: 1/2, step 6484/7134 completed (loss: 3.5075008869171143, acc: 0.30994153022766113)
[2024-12-17 02:27:33,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:33,691][root][INFO] - Training Epoch: 1/2, step 6485/7134 completed (loss: 3.533649206161499, acc: 0.29411765933036804)
[2024-12-17 02:27:33,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,095][root][INFO] - Training Epoch: 1/2, step 6486/7134 completed (loss: 3.506643295288086, acc: 0.3695652186870575)
[2024-12-17 02:27:34,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,472][root][INFO] - Training Epoch: 1/2, step 6487/7134 completed (loss: 2.9231042861938477, acc: 0.4117647111415863)
[2024-12-17 02:27:34,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:34,858][root][INFO] - Training Epoch: 1/2, step 6488/7134 completed (loss: 3.3068177700042725, acc: 0.3636363744735718)
[2024-12-17 02:27:34,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,227][root][INFO] - Training Epoch: 1/2, step 6489/7134 completed (loss: 3.842728853225708, acc: 0.38461539149284363)
[2024-12-17 02:27:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,586][root][INFO] - Training Epoch: 1/2, step 6490/7134 completed (loss: 4.129639625549316, acc: 0.2985074520111084)
[2024-12-17 02:27:35,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:35,946][root][INFO] - Training Epoch: 1/2, step 6491/7134 completed (loss: 3.6516435146331787, acc: 0.3571428656578064)
[2024-12-17 02:27:36,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,274][root][INFO] - Training Epoch: 1/2, step 6492/7134 completed (loss: 3.667893886566162, acc: 0.3677419424057007)
[2024-12-17 02:27:36,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:36,652][root][INFO] - Training Epoch: 1/2, step 6493/7134 completed (loss: 3.289043664932251, acc: 0.4047619104385376)
[2024-12-17 02:27:36,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,000][root][INFO] - Training Epoch: 1/2, step 6494/7134 completed (loss: 4.000151634216309, acc: 0.29203540086746216)
[2024-12-17 02:27:37,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,382][root][INFO] - Training Epoch: 1/2, step 6495/7134 completed (loss: 3.538850784301758, acc: 0.40740740299224854)
[2024-12-17 02:27:37,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:37,781][root][INFO] - Training Epoch: 1/2, step 6496/7134 completed (loss: 4.101001739501953, acc: 0.3583815097808838)
[2024-12-17 02:27:37,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,142][root][INFO] - Training Epoch: 1/2, step 6497/7134 completed (loss: 3.885754108428955, acc: 0.3541666567325592)
[2024-12-17 02:27:38,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,482][root][INFO] - Training Epoch: 1/2, step 6498/7134 completed (loss: 3.833142042160034, acc: 0.33529412746429443)
[2024-12-17 02:27:38,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:38,888][root][INFO] - Training Epoch: 1/2, step 6499/7134 completed (loss: 3.5213065147399902, acc: 0.3723404109477997)
[2024-12-17 02:27:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,276][root][INFO] - Training Epoch: 1/2, step 6500/7134 completed (loss: 3.9856033325195312, acc: 0.26436781883239746)
[2024-12-17 02:27:39,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:39,672][root][INFO] - Training Epoch: 1/2, step 6501/7134 completed (loss: 4.318073749542236, acc: 0.30927833914756775)
[2024-12-17 02:27:39,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,111][root][INFO] - Training Epoch: 1/2, step 6502/7134 completed (loss: 3.5336363315582275, acc: 0.35353535413742065)
[2024-12-17 02:27:40,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,501][root][INFO] - Training Epoch: 1/2, step 6503/7134 completed (loss: 3.5469300746917725, acc: 0.3726707994937897)
[2024-12-17 02:27:40,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:40,920][root][INFO] - Training Epoch: 1/2, step 6504/7134 completed (loss: 3.9350762367248535, acc: 0.30821916460990906)
[2024-12-17 02:27:41,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,322][root][INFO] - Training Epoch: 1/2, step 6505/7134 completed (loss: 3.757714033126831, acc: 0.3799999952316284)
[2024-12-17 02:27:41,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:41,707][root][INFO] - Training Epoch: 1/2, step 6506/7134 completed (loss: 3.5250236988067627, acc: 0.35567009449005127)
[2024-12-17 02:27:41,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,078][root][INFO] - Training Epoch: 1/2, step 6507/7134 completed (loss: 3.9644579887390137, acc: 0.3190183937549591)
[2024-12-17 02:27:42,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,461][root][INFO] - Training Epoch: 1/2, step 6508/7134 completed (loss: 3.549913167953491, acc: 0.3499999940395355)
[2024-12-17 02:27:42,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:42,820][root][INFO] - Training Epoch: 1/2, step 6509/7134 completed (loss: 3.060267210006714, acc: 0.3865979313850403)
[2024-12-17 02:27:42,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,208][root][INFO] - Training Epoch: 1/2, step 6510/7134 completed (loss: 3.4825780391693115, acc: 0.37378641963005066)
[2024-12-17 02:27:43,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,560][root][INFO] - Training Epoch: 1/2, step 6511/7134 completed (loss: 3.3627870082855225, acc: 0.38805970549583435)
[2024-12-17 02:27:43,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:43,967][root][INFO] - Training Epoch: 1/2, step 6512/7134 completed (loss: 3.88059139251709, acc: 0.2545454502105713)
[2024-12-17 02:27:44,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,320][root][INFO] - Training Epoch: 1/2, step 6513/7134 completed (loss: 3.600461721420288, acc: 0.31111112236976624)
[2024-12-17 02:27:44,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:44,709][root][INFO] - Training Epoch: 1/2, step 6514/7134 completed (loss: 3.388326406478882, acc: 0.37654322385787964)
[2024-12-17 02:27:44,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,078][root][INFO] - Training Epoch: 1/2, step 6515/7134 completed (loss: 3.362053155899048, acc: 0.41208791732788086)
[2024-12-17 02:27:45,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,494][root][INFO] - Training Epoch: 1/2, step 6516/7134 completed (loss: 3.272096872329712, acc: 0.4117647111415863)
[2024-12-17 02:27:45,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:45,870][root][INFO] - Training Epoch: 1/2, step 6517/7134 completed (loss: 3.121025562286377, acc: 0.4285714328289032)
[2024-12-17 02:27:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,308][root][INFO] - Training Epoch: 1/2, step 6518/7134 completed (loss: 3.1023969650268555, acc: 0.39520958065986633)
[2024-12-17 02:27:46,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:46,696][root][INFO] - Training Epoch: 1/2, step 6519/7134 completed (loss: 3.3072586059570312, acc: 0.36220473051071167)
[2024-12-17 02:27:46,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,070][root][INFO] - Training Epoch: 1/2, step 6520/7134 completed (loss: 2.8453333377838135, acc: 0.44805195927619934)
[2024-12-17 02:27:47,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,452][root][INFO] - Training Epoch: 1/2, step 6521/7134 completed (loss: 3.2311854362487793, acc: 0.3891891837120056)
[2024-12-17 02:27:47,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:47,842][root][INFO] - Training Epoch: 1/2, step 6522/7134 completed (loss: 2.9794559478759766, acc: 0.4575163424015045)
[2024-12-17 02:27:47,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,207][root][INFO] - Training Epoch: 1/2, step 6523/7134 completed (loss: 3.334465265274048, acc: 0.4305555522441864)
[2024-12-17 02:27:48,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,615][root][INFO] - Training Epoch: 1/2, step 6524/7134 completed (loss: 3.071200370788574, acc: 0.3922652006149292)
[2024-12-17 02:27:48,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:48,993][root][INFO] - Training Epoch: 1/2, step 6525/7134 completed (loss: 2.7571702003479004, acc: 0.42148759961128235)
[2024-12-17 02:27:49,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,408][root][INFO] - Training Epoch: 1/2, step 6526/7134 completed (loss: 3.2772064208984375, acc: 0.4010152220726013)
[2024-12-17 02:27:49,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:49,767][root][INFO] - Training Epoch: 1/2, step 6527/7134 completed (loss: 3.390641927719116, acc: 0.3987341821193695)
[2024-12-17 02:27:49,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,153][root][INFO] - Training Epoch: 1/2, step 6528/7134 completed (loss: 2.8517701625823975, acc: 0.41304346919059753)
[2024-12-17 02:27:50,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,540][root][INFO] - Training Epoch: 1/2, step 6529/7134 completed (loss: 3.335359573364258, acc: 0.40458014607429504)
[2024-12-17 02:27:50,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:50,966][root][INFO] - Training Epoch: 1/2, step 6530/7134 completed (loss: 3.1384928226470947, acc: 0.3867403268814087)
[2024-12-17 02:27:51,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,340][root][INFO] - Training Epoch: 1/2, step 6531/7134 completed (loss: 2.9406216144561768, acc: 0.45121949911117554)
[2024-12-17 02:27:51,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:51,726][root][INFO] - Training Epoch: 1/2, step 6532/7134 completed (loss: 3.044455051422119, acc: 0.4175824224948883)
[2024-12-17 02:27:51,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,131][root][INFO] - Training Epoch: 1/2, step 6533/7134 completed (loss: 3.0544259548187256, acc: 0.38311687111854553)
[2024-12-17 02:27:52,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,528][root][INFO] - Training Epoch: 1/2, step 6534/7134 completed (loss: 2.9070353507995605, acc: 0.4219653308391571)
[2024-12-17 02:27:52,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:52,906][root][INFO] - Training Epoch: 1/2, step 6535/7134 completed (loss: 2.7606940269470215, acc: 0.40566039085388184)
[2024-12-17 02:27:53,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,286][root][INFO] - Training Epoch: 1/2, step 6536/7134 completed (loss: 3.134065866470337, acc: 0.35652172565460205)
[2024-12-17 02:27:53,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,630][root][INFO] - Training Epoch: 1/2, step 6537/7134 completed (loss: 3.2352378368377686, acc: 0.4285714328289032)
[2024-12-17 02:27:53,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:53,971][root][INFO] - Training Epoch: 1/2, step 6538/7134 completed (loss: 3.2327959537506104, acc: 0.42465752363204956)
[2024-12-17 02:27:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,350][root][INFO] - Training Epoch: 1/2, step 6539/7134 completed (loss: 2.7538509368896484, acc: 0.3896103799343109)
[2024-12-17 02:27:54,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:54,746][root][INFO] - Training Epoch: 1/2, step 6540/7134 completed (loss: 3.565199136734009, acc: 0.3636363744735718)
[2024-12-17 02:27:54,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,159][root][INFO] - Training Epoch: 1/2, step 6541/7134 completed (loss: 2.8730218410491943, acc: 0.37016573548316956)
[2024-12-17 02:27:55,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,551][root][INFO] - Training Epoch: 1/2, step 6542/7134 completed (loss: 3.1398985385894775, acc: 0.4214285612106323)
[2024-12-17 02:27:55,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:55,920][root][INFO] - Training Epoch: 1/2, step 6543/7134 completed (loss: 2.87455153465271, acc: 0.3070175349712372)
[2024-12-17 02:27:56,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,353][root][INFO] - Training Epoch: 1/2, step 6544/7134 completed (loss: 3.048745632171631, acc: 0.4054054021835327)
[2024-12-17 02:27:56,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:56,729][root][INFO] - Training Epoch: 1/2, step 6545/7134 completed (loss: 2.8504838943481445, acc: 0.3719008266925812)
[2024-12-17 02:27:56,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,114][root][INFO] - Training Epoch: 1/2, step 6546/7134 completed (loss: 3.22460675239563, acc: 0.37681159377098083)
[2024-12-17 02:27:57,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,528][root][INFO] - Training Epoch: 1/2, step 6547/7134 completed (loss: 3.057793617248535, acc: 0.4202898442745209)
[2024-12-17 02:27:57,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:57,882][root][INFO] - Training Epoch: 1/2, step 6548/7134 completed (loss: 2.888045310974121, acc: 0.4476190507411957)
[2024-12-17 02:27:58,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,257][root][INFO] - Training Epoch: 1/2, step 6549/7134 completed (loss: 3.265427350997925, acc: 0.38167938590049744)
[2024-12-17 02:27:58,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,625][root][INFO] - Training Epoch: 1/2, step 6550/7134 completed (loss: 3.601733446121216, acc: 0.35031846165657043)
[2024-12-17 02:27:58,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:58,970][root][INFO] - Training Epoch: 1/2, step 6551/7134 completed (loss: 4.076828479766846, acc: 0.3147208094596863)
[2024-12-17 02:27:59,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,329][root][INFO] - Training Epoch: 1/2, step 6552/7134 completed (loss: 4.109503269195557, acc: 0.3259911835193634)
[2024-12-17 02:27:59,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:27:59,714][root][INFO] - Training Epoch: 1/2, step 6553/7134 completed (loss: 4.114938259124756, acc: 0.3080808222293854)
[2024-12-17 02:27:59,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,093][root][INFO] - Training Epoch: 1/2, step 6554/7134 completed (loss: 3.787304401397705, acc: 0.32710281014442444)
[2024-12-17 02:28:00,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,481][root][INFO] - Training Epoch: 1/2, step 6555/7134 completed (loss: 4.316585540771484, acc: 0.2887931168079376)
[2024-12-17 02:28:00,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:00,873][root][INFO] - Training Epoch: 1/2, step 6556/7134 completed (loss: 4.197456359863281, acc: 0.2805429995059967)
[2024-12-17 02:28:01,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,245][root][INFO] - Training Epoch: 1/2, step 6557/7134 completed (loss: 4.19826078414917, acc: 0.2612612545490265)
[2024-12-17 02:28:01,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,615][root][INFO] - Training Epoch: 1/2, step 6558/7134 completed (loss: 4.391481399536133, acc: 0.29906541109085083)
[2024-12-17 02:28:01,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:01,970][root][INFO] - Training Epoch: 1/2, step 6559/7134 completed (loss: 4.228121280670166, acc: 0.27710843086242676)
[2024-12-17 02:28:02,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,374][root][INFO] - Training Epoch: 1/2, step 6560/7134 completed (loss: 3.793165922164917, acc: 0.32460734248161316)
[2024-12-17 02:28:02,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:02,766][root][INFO] - Training Epoch: 1/2, step 6561/7134 completed (loss: 4.05804967880249, acc: 0.34554973244667053)
[2024-12-17 02:28:02,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,178][root][INFO] - Training Epoch: 1/2, step 6562/7134 completed (loss: 3.8770267963409424, acc: 0.3333333432674408)
[2024-12-17 02:28:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,598][root][INFO] - Training Epoch: 1/2, step 6563/7134 completed (loss: 4.530043125152588, acc: 0.26767677068710327)
[2024-12-17 02:28:03,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:03,987][root][INFO] - Training Epoch: 1/2, step 6564/7134 completed (loss: 4.085155487060547, acc: 0.3192771077156067)
[2024-12-17 02:28:04,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,401][root][INFO] - Training Epoch: 1/2, step 6565/7134 completed (loss: 4.363597869873047, acc: 0.2747747600078583)
[2024-12-17 02:28:04,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:04,795][root][INFO] - Training Epoch: 1/2, step 6566/7134 completed (loss: 3.861539363861084, acc: 0.3467741906642914)
[2024-12-17 02:28:04,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,182][root][INFO] - Training Epoch: 1/2, step 6567/7134 completed (loss: 4.2337493896484375, acc: 0.25777778029441833)
[2024-12-17 02:28:05,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,588][root][INFO] - Training Epoch: 1/2, step 6568/7134 completed (loss: 4.1142120361328125, acc: 0.30219781398773193)
[2024-12-17 02:28:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:05,942][root][INFO] - Training Epoch: 1/2, step 6569/7134 completed (loss: 3.91365385055542, acc: 0.2588832378387451)
[2024-12-17 02:28:06,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,313][root][INFO] - Training Epoch: 1/2, step 6570/7134 completed (loss: 3.7875328063964844, acc: 0.31527093052864075)
[2024-12-17 02:28:06,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:06,664][root][INFO] - Training Epoch: 1/2, step 6571/7134 completed (loss: 3.724090337753296, acc: 0.34545454382896423)
[2024-12-17 02:28:06,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,020][root][INFO] - Training Epoch: 1/2, step 6572/7134 completed (loss: 3.7658839225769043, acc: 0.3073170781135559)
[2024-12-17 02:28:07,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,389][root][INFO] - Training Epoch: 1/2, step 6573/7134 completed (loss: 3.767117500305176, acc: 0.3106796145439148)
[2024-12-17 02:28:07,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:07,757][root][INFO] - Training Epoch: 1/2, step 6574/7134 completed (loss: 3.8492565155029297, acc: 0.3232758641242981)
[2024-12-17 02:28:07,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,159][root][INFO] - Training Epoch: 1/2, step 6575/7134 completed (loss: 3.9359683990478516, acc: 0.3004694879055023)
[2024-12-17 02:28:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,542][root][INFO] - Training Epoch: 1/2, step 6576/7134 completed (loss: 4.015293598175049, acc: 0.27981650829315186)
[2024-12-17 02:28:08,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:08,928][root][INFO] - Training Epoch: 1/2, step 6577/7134 completed (loss: 3.698901414871216, acc: 0.3696969747543335)
[2024-12-17 02:28:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,429][root][INFO] - Training Epoch: 1/2, step 6578/7134 completed (loss: 4.100783348083496, acc: 0.25819671154022217)
[2024-12-17 02:28:09,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:09,776][root][INFO] - Training Epoch: 1/2, step 6579/7134 completed (loss: 3.9729530811309814, acc: 0.36090224981307983)
[2024-12-17 02:28:09,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,147][root][INFO] - Training Epoch: 1/2, step 6580/7134 completed (loss: 4.189603328704834, acc: 0.3263157904148102)
[2024-12-17 02:28:10,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,484][root][INFO] - Training Epoch: 1/2, step 6581/7134 completed (loss: 3.8206865787506104, acc: 0.3243243098258972)
[2024-12-17 02:28:10,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:10,860][root][INFO] - Training Epoch: 1/2, step 6582/7134 completed (loss: 4.832644462585449, acc: 0.22368420660495758)
[2024-12-17 02:28:10,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,267][root][INFO] - Training Epoch: 1/2, step 6583/7134 completed (loss: 4.060781955718994, acc: 0.311557799577713)
[2024-12-17 02:28:11,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:11,672][root][INFO] - Training Epoch: 1/2, step 6584/7134 completed (loss: 4.172014236450195, acc: 0.3172042965888977)
[2024-12-17 02:28:11,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,032][root][INFO] - Training Epoch: 1/2, step 6585/7134 completed (loss: 3.9528555870056152, acc: 0.3445945978164673)
[2024-12-17 02:28:12,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,397][root][INFO] - Training Epoch: 1/2, step 6586/7134 completed (loss: 4.523902893066406, acc: 0.23926380276679993)
[2024-12-17 02:28:12,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:12,762][root][INFO] - Training Epoch: 1/2, step 6587/7134 completed (loss: 3.7181994915008545, acc: 0.35567009449005127)
[2024-12-17 02:28:12,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,117][root][INFO] - Training Epoch: 1/2, step 6588/7134 completed (loss: 3.9151291847229004, acc: 0.33139535784721375)
[2024-12-17 02:28:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,468][root][INFO] - Training Epoch: 1/2, step 6589/7134 completed (loss: 4.045629978179932, acc: 0.2732919156551361)
[2024-12-17 02:28:13,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:13,836][root][INFO] - Training Epoch: 1/2, step 6590/7134 completed (loss: 4.261897087097168, acc: 0.2978723347187042)
[2024-12-17 02:28:13,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,217][root][INFO] - Training Epoch: 1/2, step 6591/7134 completed (loss: 4.350718021392822, acc: 0.30994153022766113)
[2024-12-17 02:28:14,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,587][root][INFO] - Training Epoch: 1/2, step 6592/7134 completed (loss: 3.7734642028808594, acc: 0.3251231610774994)
[2024-12-17 02:28:14,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:14,962][root][INFO] - Training Epoch: 1/2, step 6593/7134 completed (loss: 3.589820146560669, acc: 0.3199999928474426)
[2024-12-17 02:28:15,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,338][root][INFO] - Training Epoch: 1/2, step 6594/7134 completed (loss: 4.051775932312012, acc: 0.29064038395881653)
[2024-12-17 02:28:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:15,718][root][INFO] - Training Epoch: 1/2, step 6595/7134 completed (loss: 3.6777429580688477, acc: 0.3333333432674408)
[2024-12-17 02:28:15,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,077][root][INFO] - Training Epoch: 1/2, step 6596/7134 completed (loss: 4.06174898147583, acc: 0.34337350726127625)
[2024-12-17 02:28:16,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,431][root][INFO] - Training Epoch: 1/2, step 6597/7134 completed (loss: 3.8920533657073975, acc: 0.32460734248161316)
[2024-12-17 02:28:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:16,818][root][INFO] - Training Epoch: 1/2, step 6598/7134 completed (loss: 4.080729007720947, acc: 0.284153014421463)
[2024-12-17 02:28:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,208][root][INFO] - Training Epoch: 1/2, step 6599/7134 completed (loss: 3.7842888832092285, acc: 0.3219512104988098)
[2024-12-17 02:28:17,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,573][root][INFO] - Training Epoch: 1/2, step 6600/7134 completed (loss: 3.2117037773132324, acc: 0.3651685416698456)
[2024-12-17 02:28:17,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:17,966][root][INFO] - Training Epoch: 1/2, step 6601/7134 completed (loss: 4.140508651733398, acc: 0.25)
[2024-12-17 02:28:18,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,332][root][INFO] - Training Epoch: 1/2, step 6602/7134 completed (loss: 3.7697882652282715, acc: 0.31683167815208435)
[2024-12-17 02:28:18,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:18,711][root][INFO] - Training Epoch: 1/2, step 6603/7134 completed (loss: 3.974208116531372, acc: 0.30817610025405884)
[2024-12-17 02:28:18,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,059][root][INFO] - Training Epoch: 1/2, step 6604/7134 completed (loss: 3.852977752685547, acc: 0.3655914068222046)
[2024-12-17 02:28:19,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,406][root][INFO] - Training Epoch: 1/2, step 6605/7134 completed (loss: 3.9132368564605713, acc: 0.3655914068222046)
[2024-12-17 02:28:19,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:19,789][root][INFO] - Training Epoch: 1/2, step 6606/7134 completed (loss: 4.351254463195801, acc: 0.3016759753227234)
[2024-12-17 02:28:19,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,178][root][INFO] - Training Epoch: 1/2, step 6607/7134 completed (loss: 4.352949619293213, acc: 0.3032258152961731)
[2024-12-17 02:28:20,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,541][root][INFO] - Training Epoch: 1/2, step 6608/7134 completed (loss: 4.0629472732543945, acc: 0.30136987566947937)
[2024-12-17 02:28:20,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:20,878][root][INFO] - Training Epoch: 1/2, step 6609/7134 completed (loss: 4.5642409324646, acc: 0.2641509473323822)
[2024-12-17 02:28:21,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,281][root][INFO] - Training Epoch: 1/2, step 6610/7134 completed (loss: 4.502547740936279, acc: 0.27878788113594055)
[2024-12-17 02:28:21,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:21,657][root][INFO] - Training Epoch: 1/2, step 6611/7134 completed (loss: 3.996683120727539, acc: 0.3561643958091736)
[2024-12-17 02:28:21,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,052][root][INFO] - Training Epoch: 1/2, step 6612/7134 completed (loss: 4.233290672302246, acc: 0.28717949986457825)
[2024-12-17 02:28:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,431][root][INFO] - Training Epoch: 1/2, step 6613/7134 completed (loss: 4.118293762207031, acc: 0.26174497604370117)
[2024-12-17 02:28:22,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:22,781][root][INFO] - Training Epoch: 1/2, step 6614/7134 completed (loss: 4.199645519256592, acc: 0.26923078298568726)
[2024-12-17 02:28:22,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,136][root][INFO] - Training Epoch: 1/2, step 6615/7134 completed (loss: 4.700222492218018, acc: 0.23648647964000702)
[2024-12-17 02:28:23,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,563][root][INFO] - Training Epoch: 1/2, step 6616/7134 completed (loss: 4.395964622497559, acc: 0.27272728085517883)
[2024-12-17 02:28:23,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:23,947][root][INFO] - Training Epoch: 1/2, step 6617/7134 completed (loss: 4.276172161102295, acc: 0.3037036955356598)
[2024-12-17 02:28:24,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,290][root][INFO] - Training Epoch: 1/2, step 6618/7134 completed (loss: 3.780104875564575, acc: 0.32608696818351746)
[2024-12-17 02:28:24,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:24,674][root][INFO] - Training Epoch: 1/2, step 6619/7134 completed (loss: 4.174755096435547, acc: 0.24858756363391876)
[2024-12-17 02:28:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,085][root][INFO] - Training Epoch: 1/2, step 6620/7134 completed (loss: 4.2316107749938965, acc: 0.3055555522441864)
[2024-12-17 02:28:25,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,469][root][INFO] - Training Epoch: 1/2, step 6621/7134 completed (loss: 4.351990222930908, acc: 0.22285714745521545)
[2024-12-17 02:28:25,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:25,828][root][INFO] - Training Epoch: 1/2, step 6622/7134 completed (loss: 3.602947473526001, acc: 0.3461538553237915)
[2024-12-17 02:28:25,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,222][root][INFO] - Training Epoch: 1/2, step 6623/7134 completed (loss: 4.448946475982666, acc: 0.23952095210552216)
[2024-12-17 02:28:26,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,582][root][INFO] - Training Epoch: 1/2, step 6624/7134 completed (loss: 4.059016704559326, acc: 0.2675159275531769)
[2024-12-17 02:28:26,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:26,950][root][INFO] - Training Epoch: 1/2, step 6625/7134 completed (loss: 3.6281604766845703, acc: 0.33774834871292114)
[2024-12-17 02:28:27,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,355][root][INFO] - Training Epoch: 1/2, step 6626/7134 completed (loss: 4.364011764526367, acc: 0.2800000011920929)
[2024-12-17 02:28:27,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:27,735][root][INFO] - Training Epoch: 1/2, step 6627/7134 completed (loss: 4.130788803100586, acc: 0.3172042965888977)
[2024-12-17 02:28:27,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,116][root][INFO] - Training Epoch: 1/2, step 6628/7134 completed (loss: 3.882098913192749, acc: 0.2976190447807312)
[2024-12-17 02:28:28,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,459][root][INFO] - Training Epoch: 1/2, step 6629/7134 completed (loss: 4.125507354736328, acc: 0.2874999940395355)
[2024-12-17 02:28:28,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:28,863][root][INFO] - Training Epoch: 1/2, step 6630/7134 completed (loss: 3.9098472595214844, acc: 0.34375)
[2024-12-17 02:28:29,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,251][root][INFO] - Training Epoch: 1/2, step 6631/7134 completed (loss: 3.454275608062744, acc: 0.39751553535461426)
[2024-12-17 02:28:29,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:29,696][root][INFO] - Training Epoch: 1/2, step 6632/7134 completed (loss: 4.2282586097717285, acc: 0.25380709767341614)
[2024-12-17 02:28:29,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,080][root][INFO] - Training Epoch: 1/2, step 6633/7134 completed (loss: 3.0525119304656982, acc: 0.4175824224948883)
[2024-12-17 02:28:30,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,492][root][INFO] - Training Epoch: 1/2, step 6634/7134 completed (loss: 4.428699016571045, acc: 0.3308270573616028)
[2024-12-17 02:28:30,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:30,871][root][INFO] - Training Epoch: 1/2, step 6635/7134 completed (loss: 4.375886917114258, acc: 0.2849999964237213)
[2024-12-17 02:28:30,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,254][root][INFO] - Training Epoch: 1/2, step 6636/7134 completed (loss: 4.129363536834717, acc: 0.26829269528388977)
[2024-12-17 02:28:31,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,623][root][INFO] - Training Epoch: 1/2, step 6637/7134 completed (loss: 4.481058120727539, acc: 0.2750000059604645)
[2024-12-17 02:28:31,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:31,996][root][INFO] - Training Epoch: 1/2, step 6638/7134 completed (loss: 3.781329393386841, acc: 0.38461539149284363)
[2024-12-17 02:28:32,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,377][root][INFO] - Training Epoch: 1/2, step 6639/7134 completed (loss: 4.185348033905029, acc: 0.27544909715652466)
[2024-12-17 02:28:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:32,767][root][INFO] - Training Epoch: 1/2, step 6640/7134 completed (loss: 4.201121807098389, acc: 0.30573248863220215)
[2024-12-17 02:28:32,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,136][root][INFO] - Training Epoch: 1/2, step 6641/7134 completed (loss: 3.8633925914764404, acc: 0.33185839653015137)
[2024-12-17 02:28:33,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,534][root][INFO] - Training Epoch: 1/2, step 6642/7134 completed (loss: 3.8829331398010254, acc: 0.3132530152797699)
[2024-12-17 02:28:33,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:33,932][root][INFO] - Training Epoch: 1/2, step 6643/7134 completed (loss: 3.5550756454467773, acc: 0.2688172161579132)
[2024-12-17 02:28:34,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,375][root][INFO] - Training Epoch: 1/2, step 6644/7134 completed (loss: 3.871901273727417, acc: 0.2904564440250397)
[2024-12-17 02:28:34,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:34,762][root][INFO] - Training Epoch: 1/2, step 6645/7134 completed (loss: 4.199505805969238, acc: 0.32804232835769653)
[2024-12-17 02:28:34,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,135][root][INFO] - Training Epoch: 1/2, step 6646/7134 completed (loss: 3.837631940841675, acc: 0.3013100326061249)
[2024-12-17 02:28:35,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,507][root][INFO] - Training Epoch: 1/2, step 6647/7134 completed (loss: 3.835934638977051, acc: 0.34705883264541626)
[2024-12-17 02:28:35,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:35,875][root][INFO] - Training Epoch: 1/2, step 6648/7134 completed (loss: 4.073801517486572, acc: 0.3290322721004486)
[2024-12-17 02:28:35,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,264][root][INFO] - Training Epoch: 1/2, step 6649/7134 completed (loss: 3.7904438972473145, acc: 0.33816424012184143)
[2024-12-17 02:28:36,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:36,674][root][INFO] - Training Epoch: 1/2, step 6650/7134 completed (loss: 3.6167635917663574, acc: 0.34545454382896423)
[2024-12-17 02:28:36,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,078][root][INFO] - Training Epoch: 1/2, step 6651/7134 completed (loss: 3.6603453159332275, acc: 0.3579545319080353)
[2024-12-17 02:28:37,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,461][root][INFO] - Training Epoch: 1/2, step 6652/7134 completed (loss: 3.979314088821411, acc: 0.3333333432674408)
[2024-12-17 02:28:37,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:37,869][root][INFO] - Training Epoch: 1/2, step 6653/7134 completed (loss: 4.000611782073975, acc: 0.3499999940395355)
[2024-12-17 02:28:37,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,241][root][INFO] - Training Epoch: 1/2, step 6654/7134 completed (loss: 3.9005937576293945, acc: 0.3164556920528412)
[2024-12-17 02:28:38,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,581][root][INFO] - Training Epoch: 1/2, step 6655/7134 completed (loss: 3.7211623191833496, acc: 0.29523810744285583)
[2024-12-17 02:28:38,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:38,929][root][INFO] - Training Epoch: 1/2, step 6656/7134 completed (loss: 4.0690598487854, acc: 0.24210526049137115)
[2024-12-17 02:28:39,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,327][root][INFO] - Training Epoch: 1/2, step 6657/7134 completed (loss: 3.6642346382141113, acc: 0.3297872245311737)
[2024-12-17 02:28:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:39,711][root][INFO] - Training Epoch: 1/2, step 6658/7134 completed (loss: 3.6074881553649902, acc: 0.3553299605846405)
[2024-12-17 02:28:39,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,090][root][INFO] - Training Epoch: 1/2, step 6659/7134 completed (loss: 3.6405162811279297, acc: 0.35519126057624817)
[2024-12-17 02:28:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,484][root][INFO] - Training Epoch: 1/2, step 6660/7134 completed (loss: 3.5154428482055664, acc: 0.33196720480918884)
[2024-12-17 02:28:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:40,870][root][INFO] - Training Epoch: 1/2, step 6661/7134 completed (loss: 4.334877014160156, acc: 0.24875621497631073)
[2024-12-17 02:28:40,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,242][root][INFO] - Training Epoch: 1/2, step 6662/7134 completed (loss: 4.375913143157959, acc: 0.2374100685119629)
[2024-12-17 02:28:41,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:41,630][root][INFO] - Training Epoch: 1/2, step 6663/7134 completed (loss: 3.7057316303253174, acc: 0.3073593080043793)
[2024-12-17 02:28:41,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,032][root][INFO] - Training Epoch: 1/2, step 6664/7134 completed (loss: 3.2556779384613037, acc: 0.4285714328289032)
[2024-12-17 02:28:42,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,464][root][INFO] - Training Epoch: 1/2, step 6665/7134 completed (loss: 4.257035255432129, acc: 0.31446540355682373)
[2024-12-17 02:28:42,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:42,839][root][INFO] - Training Epoch: 1/2, step 6666/7134 completed (loss: 3.9905292987823486, acc: 0.3272727131843567)
[2024-12-17 02:28:42,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,244][root][INFO] - Training Epoch: 1/2, step 6667/7134 completed (loss: 4.147639274597168, acc: 0.380952388048172)
[2024-12-17 02:28:43,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,618][root][INFO] - Training Epoch: 1/2, step 6668/7134 completed (loss: 3.336815595626831, acc: 0.40875911712646484)
[2024-12-17 02:28:43,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:43,999][root][INFO] - Training Epoch: 1/2, step 6669/7134 completed (loss: 3.7254533767700195, acc: 0.2777777910232544)
[2024-12-17 02:28:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,386][root][INFO] - Training Epoch: 1/2, step 6670/7134 completed (loss: 3.5136923789978027, acc: 0.3309352397918701)
[2024-12-17 02:28:44,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:44,780][root][INFO] - Training Epoch: 1/2, step 6671/7134 completed (loss: 3.494408130645752, acc: 0.3231707215309143)
[2024-12-17 02:28:44,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,146][root][INFO] - Training Epoch: 1/2, step 6672/7134 completed (loss: 3.7683205604553223, acc: 0.3199999928474426)
[2024-12-17 02:28:45,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,513][root][INFO] - Training Epoch: 1/2, step 6673/7134 completed (loss: 3.7143194675445557, acc: 0.28930819034576416)
[2024-12-17 02:28:45,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:45,912][root][INFO] - Training Epoch: 1/2, step 6674/7134 completed (loss: 3.392608404159546, acc: 0.3050847351551056)
[2024-12-17 02:28:46,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,306][root][INFO] - Training Epoch: 1/2, step 6675/7134 completed (loss: 3.627070665359497, acc: 0.3529411852359772)
[2024-12-17 02:28:46,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:46,692][root][INFO] - Training Epoch: 1/2, step 6676/7134 completed (loss: 3.866659641265869, acc: 0.2800000011920929)
[2024-12-17 02:28:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,083][root][INFO] - Training Epoch: 1/2, step 6677/7134 completed (loss: 3.4425339698791504, acc: 0.3358778655529022)
[2024-12-17 02:28:47,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,456][root][INFO] - Training Epoch: 1/2, step 6678/7134 completed (loss: 3.761613130569458, acc: 0.34074074029922485)
[2024-12-17 02:28:47,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:47,843][root][INFO] - Training Epoch: 1/2, step 6679/7134 completed (loss: 3.406078577041626, acc: 0.32743361592292786)
[2024-12-17 02:28:47,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,218][root][INFO] - Training Epoch: 1/2, step 6680/7134 completed (loss: 3.519545316696167, acc: 0.3218390941619873)
[2024-12-17 02:28:48,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:48,617][root][INFO] - Training Epoch: 1/2, step 6681/7134 completed (loss: 3.5286386013031006, acc: 0.328125)
[2024-12-17 02:28:48,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,003][root][INFO] - Training Epoch: 1/2, step 6682/7134 completed (loss: 3.0850942134857178, acc: 0.40776699781417847)
[2024-12-17 02:28:49,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,400][root][INFO] - Training Epoch: 1/2, step 6683/7134 completed (loss: 4.067736625671387, acc: 0.26436781883239746)
[2024-12-17 02:28:49,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:49,802][root][INFO] - Training Epoch: 1/2, step 6684/7134 completed (loss: 4.203180313110352, acc: 0.28346458077430725)
[2024-12-17 02:28:49,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,176][root][INFO] - Training Epoch: 1/2, step 6685/7134 completed (loss: 3.736870527267456, acc: 0.3199999928474426)
[2024-12-17 02:28:50,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,550][root][INFO] - Training Epoch: 1/2, step 6686/7134 completed (loss: 3.2049052715301514, acc: 0.38793104887008667)
[2024-12-17 02:28:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:50,933][root][INFO] - Training Epoch: 1/2, step 6687/7134 completed (loss: 3.5466346740722656, acc: 0.3372093141078949)
[2024-12-17 02:28:51,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,314][root][INFO] - Training Epoch: 1/2, step 6688/7134 completed (loss: 3.925713300704956, acc: 0.3525179922580719)
[2024-12-17 02:28:51,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:51,691][root][INFO] - Training Epoch: 1/2, step 6689/7134 completed (loss: 3.557101011276245, acc: 0.3055555522441864)
[2024-12-17 02:28:51,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,079][root][INFO] - Training Epoch: 1/2, step 6690/7134 completed (loss: 3.7319700717926025, acc: 0.3137255012989044)
[2024-12-17 02:28:52,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,456][root][INFO] - Training Epoch: 1/2, step 6691/7134 completed (loss: 3.6544690132141113, acc: 0.3541666567325592)
[2024-12-17 02:28:52,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:52,813][root][INFO] - Training Epoch: 1/2, step 6692/7134 completed (loss: 4.400775909423828, acc: 0.29906541109085083)
[2024-12-17 02:28:52,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,163][root][INFO] - Training Epoch: 1/2, step 6693/7134 completed (loss: 3.951536178588867, acc: 0.28148147463798523)
[2024-12-17 02:28:53,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,528][root][INFO] - Training Epoch: 1/2, step 6694/7134 completed (loss: 4.407094478607178, acc: 0.2450331151485443)
[2024-12-17 02:28:53,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:53,890][root][INFO] - Training Epoch: 1/2, step 6695/7134 completed (loss: 3.954612970352173, acc: 0.3125)
[2024-12-17 02:28:54,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,296][root][INFO] - Training Epoch: 1/2, step 6696/7134 completed (loss: 3.700052499771118, acc: 0.3333333432674408)
[2024-12-17 02:28:54,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:54,680][root][INFO] - Training Epoch: 1/2, step 6697/7134 completed (loss: 4.3486409187316895, acc: 0.3142857253551483)
[2024-12-17 02:28:54,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,070][root][INFO] - Training Epoch: 1/2, step 6698/7134 completed (loss: 4.144528388977051, acc: 0.24832214415073395)
[2024-12-17 02:28:55,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,435][root][INFO] - Training Epoch: 1/2, step 6699/7134 completed (loss: 4.529042720794678, acc: 0.27619048953056335)
[2024-12-17 02:28:55,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:55,807][root][INFO] - Training Epoch: 1/2, step 6700/7134 completed (loss: 4.329493522644043, acc: 0.34074074029922485)
[2024-12-17 02:28:55,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,184][root][INFO] - Training Epoch: 1/2, step 6701/7134 completed (loss: 4.715885162353516, acc: 0.28358209133148193)
[2024-12-17 02:28:56,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,535][root][INFO] - Training Epoch: 1/2, step 6702/7134 completed (loss: 4.094898700714111, acc: 0.3478260934352875)
[2024-12-17 02:28:56,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:56,875][root][INFO] - Training Epoch: 1/2, step 6703/7134 completed (loss: 4.279536724090576, acc: 0.2971014380455017)
[2024-12-17 02:28:56,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,258][root][INFO] - Training Epoch: 1/2, step 6704/7134 completed (loss: 4.060483932495117, acc: 0.29885056614875793)
[2024-12-17 02:28:57,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:57,637][root][INFO] - Training Epoch: 1/2, step 6705/7134 completed (loss: 4.4162678718566895, acc: 0.30635836720466614)
[2024-12-17 02:28:57,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,037][root][INFO] - Training Epoch: 1/2, step 6706/7134 completed (loss: 4.0236945152282715, acc: 0.33636364340782166)
[2024-12-17 02:28:58,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,386][root][INFO] - Training Epoch: 1/2, step 6707/7134 completed (loss: 4.564847946166992, acc: 0.2735042870044708)
[2024-12-17 02:28:58,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:58,767][root][INFO] - Training Epoch: 1/2, step 6708/7134 completed (loss: 4.656538963317871, acc: 0.3358778655529022)
[2024-12-17 02:28:58,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,127][root][INFO] - Training Epoch: 1/2, step 6709/7134 completed (loss: 4.216880798339844, acc: 0.23170731961727142)
[2024-12-17 02:28:59,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,474][root][INFO] - Training Epoch: 1/2, step 6710/7134 completed (loss: 3.8886778354644775, acc: 0.3834586441516876)
[2024-12-17 02:28:59,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:28:59,879][root][INFO] - Training Epoch: 1/2, step 6711/7134 completed (loss: 3.7845470905303955, acc: 0.3607594966888428)
[2024-12-17 02:29:00,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,245][root][INFO] - Training Epoch: 1/2, step 6712/7134 completed (loss: 4.00872802734375, acc: 0.35862070322036743)
[2024-12-17 02:29:00,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:00,690][root][INFO] - Training Epoch: 1/2, step 6713/7134 completed (loss: 4.188529014587402, acc: 0.28834354877471924)
[2024-12-17 02:29:00,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,090][root][INFO] - Training Epoch: 1/2, step 6714/7134 completed (loss: 3.9026472568511963, acc: 0.3179190754890442)
[2024-12-17 02:29:01,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,458][root][INFO] - Training Epoch: 1/2, step 6715/7134 completed (loss: 4.042507648468018, acc: 0.36486485600471497)
[2024-12-17 02:29:01,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:01,832][root][INFO] - Training Epoch: 1/2, step 6716/7134 completed (loss: 3.99575138092041, acc: 0.3287671208381653)
[2024-12-17 02:29:01,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,209][root][INFO] - Training Epoch: 1/2, step 6717/7134 completed (loss: 3.86061429977417, acc: 0.3175675570964813)
[2024-12-17 02:29:02,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,565][root][INFO] - Training Epoch: 1/2, step 6718/7134 completed (loss: 3.838873863220215, acc: 0.3448275923728943)
[2024-12-17 02:29:02,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:02,922][root][INFO] - Training Epoch: 1/2, step 6719/7134 completed (loss: 3.7397947311401367, acc: 0.3154362440109253)
[2024-12-17 02:29:03,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,317][root][INFO] - Training Epoch: 1/2, step 6720/7134 completed (loss: 4.441198825836182, acc: 0.21264368295669556)
[2024-12-17 02:29:03,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:03,668][root][INFO] - Training Epoch: 1/2, step 6721/7134 completed (loss: 4.075512409210205, acc: 0.2675159275531769)
[2024-12-17 02:29:03,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,021][root][INFO] - Training Epoch: 1/2, step 6722/7134 completed (loss: 5.104242324829102, acc: 0.16083915531635284)
[2024-12-17 02:29:04,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,419][root][INFO] - Training Epoch: 1/2, step 6723/7134 completed (loss: 4.370119094848633, acc: 0.2677595615386963)
[2024-12-17 02:29:04,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:04,780][root][INFO] - Training Epoch: 1/2, step 6724/7134 completed (loss: 4.253105163574219, acc: 0.28930819034576416)
[2024-12-17 02:29:04,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,131][root][INFO] - Training Epoch: 1/2, step 6725/7134 completed (loss: 4.326842308044434, acc: 0.2763157784938812)
[2024-12-17 02:29:05,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,493][root][INFO] - Training Epoch: 1/2, step 6726/7134 completed (loss: 3.7764604091644287, acc: 0.32231405377388)
[2024-12-17 02:29:05,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:05,868][root][INFO] - Training Epoch: 1/2, step 6727/7134 completed (loss: 4.118725299835205, acc: 0.26618704199790955)
[2024-12-17 02:29:05,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,255][root][INFO] - Training Epoch: 1/2, step 6728/7134 completed (loss: 3.970573663711548, acc: 0.3354838788509369)
[2024-12-17 02:29:06,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:06,639][root][INFO] - Training Epoch: 1/2, step 6729/7134 completed (loss: 4.107431888580322, acc: 0.3037974536418915)
[2024-12-17 02:29:06,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,048][root][INFO] - Training Epoch: 1/2, step 6730/7134 completed (loss: 3.856832265853882, acc: 0.3333333432674408)
[2024-12-17 02:29:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,453][root][INFO] - Training Epoch: 1/2, step 6731/7134 completed (loss: 3.796544075012207, acc: 0.3313252925872803)
[2024-12-17 02:29:07,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:07,826][root][INFO] - Training Epoch: 1/2, step 6732/7134 completed (loss: 3.999692440032959, acc: 0.3205128312110901)
[2024-12-17 02:29:07,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,185][root][INFO] - Training Epoch: 1/2, step 6733/7134 completed (loss: 3.916470527648926, acc: 0.30215826630592346)
[2024-12-17 02:29:08,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,540][root][INFO] - Training Epoch: 1/2, step 6734/7134 completed (loss: 4.125767230987549, acc: 0.28671327233314514)
[2024-12-17 02:29:08,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:08,980][root][INFO] - Training Epoch: 1/2, step 6735/7134 completed (loss: 4.082259178161621, acc: 0.29487180709838867)
[2024-12-17 02:29:09,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,368][root][INFO] - Training Epoch: 1/2, step 6736/7134 completed (loss: 4.298259258270264, acc: 0.25555557012557983)
[2024-12-17 02:29:09,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:09,799][root][INFO] - Training Epoch: 1/2, step 6737/7134 completed (loss: 3.885035991668701, acc: 0.2781457006931305)
[2024-12-17 02:29:09,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,168][root][INFO] - Training Epoch: 1/2, step 6738/7134 completed (loss: 3.9607961177825928, acc: 0.31617647409439087)
[2024-12-17 02:29:10,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,501][root][INFO] - Training Epoch: 1/2, step 6739/7134 completed (loss: 3.567455530166626, acc: 0.2928571403026581)
[2024-12-17 02:29:10,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:10,890][root][INFO] - Training Epoch: 1/2, step 6740/7134 completed (loss: 3.6930954456329346, acc: 0.36486485600471497)
[2024-12-17 02:29:10,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,257][root][INFO] - Training Epoch: 1/2, step 6741/7134 completed (loss: 3.342898368835449, acc: 0.379518061876297)
[2024-12-17 02:29:11,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:11,613][root][INFO] - Training Epoch: 1/2, step 6742/7134 completed (loss: 3.217193126678467, acc: 0.38235294818878174)
[2024-12-17 02:29:11,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,017][root][INFO] - Training Epoch: 1/2, step 6743/7134 completed (loss: 3.178630828857422, acc: 0.37288135290145874)
[2024-12-17 02:29:12,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,394][root][INFO] - Training Epoch: 1/2, step 6744/7134 completed (loss: 3.1328232288360596, acc: 0.37162160873413086)
[2024-12-17 02:29:12,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:12,778][root][INFO] - Training Epoch: 1/2, step 6745/7134 completed (loss: 3.2832539081573486, acc: 0.33139535784721375)
[2024-12-17 02:29:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,137][root][INFO] - Training Epoch: 1/2, step 6746/7134 completed (loss: 3.6561973094940186, acc: 0.2985074520111084)
[2024-12-17 02:29:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,469][root][INFO] - Training Epoch: 1/2, step 6747/7134 completed (loss: 3.2541956901550293, acc: 0.36125653982162476)
[2024-12-17 02:29:13,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:13,845][root][INFO] - Training Epoch: 1/2, step 6748/7134 completed (loss: 3.4097440242767334, acc: 0.3284313678741455)
[2024-12-17 02:29:13,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,265][root][INFO] - Training Epoch: 1/2, step 6749/7134 completed (loss: 3.4778459072113037, acc: 0.36000001430511475)
[2024-12-17 02:29:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:14,664][root][INFO] - Training Epoch: 1/2, step 6750/7134 completed (loss: 3.605971574783325, acc: 0.34158414602279663)
[2024-12-17 02:29:14,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,061][root][INFO] - Training Epoch: 1/2, step 6751/7134 completed (loss: 4.047900199890137, acc: 0.3034825921058655)
[2024-12-17 02:29:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,427][root][INFO] - Training Epoch: 1/2, step 6752/7134 completed (loss: 3.512582540512085, acc: 0.30674847960472107)
[2024-12-17 02:29:15,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:15,815][root][INFO] - Training Epoch: 1/2, step 6753/7134 completed (loss: 3.2807114124298096, acc: 0.33838382363319397)
[2024-12-17 02:29:15,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,197][root][INFO] - Training Epoch: 1/2, step 6754/7134 completed (loss: 3.8345789909362793, acc: 0.3298429250717163)
[2024-12-17 02:29:16,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,573][root][INFO] - Training Epoch: 1/2, step 6755/7134 completed (loss: 3.4464476108551025, acc: 0.3403141498565674)
[2024-12-17 02:29:16,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:16,962][root][INFO] - Training Epoch: 1/2, step 6756/7134 completed (loss: 3.0733752250671387, acc: 0.40449437499046326)
[2024-12-17 02:29:17,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,345][root][INFO] - Training Epoch: 1/2, step 6757/7134 completed (loss: 3.1208784580230713, acc: 0.3612903356552124)
[2024-12-17 02:29:17,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:17,732][root][INFO] - Training Epoch: 1/2, step 6758/7134 completed (loss: 3.4295835494995117, acc: 0.3108808398246765)
[2024-12-17 02:29:17,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,128][root][INFO] - Training Epoch: 1/2, step 6759/7134 completed (loss: 2.9738924503326416, acc: 0.3571428656578064)
[2024-12-17 02:29:18,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,510][root][INFO] - Training Epoch: 1/2, step 6760/7134 completed (loss: 3.615328311920166, acc: 0.32446807622909546)
[2024-12-17 02:29:18,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:18,887][root][INFO] - Training Epoch: 1/2, step 6761/7134 completed (loss: 3.8750436305999756, acc: 0.3142857253551483)
[2024-12-17 02:29:19,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,282][root][INFO] - Training Epoch: 1/2, step 6762/7134 completed (loss: 3.7522270679473877, acc: 0.33000001311302185)
[2024-12-17 02:29:19,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:19,673][root][INFO] - Training Epoch: 1/2, step 6763/7134 completed (loss: 3.6088006496429443, acc: 0.30481284856796265)
[2024-12-17 02:29:19,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,032][root][INFO] - Training Epoch: 1/2, step 6764/7134 completed (loss: 3.9801580905914307, acc: 0.25294119119644165)
[2024-12-17 02:29:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,410][root][INFO] - Training Epoch: 1/2, step 6765/7134 completed (loss: 3.2613449096679688, acc: 0.36263737082481384)
[2024-12-17 02:29:20,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:20,775][root][INFO] - Training Epoch: 1/2, step 6766/7134 completed (loss: 3.6070218086242676, acc: 0.34857141971588135)
[2024-12-17 02:29:20,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,084][root][INFO] - Training Epoch: 1/2, step 6767/7134 completed (loss: 3.3372139930725098, acc: 0.375)
[2024-12-17 02:29:21,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,462][root][INFO] - Training Epoch: 1/2, step 6768/7134 completed (loss: 3.174523115158081, acc: 0.3571428656578064)
[2024-12-17 02:29:21,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:21,845][root][INFO] - Training Epoch: 1/2, step 6769/7134 completed (loss: 3.9531409740448, acc: 0.2756410241127014)
[2024-12-17 02:29:21,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,223][root][INFO] - Training Epoch: 1/2, step 6770/7134 completed (loss: 3.963031530380249, acc: 0.3526315689086914)
[2024-12-17 02:29:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,607][root][INFO] - Training Epoch: 1/2, step 6771/7134 completed (loss: 3.744798183441162, acc: 0.28070175647735596)
[2024-12-17 02:29:22,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:22,978][root][INFO] - Training Epoch: 1/2, step 6772/7134 completed (loss: 4.013521194458008, acc: 0.2657342553138733)
[2024-12-17 02:29:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,323][root][INFO] - Training Epoch: 1/2, step 6773/7134 completed (loss: 3.992659568786621, acc: 0.32098764181137085)
[2024-12-17 02:29:23,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:23,689][root][INFO] - Training Epoch: 1/2, step 6774/7134 completed (loss: 4.284417152404785, acc: 0.28994083404541016)
[2024-12-17 02:29:23,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,100][root][INFO] - Training Epoch: 1/2, step 6775/7134 completed (loss: 3.53389310836792, acc: 0.317241370677948)
[2024-12-17 02:29:24,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,488][root][INFO] - Training Epoch: 1/2, step 6776/7134 completed (loss: 3.486201763153076, acc: 0.37599998712539673)
[2024-12-17 02:29:24,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:24,860][root][INFO] - Training Epoch: 1/2, step 6777/7134 completed (loss: 3.798068046569824, acc: 0.2571428716182709)
[2024-12-17 02:29:24,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,252][root][INFO] - Training Epoch: 1/2, step 6778/7134 completed (loss: 3.5836143493652344, acc: 0.3238636255264282)
[2024-12-17 02:29:25,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:25,634][root][INFO] - Training Epoch: 1/2, step 6779/7134 completed (loss: 3.4656176567077637, acc: 0.3452380895614624)
[2024-12-17 02:29:25,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,011][root][INFO] - Training Epoch: 1/2, step 6780/7134 completed (loss: 3.3630008697509766, acc: 0.35329341888427734)
[2024-12-17 02:29:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,392][root][INFO] - Training Epoch: 1/2, step 6781/7134 completed (loss: 3.3954739570617676, acc: 0.34502923488616943)
[2024-12-17 02:29:26,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:26,790][root][INFO] - Training Epoch: 1/2, step 6782/7134 completed (loss: 3.517152786254883, acc: 0.3354838788509369)
[2024-12-17 02:29:26,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,161][root][INFO] - Training Epoch: 1/2, step 6783/7134 completed (loss: 3.516935348510742, acc: 0.317241370677948)
[2024-12-17 02:29:27,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,535][root][INFO] - Training Epoch: 1/2, step 6784/7134 completed (loss: 3.2795422077178955, acc: 0.37974682450294495)
[2024-12-17 02:29:27,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:27,913][root][INFO] - Training Epoch: 1/2, step 6785/7134 completed (loss: 3.569960355758667, acc: 0.30718955397605896)
[2024-12-17 02:29:28,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,304][root][INFO] - Training Epoch: 1/2, step 6786/7134 completed (loss: 3.526977300643921, acc: 0.26553672552108765)
[2024-12-17 02:29:28,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:28,692][root][INFO] - Training Epoch: 1/2, step 6787/7134 completed (loss: 3.5544731616973877, acc: 0.31147539615631104)
[2024-12-17 02:29:28,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,091][root][INFO] - Training Epoch: 1/2, step 6788/7134 completed (loss: 3.4960885047912598, acc: 0.36690646409988403)
[2024-12-17 02:29:29,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,471][root][INFO] - Training Epoch: 1/2, step 6789/7134 completed (loss: 3.4612977504730225, acc: 0.3617021143436432)
[2024-12-17 02:29:29,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:29,867][root][INFO] - Training Epoch: 1/2, step 6790/7134 completed (loss: 3.8222780227661133, acc: 0.33522728085517883)
[2024-12-17 02:29:29,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,255][root][INFO] - Training Epoch: 1/2, step 6791/7134 completed (loss: 3.6086249351501465, acc: 0.32692307233810425)
[2024-12-17 02:29:30,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:30,659][root][INFO] - Training Epoch: 1/2, step 6792/7134 completed (loss: 3.1830718517303467, acc: 0.3805970251560211)
[2024-12-17 02:29:30,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,041][root][INFO] - Training Epoch: 1/2, step 6793/7134 completed (loss: 3.344773769378662, acc: 0.3684210479259491)
[2024-12-17 02:29:31,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,466][root][INFO] - Training Epoch: 1/2, step 6794/7134 completed (loss: 3.256038188934326, acc: 0.3945578336715698)
[2024-12-17 02:29:31,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:31,840][root][INFO] - Training Epoch: 1/2, step 6795/7134 completed (loss: 3.7239742279052734, acc: 0.34285715222358704)
[2024-12-17 02:29:31,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,234][root][INFO] - Training Epoch: 1/2, step 6796/7134 completed (loss: 3.614929437637329, acc: 0.3255814015865326)
[2024-12-17 02:29:32,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:32,639][root][INFO] - Training Epoch: 1/2, step 6797/7134 completed (loss: 3.8743128776550293, acc: 0.31707316637039185)
[2024-12-17 02:29:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,023][root][INFO] - Training Epoch: 1/2, step 6798/7134 completed (loss: 3.609448194503784, acc: 0.3072289228439331)
[2024-12-17 02:29:33,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,394][root][INFO] - Training Epoch: 1/2, step 6799/7134 completed (loss: 3.997218370437622, acc: 0.299401193857193)
[2024-12-17 02:29:33,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:33,733][root][INFO] - Training Epoch: 1/2, step 6800/7134 completed (loss: 4.536139965057373, acc: 0.31012657284736633)
[2024-12-17 02:29:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,123][root][INFO] - Training Epoch: 1/2, step 6801/7134 completed (loss: 4.038965225219727, acc: 0.28057554364204407)
[2024-12-17 02:29:34,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,484][root][INFO] - Training Epoch: 1/2, step 6802/7134 completed (loss: 4.186812877655029, acc: 0.2937062978744507)
[2024-12-17 02:29:34,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:34,863][root][INFO] - Training Epoch: 1/2, step 6803/7134 completed (loss: 3.8758761882781982, acc: 0.3444444537162781)
[2024-12-17 02:29:34,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,230][root][INFO] - Training Epoch: 1/2, step 6804/7134 completed (loss: 4.116852283477783, acc: 0.28859061002731323)
[2024-12-17 02:29:35,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:35,610][root][INFO] - Training Epoch: 1/2, step 6805/7134 completed (loss: 3.722231864929199, acc: 0.3185185194015503)
[2024-12-17 02:29:35,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,001][root][INFO] - Training Epoch: 1/2, step 6806/7134 completed (loss: 3.9897217750549316, acc: 0.28651684522628784)
[2024-12-17 02:29:36,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,375][root][INFO] - Training Epoch: 1/2, step 6807/7134 completed (loss: 3.744828701019287, acc: 0.29374998807907104)
[2024-12-17 02:29:36,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:36,737][root][INFO] - Training Epoch: 1/2, step 6808/7134 completed (loss: 3.781972646713257, acc: 0.3557046949863434)
[2024-12-17 02:29:36,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,107][root][INFO] - Training Epoch: 1/2, step 6809/7134 completed (loss: 3.8825621604919434, acc: 0.3333333432674408)
[2024-12-17 02:29:37,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,463][root][INFO] - Training Epoch: 1/2, step 6810/7134 completed (loss: 4.092796802520752, acc: 0.3181818127632141)
[2024-12-17 02:29:37,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:37,859][root][INFO] - Training Epoch: 1/2, step 6811/7134 completed (loss: 4.003011703491211, acc: 0.33139535784721375)
[2024-12-17 02:29:37,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,256][root][INFO] - Training Epoch: 1/2, step 6812/7134 completed (loss: 4.63427734375, acc: 0.2370370328426361)
[2024-12-17 02:29:38,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:38,642][root][INFO] - Training Epoch: 1/2, step 6813/7134 completed (loss: 4.049252510070801, acc: 0.3062500059604645)
[2024-12-17 02:29:38,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,008][root][INFO] - Training Epoch: 1/2, step 6814/7134 completed (loss: 3.8504879474639893, acc: 0.34285715222358704)
[2024-12-17 02:29:39,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,402][root][INFO] - Training Epoch: 1/2, step 6815/7134 completed (loss: 3.5785579681396484, acc: 0.33529412746429443)
[2024-12-17 02:29:39,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:39,785][root][INFO] - Training Epoch: 1/2, step 6816/7134 completed (loss: 3.414355993270874, acc: 0.3958333432674408)
[2024-12-17 02:29:39,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,157][root][INFO] - Training Epoch: 1/2, step 6817/7134 completed (loss: 4.063709735870361, acc: 0.2957746386528015)
[2024-12-17 02:29:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,547][root][INFO] - Training Epoch: 1/2, step 6818/7134 completed (loss: 4.056149959564209, acc: 0.2857142984867096)
[2024-12-17 02:29:40,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:40,950][root][INFO] - Training Epoch: 1/2, step 6819/7134 completed (loss: 3.8950631618499756, acc: 0.30656933784484863)
[2024-12-17 02:29:41,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,334][root][INFO] - Training Epoch: 1/2, step 6820/7134 completed (loss: 3.4628384113311768, acc: 0.39416059851646423)
[2024-12-17 02:29:41,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:41,702][root][INFO] - Training Epoch: 1/2, step 6821/7134 completed (loss: 3.697035551071167, acc: 0.34545454382896423)
[2024-12-17 02:29:41,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,094][root][INFO] - Training Epoch: 1/2, step 6822/7134 completed (loss: 3.8668158054351807, acc: 0.3255814015865326)
[2024-12-17 02:29:42,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,457][root][INFO] - Training Epoch: 1/2, step 6823/7134 completed (loss: 3.7368862628936768, acc: 0.3734939694404602)
[2024-12-17 02:29:42,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:42,817][root][INFO] - Training Epoch: 1/2, step 6824/7134 completed (loss: 4.296485424041748, acc: 0.34959349036216736)
[2024-12-17 02:29:42,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,199][root][INFO] - Training Epoch: 1/2, step 6825/7134 completed (loss: 4.1501030921936035, acc: 0.31182795763015747)
[2024-12-17 02:29:43,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,591][root][INFO] - Training Epoch: 1/2, step 6826/7134 completed (loss: 4.026749134063721, acc: 0.3695652186870575)
[2024-12-17 02:29:43,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:43,979][root][INFO] - Training Epoch: 1/2, step 6827/7134 completed (loss: 4.875821590423584, acc: 0.2239583283662796)
[2024-12-17 02:29:44,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,352][root][INFO] - Training Epoch: 1/2, step 6828/7134 completed (loss: 4.318122863769531, acc: 0.27464789152145386)
[2024-12-17 02:29:44,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:44,758][root][INFO] - Training Epoch: 1/2, step 6829/7134 completed (loss: 4.265171527862549, acc: 0.3136094808578491)
[2024-12-17 02:29:44,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,134][root][INFO] - Training Epoch: 1/2, step 6830/7134 completed (loss: 3.962205171585083, acc: 0.3175675570964813)
[2024-12-17 02:29:45,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,496][root][INFO] - Training Epoch: 1/2, step 6831/7134 completed (loss: 4.4365644454956055, acc: 0.2402234673500061)
[2024-12-17 02:29:45,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:45,859][root][INFO] - Training Epoch: 1/2, step 6832/7134 completed (loss: 4.2618184089660645, acc: 0.2916666567325592)
[2024-12-17 02:29:45,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,214][root][INFO] - Training Epoch: 1/2, step 6833/7134 completed (loss: 4.563928127288818, acc: 0.25477707386016846)
[2024-12-17 02:29:46,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,619][root][INFO] - Training Epoch: 1/2, step 6834/7134 completed (loss: 4.442358493804932, acc: 0.30201342701911926)
[2024-12-17 02:29:46,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:46,988][root][INFO] - Training Epoch: 1/2, step 6835/7134 completed (loss: 3.8833541870117188, acc: 0.3006536066532135)
[2024-12-17 02:29:47,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,355][root][INFO] - Training Epoch: 1/2, step 6836/7134 completed (loss: 4.134488105773926, acc: 0.3033175468444824)
[2024-12-17 02:29:47,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:47,736][root][INFO] - Training Epoch: 1/2, step 6837/7134 completed (loss: 3.549926996231079, acc: 0.31313130259513855)
[2024-12-17 02:29:47,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,117][root][INFO] - Training Epoch: 1/2, step 6838/7134 completed (loss: 4.112462997436523, acc: 0.27710843086242676)
[2024-12-17 02:29:48,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,502][root][INFO] - Training Epoch: 1/2, step 6839/7134 completed (loss: 4.758090019226074, acc: 0.25333333015441895)
[2024-12-17 02:29:48,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:48,862][root][INFO] - Training Epoch: 1/2, step 6840/7134 completed (loss: 4.487245559692383, acc: 0.2611464858055115)
[2024-12-17 02:29:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,241][root][INFO] - Training Epoch: 1/2, step 6841/7134 completed (loss: 4.367219924926758, acc: 0.2073170691728592)
[2024-12-17 02:29:49,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:49,622][root][INFO] - Training Epoch: 1/2, step 6842/7134 completed (loss: 4.405856132507324, acc: 0.24175824224948883)
[2024-12-17 02:29:49,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,001][root][INFO] - Training Epoch: 1/2, step 6843/7134 completed (loss: 4.011785984039307, acc: 0.27979275584220886)
[2024-12-17 02:29:50,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,393][root][INFO] - Training Epoch: 1/2, step 6844/7134 completed (loss: 3.9744720458984375, acc: 0.281879186630249)
[2024-12-17 02:29:50,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:50,777][root][INFO] - Training Epoch: 1/2, step 6845/7134 completed (loss: 4.263735294342041, acc: 0.23846153914928436)
[2024-12-17 02:29:50,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,144][root][INFO] - Training Epoch: 1/2, step 6846/7134 completed (loss: 4.380363464355469, acc: 0.3086419701576233)
[2024-12-17 02:29:51,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,533][root][INFO] - Training Epoch: 1/2, step 6847/7134 completed (loss: 4.677130699157715, acc: 0.22499999403953552)
[2024-12-17 02:29:51,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:51,892][root][INFO] - Training Epoch: 1/2, step 6848/7134 completed (loss: 4.074233531951904, acc: 0.31460675597190857)
[2024-12-17 02:29:51,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,287][root][INFO] - Training Epoch: 1/2, step 6849/7134 completed (loss: 4.362555980682373, acc: 0.26428571343421936)
[2024-12-17 02:29:52,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:52,658][root][INFO] - Training Epoch: 1/2, step 6850/7134 completed (loss: 4.4764299392700195, acc: 0.24761904776096344)
[2024-12-17 02:29:52,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,049][root][INFO] - Training Epoch: 1/2, step 6851/7134 completed (loss: 4.008715629577637, acc: 0.3038673996925354)
[2024-12-17 02:29:53,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,437][root][INFO] - Training Epoch: 1/2, step 6852/7134 completed (loss: 3.949942111968994, acc: 0.3142857253551483)
[2024-12-17 02:29:53,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:53,811][root][INFO] - Training Epoch: 1/2, step 6853/7134 completed (loss: 3.9733259677886963, acc: 0.28901734948158264)
[2024-12-17 02:29:53,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,173][root][INFO] - Training Epoch: 1/2, step 6854/7134 completed (loss: 3.6264803409576416, acc: 0.31355932354927063)
[2024-12-17 02:29:54,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,542][root][INFO] - Training Epoch: 1/2, step 6855/7134 completed (loss: 3.8278732299804688, acc: 0.2616822421550751)
[2024-12-17 02:29:54,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:54,916][root][INFO] - Training Epoch: 1/2, step 6856/7134 completed (loss: 3.201542854309082, acc: 0.3614457845687866)
[2024-12-17 02:29:55,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,322][root][INFO] - Training Epoch: 1/2, step 6857/7134 completed (loss: 3.5766713619232178, acc: 0.3214285671710968)
[2024-12-17 02:29:55,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:55,694][root][INFO] - Training Epoch: 1/2, step 6858/7134 completed (loss: 3.546989917755127, acc: 0.3636363744735718)
[2024-12-17 02:29:55,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,074][root][INFO] - Training Epoch: 1/2, step 6859/7134 completed (loss: 3.620469093322754, acc: 0.32022473216056824)
[2024-12-17 02:29:56,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,448][root][INFO] - Training Epoch: 1/2, step 6860/7134 completed (loss: 3.4080240726470947, acc: 0.3379310369491577)
[2024-12-17 02:29:56,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:56,815][root][INFO] - Training Epoch: 1/2, step 6861/7134 completed (loss: 3.5007126331329346, acc: 0.35664334893226624)
[2024-12-17 02:29:56,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,194][root][INFO] - Training Epoch: 1/2, step 6862/7134 completed (loss: 3.741926431655884, acc: 0.35606059432029724)
[2024-12-17 02:29:57,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,570][root][INFO] - Training Epoch: 1/2, step 6863/7134 completed (loss: 3.5003209114074707, acc: 0.4117647111415863)
[2024-12-17 02:29:57,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:57,933][root][INFO] - Training Epoch: 1/2, step 6864/7134 completed (loss: 3.713759422302246, acc: 0.283687949180603)
[2024-12-17 02:29:58,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,277][root][INFO] - Training Epoch: 1/2, step 6865/7134 completed (loss: 3.1116702556610107, acc: 0.43089431524276733)
[2024-12-17 02:29:58,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,598][root][INFO] - Training Epoch: 1/2, step 6866/7134 completed (loss: 3.0381293296813965, acc: 0.4248366057872772)
[2024-12-17 02:29:58,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:58,958][root][INFO] - Training Epoch: 1/2, step 6867/7134 completed (loss: 2.8570265769958496, acc: 0.4285714328289032)
[2024-12-17 02:29:59,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,322][root][INFO] - Training Epoch: 1/2, step 6868/7134 completed (loss: 2.8538930416107178, acc: 0.375)
[2024-12-17 02:29:59,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:29:59,663][root][INFO] - Training Epoch: 1/2, step 6869/7134 completed (loss: 3.38366961479187, acc: 0.3669724762439728)
[2024-12-17 02:29:59,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,054][root][INFO] - Training Epoch: 1/2, step 6870/7134 completed (loss: 2.8536338806152344, acc: 0.4177215099334717)
[2024-12-17 02:30:00,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,451][root][INFO] - Training Epoch: 1/2, step 6871/7134 completed (loss: 3.0619912147521973, acc: 0.3968254029750824)
[2024-12-17 02:30:00,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:00,804][root][INFO] - Training Epoch: 1/2, step 6872/7134 completed (loss: 3.012349843978882, acc: 0.3806818127632141)
[2024-12-17 02:30:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,185][root][INFO] - Training Epoch: 1/2, step 6873/7134 completed (loss: 3.118924856185913, acc: 0.38823530077934265)
[2024-12-17 02:30:01,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,541][root][INFO] - Training Epoch: 1/2, step 6874/7134 completed (loss: 2.9645564556121826, acc: 0.3515625)
[2024-12-17 02:30:01,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:01,927][root][INFO] - Training Epoch: 1/2, step 6875/7134 completed (loss: 3.384526491165161, acc: 0.38926175236701965)
[2024-12-17 02:30:02,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,295][root][INFO] - Training Epoch: 1/2, step 6876/7134 completed (loss: 3.0742416381835938, acc: 0.3664122223854065)
[2024-12-17 02:30:02,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:02,679][root][INFO] - Training Epoch: 1/2, step 6877/7134 completed (loss: 3.216840982437134, acc: 0.3294117748737335)
[2024-12-17 02:30:02,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,063][root][INFO] - Training Epoch: 1/2, step 6878/7134 completed (loss: 4.051197528839111, acc: 0.26143792271614075)
[2024-12-17 02:30:03,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,411][root][INFO] - Training Epoch: 1/2, step 6879/7134 completed (loss: 4.007208347320557, acc: 0.2844827473163605)
[2024-12-17 02:30:03,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:03,813][root][INFO] - Training Epoch: 1/2, step 6880/7134 completed (loss: 3.3680319786071777, acc: 0.3147208094596863)
[2024-12-17 02:30:03,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,192][root][INFO] - Training Epoch: 1/2, step 6881/7134 completed (loss: 3.3777225017547607, acc: 0.3297872245311737)
[2024-12-17 02:30:04,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,524][root][INFO] - Training Epoch: 1/2, step 6882/7134 completed (loss: 3.6485605239868164, acc: 0.31690141558647156)
[2024-12-17 02:30:04,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:04,879][root][INFO] - Training Epoch: 1/2, step 6883/7134 completed (loss: 3.5321521759033203, acc: 0.27941176295280457)
[2024-12-17 02:30:04,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,252][root][INFO] - Training Epoch: 1/2, step 6884/7134 completed (loss: 3.6559667587280273, acc: 0.3238636255264282)
[2024-12-17 02:30:05,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:05,627][root][INFO] - Training Epoch: 1/2, step 6885/7134 completed (loss: 3.0642757415771484, acc: 0.38317757844924927)
[2024-12-17 02:30:05,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,000][root][INFO] - Training Epoch: 1/2, step 6886/7134 completed (loss: 3.764116048812866, acc: 0.3310810923576355)
[2024-12-17 02:30:06,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,320][root][INFO] - Training Epoch: 1/2, step 6887/7134 completed (loss: 3.6456518173217773, acc: 0.2956521809101105)
[2024-12-17 02:30:06,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:06,694][root][INFO] - Training Epoch: 1/2, step 6888/7134 completed (loss: 3.7063546180725098, acc: 0.35333332419395447)
[2024-12-17 02:30:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,086][root][INFO] - Training Epoch: 1/2, step 6889/7134 completed (loss: 3.7570362091064453, acc: 0.3333333432674408)
[2024-12-17 02:30:07,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,472][root][INFO] - Training Epoch: 1/2, step 6890/7134 completed (loss: 3.6938316822052, acc: 0.30645161867141724)
[2024-12-17 02:30:07,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:07,838][root][INFO] - Training Epoch: 1/2, step 6891/7134 completed (loss: 3.5826735496520996, acc: 0.35185185074806213)
[2024-12-17 02:30:07,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,200][root][INFO] - Training Epoch: 1/2, step 6892/7134 completed (loss: 3.644474506378174, acc: 0.301075279712677)
[2024-12-17 02:30:08,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,573][root][INFO] - Training Epoch: 1/2, step 6893/7134 completed (loss: 3.6907083988189697, acc: 0.32211539149284363)
[2024-12-17 02:30:08,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:08,939][root][INFO] - Training Epoch: 1/2, step 6894/7134 completed (loss: 3.7138473987579346, acc: 0.3229166567325592)
[2024-12-17 02:30:09,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,367][root][INFO] - Training Epoch: 1/2, step 6895/7134 completed (loss: 3.7642476558685303, acc: 0.33990147709846497)
[2024-12-17 02:30:09,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:09,760][root][INFO] - Training Epoch: 1/2, step 6896/7134 completed (loss: 4.109308242797852, acc: 0.28901734948158264)
[2024-12-17 02:30:09,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,107][root][INFO] - Training Epoch: 1/2, step 6897/7134 completed (loss: 3.653620719909668, acc: 0.35148516297340393)
[2024-12-17 02:30:10,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,466][root][INFO] - Training Epoch: 1/2, step 6898/7134 completed (loss: 3.9040093421936035, acc: 0.30635836720466614)
[2024-12-17 02:30:10,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:10,833][root][INFO] - Training Epoch: 1/2, step 6899/7134 completed (loss: 3.8276140689849854, acc: 0.2978723347187042)
[2024-12-17 02:30:10,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,206][root][INFO] - Training Epoch: 1/2, step 6900/7134 completed (loss: 4.112473964691162, acc: 0.2543352544307709)
[2024-12-17 02:30:11,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:11,591][root][INFO] - Training Epoch: 1/2, step 6901/7134 completed (loss: 3.6738107204437256, acc: 0.2918919026851654)
[2024-12-17 02:30:11,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,001][root][INFO] - Training Epoch: 1/2, step 6902/7134 completed (loss: 3.3853824138641357, acc: 0.33707866072654724)
[2024-12-17 02:30:12,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,372][root][INFO] - Training Epoch: 1/2, step 6903/7134 completed (loss: 3.501035213470459, acc: 0.3121951222419739)
[2024-12-17 02:30:12,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:12,755][root][INFO] - Training Epoch: 1/2, step 6904/7134 completed (loss: 3.4766359329223633, acc: 0.36269429326057434)
[2024-12-17 02:30:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,136][root][INFO] - Training Epoch: 1/2, step 6905/7134 completed (loss: 3.1971843242645264, acc: 0.34825870394706726)
[2024-12-17 02:30:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,505][root][INFO] - Training Epoch: 1/2, step 6906/7134 completed (loss: 3.6060259342193604, acc: 0.3382352888584137)
[2024-12-17 02:30:13,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:13,865][root][INFO] - Training Epoch: 1/2, step 6907/7134 completed (loss: 3.550365686416626, acc: 0.3834196925163269)
[2024-12-17 02:30:13,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,241][root][INFO] - Training Epoch: 1/2, step 6908/7134 completed (loss: 3.567734479904175, acc: 0.2857142984867096)
[2024-12-17 02:30:14,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,616][root][INFO] - Training Epoch: 1/2, step 6909/7134 completed (loss: 3.6854894161224365, acc: 0.3060109317302704)
[2024-12-17 02:30:14,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:14,981][root][INFO] - Training Epoch: 1/2, step 6910/7134 completed (loss: 3.6443490982055664, acc: 0.34375)
[2024-12-17 02:30:15,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,326][root][INFO] - Training Epoch: 1/2, step 6911/7134 completed (loss: 3.8985447883605957, acc: 0.3093922734260559)
[2024-12-17 02:30:15,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:15,675][root][INFO] - Training Epoch: 1/2, step 6912/7134 completed (loss: 2.882861614227295, acc: 0.4000000059604645)
[2024-12-17 02:30:15,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,080][root][INFO] - Training Epoch: 1/2, step 6913/7134 completed (loss: 3.6442346572875977, acc: 0.3478260934352875)
[2024-12-17 02:30:16,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,439][root][INFO] - Training Epoch: 1/2, step 6914/7134 completed (loss: 3.6244957447052, acc: 0.3006536066532135)
[2024-12-17 02:30:16,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:16,820][root][INFO] - Training Epoch: 1/2, step 6915/7134 completed (loss: 4.00242805480957, acc: 0.2918919026851654)
[2024-12-17 02:30:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,182][root][INFO] - Training Epoch: 1/2, step 6916/7134 completed (loss: 3.977799892425537, acc: 0.2536585330963135)
[2024-12-17 02:30:17,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,555][root][INFO] - Training Epoch: 1/2, step 6917/7134 completed (loss: 3.8877408504486084, acc: 0.25773194432258606)
[2024-12-17 02:30:17,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:17,917][root][INFO] - Training Epoch: 1/2, step 6918/7134 completed (loss: 3.8742871284484863, acc: 0.27835050225257874)
[2024-12-17 02:30:18,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,315][root][INFO] - Training Epoch: 1/2, step 6919/7134 completed (loss: 4.12713623046875, acc: 0.2842639684677124)
[2024-12-17 02:30:18,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:18,695][root][INFO] - Training Epoch: 1/2, step 6920/7134 completed (loss: 3.556140184402466, acc: 0.3652694523334503)
[2024-12-17 02:30:18,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,068][root][INFO] - Training Epoch: 1/2, step 6921/7134 completed (loss: 3.677435874938965, acc: 0.3382352888584137)
[2024-12-17 02:30:19,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,415][root][INFO] - Training Epoch: 1/2, step 6922/7134 completed (loss: 4.196610450744629, acc: 0.28205129504203796)
[2024-12-17 02:30:19,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:19,775][root][INFO] - Training Epoch: 1/2, step 6923/7134 completed (loss: 3.312269687652588, acc: 0.38596490025520325)
[2024-12-17 02:30:19,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,137][root][INFO] - Training Epoch: 1/2, step 6924/7134 completed (loss: 3.5835464000701904, acc: 0.30909091234207153)
[2024-12-17 02:30:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,469][root][INFO] - Training Epoch: 1/2, step 6925/7134 completed (loss: 3.4510250091552734, acc: 0.38823530077934265)
[2024-12-17 02:30:20,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:20,806][root][INFO] - Training Epoch: 1/2, step 6926/7134 completed (loss: 4.259429454803467, acc: 0.2460317462682724)
[2024-12-17 02:30:20,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,181][root][INFO] - Training Epoch: 1/2, step 6927/7134 completed (loss: 3.744567632675171, acc: 0.2673267424106598)
[2024-12-17 02:30:21,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,532][root][INFO] - Training Epoch: 1/2, step 6928/7134 completed (loss: 3.5779576301574707, acc: 0.328125)
[2024-12-17 02:30:21,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:21,905][root][INFO] - Training Epoch: 1/2, step 6929/7134 completed (loss: 3.2964532375335693, acc: 0.33522728085517883)
[2024-12-17 02:30:22,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,263][root][INFO] - Training Epoch: 1/2, step 6930/7134 completed (loss: 3.100764036178589, acc: 0.4166666567325592)
[2024-12-17 02:30:22,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,648][root][INFO] - Training Epoch: 1/2, step 6931/7134 completed (loss: 3.618999481201172, acc: 0.35978835821151733)
[2024-12-17 02:30:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:22,999][root][INFO] - Training Epoch: 1/2, step 6932/7134 completed (loss: 3.789238214492798, acc: 0.2934131622314453)
[2024-12-17 02:30:23,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,356][root][INFO] - Training Epoch: 1/2, step 6933/7134 completed (loss: 3.68202805519104, acc: 0.3053892254829407)
[2024-12-17 02:30:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:23,706][root][INFO] - Training Epoch: 1/2, step 6934/7134 completed (loss: 3.4771289825439453, acc: 0.3717948794364929)
[2024-12-17 02:30:23,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,058][root][INFO] - Training Epoch: 1/2, step 6935/7134 completed (loss: 3.0704166889190674, acc: 0.4095744788646698)
[2024-12-17 02:30:24,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,454][root][INFO] - Training Epoch: 1/2, step 6936/7134 completed (loss: 3.16011905670166, acc: 0.37634408473968506)
[2024-12-17 02:30:24,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:24,834][root][INFO] - Training Epoch: 1/2, step 6937/7134 completed (loss: 3.739300012588501, acc: 0.33561643958091736)
[2024-12-17 02:30:24,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,206][root][INFO] - Training Epoch: 1/2, step 6938/7134 completed (loss: 4.208500385284424, acc: 0.28735631704330444)
[2024-12-17 02:30:25,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,597][root][INFO] - Training Epoch: 1/2, step 6939/7134 completed (loss: 3.750056743621826, acc: 0.3154761791229248)
[2024-12-17 02:30:25,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:25,960][root][INFO] - Training Epoch: 1/2, step 6940/7134 completed (loss: 4.252964019775391, acc: 0.317241370677948)
[2024-12-17 02:30:26,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,307][root][INFO] - Training Epoch: 1/2, step 6941/7134 completed (loss: 3.545250177383423, acc: 0.3014705777168274)
[2024-12-17 02:30:26,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:26,631][root][INFO] - Training Epoch: 1/2, step 6942/7134 completed (loss: 3.960270881652832, acc: 0.337579607963562)
[2024-12-17 02:30:26,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,009][root][INFO] - Training Epoch: 1/2, step 6943/7134 completed (loss: 3.5607950687408447, acc: 0.36283186078071594)
[2024-12-17 02:30:27,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,377][root][INFO] - Training Epoch: 1/2, step 6944/7134 completed (loss: 3.6589107513427734, acc: 0.29655173420906067)
[2024-12-17 02:30:27,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:27,690][root][INFO] - Training Epoch: 1/2, step 6945/7134 completed (loss: 3.64471697807312, acc: 0.3125)
[2024-12-17 02:30:27,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,052][root][INFO] - Training Epoch: 1/2, step 6946/7134 completed (loss: 3.676305055618286, acc: 0.40860214829444885)
[2024-12-17 02:30:28,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,441][root][INFO] - Training Epoch: 1/2, step 6947/7134 completed (loss: 3.3224799633026123, acc: 0.4247787594795227)
[2024-12-17 02:30:28,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:28,799][root][INFO] - Training Epoch: 1/2, step 6948/7134 completed (loss: 3.903473377227783, acc: 0.3142857253551483)
[2024-12-17 02:30:28,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,176][root][INFO] - Training Epoch: 1/2, step 6949/7134 completed (loss: 3.6741085052490234, acc: 0.35652172565460205)
[2024-12-17 02:30:29,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,555][root][INFO] - Training Epoch: 1/2, step 6950/7134 completed (loss: 3.9113900661468506, acc: 0.3164556920528412)
[2024-12-17 02:30:29,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:29,935][root][INFO] - Training Epoch: 1/2, step 6951/7134 completed (loss: 4.320840358734131, acc: 0.2986111044883728)
[2024-12-17 02:30:30,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,286][root][INFO] - Training Epoch: 1/2, step 6952/7134 completed (loss: 4.163184642791748, acc: 0.34285715222358704)
[2024-12-17 02:30:30,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:30,659][root][INFO] - Training Epoch: 1/2, step 6953/7134 completed (loss: 4.3064470291137695, acc: 0.29323309659957886)
[2024-12-17 02:30:30,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,042][root][INFO] - Training Epoch: 1/2, step 6954/7134 completed (loss: 4.079495429992676, acc: 0.3448275923728943)
[2024-12-17 02:30:31,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,456][root][INFO] - Training Epoch: 1/2, step 6955/7134 completed (loss: 4.357973098754883, acc: 0.20000000298023224)
[2024-12-17 02:30:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:31,829][root][INFO] - Training Epoch: 1/2, step 6956/7134 completed (loss: 3.2117152214050293, acc: 0.35766422748565674)
[2024-12-17 02:30:31,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,214][root][INFO] - Training Epoch: 1/2, step 6957/7134 completed (loss: 3.849517822265625, acc: 0.36000001430511475)
[2024-12-17 02:30:32,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,596][root][INFO] - Training Epoch: 1/2, step 6958/7134 completed (loss: 4.063094615936279, acc: 0.3162393271923065)
[2024-12-17 02:30:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:32,988][root][INFO] - Training Epoch: 1/2, step 6959/7134 completed (loss: 4.697747230529785, acc: 0.24770642817020416)
[2024-12-17 02:30:33,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,397][root][INFO] - Training Epoch: 1/2, step 6960/7134 completed (loss: 4.086233139038086, acc: 0.3472222089767456)
[2024-12-17 02:30:33,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:33,779][root][INFO] - Training Epoch: 1/2, step 6961/7134 completed (loss: 3.5930917263031006, acc: 0.38461539149284363)
[2024-12-17 02:30:33,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,162][root][INFO] - Training Epoch: 1/2, step 6962/7134 completed (loss: 3.6792564392089844, acc: 0.28985506296157837)
[2024-12-17 02:30:34,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,539][root][INFO] - Training Epoch: 1/2, step 6963/7134 completed (loss: 3.7613322734832764, acc: 0.33774834871292114)
[2024-12-17 02:30:34,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:34,947][root][INFO] - Training Epoch: 1/2, step 6964/7134 completed (loss: 3.602431297302246, acc: 0.3333333432674408)
[2024-12-17 02:30:35,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,347][root][INFO] - Training Epoch: 1/2, step 6965/7134 completed (loss: 3.3060450553894043, acc: 0.3741007149219513)
[2024-12-17 02:30:35,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:35,724][root][INFO] - Training Epoch: 1/2, step 6966/7134 completed (loss: 3.694037675857544, acc: 0.3142857253551483)
[2024-12-17 02:30:35,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,105][root][INFO] - Training Epoch: 1/2, step 6967/7134 completed (loss: 3.667445182800293, acc: 0.3741496503353119)
[2024-12-17 02:30:36,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,497][root][INFO] - Training Epoch: 1/2, step 6968/7134 completed (loss: 4.045062065124512, acc: 0.34228187799453735)
[2024-12-17 02:30:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:36,869][root][INFO] - Training Epoch: 1/2, step 6969/7134 completed (loss: 4.114498615264893, acc: 0.27419355511665344)
[2024-12-17 02:30:36,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,237][root][INFO] - Training Epoch: 1/2, step 6970/7134 completed (loss: 4.02632474899292, acc: 0.31896552443504333)
[2024-12-17 02:30:37,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,622][root][INFO] - Training Epoch: 1/2, step 6971/7134 completed (loss: 4.102887153625488, acc: 0.2777777910232544)
[2024-12-17 02:30:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:37,994][root][INFO] - Training Epoch: 1/2, step 6972/7134 completed (loss: 4.165163040161133, acc: 0.27906978130340576)
[2024-12-17 02:30:38,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,371][root][INFO] - Training Epoch: 1/2, step 6973/7134 completed (loss: 3.658343553543091, acc: 0.36206895112991333)
[2024-12-17 02:30:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:38,715][root][INFO] - Training Epoch: 1/2, step 6974/7134 completed (loss: 3.8974270820617676, acc: 0.26143792271614075)
[2024-12-17 02:30:38,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,108][root][INFO] - Training Epoch: 1/2, step 6975/7134 completed (loss: 3.8198440074920654, acc: 0.36752137541770935)
[2024-12-17 02:30:39,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,469][root][INFO] - Training Epoch: 1/2, step 6976/7134 completed (loss: 3.2986955642700195, acc: 0.37857142090797424)
[2024-12-17 02:30:39,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:39,857][root][INFO] - Training Epoch: 1/2, step 6977/7134 completed (loss: 4.023766994476318, acc: 0.2748091518878937)
[2024-12-17 02:30:39,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,234][root][INFO] - Training Epoch: 1/2, step 6978/7134 completed (loss: 3.7587740421295166, acc: 0.31012657284736633)
[2024-12-17 02:30:40,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:40,599][root][INFO] - Training Epoch: 1/2, step 6979/7134 completed (loss: 3.759579658508301, acc: 0.38410595059394836)
[2024-12-17 02:30:40,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,011][root][INFO] - Training Epoch: 1/2, step 6980/7134 completed (loss: 4.389397621154785, acc: 0.1977401077747345)
[2024-12-17 02:30:41,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,399][root][INFO] - Training Epoch: 1/2, step 6981/7134 completed (loss: 4.048071384429932, acc: 0.2835051417350769)
[2024-12-17 02:30:41,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:41,787][root][INFO] - Training Epoch: 1/2, step 6982/7134 completed (loss: 3.785780668258667, acc: 0.35078534483909607)
[2024-12-17 02:30:41,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,168][root][INFO] - Training Epoch: 1/2, step 6983/7134 completed (loss: 4.288672924041748, acc: 0.26923078298568726)
[2024-12-17 02:30:42,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,539][root][INFO] - Training Epoch: 1/2, step 6984/7134 completed (loss: 3.9064719676971436, acc: 0.3395348787307739)
[2024-12-17 02:30:42,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:42,926][root][INFO] - Training Epoch: 1/2, step 6985/7134 completed (loss: 3.995267629623413, acc: 0.30042919516563416)
[2024-12-17 02:30:43,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,299][root][INFO] - Training Epoch: 1/2, step 6986/7134 completed (loss: 3.7850375175476074, acc: 0.327160507440567)
[2024-12-17 02:30:43,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:43,680][root][INFO] - Training Epoch: 1/2, step 6987/7134 completed (loss: 4.009073257446289, acc: 0.3181818127632141)
[2024-12-17 02:30:43,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,038][root][INFO] - Training Epoch: 1/2, step 6988/7134 completed (loss: 3.955439329147339, acc: 0.28346458077430725)
[2024-12-17 02:30:44,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,415][root][INFO] - Training Epoch: 1/2, step 6989/7134 completed (loss: 3.5727028846740723, acc: 0.3918918967247009)
[2024-12-17 02:30:44,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:44,802][root][INFO] - Training Epoch: 1/2, step 6990/7134 completed (loss: 3.409820795059204, acc: 0.31481480598449707)
[2024-12-17 02:30:44,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,184][root][INFO] - Training Epoch: 1/2, step 6991/7134 completed (loss: 3.524155378341675, acc: 0.39603960514068604)
[2024-12-17 02:30:45,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,615][root][INFO] - Training Epoch: 1/2, step 6992/7134 completed (loss: 4.017217636108398, acc: 0.28828829526901245)
[2024-12-17 02:30:45,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:45,984][root][INFO] - Training Epoch: 1/2, step 6993/7134 completed (loss: 3.721020460128784, acc: 0.30573248863220215)
[2024-12-17 02:30:46,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,350][root][INFO] - Training Epoch: 1/2, step 6994/7134 completed (loss: 3.7398343086242676, acc: 0.3199999928474426)
[2024-12-17 02:30:46,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:46,713][root][INFO] - Training Epoch: 1/2, step 6995/7134 completed (loss: 4.060600280761719, acc: 0.2732558250427246)
[2024-12-17 02:30:46,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,051][root][INFO] - Training Epoch: 1/2, step 6996/7134 completed (loss: 3.8046836853027344, acc: 0.30136987566947937)
[2024-12-17 02:30:47,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,410][root][INFO] - Training Epoch: 1/2, step 6997/7134 completed (loss: 3.819371461868286, acc: 0.3677419424057007)
[2024-12-17 02:30:47,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:47,761][root][INFO] - Training Epoch: 1/2, step 6998/7134 completed (loss: 3.896456003189087, acc: 0.3368421196937561)
[2024-12-17 02:30:47,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,153][root][INFO] - Training Epoch: 1/2, step 6999/7134 completed (loss: 3.6696276664733887, acc: 0.299435019493103)
[2024-12-17 02:30:48,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,457][root][INFO] - Training Epoch: 1/2, step 7000/7134 completed (loss: 3.755127429962158, acc: 0.30909091234207153)
[2024-12-17 02:30:48,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:48,838][root][INFO] - Training Epoch: 1/2, step 7001/7134 completed (loss: 3.54302978515625, acc: 0.30519479513168335)
[2024-12-17 02:30:48,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,214][root][INFO] - Training Epoch: 1/2, step 7002/7134 completed (loss: 3.4675815105438232, acc: 0.2857142984867096)
[2024-12-17 02:30:49,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,554][root][INFO] - Training Epoch: 1/2, step 7003/7134 completed (loss: 3.3619956970214844, acc: 0.40414509177207947)
[2024-12-17 02:30:49,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:49,993][root][INFO] - Training Epoch: 1/2, step 7004/7134 completed (loss: 3.1450202465057373, acc: 0.4085365831851959)
[2024-12-17 02:30:50,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,369][root][INFO] - Training Epoch: 1/2, step 7005/7134 completed (loss: 3.68902587890625, acc: 0.34337350726127625)
[2024-12-17 02:30:50,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:50,776][root][INFO] - Training Epoch: 1/2, step 7006/7134 completed (loss: 3.46431827545166, acc: 0.35403725504875183)
[2024-12-17 02:30:50,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,155][root][INFO] - Training Epoch: 1/2, step 7007/7134 completed (loss: 3.6880276203155518, acc: 0.3096774220466614)
[2024-12-17 02:30:51,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,495][root][INFO] - Training Epoch: 1/2, step 7008/7134 completed (loss: 3.315829038619995, acc: 0.3535911738872528)
[2024-12-17 02:30:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:51,893][root][INFO] - Training Epoch: 1/2, step 7009/7134 completed (loss: 3.695246696472168, acc: 0.2760416567325592)
[2024-12-17 02:30:52,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,281][root][INFO] - Training Epoch: 1/2, step 7010/7134 completed (loss: 3.595536231994629, acc: 0.2709677517414093)
[2024-12-17 02:30:52,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:52,669][root][INFO] - Training Epoch: 1/2, step 7011/7134 completed (loss: 3.4674599170684814, acc: 0.36125653982162476)
[2024-12-17 02:30:52,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,038][root][INFO] - Training Epoch: 1/2, step 7012/7134 completed (loss: 3.093510627746582, acc: 0.39759036898612976)
[2024-12-17 02:30:53,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,430][root][INFO] - Training Epoch: 1/2, step 7013/7134 completed (loss: 3.338329553604126, acc: 0.3821656107902527)
[2024-12-17 02:30:53,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:53,805][root][INFO] - Training Epoch: 1/2, step 7014/7134 completed (loss: 3.5828332901000977, acc: 0.37837839126586914)
[2024-12-17 02:30:53,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,119][root][INFO] - Training Epoch: 1/2, step 7015/7134 completed (loss: 3.578753709793091, acc: 0.3805970251560211)
[2024-12-17 02:30:54,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,513][root][INFO] - Training Epoch: 1/2, step 7016/7134 completed (loss: 3.2976832389831543, acc: 0.36538460850715637)
[2024-12-17 02:30:54,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:54,869][root][INFO] - Training Epoch: 1/2, step 7017/7134 completed (loss: 3.788114309310913, acc: 0.3185840845108032)
[2024-12-17 02:30:54,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,255][root][INFO] - Training Epoch: 1/2, step 7018/7134 completed (loss: 3.4634079933166504, acc: 0.3888888955116272)
[2024-12-17 02:30:55,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:55,650][root][INFO] - Training Epoch: 1/2, step 7019/7134 completed (loss: 3.978590965270996, acc: 0.37974682450294495)
[2024-12-17 02:30:55,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,011][root][INFO] - Training Epoch: 1/2, step 7020/7134 completed (loss: 3.412189483642578, acc: 0.3614457845687866)
[2024-12-17 02:30:56,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,419][root][INFO] - Training Epoch: 1/2, step 7021/7134 completed (loss: 3.595200777053833, acc: 0.3185185194015503)
[2024-12-17 02:30:56,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:56,776][root][INFO] - Training Epoch: 1/2, step 7022/7134 completed (loss: 4.813404560089111, acc: 0.2083333283662796)
[2024-12-17 02:30:56,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,138][root][INFO] - Training Epoch: 1/2, step 7023/7134 completed (loss: 4.20898962020874, acc: 0.3253012001514435)
[2024-12-17 02:30:57,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,514][root][INFO] - Training Epoch: 1/2, step 7024/7134 completed (loss: 4.376722812652588, acc: 0.36231884360313416)
[2024-12-17 02:30:57,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:57,907][root][INFO] - Training Epoch: 1/2, step 7025/7134 completed (loss: 4.1045379638671875, acc: 0.4285714328289032)
[2024-12-17 02:30:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,296][root][INFO] - Training Epoch: 1/2, step 7026/7134 completed (loss: 4.475257396697998, acc: 0.296875)
[2024-12-17 02:30:58,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:58,685][root][INFO] - Training Epoch: 1/2, step 7027/7134 completed (loss: 4.204254627227783, acc: 0.3661971688270569)
[2024-12-17 02:30:58,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,026][root][INFO] - Training Epoch: 1/2, step 7028/7134 completed (loss: 3.7286245822906494, acc: 0.35164836049079895)
[2024-12-17 02:30:59,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,389][root][INFO] - Training Epoch: 1/2, step 7029/7134 completed (loss: 3.4190752506256104, acc: 0.4157303273677826)
[2024-12-17 02:30:59,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:30:59,737][root][INFO] - Training Epoch: 1/2, step 7030/7134 completed (loss: 3.6279966831207275, acc: 0.3913043439388275)
[2024-12-17 02:30:59,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,111][root][INFO] - Training Epoch: 1/2, step 7031/7134 completed (loss: 4.246336460113525, acc: 0.34567901492118835)
[2024-12-17 02:31:00,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,475][root][INFO] - Training Epoch: 1/2, step 7032/7134 completed (loss: 4.407011032104492, acc: 0.30882352590560913)
[2024-12-17 02:31:00,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:00,822][root][INFO] - Training Epoch: 1/2, step 7033/7134 completed (loss: 4.5707316398620605, acc: 0.32098764181137085)
[2024-12-17 02:31:00,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,195][root][INFO] - Training Epoch: 1/2, step 7034/7134 completed (loss: 3.9009132385253906, acc: 0.390625)
[2024-12-17 02:31:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,576][root][INFO] - Training Epoch: 1/2, step 7035/7134 completed (loss: 4.0513105392456055, acc: 0.4126984179019928)
[2024-12-17 02:31:01,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:01,966][root][INFO] - Training Epoch: 1/2, step 7036/7134 completed (loss: 3.5840699672698975, acc: 0.3492063581943512)
[2024-12-17 02:31:02,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,311][root][INFO] - Training Epoch: 1/2, step 7037/7134 completed (loss: 4.2119059562683105, acc: 0.2537313401699066)
[2024-12-17 02:31:02,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:02,679][root][INFO] - Training Epoch: 1/2, step 7038/7134 completed (loss: 4.063980579376221, acc: 0.4177215099334717)
[2024-12-17 02:31:02,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,107][root][INFO] - Training Epoch: 1/2, step 7039/7134 completed (loss: 4.157114505767822, acc: 0.3777777850627899)
[2024-12-17 02:31:03,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,450][root][INFO] - Training Epoch: 1/2, step 7040/7134 completed (loss: 4.8266754150390625, acc: 0.3333333432674408)
[2024-12-17 02:31:03,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:03,805][root][INFO] - Training Epoch: 1/2, step 7041/7134 completed (loss: 4.125688076019287, acc: 0.38749998807907104)
[2024-12-17 02:31:03,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,186][root][INFO] - Training Epoch: 1/2, step 7042/7134 completed (loss: 3.9837448596954346, acc: 0.39436620473861694)
[2024-12-17 02:31:04,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,559][root][INFO] - Training Epoch: 1/2, step 7043/7134 completed (loss: 3.9982247352600098, acc: 0.3333333432674408)
[2024-12-17 02:31:04,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:04,922][root][INFO] - Training Epoch: 1/2, step 7044/7134 completed (loss: 4.530384540557861, acc: 0.30985915660858154)
[2024-12-17 02:31:05,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,304][root][INFO] - Training Epoch: 1/2, step 7045/7134 completed (loss: 3.5782482624053955, acc: 0.3379310369491577)
[2024-12-17 02:31:05,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:05,698][root][INFO] - Training Epoch: 1/2, step 7046/7134 completed (loss: 3.711682081222534, acc: 0.35329341888427734)
[2024-12-17 02:31:05,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,102][root][INFO] - Training Epoch: 1/2, step 7047/7134 completed (loss: 3.547283411026001, acc: 0.34272301197052)
[2024-12-17 02:31:06,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,481][root][INFO] - Training Epoch: 1/2, step 7048/7134 completed (loss: 3.127324104309082, acc: 0.3865979313850403)
[2024-12-17 02:31:06,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:06,870][root][INFO] - Training Epoch: 1/2, step 7049/7134 completed (loss: 3.386979579925537, acc: 0.3179190754890442)
[2024-12-17 02:31:07,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,272][root][INFO] - Training Epoch: 1/2, step 7050/7134 completed (loss: 3.261666774749756, acc: 0.38285714387893677)
[2024-12-17 02:31:07,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:07,645][root][INFO] - Training Epoch: 1/2, step 7051/7134 completed (loss: 3.6961629390716553, acc: 0.31521740555763245)
[2024-12-17 02:31:07,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,026][root][INFO] - Training Epoch: 1/2, step 7052/7134 completed (loss: 3.1305274963378906, acc: 0.41040462255477905)
[2024-12-17 02:31:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,413][root][INFO] - Training Epoch: 1/2, step 7053/7134 completed (loss: 3.1275548934936523, acc: 0.41530054807662964)
[2024-12-17 02:31:08,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:08,808][root][INFO] - Training Epoch: 1/2, step 7054/7134 completed (loss: 3.9989757537841797, acc: 0.29032257199287415)
[2024-12-17 02:31:08,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,180][root][INFO] - Training Epoch: 1/2, step 7055/7134 completed (loss: 4.361713886260986, acc: 0.3076923191547394)
[2024-12-17 02:31:09,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,573][root][INFO] - Training Epoch: 1/2, step 7056/7134 completed (loss: 3.9591917991638184, acc: 0.2944444417953491)
[2024-12-17 02:31:09,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:09,934][root][INFO] - Training Epoch: 1/2, step 7057/7134 completed (loss: 3.959468364715576, acc: 0.32596686482429504)
[2024-12-17 02:31:10,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,351][root][INFO] - Training Epoch: 1/2, step 7058/7134 completed (loss: 4.064277172088623, acc: 0.341085284948349)
[2024-12-17 02:31:10,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:10,767][root][INFO] - Training Epoch: 1/2, step 7059/7134 completed (loss: 4.197550296783447, acc: 0.2884615361690521)
[2024-12-17 02:31:10,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,167][root][INFO] - Training Epoch: 1/2, step 7060/7134 completed (loss: 4.078433513641357, acc: 0.2957746386528015)
[2024-12-17 02:31:11,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,539][root][INFO] - Training Epoch: 1/2, step 7061/7134 completed (loss: 3.9464545249938965, acc: 0.29032257199287415)
[2024-12-17 02:31:11,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:11,922][root][INFO] - Training Epoch: 1/2, step 7062/7134 completed (loss: 3.9903669357299805, acc: 0.26271185278892517)
[2024-12-17 02:31:12,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,303][root][INFO] - Training Epoch: 1/2, step 7063/7134 completed (loss: 4.006984710693359, acc: 0.31351351737976074)
[2024-12-17 02:31:12,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:12,686][root][INFO] - Training Epoch: 1/2, step 7064/7134 completed (loss: 3.2069642543792725, acc: 0.40361446142196655)
[2024-12-17 02:31:12,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,070][root][INFO] - Training Epoch: 1/2, step 7065/7134 completed (loss: 2.8295698165893555, acc: 0.36868685483932495)
[2024-12-17 02:31:13,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,449][root][INFO] - Training Epoch: 1/2, step 7066/7134 completed (loss: 3.1781795024871826, acc: 0.33507853746414185)
[2024-12-17 02:31:13,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:13,874][root][INFO] - Training Epoch: 1/2, step 7067/7134 completed (loss: 3.6202950477600098, acc: 0.3333333432674408)
[2024-12-17 02:31:14,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,262][root][INFO] - Training Epoch: 1/2, step 7068/7134 completed (loss: 3.124908924102783, acc: 0.4000000059604645)
[2024-12-17 02:31:14,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:14,666][root][INFO] - Training Epoch: 1/2, step 7069/7134 completed (loss: 3.067593812942505, acc: 0.36796537041664124)
[2024-12-17 02:31:14,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,068][root][INFO] - Training Epoch: 1/2, step 7070/7134 completed (loss: 3.3199543952941895, acc: 0.4161849617958069)
[2024-12-17 02:31:15,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,443][root][INFO] - Training Epoch: 1/2, step 7071/7134 completed (loss: 3.0222339630126953, acc: 0.3781512677669525)
[2024-12-17 02:31:15,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:15,829][root][INFO] - Training Epoch: 1/2, step 7072/7134 completed (loss: 3.165235757827759, acc: 0.3585858643054962)
[2024-12-17 02:31:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,203][root][INFO] - Training Epoch: 1/2, step 7073/7134 completed (loss: 3.7109575271606445, acc: 0.3216080367565155)
[2024-12-17 02:31:16,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,572][root][INFO] - Training Epoch: 1/2, step 7074/7134 completed (loss: 4.818105697631836, acc: 0.27642276883125305)
[2024-12-17 02:31:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:16,927][root][INFO] - Training Epoch: 1/2, step 7075/7134 completed (loss: 4.204930305480957, acc: 0.331210196018219)
[2024-12-17 02:31:17,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,259][root][INFO] - Training Epoch: 1/2, step 7076/7134 completed (loss: 4.111508846282959, acc: 0.30337077379226685)
[2024-12-17 02:31:17,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:17,625][root][INFO] - Training Epoch: 1/2, step 7077/7134 completed (loss: 4.218164443969727, acc: 0.2602739632129669)
[2024-12-17 02:31:17,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,020][root][INFO] - Training Epoch: 1/2, step 7078/7134 completed (loss: 4.57496452331543, acc: 0.24137930572032928)
[2024-12-17 02:31:18,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,419][root][INFO] - Training Epoch: 1/2, step 7079/7134 completed (loss: 3.4703831672668457, acc: 0.3618420958518982)
[2024-12-17 02:31:18,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:18,778][root][INFO] - Training Epoch: 1/2, step 7080/7134 completed (loss: 4.61891508102417, acc: 0.30612245202064514)
[2024-12-17 02:31:18,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,151][root][INFO] - Training Epoch: 1/2, step 7081/7134 completed (loss: 3.889692783355713, acc: 0.3179190754890442)
[2024-12-17 02:31:19,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,559][root][INFO] - Training Epoch: 1/2, step 7082/7134 completed (loss: 3.795506238937378, acc: 0.2763157784938812)
[2024-12-17 02:31:19,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:19,938][root][INFO] - Training Epoch: 1/2, step 7083/7134 completed (loss: 3.857762098312378, acc: 0.304964542388916)
[2024-12-17 02:31:20,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,327][root][INFO] - Training Epoch: 1/2, step 7084/7134 completed (loss: 3.785146474838257, acc: 0.3218390941619873)
[2024-12-17 02:31:20,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:20,696][root][INFO] - Training Epoch: 1/2, step 7085/7134 completed (loss: 4.232149600982666, acc: 0.3266666531562805)
[2024-12-17 02:31:20,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,089][root][INFO] - Training Epoch: 1/2, step 7086/7134 completed (loss: 3.885869264602661, acc: 0.2967741787433624)
[2024-12-17 02:31:21,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,465][root][INFO] - Training Epoch: 1/2, step 7087/7134 completed (loss: 4.368547439575195, acc: 0.24031007289886475)
[2024-12-17 02:31:21,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:21,835][root][INFO] - Training Epoch: 1/2, step 7088/7134 completed (loss: 4.586641311645508, acc: 0.22695034742355347)
[2024-12-17 02:31:21,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,241][root][INFO] - Training Epoch: 1/2, step 7089/7134 completed (loss: 3.9603755474090576, acc: 0.3032258152961731)
[2024-12-17 02:31:22,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,624][root][INFO] - Training Epoch: 1/2, step 7090/7134 completed (loss: 3.657496929168701, acc: 0.3392857015132904)
[2024-12-17 02:31:22,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:22,987][root][INFO] - Training Epoch: 1/2, step 7091/7134 completed (loss: 3.2824440002441406, acc: 0.3636363744735718)
[2024-12-17 02:31:23,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,379][root][INFO] - Training Epoch: 1/2, step 7092/7134 completed (loss: 3.8657524585723877, acc: 0.2857142984867096)
[2024-12-17 02:31:23,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:23,770][root][INFO] - Training Epoch: 1/2, step 7093/7134 completed (loss: 3.9941329956054688, acc: 0.23076923191547394)
[2024-12-17 02:31:23,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,141][root][INFO] - Training Epoch: 1/2, step 7094/7134 completed (loss: 3.8310210704803467, acc: 0.2604166567325592)
[2024-12-17 02:31:24,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,517][root][INFO] - Training Epoch: 1/2, step 7095/7134 completed (loss: 4.156160354614258, acc: 0.2881355881690979)
[2024-12-17 02:31:24,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:24,893][root][INFO] - Training Epoch: 1/2, step 7096/7134 completed (loss: 3.730708122253418, acc: 0.28169015049934387)
[2024-12-17 02:31:25,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,267][root][INFO] - Training Epoch: 1/2, step 7097/7134 completed (loss: 3.7500505447387695, acc: 0.3333333432674408)
[2024-12-17 02:31:25,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:25,658][root][INFO] - Training Epoch: 1/2, step 7098/7134 completed (loss: 3.840567111968994, acc: 0.30069929361343384)
[2024-12-17 02:31:25,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,024][root][INFO] - Training Epoch: 1/2, step 7099/7134 completed (loss: 4.467449188232422, acc: 0.26811593770980835)
[2024-12-17 02:31:26,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,392][root][INFO] - Training Epoch: 1/2, step 7100/7134 completed (loss: 4.049254417419434, acc: 0.2934131622314453)
[2024-12-17 02:31:26,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:26,743][root][INFO] - Training Epoch: 1/2, step 7101/7134 completed (loss: 3.9799511432647705, acc: 0.34532374143600464)
[2024-12-17 02:31:26,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,130][root][INFO] - Training Epoch: 1/2, step 7102/7134 completed (loss: 3.54506778717041, acc: 0.31355932354927063)
[2024-12-17 02:31:27,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,538][root][INFO] - Training Epoch: 1/2, step 7103/7134 completed (loss: 4.1479902267456055, acc: 0.359375)
[2024-12-17 02:31:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:27,916][root][INFO] - Training Epoch: 1/2, step 7104/7134 completed (loss: 3.8165030479431152, acc: 0.359649121761322)
[2024-12-17 02:31:28,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,290][root][INFO] - Training Epoch: 1/2, step 7105/7134 completed (loss: 3.7378921508789062, acc: 0.2777777910232544)
[2024-12-17 02:31:28,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:28,650][root][INFO] - Training Epoch: 1/2, step 7106/7134 completed (loss: 4.484973430633545, acc: 0.25925925374031067)
[2024-12-17 02:31:28,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,027][root][INFO] - Training Epoch: 1/2, step 7107/7134 completed (loss: 3.755361557006836, acc: 0.29192546010017395)
[2024-12-17 02:31:29,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,391][root][INFO] - Training Epoch: 1/2, step 7108/7134 completed (loss: 3.6319220066070557, acc: 0.29197078943252563)
[2024-12-17 02:31:29,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:29,757][root][INFO] - Training Epoch: 1/2, step 7109/7134 completed (loss: 4.285288333892822, acc: 0.32592591643333435)
[2024-12-17 02:31:29,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,147][root][INFO] - Training Epoch: 1/2, step 7110/7134 completed (loss: 3.852334499359131, acc: 0.33834585547447205)
[2024-12-17 02:31:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,507][root][INFO] - Training Epoch: 1/2, step 7111/7134 completed (loss: 4.178494930267334, acc: 0.32407405972480774)
[2024-12-17 02:31:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:30,878][root][INFO] - Training Epoch: 1/2, step 7112/7134 completed (loss: 3.609550714492798, acc: 0.37837839126586914)
[2024-12-17 02:31:31,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,263][root][INFO] - Training Epoch: 1/2, step 7113/7134 completed (loss: 3.9195940494537354, acc: 0.36305731534957886)
[2024-12-17 02:31:31,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,629][root][INFO] - Training Epoch: 1/2, step 7114/7134 completed (loss: 5.194921493530273, acc: 0.2293577939271927)
[2024-12-17 02:31:31,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:31,985][root][INFO] - Training Epoch: 1/2, step 7115/7134 completed (loss: 4.270717620849609, acc: 0.35114502906799316)
[2024-12-17 02:31:32,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,337][root][INFO] - Training Epoch: 1/2, step 7116/7134 completed (loss: 3.963153600692749, acc: 0.3602941036224365)
[2024-12-17 02:31:32,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:32,689][root][INFO] - Training Epoch: 1/2, step 7117/7134 completed (loss: 4.4927449226379395, acc: 0.25984251499176025)
[2024-12-17 02:31:32,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,069][root][INFO] - Training Epoch: 1/2, step 7118/7134 completed (loss: 4.309719562530518, acc: 0.26428571343421936)
[2024-12-17 02:31:33,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,439][root][INFO] - Training Epoch: 1/2, step 7119/7134 completed (loss: 4.1596360206604, acc: 0.317241370677948)
[2024-12-17 02:31:33,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:33,811][root][INFO] - Training Epoch: 1/2, step 7120/7134 completed (loss: 4.057559013366699, acc: 0.3106796145439148)
[2024-12-17 02:31:33,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,199][root][INFO] - Training Epoch: 1/2, step 7121/7134 completed (loss: 3.439754009246826, acc: 0.39230769872665405)
[2024-12-17 02:31:34,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,539][root][INFO] - Training Epoch: 1/2, step 7122/7134 completed (loss: 3.6737868785858154, acc: 0.37634408473968506)
[2024-12-17 02:31:34,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:34,909][root][INFO] - Training Epoch: 1/2, step 7123/7134 completed (loss: 3.7806236743927, acc: 0.35353535413742065)
[2024-12-17 02:31:35,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,308][root][INFO] - Training Epoch: 1/2, step 7124/7134 completed (loss: 4.065193176269531, acc: 0.32786884903907776)
[2024-12-17 02:31:35,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:35,672][root][INFO] - Training Epoch: 1/2, step 7125/7134 completed (loss: 3.7922942638397217, acc: 0.35114502906799316)
[2024-12-17 02:31:35,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,043][root][INFO] - Training Epoch: 1/2, step 7126/7134 completed (loss: 4.271911144256592, acc: 0.32846716046333313)
[2024-12-17 02:31:36,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,416][root][INFO] - Training Epoch: 1/2, step 7127/7134 completed (loss: 3.5321874618530273, acc: 0.395061731338501)
[2024-12-17 02:31:36,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:36,776][root][INFO] - Training Epoch: 1/2, step 7128/7134 completed (loss: 4.016394138336182, acc: 0.34246575832366943)
[2024-12-17 02:31:36,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,171][root][INFO] - Training Epoch: 1/2, step 7129/7134 completed (loss: 4.224068641662598, acc: 0.3178294599056244)
[2024-12-17 02:31:37,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,559][root][INFO] - Training Epoch: 1/2, step 7130/7134 completed (loss: 4.710803985595703, acc: 0.273333340883255)
[2024-12-17 02:31:37,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:37,920][root][INFO] - Training Epoch: 1/2, step 7131/7134 completed (loss: 4.130030632019043, acc: 0.3679245412349701)
[2024-12-17 02:31:38,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:39,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:40,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:41,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:42,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:43,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:44,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:45,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:46,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:47,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:48,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:49,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:50,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:51,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:52,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:53,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:54,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:55,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:56,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:57,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:58,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:31:59,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:00,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:01,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:02,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:03,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:04,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:05,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:06,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:07,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:08,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:09,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:10,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:11,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:12,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:13,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:14,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:15,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:16,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:17,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:18,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:19,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:23,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:24,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:25,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:26,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:28,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:29,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:30,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:31,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:32,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:34,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:35,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:36,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:37,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:38,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:39,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:40,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:41,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:42,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:43,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:44,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:45,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:46,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:47,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:48,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:49,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:50,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:52,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:53,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:54,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:56,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:57,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:58,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:32:59,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:00,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:01,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:02,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:04,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:05,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:06,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:07,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:08,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:09,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:10,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:11,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:12,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:13,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:14,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:16,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:17,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:18,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:19,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:20,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:22,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:23,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:24,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:25,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:26,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:27,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:28,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:29,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:30,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:31,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:32,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:33,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:34,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:35,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:36,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:37,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:38,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:39,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:40,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:41,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:42,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:43,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:44,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:45,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:46,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:47,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:48,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:49,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:50,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:51,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:52,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:53,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:54,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:55,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:56,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:57,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:58,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:33:59,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:01,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:02,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:03,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:04,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:06,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:07,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:08,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:09,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:10,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:11,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:12,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:13,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:14,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:15,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:16,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:17,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:18,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:19,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:20,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:21,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:22,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:23,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:24,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:25,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:26,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:28,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:29,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:30,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:31,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:32,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:34,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:35,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:36,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:37,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:38,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:39,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:40,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:41,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:42,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:43,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:44,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:45,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:47,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:49,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:50,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:51,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:52,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:53,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:54,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:55,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:56,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:57,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:58,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:34:59,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:00,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:01,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:03,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:04,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:05,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:06,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:08,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:09,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:10,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:11,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:12,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:13,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:14,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:15,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:16,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:17,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:18,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:19,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:21,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:22,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:24,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:26,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:27,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:28,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:29,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:30,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:31,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:32,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:33,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:34,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:35,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:36,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:37,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:38,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:39,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:40,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:41,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,167][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(42.6824, device='cuda:0') eval_epoch_loss=tensor(3.7538, device='cuda:0') eval_epoch_acc=tensor(0.3380, device='cuda:0')
[2024-12-17 02:35:42,170][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 02:35:42,170][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:35:42,432][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_7132_loss_3.75378680229187/model.pt
[2024-12-17 02:35:42,436][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 02:35:42,437][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 3.75378680229187
[2024-12-17 02:35:42,438][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.33799082040786743
[2024-12-17 02:35:42,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:42,834][root][INFO] - Training Epoch: 1/2, step 7132/7134 completed (loss: 3.7312893867492676, acc: 0.29411765933036804)
[2024-12-17 02:35:42,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:43,200][root][INFO] - Training Epoch: 1/2, step 7133/7134 completed (loss: 3.5727486610412598, acc: 0.37593984603881836)
[2024-12-17 02:35:43,634][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=52.3203, train_epoch_loss=3.9574, epoch time 3711.3108118623495s
[2024-12-17 02:35:43,634][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-17 02:35:43,635][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-12-17 02:35:43,635][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-17 02:35:43,635][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-12-17 02:35:43,635][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 7 GB
[2024-12-17 02:35:44,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,598][root][INFO] - Training Epoch: 2/2, step 0/7134 completed (loss: 3.9248411655426025, acc: 0.30128204822540283)
[2024-12-17 02:35:44,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:44,984][root][INFO] - Training Epoch: 2/2, step 1/7134 completed (loss: 3.7133331298828125, acc: 0.3248407542705536)
[2024-12-17 02:35:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,374][root][INFO] - Training Epoch: 2/2, step 2/7134 completed (loss: 2.997116804122925, acc: 0.3806818127632141)
[2024-12-17 02:35:45,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:45,740][root][INFO] - Training Epoch: 2/2, step 3/7134 completed (loss: 3.5865793228149414, acc: 0.35465115308761597)
[2024-12-17 02:35:45,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,121][root][INFO] - Training Epoch: 2/2, step 4/7134 completed (loss: 3.8570353984832764, acc: 0.30188679695129395)
[2024-12-17 02:35:46,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,480][root][INFO] - Training Epoch: 2/2, step 5/7134 completed (loss: 3.4046497344970703, acc: 0.34078213572502136)
[2024-12-17 02:35:46,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:46,892][root][INFO] - Training Epoch: 2/2, step 6/7134 completed (loss: 3.3361117839813232, acc: 0.3802816867828369)
[2024-12-17 02:35:47,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,298][root][INFO] - Training Epoch: 2/2, step 7/7134 completed (loss: 3.5899789333343506, acc: 0.32258063554763794)
[2024-12-17 02:35:47,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:47,700][root][INFO] - Training Epoch: 2/2, step 8/7134 completed (loss: 3.564258098602295, acc: 0.3414634168148041)
[2024-12-17 02:35:47,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,090][root][INFO] - Training Epoch: 2/2, step 9/7134 completed (loss: 3.1351914405822754, acc: 0.3708609342575073)
[2024-12-17 02:35:48,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,537][root][INFO] - Training Epoch: 2/2, step 10/7134 completed (loss: 3.7923743724823, acc: 0.28994083404541016)
[2024-12-17 02:35:48,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:48,933][root][INFO] - Training Epoch: 2/2, step 11/7134 completed (loss: 3.9892685413360596, acc: 0.2750000059604645)
[2024-12-17 02:35:49,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,307][root][INFO] - Training Epoch: 2/2, step 12/7134 completed (loss: 3.601254940032959, acc: 0.323699414730072)
[2024-12-17 02:35:49,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:49,702][root][INFO] - Training Epoch: 2/2, step 13/7134 completed (loss: 3.480119228363037, acc: 0.3932584226131439)
[2024-12-17 02:35:49,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,091][root][INFO] - Training Epoch: 2/2, step 14/7134 completed (loss: 3.2745394706726074, acc: 0.3243243098258972)
[2024-12-17 02:35:50,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,455][root][INFO] - Training Epoch: 2/2, step 15/7134 completed (loss: 3.2807962894439697, acc: 0.3913043439388275)
[2024-12-17 02:35:50,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:50,833][root][INFO] - Training Epoch: 2/2, step 16/7134 completed (loss: 3.146245002746582, acc: 0.3947368562221527)
[2024-12-17 02:35:50,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,210][root][INFO] - Training Epoch: 2/2, step 17/7134 completed (loss: 3.670597553253174, acc: 0.3297872245311737)
[2024-12-17 02:35:51,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,578][root][INFO] - Training Epoch: 2/2, step 18/7134 completed (loss: 3.154538869857788, acc: 0.39759036898612976)
[2024-12-17 02:35:51,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:51,926][root][INFO] - Training Epoch: 2/2, step 19/7134 completed (loss: 3.127730369567871, acc: 0.35260117053985596)
[2024-12-17 02:35:52,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,310][root][INFO] - Training Epoch: 2/2, step 20/7134 completed (loss: 3.000446081161499, acc: 0.3693181872367859)
[2024-12-17 02:35:52,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:52,697][root][INFO] - Training Epoch: 2/2, step 21/7134 completed (loss: 3.7682294845581055, acc: 0.34090909361839294)
[2024-12-17 02:35:52,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,092][root][INFO] - Training Epoch: 2/2, step 22/7134 completed (loss: 3.1142935752868652, acc: 0.38650307059288025)
[2024-12-17 02:35:53,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,456][root][INFO] - Training Epoch: 2/2, step 23/7134 completed (loss: 2.9204301834106445, acc: 0.40112993121147156)
[2024-12-17 02:35:53,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:53,855][root][INFO] - Training Epoch: 2/2, step 24/7134 completed (loss: 3.285616397857666, acc: 0.3499999940395355)
[2024-12-17 02:35:53,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,244][root][INFO] - Training Epoch: 2/2, step 25/7134 completed (loss: 2.8907735347747803, acc: 0.42603549361228943)
[2024-12-17 02:35:54,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:54,652][root][INFO] - Training Epoch: 2/2, step 26/7134 completed (loss: 3.2634270191192627, acc: 0.38036808371543884)
[2024-12-17 02:35:54,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,037][root][INFO] - Training Epoch: 2/2, step 27/7134 completed (loss: 3.358065128326416, acc: 0.3589743673801422)
[2024-12-17 02:35:55,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,442][root][INFO] - Training Epoch: 2/2, step 28/7134 completed (loss: 3.929736852645874, acc: 0.29441624879837036)
[2024-12-17 02:35:55,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:55,832][root][INFO] - Training Epoch: 2/2, step 29/7134 completed (loss: 3.5082685947418213, acc: 0.2840236723423004)
[2024-12-17 02:35:55,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,236][root][INFO] - Training Epoch: 2/2, step 30/7134 completed (loss: 4.023924350738525, acc: 0.2995169162750244)
[2024-12-17 02:35:56,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,608][root][INFO] - Training Epoch: 2/2, step 31/7134 completed (loss: 4.058197021484375, acc: 0.2837209403514862)
[2024-12-17 02:35:56,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:56,987][root][INFO] - Training Epoch: 2/2, step 32/7134 completed (loss: 4.0403642654418945, acc: 0.29347825050354004)
[2024-12-17 02:35:57,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,328][root][INFO] - Training Epoch: 2/2, step 33/7134 completed (loss: 3.6288671493530273, acc: 0.32307693362236023)
[2024-12-17 02:35:57,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:57,722][root][INFO] - Training Epoch: 2/2, step 34/7134 completed (loss: 3.7161037921905518, acc: 0.3047619163990021)
[2024-12-17 02:35:57,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,141][root][INFO] - Training Epoch: 2/2, step 35/7134 completed (loss: 3.964829444885254, acc: 0.2666666805744171)
[2024-12-17 02:35:58,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,532][root][INFO] - Training Epoch: 2/2, step 36/7134 completed (loss: 3.837229013442993, acc: 0.31336405873298645)
[2024-12-17 02:35:58,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:58,905][root][INFO] - Training Epoch: 2/2, step 37/7134 completed (loss: 4.282423496246338, acc: 0.2698412835597992)
[2024-12-17 02:35:58,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,276][root][INFO] - Training Epoch: 2/2, step 38/7134 completed (loss: 3.97012996673584, acc: 0.28930819034576416)
[2024-12-17 02:35:59,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:35:59,663][root][INFO] - Training Epoch: 2/2, step 39/7134 completed (loss: 3.64693021774292, acc: 0.2923976480960846)
[2024-12-17 02:35:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,049][root][INFO] - Training Epoch: 2/2, step 40/7134 completed (loss: 3.8936855792999268, acc: 0.3125)
[2024-12-17 02:36:00,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,394][root][INFO] - Training Epoch: 2/2, step 41/7134 completed (loss: 3.8722031116485596, acc: 0.28723403811454773)
[2024-12-17 02:36:00,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:00,775][root][INFO] - Training Epoch: 2/2, step 42/7134 completed (loss: 3.7133514881134033, acc: 0.2839506268501282)
[2024-12-17 02:36:00,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,155][root][INFO] - Training Epoch: 2/2, step 43/7134 completed (loss: 3.281782865524292, acc: 0.3743016719818115)
[2024-12-17 02:36:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,521][root][INFO] - Training Epoch: 2/2, step 44/7134 completed (loss: 3.703895330429077, acc: 0.3368983864784241)
[2024-12-17 02:36:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:01,900][root][INFO] - Training Epoch: 2/2, step 45/7134 completed (loss: 3.793492555618286, acc: 0.33018869161605835)
[2024-12-17 02:36:01,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,271][root][INFO] - Training Epoch: 2/2, step 46/7134 completed (loss: 4.493102550506592, acc: 0.26744186878204346)
[2024-12-17 02:36:02,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:02,678][root][INFO] - Training Epoch: 2/2, step 47/7134 completed (loss: 3.786050319671631, acc: 0.29608938097953796)
[2024-12-17 02:36:02,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,084][root][INFO] - Training Epoch: 2/2, step 48/7134 completed (loss: 3.6691174507141113, acc: 0.2801932394504547)
[2024-12-17 02:36:03,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,461][root][INFO] - Training Epoch: 2/2, step 49/7134 completed (loss: 3.9590718746185303, acc: 0.2823529541492462)
[2024-12-17 02:36:03,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:03,843][root][INFO] - Training Epoch: 2/2, step 50/7134 completed (loss: 3.6782429218292236, acc: 0.3252427279949188)
[2024-12-17 02:36:03,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,225][root][INFO] - Training Epoch: 2/2, step 51/7134 completed (loss: 3.8170461654663086, acc: 0.2551020383834839)
[2024-12-17 02:36:04,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,604][root][INFO] - Training Epoch: 2/2, step 52/7134 completed (loss: 3.5133509635925293, acc: 0.29801324009895325)
[2024-12-17 02:36:04,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:04,980][root][INFO] - Training Epoch: 2/2, step 53/7134 completed (loss: 3.595630645751953, acc: 0.3027026951313019)
[2024-12-17 02:36:05,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,370][root][INFO] - Training Epoch: 2/2, step 54/7134 completed (loss: 3.797642230987549, acc: 0.34285715222358704)
[2024-12-17 02:36:05,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:05,753][root][INFO] - Training Epoch: 2/2, step 55/7134 completed (loss: 3.8956258296966553, acc: 0.30978259444236755)
[2024-12-17 02:36:05,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,168][root][INFO] - Training Epoch: 2/2, step 56/7134 completed (loss: 3.6982638835906982, acc: 0.32307693362236023)
[2024-12-17 02:36:06,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,522][root][INFO] - Training Epoch: 2/2, step 57/7134 completed (loss: 4.450802803039551, acc: 0.26923078298568726)
[2024-12-17 02:36:06,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:06,889][root][INFO] - Training Epoch: 2/2, step 58/7134 completed (loss: 4.335415363311768, acc: 0.2849161922931671)
[2024-12-17 02:36:06,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,308][root][INFO] - Training Epoch: 2/2, step 59/7134 completed (loss: 4.283968448638916, acc: 0.27272728085517883)
[2024-12-17 02:36:07,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:07,713][root][INFO] - Training Epoch: 2/2, step 60/7134 completed (loss: 4.440489768981934, acc: 0.2721518874168396)
[2024-12-17 02:36:07,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,117][root][INFO] - Training Epoch: 2/2, step 61/7134 completed (loss: 4.35837984085083, acc: 0.29050278663635254)
[2024-12-17 02:36:08,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,508][root][INFO] - Training Epoch: 2/2, step 62/7134 completed (loss: 4.906496047973633, acc: 0.1910112351179123)
[2024-12-17 02:36:08,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:08,901][root][INFO] - Training Epoch: 2/2, step 63/7134 completed (loss: 4.520277976989746, acc: 0.24725274741649628)
[2024-12-17 02:36:09,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,295][root][INFO] - Training Epoch: 2/2, step 64/7134 completed (loss: 4.621428966522217, acc: 0.25294119119644165)
[2024-12-17 02:36:09,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:09,700][root][INFO] - Training Epoch: 2/2, step 65/7134 completed (loss: 5.0102219581604, acc: 0.21276596188545227)
[2024-12-17 02:36:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,104][root][INFO] - Training Epoch: 2/2, step 66/7134 completed (loss: 4.485801696777344, acc: 0.22727273404598236)
[2024-12-17 02:36:10,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,485][root][INFO] - Training Epoch: 2/2, step 67/7134 completed (loss: 4.736729145050049, acc: 0.270114928483963)
[2024-12-17 02:36:10,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:10,873][root][INFO] - Training Epoch: 2/2, step 68/7134 completed (loss: 4.339075565338135, acc: 0.3651685416698456)
[2024-12-17 02:36:10,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,248][root][INFO] - Training Epoch: 2/2, step 69/7134 completed (loss: 4.431081295013428, acc: 0.2539682686328888)
[2024-12-17 02:36:11,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:11,609][root][INFO] - Training Epoch: 2/2, step 70/7134 completed (loss: 4.5808563232421875, acc: 0.2421875)
[2024-12-17 02:36:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,006][root][INFO] - Training Epoch: 2/2, step 71/7134 completed (loss: 4.1433000564575195, acc: 0.31515151262283325)
[2024-12-17 02:36:12,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,397][root][INFO] - Training Epoch: 2/2, step 72/7134 completed (loss: 4.447708606719971, acc: 0.2544378638267517)
[2024-12-17 02:36:12,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:12,764][root][INFO] - Training Epoch: 2/2, step 73/7134 completed (loss: 4.253639221191406, acc: 0.20809248089790344)
[2024-12-17 02:36:12,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,122][root][INFO] - Training Epoch: 2/2, step 74/7134 completed (loss: 3.918896436691284, acc: 0.30813953280448914)
[2024-12-17 02:36:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,516][root][INFO] - Training Epoch: 2/2, step 75/7134 completed (loss: 4.246649265289307, acc: 0.3095238208770752)
[2024-12-17 02:36:13,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:13,873][root][INFO] - Training Epoch: 2/2, step 76/7134 completed (loss: 4.209160804748535, acc: 0.29891303181648254)
[2024-12-17 02:36:13,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,244][root][INFO] - Training Epoch: 2/2, step 77/7134 completed (loss: 4.1363043785095215, acc: 0.23756906390190125)
[2024-12-17 02:36:14,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:14,657][root][INFO] - Training Epoch: 2/2, step 78/7134 completed (loss: 4.338555335998535, acc: 0.2847682237625122)
[2024-12-17 02:36:14,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,033][root][INFO] - Training Epoch: 2/2, step 79/7134 completed (loss: 4.414585113525391, acc: 0.2933333218097687)
[2024-12-17 02:36:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,402][root][INFO] - Training Epoch: 2/2, step 80/7134 completed (loss: 3.9609837532043457, acc: 0.30337077379226685)
[2024-12-17 02:36:15,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:15,779][root][INFO] - Training Epoch: 2/2, step 81/7134 completed (loss: 4.006601333618164, acc: 0.30687829852104187)
[2024-12-17 02:36:15,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,195][root][INFO] - Training Epoch: 2/2, step 82/7134 completed (loss: 4.314391136169434, acc: 0.2590361535549164)
[2024-12-17 02:36:16,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,558][root][INFO] - Training Epoch: 2/2, step 83/7134 completed (loss: 4.153818130493164, acc: 0.3085106313228607)
[2024-12-17 02:36:16,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:16,954][root][INFO] - Training Epoch: 2/2, step 84/7134 completed (loss: 4.108922958374023, acc: 0.316546767950058)
[2024-12-17 02:36:17,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,374][root][INFO] - Training Epoch: 2/2, step 85/7134 completed (loss: 4.0730767250061035, acc: 0.2800000011920929)
[2024-12-17 02:36:17,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:17,738][root][INFO] - Training Epoch: 2/2, step 86/7134 completed (loss: 3.961883068084717, acc: 0.3125)
[2024-12-17 02:36:17,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,121][root][INFO] - Training Epoch: 2/2, step 87/7134 completed (loss: 4.157268047332764, acc: 0.33766233921051025)
[2024-12-17 02:36:18,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,493][root][INFO] - Training Epoch: 2/2, step 88/7134 completed (loss: 4.536236763000488, acc: 0.2469879537820816)
[2024-12-17 02:36:18,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:18,874][root][INFO] - Training Epoch: 2/2, step 89/7134 completed (loss: 4.225614070892334, acc: 0.2800000011920929)
[2024-12-17 02:36:18,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,235][root][INFO] - Training Epoch: 2/2, step 90/7134 completed (loss: 4.251650333404541, acc: 0.29411765933036804)
[2024-12-17 02:36:19,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:19,623][root][INFO] - Training Epoch: 2/2, step 91/7134 completed (loss: 4.303902626037598, acc: 0.3057851195335388)
[2024-12-17 02:36:19,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,022][root][INFO] - Training Epoch: 2/2, step 92/7134 completed (loss: 4.258796215057373, acc: 0.30519479513168335)
[2024-12-17 02:36:20,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,399][root][INFO] - Training Epoch: 2/2, step 93/7134 completed (loss: 3.8462908267974854, acc: 0.3199999928474426)
[2024-12-17 02:36:20,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:20,746][root][INFO] - Training Epoch: 2/2, step 94/7134 completed (loss: 4.015803813934326, acc: 0.40566039085388184)
[2024-12-17 02:36:20,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,129][root][INFO] - Training Epoch: 2/2, step 95/7134 completed (loss: 4.311264514923096, acc: 0.2804878056049347)
[2024-12-17 02:36:21,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,543][root][INFO] - Training Epoch: 2/2, step 96/7134 completed (loss: 4.068666934967041, acc: 0.3177570104598999)
[2024-12-17 02:36:21,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:21,937][root][INFO] - Training Epoch: 2/2, step 97/7134 completed (loss: 3.999185800552368, acc: 0.2142857164144516)
[2024-12-17 02:36:22,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,326][root][INFO] - Training Epoch: 2/2, step 98/7134 completed (loss: 4.284812927246094, acc: 0.27464789152145386)
[2024-12-17 02:36:22,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:22,700][root][INFO] - Training Epoch: 2/2, step 99/7134 completed (loss: 3.5986831188201904, acc: 0.39230769872665405)
[2024-12-17 02:36:22,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,094][root][INFO] - Training Epoch: 2/2, step 100/7134 completed (loss: 4.062633991241455, acc: 0.32044199109077454)
[2024-12-17 02:36:23,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,495][root][INFO] - Training Epoch: 2/2, step 101/7134 completed (loss: 4.683615684509277, acc: 0.234375)
[2024-12-17 02:36:23,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:23,870][root][INFO] - Training Epoch: 2/2, step 102/7134 completed (loss: 3.9926741123199463, acc: 0.2568306028842926)
[2024-12-17 02:36:23,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,256][root][INFO] - Training Epoch: 2/2, step 103/7134 completed (loss: 4.367020130157471, acc: 0.2602739632129669)
[2024-12-17 02:36:24,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:24,632][root][INFO] - Training Epoch: 2/2, step 104/7134 completed (loss: 3.8003666400909424, acc: 0.3333333432674408)
[2024-12-17 02:36:24,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,020][root][INFO] - Training Epoch: 2/2, step 105/7134 completed (loss: 3.7452809810638428, acc: 0.3208955228328705)
[2024-12-17 02:36:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,398][root][INFO] - Training Epoch: 2/2, step 106/7134 completed (loss: 3.984320878982544, acc: 0.3354037404060364)
[2024-12-17 02:36:25,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:25,783][root][INFO] - Training Epoch: 2/2, step 107/7134 completed (loss: 4.1263909339904785, acc: 0.35465115308761597)
[2024-12-17 02:36:25,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,156][root][INFO] - Training Epoch: 2/2, step 108/7134 completed (loss: 3.919801712036133, acc: 0.318918913602829)
[2024-12-17 02:36:26,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,508][root][INFO] - Training Epoch: 2/2, step 109/7134 completed (loss: 3.985200881958008, acc: 0.2857142984867096)
[2024-12-17 02:36:26,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:26,922][root][INFO] - Training Epoch: 2/2, step 110/7134 completed (loss: 3.772473096847534, acc: 0.3463687002658844)
[2024-12-17 02:36:27,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,303][root][INFO] - Training Epoch: 2/2, step 111/7134 completed (loss: 3.2864859104156494, acc: 0.4318181872367859)
[2024-12-17 02:36:27,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,647][root][INFO] - Training Epoch: 2/2, step 112/7134 completed (loss: 3.8678712844848633, acc: 0.3472222089767456)
[2024-12-17 02:36:27,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:27,994][root][INFO] - Training Epoch: 2/2, step 113/7134 completed (loss: 3.362410068511963, acc: 0.3854748606681824)
[2024-12-17 02:36:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,427][root][INFO] - Training Epoch: 2/2, step 114/7134 completed (loss: 3.958197593688965, acc: 0.3028571307659149)
[2024-12-17 02:36:28,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:28,764][root][INFO] - Training Epoch: 2/2, step 115/7134 completed (loss: 4.208807468414307, acc: 0.3366336524486542)
[2024-12-17 02:36:28,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,179][root][INFO] - Training Epoch: 2/2, step 116/7134 completed (loss: 4.535724639892578, acc: 0.26436781883239746)
[2024-12-17 02:36:29,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,533][root][INFO] - Training Epoch: 2/2, step 117/7134 completed (loss: 4.2853617668151855, acc: 0.3030303120613098)
[2024-12-17 02:36:29,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:29,967][root][INFO] - Training Epoch: 2/2, step 118/7134 completed (loss: 4.6443705558776855, acc: 0.27222222089767456)
[2024-12-17 02:36:30,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,362][root][INFO] - Training Epoch: 2/2, step 119/7134 completed (loss: 4.594828128814697, acc: 0.292553186416626)
[2024-12-17 02:36:30,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:30,748][root][INFO] - Training Epoch: 2/2, step 120/7134 completed (loss: 4.1015706062316895, acc: 0.3154761791229248)
[2024-12-17 02:36:30,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,090][root][INFO] - Training Epoch: 2/2, step 121/7134 completed (loss: 4.522874355316162, acc: 0.24581006169319153)
[2024-12-17 02:36:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,469][root][INFO] - Training Epoch: 2/2, step 122/7134 completed (loss: 3.867203712463379, acc: 0.36263737082481384)
[2024-12-17 02:36:31,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:31,845][root][INFO] - Training Epoch: 2/2, step 123/7134 completed (loss: 4.1907782554626465, acc: 0.2704402506351471)
[2024-12-17 02:36:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,223][root][INFO] - Training Epoch: 2/2, step 124/7134 completed (loss: 3.938710927963257, acc: 0.3263888955116272)
[2024-12-17 02:36:32,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:32,627][root][INFO] - Training Epoch: 2/2, step 125/7134 completed (loss: 4.06908655166626, acc: 0.3235294222831726)
[2024-12-17 02:36:32,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,007][root][INFO] - Training Epoch: 2/2, step 126/7134 completed (loss: 3.9849326610565186, acc: 0.3191489279270172)
[2024-12-17 02:36:33,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,396][root][INFO] - Training Epoch: 2/2, step 127/7134 completed (loss: 3.3335514068603516, acc: 0.3958333432674408)
[2024-12-17 02:36:33,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:33,781][root][INFO] - Training Epoch: 2/2, step 128/7134 completed (loss: 3.8650617599487305, acc: 0.35406699776649475)
[2024-12-17 02:36:33,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,160][root][INFO] - Training Epoch: 2/2, step 129/7134 completed (loss: 3.6587324142456055, acc: 0.31284916400909424)
[2024-12-17 02:36:34,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,545][root][INFO] - Training Epoch: 2/2, step 130/7134 completed (loss: 3.535738706588745, acc: 0.3764705955982208)
[2024-12-17 02:36:34,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:34,923][root][INFO] - Training Epoch: 2/2, step 131/7134 completed (loss: 3.662313938140869, acc: 0.35087719559669495)
[2024-12-17 02:36:35,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,288][root][INFO] - Training Epoch: 2/2, step 132/7134 completed (loss: 3.804980754852295, acc: 0.3270440399646759)
[2024-12-17 02:36:35,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:35,682][root][INFO] - Training Epoch: 2/2, step 133/7134 completed (loss: 3.8093504905700684, acc: 0.30882352590560913)
[2024-12-17 02:36:35,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,080][root][INFO] - Training Epoch: 2/2, step 134/7134 completed (loss: 3.67773175239563, acc: 0.36090224981307983)
[2024-12-17 02:36:36,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,465][root][INFO] - Training Epoch: 2/2, step 135/7134 completed (loss: 3.6261439323425293, acc: 0.32804232835769653)
[2024-12-17 02:36:36,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:36,850][root][INFO] - Training Epoch: 2/2, step 136/7134 completed (loss: 4.090089321136475, acc: 0.28804346919059753)
[2024-12-17 02:36:36,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,253][root][INFO] - Training Epoch: 2/2, step 137/7134 completed (loss: 3.457575559616089, acc: 0.41206029057502747)
[2024-12-17 02:36:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:37,645][root][INFO] - Training Epoch: 2/2, step 138/7134 completed (loss: 3.5225234031677246, acc: 0.3978494703769684)
[2024-12-17 02:36:37,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,040][root][INFO] - Training Epoch: 2/2, step 139/7134 completed (loss: 3.7754712104797363, acc: 0.3085106313228607)
[2024-12-17 02:36:38,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,423][root][INFO] - Training Epoch: 2/2, step 140/7134 completed (loss: 3.4316601753234863, acc: 0.39263802766799927)
[2024-12-17 02:36:38,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:38,789][root][INFO] - Training Epoch: 2/2, step 141/7134 completed (loss: 3.45156192779541, acc: 0.4099999964237213)
[2024-12-17 02:36:38,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,181][root][INFO] - Training Epoch: 2/2, step 142/7134 completed (loss: 3.9329609870910645, acc: 0.2768361568450928)
[2024-12-17 02:36:39,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,572][root][INFO] - Training Epoch: 2/2, step 143/7134 completed (loss: 3.464219331741333, acc: 0.3591160178184509)
[2024-12-17 02:36:39,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:39,965][root][INFO] - Training Epoch: 2/2, step 144/7134 completed (loss: 4.260889053344727, acc: 0.3243243098258972)
[2024-12-17 02:36:40,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,349][root][INFO] - Training Epoch: 2/2, step 145/7134 completed (loss: 4.906179904937744, acc: 0.27979275584220886)
[2024-12-17 02:36:40,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:40,746][root][INFO] - Training Epoch: 2/2, step 146/7134 completed (loss: 4.525512218475342, acc: 0.2711864411830902)
[2024-12-17 02:36:40,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,125][root][INFO] - Training Epoch: 2/2, step 147/7134 completed (loss: 4.3763580322265625, acc: 0.2896551787853241)
[2024-12-17 02:36:41,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,514][root][INFO] - Training Epoch: 2/2, step 148/7134 completed (loss: 4.615336894989014, acc: 0.3145161271095276)
[2024-12-17 02:36:41,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:41,891][root][INFO] - Training Epoch: 2/2, step 149/7134 completed (loss: 4.392704963684082, acc: 0.29949238896369934)
[2024-12-17 02:36:42,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,286][root][INFO] - Training Epoch: 2/2, step 150/7134 completed (loss: 4.568729400634766, acc: 0.2565445005893707)
[2024-12-17 02:36:42,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:42,653][root][INFO] - Training Epoch: 2/2, step 151/7134 completed (loss: 3.783447265625, acc: 0.32258063554763794)
[2024-12-17 02:36:42,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,033][root][INFO] - Training Epoch: 2/2, step 152/7134 completed (loss: 3.929586410522461, acc: 0.30622008442878723)
[2024-12-17 02:36:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,418][root][INFO] - Training Epoch: 2/2, step 153/7134 completed (loss: 4.393285274505615, acc: 0.2707182466983795)
[2024-12-17 02:36:43,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:43,806][root][INFO] - Training Epoch: 2/2, step 154/7134 completed (loss: 4.408594131469727, acc: 0.29411765933036804)
[2024-12-17 02:36:43,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,190][root][INFO] - Training Epoch: 2/2, step 155/7134 completed (loss: 4.135685920715332, acc: 0.30054643750190735)
[2024-12-17 02:36:44,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,598][root][INFO] - Training Epoch: 2/2, step 156/7134 completed (loss: 4.073049545288086, acc: 0.2857142984867096)
[2024-12-17 02:36:44,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:44,980][root][INFO] - Training Epoch: 2/2, step 157/7134 completed (loss: 4.568080425262451, acc: 0.21693122386932373)
[2024-12-17 02:36:45,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,360][root][INFO] - Training Epoch: 2/2, step 158/7134 completed (loss: 4.076199531555176, acc: 0.2923976480960846)
[2024-12-17 02:36:45,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:45,728][root][INFO] - Training Epoch: 2/2, step 159/7134 completed (loss: 3.5575127601623535, acc: 0.3641618490219116)
[2024-12-17 02:36:45,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,088][root][INFO] - Training Epoch: 2/2, step 160/7134 completed (loss: 4.114509582519531, acc: 0.2881355881690979)
[2024-12-17 02:36:46,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,449][root][INFO] - Training Epoch: 2/2, step 161/7134 completed (loss: 3.3624184131622314, acc: 0.45945945382118225)
[2024-12-17 02:36:46,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:46,845][root][INFO] - Training Epoch: 2/2, step 162/7134 completed (loss: 3.656895399093628, acc: 0.32098764181137085)
[2024-12-17 02:36:46,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,247][root][INFO] - Training Epoch: 2/2, step 163/7134 completed (loss: 3.9214320182800293, acc: 0.30215826630592346)
[2024-12-17 02:36:47,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:47,660][root][INFO] - Training Epoch: 2/2, step 164/7134 completed (loss: 3.772779941558838, acc: 0.38383838534355164)
[2024-12-17 02:36:47,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,008][root][INFO] - Training Epoch: 2/2, step 165/7134 completed (loss: 3.5100088119506836, acc: 0.3700000047683716)
[2024-12-17 02:36:48,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,393][root][INFO] - Training Epoch: 2/2, step 166/7134 completed (loss: 3.627368211746216, acc: 0.40789473056793213)
[2024-12-17 02:36:48,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:48,778][root][INFO] - Training Epoch: 2/2, step 167/7134 completed (loss: 4.915221214294434, acc: 0.21686747670173645)
[2024-12-17 02:36:48,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,193][root][INFO] - Training Epoch: 2/2, step 168/7134 completed (loss: 6.089339256286621, acc: 0.15454545617103577)
[2024-12-17 02:36:49,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,537][root][INFO] - Training Epoch: 2/2, step 169/7134 completed (loss: 5.9293904304504395, acc: 0.1875)
[2024-12-17 02:36:49,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:49,905][root][INFO] - Training Epoch: 2/2, step 170/7134 completed (loss: 4.827951908111572, acc: 0.2857142984867096)
[2024-12-17 02:36:50,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,292][root][INFO] - Training Epoch: 2/2, step 171/7134 completed (loss: 5.283463001251221, acc: 0.20792078971862793)
[2024-12-17 02:36:50,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:50,649][root][INFO] - Training Epoch: 2/2, step 172/7134 completed (loss: 4.608121871948242, acc: 0.27131783962249756)
[2024-12-17 02:36:50,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,010][root][INFO] - Training Epoch: 2/2, step 173/7134 completed (loss: 4.98822546005249, acc: 0.2240000069141388)
[2024-12-17 02:36:51,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,385][root][INFO] - Training Epoch: 2/2, step 174/7134 completed (loss: 4.693465232849121, acc: 0.32894736528396606)
[2024-12-17 02:36:51,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:51,752][root][INFO] - Training Epoch: 2/2, step 175/7134 completed (loss: 4.317596435546875, acc: 0.29139071702957153)
[2024-12-17 02:36:51,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,120][root][INFO] - Training Epoch: 2/2, step 176/7134 completed (loss: 4.2195048332214355, acc: 0.32786884903907776)
[2024-12-17 02:36:52,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,524][root][INFO] - Training Epoch: 2/2, step 177/7134 completed (loss: 4.637000560760498, acc: 0.2215568870306015)
[2024-12-17 02:36:52,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:52,876][root][INFO] - Training Epoch: 2/2, step 178/7134 completed (loss: 3.947906017303467, acc: 0.2857142984867096)
[2024-12-17 02:36:52,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,260][root][INFO] - Training Epoch: 2/2, step 179/7134 completed (loss: 3.706700325012207, acc: 0.39416059851646423)
[2024-12-17 02:36:53,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:53,659][root][INFO] - Training Epoch: 2/2, step 180/7134 completed (loss: 4.28395414352417, acc: 0.3221476376056671)
[2024-12-17 02:36:53,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,054][root][INFO] - Training Epoch: 2/2, step 181/7134 completed (loss: 3.9473893642425537, acc: 0.3379310369491577)
[2024-12-17 02:36:54,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,453][root][INFO] - Training Epoch: 2/2, step 182/7134 completed (loss: 3.7052907943725586, acc: 0.32919254899024963)
[2024-12-17 02:36:54,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:54,840][root][INFO] - Training Epoch: 2/2, step 183/7134 completed (loss: 3.7826859951019287, acc: 0.3767123222351074)
[2024-12-17 02:36:54,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,240][root][INFO] - Training Epoch: 2/2, step 184/7134 completed (loss: 4.029192924499512, acc: 0.3671875)
[2024-12-17 02:36:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,606][root][INFO] - Training Epoch: 2/2, step 185/7134 completed (loss: 3.669071912765503, acc: 0.36734694242477417)
[2024-12-17 02:36:55,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:55,977][root][INFO] - Training Epoch: 2/2, step 186/7134 completed (loss: 3.6071982383728027, acc: 0.3731343150138855)
[2024-12-17 02:36:56,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,359][root][INFO] - Training Epoch: 2/2, step 187/7134 completed (loss: 3.3588292598724365, acc: 0.4117647111415863)
[2024-12-17 02:36:56,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:56,739][root][INFO] - Training Epoch: 2/2, step 188/7134 completed (loss: 3.5568535327911377, acc: 0.37195122241973877)
[2024-12-17 02:36:56,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,054][root][INFO] - Training Epoch: 2/2, step 189/7134 completed (loss: 3.4022045135498047, acc: 0.4344262182712555)
[2024-12-17 02:36:57,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,452][root][INFO] - Training Epoch: 2/2, step 190/7134 completed (loss: 3.5307202339172363, acc: 0.2985074520111084)
[2024-12-17 02:36:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:57,826][root][INFO] - Training Epoch: 2/2, step 191/7134 completed (loss: 3.3968076705932617, acc: 0.4326923191547394)
[2024-12-17 02:36:57,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,224][root][INFO] - Training Epoch: 2/2, step 192/7134 completed (loss: 3.085548162460327, acc: 0.4127906858921051)
[2024-12-17 02:36:58,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,565][root][INFO] - Training Epoch: 2/2, step 193/7134 completed (loss: 3.617082357406616, acc: 0.38922154903411865)
[2024-12-17 02:36:58,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:58,939][root][INFO] - Training Epoch: 2/2, step 194/7134 completed (loss: 3.6709563732147217, acc: 0.3459119498729706)
[2024-12-17 02:36:59,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,304][root][INFO] - Training Epoch: 2/2, step 195/7134 completed (loss: 4.068135738372803, acc: 0.2734375)
[2024-12-17 02:36:59,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:36:59,680][root][INFO] - Training Epoch: 2/2, step 196/7134 completed (loss: 4.279406547546387, acc: 0.31843575835227966)
[2024-12-17 02:36:59,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,064][root][INFO] - Training Epoch: 2/2, step 197/7134 completed (loss: 3.114238739013672, acc: 0.4054054021835327)
[2024-12-17 02:37:00,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,440][root][INFO] - Training Epoch: 2/2, step 198/7134 completed (loss: 3.3442394733428955, acc: 0.36305731534957886)
[2024-12-17 02:37:00,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:00,813][root][INFO] - Training Epoch: 2/2, step 199/7134 completed (loss: 3.4179835319519043, acc: 0.4117647111415863)
[2024-12-17 02:37:00,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,201][root][INFO] - Training Epoch: 2/2, step 200/7134 completed (loss: 3.4636852741241455, acc: 0.3333333432674408)
[2024-12-17 02:37:01,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,553][root][INFO] - Training Epoch: 2/2, step 201/7134 completed (loss: 3.8597235679626465, acc: 0.3546099364757538)
[2024-12-17 02:37:01,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:01,918][root][INFO] - Training Epoch: 2/2, step 202/7134 completed (loss: 4.018872261047363, acc: 0.31612902879714966)
[2024-12-17 02:37:02,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,294][root][INFO] - Training Epoch: 2/2, step 203/7134 completed (loss: 4.4139323234558105, acc: 0.3195266127586365)
[2024-12-17 02:37:02,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:02,654][root][INFO] - Training Epoch: 2/2, step 204/7134 completed (loss: 4.3240742683410645, acc: 0.30817610025405884)
[2024-12-17 02:37:02,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,045][root][INFO] - Training Epoch: 2/2, step 205/7134 completed (loss: 4.193285942077637, acc: 0.30000001192092896)
[2024-12-17 02:37:03,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,427][root][INFO] - Training Epoch: 2/2, step 206/7134 completed (loss: 3.68497371673584, acc: 0.3194444477558136)
[2024-12-17 02:37:03,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:03,791][root][INFO] - Training Epoch: 2/2, step 207/7134 completed (loss: 3.611708402633667, acc: 0.3945578336715698)
[2024-12-17 02:37:03,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,167][root][INFO] - Training Epoch: 2/2, step 208/7134 completed (loss: 4.4513115882873535, acc: 0.3285714387893677)
[2024-12-17 02:37:04,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,543][root][INFO] - Training Epoch: 2/2, step 209/7134 completed (loss: 4.3168864250183105, acc: 0.2569832503795624)
[2024-12-17 02:37:04,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:04,922][root][INFO] - Training Epoch: 2/2, step 210/7134 completed (loss: 4.0376386642456055, acc: 0.32158589363098145)
[2024-12-17 02:37:05,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,256][root][INFO] - Training Epoch: 2/2, step 211/7134 completed (loss: 3.849648952484131, acc: 0.38513514399528503)
[2024-12-17 02:37:05,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:05,619][root][INFO] - Training Epoch: 2/2, step 212/7134 completed (loss: 4.806996822357178, acc: 0.2975206673145294)
[2024-12-17 02:37:05,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,011][root][INFO] - Training Epoch: 2/2, step 213/7134 completed (loss: 3.6756973266601562, acc: 0.4000000059604645)
[2024-12-17 02:37:06,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,367][root][INFO] - Training Epoch: 2/2, step 214/7134 completed (loss: 4.121573448181152, acc: 0.2871287167072296)
[2024-12-17 02:37:06,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:06,727][root][INFO] - Training Epoch: 2/2, step 215/7134 completed (loss: 3.354656934738159, acc: 0.4571428596973419)
[2024-12-17 02:37:06,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,117][root][INFO] - Training Epoch: 2/2, step 216/7134 completed (loss: 3.1761112213134766, acc: 0.3988763988018036)
[2024-12-17 02:37:07,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,497][root][INFO] - Training Epoch: 2/2, step 217/7134 completed (loss: 3.039581060409546, acc: 0.4114583432674408)
[2024-12-17 02:37:07,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:07,874][root][INFO] - Training Epoch: 2/2, step 218/7134 completed (loss: 3.1303091049194336, acc: 0.427807480096817)
[2024-12-17 02:37:07,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,261][root][INFO] - Training Epoch: 2/2, step 219/7134 completed (loss: 3.8528034687042236, acc: 0.34210526943206787)
[2024-12-17 02:37:08,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:08,634][root][INFO] - Training Epoch: 2/2, step 220/7134 completed (loss: 2.9953773021698, acc: 0.4434782564640045)
[2024-12-17 02:37:08,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,020][root][INFO] - Training Epoch: 2/2, step 221/7134 completed (loss: 2.961641788482666, acc: 0.4625000059604645)
[2024-12-17 02:37:09,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,474][root][INFO] - Training Epoch: 2/2, step 222/7134 completed (loss: 3.3460142612457275, acc: 0.4624277353286743)
[2024-12-17 02:37:09,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:09,859][root][INFO] - Training Epoch: 2/2, step 223/7134 completed (loss: 3.927706003189087, acc: 0.3675675690174103)
[2024-12-17 02:37:09,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,265][root][INFO] - Training Epoch: 2/2, step 224/7134 completed (loss: 4.184129238128662, acc: 0.3631284832954407)
[2024-12-17 02:37:10,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:10,659][root][INFO] - Training Epoch: 2/2, step 225/7134 completed (loss: 3.554969310760498, acc: 0.4201183319091797)
[2024-12-17 02:37:10,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,015][root][INFO] - Training Epoch: 2/2, step 226/7134 completed (loss: 3.6206228733062744, acc: 0.4114285707473755)
[2024-12-17 02:37:11,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,406][root][INFO] - Training Epoch: 2/2, step 227/7134 completed (loss: 3.671910285949707, acc: 0.44680851697921753)
[2024-12-17 02:37:11,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:11,798][root][INFO] - Training Epoch: 2/2, step 228/7134 completed (loss: 3.583381414413452, acc: 0.455089807510376)
[2024-12-17 02:37:11,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,201][root][INFO] - Training Epoch: 2/2, step 229/7134 completed (loss: 4.017120838165283, acc: 0.4000000059604645)
[2024-12-17 02:37:12,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,582][root][INFO] - Training Epoch: 2/2, step 230/7134 completed (loss: 3.633021831512451, acc: 0.4364641010761261)
[2024-12-17 02:37:12,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:12,976][root][INFO] - Training Epoch: 2/2, step 231/7134 completed (loss: 3.511594772338867, acc: 0.41228070855140686)
[2024-12-17 02:37:13,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,368][root][INFO] - Training Epoch: 2/2, step 232/7134 completed (loss: 3.2464680671691895, acc: 0.46853145956993103)
[2024-12-17 02:37:13,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:13,769][root][INFO] - Training Epoch: 2/2, step 233/7134 completed (loss: 3.4671716690063477, acc: 0.45255473256111145)
[2024-12-17 02:37:13,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,163][root][INFO] - Training Epoch: 2/2, step 234/7134 completed (loss: 2.9995276927948, acc: 0.5)
[2024-12-17 02:37:14,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,551][root][INFO] - Training Epoch: 2/2, step 235/7134 completed (loss: 3.287168502807617, acc: 0.4695121943950653)
[2024-12-17 02:37:14,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:14,925][root][INFO] - Training Epoch: 2/2, step 236/7134 completed (loss: 2.656080722808838, acc: 0.556291401386261)
[2024-12-17 02:37:15,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,305][root][INFO] - Training Epoch: 2/2, step 237/7134 completed (loss: 2.8350677490234375, acc: 0.48407644033432007)
[2024-12-17 02:37:15,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:15,687][root][INFO] - Training Epoch: 2/2, step 238/7134 completed (loss: 2.8611044883728027, acc: 0.6106870174407959)
[2024-12-17 02:37:15,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,064][root][INFO] - Training Epoch: 2/2, step 239/7134 completed (loss: 2.7141852378845215, acc: 0.5660377144813538)
[2024-12-17 02:37:16,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,453][root][INFO] - Training Epoch: 2/2, step 240/7134 completed (loss: 2.4808614253997803, acc: 0.6019417643547058)
[2024-12-17 02:37:16,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:16,821][root][INFO] - Training Epoch: 2/2, step 241/7134 completed (loss: 2.665281057357788, acc: 0.49253731966018677)
[2024-12-17 02:37:16,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,184][root][INFO] - Training Epoch: 2/2, step 242/7134 completed (loss: 2.7527916431427, acc: 0.5436241626739502)
[2024-12-17 02:37:17,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,543][root][INFO] - Training Epoch: 2/2, step 243/7134 completed (loss: 3.1568171977996826, acc: 0.5103448033332825)
[2024-12-17 02:37:17,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:17,889][root][INFO] - Training Epoch: 2/2, step 244/7134 completed (loss: 2.1468169689178467, acc: 0.6043165326118469)
[2024-12-17 02:37:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,260][root][INFO] - Training Epoch: 2/2, step 245/7134 completed (loss: 2.6026506423950195, acc: 0.5983606576919556)
[2024-12-17 02:37:18,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:18,648][root][INFO] - Training Epoch: 2/2, step 246/7134 completed (loss: 2.033362627029419, acc: 0.6376811861991882)
[2024-12-17 02:37:18,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,015][root][INFO] - Training Epoch: 2/2, step 247/7134 completed (loss: 1.9792245626449585, acc: 0.6349206566810608)
[2024-12-17 02:37:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,424][root][INFO] - Training Epoch: 2/2, step 248/7134 completed (loss: 1.819503903388977, acc: 0.6747967600822449)
[2024-12-17 02:37:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:19,811][root][INFO] - Training Epoch: 2/2, step 249/7134 completed (loss: 1.8363962173461914, acc: 0.6739130616188049)
[2024-12-17 02:37:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,156][root][INFO] - Training Epoch: 2/2, step 250/7134 completed (loss: 2.2522544860839844, acc: 0.556291401386261)
[2024-12-17 02:37:20,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,523][root][INFO] - Training Epoch: 2/2, step 251/7134 completed (loss: 1.5580873489379883, acc: 0.6834532618522644)
[2024-12-17 02:37:20,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:20,913][root][INFO] - Training Epoch: 2/2, step 252/7134 completed (loss: 1.2360271215438843, acc: 0.7266187071800232)
[2024-12-17 02:37:21,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,318][root][INFO] - Training Epoch: 2/2, step 253/7134 completed (loss: 1.420267105102539, acc: 0.7039999961853027)
[2024-12-17 02:37:21,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:21,705][root][INFO] - Training Epoch: 2/2, step 254/7134 completed (loss: 1.8154195547103882, acc: 0.640350878238678)
[2024-12-17 02:37:21,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,088][root][INFO] - Training Epoch: 2/2, step 255/7134 completed (loss: 1.4668567180633545, acc: 0.7051281929016113)
[2024-12-17 02:37:22,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,459][root][INFO] - Training Epoch: 2/2, step 256/7134 completed (loss: 2.0431623458862305, acc: 0.6081081032752991)
[2024-12-17 02:37:22,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:22,832][root][INFO] - Training Epoch: 2/2, step 257/7134 completed (loss: 1.4918183088302612, acc: 0.7317073345184326)
[2024-12-17 02:37:22,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,203][root][INFO] - Training Epoch: 2/2, step 258/7134 completed (loss: 1.7159910202026367, acc: 0.6451612710952759)
[2024-12-17 02:37:23,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,589][root][INFO] - Training Epoch: 2/2, step 259/7134 completed (loss: 1.5355193614959717, acc: 0.6818181872367859)
[2024-12-17 02:37:23,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:23,966][root][INFO] - Training Epoch: 2/2, step 260/7134 completed (loss: 1.1442525386810303, acc: 0.7593985199928284)
[2024-12-17 02:37:24,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,304][root][INFO] - Training Epoch: 2/2, step 261/7134 completed (loss: 1.3302627801895142, acc: 0.7222222089767456)
[2024-12-17 02:37:24,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:24,661][root][INFO] - Training Epoch: 2/2, step 262/7134 completed (loss: 1.0825783014297485, acc: 0.772357702255249)
[2024-12-17 02:37:24,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,029][root][INFO] - Training Epoch: 2/2, step 263/7134 completed (loss: 1.3511449098587036, acc: 0.7283950448036194)
[2024-12-17 02:37:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,438][root][INFO] - Training Epoch: 2/2, step 264/7134 completed (loss: 1.3165069818496704, acc: 0.699999988079071)
[2024-12-17 02:37:25,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:25,849][root][INFO] - Training Epoch: 2/2, step 265/7134 completed (loss: 1.3302119970321655, acc: 0.7078651785850525)
[2024-12-17 02:37:25,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,242][root][INFO] - Training Epoch: 2/2, step 266/7134 completed (loss: 1.2828726768493652, acc: 0.7239583134651184)
[2024-12-17 02:37:26,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,616][root][INFO] - Training Epoch: 2/2, step 267/7134 completed (loss: 1.510284423828125, acc: 0.7234042286872864)
[2024-12-17 02:37:26,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:26,982][root][INFO] - Training Epoch: 2/2, step 268/7134 completed (loss: 1.3575940132141113, acc: 0.7151514887809753)
[2024-12-17 02:37:27,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,371][root][INFO] - Training Epoch: 2/2, step 269/7134 completed (loss: 1.6174743175506592, acc: 0.648809552192688)
[2024-12-17 02:37:27,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:27,762][root][INFO] - Training Epoch: 2/2, step 270/7134 completed (loss: 1.2286150455474854, acc: 0.737500011920929)
[2024-12-17 02:37:27,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,162][root][INFO] - Training Epoch: 2/2, step 271/7134 completed (loss: 1.304247498512268, acc: 0.7055555582046509)
[2024-12-17 02:37:28,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,545][root][INFO] - Training Epoch: 2/2, step 272/7134 completed (loss: 1.3596731424331665, acc: 0.7206704020500183)
[2024-12-17 02:37:28,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:28,911][root][INFO] - Training Epoch: 2/2, step 273/7134 completed (loss: 0.9288073778152466, acc: 0.792553186416626)
[2024-12-17 02:37:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,267][root][INFO] - Training Epoch: 2/2, step 274/7134 completed (loss: 1.3362038135528564, acc: 0.719298243522644)
[2024-12-17 02:37:29,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:29,658][root][INFO] - Training Epoch: 2/2, step 275/7134 completed (loss: 1.0603957176208496, acc: 0.7563451528549194)
[2024-12-17 02:37:29,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,045][root][INFO] - Training Epoch: 2/2, step 276/7134 completed (loss: 1.1932454109191895, acc: 0.7731958627700806)
[2024-12-17 02:37:30,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,411][root][INFO] - Training Epoch: 2/2, step 277/7134 completed (loss: 1.090984582901001, acc: 0.7891891598701477)
[2024-12-17 02:37:30,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:30,779][root][INFO] - Training Epoch: 2/2, step 278/7134 completed (loss: 0.9989767074584961, acc: 0.765625)
[2024-12-17 02:37:30,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,172][root][INFO] - Training Epoch: 2/2, step 279/7134 completed (loss: 0.8913462162017822, acc: 0.7945945858955383)
[2024-12-17 02:37:31,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,532][root][INFO] - Training Epoch: 2/2, step 280/7134 completed (loss: 1.1580556631088257, acc: 0.7360000014305115)
[2024-12-17 02:37:31,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:31,909][root][INFO] - Training Epoch: 2/2, step 281/7134 completed (loss: 1.1586577892303467, acc: 0.7711864113807678)
[2024-12-17 02:37:32,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,297][root][INFO] - Training Epoch: 2/2, step 282/7134 completed (loss: 1.2922768592834473, acc: 0.7594936490058899)
[2024-12-17 02:37:32,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:32,709][root][INFO] - Training Epoch: 2/2, step 283/7134 completed (loss: 1.3219066858291626, acc: 0.7251908183097839)
[2024-12-17 02:37:32,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,097][root][INFO] - Training Epoch: 2/2, step 284/7134 completed (loss: 0.7867475748062134, acc: 0.8181818127632141)
[2024-12-17 02:37:33,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,493][root][INFO] - Training Epoch: 2/2, step 285/7134 completed (loss: 1.0771979093551636, acc: 0.7629629373550415)
[2024-12-17 02:37:33,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:33,854][root][INFO] - Training Epoch: 2/2, step 286/7134 completed (loss: 1.073055624961853, acc: 0.7777777910232544)
[2024-12-17 02:37:33,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,254][root][INFO] - Training Epoch: 2/2, step 287/7134 completed (loss: 0.9057426452636719, acc: 0.7852349281311035)
[2024-12-17 02:37:34,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:34,659][root][INFO] - Training Epoch: 2/2, step 288/7134 completed (loss: 0.7624836564064026, acc: 0.8267716765403748)
[2024-12-17 02:37:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,031][root][INFO] - Training Epoch: 2/2, step 289/7134 completed (loss: 0.8299260139465332, acc: 0.8372092843055725)
[2024-12-17 02:37:35,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,412][root][INFO] - Training Epoch: 2/2, step 290/7134 completed (loss: 1.0873197317123413, acc: 0.7597402334213257)
[2024-12-17 02:37:35,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:35,809][root][INFO] - Training Epoch: 2/2, step 291/7134 completed (loss: 1.206015706062317, acc: 0.7687074542045593)
[2024-12-17 02:37:35,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,214][root][INFO] - Training Epoch: 2/2, step 292/7134 completed (loss: 1.468017816543579, acc: 0.7160493731498718)
[2024-12-17 02:37:36,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,600][root][INFO] - Training Epoch: 2/2, step 293/7134 completed (loss: 1.160634994506836, acc: 0.7433628439903259)
[2024-12-17 02:37:36,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:36,978][root][INFO] - Training Epoch: 2/2, step 294/7134 completed (loss: 1.2283086776733398, acc: 0.6864407062530518)
[2024-12-17 02:37:37,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,380][root][INFO] - Training Epoch: 2/2, step 295/7134 completed (loss: 1.2666337490081787, acc: 0.75)
[2024-12-17 02:37:37,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:37,760][root][INFO] - Training Epoch: 2/2, step 296/7134 completed (loss: 0.8190739750862122, acc: 0.8257575631141663)
[2024-12-17 02:37:37,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,161][root][INFO] - Training Epoch: 2/2, step 297/7134 completed (loss: 0.9784379601478577, acc: 0.8016529083251953)
[2024-12-17 02:37:38,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,548][root][INFO] - Training Epoch: 2/2, step 298/7134 completed (loss: 0.9232003092765808, acc: 0.7615384459495544)
[2024-12-17 02:37:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:38,903][root][INFO] - Training Epoch: 2/2, step 299/7134 completed (loss: 0.605129599571228, acc: 0.8394160866737366)
[2024-12-17 02:37:39,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,274][root][INFO] - Training Epoch: 2/2, step 300/7134 completed (loss: 0.668350100517273, acc: 0.8333333134651184)
[2024-12-17 02:37:39,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:39,655][root][INFO] - Training Epoch: 2/2, step 301/7134 completed (loss: 0.693780779838562, acc: 0.8601398468017578)
[2024-12-17 02:37:39,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,024][root][INFO] - Training Epoch: 2/2, step 302/7134 completed (loss: 0.8962235450744629, acc: 0.801980197429657)
[2024-12-17 02:37:40,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,389][root][INFO] - Training Epoch: 2/2, step 303/7134 completed (loss: 0.8134168982505798, acc: 0.792792797088623)
[2024-12-17 02:37:40,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:40,772][root][INFO] - Training Epoch: 2/2, step 304/7134 completed (loss: 0.6492606401443481, acc: 0.8415841460227966)
[2024-12-17 02:37:40,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,157][root][INFO] - Training Epoch: 2/2, step 305/7134 completed (loss: 0.7112485766410828, acc: 0.8515625)
[2024-12-17 02:37:41,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,522][root][INFO] - Training Epoch: 2/2, step 306/7134 completed (loss: 0.5255600810050964, acc: 0.886956512928009)
[2024-12-17 02:37:41,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:41,924][root][INFO] - Training Epoch: 2/2, step 307/7134 completed (loss: 1.1147181987762451, acc: 0.7476635575294495)
[2024-12-17 02:37:42,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,307][root][INFO] - Training Epoch: 2/2, step 308/7134 completed (loss: 0.48341143131256104, acc: 0.834645688533783)
[2024-12-17 02:37:42,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:42,695][root][INFO] - Training Epoch: 2/2, step 309/7134 completed (loss: 0.9679821133613586, acc: 0.7964601516723633)
[2024-12-17 02:37:42,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,086][root][INFO] - Training Epoch: 2/2, step 310/7134 completed (loss: 0.98243647813797, acc: 0.8062015771865845)
[2024-12-17 02:37:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,455][root][INFO] - Training Epoch: 2/2, step 311/7134 completed (loss: 0.5736091136932373, acc: 0.8270676732063293)
[2024-12-17 02:37:43,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:43,828][root][INFO] - Training Epoch: 2/2, step 312/7134 completed (loss: 0.37849336862564087, acc: 0.8852459192276001)
[2024-12-17 02:37:43,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,205][root][INFO] - Training Epoch: 2/2, step 313/7134 completed (loss: 0.6267569661140442, acc: 0.8479999899864197)
[2024-12-17 02:37:44,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,543][root][INFO] - Training Epoch: 2/2, step 314/7134 completed (loss: 0.747696042060852, acc: 0.8296296000480652)
[2024-12-17 02:37:44,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:44,916][root][INFO] - Training Epoch: 2/2, step 315/7134 completed (loss: 1.1733736991882324, acc: 0.7749999761581421)
[2024-12-17 02:37:45,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,315][root][INFO] - Training Epoch: 2/2, step 316/7134 completed (loss: 0.7453411221504211, acc: 0.837837815284729)
[2024-12-17 02:37:45,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:45,711][root][INFO] - Training Epoch: 2/2, step 317/7134 completed (loss: 0.5588515400886536, acc: 0.8670886158943176)
[2024-12-17 02:37:45,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,080][root][INFO] - Training Epoch: 2/2, step 318/7134 completed (loss: 0.9162124395370483, acc: 0.7795698642730713)
[2024-12-17 02:37:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,467][root][INFO] - Training Epoch: 2/2, step 319/7134 completed (loss: 1.0256375074386597, acc: 0.7515528202056885)
[2024-12-17 02:37:46,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:46,830][root][INFO] - Training Epoch: 2/2, step 320/7134 completed (loss: 0.917979896068573, acc: 0.7976190447807312)
[2024-12-17 02:37:46,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,274][root][INFO] - Training Epoch: 2/2, step 321/7134 completed (loss: 0.8787544369697571, acc: 0.7873563170433044)
[2024-12-17 02:37:47,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:47,661][root][INFO] - Training Epoch: 2/2, step 322/7134 completed (loss: 0.7859302759170532, acc: 0.8235294222831726)
[2024-12-17 02:37:47,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,038][root][INFO] - Training Epoch: 2/2, step 323/7134 completed (loss: 1.0585298538208008, acc: 0.7755101919174194)
[2024-12-17 02:37:48,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,395][root][INFO] - Training Epoch: 2/2, step 324/7134 completed (loss: 1.016406536102295, acc: 0.8101851940155029)
[2024-12-17 02:37:48,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:48,770][root][INFO] - Training Epoch: 2/2, step 325/7134 completed (loss: 0.6529442071914673, acc: 0.8579545617103577)
[2024-12-17 02:37:48,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,151][root][INFO] - Training Epoch: 2/2, step 326/7134 completed (loss: 0.7142438292503357, acc: 0.8314606547355652)
[2024-12-17 02:37:49,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,538][root][INFO] - Training Epoch: 2/2, step 327/7134 completed (loss: 0.7912166714668274, acc: 0.8131313323974609)
[2024-12-17 02:37:49,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:49,917][root][INFO] - Training Epoch: 2/2, step 328/7134 completed (loss: 0.7063586711883545, acc: 0.8187500238418579)
[2024-12-17 02:37:50,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,303][root][INFO] - Training Epoch: 2/2, step 329/7134 completed (loss: 0.6665757298469543, acc: 0.8656716346740723)
[2024-12-17 02:37:50,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:50,675][root][INFO] - Training Epoch: 2/2, step 330/7134 completed (loss: 0.7983620166778564, acc: 0.8289473652839661)
[2024-12-17 02:37:50,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,043][root][INFO] - Training Epoch: 2/2, step 331/7134 completed (loss: 0.6502295732498169, acc: 0.859375)
[2024-12-17 02:37:51,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,421][root][INFO] - Training Epoch: 2/2, step 332/7134 completed (loss: 0.36869558691978455, acc: 0.9054726362228394)
[2024-12-17 02:37:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:51,780][root][INFO] - Training Epoch: 2/2, step 333/7134 completed (loss: 0.8172124028205872, acc: 0.8548387289047241)
[2024-12-17 02:37:51,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,149][root][INFO] - Training Epoch: 2/2, step 334/7134 completed (loss: 0.7706884145736694, acc: 0.807692289352417)
[2024-12-17 02:37:52,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,539][root][INFO] - Training Epoch: 2/2, step 335/7134 completed (loss: 0.709313154220581, acc: 0.837837815284729)
[2024-12-17 02:37:52,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:52,923][root][INFO] - Training Epoch: 2/2, step 336/7134 completed (loss: 0.7587110996246338, acc: 0.8445596098899841)
[2024-12-17 02:37:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,298][root][INFO] - Training Epoch: 2/2, step 337/7134 completed (loss: 0.7241559624671936, acc: 0.8260869383811951)
[2024-12-17 02:37:53,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:53,687][root][INFO] - Training Epoch: 2/2, step 338/7134 completed (loss: 0.8061988949775696, acc: 0.8062826991081238)
[2024-12-17 02:37:53,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,046][root][INFO] - Training Epoch: 2/2, step 339/7134 completed (loss: 0.70712810754776, acc: 0.8181818127632141)
[2024-12-17 02:37:54,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,410][root][INFO] - Training Epoch: 2/2, step 340/7134 completed (loss: 0.6218281984329224, acc: 0.8585858345031738)
[2024-12-17 02:37:54,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:54,779][root][INFO] - Training Epoch: 2/2, step 341/7134 completed (loss: 0.6168639659881592, acc: 0.8571428656578064)
[2024-12-17 02:37:54,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,144][root][INFO] - Training Epoch: 2/2, step 342/7134 completed (loss: 0.595167338848114, acc: 0.8553459048271179)
[2024-12-17 02:37:55,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,507][root][INFO] - Training Epoch: 2/2, step 343/7134 completed (loss: 0.6154601573944092, acc: 0.8384615182876587)
[2024-12-17 02:37:55,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:55,859][root][INFO] - Training Epoch: 2/2, step 344/7134 completed (loss: 0.610874354839325, acc: 0.8682170510292053)
[2024-12-17 02:37:56,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,275][root][INFO] - Training Epoch: 2/2, step 345/7134 completed (loss: 0.5699697732925415, acc: 0.8439716100692749)
[2024-12-17 02:37:56,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:56,663][root][INFO] - Training Epoch: 2/2, step 346/7134 completed (loss: 0.5025607943534851, acc: 0.9013158082962036)
[2024-12-17 02:37:56,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,055][root][INFO] - Training Epoch: 2/2, step 347/7134 completed (loss: 0.8032700419425964, acc: 0.8187500238418579)
[2024-12-17 02:37:57,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,429][root][INFO] - Training Epoch: 2/2, step 348/7134 completed (loss: 0.6155152320861816, acc: 0.8402366638183594)
[2024-12-17 02:37:57,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:57,802][root][INFO] - Training Epoch: 2/2, step 349/7134 completed (loss: 0.5907546281814575, acc: 0.8284023404121399)
[2024-12-17 02:37:57,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,245][root][INFO] - Training Epoch: 2/2, step 350/7134 completed (loss: 0.5656675100326538, acc: 0.8631578683853149)
[2024-12-17 02:37:58,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:58,635][root][INFO] - Training Epoch: 2/2, step 351/7134 completed (loss: 0.6265764832496643, acc: 0.8586956262588501)
[2024-12-17 02:37:58,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,002][root][INFO] - Training Epoch: 2/2, step 352/7134 completed (loss: 0.6653252840042114, acc: 0.8421052694320679)
[2024-12-17 02:37:59,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,417][root][INFO] - Training Epoch: 2/2, step 353/7134 completed (loss: 0.6690727472305298, acc: 0.8527607321739197)
[2024-12-17 02:37:59,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:37:59,807][root][INFO] - Training Epoch: 2/2, step 354/7134 completed (loss: 0.5110419988632202, acc: 0.8844221234321594)
[2024-12-17 02:37:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,178][root][INFO] - Training Epoch: 2/2, step 355/7134 completed (loss: 0.625485360622406, acc: 0.8757396340370178)
[2024-12-17 02:38:00,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:00,604][root][INFO] - Training Epoch: 2/2, step 356/7134 completed (loss: 0.474489688873291, acc: 0.8742514848709106)
[2024-12-17 02:38:00,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,026][root][INFO] - Training Epoch: 2/2, step 357/7134 completed (loss: 0.4431840181350708, acc: 0.8720930218696594)
[2024-12-17 02:38:01,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,410][root][INFO] - Training Epoch: 2/2, step 358/7134 completed (loss: 0.439049631357193, acc: 0.875)
[2024-12-17 02:38:01,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:01,794][root][INFO] - Training Epoch: 2/2, step 359/7134 completed (loss: 0.6304090619087219, acc: 0.8941176533699036)
[2024-12-17 02:38:01,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,178][root][INFO] - Training Epoch: 2/2, step 360/7134 completed (loss: 0.40743187069892883, acc: 0.9019607901573181)
[2024-12-17 02:38:02,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,589][root][INFO] - Training Epoch: 2/2, step 361/7134 completed (loss: 0.31843265891075134, acc: 0.9263803958892822)
[2024-12-17 02:38:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:02,974][root][INFO] - Training Epoch: 2/2, step 362/7134 completed (loss: 0.5727911591529846, acc: 0.8544303774833679)
[2024-12-17 02:38:03,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,381][root][INFO] - Training Epoch: 2/2, step 363/7134 completed (loss: 0.6419712901115417, acc: 0.8415300250053406)
[2024-12-17 02:38:03,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:03,781][root][INFO] - Training Epoch: 2/2, step 364/7134 completed (loss: 0.6037249565124512, acc: 0.8252426981925964)
[2024-12-17 02:38:03,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,177][root][INFO] - Training Epoch: 2/2, step 365/7134 completed (loss: 0.47314852476119995, acc: 0.8860759735107422)
[2024-12-17 02:38:04,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,570][root][INFO] - Training Epoch: 2/2, step 366/7134 completed (loss: 0.5079708099365234, acc: 0.8343949317932129)
[2024-12-17 02:38:04,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:04,952][root][INFO] - Training Epoch: 2/2, step 367/7134 completed (loss: 0.3482573926448822, acc: 0.9123711585998535)
[2024-12-17 02:38:05,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,327][root][INFO] - Training Epoch: 2/2, step 368/7134 completed (loss: 0.3130507469177246, acc: 0.9112426042556763)
[2024-12-17 02:38:05,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:05,733][root][INFO] - Training Epoch: 2/2, step 369/7134 completed (loss: 0.5203753709793091, acc: 0.8466257452964783)
[2024-12-17 02:38:05,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,097][root][INFO] - Training Epoch: 2/2, step 370/7134 completed (loss: 0.513352632522583, acc: 0.8734177350997925)
[2024-12-17 02:38:06,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,493][root][INFO] - Training Epoch: 2/2, step 371/7134 completed (loss: 0.5244652628898621, acc: 0.9192546606063843)
[2024-12-17 02:38:06,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:06,892][root][INFO] - Training Epoch: 2/2, step 372/7134 completed (loss: 0.5291726589202881, acc: 0.8867924809455872)
[2024-12-17 02:38:07,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,267][root][INFO] - Training Epoch: 2/2, step 373/7134 completed (loss: 0.4468299448490143, acc: 0.915032684803009)
[2024-12-17 02:38:07,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:07,660][root][INFO] - Training Epoch: 2/2, step 374/7134 completed (loss: 0.39569976925849915, acc: 0.8851351141929626)
[2024-12-17 02:38:07,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,046][root][INFO] - Training Epoch: 2/2, step 375/7134 completed (loss: 0.6086747050285339, acc: 0.8510638475418091)
[2024-12-17 02:38:08,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,433][root][INFO] - Training Epoch: 2/2, step 376/7134 completed (loss: 0.6947780251502991, acc: 0.8388888835906982)
[2024-12-17 02:38:08,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:08,856][root][INFO] - Training Epoch: 2/2, step 377/7134 completed (loss: 0.4755673408508301, acc: 0.8770949840545654)
[2024-12-17 02:38:08,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,224][root][INFO] - Training Epoch: 2/2, step 378/7134 completed (loss: 0.7055288553237915, acc: 0.8474576473236084)
[2024-12-17 02:38:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,587][root][INFO] - Training Epoch: 2/2, step 379/7134 completed (loss: 0.29209527373313904, acc: 0.9264705777168274)
[2024-12-17 02:38:09,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:09,991][root][INFO] - Training Epoch: 2/2, step 380/7134 completed (loss: 0.8120967149734497, acc: 0.7835051417350769)
[2024-12-17 02:38:10,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,388][root][INFO] - Training Epoch: 2/2, step 381/7134 completed (loss: 0.5658450126647949, acc: 0.8736842274665833)
[2024-12-17 02:38:10,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:10,751][root][INFO] - Training Epoch: 2/2, step 382/7134 completed (loss: 0.43258580565452576, acc: 0.8769230842590332)
[2024-12-17 02:38:10,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,143][root][INFO] - Training Epoch: 2/2, step 383/7134 completed (loss: 0.40056878328323364, acc: 0.9069767594337463)
[2024-12-17 02:38:11,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,531][root][INFO] - Training Epoch: 2/2, step 384/7134 completed (loss: 0.47594502568244934, acc: 0.889502763748169)
[2024-12-17 02:38:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:11,893][root][INFO] - Training Epoch: 2/2, step 385/7134 completed (loss: 0.32670092582702637, acc: 0.9281045794487)
[2024-12-17 02:38:11,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,248][root][INFO] - Training Epoch: 2/2, step 386/7134 completed (loss: 0.4133039712905884, acc: 0.9369369149208069)
[2024-12-17 02:38:12,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,622][root][INFO] - Training Epoch: 2/2, step 387/7134 completed (loss: 0.5362849831581116, acc: 0.8757396340370178)
[2024-12-17 02:38:12,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:12,981][root][INFO] - Training Epoch: 2/2, step 388/7134 completed (loss: 0.33545005321502686, acc: 0.9138755798339844)
[2024-12-17 02:38:13,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,359][root][INFO] - Training Epoch: 2/2, step 389/7134 completed (loss: 0.4827858507633209, acc: 0.8628571629524231)
[2024-12-17 02:38:13,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:13,701][root][INFO] - Training Epoch: 2/2, step 390/7134 completed (loss: 0.32576364278793335, acc: 0.8918918967247009)
[2024-12-17 02:38:13,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,092][root][INFO] - Training Epoch: 2/2, step 391/7134 completed (loss: 0.36432015895843506, acc: 0.9066666960716248)
[2024-12-17 02:38:14,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,497][root][INFO] - Training Epoch: 2/2, step 392/7134 completed (loss: 0.3890140950679779, acc: 0.9011628031730652)
[2024-12-17 02:38:14,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:14,863][root][INFO] - Training Epoch: 2/2, step 393/7134 completed (loss: 0.4073584973812103, acc: 0.8823529481887817)
[2024-12-17 02:38:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,229][root][INFO] - Training Epoch: 2/2, step 394/7134 completed (loss: 0.5594729781150818, acc: 0.885496199131012)
[2024-12-17 02:38:15,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:15,614][root][INFO] - Training Epoch: 2/2, step 395/7134 completed (loss: 0.565532386302948, acc: 0.8723404407501221)
[2024-12-17 02:38:15,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,000][root][INFO] - Training Epoch: 2/2, step 396/7134 completed (loss: 0.49811121821403503, acc: 0.9224137663841248)
[2024-12-17 02:38:16,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,376][root][INFO] - Training Epoch: 2/2, step 397/7134 completed (loss: 0.6083723306655884, acc: 0.907608687877655)
[2024-12-17 02:38:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:16,755][root][INFO] - Training Epoch: 2/2, step 398/7134 completed (loss: 0.4749913811683655, acc: 0.868686854839325)
[2024-12-17 02:38:16,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,123][root][INFO] - Training Epoch: 2/2, step 399/7134 completed (loss: 0.4760189354419708, acc: 0.8797468543052673)
[2024-12-17 02:38:17,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,508][root][INFO] - Training Epoch: 2/2, step 400/7134 completed (loss: 0.8484375476837158, acc: 0.7784810066223145)
[2024-12-17 02:38:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:17,878][root][INFO] - Training Epoch: 2/2, step 401/7134 completed (loss: 0.6019051671028137, acc: 0.8382353186607361)
[2024-12-17 02:38:18,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,238][root][INFO] - Training Epoch: 2/2, step 402/7134 completed (loss: 0.6262187361717224, acc: 0.8291457295417786)
[2024-12-17 02:38:18,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:18,644][root][INFO] - Training Epoch: 2/2, step 403/7134 completed (loss: 0.39949876070022583, acc: 0.8864628672599792)
[2024-12-17 02:38:18,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,005][root][INFO] - Training Epoch: 2/2, step 404/7134 completed (loss: 0.516328752040863, acc: 0.8602150678634644)
[2024-12-17 02:38:19,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,372][root][INFO] - Training Epoch: 2/2, step 405/7134 completed (loss: 0.7755388021469116, acc: 0.8081395626068115)
[2024-12-17 02:38:19,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:19,745][root][INFO] - Training Epoch: 2/2, step 406/7134 completed (loss: 0.8180693984031677, acc: 0.7891891598701477)
[2024-12-17 02:38:19,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,081][root][INFO] - Training Epoch: 2/2, step 407/7134 completed (loss: 0.8365306258201599, acc: 0.8152866363525391)
[2024-12-17 02:38:20,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,459][root][INFO] - Training Epoch: 2/2, step 408/7134 completed (loss: 0.5803778171539307, acc: 0.8491619825363159)
[2024-12-17 02:38:20,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:20,828][root][INFO] - Training Epoch: 2/2, step 409/7134 completed (loss: 0.5341230630874634, acc: 0.8842105269432068)
[2024-12-17 02:38:20,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,197][root][INFO] - Training Epoch: 2/2, step 410/7134 completed (loss: 0.635867178440094, acc: 0.8545454740524292)
[2024-12-17 02:38:21,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,588][root][INFO] - Training Epoch: 2/2, step 411/7134 completed (loss: 0.5267506241798401, acc: 0.869369387626648)
[2024-12-17 02:38:21,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:21,993][root][INFO] - Training Epoch: 2/2, step 412/7134 completed (loss: 0.3867032825946808, acc: 0.8744394779205322)
[2024-12-17 02:38:22,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,381][root][INFO] - Training Epoch: 2/2, step 413/7134 completed (loss: 0.7013510465621948, acc: 0.8691099286079407)
[2024-12-17 02:38:22,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:22,758][root][INFO] - Training Epoch: 2/2, step 414/7134 completed (loss: 0.5182526111602783, acc: 0.8901734352111816)
[2024-12-17 02:38:22,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,145][root][INFO] - Training Epoch: 2/2, step 415/7134 completed (loss: 0.3984021246433258, acc: 0.9190475940704346)
[2024-12-17 02:38:23,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,541][root][INFO] - Training Epoch: 2/2, step 416/7134 completed (loss: 0.4643964469432831, acc: 0.8846153616905212)
[2024-12-17 02:38:23,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:23,930][root][INFO] - Training Epoch: 2/2, step 417/7134 completed (loss: 0.557109534740448, acc: 0.8626373410224915)
[2024-12-17 02:38:24,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,335][root][INFO] - Training Epoch: 2/2, step 418/7134 completed (loss: 0.5112048983573914, acc: 0.8743961453437805)
[2024-12-17 02:38:24,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:24,720][root][INFO] - Training Epoch: 2/2, step 419/7134 completed (loss: 0.3532988727092743, acc: 0.9306930899620056)
[2024-12-17 02:38:24,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,131][root][INFO] - Training Epoch: 2/2, step 420/7134 completed (loss: 0.6289388537406921, acc: 0.8785714507102966)
[2024-12-17 02:38:25,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:25,607][root][INFO] - Training Epoch: 2/2, step 421/7134 completed (loss: 0.5885279178619385, acc: 0.8427672982215881)
[2024-12-17 02:38:25,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,004][root][INFO] - Training Epoch: 2/2, step 422/7134 completed (loss: 0.5123403668403625, acc: 0.88165682554245)
[2024-12-17 02:38:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,395][root][INFO] - Training Epoch: 2/2, step 423/7134 completed (loss: 0.20925380289554596, acc: 0.9606741666793823)
[2024-12-17 02:38:26,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:26,756][root][INFO] - Training Epoch: 2/2, step 424/7134 completed (loss: 0.411349356174469, acc: 0.9074074029922485)
[2024-12-17 02:38:26,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,135][root][INFO] - Training Epoch: 2/2, step 425/7134 completed (loss: 0.16520996391773224, acc: 0.9488636255264282)
[2024-12-17 02:38:27,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,497][root][INFO] - Training Epoch: 2/2, step 426/7134 completed (loss: 0.2112801969051361, acc: 0.9470587968826294)
[2024-12-17 02:38:27,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:27,873][root][INFO] - Training Epoch: 2/2, step 427/7134 completed (loss: 0.36287128925323486, acc: 0.8993710875511169)
[2024-12-17 02:38:28,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,270][root][INFO] - Training Epoch: 2/2, step 428/7134 completed (loss: 0.37625184655189514, acc: 0.910179615020752)
[2024-12-17 02:38:28,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:28,641][root][INFO] - Training Epoch: 2/2, step 429/7134 completed (loss: 0.7529129981994629, acc: 0.8421052694320679)
[2024-12-17 02:38:28,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,031][root][INFO] - Training Epoch: 2/2, step 430/7134 completed (loss: 0.4088870882987976, acc: 0.8823529481887817)
[2024-12-17 02:38:29,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,401][root][INFO] - Training Epoch: 2/2, step 431/7134 completed (loss: 0.2814170718193054, acc: 0.9408283829689026)
[2024-12-17 02:38:29,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:29,764][root][INFO] - Training Epoch: 2/2, step 432/7134 completed (loss: 0.40504246950149536, acc: 0.9090909361839294)
[2024-12-17 02:38:29,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,165][root][INFO] - Training Epoch: 2/2, step 433/7134 completed (loss: 0.3061582148075104, acc: 0.9414893388748169)
[2024-12-17 02:38:30,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,518][root][INFO] - Training Epoch: 2/2, step 434/7134 completed (loss: 0.41694673895835876, acc: 0.9074074029922485)
[2024-12-17 02:38:30,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:30,908][root][INFO] - Training Epoch: 2/2, step 435/7134 completed (loss: 0.34534481167793274, acc: 0.9388889074325562)
[2024-12-17 02:38:31,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,281][root][INFO] - Training Epoch: 2/2, step 436/7134 completed (loss: 0.315635085105896, acc: 0.9236111044883728)
[2024-12-17 02:38:31,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:31,674][root][INFO] - Training Epoch: 2/2, step 437/7134 completed (loss: 0.5336188673973083, acc: 0.8873239159584045)
[2024-12-17 02:38:31,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,035][root][INFO] - Training Epoch: 2/2, step 438/7134 completed (loss: 0.3765491247177124, acc: 0.8897637724876404)
[2024-12-17 02:38:32,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,434][root][INFO] - Training Epoch: 2/2, step 439/7134 completed (loss: 0.5539817214012146, acc: 0.8505747318267822)
[2024-12-17 02:38:32,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:32,803][root][INFO] - Training Epoch: 2/2, step 440/7134 completed (loss: 0.3885036110877991, acc: 0.8846153616905212)
[2024-12-17 02:38:32,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,180][root][INFO] - Training Epoch: 2/2, step 441/7134 completed (loss: 0.3031757175922394, acc: 0.9109588861465454)
[2024-12-17 02:38:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,553][root][INFO] - Training Epoch: 2/2, step 442/7134 completed (loss: 0.3633383810520172, acc: 0.9069767594337463)
[2024-12-17 02:38:33,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:33,945][root][INFO] - Training Epoch: 2/2, step 443/7134 completed (loss: 0.266217976808548, acc: 0.9591836929321289)
[2024-12-17 02:38:34,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,321][root][INFO] - Training Epoch: 2/2, step 444/7134 completed (loss: 0.22562529146671295, acc: 0.961240291595459)
[2024-12-17 02:38:34,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:34,715][root][INFO] - Training Epoch: 2/2, step 445/7134 completed (loss: 0.48883605003356934, acc: 0.9056603908538818)
[2024-12-17 02:38:34,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,171][root][INFO] - Training Epoch: 2/2, step 446/7134 completed (loss: 0.25008004903793335, acc: 0.9526627063751221)
[2024-12-17 02:38:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,563][root][INFO] - Training Epoch: 2/2, step 447/7134 completed (loss: 0.2853504717350006, acc: 0.9202454090118408)
[2024-12-17 02:38:35,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:35,960][root][INFO] - Training Epoch: 2/2, step 448/7134 completed (loss: 0.6569430828094482, acc: 0.8465608358383179)
[2024-12-17 02:38:36,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,346][root][INFO] - Training Epoch: 2/2, step 449/7134 completed (loss: 0.7127364873886108, acc: 0.835106372833252)
[2024-12-17 02:38:36,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:36,794][root][INFO] - Training Epoch: 2/2, step 450/7134 completed (loss: 0.6217477321624756, acc: 0.8113207817077637)
[2024-12-17 02:38:36,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,204][root][INFO] - Training Epoch: 2/2, step 451/7134 completed (loss: 0.7946497201919556, acc: 0.8347457647323608)
[2024-12-17 02:38:37,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:37,647][root][INFO] - Training Epoch: 2/2, step 452/7134 completed (loss: 0.8536417484283447, acc: 0.8033707737922668)
[2024-12-17 02:38:37,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,053][root][INFO] - Training Epoch: 2/2, step 453/7134 completed (loss: 0.40830931067466736, acc: 0.8865247964859009)
[2024-12-17 02:38:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,441][root][INFO] - Training Epoch: 2/2, step 454/7134 completed (loss: 0.6710959672927856, acc: 0.8649789094924927)
[2024-12-17 02:38:38,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:38,837][root][INFO] - Training Epoch: 2/2, step 455/7134 completed (loss: 0.5488451719284058, acc: 0.8615384697914124)
[2024-12-17 02:38:38,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,228][root][INFO] - Training Epoch: 2/2, step 456/7134 completed (loss: 0.5467056035995483, acc: 0.8588957190513611)
[2024-12-17 02:38:39,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,620][root][INFO] - Training Epoch: 2/2, step 457/7134 completed (loss: 0.5186213254928589, acc: 0.8551723957061768)
[2024-12-17 02:38:39,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:39,975][root][INFO] - Training Epoch: 2/2, step 458/7134 completed (loss: 0.6023285388946533, acc: 0.8870967626571655)
[2024-12-17 02:38:40,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,319][root][INFO] - Training Epoch: 2/2, step 459/7134 completed (loss: 0.8651241660118103, acc: 0.8072289228439331)
[2024-12-17 02:38:40,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:40,689][root][INFO] - Training Epoch: 2/2, step 460/7134 completed (loss: 0.712141215801239, acc: 0.8533333539962769)
[2024-12-17 02:38:40,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,052][root][INFO] - Training Epoch: 2/2, step 461/7134 completed (loss: 0.4647282361984253, acc: 0.8823529481887817)
[2024-12-17 02:38:41,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,455][root][INFO] - Training Epoch: 2/2, step 462/7134 completed (loss: 0.6561599969863892, acc: 0.8472222089767456)
[2024-12-17 02:38:41,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:41,848][root][INFO] - Training Epoch: 2/2, step 463/7134 completed (loss: 0.7067990303039551, acc: 0.8457711338996887)
[2024-12-17 02:38:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,211][root][INFO] - Training Epoch: 2/2, step 464/7134 completed (loss: 0.5249984264373779, acc: 0.8579545617103577)
[2024-12-17 02:38:42,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,567][root][INFO] - Training Epoch: 2/2, step 465/7134 completed (loss: 0.38694459199905396, acc: 0.9273743033409119)
[2024-12-17 02:38:42,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:42,946][root][INFO] - Training Epoch: 2/2, step 466/7134 completed (loss: 0.8342588543891907, acc: 0.8011695742607117)
[2024-12-17 02:38:43,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,338][root][INFO] - Training Epoch: 2/2, step 467/7134 completed (loss: 0.8148983716964722, acc: 0.820105791091919)
[2024-12-17 02:38:43,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:43,746][root][INFO] - Training Epoch: 2/2, step 468/7134 completed (loss: 0.823525607585907, acc: 0.8133333325386047)
[2024-12-17 02:38:43,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,120][root][INFO] - Training Epoch: 2/2, step 469/7134 completed (loss: 0.599383533000946, acc: 0.8333333134651184)
[2024-12-17 02:38:44,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,521][root][INFO] - Training Epoch: 2/2, step 470/7134 completed (loss: 0.6617068648338318, acc: 0.8445945978164673)
[2024-12-17 02:38:44,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:44,962][root][INFO] - Training Epoch: 2/2, step 471/7134 completed (loss: 0.6988061666488647, acc: 0.8351648449897766)
[2024-12-17 02:38:45,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,349][root][INFO] - Training Epoch: 2/2, step 472/7134 completed (loss: 0.6349475383758545, acc: 0.8266666531562805)
[2024-12-17 02:38:45,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:45,738][root][INFO] - Training Epoch: 2/2, step 473/7134 completed (loss: 0.531037449836731, acc: 0.8636363744735718)
[2024-12-17 02:38:45,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,122][root][INFO] - Training Epoch: 2/2, step 474/7134 completed (loss: 0.7539765238761902, acc: 0.8121212124824524)
[2024-12-17 02:38:46,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,494][root][INFO] - Training Epoch: 2/2, step 475/7134 completed (loss: 0.9210237860679626, acc: 0.7832167744636536)
[2024-12-17 02:38:46,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:46,871][root][INFO] - Training Epoch: 2/2, step 476/7134 completed (loss: 0.8934470415115356, acc: 0.800000011920929)
[2024-12-17 02:38:46,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,258][root][INFO] - Training Epoch: 2/2, step 477/7134 completed (loss: 0.6110866665840149, acc: 0.855614960193634)
[2024-12-17 02:38:47,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:47,654][root][INFO] - Training Epoch: 2/2, step 478/7134 completed (loss: 0.72245854139328, acc: 0.834782600402832)
[2024-12-17 02:38:47,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,041][root][INFO] - Training Epoch: 2/2, step 479/7134 completed (loss: 0.6205341219902039, acc: 0.860927164554596)
[2024-12-17 02:38:48,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,433][root][INFO] - Training Epoch: 2/2, step 480/7134 completed (loss: 0.5943390727043152, acc: 0.84375)
[2024-12-17 02:38:48,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:48,856][root][INFO] - Training Epoch: 2/2, step 481/7134 completed (loss: 0.6594702005386353, acc: 0.8322981595993042)
[2024-12-17 02:38:48,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,238][root][INFO] - Training Epoch: 2/2, step 482/7134 completed (loss: 0.4291229248046875, acc: 0.8867924809455872)
[2024-12-17 02:38:49,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:49,604][root][INFO] - Training Epoch: 2/2, step 483/7134 completed (loss: 0.37693923711776733, acc: 0.8956043720245361)
[2024-12-17 02:38:49,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,015][root][INFO] - Training Epoch: 2/2, step 484/7134 completed (loss: 0.7369707822799683, acc: 0.8112244606018066)
[2024-12-17 02:38:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,402][root][INFO] - Training Epoch: 2/2, step 485/7134 completed (loss: 0.6902564764022827, acc: 0.8385093212127686)
[2024-12-17 02:38:50,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:50,806][root][INFO] - Training Epoch: 2/2, step 486/7134 completed (loss: 0.8673047423362732, acc: 0.8064516186714172)
[2024-12-17 02:38:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,182][root][INFO] - Training Epoch: 2/2, step 487/7134 completed (loss: 0.3815632164478302, acc: 0.9259259104728699)
[2024-12-17 02:38:51,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,569][root][INFO] - Training Epoch: 2/2, step 488/7134 completed (loss: 0.6874390244483948, acc: 0.8358209133148193)
[2024-12-17 02:38:51,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:51,928][root][INFO] - Training Epoch: 2/2, step 489/7134 completed (loss: 0.6065646409988403, acc: 0.8992805480957031)
[2024-12-17 02:38:52,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,315][root][INFO] - Training Epoch: 2/2, step 490/7134 completed (loss: 0.4634687304496765, acc: 0.8670886158943176)
[2024-12-17 02:38:52,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:52,685][root][INFO] - Training Epoch: 2/2, step 491/7134 completed (loss: 0.3606069087982178, acc: 0.9305555820465088)
[2024-12-17 02:38:52,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,102][root][INFO] - Training Epoch: 2/2, step 492/7134 completed (loss: 0.3538987636566162, acc: 0.9225806593894958)
[2024-12-17 02:38:53,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,495][root][INFO] - Training Epoch: 2/2, step 493/7134 completed (loss: 0.3916883170604706, acc: 0.9289940595626831)
[2024-12-17 02:38:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:53,856][root][INFO] - Training Epoch: 2/2, step 494/7134 completed (loss: 0.48663854598999023, acc: 0.8866666555404663)
[2024-12-17 02:38:53,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,239][root][INFO] - Training Epoch: 2/2, step 495/7134 completed (loss: 0.37120485305786133, acc: 0.9256198406219482)
[2024-12-17 02:38:54,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:54,638][root][INFO] - Training Epoch: 2/2, step 496/7134 completed (loss: 0.8356292843818665, acc: 0.8526315689086914)
[2024-12-17 02:38:54,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,043][root][INFO] - Training Epoch: 2/2, step 497/7134 completed (loss: 0.3600783944129944, acc: 0.9461538195610046)
[2024-12-17 02:38:55,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,573][root][INFO] - Training Epoch: 2/2, step 498/7134 completed (loss: 0.3393782079219818, acc: 0.9194630980491638)
[2024-12-17 02:38:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:55,963][root][INFO] - Training Epoch: 2/2, step 499/7134 completed (loss: 0.27866414189338684, acc: 0.9235293865203857)
[2024-12-17 02:38:56,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,334][root][INFO] - Training Epoch: 2/2, step 500/7134 completed (loss: 0.3731878101825714, acc: 0.9069767594337463)
[2024-12-17 02:38:56,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:56,716][root][INFO] - Training Epoch: 2/2, step 501/7134 completed (loss: 0.25228309631347656, acc: 0.9479768872261047)
[2024-12-17 02:38:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,090][root][INFO] - Training Epoch: 2/2, step 502/7134 completed (loss: 0.23185785114765167, acc: 0.9545454382896423)
[2024-12-17 02:38:57,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,479][root][INFO] - Training Epoch: 2/2, step 503/7134 completed (loss: 0.3365047872066498, acc: 0.9375)
[2024-12-17 02:38:57,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:57,851][root][INFO] - Training Epoch: 2/2, step 504/7134 completed (loss: 0.30104413628578186, acc: 0.9316770434379578)
[2024-12-17 02:38:57,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,229][root][INFO] - Training Epoch: 2/2, step 505/7134 completed (loss: 0.32835066318511963, acc: 0.9166666865348816)
[2024-12-17 02:38:58,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:58,632][root][INFO] - Training Epoch: 2/2, step 506/7134 completed (loss: 0.6253447532653809, acc: 0.8579545617103577)
[2024-12-17 02:38:58,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,012][root][INFO] - Training Epoch: 2/2, step 507/7134 completed (loss: 0.3633148968219757, acc: 0.8961748480796814)
[2024-12-17 02:38:59,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,409][root][INFO] - Training Epoch: 2/2, step 508/7134 completed (loss: 0.3931208550930023, acc: 0.9117646813392639)
[2024-12-17 02:38:59,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:38:59,812][root][INFO] - Training Epoch: 2/2, step 509/7134 completed (loss: 0.49050161242485046, acc: 0.9054054021835327)
[2024-12-17 02:38:59,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,217][root][INFO] - Training Epoch: 2/2, step 510/7134 completed (loss: 1.0645824670791626, acc: 0.7804877758026123)
[2024-12-17 02:39:00,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,604][root][INFO] - Training Epoch: 2/2, step 511/7134 completed (loss: 0.5729893445968628, acc: 0.8857142925262451)
[2024-12-17 02:39:00,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:00,993][root][INFO] - Training Epoch: 2/2, step 512/7134 completed (loss: 0.7478494048118591, acc: 0.8625954389572144)
[2024-12-17 02:39:01,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,385][root][INFO] - Training Epoch: 2/2, step 513/7134 completed (loss: 0.6999437212944031, acc: 0.8389261960983276)
[2024-12-17 02:39:01,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:01,722][root][INFO] - Training Epoch: 2/2, step 514/7134 completed (loss: 1.3100687265396118, acc: 0.7314814925193787)
[2024-12-17 02:39:01,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,098][root][INFO] - Training Epoch: 2/2, step 515/7134 completed (loss: 0.5493825078010559, acc: 0.863095223903656)
[2024-12-17 02:39:02,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,446][root][INFO] - Training Epoch: 2/2, step 516/7134 completed (loss: 0.6030188798904419, acc: 0.8559321761131287)
[2024-12-17 02:39:02,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:02,822][root][INFO] - Training Epoch: 2/2, step 517/7134 completed (loss: 0.6183419823646545, acc: 0.8478260636329651)
[2024-12-17 02:39:02,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,207][root][INFO] - Training Epoch: 2/2, step 518/7134 completed (loss: 0.4040747284889221, acc: 0.887417197227478)
[2024-12-17 02:39:03,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,571][root][INFO] - Training Epoch: 2/2, step 519/7134 completed (loss: 0.4083976745605469, acc: 0.904347836971283)
[2024-12-17 02:39:03,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:03,938][root][INFO] - Training Epoch: 2/2, step 520/7134 completed (loss: 0.5008346438407898, acc: 0.8684210777282715)
[2024-12-17 02:39:04,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,328][root][INFO] - Training Epoch: 2/2, step 521/7134 completed (loss: 0.5135129690170288, acc: 0.8771929740905762)
[2024-12-17 02:39:04,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:04,726][root][INFO] - Training Epoch: 2/2, step 522/7134 completed (loss: 0.3333444595336914, acc: 0.915730357170105)
[2024-12-17 02:39:04,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,127][root][INFO] - Training Epoch: 2/2, step 523/7134 completed (loss: 0.3418656587600708, acc: 0.9011628031730652)
[2024-12-17 02:39:05,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,514][root][INFO] - Training Epoch: 2/2, step 524/7134 completed (loss: 0.44228506088256836, acc: 0.903954803943634)
[2024-12-17 02:39:05,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:05,887][root][INFO] - Training Epoch: 2/2, step 525/7134 completed (loss: 0.48513177037239075, acc: 0.8711656332015991)
[2024-12-17 02:39:05,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,268][root][INFO] - Training Epoch: 2/2, step 526/7134 completed (loss: 0.4284382164478302, acc: 0.8806818127632141)
[2024-12-17 02:39:06,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:06,654][root][INFO] - Training Epoch: 2/2, step 527/7134 completed (loss: 0.3572859466075897, acc: 0.9296875)
[2024-12-17 02:39:06,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,069][root][INFO] - Training Epoch: 2/2, step 528/7134 completed (loss: 0.4055987000465393, acc: 0.8879310488700867)
[2024-12-17 02:39:07,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,469][root][INFO] - Training Epoch: 2/2, step 529/7134 completed (loss: 0.5024762749671936, acc: 0.8726114630699158)
[2024-12-17 02:39:07,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:07,831][root][INFO] - Training Epoch: 2/2, step 530/7134 completed (loss: 0.496053546667099, acc: 0.8692307472229004)
[2024-12-17 02:39:07,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,144][root][INFO] - Training Epoch: 2/2, step 531/7134 completed (loss: 0.5541477799415588, acc: 0.8561643958091736)
[2024-12-17 02:39:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,542][root][INFO] - Training Epoch: 2/2, step 532/7134 completed (loss: 0.24185074865818024, acc: 0.9469026327133179)
[2024-12-17 02:39:08,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:08,933][root][INFO] - Training Epoch: 2/2, step 533/7134 completed (loss: 0.5925243496894836, acc: 0.8571428656578064)
[2024-12-17 02:39:09,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,314][root][INFO] - Training Epoch: 2/2, step 534/7134 completed (loss: 0.36771345138549805, acc: 0.910179615020752)
[2024-12-17 02:39:09,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:09,704][root][INFO] - Training Epoch: 2/2, step 535/7134 completed (loss: 0.41841188073158264, acc: 0.9051094651222229)
[2024-12-17 02:39:09,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,086][root][INFO] - Training Epoch: 2/2, step 536/7134 completed (loss: 0.29639798402786255, acc: 0.9085366129875183)
[2024-12-17 02:39:10,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,464][root][INFO] - Training Epoch: 2/2, step 537/7134 completed (loss: 0.5165194869041443, acc: 0.8728323578834534)
[2024-12-17 02:39:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:10,854][root][INFO] - Training Epoch: 2/2, step 538/7134 completed (loss: 0.44845256209373474, acc: 0.8855421543121338)
[2024-12-17 02:39:10,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,262][root][INFO] - Training Epoch: 2/2, step 539/7134 completed (loss: 0.5838384032249451, acc: 0.8702290058135986)
[2024-12-17 02:39:11,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:11,626][root][INFO] - Training Epoch: 2/2, step 540/7134 completed (loss: 0.5342288613319397, acc: 0.8773584961891174)
[2024-12-17 02:39:11,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,013][root][INFO] - Training Epoch: 2/2, step 541/7134 completed (loss: 0.6263965964317322, acc: 0.863095223903656)
[2024-12-17 02:39:12,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,325][root][INFO] - Training Epoch: 2/2, step 542/7134 completed (loss: 0.9482729434967041, acc: 0.7699999809265137)
[2024-12-17 02:39:12,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:12,713][root][INFO] - Training Epoch: 2/2, step 543/7134 completed (loss: 0.691326916217804, acc: 0.8092105388641357)
[2024-12-17 02:39:12,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,120][root][INFO] - Training Epoch: 2/2, step 544/7134 completed (loss: 0.7141841053962708, acc: 0.8071428537368774)
[2024-12-17 02:39:13,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,559][root][INFO] - Training Epoch: 2/2, step 545/7134 completed (loss: 0.8193047642707825, acc: 0.8421052694320679)
[2024-12-17 02:39:13,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:13,973][root][INFO] - Training Epoch: 2/2, step 546/7134 completed (loss: 0.8070653080940247, acc: 0.8055555820465088)
[2024-12-17 02:39:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,390][root][INFO] - Training Epoch: 2/2, step 547/7134 completed (loss: 0.5394034385681152, acc: 0.9072847962379456)
[2024-12-17 02:39:14,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:14,790][root][INFO] - Training Epoch: 2/2, step 548/7134 completed (loss: 0.424531489610672, acc: 0.9144737124443054)
[2024-12-17 02:39:14,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,190][root][INFO] - Training Epoch: 2/2, step 549/7134 completed (loss: 0.9650480151176453, acc: 0.7785714268684387)
[2024-12-17 02:39:15,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,585][root][INFO] - Training Epoch: 2/2, step 550/7134 completed (loss: 0.5621315836906433, acc: 0.874015748500824)
[2024-12-17 02:39:15,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:15,963][root][INFO] - Training Epoch: 2/2, step 551/7134 completed (loss: 0.7300843596458435, acc: 0.84375)
[2024-12-17 02:39:16,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,355][root][INFO] - Training Epoch: 2/2, step 552/7134 completed (loss: 0.5145696997642517, acc: 0.884353756904602)
[2024-12-17 02:39:16,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:16,709][root][INFO] - Training Epoch: 2/2, step 553/7134 completed (loss: 0.48386940360069275, acc: 0.9052631855010986)
[2024-12-17 02:39:16,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,119][root][INFO] - Training Epoch: 2/2, step 554/7134 completed (loss: 0.6664261221885681, acc: 0.8535031676292419)
[2024-12-17 02:39:17,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,472][root][INFO] - Training Epoch: 2/2, step 555/7134 completed (loss: 0.7156266570091248, acc: 0.8636363744735718)
[2024-12-17 02:39:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:17,840][root][INFO] - Training Epoch: 2/2, step 556/7134 completed (loss: 0.3067813515663147, acc: 0.925000011920929)
[2024-12-17 02:39:17,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,232][root][INFO] - Training Epoch: 2/2, step 557/7134 completed (loss: 0.5536623597145081, acc: 0.8226950168609619)
[2024-12-17 02:39:18,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,600][root][INFO] - Training Epoch: 2/2, step 558/7134 completed (loss: 0.5143092274665833, acc: 0.8653846383094788)
[2024-12-17 02:39:18,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:18,960][root][INFO] - Training Epoch: 2/2, step 559/7134 completed (loss: 0.6914731860160828, acc: 0.791946291923523)
[2024-12-17 02:39:19,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,323][root][INFO] - Training Epoch: 2/2, step 560/7134 completed (loss: 0.3672815263271332, acc: 0.9430894255638123)
[2024-12-17 02:39:19,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:19,708][root][INFO] - Training Epoch: 2/2, step 561/7134 completed (loss: 0.5173982381820679, acc: 0.8812500238418579)
[2024-12-17 02:39:19,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,092][root][INFO] - Training Epoch: 2/2, step 562/7134 completed (loss: 0.6271272301673889, acc: 0.8246753215789795)
[2024-12-17 02:39:20,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,479][root][INFO] - Training Epoch: 2/2, step 563/7134 completed (loss: 0.8364596366882324, acc: 0.7902097702026367)
[2024-12-17 02:39:20,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:20,876][root][INFO] - Training Epoch: 2/2, step 564/7134 completed (loss: 0.5664269328117371, acc: 0.8771929740905762)
[2024-12-17 02:39:20,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,247][root][INFO] - Training Epoch: 2/2, step 565/7134 completed (loss: 0.541653037071228, acc: 0.8976377844810486)
[2024-12-17 02:39:21,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:21,642][root][INFO] - Training Epoch: 2/2, step 566/7134 completed (loss: 0.6006730794906616, acc: 0.8558558821678162)
[2024-12-17 02:39:21,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,017][root][INFO] - Training Epoch: 2/2, step 567/7134 completed (loss: 0.6313562989234924, acc: 0.832335352897644)
[2024-12-17 02:39:22,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,426][root][INFO] - Training Epoch: 2/2, step 568/7134 completed (loss: 0.5404213070869446, acc: 0.8631578683853149)
[2024-12-17 02:39:22,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:22,809][root][INFO] - Training Epoch: 2/2, step 569/7134 completed (loss: 0.4987773895263672, acc: 0.8994413614273071)
[2024-12-17 02:39:22,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,175][root][INFO] - Training Epoch: 2/2, step 570/7134 completed (loss: 0.6008498668670654, acc: 0.89552241563797)
[2024-12-17 02:39:23,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,548][root][INFO] - Training Epoch: 2/2, step 571/7134 completed (loss: 0.44379478693008423, acc: 0.8846153616905212)
[2024-12-17 02:39:23,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:23,932][root][INFO] - Training Epoch: 2/2, step 572/7134 completed (loss: 0.2965073585510254, acc: 0.9257143139839172)
[2024-12-17 02:39:24,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,304][root][INFO] - Training Epoch: 2/2, step 573/7134 completed (loss: 0.38858306407928467, acc: 0.8969696760177612)
[2024-12-17 02:39:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:24,696][root][INFO] - Training Epoch: 2/2, step 574/7134 completed (loss: 0.38437554240226746, acc: 0.9053254723548889)
[2024-12-17 02:39:24,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,106][root][INFO] - Training Epoch: 2/2, step 575/7134 completed (loss: 0.4027208983898163, acc: 0.8947368264198303)
[2024-12-17 02:39:25,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,452][root][INFO] - Training Epoch: 2/2, step 576/7134 completed (loss: 0.32878926396369934, acc: 0.9193548560142517)
[2024-12-17 02:39:25,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:25,838][root][INFO] - Training Epoch: 2/2, step 577/7134 completed (loss: 0.4963841438293457, acc: 0.903030276298523)
[2024-12-17 02:39:25,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,227][root][INFO] - Training Epoch: 2/2, step 578/7134 completed (loss: 0.4498075842857361, acc: 0.89552241563797)
[2024-12-17 02:39:26,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,605][root][INFO] - Training Epoch: 2/2, step 579/7134 completed (loss: 0.6432220935821533, acc: 0.8387096524238586)
[2024-12-17 02:39:26,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:26,963][root][INFO] - Training Epoch: 2/2, step 580/7134 completed (loss: 0.6734170913696289, acc: 0.8500000238418579)
[2024-12-17 02:39:27,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,321][root][INFO] - Training Epoch: 2/2, step 581/7134 completed (loss: 0.31915539503097534, acc: 0.9013158082962036)
[2024-12-17 02:39:27,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:27,718][root][INFO] - Training Epoch: 2/2, step 582/7134 completed (loss: 0.48388901352882385, acc: 0.864130437374115)
[2024-12-17 02:39:27,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,119][root][INFO] - Training Epoch: 2/2, step 583/7134 completed (loss: 0.36814531683921814, acc: 0.9041916131973267)
[2024-12-17 02:39:28,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,512][root][INFO] - Training Epoch: 2/2, step 584/7134 completed (loss: 0.3052668273448944, acc: 0.9234972596168518)
[2024-12-17 02:39:28,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:28,856][root][INFO] - Training Epoch: 2/2, step 585/7134 completed (loss: 0.3361426293849945, acc: 0.908108115196228)
[2024-12-17 02:39:28,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,192][root][INFO] - Training Epoch: 2/2, step 586/7134 completed (loss: 0.26614707708358765, acc: 0.9202127456665039)
[2024-12-17 02:39:29,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,543][root][INFO] - Training Epoch: 2/2, step 587/7134 completed (loss: 0.3340802788734436, acc: 0.9337016344070435)
[2024-12-17 02:39:29,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:29,908][root][INFO] - Training Epoch: 2/2, step 588/7134 completed (loss: 0.31089210510253906, acc: 0.9256756901741028)
[2024-12-17 02:39:30,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,282][root][INFO] - Training Epoch: 2/2, step 589/7134 completed (loss: 0.3173632323741913, acc: 0.9018405079841614)
[2024-12-17 02:39:30,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:30,657][root][INFO] - Training Epoch: 2/2, step 590/7134 completed (loss: 0.2819480001926422, acc: 0.9337748289108276)
[2024-12-17 02:39:30,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,031][root][INFO] - Training Epoch: 2/2, step 591/7134 completed (loss: 0.30436626076698303, acc: 0.9209039807319641)
[2024-12-17 02:39:31,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,397][root][INFO] - Training Epoch: 2/2, step 592/7134 completed (loss: 0.2681621313095093, acc: 0.9375)
[2024-12-17 02:39:31,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:31,742][root][INFO] - Training Epoch: 2/2, step 593/7134 completed (loss: 0.38517940044403076, acc: 0.9122806787490845)
[2024-12-17 02:39:31,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,096][root][INFO] - Training Epoch: 2/2, step 594/7134 completed (loss: 0.4312686026096344, acc: 0.910179615020752)
[2024-12-17 02:39:32,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,482][root][INFO] - Training Epoch: 2/2, step 595/7134 completed (loss: 0.32749465107917786, acc: 0.9247311949729919)
[2024-12-17 02:39:32,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:32,854][root][INFO] - Training Epoch: 2/2, step 596/7134 completed (loss: 0.3599575459957123, acc: 0.9222221970558167)
[2024-12-17 02:39:32,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,227][root][INFO] - Training Epoch: 2/2, step 597/7134 completed (loss: 0.37529969215393066, acc: 0.916201114654541)
[2024-12-17 02:39:33,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,603][root][INFO] - Training Epoch: 2/2, step 598/7134 completed (loss: 0.5862994194030762, acc: 0.89673912525177)
[2024-12-17 02:39:33,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:33,997][root][INFO] - Training Epoch: 2/2, step 599/7134 completed (loss: 0.3761531412601471, acc: 0.9301075339317322)
[2024-12-17 02:39:34,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,439][root][INFO] - Training Epoch: 2/2, step 600/7134 completed (loss: 0.33367615938186646, acc: 0.9016393423080444)
[2024-12-17 02:39:34,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:34,839][root][INFO] - Training Epoch: 2/2, step 601/7134 completed (loss: 0.46938732266426086, acc: 0.8863636255264282)
[2024-12-17 02:39:34,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,229][root][INFO] - Training Epoch: 2/2, step 602/7134 completed (loss: 0.46687403321266174, acc: 0.8918918967247009)
[2024-12-17 02:39:35,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:35,637][root][INFO] - Training Epoch: 2/2, step 603/7134 completed (loss: 0.5160210132598877, acc: 0.8624338507652283)
[2024-12-17 02:39:35,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,017][root][INFO] - Training Epoch: 2/2, step 604/7134 completed (loss: 0.42903146147727966, acc: 0.9090909361839294)
[2024-12-17 02:39:36,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,401][root][INFO] - Training Epoch: 2/2, step 605/7134 completed (loss: 0.28825843334198, acc: 0.9411764740943909)
[2024-12-17 02:39:36,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:36,793][root][INFO] - Training Epoch: 2/2, step 606/7134 completed (loss: 0.39453229308128357, acc: 0.9150000214576721)
[2024-12-17 02:39:36,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,185][root][INFO] - Training Epoch: 2/2, step 607/7134 completed (loss: 0.4206116199493408, acc: 0.8735632300376892)
[2024-12-17 02:39:37,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,602][root][INFO] - Training Epoch: 2/2, step 608/7134 completed (loss: 0.36979490518569946, acc: 0.9405405521392822)
[2024-12-17 02:39:37,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:37,993][root][INFO] - Training Epoch: 2/2, step 609/7134 completed (loss: 0.33751988410949707, acc: 0.928205132484436)
[2024-12-17 02:39:38,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,375][root][INFO] - Training Epoch: 2/2, step 610/7134 completed (loss: 0.3069382607936859, acc: 0.9408866763114929)
[2024-12-17 02:39:38,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:38,736][root][INFO] - Training Epoch: 2/2, step 611/7134 completed (loss: 0.31121233105659485, acc: 0.9322034120559692)
[2024-12-17 02:39:38,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,097][root][INFO] - Training Epoch: 2/2, step 612/7134 completed (loss: 0.39482030272483826, acc: 0.9021739363670349)
[2024-12-17 02:39:39,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,484][root][INFO] - Training Epoch: 2/2, step 613/7134 completed (loss: 0.32193461060523987, acc: 0.8989899158477783)
[2024-12-17 02:39:39,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:39,847][root][INFO] - Training Epoch: 2/2, step 614/7134 completed (loss: 0.28077635169029236, acc: 0.9347826242446899)
[2024-12-17 02:39:39,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,234][root][INFO] - Training Epoch: 2/2, step 615/7134 completed (loss: 0.27801552414894104, acc: 0.9105263352394104)
[2024-12-17 02:39:40,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,613][root][INFO] - Training Epoch: 2/2, step 616/7134 completed (loss: 0.22935271263122559, acc: 0.9354838728904724)
[2024-12-17 02:39:40,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:40,993][root][INFO] - Training Epoch: 2/2, step 617/7134 completed (loss: 0.34006717801094055, acc: 0.9234449863433838)
[2024-12-17 02:39:41,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,338][root][INFO] - Training Epoch: 2/2, step 618/7134 completed (loss: 0.28973114490509033, acc: 0.9358288645744324)
[2024-12-17 02:39:41,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:41,668][root][INFO] - Training Epoch: 2/2, step 619/7134 completed (loss: 0.42039191722869873, acc: 0.8852459192276001)
[2024-12-17 02:39:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,034][root][INFO] - Training Epoch: 2/2, step 620/7134 completed (loss: 0.3499797284603119, acc: 0.9178082346916199)
[2024-12-17 02:39:42,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,414][root][INFO] - Training Epoch: 2/2, step 621/7134 completed (loss: 0.3659422993659973, acc: 0.9133333563804626)
[2024-12-17 02:39:42,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:42,797][root][INFO] - Training Epoch: 2/2, step 622/7134 completed (loss: 0.48442548513412476, acc: 0.875)
[2024-12-17 02:39:42,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,148][root][INFO] - Training Epoch: 2/2, step 623/7134 completed (loss: 0.6915404796600342, acc: 0.8417266011238098)
[2024-12-17 02:39:43,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,508][root][INFO] - Training Epoch: 2/2, step 624/7134 completed (loss: 0.3658647835254669, acc: 0.9051094651222229)
[2024-12-17 02:39:43,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:43,871][root][INFO] - Training Epoch: 2/2, step 625/7134 completed (loss: 0.4490077495574951, acc: 0.8999999761581421)
[2024-12-17 02:39:43,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,215][root][INFO] - Training Epoch: 2/2, step 626/7134 completed (loss: 0.4605891704559326, acc: 0.9039999842643738)
[2024-12-17 02:39:44,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,576][root][INFO] - Training Epoch: 2/2, step 627/7134 completed (loss: 0.40577852725982666, acc: 0.9047619104385376)
[2024-12-17 02:39:44,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:44,955][root][INFO] - Training Epoch: 2/2, step 628/7134 completed (loss: 0.472434937953949, acc: 0.8503401279449463)
[2024-12-17 02:39:45,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,356][root][INFO] - Training Epoch: 2/2, step 629/7134 completed (loss: 0.6473298072814941, acc: 0.8723404407501221)
[2024-12-17 02:39:45,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:45,730][root][INFO] - Training Epoch: 2/2, step 630/7134 completed (loss: 0.6452874541282654, acc: 0.8535031676292419)
[2024-12-17 02:39:45,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,059][root][INFO] - Training Epoch: 2/2, step 631/7134 completed (loss: 0.4218793511390686, acc: 0.8961039185523987)
[2024-12-17 02:39:46,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,446][root][INFO] - Training Epoch: 2/2, step 632/7134 completed (loss: 0.24235112965106964, acc: 0.9366196990013123)
[2024-12-17 02:39:46,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:46,824][root][INFO] - Training Epoch: 2/2, step 633/7134 completed (loss: 0.3883989453315735, acc: 0.90625)
[2024-12-17 02:39:46,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,213][root][INFO] - Training Epoch: 2/2, step 634/7134 completed (loss: 0.47193798422813416, acc: 0.8831169009208679)
[2024-12-17 02:39:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,597][root][INFO] - Training Epoch: 2/2, step 635/7134 completed (loss: 0.3996400833129883, acc: 0.8961039185523987)
[2024-12-17 02:39:47,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:47,976][root][INFO] - Training Epoch: 2/2, step 636/7134 completed (loss: 0.32746732234954834, acc: 0.940119743347168)
[2024-12-17 02:39:48,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,370][root][INFO] - Training Epoch: 2/2, step 637/7134 completed (loss: 0.2946999967098236, acc: 0.9136690497398376)
[2024-12-17 02:39:48,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:48,757][root][INFO] - Training Epoch: 2/2, step 638/7134 completed (loss: 0.4636967182159424, acc: 0.8926174640655518)
[2024-12-17 02:39:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,135][root][INFO] - Training Epoch: 2/2, step 639/7134 completed (loss: 0.3926307260990143, acc: 0.8999999761581421)
[2024-12-17 02:39:49,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,527][root][INFO] - Training Epoch: 2/2, step 640/7134 completed (loss: 0.3559253513813019, acc: 0.9275362491607666)
[2024-12-17 02:39:49,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:49,866][root][INFO] - Training Epoch: 2/2, step 641/7134 completed (loss: 0.37427520751953125, acc: 0.9275362491607666)
[2024-12-17 02:39:49,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,239][root][INFO] - Training Epoch: 2/2, step 642/7134 completed (loss: 0.3273906409740448, acc: 0.9191176295280457)
[2024-12-17 02:39:50,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:50,636][root][INFO] - Training Epoch: 2/2, step 643/7134 completed (loss: 0.3144763708114624, acc: 0.9382022619247437)
[2024-12-17 02:39:50,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,019][root][INFO] - Training Epoch: 2/2, step 644/7134 completed (loss: 0.377845823764801, acc: 0.921875)
[2024-12-17 02:39:51,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,393][root][INFO] - Training Epoch: 2/2, step 645/7134 completed (loss: 0.16175711154937744, acc: 0.951724112033844)
[2024-12-17 02:39:51,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:51,792][root][INFO] - Training Epoch: 2/2, step 646/7134 completed (loss: 0.36472421884536743, acc: 0.905063271522522)
[2024-12-17 02:39:51,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,196][root][INFO] - Training Epoch: 2/2, step 647/7134 completed (loss: 0.24064119160175323, acc: 0.9333333373069763)
[2024-12-17 02:39:52,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,585][root][INFO] - Training Epoch: 2/2, step 648/7134 completed (loss: 0.8749143481254578, acc: 0.8153846263885498)
[2024-12-17 02:39:52,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:52,990][root][INFO] - Training Epoch: 2/2, step 649/7134 completed (loss: 0.659293532371521, acc: 0.8648648858070374)
[2024-12-17 02:39:53,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,374][root][INFO] - Training Epoch: 2/2, step 650/7134 completed (loss: 0.7376334071159363, acc: 0.8219178318977356)
[2024-12-17 02:39:53,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:53,745][root][INFO] - Training Epoch: 2/2, step 651/7134 completed (loss: 0.7959933876991272, acc: 0.7922077775001526)
[2024-12-17 02:39:53,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,130][root][INFO] - Training Epoch: 2/2, step 652/7134 completed (loss: 0.7239587306976318, acc: 0.8591549396514893)
[2024-12-17 02:39:54,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,504][root][INFO] - Training Epoch: 2/2, step 653/7134 completed (loss: 0.46925002336502075, acc: 0.9272727370262146)
[2024-12-17 02:39:54,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:54,887][root][INFO] - Training Epoch: 2/2, step 654/7134 completed (loss: 0.5668500065803528, acc: 0.8721804618835449)
[2024-12-17 02:39:54,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,250][root][INFO] - Training Epoch: 2/2, step 655/7134 completed (loss: 0.4458393156528473, acc: 0.9137930870056152)
[2024-12-17 02:39:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:55,632][root][INFO] - Training Epoch: 2/2, step 656/7134 completed (loss: 0.5039433836936951, acc: 0.868686854839325)
[2024-12-17 02:39:55,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,011][root][INFO] - Training Epoch: 2/2, step 657/7134 completed (loss: 0.5472617149353027, acc: 0.8591549396514893)
[2024-12-17 02:39:56,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,364][root][INFO] - Training Epoch: 2/2, step 658/7134 completed (loss: 0.3354801833629608, acc: 0.9209039807319641)
[2024-12-17 02:39:56,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:56,738][root][INFO] - Training Epoch: 2/2, step 659/7134 completed (loss: 0.3179737627506256, acc: 0.9221556782722473)
[2024-12-17 02:39:56,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,115][root][INFO] - Training Epoch: 2/2, step 660/7134 completed (loss: 0.43658119440078735, acc: 0.8882352709770203)
[2024-12-17 02:39:57,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,497][root][INFO] - Training Epoch: 2/2, step 661/7134 completed (loss: 0.5234597325325012, acc: 0.8644067645072937)
[2024-12-17 02:39:57,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:57,882][root][INFO] - Training Epoch: 2/2, step 662/7134 completed (loss: 0.41030359268188477, acc: 0.8888888955116272)
[2024-12-17 02:39:58,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,273][root][INFO] - Training Epoch: 2/2, step 663/7134 completed (loss: 0.49096786975860596, acc: 0.8737863898277283)
[2024-12-17 02:39:58,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:58,626][root][INFO] - Training Epoch: 2/2, step 664/7134 completed (loss: 0.6157608032226562, acc: 0.8251748085021973)
[2024-12-17 02:39:58,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,017][root][INFO] - Training Epoch: 2/2, step 665/7134 completed (loss: 0.49003925919532776, acc: 0.8852459192276001)
[2024-12-17 02:39:59,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,383][root][INFO] - Training Epoch: 2/2, step 666/7134 completed (loss: 0.507611870765686, acc: 0.8914285898208618)
[2024-12-17 02:39:59,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:39:59,800][root][INFO] - Training Epoch: 2/2, step 667/7134 completed (loss: 0.6643667221069336, acc: 0.8383233547210693)
[2024-12-17 02:39:59,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,195][root][INFO] - Training Epoch: 2/2, step 668/7134 completed (loss: 0.26142507791519165, acc: 0.9234972596168518)
[2024-12-17 02:40:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,588][root][INFO] - Training Epoch: 2/2, step 669/7134 completed (loss: 0.3216838836669922, acc: 0.916201114654541)
[2024-12-17 02:40:00,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:00,994][root][INFO] - Training Epoch: 2/2, step 670/7134 completed (loss: 0.4719012975692749, acc: 0.8812785148620605)
[2024-12-17 02:40:01,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,385][root][INFO] - Training Epoch: 2/2, step 671/7134 completed (loss: 0.35834842920303345, acc: 0.9004524946212769)
[2024-12-17 02:40:01,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:01,730][root][INFO] - Training Epoch: 2/2, step 672/7134 completed (loss: 0.29588809609413147, acc: 0.9437500238418579)
[2024-12-17 02:40:01,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,141][root][INFO] - Training Epoch: 2/2, step 673/7134 completed (loss: 0.3964272141456604, acc: 0.9203979969024658)
[2024-12-17 02:40:02,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,519][root][INFO] - Training Epoch: 2/2, step 674/7134 completed (loss: 0.290791392326355, acc: 0.9268292784690857)
[2024-12-17 02:40:02,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:02,950][root][INFO] - Training Epoch: 2/2, step 675/7134 completed (loss: 0.3227536976337433, acc: 0.9226519465446472)
[2024-12-17 02:40:03,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,332][root][INFO] - Training Epoch: 2/2, step 676/7134 completed (loss: 0.27438467741012573, acc: 0.945652186870575)
[2024-12-17 02:40:03,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:03,700][root][INFO] - Training Epoch: 2/2, step 677/7134 completed (loss: 0.19220027327537537, acc: 0.9629629850387573)
[2024-12-17 02:40:03,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,091][root][INFO] - Training Epoch: 2/2, step 678/7134 completed (loss: 0.47637757658958435, acc: 0.8719512224197388)
[2024-12-17 02:40:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,495][root][INFO] - Training Epoch: 2/2, step 679/7134 completed (loss: 0.3493417203426361, acc: 0.9097744226455688)
[2024-12-17 02:40:04,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:04,876][root][INFO] - Training Epoch: 2/2, step 680/7134 completed (loss: 0.39251765608787537, acc: 0.8994975090026855)
[2024-12-17 02:40:04,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,263][root][INFO] - Training Epoch: 2/2, step 681/7134 completed (loss: 0.3015252649784088, acc: 0.9052631855010986)
[2024-12-17 02:40:05,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:05,635][root][INFO] - Training Epoch: 2/2, step 682/7134 completed (loss: 0.20627926290035248, acc: 0.9491525292396545)
[2024-12-17 02:40:05,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,042][root][INFO] - Training Epoch: 2/2, step 683/7134 completed (loss: 0.2943682372570038, acc: 0.929729700088501)
[2024-12-17 02:40:06,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,506][root][INFO] - Training Epoch: 2/2, step 684/7134 completed (loss: 0.3108743131160736, acc: 0.9111111164093018)
[2024-12-17 02:40:06,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:06,911][root][INFO] - Training Epoch: 2/2, step 685/7134 completed (loss: 0.21015475690364838, acc: 0.9497487545013428)
[2024-12-17 02:40:07,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,306][root][INFO] - Training Epoch: 2/2, step 686/7134 completed (loss: 0.1896621435880661, acc: 0.9508196711540222)
[2024-12-17 02:40:07,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:07,717][root][INFO] - Training Epoch: 2/2, step 687/7134 completed (loss: 0.3434787690639496, acc: 0.8897637724876404)
[2024-12-17 02:40:07,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,156][root][INFO] - Training Epoch: 2/2, step 688/7134 completed (loss: 0.13110248744487762, acc: 0.9620253443717957)
[2024-12-17 02:40:08,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,535][root][INFO] - Training Epoch: 2/2, step 689/7134 completed (loss: 0.28666412830352783, acc: 0.9333333373069763)
[2024-12-17 02:40:08,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:08,911][root][INFO] - Training Epoch: 2/2, step 690/7134 completed (loss: 0.4391660690307617, acc: 0.896774172782898)
[2024-12-17 02:40:09,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,300][root][INFO] - Training Epoch: 2/2, step 691/7134 completed (loss: 0.5686143636703491, acc: 0.8571428656578064)
[2024-12-17 02:40:09,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:09,678][root][INFO] - Training Epoch: 2/2, step 692/7134 completed (loss: 0.6151286959648132, acc: 0.8832487463951111)
[2024-12-17 02:40:09,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,041][root][INFO] - Training Epoch: 2/2, step 693/7134 completed (loss: 0.5748434662818909, acc: 0.8581560254096985)
[2024-12-17 02:40:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,428][root][INFO] - Training Epoch: 2/2, step 694/7134 completed (loss: 0.7071212530136108, acc: 0.800000011920929)
[2024-12-17 02:40:10,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:10,819][root][INFO] - Training Epoch: 2/2, step 695/7134 completed (loss: 0.5719791650772095, acc: 0.8432835936546326)
[2024-12-17 02:40:10,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,203][root][INFO] - Training Epoch: 2/2, step 696/7134 completed (loss: 0.5748938918113708, acc: 0.8616352081298828)
[2024-12-17 02:40:11,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,619][root][INFO] - Training Epoch: 2/2, step 697/7134 completed (loss: 0.36942058801651, acc: 0.9130434989929199)
[2024-12-17 02:40:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:11,999][root][INFO] - Training Epoch: 2/2, step 698/7134 completed (loss: 0.3704301118850708, acc: 0.9242424368858337)
[2024-12-17 02:40:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,390][root][INFO] - Training Epoch: 2/2, step 699/7134 completed (loss: 0.30830109119415283, acc: 0.9041095972061157)
[2024-12-17 02:40:12,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:12,781][root][INFO] - Training Epoch: 2/2, step 700/7134 completed (loss: 0.5606102347373962, acc: 0.8399999737739563)
[2024-12-17 02:40:12,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,166][root][INFO] - Training Epoch: 2/2, step 701/7134 completed (loss: 0.709091305732727, acc: 0.8086956739425659)
[2024-12-17 02:40:13,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,554][root][INFO] - Training Epoch: 2/2, step 702/7134 completed (loss: 0.5276392102241516, acc: 0.8543046116828918)
[2024-12-17 02:40:13,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:13,937][root][INFO] - Training Epoch: 2/2, step 703/7134 completed (loss: 0.5155501961708069, acc: 0.8581081032752991)
[2024-12-17 02:40:14,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,339][root][INFO] - Training Epoch: 2/2, step 704/7134 completed (loss: 0.42356619238853455, acc: 0.9155844449996948)
[2024-12-17 02:40:14,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:14,751][root][INFO] - Training Epoch: 2/2, step 705/7134 completed (loss: 0.49275466799736023, acc: 0.8899082541465759)
[2024-12-17 02:40:14,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,128][root][INFO] - Training Epoch: 2/2, step 706/7134 completed (loss: 0.33584505319595337, acc: 0.9056603908538818)
[2024-12-17 02:40:15,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,492][root][INFO] - Training Epoch: 2/2, step 707/7134 completed (loss: 0.4562597870826721, acc: 0.8811880946159363)
[2024-12-17 02:40:15,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:15,873][root][INFO] - Training Epoch: 2/2, step 708/7134 completed (loss: 0.2776142358779907, acc: 0.949438214302063)
[2024-12-17 02:40:16,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,267][root][INFO] - Training Epoch: 2/2, step 709/7134 completed (loss: 0.3806224763393402, acc: 0.8971428275108337)
[2024-12-17 02:40:16,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:16,657][root][INFO] - Training Epoch: 2/2, step 710/7134 completed (loss: 0.33526885509490967, acc: 0.921875)
[2024-12-17 02:40:16,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,030][root][INFO] - Training Epoch: 2/2, step 711/7134 completed (loss: 0.4201936423778534, acc: 0.9166666865348816)
[2024-12-17 02:40:17,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,422][root][INFO] - Training Epoch: 2/2, step 712/7134 completed (loss: 0.1810474395751953, acc: 0.9635416865348816)
[2024-12-17 02:40:17,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:17,800][root][INFO] - Training Epoch: 2/2, step 713/7134 completed (loss: 0.25565868616104126, acc: 0.929648220539093)
[2024-12-17 02:40:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,232][root][INFO] - Training Epoch: 2/2, step 714/7134 completed (loss: 0.39491793513298035, acc: 0.8899999856948853)
[2024-12-17 02:40:18,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:18,632][root][INFO] - Training Epoch: 2/2, step 715/7134 completed (loss: 0.24478740990161896, acc: 0.9239130616188049)
[2024-12-17 02:40:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,009][root][INFO] - Training Epoch: 2/2, step 716/7134 completed (loss: 0.20703303813934326, acc: 0.9558823704719543)
[2024-12-17 02:40:19,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,378][root][INFO] - Training Epoch: 2/2, step 717/7134 completed (loss: 0.38440272212028503, acc: 0.9090909361839294)
[2024-12-17 02:40:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:19,765][root][INFO] - Training Epoch: 2/2, step 718/7134 completed (loss: 0.22818388044834137, acc: 0.920634925365448)
[2024-12-17 02:40:19,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,152][root][INFO] - Training Epoch: 2/2, step 719/7134 completed (loss: 0.13925625383853912, acc: 0.9645389914512634)
[2024-12-17 02:40:20,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,536][root][INFO] - Training Epoch: 2/2, step 720/7134 completed (loss: 0.1946362853050232, acc: 0.9567567706108093)
[2024-12-17 02:40:20,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:20,929][root][INFO] - Training Epoch: 2/2, step 721/7134 completed (loss: 0.18049302697181702, acc: 0.9526315927505493)
[2024-12-17 02:40:21,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,320][root][INFO] - Training Epoch: 2/2, step 722/7134 completed (loss: 0.27049365639686584, acc: 0.9242424368858337)
[2024-12-17 02:40:21,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:21,721][root][INFO] - Training Epoch: 2/2, step 723/7134 completed (loss: 0.21417023241519928, acc: 0.9402173757553101)
[2024-12-17 02:40:21,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,094][root][INFO] - Training Epoch: 2/2, step 724/7134 completed (loss: 0.2974064350128174, acc: 0.9308176040649414)
[2024-12-17 02:40:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,477][root][INFO] - Training Epoch: 2/2, step 725/7134 completed (loss: 0.11211763322353363, acc: 0.976190447807312)
[2024-12-17 02:40:22,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:22,875][root][INFO] - Training Epoch: 2/2, step 726/7134 completed (loss: 0.1980101764202118, acc: 0.9385474920272827)
[2024-12-17 02:40:23,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,265][root][INFO] - Training Epoch: 2/2, step 727/7134 completed (loss: 0.29339051246643066, acc: 0.9479768872261047)
[2024-12-17 02:40:23,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:23,663][root][INFO] - Training Epoch: 2/2, step 728/7134 completed (loss: 0.2235717922449112, acc: 0.9485714435577393)
[2024-12-17 02:40:23,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,058][root][INFO] - Training Epoch: 2/2, step 729/7134 completed (loss: 0.21649235486984253, acc: 0.949367105960846)
[2024-12-17 02:40:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,410][root][INFO] - Training Epoch: 2/2, step 730/7134 completed (loss: 0.148323193192482, acc: 0.957446813583374)
[2024-12-17 02:40:24,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:24,782][root][INFO] - Training Epoch: 2/2, step 731/7134 completed (loss: 0.14476174116134644, acc: 0.9548022747039795)
[2024-12-17 02:40:24,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,157][root][INFO] - Training Epoch: 2/2, step 732/7134 completed (loss: 0.3898726999759674, acc: 0.9098360538482666)
[2024-12-17 02:40:25,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,536][root][INFO] - Training Epoch: 2/2, step 733/7134 completed (loss: 0.3105885088443756, acc: 0.9230769276618958)
[2024-12-17 02:40:25,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:25,922][root][INFO] - Training Epoch: 2/2, step 734/7134 completed (loss: 0.39603522419929504, acc: 0.9032257795333862)
[2024-12-17 02:40:26,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,288][root][INFO] - Training Epoch: 2/2, step 735/7134 completed (loss: 0.34216946363449097, acc: 0.9366196990013123)
[2024-12-17 02:40:26,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:26,667][root][INFO] - Training Epoch: 2/2, step 736/7134 completed (loss: 0.7153941988945007, acc: 0.8613861203193665)
[2024-12-17 02:40:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,056][root][INFO] - Training Epoch: 2/2, step 737/7134 completed (loss: 0.4691978394985199, acc: 0.8898305296897888)
[2024-12-17 02:40:27,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,445][root][INFO] - Training Epoch: 2/2, step 738/7134 completed (loss: 0.2563967704772949, acc: 0.9339622855186462)
[2024-12-17 02:40:27,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:27,820][root][INFO] - Training Epoch: 2/2, step 739/7134 completed (loss: 0.30947956442832947, acc: 0.9304347634315491)
[2024-12-17 02:40:27,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,184][root][INFO] - Training Epoch: 2/2, step 740/7134 completed (loss: 0.3159402012825012, acc: 0.9186992049217224)
[2024-12-17 02:40:28,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,556][root][INFO] - Training Epoch: 2/2, step 741/7134 completed (loss: 0.4064576327800751, acc: 0.9185185432434082)
[2024-12-17 02:40:28,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:28,923][root][INFO] - Training Epoch: 2/2, step 742/7134 completed (loss: 0.3248543441295624, acc: 0.9263157844543457)
[2024-12-17 02:40:29,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,331][root][INFO] - Training Epoch: 2/2, step 743/7134 completed (loss: 0.39420273900032043, acc: 0.918367326259613)
[2024-12-17 02:40:29,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:29,703][root][INFO] - Training Epoch: 2/2, step 744/7134 completed (loss: 0.2357163280248642, acc: 0.949999988079071)
[2024-12-17 02:40:29,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,080][root][INFO] - Training Epoch: 2/2, step 745/7134 completed (loss: 0.275467187166214, acc: 0.9411764740943909)
[2024-12-17 02:40:30,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,483][root][INFO] - Training Epoch: 2/2, step 746/7134 completed (loss: 0.34262022376060486, acc: 0.9236640930175781)
[2024-12-17 02:40:30,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:30,849][root][INFO] - Training Epoch: 2/2, step 747/7134 completed (loss: 0.5297728180885315, acc: 0.8661417365074158)
[2024-12-17 02:40:30,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,225][root][INFO] - Training Epoch: 2/2, step 748/7134 completed (loss: 0.3089628219604492, acc: 0.9029850959777832)
[2024-12-17 02:40:31,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:31,621][root][INFO] - Training Epoch: 2/2, step 749/7134 completed (loss: 0.27920007705688477, acc: 0.9285714030265808)
[2024-12-17 02:40:31,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,045][root][INFO] - Training Epoch: 2/2, step 750/7134 completed (loss: 0.3309879004955292, acc: 0.9256198406219482)
[2024-12-17 02:40:32,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,419][root][INFO] - Training Epoch: 2/2, step 751/7134 completed (loss: 0.4162936210632324, acc: 0.8799999952316284)
[2024-12-17 02:40:32,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:32,794][root][INFO] - Training Epoch: 2/2, step 752/7134 completed (loss: 0.3704020380973816, acc: 0.9459459185600281)
[2024-12-17 02:40:32,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,190][root][INFO] - Training Epoch: 2/2, step 753/7134 completed (loss: 0.28838828206062317, acc: 0.9140625)
[2024-12-17 02:40:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,557][root][INFO] - Training Epoch: 2/2, step 754/7134 completed (loss: 0.3235946297645569, acc: 0.9202898740768433)
[2024-12-17 02:40:33,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:33,959][root][INFO] - Training Epoch: 2/2, step 755/7134 completed (loss: 0.4436521530151367, acc: 0.8880000114440918)
[2024-12-17 02:40:34,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,368][root][INFO] - Training Epoch: 2/2, step 756/7134 completed (loss: 0.2772202789783478, acc: 0.9375)
[2024-12-17 02:40:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:34,778][root][INFO] - Training Epoch: 2/2, step 757/7134 completed (loss: 0.17343474924564362, acc: 0.9807692170143127)
[2024-12-17 02:40:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,166][root][INFO] - Training Epoch: 2/2, step 758/7134 completed (loss: 0.2519078254699707, acc: 0.9189189076423645)
[2024-12-17 02:40:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,551][root][INFO] - Training Epoch: 2/2, step 759/7134 completed (loss: 0.24868197739124298, acc: 0.954954981803894)
[2024-12-17 02:40:35,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:35,935][root][INFO] - Training Epoch: 2/2, step 760/7134 completed (loss: 0.2914963960647583, acc: 0.9318181872367859)
[2024-12-17 02:40:36,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,302][root][INFO] - Training Epoch: 2/2, step 761/7134 completed (loss: 0.2918531894683838, acc: 0.9281437397003174)
[2024-12-17 02:40:36,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:36,688][root][INFO] - Training Epoch: 2/2, step 762/7134 completed (loss: 0.2789584994316101, acc: 0.9420289993286133)
[2024-12-17 02:40:36,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,169][root][INFO] - Training Epoch: 2/2, step 763/7134 completed (loss: 0.3662673234939575, acc: 0.8881579041481018)
[2024-12-17 02:40:37,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,554][root][INFO] - Training Epoch: 2/2, step 764/7134 completed (loss: 0.14952556788921356, acc: 0.9585798978805542)
[2024-12-17 02:40:37,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:37,930][root][INFO] - Training Epoch: 2/2, step 765/7134 completed (loss: 0.19971174001693726, acc: 0.9496855139732361)
[2024-12-17 02:40:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,299][root][INFO] - Training Epoch: 2/2, step 766/7134 completed (loss: 0.1778283417224884, acc: 0.9437500238418579)
[2024-12-17 02:40:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:38,667][root][INFO] - Training Epoch: 2/2, step 767/7134 completed (loss: 0.281850665807724, acc: 0.9285714030265808)
[2024-12-17 02:40:38,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,059][root][INFO] - Training Epoch: 2/2, step 768/7134 completed (loss: 0.4427725374698639, acc: 0.9180327653884888)
[2024-12-17 02:40:39,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,461][root][INFO] - Training Epoch: 2/2, step 769/7134 completed (loss: 0.2688293159008026, acc: 0.9440993666648865)
[2024-12-17 02:40:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:39,825][root][INFO] - Training Epoch: 2/2, step 770/7134 completed (loss: 0.2747925817966461, acc: 0.9506173133850098)
[2024-12-17 02:40:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,220][root][INFO] - Training Epoch: 2/2, step 771/7134 completed (loss: 0.26734960079193115, acc: 0.9124087691307068)
[2024-12-17 02:40:40,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,585][root][INFO] - Training Epoch: 2/2, step 772/7134 completed (loss: 0.2437559962272644, acc: 0.9319728016853333)
[2024-12-17 02:40:40,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:40,983][root][INFO] - Training Epoch: 2/2, step 773/7134 completed (loss: 0.29527753591537476, acc: 0.9315789341926575)
[2024-12-17 02:40:41,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,382][root][INFO] - Training Epoch: 2/2, step 774/7134 completed (loss: 0.2783025801181793, acc: 0.9295774698257446)
[2024-12-17 02:40:41,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:41,766][root][INFO] - Training Epoch: 2/2, step 775/7134 completed (loss: 0.12980905175209045, acc: 0.9627659320831299)
[2024-12-17 02:40:41,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,140][root][INFO] - Training Epoch: 2/2, step 776/7134 completed (loss: 0.2676820755004883, acc: 0.9617834687232971)
[2024-12-17 02:40:42,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,518][root][INFO] - Training Epoch: 2/2, step 777/7134 completed (loss: 0.11598055809736252, acc: 0.9733333587646484)
[2024-12-17 02:40:42,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:42,901][root][INFO] - Training Epoch: 2/2, step 778/7134 completed (loss: 0.29667502641677856, acc: 0.9308176040649414)
[2024-12-17 02:40:43,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,276][root][INFO] - Training Epoch: 2/2, step 779/7134 completed (loss: 0.38422518968582153, acc: 0.9122806787490845)
[2024-12-17 02:40:43,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:43,669][root][INFO] - Training Epoch: 2/2, step 780/7134 completed (loss: 0.3574782609939575, acc: 0.9027026891708374)
[2024-12-17 02:40:43,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,068][root][INFO] - Training Epoch: 2/2, step 781/7134 completed (loss: 0.4227274954319, acc: 0.8872548937797546)
[2024-12-17 02:40:44,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,446][root][INFO] - Training Epoch: 2/2, step 782/7134 completed (loss: 0.3679755628108978, acc: 0.905063271522522)
[2024-12-17 02:40:44,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:44,851][root][INFO] - Training Epoch: 2/2, step 783/7134 completed (loss: 0.42423346638679504, acc: 0.8878504633903503)
[2024-12-17 02:40:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,241][root][INFO] - Training Epoch: 2/2, step 784/7134 completed (loss: 0.2348584085702896, acc: 0.9253731369972229)
[2024-12-17 02:40:45,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:45,640][root][INFO] - Training Epoch: 2/2, step 785/7134 completed (loss: 0.37996944785118103, acc: 0.9066666960716248)
[2024-12-17 02:40:45,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,035][root][INFO] - Training Epoch: 2/2, step 786/7134 completed (loss: 0.41425254940986633, acc: 0.89552241563797)
[2024-12-17 02:40:46,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,432][root][INFO] - Training Epoch: 2/2, step 787/7134 completed (loss: 0.1768888533115387, acc: 0.9473684430122375)
[2024-12-17 02:40:46,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:46,809][root][INFO] - Training Epoch: 2/2, step 788/7134 completed (loss: 0.4017840325832367, acc: 0.910614550113678)
[2024-12-17 02:40:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,203][root][INFO] - Training Epoch: 2/2, step 789/7134 completed (loss: 0.3357449769973755, acc: 0.9166666865348816)
[2024-12-17 02:40:47,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,575][root][INFO] - Training Epoch: 2/2, step 790/7134 completed (loss: 0.41106975078582764, acc: 0.8986486196517944)
[2024-12-17 02:40:47,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:47,936][root][INFO] - Training Epoch: 2/2, step 791/7134 completed (loss: 0.45817211270332336, acc: 0.9024389982223511)
[2024-12-17 02:40:48,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,312][root][INFO] - Training Epoch: 2/2, step 792/7134 completed (loss: 0.4122951328754425, acc: 0.8987341523170471)
[2024-12-17 02:40:48,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:48,720][root][INFO] - Training Epoch: 2/2, step 793/7134 completed (loss: 0.266437828540802, acc: 0.9375)
[2024-12-17 02:40:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,117][root][INFO] - Training Epoch: 2/2, step 794/7134 completed (loss: 0.3001706004142761, acc: 0.931034505367279)
[2024-12-17 02:40:49,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,470][root][INFO] - Training Epoch: 2/2, step 795/7134 completed (loss: 0.4216489791870117, acc: 0.8860759735107422)
[2024-12-17 02:40:49,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:49,871][root][INFO] - Training Epoch: 2/2, step 796/7134 completed (loss: 0.3371504247188568, acc: 0.9238095283508301)
[2024-12-17 02:40:49,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,244][root][INFO] - Training Epoch: 2/2, step 797/7134 completed (loss: 0.4233790338039398, acc: 0.9055117964744568)
[2024-12-17 02:40:50,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:50,620][root][INFO] - Training Epoch: 2/2, step 798/7134 completed (loss: 0.2864049971103668, acc: 0.939393937587738)
[2024-12-17 02:40:50,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,000][root][INFO] - Training Epoch: 2/2, step 799/7134 completed (loss: 0.2514590919017792, acc: 0.93388432264328)
[2024-12-17 02:40:51,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,385][root][INFO] - Training Epoch: 2/2, step 800/7134 completed (loss: 0.4848308861255646, acc: 0.8962963223457336)
[2024-12-17 02:40:51,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:51,791][root][INFO] - Training Epoch: 2/2, step 801/7134 completed (loss: 0.44302117824554443, acc: 0.8903225660324097)
[2024-12-17 02:40:51,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,198][root][INFO] - Training Epoch: 2/2, step 802/7134 completed (loss: 0.2678365111351013, acc: 0.936170220375061)
[2024-12-17 02:40:52,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:52,612][root][INFO] - Training Epoch: 2/2, step 803/7134 completed (loss: 0.20342415571212769, acc: 0.9420289993286133)
[2024-12-17 02:40:52,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,012][root][INFO] - Training Epoch: 2/2, step 804/7134 completed (loss: 0.5986281037330627, acc: 0.8527131676673889)
[2024-12-17 02:40:53,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,395][root][INFO] - Training Epoch: 2/2, step 805/7134 completed (loss: 0.4436265528202057, acc: 0.8951048851013184)
[2024-12-17 02:40:53,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:53,770][root][INFO] - Training Epoch: 2/2, step 806/7134 completed (loss: 0.3039698600769043, acc: 0.9135802388191223)
[2024-12-17 02:40:53,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,161][root][INFO] - Training Epoch: 2/2, step 807/7134 completed (loss: 0.3974730372428894, acc: 0.8899999856948853)
[2024-12-17 02:40:54,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,534][root][INFO] - Training Epoch: 2/2, step 808/7134 completed (loss: 0.18715088069438934, acc: 0.9593908786773682)
[2024-12-17 02:40:54,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:54,926][root][INFO] - Training Epoch: 2/2, step 809/7134 completed (loss: 0.29250597953796387, acc: 0.9333333373069763)
[2024-12-17 02:40:55,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,313][root][INFO] - Training Epoch: 2/2, step 810/7134 completed (loss: 0.36048296093940735, acc: 0.9312169551849365)
[2024-12-17 02:40:55,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:55,717][root][INFO] - Training Epoch: 2/2, step 811/7134 completed (loss: 0.4176313877105713, acc: 0.8896551728248596)
[2024-12-17 02:40:55,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,130][root][INFO] - Training Epoch: 2/2, step 812/7134 completed (loss: 0.34839630126953125, acc: 0.9315789341926575)
[2024-12-17 02:40:56,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,519][root][INFO] - Training Epoch: 2/2, step 813/7134 completed (loss: 0.4462788701057434, acc: 0.9235293865203857)
[2024-12-17 02:40:56,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:56,903][root][INFO] - Training Epoch: 2/2, step 814/7134 completed (loss: 0.24654273688793182, acc: 0.9322034120559692)
[2024-12-17 02:40:57,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,282][root][INFO] - Training Epoch: 2/2, step 815/7134 completed (loss: 0.27131062746047974, acc: 0.942307710647583)
[2024-12-17 02:40:57,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:57,669][root][INFO] - Training Epoch: 2/2, step 816/7134 completed (loss: 0.41146430373191833, acc: 0.8865247964859009)
[2024-12-17 02:40:57,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,068][root][INFO] - Training Epoch: 2/2, step 817/7134 completed (loss: 0.5027540922164917, acc: 0.8561151027679443)
[2024-12-17 02:40:58,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,444][root][INFO] - Training Epoch: 2/2, step 818/7134 completed (loss: 0.5511816143989563, acc: 0.8758170008659363)
[2024-12-17 02:40:58,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:58,831][root][INFO] - Training Epoch: 2/2, step 819/7134 completed (loss: 0.4996424615383148, acc: 0.9109588861465454)
[2024-12-17 02:40:58,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,236][root][INFO] - Training Epoch: 2/2, step 820/7134 completed (loss: 0.3512129783630371, acc: 0.9090909361839294)
[2024-12-17 02:40:59,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:40:59,630][root][INFO] - Training Epoch: 2/2, step 821/7134 completed (loss: 0.31179946660995483, acc: 0.9479768872261047)
[2024-12-17 02:40:59,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,020][root][INFO] - Training Epoch: 2/2, step 822/7134 completed (loss: 0.43317562341690063, acc: 0.8734177350997925)
[2024-12-17 02:41:00,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,387][root][INFO] - Training Epoch: 2/2, step 823/7134 completed (loss: 0.2905314266681671, acc: 0.9186992049217224)
[2024-12-17 02:41:00,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:00,762][root][INFO] - Training Epoch: 2/2, step 824/7134 completed (loss: 0.31985512375831604, acc: 0.9242424368858337)
[2024-12-17 02:41:00,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,153][root][INFO] - Training Epoch: 2/2, step 825/7134 completed (loss: 0.2846398651599884, acc: 0.9318181872367859)
[2024-12-17 02:41:01,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,554][root][INFO] - Training Epoch: 2/2, step 826/7134 completed (loss: 0.33950722217559814, acc: 0.9005848169326782)
[2024-12-17 02:41:01,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:01,939][root][INFO] - Training Epoch: 2/2, step 827/7134 completed (loss: 0.35284730792045593, acc: 0.9005848169326782)
[2024-12-17 02:41:02,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,329][root][INFO] - Training Epoch: 2/2, step 828/7134 completed (loss: 0.3392176330089569, acc: 0.9155844449996948)
[2024-12-17 02:41:02,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:02,730][root][INFO] - Training Epoch: 2/2, step 829/7134 completed (loss: 0.41520899534225464, acc: 0.8942307829856873)
[2024-12-17 02:41:02,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,128][root][INFO] - Training Epoch: 2/2, step 830/7134 completed (loss: 0.24462059140205383, acc: 0.9496402740478516)
[2024-12-17 02:41:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,514][root][INFO] - Training Epoch: 2/2, step 831/7134 completed (loss: 0.18861111998558044, acc: 0.9638554453849792)
[2024-12-17 02:41:03,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:03,910][root][INFO] - Training Epoch: 2/2, step 832/7134 completed (loss: 0.46644794940948486, acc: 0.884353756904602)
[2024-12-17 02:41:04,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,306][root][INFO] - Training Epoch: 2/2, step 833/7134 completed (loss: 0.21715572476387024, acc: 0.9404761791229248)
[2024-12-17 02:41:04,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:04,719][root][INFO] - Training Epoch: 2/2, step 834/7134 completed (loss: 0.31878867745399475, acc: 0.9235293865203857)
[2024-12-17 02:41:04,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,106][root][INFO] - Training Epoch: 2/2, step 835/7134 completed (loss: 0.2810874283313751, acc: 0.9356725215911865)
[2024-12-17 02:41:05,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,501][root][INFO] - Training Epoch: 2/2, step 836/7134 completed (loss: 0.2627791464328766, acc: 0.9340101480484009)
[2024-12-17 02:41:05,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:05,873][root][INFO] - Training Epoch: 2/2, step 837/7134 completed (loss: 0.39364737272262573, acc: 0.903954803943634)
[2024-12-17 02:41:06,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,266][root][INFO] - Training Epoch: 2/2, step 838/7134 completed (loss: 0.2911272346973419, acc: 0.9281045794487)
[2024-12-17 02:41:06,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:06,663][root][INFO] - Training Epoch: 2/2, step 839/7134 completed (loss: 0.3320079743862152, acc: 0.9009901285171509)
[2024-12-17 02:41:06,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,033][root][INFO] - Training Epoch: 2/2, step 840/7134 completed (loss: 0.2627490162849426, acc: 0.9341317415237427)
[2024-12-17 02:41:07,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,428][root][INFO] - Training Epoch: 2/2, step 841/7134 completed (loss: 0.2453576624393463, acc: 0.9532163739204407)
[2024-12-17 02:41:07,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:07,848][root][INFO] - Training Epoch: 2/2, step 842/7134 completed (loss: 0.2731912136077881, acc: 0.9352940917015076)
[2024-12-17 02:41:07,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,235][root][INFO] - Training Epoch: 2/2, step 843/7134 completed (loss: 0.18655863404273987, acc: 0.9415204524993896)
[2024-12-17 02:41:08,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,608][root][INFO] - Training Epoch: 2/2, step 844/7134 completed (loss: 0.2038515955209732, acc: 0.9520547986030579)
[2024-12-17 02:41:08,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:08,991][root][INFO] - Training Epoch: 2/2, step 845/7134 completed (loss: 0.22602353990077972, acc: 0.9407407641410828)
[2024-12-17 02:41:09,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,376][root][INFO] - Training Epoch: 2/2, step 846/7134 completed (loss: 0.3089483976364136, acc: 0.9452054500579834)
[2024-12-17 02:41:09,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:09,760][root][INFO] - Training Epoch: 2/2, step 847/7134 completed (loss: 0.3826357424259186, acc: 0.9041916131973267)
[2024-12-17 02:41:09,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,124][root][INFO] - Training Epoch: 2/2, step 848/7134 completed (loss: 0.4261575937271118, acc: 0.8771929740905762)
[2024-12-17 02:41:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,511][root][INFO] - Training Epoch: 2/2, step 849/7134 completed (loss: 0.34181296825408936, acc: 0.9268292784690857)
[2024-12-17 02:41:10,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:10,915][root][INFO] - Training Epoch: 2/2, step 850/7134 completed (loss: 0.20418579876422882, acc: 0.9530201554298401)
[2024-12-17 02:41:11,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,283][root][INFO] - Training Epoch: 2/2, step 851/7134 completed (loss: 0.2973860502243042, acc: 0.9186046719551086)
[2024-12-17 02:41:11,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:11,657][root][INFO] - Training Epoch: 2/2, step 852/7134 completed (loss: 0.2665136754512787, acc: 0.9319371581077576)
[2024-12-17 02:41:11,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,027][root][INFO] - Training Epoch: 2/2, step 853/7134 completed (loss: 0.22446677088737488, acc: 0.9476439952850342)
[2024-12-17 02:41:12,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,414][root][INFO] - Training Epoch: 2/2, step 854/7134 completed (loss: 0.23084498941898346, acc: 0.9390243887901306)
[2024-12-17 02:41:12,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:12,800][root][INFO] - Training Epoch: 2/2, step 855/7134 completed (loss: 0.20338940620422363, acc: 0.9537572264671326)
[2024-12-17 02:41:12,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,158][root][INFO] - Training Epoch: 2/2, step 856/7134 completed (loss: 0.16394618153572083, acc: 0.9672130942344666)
[2024-12-17 02:41:13,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,515][root][INFO] - Training Epoch: 2/2, step 857/7134 completed (loss: 0.3735446333885193, acc: 0.9142857193946838)
[2024-12-17 02:41:13,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:13,884][root][INFO] - Training Epoch: 2/2, step 858/7134 completed (loss: 0.41464763879776, acc: 0.8809523582458496)
[2024-12-17 02:41:13,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,270][root][INFO] - Training Epoch: 2/2, step 859/7134 completed (loss: 0.6090846657752991, acc: 0.8644067645072937)
[2024-12-17 02:41:14,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:14,665][root][INFO] - Training Epoch: 2/2, step 860/7134 completed (loss: 0.7217263579368591, acc: 0.8278145790100098)
[2024-12-17 02:41:14,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,062][root][INFO] - Training Epoch: 2/2, step 861/7134 completed (loss: 0.4460553824901581, acc: 0.9032257795333862)
[2024-12-17 02:41:15,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,417][root][INFO] - Training Epoch: 2/2, step 862/7134 completed (loss: 0.5266523957252502, acc: 0.8628571629524231)
[2024-12-17 02:41:15,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:15,819][root][INFO] - Training Epoch: 2/2, step 863/7134 completed (loss: 0.5725517272949219, acc: 0.8469945192337036)
[2024-12-17 02:41:15,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,212][root][INFO] - Training Epoch: 2/2, step 864/7134 completed (loss: 0.5690722465515137, acc: 0.89682537317276)
[2024-12-17 02:41:16,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,593][root][INFO] - Training Epoch: 2/2, step 865/7134 completed (loss: 0.6456441879272461, acc: 0.8488371968269348)
[2024-12-17 02:41:16,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:16,958][root][INFO] - Training Epoch: 2/2, step 866/7134 completed (loss: 0.4909970462322235, acc: 0.8999999761581421)
[2024-12-17 02:41:17,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,333][root][INFO] - Training Epoch: 2/2, step 867/7134 completed (loss: 0.4536038339138031, acc: 0.9125000238418579)
[2024-12-17 02:41:17,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:17,707][root][INFO] - Training Epoch: 2/2, step 868/7134 completed (loss: 0.6080445051193237, acc: 0.8662790656089783)
[2024-12-17 02:41:17,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,085][root][INFO] - Training Epoch: 2/2, step 869/7134 completed (loss: 0.47327932715415955, acc: 0.891566276550293)
[2024-12-17 02:41:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,470][root][INFO] - Training Epoch: 2/2, step 870/7134 completed (loss: 0.3938283324241638, acc: 0.9005848169326782)
[2024-12-17 02:41:18,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:18,860][root][INFO] - Training Epoch: 2/2, step 871/7134 completed (loss: 0.40306511521339417, acc: 0.9109588861465454)
[2024-12-17 02:41:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,256][root][INFO] - Training Epoch: 2/2, step 872/7134 completed (loss: 0.20206302404403687, acc: 0.9513888955116272)
[2024-12-17 02:41:19,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:19,631][root][INFO] - Training Epoch: 2/2, step 873/7134 completed (loss: 0.4036399722099304, acc: 0.8969696760177612)
[2024-12-17 02:41:19,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,030][root][INFO] - Training Epoch: 2/2, step 874/7134 completed (loss: 0.4652721583843231, acc: 0.8819444179534912)
[2024-12-17 02:41:20,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,395][root][INFO] - Training Epoch: 2/2, step 875/7134 completed (loss: 0.2207198143005371, acc: 0.9424460530281067)
[2024-12-17 02:41:20,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:20,780][root][INFO] - Training Epoch: 2/2, step 876/7134 completed (loss: 0.21167795360088348, acc: 0.9473684430122375)
[2024-12-17 02:41:20,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,179][root][INFO] - Training Epoch: 2/2, step 877/7134 completed (loss: 0.4309760332107544, acc: 0.9141104221343994)
[2024-12-17 02:41:21,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,559][root][INFO] - Training Epoch: 2/2, step 878/7134 completed (loss: 0.3395986258983612, acc: 0.925000011920929)
[2024-12-17 02:41:21,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:21,934][root][INFO] - Training Epoch: 2/2, step 879/7134 completed (loss: 0.40187451243400574, acc: 0.8980891704559326)
[2024-12-17 02:41:22,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,297][root][INFO] - Training Epoch: 2/2, step 880/7134 completed (loss: 0.2334262579679489, acc: 0.9386503100395203)
[2024-12-17 02:41:22,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,628][root][INFO] - Training Epoch: 2/2, step 881/7134 completed (loss: 0.3736094832420349, acc: 0.9024389982223511)
[2024-12-17 02:41:22,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:22,998][root][INFO] - Training Epoch: 2/2, step 882/7134 completed (loss: 0.24418631196022034, acc: 0.9435483813285828)
[2024-12-17 02:41:23,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,352][root][INFO] - Training Epoch: 2/2, step 883/7134 completed (loss: 0.5884763598442078, acc: 0.875)
[2024-12-17 02:41:23,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:23,729][root][INFO] - Training Epoch: 2/2, step 884/7134 completed (loss: 0.4556746780872345, acc: 0.8622754216194153)
[2024-12-17 02:41:23,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,130][root][INFO] - Training Epoch: 2/2, step 885/7134 completed (loss: 0.19729012250900269, acc: 0.9451219439506531)
[2024-12-17 02:41:24,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,513][root][INFO] - Training Epoch: 2/2, step 886/7134 completed (loss: 0.3210783302783966, acc: 0.9327731132507324)
[2024-12-17 02:41:24,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:24,907][root][INFO] - Training Epoch: 2/2, step 887/7134 completed (loss: 0.2507205605506897, acc: 0.9402984976768494)
[2024-12-17 02:41:25,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,296][root][INFO] - Training Epoch: 2/2, step 888/7134 completed (loss: 0.3947208821773529, acc: 0.9328858852386475)
[2024-12-17 02:41:25,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:25,624][root][INFO] - Training Epoch: 2/2, step 889/7134 completed (loss: 0.2603887915611267, acc: 0.9306930899620056)
[2024-12-17 02:41:25,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,004][root][INFO] - Training Epoch: 2/2, step 890/7134 completed (loss: 0.2990802228450775, acc: 0.9060402512550354)
[2024-12-17 02:41:26,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,367][root][INFO] - Training Epoch: 2/2, step 891/7134 completed (loss: 0.38113608956336975, acc: 0.9385474920272827)
[2024-12-17 02:41:26,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:26,762][root][INFO] - Training Epoch: 2/2, step 892/7134 completed (loss: 0.2666083574295044, acc: 0.9464285969734192)
[2024-12-17 02:41:26,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,149][root][INFO] - Training Epoch: 2/2, step 893/7134 completed (loss: 0.32993659377098083, acc: 0.915032684803009)
[2024-12-17 02:41:27,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,528][root][INFO] - Training Epoch: 2/2, step 894/7134 completed (loss: 0.1070469468832016, acc: 0.9774011373519897)
[2024-12-17 02:41:27,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:27,917][root][INFO] - Training Epoch: 2/2, step 895/7134 completed (loss: 0.1598801165819168, acc: 0.965753436088562)
[2024-12-17 02:41:28,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,288][root][INFO] - Training Epoch: 2/2, step 896/7134 completed (loss: 0.22039811313152313, acc: 0.9370078444480896)
[2024-12-17 02:41:28,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:28,678][root][INFO] - Training Epoch: 2/2, step 897/7134 completed (loss: 0.24290317296981812, acc: 0.9553072452545166)
[2024-12-17 02:41:28,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,082][root][INFO] - Training Epoch: 2/2, step 898/7134 completed (loss: 0.3805672824382782, acc: 0.9034090638160706)
[2024-12-17 02:41:29,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,451][root][INFO] - Training Epoch: 2/2, step 899/7134 completed (loss: 0.35944199562072754, acc: 0.9144384860992432)
[2024-12-17 02:41:29,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:29,814][root][INFO] - Training Epoch: 2/2, step 900/7134 completed (loss: 0.18689465522766113, acc: 0.9512194991111755)
[2024-12-17 02:41:29,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,188][root][INFO] - Training Epoch: 2/2, step 901/7134 completed (loss: 0.3731510639190674, acc: 0.898809552192688)
[2024-12-17 02:41:30,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,529][root][INFO] - Training Epoch: 2/2, step 902/7134 completed (loss: 0.29933133721351624, acc: 0.9285714030265808)
[2024-12-17 02:41:30,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:30,910][root][INFO] - Training Epoch: 2/2, step 903/7134 completed (loss: 0.11498110741376877, acc: 0.9710982441902161)
[2024-12-17 02:41:31,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,313][root][INFO] - Training Epoch: 2/2, step 904/7134 completed (loss: 0.33015677332878113, acc: 0.9209039807319641)
[2024-12-17 02:41:31,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:31,703][root][INFO] - Training Epoch: 2/2, step 905/7134 completed (loss: 0.2053796648979187, acc: 0.9425287246704102)
[2024-12-17 02:41:31,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,057][root][INFO] - Training Epoch: 2/2, step 906/7134 completed (loss: 0.19553309679031372, acc: 0.9558011293411255)
[2024-12-17 02:41:32,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,429][root][INFO] - Training Epoch: 2/2, step 907/7134 completed (loss: 0.26607802510261536, acc: 0.9301075339317322)
[2024-12-17 02:41:32,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:32,793][root][INFO] - Training Epoch: 2/2, step 908/7134 completed (loss: 0.22502288222312927, acc: 0.9388889074325562)
[2024-12-17 02:41:32,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,152][root][INFO] - Training Epoch: 2/2, step 909/7134 completed (loss: 0.17403605580329895, acc: 0.9605262875556946)
[2024-12-17 02:41:33,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,553][root][INFO] - Training Epoch: 2/2, step 910/7134 completed (loss: 0.29125863313674927, acc: 0.925000011920929)
[2024-12-17 02:41:33,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:33,942][root][INFO] - Training Epoch: 2/2, step 911/7134 completed (loss: 0.30038154125213623, acc: 0.9419354796409607)
[2024-12-17 02:41:34,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,338][root][INFO] - Training Epoch: 2/2, step 912/7134 completed (loss: 0.2735384404659271, acc: 0.9526315927505493)
[2024-12-17 02:41:34,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:34,729][root][INFO] - Training Epoch: 2/2, step 913/7134 completed (loss: 0.17423391342163086, acc: 0.9560439586639404)
[2024-12-17 02:41:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,118][root][INFO] - Training Epoch: 2/2, step 914/7134 completed (loss: 0.2508174180984497, acc: 0.9333333373069763)
[2024-12-17 02:41:35,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,506][root][INFO] - Training Epoch: 2/2, step 915/7134 completed (loss: 0.32227542996406555, acc: 0.9285714030265808)
[2024-12-17 02:41:35,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:35,863][root][INFO] - Training Epoch: 2/2, step 916/7134 completed (loss: 0.17753654718399048, acc: 0.9457364082336426)
[2024-12-17 02:41:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,222][root][INFO] - Training Epoch: 2/2, step 917/7134 completed (loss: 0.36906442046165466, acc: 0.9025974273681641)
[2024-12-17 02:41:36,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,603][root][INFO] - Training Epoch: 2/2, step 918/7134 completed (loss: 0.3143651485443115, acc: 0.9337748289108276)
[2024-12-17 02:41:36,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:36,953][root][INFO] - Training Epoch: 2/2, step 919/7134 completed (loss: 0.17006537318229675, acc: 0.9610389471054077)
[2024-12-17 02:41:37,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,325][root][INFO] - Training Epoch: 2/2, step 920/7134 completed (loss: 0.2090379148721695, acc: 0.9534883499145508)
[2024-12-17 02:41:37,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:37,704][root][INFO] - Training Epoch: 2/2, step 921/7134 completed (loss: 0.2637518644332886, acc: 0.9356725215911865)
[2024-12-17 02:41:37,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,092][root][INFO] - Training Epoch: 2/2, step 922/7134 completed (loss: 0.16698846220970154, acc: 0.9626865386962891)
[2024-12-17 02:41:38,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,455][root][INFO] - Training Epoch: 2/2, step 923/7134 completed (loss: 0.20652318000793457, acc: 0.9473684430122375)
[2024-12-17 02:41:38,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:38,844][root][INFO] - Training Epoch: 2/2, step 924/7134 completed (loss: 0.17012107372283936, acc: 0.9604519605636597)
[2024-12-17 02:41:38,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,215][root][INFO] - Training Epoch: 2/2, step 925/7134 completed (loss: 0.6092650890350342, acc: 0.8580645322799683)
[2024-12-17 02:41:39,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,605][root][INFO] - Training Epoch: 2/2, step 926/7134 completed (loss: 0.3021908104419708, acc: 0.9388889074325562)
[2024-12-17 02:41:39,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:39,980][root][INFO] - Training Epoch: 2/2, step 927/7134 completed (loss: 0.30778267979621887, acc: 0.9208633303642273)
[2024-12-17 02:41:40,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,377][root][INFO] - Training Epoch: 2/2, step 928/7134 completed (loss: 0.11112640798091888, acc: 0.9816513657569885)
[2024-12-17 02:41:40,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:40,769][root][INFO] - Training Epoch: 2/2, step 929/7134 completed (loss: 0.25656062364578247, acc: 0.9605262875556946)
[2024-12-17 02:41:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,167][root][INFO] - Training Epoch: 2/2, step 930/7134 completed (loss: 0.5029636025428772, acc: 0.8870967626571655)
[2024-12-17 02:41:41,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,548][root][INFO] - Training Epoch: 2/2, step 931/7134 completed (loss: 0.3093174993991852, acc: 0.904411792755127)
[2024-12-17 02:41:41,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:41,933][root][INFO] - Training Epoch: 2/2, step 932/7134 completed (loss: 0.22901798784732819, acc: 0.9464285969734192)
[2024-12-17 02:41:42,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,320][root][INFO] - Training Epoch: 2/2, step 933/7134 completed (loss: 0.29963093996047974, acc: 0.9041916131973267)
[2024-12-17 02:41:42,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:42,681][root][INFO] - Training Epoch: 2/2, step 934/7134 completed (loss: 0.22930364310741425, acc: 0.9360465407371521)
[2024-12-17 02:41:42,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,074][root][INFO] - Training Epoch: 2/2, step 935/7134 completed (loss: 0.2459954172372818, acc: 0.9224806427955627)
[2024-12-17 02:41:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,468][root][INFO] - Training Epoch: 2/2, step 936/7134 completed (loss: 0.24095091223716736, acc: 0.9448819160461426)
[2024-12-17 02:41:43,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:43,870][root][INFO] - Training Epoch: 2/2, step 937/7134 completed (loss: 0.28591418266296387, acc: 0.9268292784690857)
[2024-12-17 02:41:43,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,220][root][INFO] - Training Epoch: 2/2, step 938/7134 completed (loss: 0.24077346920967102, acc: 0.9230769276618958)
[2024-12-17 02:41:44,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,572][root][INFO] - Training Epoch: 2/2, step 939/7134 completed (loss: 0.3449970483779907, acc: 0.9268292784690857)
[2024-12-17 02:41:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:44,960][root][INFO] - Training Epoch: 2/2, step 940/7134 completed (loss: 0.2924990952014923, acc: 0.9306358098983765)
[2024-12-17 02:41:45,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,358][root][INFO] - Training Epoch: 2/2, step 941/7134 completed (loss: 0.2680690586566925, acc: 0.9438202381134033)
[2024-12-17 02:41:45,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:45,753][root][INFO] - Training Epoch: 2/2, step 942/7134 completed (loss: 0.3601289689540863, acc: 0.9127907156944275)
[2024-12-17 02:41:45,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,133][root][INFO] - Training Epoch: 2/2, step 943/7134 completed (loss: 0.24813653528690338, acc: 0.9447852969169617)
[2024-12-17 02:41:46,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,476][root][INFO] - Training Epoch: 2/2, step 944/7134 completed (loss: 0.2347891479730606, acc: 0.9490445852279663)
[2024-12-17 02:41:46,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:46,860][root][INFO] - Training Epoch: 2/2, step 945/7134 completed (loss: 0.24229975044727325, acc: 0.940397322177887)
[2024-12-17 02:41:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,232][root][INFO] - Training Epoch: 2/2, step 946/7134 completed (loss: 0.18671265244483948, acc: 0.9417475461959839)
[2024-12-17 02:41:47,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:47,624][root][INFO] - Training Epoch: 2/2, step 947/7134 completed (loss: 0.4439440369606018, acc: 0.8897058963775635)
[2024-12-17 02:41:47,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,012][root][INFO] - Training Epoch: 2/2, step 948/7134 completed (loss: 0.1720297783613205, acc: 0.9457831382751465)
[2024-12-17 02:41:48,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,409][root][INFO] - Training Epoch: 2/2, step 949/7134 completed (loss: 0.27485406398773193, acc: 0.918749988079071)
[2024-12-17 02:41:48,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:48,760][root][INFO] - Training Epoch: 2/2, step 950/7134 completed (loss: 0.2789147198200226, acc: 0.9220778942108154)
[2024-12-17 02:41:48,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,134][root][INFO] - Training Epoch: 2/2, step 951/7134 completed (loss: 0.23252159357070923, acc: 0.9236640930175781)
[2024-12-17 02:41:49,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,520][root][INFO] - Training Epoch: 2/2, step 952/7134 completed (loss: 0.3793509900569916, acc: 0.904411792755127)
[2024-12-17 02:41:49,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:49,905][root][INFO] - Training Epoch: 2/2, step 953/7134 completed (loss: 0.3629016578197479, acc: 0.9085366129875183)
[2024-12-17 02:41:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,281][root][INFO] - Training Epoch: 2/2, step 954/7134 completed (loss: 0.33943432569503784, acc: 0.931034505367279)
[2024-12-17 02:41:50,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:50,664][root][INFO] - Training Epoch: 2/2, step 955/7134 completed (loss: 0.30615347623825073, acc: 0.9378530979156494)
[2024-12-17 02:41:50,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,021][root][INFO] - Training Epoch: 2/2, step 956/7134 completed (loss: 0.32091906666755676, acc: 0.9402173757553101)
[2024-12-17 02:41:51,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,385][root][INFO] - Training Epoch: 2/2, step 957/7134 completed (loss: 0.33266255259513855, acc: 0.9411764740943909)
[2024-12-17 02:41:51,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:51,773][root][INFO] - Training Epoch: 2/2, step 958/7134 completed (loss: 0.4339311122894287, acc: 0.9104477763175964)
[2024-12-17 02:41:51,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,169][root][INFO] - Training Epoch: 2/2, step 959/7134 completed (loss: 0.3464628756046295, acc: 0.9278350472450256)
[2024-12-17 02:41:52,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,539][root][INFO] - Training Epoch: 2/2, step 960/7134 completed (loss: 0.5041607618331909, acc: 0.888059675693512)
[2024-12-17 02:41:52,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:52,923][root][INFO] - Training Epoch: 2/2, step 961/7134 completed (loss: 0.45090535283088684, acc: 0.9120879173278809)
[2024-12-17 02:41:53,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,306][root][INFO] - Training Epoch: 2/2, step 962/7134 completed (loss: 0.4686323404312134, acc: 0.8947368264198303)
[2024-12-17 02:41:53,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:53,691][root][INFO] - Training Epoch: 2/2, step 963/7134 completed (loss: 0.3862640857696533, acc: 0.9011628031730652)
[2024-12-17 02:41:53,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,074][root][INFO] - Training Epoch: 2/2, step 964/7134 completed (loss: 0.5761533379554749, acc: 0.8841463327407837)
[2024-12-17 02:41:54,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,443][root][INFO] - Training Epoch: 2/2, step 965/7134 completed (loss: 0.516022801399231, acc: 0.8823529481887817)
[2024-12-17 02:41:54,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:54,812][root][INFO] - Training Epoch: 2/2, step 966/7134 completed (loss: 0.37349942326545715, acc: 0.9141104221343994)
[2024-12-17 02:41:54,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,203][root][INFO] - Training Epoch: 2/2, step 967/7134 completed (loss: 0.23554208874702454, acc: 0.9308510422706604)
[2024-12-17 02:41:55,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,553][root][INFO] - Training Epoch: 2/2, step 968/7134 completed (loss: 0.42613786458969116, acc: 0.8721804618835449)
[2024-12-17 02:41:55,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:55,879][root][INFO] - Training Epoch: 2/2, step 969/7134 completed (loss: 0.31062835454940796, acc: 0.9314285516738892)
[2024-12-17 02:41:55,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,244][root][INFO] - Training Epoch: 2/2, step 970/7134 completed (loss: 0.526163637638092, acc: 0.8823529481887817)
[2024-12-17 02:41:56,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,607][root][INFO] - Training Epoch: 2/2, step 971/7134 completed (loss: 0.41310784220695496, acc: 0.8909952640533447)
[2024-12-17 02:41:56,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:56,985][root][INFO] - Training Epoch: 2/2, step 972/7134 completed (loss: 0.5327553153038025, acc: 0.8717948794364929)
[2024-12-17 02:41:57,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,353][root][INFO] - Training Epoch: 2/2, step 973/7134 completed (loss: 0.4397384226322174, acc: 0.8901098966598511)
[2024-12-17 02:41:57,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:57,744][root][INFO] - Training Epoch: 2/2, step 974/7134 completed (loss: 0.3646095097064972, acc: 0.9108911156654358)
[2024-12-17 02:41:57,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,109][root][INFO] - Training Epoch: 2/2, step 975/7134 completed (loss: 0.3639657497406006, acc: 0.9202127456665039)
[2024-12-17 02:41:58,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,504][root][INFO] - Training Epoch: 2/2, step 976/7134 completed (loss: 0.20424742996692657, acc: 0.940397322177887)
[2024-12-17 02:41:58,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:58,867][root][INFO] - Training Epoch: 2/2, step 977/7134 completed (loss: 0.5060343146324158, acc: 0.882022500038147)
[2024-12-17 02:41:58,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,264][root][INFO] - Training Epoch: 2/2, step 978/7134 completed (loss: 0.2024136781692505, acc: 0.9639175534248352)
[2024-12-17 02:41:59,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:41:59,671][root][INFO] - Training Epoch: 2/2, step 979/7134 completed (loss: 0.36529242992401123, acc: 0.9243243336677551)
[2024-12-17 02:41:59,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,063][root][INFO] - Training Epoch: 2/2, step 980/7134 completed (loss: 0.2747412323951721, acc: 0.9295774698257446)
[2024-12-17 02:42:00,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,396][root][INFO] - Training Epoch: 2/2, step 981/7134 completed (loss: 0.4232034385204315, acc: 0.9308176040649414)
[2024-12-17 02:42:00,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:00,854][root][INFO] - Training Epoch: 2/2, step 982/7134 completed (loss: 0.5586013197898865, acc: 0.8914285898208618)
[2024-12-17 02:42:00,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,262][root][INFO] - Training Epoch: 2/2, step 983/7134 completed (loss: 0.34293970465660095, acc: 0.9248120188713074)
[2024-12-17 02:42:01,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:01,655][root][INFO] - Training Epoch: 2/2, step 984/7134 completed (loss: 0.2786094546318054, acc: 0.957446813583374)
[2024-12-17 02:42:01,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,027][root][INFO] - Training Epoch: 2/2, step 985/7134 completed (loss: 0.22797296941280365, acc: 0.9555555582046509)
[2024-12-17 02:42:02,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,397][root][INFO] - Training Epoch: 2/2, step 986/7134 completed (loss: 0.1681351214647293, acc: 0.9553072452545166)
[2024-12-17 02:42:02,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:02,737][root][INFO] - Training Epoch: 2/2, step 987/7134 completed (loss: 0.20345258712768555, acc: 0.9463087320327759)
[2024-12-17 02:42:02,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,130][root][INFO] - Training Epoch: 2/2, step 988/7134 completed (loss: 0.4926789700984955, acc: 0.8983050584793091)
[2024-12-17 02:42:03,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,523][root][INFO] - Training Epoch: 2/2, step 989/7134 completed (loss: 0.40884003043174744, acc: 0.9018405079841614)
[2024-12-17 02:42:03,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:03,912][root][INFO] - Training Epoch: 2/2, step 990/7134 completed (loss: 0.35409650206565857, acc: 0.8901098966598511)
[2024-12-17 02:42:03,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,281][root][INFO] - Training Epoch: 2/2, step 991/7134 completed (loss: 0.6274948716163635, acc: 0.8742138147354126)
[2024-12-17 02:42:04,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:04,676][root][INFO] - Training Epoch: 2/2, step 992/7134 completed (loss: 0.35283738374710083, acc: 0.9190751314163208)
[2024-12-17 02:42:04,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,022][root][INFO] - Training Epoch: 2/2, step 993/7134 completed (loss: 0.39711833000183105, acc: 0.8776978254318237)
[2024-12-17 02:42:05,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,416][root][INFO] - Training Epoch: 2/2, step 994/7134 completed (loss: 0.3483525514602661, acc: 0.9029126167297363)
[2024-12-17 02:42:05,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:05,799][root][INFO] - Training Epoch: 2/2, step 995/7134 completed (loss: 0.2617797553539276, acc: 0.9387755393981934)
[2024-12-17 02:42:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,184][root][INFO] - Training Epoch: 2/2, step 996/7134 completed (loss: 0.39473968744277954, acc: 0.9360465407371521)
[2024-12-17 02:42:06,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,547][root][INFO] - Training Epoch: 2/2, step 997/7134 completed (loss: 0.19652804732322693, acc: 0.9588235020637512)
[2024-12-17 02:42:06,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:06,932][root][INFO] - Training Epoch: 2/2, step 998/7134 completed (loss: 0.3065739572048187, acc: 0.9221556782722473)
[2024-12-17 02:42:07,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,300][root][INFO] - Training Epoch: 2/2, step 999/7134 completed (loss: 0.24324724078178406, acc: 0.9692307710647583)
[2024-12-17 02:42:07,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:07,674][root][INFO] - Training Epoch: 2/2, step 1000/7134 completed (loss: 0.27819952368736267, acc: 0.9338235259056091)
[2024-12-17 02:42:07,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,053][root][INFO] - Training Epoch: 2/2, step 1001/7134 completed (loss: 0.2592169940471649, acc: 0.9454545378684998)
[2024-12-17 02:42:08,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,440][root][INFO] - Training Epoch: 2/2, step 1002/7134 completed (loss: 0.2367517054080963, acc: 0.955974817276001)
[2024-12-17 02:42:08,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:08,814][root][INFO] - Training Epoch: 2/2, step 1003/7134 completed (loss: 0.257913202047348, acc: 0.9444444179534912)
[2024-12-17 02:42:08,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,200][root][INFO] - Training Epoch: 2/2, step 1004/7134 completed (loss: 0.3088795244693756, acc: 0.9292035102844238)
[2024-12-17 02:42:09,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,591][root][INFO] - Training Epoch: 2/2, step 1005/7134 completed (loss: 0.37100380659103394, acc: 0.9078013896942139)
[2024-12-17 02:42:09,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:09,991][root][INFO] - Training Epoch: 2/2, step 1006/7134 completed (loss: 0.3918898403644562, acc: 0.8917197585105896)
[2024-12-17 02:42:10,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,372][root][INFO] - Training Epoch: 2/2, step 1007/7134 completed (loss: 0.45609599351882935, acc: 0.8732394576072693)
[2024-12-17 02:42:10,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:10,781][root][INFO] - Training Epoch: 2/2, step 1008/7134 completed (loss: 0.24222584068775177, acc: 0.9444444179534912)
[2024-12-17 02:42:10,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,179][root][INFO] - Training Epoch: 2/2, step 1009/7134 completed (loss: 0.23114891350269318, acc: 0.961240291595459)
[2024-12-17 02:42:11,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,573][root][INFO] - Training Epoch: 2/2, step 1010/7134 completed (loss: 0.3434188663959503, acc: 0.8888888955116272)
[2024-12-17 02:42:11,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:11,969][root][INFO] - Training Epoch: 2/2, step 1011/7134 completed (loss: 0.3528842031955719, acc: 0.9056603908538818)
[2024-12-17 02:42:12,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,332][root][INFO] - Training Epoch: 2/2, step 1012/7134 completed (loss: 0.5889492034912109, acc: 0.8999999761581421)
[2024-12-17 02:42:12,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:12,732][root][INFO] - Training Epoch: 2/2, step 1013/7134 completed (loss: 0.5029717683792114, acc: 0.8855421543121338)
[2024-12-17 02:42:12,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,126][root][INFO] - Training Epoch: 2/2, step 1014/7134 completed (loss: 0.29849115014076233, acc: 0.9503546357154846)
[2024-12-17 02:42:13,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,512][root][INFO] - Training Epoch: 2/2, step 1015/7134 completed (loss: 0.2715824544429779, acc: 0.9470198750495911)
[2024-12-17 02:42:13,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:13,873][root][INFO] - Training Epoch: 2/2, step 1016/7134 completed (loss: 0.132389098405838, acc: 0.9747899174690247)
[2024-12-17 02:42:14,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,262][root][INFO] - Training Epoch: 2/2, step 1017/7134 completed (loss: 0.3553633987903595, acc: 0.9085714221000671)
[2024-12-17 02:42:14,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:14,633][root][INFO] - Training Epoch: 2/2, step 1018/7134 completed (loss: 0.42155689001083374, acc: 0.9068322777748108)
[2024-12-17 02:42:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,066][root][INFO] - Training Epoch: 2/2, step 1019/7134 completed (loss: 0.3035884499549866, acc: 0.9220778942108154)
[2024-12-17 02:42:15,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,424][root][INFO] - Training Epoch: 2/2, step 1020/7134 completed (loss: 0.20871928334236145, acc: 0.9490445852279663)
[2024-12-17 02:42:15,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:15,821][root][INFO] - Training Epoch: 2/2, step 1021/7134 completed (loss: 0.17867344617843628, acc: 0.9673202633857727)
[2024-12-17 02:42:15,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,193][root][INFO] - Training Epoch: 2/2, step 1022/7134 completed (loss: 0.0772228091955185, acc: 0.9653179049491882)
[2024-12-17 02:42:16,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,542][root][INFO] - Training Epoch: 2/2, step 1023/7134 completed (loss: 0.235926553606987, acc: 0.9497206807136536)
[2024-12-17 02:42:16,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:16,902][root][INFO] - Training Epoch: 2/2, step 1024/7134 completed (loss: 0.2496732771396637, acc: 0.9402984976768494)
[2024-12-17 02:42:17,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,263][root][INFO] - Training Epoch: 2/2, step 1025/7134 completed (loss: 0.19216930866241455, acc: 0.957446813583374)
[2024-12-17 02:42:17,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,608][root][INFO] - Training Epoch: 2/2, step 1026/7134 completed (loss: 0.49384018778800964, acc: 0.8584070801734924)
[2024-12-17 02:42:17,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:17,987][root][INFO] - Training Epoch: 2/2, step 1027/7134 completed (loss: 0.12049786001443863, acc: 0.9764705896377563)
[2024-12-17 02:42:18,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,383][root][INFO] - Training Epoch: 2/2, step 1028/7134 completed (loss: 0.12526097893714905, acc: 0.9748427867889404)
[2024-12-17 02:42:18,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:18,746][root][INFO] - Training Epoch: 2/2, step 1029/7134 completed (loss: 0.15489672124385834, acc: 0.9567901492118835)
[2024-12-17 02:42:18,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,134][root][INFO] - Training Epoch: 2/2, step 1030/7134 completed (loss: 0.11651381105184555, acc: 0.959770143032074)
[2024-12-17 02:42:19,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,497][root][INFO] - Training Epoch: 2/2, step 1031/7134 completed (loss: 0.284108430147171, acc: 0.9192546606063843)
[2024-12-17 02:42:19,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:19,888][root][INFO] - Training Epoch: 2/2, step 1032/7134 completed (loss: 0.2120671570301056, acc: 0.9468085169792175)
[2024-12-17 02:42:19,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,278][root][INFO] - Training Epoch: 2/2, step 1033/7134 completed (loss: 0.23342177271842957, acc: 0.931506872177124)
[2024-12-17 02:42:20,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:20,658][root][INFO] - Training Epoch: 2/2, step 1034/7134 completed (loss: 0.4618697166442871, acc: 0.8896104097366333)
[2024-12-17 02:42:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,076][root][INFO] - Training Epoch: 2/2, step 1035/7134 completed (loss: 0.720604658126831, acc: 0.8310810923576355)
[2024-12-17 02:42:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,471][root][INFO] - Training Epoch: 2/2, step 1036/7134 completed (loss: 0.7249655723571777, acc: 0.8474576473236084)
[2024-12-17 02:42:21,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:21,869][root][INFO] - Training Epoch: 2/2, step 1037/7134 completed (loss: 0.15542855858802795, acc: 0.957446813583374)
[2024-12-17 02:42:21,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,246][root][INFO] - Training Epoch: 2/2, step 1038/7134 completed (loss: 0.2586101293563843, acc: 0.9359999895095825)
[2024-12-17 02:42:22,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:22,643][root][INFO] - Training Epoch: 2/2, step 1039/7134 completed (loss: 0.2922998368740082, acc: 0.9174311757087708)
[2024-12-17 02:42:22,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,061][root][INFO] - Training Epoch: 2/2, step 1040/7134 completed (loss: 0.13106539845466614, acc: 0.95652174949646)
[2024-12-17 02:42:23,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,425][root][INFO] - Training Epoch: 2/2, step 1041/7134 completed (loss: 0.1775730848312378, acc: 0.9664429426193237)
[2024-12-17 02:42:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:23,812][root][INFO] - Training Epoch: 2/2, step 1042/7134 completed (loss: 0.33295804262161255, acc: 0.9217877388000488)
[2024-12-17 02:42:23,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,174][root][INFO] - Training Epoch: 2/2, step 1043/7134 completed (loss: 0.2789240777492523, acc: 0.9257425665855408)
[2024-12-17 02:42:24,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,503][root][INFO] - Training Epoch: 2/2, step 1044/7134 completed (loss: 0.11351384222507477, acc: 0.9813664555549622)
[2024-12-17 02:42:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:24,871][root][INFO] - Training Epoch: 2/2, step 1045/7134 completed (loss: 0.6611932516098022, acc: 0.8385093212127686)
[2024-12-17 02:42:24,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,264][root][INFO] - Training Epoch: 2/2, step 1046/7134 completed (loss: 0.49166324734687805, acc: 0.8646616339683533)
[2024-12-17 02:42:25,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:25,664][root][INFO] - Training Epoch: 2/2, step 1047/7134 completed (loss: 0.5033997297286987, acc: 0.8971428275108337)
[2024-12-17 02:42:25,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,108][root][INFO] - Training Epoch: 2/2, step 1048/7134 completed (loss: 0.2650269865989685, acc: 0.9554139971733093)
[2024-12-17 02:42:26,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,495][root][INFO] - Training Epoch: 2/2, step 1049/7134 completed (loss: 0.2943553328514099, acc: 0.9407894611358643)
[2024-12-17 02:42:26,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:26,887][root][INFO] - Training Epoch: 2/2, step 1050/7134 completed (loss: 0.4315381348133087, acc: 0.8802083134651184)
[2024-12-17 02:42:26,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,277][root][INFO] - Training Epoch: 2/2, step 1051/7134 completed (loss: 0.2260836511850357, acc: 0.9428571462631226)
[2024-12-17 02:42:27,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:27,613][root][INFO] - Training Epoch: 2/2, step 1052/7134 completed (loss: 0.33486437797546387, acc: 0.9216867685317993)
[2024-12-17 02:42:27,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,003][root][INFO] - Training Epoch: 2/2, step 1053/7134 completed (loss: 0.29936784505844116, acc: 0.946107804775238)
[2024-12-17 02:42:28,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,382][root][INFO] - Training Epoch: 2/2, step 1054/7134 completed (loss: 0.20238977670669556, acc: 0.953125)
[2024-12-17 02:42:28,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:28,770][root][INFO] - Training Epoch: 2/2, step 1055/7134 completed (loss: 0.24989886581897736, acc: 0.9236640930175781)
[2024-12-17 02:42:28,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,150][root][INFO] - Training Epoch: 2/2, step 1056/7134 completed (loss: 0.33061540126800537, acc: 0.930232584476471)
[2024-12-17 02:42:29,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,538][root][INFO] - Training Epoch: 2/2, step 1057/7134 completed (loss: 0.34430980682373047, acc: 0.9170984625816345)
[2024-12-17 02:42:29,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:29,947][root][INFO] - Training Epoch: 2/2, step 1058/7134 completed (loss: 0.22996786236763, acc: 0.9526315927505493)
[2024-12-17 02:42:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,343][root][INFO] - Training Epoch: 2/2, step 1059/7134 completed (loss: 0.1827782392501831, acc: 0.9763033390045166)
[2024-12-17 02:42:30,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:30,733][root][INFO] - Training Epoch: 2/2, step 1060/7134 completed (loss: 0.2944606840610504, acc: 0.9358974099159241)
[2024-12-17 02:42:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,118][root][INFO] - Training Epoch: 2/2, step 1061/7134 completed (loss: 0.2662803530693054, acc: 0.9432989954948425)
[2024-12-17 02:42:31,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,506][root][INFO] - Training Epoch: 2/2, step 1062/7134 completed (loss: 0.30442512035369873, acc: 0.8975903391838074)
[2024-12-17 02:42:31,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:31,893][root][INFO] - Training Epoch: 2/2, step 1063/7134 completed (loss: 0.16796377301216125, acc: 0.970588207244873)
[2024-12-17 02:42:32,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,282][root][INFO] - Training Epoch: 2/2, step 1064/7134 completed (loss: 0.3058687746524811, acc: 0.9135135412216187)
[2024-12-17 02:42:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:32,669][root][INFO] - Training Epoch: 2/2, step 1065/7134 completed (loss: 0.29274940490722656, acc: 0.9337016344070435)
[2024-12-17 02:42:32,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,030][root][INFO] - Training Epoch: 2/2, step 1066/7134 completed (loss: 0.5339283347129822, acc: 0.9083969593048096)
[2024-12-17 02:42:33,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,400][root][INFO] - Training Epoch: 2/2, step 1067/7134 completed (loss: 0.20420043170452118, acc: 0.9411764740943909)
[2024-12-17 02:42:33,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:33,792][root][INFO] - Training Epoch: 2/2, step 1068/7134 completed (loss: 0.37446948885917664, acc: 0.9140625)
[2024-12-17 02:42:33,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,204][root][INFO] - Training Epoch: 2/2, step 1069/7134 completed (loss: 0.31462758779525757, acc: 0.9166666865348816)
[2024-12-17 02:42:34,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,533][root][INFO] - Training Epoch: 2/2, step 1070/7134 completed (loss: 0.4166830778121948, acc: 0.9041095972061157)
[2024-12-17 02:42:34,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:34,912][root][INFO] - Training Epoch: 2/2, step 1071/7134 completed (loss: 0.19476255774497986, acc: 0.956250011920929)
[2024-12-17 02:42:35,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,299][root][INFO] - Training Epoch: 2/2, step 1072/7134 completed (loss: 0.09559643268585205, acc: 0.9756097793579102)
[2024-12-17 02:42:35,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:35,687][root][INFO] - Training Epoch: 2/2, step 1073/7134 completed (loss: 0.1433643251657486, acc: 0.9751552939414978)
[2024-12-17 02:42:35,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,077][root][INFO] - Training Epoch: 2/2, step 1074/7134 completed (loss: 0.24346579611301422, acc: 0.9503546357154846)
[2024-12-17 02:42:36,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,464][root][INFO] - Training Epoch: 2/2, step 1075/7134 completed (loss: 0.5777000188827515, acc: 0.8686131238937378)
[2024-12-17 02:42:36,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:36,832][root][INFO] - Training Epoch: 2/2, step 1076/7134 completed (loss: 0.5517277121543884, acc: 0.8617021441459656)
[2024-12-17 02:42:36,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,178][root][INFO] - Training Epoch: 2/2, step 1077/7134 completed (loss: 0.34895604848861694, acc: 0.9292035102844238)
[2024-12-17 02:42:37,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,561][root][INFO] - Training Epoch: 2/2, step 1078/7134 completed (loss: 0.5443640947341919, acc: 0.8616352081298828)
[2024-12-17 02:42:37,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:37,930][root][INFO] - Training Epoch: 2/2, step 1079/7134 completed (loss: 0.3104704022407532, acc: 0.9170507192611694)
[2024-12-17 02:42:38,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,274][root][INFO] - Training Epoch: 2/2, step 1080/7134 completed (loss: 0.30569204688072205, acc: 0.9379844665527344)
[2024-12-17 02:42:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:38,656][root][INFO] - Training Epoch: 2/2, step 1081/7134 completed (loss: 0.295472651720047, acc: 0.9277108311653137)
[2024-12-17 02:42:38,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,056][root][INFO] - Training Epoch: 2/2, step 1082/7134 completed (loss: 0.07519573718309402, acc: 0.9730941653251648)
[2024-12-17 02:42:39,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,429][root][INFO] - Training Epoch: 2/2, step 1083/7134 completed (loss: 0.3062613308429718, acc: 0.9238578677177429)
[2024-12-17 02:42:39,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:39,810][root][INFO] - Training Epoch: 2/2, step 1084/7134 completed (loss: 0.13850390911102295, acc: 0.957446813583374)
[2024-12-17 02:42:39,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,185][root][INFO] - Training Epoch: 2/2, step 1085/7134 completed (loss: 0.2790938913822174, acc: 0.9182389974594116)
[2024-12-17 02:42:40,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,546][root][INFO] - Training Epoch: 2/2, step 1086/7134 completed (loss: 0.5441402792930603, acc: 0.8870967626571655)
[2024-12-17 02:42:40,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:40,922][root][INFO] - Training Epoch: 2/2, step 1087/7134 completed (loss: 0.23683993518352509, acc: 0.9301075339317322)
[2024-12-17 02:42:41,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,303][root][INFO] - Training Epoch: 2/2, step 1088/7134 completed (loss: 0.16915446519851685, acc: 0.9659090638160706)
[2024-12-17 02:42:41,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:41,688][root][INFO] - Training Epoch: 2/2, step 1089/7134 completed (loss: 0.3964373469352722, acc: 0.8834356069564819)
[2024-12-17 02:42:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,054][root][INFO] - Training Epoch: 2/2, step 1090/7134 completed (loss: 0.26853305101394653, acc: 0.9226190447807312)
[2024-12-17 02:42:42,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,424][root][INFO] - Training Epoch: 2/2, step 1091/7134 completed (loss: 0.3653341233730316, acc: 0.9068322777748108)
[2024-12-17 02:42:42,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:42,825][root][INFO] - Training Epoch: 2/2, step 1092/7134 completed (loss: 0.14605918526649475, acc: 0.9640718698501587)
[2024-12-17 02:42:42,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,210][root][INFO] - Training Epoch: 2/2, step 1093/7134 completed (loss: 0.29600048065185547, acc: 0.9047619104385376)
[2024-12-17 02:42:43,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,560][root][INFO] - Training Epoch: 2/2, step 1094/7134 completed (loss: 0.4381204843521118, acc: 0.8947368264198303)
[2024-12-17 02:42:43,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:43,959][root][INFO] - Training Epoch: 2/2, step 1095/7134 completed (loss: 0.2511375844478607, acc: 0.9365079402923584)
[2024-12-17 02:42:44,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,335][root][INFO] - Training Epoch: 2/2, step 1096/7134 completed (loss: 0.42267757654190063, acc: 0.897849440574646)
[2024-12-17 02:42:44,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:44,716][root][INFO] - Training Epoch: 2/2, step 1097/7134 completed (loss: 0.4120001792907715, acc: 0.8907103538513184)
[2024-12-17 02:42:44,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,100][root][INFO] - Training Epoch: 2/2, step 1098/7134 completed (loss: 0.21848954260349274, acc: 0.9333333373069763)
[2024-12-17 02:42:45,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,494][root][INFO] - Training Epoch: 2/2, step 1099/7134 completed (loss: 0.3200075924396515, acc: 0.9114583134651184)
[2024-12-17 02:42:45,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:45,900][root][INFO] - Training Epoch: 2/2, step 1100/7134 completed (loss: 0.3151227831840515, acc: 0.9122806787490845)
[2024-12-17 02:42:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,303][root][INFO] - Training Epoch: 2/2, step 1101/7134 completed (loss: 0.3992948532104492, acc: 0.9179487228393555)
[2024-12-17 02:42:46,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:46,683][root][INFO] - Training Epoch: 2/2, step 1102/7134 completed (loss: 0.48024722933769226, acc: 0.8888888955116272)
[2024-12-17 02:42:46,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,059][root][INFO] - Training Epoch: 2/2, step 1103/7134 completed (loss: 0.7425286173820496, acc: 0.851190447807312)
[2024-12-17 02:42:47,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,428][root][INFO] - Training Epoch: 2/2, step 1104/7134 completed (loss: 0.40298792719841003, acc: 0.8933333158493042)
[2024-12-17 02:42:47,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:47,820][root][INFO] - Training Epoch: 2/2, step 1105/7134 completed (loss: 0.3645128011703491, acc: 0.9197530746459961)
[2024-12-17 02:42:47,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,180][root][INFO] - Training Epoch: 2/2, step 1106/7134 completed (loss: 0.2077600657939911, acc: 0.9668874144554138)
[2024-12-17 02:42:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,563][root][INFO] - Training Epoch: 2/2, step 1107/7134 completed (loss: 0.17726561427116394, acc: 0.9666666388511658)
[2024-12-17 02:42:48,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:48,913][root][INFO] - Training Epoch: 2/2, step 1108/7134 completed (loss: 0.21831031143665314, acc: 0.9408283829689026)
[2024-12-17 02:42:49,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,274][root][INFO] - Training Epoch: 2/2, step 1109/7134 completed (loss: 0.3902495205402374, acc: 0.913294792175293)
[2024-12-17 02:42:49,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:49,659][root][INFO] - Training Epoch: 2/2, step 1110/7134 completed (loss: 0.3360559940338135, acc: 0.9247311949729919)
[2024-12-17 02:42:49,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,021][root][INFO] - Training Epoch: 2/2, step 1111/7134 completed (loss: 0.25809240341186523, acc: 0.9312499761581421)
[2024-12-17 02:42:50,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,399][root][INFO] - Training Epoch: 2/2, step 1112/7134 completed (loss: 0.21695685386657715, acc: 0.9510489702224731)
[2024-12-17 02:42:50,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:50,791][root][INFO] - Training Epoch: 2/2, step 1113/7134 completed (loss: 0.22897499799728394, acc: 0.9496855139732361)
[2024-12-17 02:42:50,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,177][root][INFO] - Training Epoch: 2/2, step 1114/7134 completed (loss: 0.27625182271003723, acc: 0.920634925365448)
[2024-12-17 02:42:51,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,571][root][INFO] - Training Epoch: 2/2, step 1115/7134 completed (loss: 0.21801543235778809, acc: 0.948387086391449)
[2024-12-17 02:42:51,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:51,961][root][INFO] - Training Epoch: 2/2, step 1116/7134 completed (loss: 0.2422456592321396, acc: 0.9268292784690857)
[2024-12-17 02:42:52,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,320][root][INFO] - Training Epoch: 2/2, step 1117/7134 completed (loss: 0.1266285479068756, acc: 0.9539473652839661)
[2024-12-17 02:42:52,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:52,687][root][INFO] - Training Epoch: 2/2, step 1118/7134 completed (loss: 0.2771929204463959, acc: 0.9236640930175781)
[2024-12-17 02:42:52,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,078][root][INFO] - Training Epoch: 2/2, step 1119/7134 completed (loss: 0.16480538249015808, acc: 0.9586206674575806)
[2024-12-17 02:42:53,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,455][root][INFO] - Training Epoch: 2/2, step 1120/7134 completed (loss: 0.45636844635009766, acc: 0.885496199131012)
[2024-12-17 02:42:53,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:53,829][root][INFO] - Training Epoch: 2/2, step 1121/7134 completed (loss: 0.29889973998069763, acc: 0.9290322661399841)
[2024-12-17 02:42:53,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,181][root][INFO] - Training Epoch: 2/2, step 1122/7134 completed (loss: 0.19649823009967804, acc: 0.9538461565971375)
[2024-12-17 02:42:54,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,531][root][INFO] - Training Epoch: 2/2, step 1123/7134 completed (loss: 0.26018065214157104, acc: 0.9448275566101074)
[2024-12-17 02:42:54,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:54,906][root][INFO] - Training Epoch: 2/2, step 1124/7134 completed (loss: 0.3775527775287628, acc: 0.9054054021835327)
[2024-12-17 02:42:55,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,288][root][INFO] - Training Epoch: 2/2, step 1125/7134 completed (loss: 0.2709556818008423, acc: 0.9464285969734192)
[2024-12-17 02:42:55,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:55,670][root][INFO] - Training Epoch: 2/2, step 1126/7134 completed (loss: 0.22142919898033142, acc: 0.9438202381134033)
[2024-12-17 02:42:55,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,054][root][INFO] - Training Epoch: 2/2, step 1127/7134 completed (loss: 0.1847439557313919, acc: 0.9558823704719543)
[2024-12-17 02:42:56,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,432][root][INFO] - Training Epoch: 2/2, step 1128/7134 completed (loss: 0.21648789942264557, acc: 0.9465649127960205)
[2024-12-17 02:42:56,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:56,819][root][INFO] - Training Epoch: 2/2, step 1129/7134 completed (loss: 0.24863025546073914, acc: 0.9083333611488342)
[2024-12-17 02:42:56,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,220][root][INFO] - Training Epoch: 2/2, step 1130/7134 completed (loss: 0.1287783533334732, acc: 0.9496402740478516)
[2024-12-17 02:42:57,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,599][root][INFO] - Training Epoch: 2/2, step 1131/7134 completed (loss: 0.2824775278568268, acc: 0.9494949579238892)
[2024-12-17 02:42:57,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:57,964][root][INFO] - Training Epoch: 2/2, step 1132/7134 completed (loss: 0.6279496550559998, acc: 0.8590604066848755)
[2024-12-17 02:42:58,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,355][root][INFO] - Training Epoch: 2/2, step 1133/7134 completed (loss: 0.34372758865356445, acc: 0.9190751314163208)
[2024-12-17 02:42:58,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:58,718][root][INFO] - Training Epoch: 2/2, step 1134/7134 completed (loss: 0.3613513112068176, acc: 0.9230769276618958)
[2024-12-17 02:42:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,059][root][INFO] - Training Epoch: 2/2, step 1135/7134 completed (loss: 0.3374466300010681, acc: 0.9060402512550354)
[2024-12-17 02:42:59,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,458][root][INFO] - Training Epoch: 2/2, step 1136/7134 completed (loss: 0.39271610975265503, acc: 0.8979591727256775)
[2024-12-17 02:42:59,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:42:59,863][root][INFO] - Training Epoch: 2/2, step 1137/7134 completed (loss: 0.41393914818763733, acc: 0.9056603908538818)
[2024-12-17 02:42:59,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,251][root][INFO] - Training Epoch: 2/2, step 1138/7134 completed (loss: 0.3909180164337158, acc: 0.8899999856948853)
[2024-12-17 02:43:00,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:00,672][root][INFO] - Training Epoch: 2/2, step 1139/7134 completed (loss: 0.4089049994945526, acc: 0.9230769276618958)
[2024-12-17 02:43:00,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,058][root][INFO] - Training Epoch: 2/2, step 1140/7134 completed (loss: 0.3824770450592041, acc: 0.9263157844543457)
[2024-12-17 02:43:01,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,438][root][INFO] - Training Epoch: 2/2, step 1141/7134 completed (loss: 0.16903962194919586, acc: 0.9545454382896423)
[2024-12-17 02:43:01,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:01,814][root][INFO] - Training Epoch: 2/2, step 1142/7134 completed (loss: 0.23663891851902008, acc: 0.9333333373069763)
[2024-12-17 02:43:01,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,185][root][INFO] - Training Epoch: 2/2, step 1143/7134 completed (loss: 0.41296741366386414, acc: 0.9156626462936401)
[2024-12-17 02:43:02,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,565][root][INFO] - Training Epoch: 2/2, step 1144/7134 completed (loss: 0.3438311219215393, acc: 0.9404761791229248)
[2024-12-17 02:43:02,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:02,958][root][INFO] - Training Epoch: 2/2, step 1145/7134 completed (loss: 0.1898070126771927, acc: 0.9608938694000244)
[2024-12-17 02:43:03,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,327][root][INFO] - Training Epoch: 2/2, step 1146/7134 completed (loss: 0.0821329802274704, acc: 0.9848484992980957)
[2024-12-17 02:43:03,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:03,699][root][INFO] - Training Epoch: 2/2, step 1147/7134 completed (loss: 0.13393491506576538, acc: 0.9621621370315552)
[2024-12-17 02:43:03,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,082][root][INFO] - Training Epoch: 2/2, step 1148/7134 completed (loss: 0.16798129677772522, acc: 0.9640287756919861)
[2024-12-17 02:43:04,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,458][root][INFO] - Training Epoch: 2/2, step 1149/7134 completed (loss: 0.34693479537963867, acc: 0.9097222089767456)
[2024-12-17 02:43:04,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:04,836][root][INFO] - Training Epoch: 2/2, step 1150/7134 completed (loss: 0.26975080370903015, acc: 0.9346405267715454)
[2024-12-17 02:43:04,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,197][root][INFO] - Training Epoch: 2/2, step 1151/7134 completed (loss: 0.2567087411880493, acc: 0.9327731132507324)
[2024-12-17 02:43:05,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,572][root][INFO] - Training Epoch: 2/2, step 1152/7134 completed (loss: 0.17909280955791473, acc: 0.9516128897666931)
[2024-12-17 02:43:05,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:05,946][root][INFO] - Training Epoch: 2/2, step 1153/7134 completed (loss: 0.32981133460998535, acc: 0.915032684803009)
[2024-12-17 02:43:06,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,311][root][INFO] - Training Epoch: 2/2, step 1154/7134 completed (loss: 0.2331041842699051, acc: 0.9375)
[2024-12-17 02:43:06,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:06,705][root][INFO] - Training Epoch: 2/2, step 1155/7134 completed (loss: 0.5096231698989868, acc: 0.8547008633613586)
[2024-12-17 02:43:06,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,094][root][INFO] - Training Epoch: 2/2, step 1156/7134 completed (loss: 0.2060902863740921, acc: 0.939393937587738)
[2024-12-17 02:43:07,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,463][root][INFO] - Training Epoch: 2/2, step 1157/7134 completed (loss: 0.5917374491691589, acc: 0.882758617401123)
[2024-12-17 02:43:07,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:07,830][root][INFO] - Training Epoch: 2/2, step 1158/7134 completed (loss: 0.473517507314682, acc: 0.9130434989929199)
[2024-12-17 02:43:07,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,210][root][INFO] - Training Epoch: 2/2, step 1159/7134 completed (loss: 0.3378485143184662, acc: 0.8982036113739014)
[2024-12-17 02:43:08,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,589][root][INFO] - Training Epoch: 2/2, step 1160/7134 completed (loss: 0.12476653605699539, acc: 0.9567901492118835)
[2024-12-17 02:43:08,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:08,967][root][INFO] - Training Epoch: 2/2, step 1161/7134 completed (loss: 0.18211540579795837, acc: 0.95652174949646)
[2024-12-17 02:43:09,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,410][root][INFO] - Training Epoch: 2/2, step 1162/7134 completed (loss: 0.3087747395038605, acc: 0.9113923907279968)
[2024-12-17 02:43:09,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:09,800][root][INFO] - Training Epoch: 2/2, step 1163/7134 completed (loss: 0.254539430141449, acc: 0.9241379499435425)
[2024-12-17 02:43:09,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,177][root][INFO] - Training Epoch: 2/2, step 1164/7134 completed (loss: 0.22524358332157135, acc: 0.950276255607605)
[2024-12-17 02:43:10,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,574][root][INFO] - Training Epoch: 2/2, step 1165/7134 completed (loss: 0.16781353950500488, acc: 0.928205132484436)
[2024-12-17 02:43:10,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:10,927][root][INFO] - Training Epoch: 2/2, step 1166/7134 completed (loss: 0.15203990042209625, acc: 0.9680851101875305)
[2024-12-17 02:43:11,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,279][root][INFO] - Training Epoch: 2/2, step 1167/7134 completed (loss: 0.15599679946899414, acc: 0.9599999785423279)
[2024-12-17 02:43:11,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:11,677][root][INFO] - Training Epoch: 2/2, step 1168/7134 completed (loss: 0.1613694280385971, acc: 0.9629629850387573)
[2024-12-17 02:43:11,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,059][root][INFO] - Training Epoch: 2/2, step 1169/7134 completed (loss: 0.28864172101020813, acc: 0.936170220375061)
[2024-12-17 02:43:12,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,448][root][INFO] - Training Epoch: 2/2, step 1170/7134 completed (loss: 0.32552802562713623, acc: 0.9435028433799744)
[2024-12-17 02:43:12,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:12,804][root][INFO] - Training Epoch: 2/2, step 1171/7134 completed (loss: 0.16714173555374146, acc: 0.9599999785423279)
[2024-12-17 02:43:12,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,197][root][INFO] - Training Epoch: 2/2, step 1172/7134 completed (loss: 0.1952461302280426, acc: 0.9404761791229248)
[2024-12-17 02:43:13,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,580][root][INFO] - Training Epoch: 2/2, step 1173/7134 completed (loss: 0.1312452107667923, acc: 0.9788359999656677)
[2024-12-17 02:43:13,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:13,948][root][INFO] - Training Epoch: 2/2, step 1174/7134 completed (loss: 0.11950476467609406, acc: 0.9815950989723206)
[2024-12-17 02:43:14,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,328][root][INFO] - Training Epoch: 2/2, step 1175/7134 completed (loss: 0.22792881727218628, acc: 0.970588207244873)
[2024-12-17 02:43:14,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:14,717][root][INFO] - Training Epoch: 2/2, step 1176/7134 completed (loss: 0.15736910700798035, acc: 0.9652777910232544)
[2024-12-17 02:43:14,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,105][root][INFO] - Training Epoch: 2/2, step 1177/7134 completed (loss: 0.06697270274162292, acc: 0.9846153855323792)
[2024-12-17 02:43:15,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,446][root][INFO] - Training Epoch: 2/2, step 1178/7134 completed (loss: 0.13403673470020294, acc: 0.9711538553237915)
[2024-12-17 02:43:15,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:15,837][root][INFO] - Training Epoch: 2/2, step 1179/7134 completed (loss: 0.1434035748243332, acc: 0.975806474685669)
[2024-12-17 02:43:15,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,240][root][INFO] - Training Epoch: 2/2, step 1180/7134 completed (loss: 0.2013058066368103, acc: 0.9594594836235046)
[2024-12-17 02:43:16,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:16,657][root][INFO] - Training Epoch: 2/2, step 1181/7134 completed (loss: 0.1020718663930893, acc: 0.9780219793319702)
[2024-12-17 02:43:16,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,057][root][INFO] - Training Epoch: 2/2, step 1182/7134 completed (loss: 0.14317907392978668, acc: 0.9523809552192688)
[2024-12-17 02:43:17,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,504][root][INFO] - Training Epoch: 2/2, step 1183/7134 completed (loss: 0.07255222648382187, acc: 0.9768785834312439)
[2024-12-17 02:43:17,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:17,913][root][INFO] - Training Epoch: 2/2, step 1184/7134 completed (loss: 0.12721633911132812, acc: 0.9710982441902161)
[2024-12-17 02:43:18,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,302][root][INFO] - Training Epoch: 2/2, step 1185/7134 completed (loss: 0.05943016707897186, acc: 0.9878787994384766)
[2024-12-17 02:43:18,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:18,693][root][INFO] - Training Epoch: 2/2, step 1186/7134 completed (loss: 0.1168159693479538, acc: 0.9728260636329651)
[2024-12-17 02:43:18,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,086][root][INFO] - Training Epoch: 2/2, step 1187/7134 completed (loss: 0.10962236672639847, acc: 0.9642857313156128)
[2024-12-17 02:43:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,468][root][INFO] - Training Epoch: 2/2, step 1188/7134 completed (loss: 0.07274685055017471, acc: 0.9784946441650391)
[2024-12-17 02:43:19,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:19,923][root][INFO] - Training Epoch: 2/2, step 1189/7134 completed (loss: 0.17961385846138, acc: 0.9704142212867737)
[2024-12-17 02:43:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,306][root][INFO] - Training Epoch: 2/2, step 1190/7134 completed (loss: 0.1770162731409073, acc: 0.9666666388511658)
[2024-12-17 02:43:20,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:20,710][root][INFO] - Training Epoch: 2/2, step 1191/7134 completed (loss: 0.3190273344516754, acc: 0.918367326259613)
[2024-12-17 02:43:20,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,097][root][INFO] - Training Epoch: 2/2, step 1192/7134 completed (loss: 0.13146275281906128, acc: 0.9849624037742615)
[2024-12-17 02:43:21,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,471][root][INFO] - Training Epoch: 2/2, step 1193/7134 completed (loss: 0.300327330827713, acc: 0.9370078444480896)
[2024-12-17 02:43:21,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:21,868][root][INFO] - Training Epoch: 2/2, step 1194/7134 completed (loss: 0.12092848867177963, acc: 0.9597315192222595)
[2024-12-17 02:43:21,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,241][root][INFO] - Training Epoch: 2/2, step 1195/7134 completed (loss: 0.29330068826675415, acc: 0.9230769276618958)
[2024-12-17 02:43:22,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:22,652][root][INFO] - Training Epoch: 2/2, step 1196/7134 completed (loss: 0.32948559522628784, acc: 0.936170220375061)
[2024-12-17 02:43:22,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,050][root][INFO] - Training Epoch: 2/2, step 1197/7134 completed (loss: 0.2625875174999237, acc: 0.9383561611175537)
[2024-12-17 02:43:23,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,422][root][INFO] - Training Epoch: 2/2, step 1198/7134 completed (loss: 0.25305140018463135, acc: 0.9375)
[2024-12-17 02:43:23,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:23,832][root][INFO] - Training Epoch: 2/2, step 1199/7134 completed (loss: 0.27235153317451477, acc: 0.948051929473877)
[2024-12-17 02:43:23,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,201][root][INFO] - Training Epoch: 2/2, step 1200/7134 completed (loss: 0.13457322120666504, acc: 0.9719626307487488)
[2024-12-17 02:43:24,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:24,603][root][INFO] - Training Epoch: 2/2, step 1201/7134 completed (loss: 0.2605622708797455, acc: 0.9245283007621765)
[2024-12-17 02:43:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,022][root][INFO] - Training Epoch: 2/2, step 1202/7134 completed (loss: 0.30772900581359863, acc: 0.9130434989929199)
[2024-12-17 02:43:25,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,391][root][INFO] - Training Epoch: 2/2, step 1203/7134 completed (loss: 0.24849167466163635, acc: 0.9466666579246521)
[2024-12-17 02:43:25,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:25,763][root][INFO] - Training Epoch: 2/2, step 1204/7134 completed (loss: 0.41242191195487976, acc: 0.904411792755127)
[2024-12-17 02:43:25,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,155][root][INFO] - Training Epoch: 2/2, step 1205/7134 completed (loss: 0.44591692090034485, acc: 0.9080459475517273)
[2024-12-17 02:43:26,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,558][root][INFO] - Training Epoch: 2/2, step 1206/7134 completed (loss: 0.3712884485721588, acc: 0.9145728349685669)
[2024-12-17 02:43:26,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:26,951][root][INFO] - Training Epoch: 2/2, step 1207/7134 completed (loss: 0.29141026735305786, acc: 0.9139785170555115)
[2024-12-17 02:43:27,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,356][root][INFO] - Training Epoch: 2/2, step 1208/7134 completed (loss: 0.2994479537010193, acc: 0.9007633328437805)
[2024-12-17 02:43:27,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:27,755][root][INFO] - Training Epoch: 2/2, step 1209/7134 completed (loss: 0.3335191607475281, acc: 0.9098360538482666)
[2024-12-17 02:43:27,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,112][root][INFO] - Training Epoch: 2/2, step 1210/7134 completed (loss: 0.6065812706947327, acc: 0.846666693687439)
[2024-12-17 02:43:28,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,491][root][INFO] - Training Epoch: 2/2, step 1211/7134 completed (loss: 0.7461089491844177, acc: 0.8273381590843201)
[2024-12-17 02:43:28,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:28,888][root][INFO] - Training Epoch: 2/2, step 1212/7134 completed (loss: 0.5548014044761658, acc: 0.8686131238937378)
[2024-12-17 02:43:29,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,278][root][INFO] - Training Epoch: 2/2, step 1213/7134 completed (loss: 0.4212823510169983, acc: 0.9230769276618958)
[2024-12-17 02:43:29,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:29,665][root][INFO] - Training Epoch: 2/2, step 1214/7134 completed (loss: 0.5076228976249695, acc: 0.8666666746139526)
[2024-12-17 02:43:29,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,032][root][INFO] - Training Epoch: 2/2, step 1215/7134 completed (loss: 0.42569926381111145, acc: 0.8941176533699036)
[2024-12-17 02:43:30,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,405][root][INFO] - Training Epoch: 2/2, step 1216/7134 completed (loss: 0.2916437089443207, acc: 0.9271523356437683)
[2024-12-17 02:43:30,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:30,795][root][INFO] - Training Epoch: 2/2, step 1217/7134 completed (loss: 0.29301050305366516, acc: 0.9276315569877625)
[2024-12-17 02:43:30,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,189][root][INFO] - Training Epoch: 2/2, step 1218/7134 completed (loss: 0.5239649415016174, acc: 0.8812500238418579)
[2024-12-17 02:43:31,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,564][root][INFO] - Training Epoch: 2/2, step 1219/7134 completed (loss: 0.4725204408168793, acc: 0.8999999761581421)
[2024-12-17 02:43:31,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:31,945][root][INFO] - Training Epoch: 2/2, step 1220/7134 completed (loss: 0.36697572469711304, acc: 0.9020618796348572)
[2024-12-17 02:43:32,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,336][root][INFO] - Training Epoch: 2/2, step 1221/7134 completed (loss: 0.33955103158950806, acc: 0.918552041053772)
[2024-12-17 02:43:32,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:32,723][root][INFO] - Training Epoch: 2/2, step 1222/7134 completed (loss: 0.4436877369880676, acc: 0.9077669978141785)
[2024-12-17 02:43:32,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,115][root][INFO] - Training Epoch: 2/2, step 1223/7134 completed (loss: 0.6208143830299377, acc: 0.8636363744735718)
[2024-12-17 02:43:33,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,513][root][INFO] - Training Epoch: 2/2, step 1224/7134 completed (loss: 0.35786694288253784, acc: 0.9150943160057068)
[2024-12-17 02:43:33,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:33,903][root][INFO] - Training Epoch: 2/2, step 1225/7134 completed (loss: 0.45770180225372314, acc: 0.913241982460022)
[2024-12-17 02:43:34,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,306][root][INFO] - Training Epoch: 2/2, step 1226/7134 completed (loss: 0.5319303870201111, acc: 0.8809523582458496)
[2024-12-17 02:43:34,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:34,687][root][INFO] - Training Epoch: 2/2, step 1227/7134 completed (loss: 0.7886754274368286, acc: 0.8659793734550476)
[2024-12-17 02:43:34,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,071][root][INFO] - Training Epoch: 2/2, step 1228/7134 completed (loss: 0.47912827134132385, acc: 0.9011628031730652)
[2024-12-17 02:43:35,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,435][root][INFO] - Training Epoch: 2/2, step 1229/7134 completed (loss: 0.4001915454864502, acc: 0.9257425665855408)
[2024-12-17 02:43:35,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:35,888][root][INFO] - Training Epoch: 2/2, step 1230/7134 completed (loss: 0.4475751519203186, acc: 0.8820754885673523)
[2024-12-17 02:43:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,281][root][INFO] - Training Epoch: 2/2, step 1231/7134 completed (loss: 0.4135262370109558, acc: 0.9008620977401733)
[2024-12-17 02:43:36,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:36,696][root][INFO] - Training Epoch: 2/2, step 1232/7134 completed (loss: 0.4164096713066101, acc: 0.8923766613006592)
[2024-12-17 02:43:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,071][root][INFO] - Training Epoch: 2/2, step 1233/7134 completed (loss: 0.6334013938903809, acc: 0.8325791954994202)
[2024-12-17 02:43:37,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,425][root][INFO] - Training Epoch: 2/2, step 1234/7134 completed (loss: 0.3596504032611847, acc: 0.9038461446762085)
[2024-12-17 02:43:37,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:37,817][root][INFO] - Training Epoch: 2/2, step 1235/7134 completed (loss: 0.34607163071632385, acc: 0.9132652878761292)
[2024-12-17 02:43:37,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,177][root][INFO] - Training Epoch: 2/2, step 1236/7134 completed (loss: 0.6411758661270142, acc: 0.8764705657958984)
[2024-12-17 02:43:38,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,555][root][INFO] - Training Epoch: 2/2, step 1237/7134 completed (loss: 0.499448299407959, acc: 0.8807947039604187)
[2024-12-17 02:43:38,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:38,946][root][INFO] - Training Epoch: 2/2, step 1238/7134 completed (loss: 1.0145137310028076, acc: 0.7860465049743652)
[2024-12-17 02:43:39,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,368][root][INFO] - Training Epoch: 2/2, step 1239/7134 completed (loss: 0.6590889692306519, acc: 0.8353658318519592)
[2024-12-17 02:43:39,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:39,761][root][INFO] - Training Epoch: 2/2, step 1240/7134 completed (loss: 0.5726520419120789, acc: 0.8430232405662537)
[2024-12-17 02:43:39,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,169][root][INFO] - Training Epoch: 2/2, step 1241/7134 completed (loss: 0.5763466358184814, acc: 0.868852436542511)
[2024-12-17 02:43:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,548][root][INFO] - Training Epoch: 2/2, step 1242/7134 completed (loss: 0.4592415392398834, acc: 0.9005235433578491)
[2024-12-17 02:43:40,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:40,943][root][INFO] - Training Epoch: 2/2, step 1243/7134 completed (loss: 0.5105376243591309, acc: 0.8684210777282715)
[2024-12-17 02:43:41,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,328][root][INFO] - Training Epoch: 2/2, step 1244/7134 completed (loss: 0.37666717171669006, acc: 0.9014084339141846)
[2024-12-17 02:43:41,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:41,714][root][INFO] - Training Epoch: 2/2, step 1245/7134 completed (loss: 0.44932064414024353, acc: 0.8939393758773804)
[2024-12-17 02:43:41,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,081][root][INFO] - Training Epoch: 2/2, step 1246/7134 completed (loss: 0.6151272058486938, acc: 0.8473684191703796)
[2024-12-17 02:43:42,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,456][root][INFO] - Training Epoch: 2/2, step 1247/7134 completed (loss: 0.3812806010246277, acc: 0.9036144614219666)
[2024-12-17 02:43:42,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:42,861][root][INFO] - Training Epoch: 2/2, step 1248/7134 completed (loss: 0.4748678505420685, acc: 0.8999999761581421)
[2024-12-17 02:43:42,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,260][root][INFO] - Training Epoch: 2/2, step 1249/7134 completed (loss: 0.22757244110107422, acc: 0.9655172228813171)
[2024-12-17 02:43:43,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:43,677][root][INFO] - Training Epoch: 2/2, step 1250/7134 completed (loss: 0.2768511474132538, acc: 0.9333333373069763)
[2024-12-17 02:43:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,075][root][INFO] - Training Epoch: 2/2, step 1251/7134 completed (loss: 0.3398459553718567, acc: 0.8909090757369995)
[2024-12-17 02:43:44,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,466][root][INFO] - Training Epoch: 2/2, step 1252/7134 completed (loss: 0.29077786207199097, acc: 0.9291338324546814)
[2024-12-17 02:43:44,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:44,903][root][INFO] - Training Epoch: 2/2, step 1253/7134 completed (loss: 0.48888957500457764, acc: 0.8888888955116272)
[2024-12-17 02:43:45,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,304][root][INFO] - Training Epoch: 2/2, step 1254/7134 completed (loss: 0.41188204288482666, acc: 0.8666666746139526)
[2024-12-17 02:43:45,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:45,688][root][INFO] - Training Epoch: 2/2, step 1255/7134 completed (loss: 0.3144325911998749, acc: 0.9241379499435425)
[2024-12-17 02:43:45,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,065][root][INFO] - Training Epoch: 2/2, step 1256/7134 completed (loss: 0.3426540195941925, acc: 0.9312977194786072)
[2024-12-17 02:43:46,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,439][root][INFO] - Training Epoch: 2/2, step 1257/7134 completed (loss: 0.28237584233283997, acc: 0.9312977194786072)
[2024-12-17 02:43:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:46,810][root][INFO] - Training Epoch: 2/2, step 1258/7134 completed (loss: 0.39627715945243835, acc: 0.9047619104385376)
[2024-12-17 02:43:46,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,167][root][INFO] - Training Epoch: 2/2, step 1259/7134 completed (loss: 0.5779093503952026, acc: 0.8942307829856873)
[2024-12-17 02:43:47,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,560][root][INFO] - Training Epoch: 2/2, step 1260/7134 completed (loss: 0.22075340151786804, acc: 0.9395973086357117)
[2024-12-17 02:43:47,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:47,966][root][INFO] - Training Epoch: 2/2, step 1261/7134 completed (loss: 0.31999659538269043, acc: 0.9189189076423645)
[2024-12-17 02:43:48,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,322][root][INFO] - Training Epoch: 2/2, step 1262/7134 completed (loss: 0.10937154293060303, acc: 0.9767441749572754)
[2024-12-17 02:43:48,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:48,692][root][INFO] - Training Epoch: 2/2, step 1263/7134 completed (loss: 0.15950937569141388, acc: 0.9612902998924255)
[2024-12-17 02:43:48,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,090][root][INFO] - Training Epoch: 2/2, step 1264/7134 completed (loss: 0.3327372372150421, acc: 0.9185185432434082)
[2024-12-17 02:43:49,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,513][root][INFO] - Training Epoch: 2/2, step 1265/7134 completed (loss: 0.16204410791397095, acc: 0.9599999785423279)
[2024-12-17 02:43:49,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:49,906][root][INFO] - Training Epoch: 2/2, step 1266/7134 completed (loss: 0.19144876301288605, acc: 0.9618320465087891)
[2024-12-17 02:43:50,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,291][root][INFO] - Training Epoch: 2/2, step 1267/7134 completed (loss: 0.272146075963974, acc: 0.9220778942108154)
[2024-12-17 02:43:50,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:50,682][root][INFO] - Training Epoch: 2/2, step 1268/7134 completed (loss: 0.3680402934551239, acc: 0.9259259104728699)
[2024-12-17 02:43:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,117][root][INFO] - Training Epoch: 2/2, step 1269/7134 completed (loss: 0.546768069267273, acc: 0.8939393758773804)
[2024-12-17 02:43:51,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,559][root][INFO] - Training Epoch: 2/2, step 1270/7134 completed (loss: 0.2180321365594864, acc: 0.931506872177124)
[2024-12-17 02:43:51,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:51,913][root][INFO] - Training Epoch: 2/2, step 1271/7134 completed (loss: 0.2817259728908539, acc: 0.949999988079071)
[2024-12-17 02:43:52,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,286][root][INFO] - Training Epoch: 2/2, step 1272/7134 completed (loss: 0.1219361275434494, acc: 0.9685534834861755)
[2024-12-17 02:43:52,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:52,682][root][INFO] - Training Epoch: 2/2, step 1273/7134 completed (loss: 0.24922706186771393, acc: 0.9333333373069763)
[2024-12-17 02:43:52,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,056][root][INFO] - Training Epoch: 2/2, step 1274/7134 completed (loss: 0.13365234434604645, acc: 0.9504132270812988)
[2024-12-17 02:43:53,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,430][root][INFO] - Training Epoch: 2/2, step 1275/7134 completed (loss: 0.28492918610572815, acc: 0.939130425453186)
[2024-12-17 02:43:53,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:53,805][root][INFO] - Training Epoch: 2/2, step 1276/7134 completed (loss: 0.1733725219964981, acc: 0.9469696879386902)
[2024-12-17 02:43:53,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,144][root][INFO] - Training Epoch: 2/2, step 1277/7134 completed (loss: 0.15915100276470184, acc: 0.9436619877815247)
[2024-12-17 02:43:54,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,540][root][INFO] - Training Epoch: 2/2, step 1278/7134 completed (loss: 0.5313956141471863, acc: 0.875)
[2024-12-17 02:43:54,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:54,909][root][INFO] - Training Epoch: 2/2, step 1279/7134 completed (loss: 0.34052130579948425, acc: 0.9239130616188049)
[2024-12-17 02:43:55,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,280][root][INFO] - Training Epoch: 2/2, step 1280/7134 completed (loss: 0.3310437798500061, acc: 0.9090909361839294)
[2024-12-17 02:43:55,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:55,629][root][INFO] - Training Epoch: 2/2, step 1281/7134 completed (loss: 0.3578571677207947, acc: 0.9090909361839294)
[2024-12-17 02:43:55,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,013][root][INFO] - Training Epoch: 2/2, step 1282/7134 completed (loss: 0.6584141850471497, acc: 0.8579235076904297)
[2024-12-17 02:43:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,381][root][INFO] - Training Epoch: 2/2, step 1283/7134 completed (loss: 0.31095775961875916, acc: 0.9379844665527344)
[2024-12-17 02:43:56,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:56,773][root][INFO] - Training Epoch: 2/2, step 1284/7134 completed (loss: 0.3878776729106903, acc: 0.8922155499458313)
[2024-12-17 02:43:56,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,139][root][INFO] - Training Epoch: 2/2, step 1285/7134 completed (loss: 0.3136700987815857, acc: 0.9437500238418579)
[2024-12-17 02:43:57,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,522][root][INFO] - Training Epoch: 2/2, step 1286/7134 completed (loss: 0.3500308394432068, acc: 0.9207317233085632)
[2024-12-17 02:43:57,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:57,893][root][INFO] - Training Epoch: 2/2, step 1287/7134 completed (loss: 0.32655104994773865, acc: 0.9185185432434082)
[2024-12-17 02:43:58,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,276][root][INFO] - Training Epoch: 2/2, step 1288/7134 completed (loss: 0.22783328592777252, acc: 0.9326424598693848)
[2024-12-17 02:43:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,633][root][INFO] - Training Epoch: 2/2, step 1289/7134 completed (loss: 0.4949953258037567, acc: 0.9172413945198059)
[2024-12-17 02:43:58,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:58,976][root][INFO] - Training Epoch: 2/2, step 1290/7134 completed (loss: 0.25207117199897766, acc: 0.9341317415237427)
[2024-12-17 02:43:59,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,358][root][INFO] - Training Epoch: 2/2, step 1291/7134 completed (loss: 0.28911060094833374, acc: 0.9352940917015076)
[2024-12-17 02:43:59,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:43:59,710][root][INFO] - Training Epoch: 2/2, step 1292/7134 completed (loss: 0.2232094407081604, acc: 0.9505494236946106)
[2024-12-17 02:43:59,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,067][root][INFO] - Training Epoch: 2/2, step 1293/7134 completed (loss: 0.2859968841075897, acc: 0.928205132484436)
[2024-12-17 02:44:00,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,454][root][INFO] - Training Epoch: 2/2, step 1294/7134 completed (loss: 0.277330607175827, acc: 0.9508196711540222)
[2024-12-17 02:44:00,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:00,859][root][INFO] - Training Epoch: 2/2, step 1295/7134 completed (loss: 0.29959189891815186, acc: 0.9328358173370361)
[2024-12-17 02:44:01,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,277][root][INFO] - Training Epoch: 2/2, step 1296/7134 completed (loss: 0.24456380307674408, acc: 0.942307710647583)
[2024-12-17 02:44:01,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:01,623][root][INFO] - Training Epoch: 2/2, step 1297/7134 completed (loss: 0.3164781630039215, acc: 0.9017857313156128)
[2024-12-17 02:44:01,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,007][root][INFO] - Training Epoch: 2/2, step 1298/7134 completed (loss: 0.23110342025756836, acc: 0.9586777091026306)
[2024-12-17 02:44:02,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,366][root][INFO] - Training Epoch: 2/2, step 1299/7134 completed (loss: 0.171568363904953, acc: 0.9518072009086609)
[2024-12-17 02:44:02,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:02,763][root][INFO] - Training Epoch: 2/2, step 1300/7134 completed (loss: 0.2382066547870636, acc: 0.9306930899620056)
[2024-12-17 02:44:02,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,144][root][INFO] - Training Epoch: 2/2, step 1301/7134 completed (loss: 0.231359601020813, acc: 0.9407894611358643)
[2024-12-17 02:44:03,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,536][root][INFO] - Training Epoch: 2/2, step 1302/7134 completed (loss: 0.22746320068836212, acc: 0.9306930899620056)
[2024-12-17 02:44:03,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:03,913][root][INFO] - Training Epoch: 2/2, step 1303/7134 completed (loss: 0.31506404280662537, acc: 0.9100000262260437)
[2024-12-17 02:44:04,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,307][root][INFO] - Training Epoch: 2/2, step 1304/7134 completed (loss: 0.3392179310321808, acc: 0.9209039807319641)
[2024-12-17 02:44:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:04,701][root][INFO] - Training Epoch: 2/2, step 1305/7134 completed (loss: 0.31100210547447205, acc: 0.9278350472450256)
[2024-12-17 02:44:04,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,106][root][INFO] - Training Epoch: 2/2, step 1306/7134 completed (loss: 0.25676822662353516, acc: 0.9605262875556946)
[2024-12-17 02:44:05,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,497][root][INFO] - Training Epoch: 2/2, step 1307/7134 completed (loss: 0.19430550932884216, acc: 0.9280575513839722)
[2024-12-17 02:44:05,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:05,854][root][INFO] - Training Epoch: 2/2, step 1308/7134 completed (loss: 0.1858271062374115, acc: 0.948387086391449)
[2024-12-17 02:44:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,240][root][INFO] - Training Epoch: 2/2, step 1309/7134 completed (loss: 0.2633325457572937, acc: 0.9323671460151672)
[2024-12-17 02:44:06,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,614][root][INFO] - Training Epoch: 2/2, step 1310/7134 completed (loss: 0.37067657709121704, acc: 0.8950276374816895)
[2024-12-17 02:44:06,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:06,983][root][INFO] - Training Epoch: 2/2, step 1311/7134 completed (loss: 0.2167588770389557, acc: 0.932692289352417)
[2024-12-17 02:44:07,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,358][root][INFO] - Training Epoch: 2/2, step 1312/7134 completed (loss: 0.5354323983192444, acc: 0.8944099545478821)
[2024-12-17 02:44:07,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:07,739][root][INFO] - Training Epoch: 2/2, step 1313/7134 completed (loss: 0.47002628445625305, acc: 0.895061731338501)
[2024-12-17 02:44:07,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,119][root][INFO] - Training Epoch: 2/2, step 1314/7134 completed (loss: 0.224752277135849, acc: 0.9347826242446899)
[2024-12-17 02:44:08,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,517][root][INFO] - Training Epoch: 2/2, step 1315/7134 completed (loss: 0.549591064453125, acc: 0.8756756782531738)
[2024-12-17 02:44:08,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:08,871][root][INFO] - Training Epoch: 2/2, step 1316/7134 completed (loss: 0.3457911014556885, acc: 0.934959352016449)
[2024-12-17 02:44:08,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,248][root][INFO] - Training Epoch: 2/2, step 1317/7134 completed (loss: 0.5466536283493042, acc: 0.8805969953536987)
[2024-12-17 02:44:09,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:09,614][root][INFO] - Training Epoch: 2/2, step 1318/7134 completed (loss: 0.19101963937282562, acc: 0.9670329689979553)
[2024-12-17 02:44:09,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,028][root][INFO] - Training Epoch: 2/2, step 1319/7134 completed (loss: 0.2764776349067688, acc: 0.9454545378684998)
[2024-12-17 02:44:10,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,405][root][INFO] - Training Epoch: 2/2, step 1320/7134 completed (loss: 0.3944281339645386, acc: 0.9006622433662415)
[2024-12-17 02:44:10,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:10,798][root][INFO] - Training Epoch: 2/2, step 1321/7134 completed (loss: 0.3609742224216461, acc: 0.8911917209625244)
[2024-12-17 02:44:10,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,184][root][INFO] - Training Epoch: 2/2, step 1322/7134 completed (loss: 0.4181714355945587, acc: 0.8911564350128174)
[2024-12-17 02:44:11,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,561][root][INFO] - Training Epoch: 2/2, step 1323/7134 completed (loss: 0.4488005042076111, acc: 0.908450722694397)
[2024-12-17 02:44:11,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:11,947][root][INFO] - Training Epoch: 2/2, step 1324/7134 completed (loss: 0.26877689361572266, acc: 0.9346405267715454)
[2024-12-17 02:44:12,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,336][root][INFO] - Training Epoch: 2/2, step 1325/7134 completed (loss: 0.38191407918930054, acc: 0.8737863898277283)
[2024-12-17 02:44:12,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:12,723][root][INFO] - Training Epoch: 2/2, step 1326/7134 completed (loss: 0.37163591384887695, acc: 0.931506872177124)
[2024-12-17 02:44:12,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,103][root][INFO] - Training Epoch: 2/2, step 1327/7134 completed (loss: 0.28909218311309814, acc: 0.9171597361564636)
[2024-12-17 02:44:13,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,493][root][INFO] - Training Epoch: 2/2, step 1328/7134 completed (loss: 0.3786584436893463, acc: 0.9306930899620056)
[2024-12-17 02:44:13,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:13,864][root][INFO] - Training Epoch: 2/2, step 1329/7134 completed (loss: 0.31685206294059753, acc: 0.9200000166893005)
[2024-12-17 02:44:13,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,240][root][INFO] - Training Epoch: 2/2, step 1330/7134 completed (loss: 0.24769702553749084, acc: 0.9424460530281067)
[2024-12-17 02:44:14,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,627][root][INFO] - Training Epoch: 2/2, step 1331/7134 completed (loss: 0.1276085376739502, acc: 0.9647887349128723)
[2024-12-17 02:44:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:14,992][root][INFO] - Training Epoch: 2/2, step 1332/7134 completed (loss: 0.23902319371700287, acc: 0.9298245906829834)
[2024-12-17 02:44:15,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,359][root][INFO] - Training Epoch: 2/2, step 1333/7134 completed (loss: 0.34050866961479187, acc: 0.9078947305679321)
[2024-12-17 02:44:15,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:15,752][root][INFO] - Training Epoch: 2/2, step 1334/7134 completed (loss: 0.5358201265335083, acc: 0.8765432238578796)
[2024-12-17 02:44:15,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,147][root][INFO] - Training Epoch: 2/2, step 1335/7134 completed (loss: 0.4189257025718689, acc: 0.9162303805351257)
[2024-12-17 02:44:16,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,541][root][INFO] - Training Epoch: 2/2, step 1336/7134 completed (loss: 0.2763100862503052, acc: 0.9304812550544739)
[2024-12-17 02:44:16,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:16,944][root][INFO] - Training Epoch: 2/2, step 1337/7134 completed (loss: 0.19567953050136566, acc: 0.9612902998924255)
[2024-12-17 02:44:17,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,317][root][INFO] - Training Epoch: 2/2, step 1338/7134 completed (loss: 0.5090686082839966, acc: 0.84375)
[2024-12-17 02:44:17,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:17,691][root][INFO] - Training Epoch: 2/2, step 1339/7134 completed (loss: 0.40594637393951416, acc: 0.8979591727256775)
[2024-12-17 02:44:17,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,084][root][INFO] - Training Epoch: 2/2, step 1340/7134 completed (loss: 0.3612796366214752, acc: 0.9220778942108154)
[2024-12-17 02:44:18,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,452][root][INFO] - Training Epoch: 2/2, step 1341/7134 completed (loss: 0.16474135220050812, acc: 0.9450549483299255)
[2024-12-17 02:44:18,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:18,830][root][INFO] - Training Epoch: 2/2, step 1342/7134 completed (loss: 0.16407938301563263, acc: 0.9470198750495911)
[2024-12-17 02:44:18,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,217][root][INFO] - Training Epoch: 2/2, step 1343/7134 completed (loss: 0.5114391446113586, acc: 0.875)
[2024-12-17 02:44:19,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,607][root][INFO] - Training Epoch: 2/2, step 1344/7134 completed (loss: 0.245788112282753, acc: 0.9449541568756104)
[2024-12-17 02:44:19,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:19,949][root][INFO] - Training Epoch: 2/2, step 1345/7134 completed (loss: 0.2770586311817169, acc: 0.9032257795333862)
[2024-12-17 02:44:20,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,332][root][INFO] - Training Epoch: 2/2, step 1346/7134 completed (loss: 0.1830223947763443, acc: 0.9562841653823853)
[2024-12-17 02:44:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:20,696][root][INFO] - Training Epoch: 2/2, step 1347/7134 completed (loss: 0.1787443906068802, acc: 0.9513888955116272)
[2024-12-17 02:44:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,084][root][INFO] - Training Epoch: 2/2, step 1348/7134 completed (loss: 0.1692376434803009, acc: 0.9447513818740845)
[2024-12-17 02:44:21,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,445][root][INFO] - Training Epoch: 2/2, step 1349/7134 completed (loss: 0.17784562706947327, acc: 0.9716312289237976)
[2024-12-17 02:44:21,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:21,808][root][INFO] - Training Epoch: 2/2, step 1350/7134 completed (loss: 0.1379595547914505, acc: 0.9640718698501587)
[2024-12-17 02:44:21,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,167][root][INFO] - Training Epoch: 2/2, step 1351/7134 completed (loss: 0.13213592767715454, acc: 0.9416666626930237)
[2024-12-17 02:44:22,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,551][root][INFO] - Training Epoch: 2/2, step 1352/7134 completed (loss: 0.15376311540603638, acc: 0.9695122241973877)
[2024-12-17 02:44:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:22,939][root][INFO] - Training Epoch: 2/2, step 1353/7134 completed (loss: 0.11023787409067154, acc: 0.9833333492279053)
[2024-12-17 02:44:23,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,335][root][INFO] - Training Epoch: 2/2, step 1354/7134 completed (loss: 0.06946171075105667, acc: 0.9866666793823242)
[2024-12-17 02:44:23,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:23,732][root][INFO] - Training Epoch: 2/2, step 1355/7134 completed (loss: 0.06964271515607834, acc: 0.9806451797485352)
[2024-12-17 02:44:23,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,130][root][INFO] - Training Epoch: 2/2, step 1356/7134 completed (loss: 0.12749014794826508, acc: 0.9651162624359131)
[2024-12-17 02:44:24,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,521][root][INFO] - Training Epoch: 2/2, step 1357/7134 completed (loss: 0.08597828447818756, acc: 0.9788359999656677)
[2024-12-17 02:44:24,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:24,901][root][INFO] - Training Epoch: 2/2, step 1358/7134 completed (loss: 0.1264715939760208, acc: 0.9829545617103577)
[2024-12-17 02:44:25,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,267][root][INFO] - Training Epoch: 2/2, step 1359/7134 completed (loss: 0.05921607464551926, acc: 0.9917355179786682)
[2024-12-17 02:44:25,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:25,647][root][INFO] - Training Epoch: 2/2, step 1360/7134 completed (loss: 0.09429632872343063, acc: 0.9702380895614624)
[2024-12-17 02:44:25,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,014][root][INFO] - Training Epoch: 2/2, step 1361/7134 completed (loss: 0.12707075476646423, acc: 0.9585798978805542)
[2024-12-17 02:44:26,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,396][root][INFO] - Training Epoch: 2/2, step 1362/7134 completed (loss: 0.22791524231433868, acc: 0.9508196711540222)
[2024-12-17 02:44:26,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:26,781][root][INFO] - Training Epoch: 2/2, step 1363/7134 completed (loss: 0.18692371249198914, acc: 0.9655172228813171)
[2024-12-17 02:44:26,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,133][root][INFO] - Training Epoch: 2/2, step 1364/7134 completed (loss: 0.0930914506316185, acc: 0.9647058844566345)
[2024-12-17 02:44:27,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,476][root][INFO] - Training Epoch: 2/2, step 1365/7134 completed (loss: 0.0790417417883873, acc: 0.9777777791023254)
[2024-12-17 02:44:27,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:27,838][root][INFO] - Training Epoch: 2/2, step 1366/7134 completed (loss: 0.10598882287740707, acc: 0.9837398529052734)
[2024-12-17 02:44:27,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,205][root][INFO] - Training Epoch: 2/2, step 1367/7134 completed (loss: 0.10961920768022537, acc: 0.9852941036224365)
[2024-12-17 02:44:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,570][root][INFO] - Training Epoch: 2/2, step 1368/7134 completed (loss: 0.23236870765686035, acc: 0.9367815852165222)
[2024-12-17 02:44:28,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:28,936][root][INFO] - Training Epoch: 2/2, step 1369/7134 completed (loss: 0.28462401032447815, acc: 0.9489051103591919)
[2024-12-17 02:44:29,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,322][root][INFO] - Training Epoch: 2/2, step 1370/7134 completed (loss: 0.2794768810272217, acc: 0.9336734414100647)
[2024-12-17 02:44:29,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:29,716][root][INFO] - Training Epoch: 2/2, step 1371/7134 completed (loss: 0.22536207735538483, acc: 0.9320987462997437)
[2024-12-17 02:44:29,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,141][root][INFO] - Training Epoch: 2/2, step 1372/7134 completed (loss: 0.38406023383140564, acc: 0.9318181872367859)
[2024-12-17 02:44:30,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:30,536][root][INFO] - Training Epoch: 2/2, step 1373/7134 completed (loss: 0.1665831059217453, acc: 0.9457364082336426)
[2024-12-17 02:44:30,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,008][root][INFO] - Training Epoch: 2/2, step 1374/7134 completed (loss: 0.3348686099052429, acc: 0.9166666865348816)
[2024-12-17 02:44:31,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,385][root][INFO] - Training Epoch: 2/2, step 1375/7134 completed (loss: 0.17887887358665466, acc: 0.9509803652763367)
[2024-12-17 02:44:31,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:31,778][root][INFO] - Training Epoch: 2/2, step 1376/7134 completed (loss: 0.3859238028526306, acc: 0.8928571343421936)
[2024-12-17 02:44:31,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,195][root][INFO] - Training Epoch: 2/2, step 1377/7134 completed (loss: 0.4561978280544281, acc: 0.8921568393707275)
[2024-12-17 02:44:32,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,541][root][INFO] - Training Epoch: 2/2, step 1378/7134 completed (loss: 0.5799362659454346, acc: 0.875)
[2024-12-17 02:44:32,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:32,904][root][INFO] - Training Epoch: 2/2, step 1379/7134 completed (loss: 0.40885859727859497, acc: 0.9108911156654358)
[2024-12-17 02:44:33,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,301][root][INFO] - Training Epoch: 2/2, step 1380/7134 completed (loss: 0.4799455404281616, acc: 0.8703703880310059)
[2024-12-17 02:44:33,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:33,701][root][INFO] - Training Epoch: 2/2, step 1381/7134 completed (loss: 0.24367623031139374, acc: 0.9420289993286133)
[2024-12-17 02:44:33,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,084][root][INFO] - Training Epoch: 2/2, step 1382/7134 completed (loss: 0.40422865748405457, acc: 0.8692307472229004)
[2024-12-17 02:44:34,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,496][root][INFO] - Training Epoch: 2/2, step 1383/7134 completed (loss: 0.5577349662780762, acc: 0.8970588445663452)
[2024-12-17 02:44:34,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:34,868][root][INFO] - Training Epoch: 2/2, step 1384/7134 completed (loss: 0.5673482418060303, acc: 0.8581560254096985)
[2024-12-17 02:44:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,230][root][INFO] - Training Epoch: 2/2, step 1385/7134 completed (loss: 0.5488529801368713, acc: 0.8799999952316284)
[2024-12-17 02:44:35,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,607][root][INFO] - Training Epoch: 2/2, step 1386/7134 completed (loss: 0.4490518569946289, acc: 0.8873239159584045)
[2024-12-17 02:44:35,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:35,988][root][INFO] - Training Epoch: 2/2, step 1387/7134 completed (loss: 0.22701242566108704, acc: 0.9510489702224731)
[2024-12-17 02:44:36,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,379][root][INFO] - Training Epoch: 2/2, step 1388/7134 completed (loss: 0.38013955950737, acc: 0.871999979019165)
[2024-12-17 02:44:36,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:36,747][root][INFO] - Training Epoch: 2/2, step 1389/7134 completed (loss: 0.4739709496498108, acc: 0.9104477763175964)
[2024-12-17 02:44:36,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,149][root][INFO] - Training Epoch: 2/2, step 1390/7134 completed (loss: 0.3083364963531494, acc: 0.9270073175430298)
[2024-12-17 02:44:37,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,518][root][INFO] - Training Epoch: 2/2, step 1391/7134 completed (loss: 0.4716438353061676, acc: 0.875)
[2024-12-17 02:44:37,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:37,898][root][INFO] - Training Epoch: 2/2, step 1392/7134 completed (loss: 0.5281679034233093, acc: 0.869918704032898)
[2024-12-17 02:44:38,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,237][root][INFO] - Training Epoch: 2/2, step 1393/7134 completed (loss: 0.41855475306510925, acc: 0.8645833134651184)
[2024-12-17 02:44:38,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,598][root][INFO] - Training Epoch: 2/2, step 1394/7134 completed (loss: 0.4413032829761505, acc: 0.8962264060974121)
[2024-12-17 02:44:38,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:38,973][root][INFO] - Training Epoch: 2/2, step 1395/7134 completed (loss: 0.3298977315425873, acc: 0.9375)
[2024-12-17 02:44:39,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,361][root][INFO] - Training Epoch: 2/2, step 1396/7134 completed (loss: 0.27740663290023804, acc: 0.9279999732971191)
[2024-12-17 02:44:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:39,791][root][INFO] - Training Epoch: 2/2, step 1397/7134 completed (loss: 0.5808946490287781, acc: 0.8648648858070374)
[2024-12-17 02:44:39,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,164][root][INFO] - Training Epoch: 2/2, step 1398/7134 completed (loss: 0.2360168993473053, acc: 0.9405940771102905)
[2024-12-17 02:44:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,543][root][INFO] - Training Epoch: 2/2, step 1399/7134 completed (loss: 0.35728365182876587, acc: 0.8920863270759583)
[2024-12-17 02:44:40,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:40,922][root][INFO] - Training Epoch: 2/2, step 1400/7134 completed (loss: 0.21695883572101593, acc: 0.9420289993286133)
[2024-12-17 02:44:41,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,278][root][INFO] - Training Epoch: 2/2, step 1401/7134 completed (loss: 0.1843046396970749, acc: 0.9481481313705444)
[2024-12-17 02:44:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:41,636][root][INFO] - Training Epoch: 2/2, step 1402/7134 completed (loss: 0.16207227110862732, acc: 0.9402984976768494)
[2024-12-17 02:44:41,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,019][root][INFO] - Training Epoch: 2/2, step 1403/7134 completed (loss: 0.18018051981925964, acc: 0.9644970297813416)
[2024-12-17 02:44:42,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,414][root][INFO] - Training Epoch: 2/2, step 1404/7134 completed (loss: 0.12054668366909027, acc: 0.9583333134651184)
[2024-12-17 02:44:42,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:42,792][root][INFO] - Training Epoch: 2/2, step 1405/7134 completed (loss: 0.222726508975029, acc: 0.9464285969734192)
[2024-12-17 02:44:42,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,151][root][INFO] - Training Epoch: 2/2, step 1406/7134 completed (loss: 0.12316476553678513, acc: 0.9689440727233887)
[2024-12-17 02:44:43,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,517][root][INFO] - Training Epoch: 2/2, step 1407/7134 completed (loss: 0.15186037123203278, acc: 0.9476743936538696)
[2024-12-17 02:44:43,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:43,918][root][INFO] - Training Epoch: 2/2, step 1408/7134 completed (loss: 0.12422573566436768, acc: 0.9655172228813171)
[2024-12-17 02:44:44,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,328][root][INFO] - Training Epoch: 2/2, step 1409/7134 completed (loss: 0.08005854487419128, acc: 0.9811320900917053)
[2024-12-17 02:44:44,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:44,714][root][INFO] - Training Epoch: 2/2, step 1410/7134 completed (loss: 0.21623940765857697, acc: 0.9613259434700012)
[2024-12-17 02:44:44,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,076][root][INFO] - Training Epoch: 2/2, step 1411/7134 completed (loss: 0.08544159680604935, acc: 0.9714285731315613)
[2024-12-17 02:44:45,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,465][root][INFO] - Training Epoch: 2/2, step 1412/7134 completed (loss: 0.19598549604415894, acc: 0.9631578922271729)
[2024-12-17 02:44:45,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:45,826][root][INFO] - Training Epoch: 2/2, step 1413/7134 completed (loss: 0.12185890227556229, acc: 0.9640718698501587)
[2024-12-17 02:44:45,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,203][root][INFO] - Training Epoch: 2/2, step 1414/7134 completed (loss: 0.09726385772228241, acc: 0.9668874144554138)
[2024-12-17 02:44:46,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,579][root][INFO] - Training Epoch: 2/2, step 1415/7134 completed (loss: 0.20882493257522583, acc: 0.956204354763031)
[2024-12-17 02:44:46,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:46,953][root][INFO] - Training Epoch: 2/2, step 1416/7134 completed (loss: 0.073461152613163, acc: 0.9774011373519897)
[2024-12-17 02:44:47,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,317][root][INFO] - Training Epoch: 2/2, step 1417/7134 completed (loss: 0.09706314653158188, acc: 0.9791666865348816)
[2024-12-17 02:44:47,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:47,696][root][INFO] - Training Epoch: 2/2, step 1418/7134 completed (loss: 0.11707630008459091, acc: 0.9689922332763672)
[2024-12-17 02:44:47,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,082][root][INFO] - Training Epoch: 2/2, step 1419/7134 completed (loss: 0.1288217455148697, acc: 0.9829545617103577)
[2024-12-17 02:44:48,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,455][root][INFO] - Training Epoch: 2/2, step 1420/7134 completed (loss: 0.13622987270355225, acc: 0.9684210419654846)
[2024-12-17 02:44:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:48,807][root][INFO] - Training Epoch: 2/2, step 1421/7134 completed (loss: 0.07768458873033524, acc: 0.9664429426193237)
[2024-12-17 02:44:48,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,189][root][INFO] - Training Epoch: 2/2, step 1422/7134 completed (loss: 0.2778073847293854, acc: 0.8975903391838074)
[2024-12-17 02:44:49,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,585][root][INFO] - Training Epoch: 2/2, step 1423/7134 completed (loss: 0.5401263236999512, acc: 0.8396946787834167)
[2024-12-17 02:44:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:49,974][root][INFO] - Training Epoch: 2/2, step 1424/7134 completed (loss: 0.4418189823627472, acc: 0.8780487775802612)
[2024-12-17 02:44:50,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,352][root][INFO] - Training Epoch: 2/2, step 1425/7134 completed (loss: 0.35309791564941406, acc: 0.9075144529342651)
[2024-12-17 02:44:50,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:50,733][root][INFO] - Training Epoch: 2/2, step 1426/7134 completed (loss: 0.24967309832572937, acc: 0.9226804375648499)
[2024-12-17 02:44:50,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,134][root][INFO] - Training Epoch: 2/2, step 1427/7134 completed (loss: 0.43465209007263184, acc: 0.903954803943634)
[2024-12-17 02:44:51,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,489][root][INFO] - Training Epoch: 2/2, step 1428/7134 completed (loss: 0.9676361680030823, acc: 0.7822580933570862)
[2024-12-17 02:44:51,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:51,881][root][INFO] - Training Epoch: 2/2, step 1429/7134 completed (loss: 0.3151112198829651, acc: 0.9166666865348816)
[2024-12-17 02:44:51,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,257][root][INFO] - Training Epoch: 2/2, step 1430/7134 completed (loss: 0.21383750438690186, acc: 0.9280575513839722)
[2024-12-17 02:44:52,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:52,616][root][INFO] - Training Epoch: 2/2, step 1431/7134 completed (loss: 0.11388931423425674, acc: 0.9784946441650391)
[2024-12-17 02:44:52,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,014][root][INFO] - Training Epoch: 2/2, step 1432/7134 completed (loss: 0.22097818553447723, acc: 0.9447236061096191)
[2024-12-17 02:44:53,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,392][root][INFO] - Training Epoch: 2/2, step 1433/7134 completed (loss: 0.26449722051620483, acc: 0.9313725233078003)
[2024-12-17 02:44:53,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:53,765][root][INFO] - Training Epoch: 2/2, step 1434/7134 completed (loss: 0.2717365622520447, acc: 0.9004974961280823)
[2024-12-17 02:44:53,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,148][root][INFO] - Training Epoch: 2/2, step 1435/7134 completed (loss: 0.3075556755065918, acc: 0.9301075339317322)
[2024-12-17 02:44:54,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,555][root][INFO] - Training Epoch: 2/2, step 1436/7134 completed (loss: 0.2592877745628357, acc: 0.9490740895271301)
[2024-12-17 02:44:54,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:54,928][root][INFO] - Training Epoch: 2/2, step 1437/7134 completed (loss: 0.18006205558776855, acc: 0.9408602118492126)
[2024-12-17 02:44:55,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,323][root][INFO] - Training Epoch: 2/2, step 1438/7134 completed (loss: 0.2677054703235626, acc: 0.939393937587738)
[2024-12-17 02:44:55,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:55,696][root][INFO] - Training Epoch: 2/2, step 1439/7134 completed (loss: 0.15272444486618042, acc: 0.9629629850387573)
[2024-12-17 02:44:55,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,059][root][INFO] - Training Epoch: 2/2, step 1440/7134 completed (loss: 0.1932862251996994, acc: 0.9627329111099243)
[2024-12-17 02:44:56,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,440][root][INFO] - Training Epoch: 2/2, step 1441/7134 completed (loss: 0.1058853417634964, acc: 0.959770143032074)
[2024-12-17 02:44:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:56,818][root][INFO] - Training Epoch: 2/2, step 1442/7134 completed (loss: 0.09475196152925491, acc: 0.9910714030265808)
[2024-12-17 02:44:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,205][root][INFO] - Training Epoch: 2/2, step 1443/7134 completed (loss: 0.24766159057617188, acc: 0.9506173133850098)
[2024-12-17 02:44:57,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,581][root][INFO] - Training Epoch: 2/2, step 1444/7134 completed (loss: 0.12159611284732819, acc: 0.9861111044883728)
[2024-12-17 02:44:57,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:57,978][root][INFO] - Training Epoch: 2/2, step 1445/7134 completed (loss: 0.1725989133119583, acc: 0.9617834687232971)
[2024-12-17 02:44:58,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,364][root][INFO] - Training Epoch: 2/2, step 1446/7134 completed (loss: 0.18282632529735565, acc: 0.9494949579238892)
[2024-12-17 02:44:58,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:58,731][root][INFO] - Training Epoch: 2/2, step 1447/7134 completed (loss: 0.137288898229599, acc: 0.9731183052062988)
[2024-12-17 02:44:58,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,120][root][INFO] - Training Epoch: 2/2, step 1448/7134 completed (loss: 0.4566473364830017, acc: 0.888059675693512)
[2024-12-17 02:44:59,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,512][root][INFO] - Training Epoch: 2/2, step 1449/7134 completed (loss: 0.47892990708351135, acc: 0.8852459192276001)
[2024-12-17 02:44:59,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:44:59,900][root][INFO] - Training Epoch: 2/2, step 1450/7134 completed (loss: 0.35967788100242615, acc: 0.9144384860992432)
[2024-12-17 02:45:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,264][root][INFO] - Training Epoch: 2/2, step 1451/7134 completed (loss: 0.18803764879703522, acc: 0.9476439952850342)
[2024-12-17 02:45:00,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:00,661][root][INFO] - Training Epoch: 2/2, step 1452/7134 completed (loss: 0.18972384929656982, acc: 0.9444444179534912)
[2024-12-17 02:45:00,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,013][root][INFO] - Training Epoch: 2/2, step 1453/7134 completed (loss: 0.5084602236747742, acc: 0.8720930218696594)
[2024-12-17 02:45:01,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,393][root][INFO] - Training Epoch: 2/2, step 1454/7134 completed (loss: 0.29256391525268555, acc: 0.9114583134651184)
[2024-12-17 02:45:01,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:01,789][root][INFO] - Training Epoch: 2/2, step 1455/7134 completed (loss: 0.39015576243400574, acc: 0.8965517282485962)
[2024-12-17 02:45:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,168][root][INFO] - Training Epoch: 2/2, step 1456/7134 completed (loss: 0.26738160848617554, acc: 0.9173553586006165)
[2024-12-17 02:45:02,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,554][root][INFO] - Training Epoch: 2/2, step 1457/7134 completed (loss: 0.13103309273719788, acc: 0.9689440727233887)
[2024-12-17 02:45:02,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:02,962][root][INFO] - Training Epoch: 2/2, step 1458/7134 completed (loss: 0.20289896428585052, acc: 0.9467455744743347)
[2024-12-17 02:45:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,337][root][INFO] - Training Epoch: 2/2, step 1459/7134 completed (loss: 0.11344491690397263, acc: 0.9629629850387573)
[2024-12-17 02:45:03,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:03,697][root][INFO] - Training Epoch: 2/2, step 1460/7134 completed (loss: 0.4115470051765442, acc: 0.9053254723548889)
[2024-12-17 02:45:03,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,061][root][INFO] - Training Epoch: 2/2, step 1461/7134 completed (loss: 0.40885767340660095, acc: 0.8741722106933594)
[2024-12-17 02:45:04,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,459][root][INFO] - Training Epoch: 2/2, step 1462/7134 completed (loss: 0.20500943064689636, acc: 0.9552238583564758)
[2024-12-17 02:45:04,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:04,838][root][INFO] - Training Epoch: 2/2, step 1463/7134 completed (loss: 0.5516329407691956, acc: 0.8692810535430908)
[2024-12-17 02:45:04,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,238][root][INFO] - Training Epoch: 2/2, step 1464/7134 completed (loss: 0.4836122989654541, acc: 0.8975903391838074)
[2024-12-17 02:45:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:05,634][root][INFO] - Training Epoch: 2/2, step 1465/7134 completed (loss: 0.22311225533485413, acc: 0.9230769276618958)
[2024-12-17 02:45:05,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,026][root][INFO] - Training Epoch: 2/2, step 1466/7134 completed (loss: 0.1457134336233139, acc: 0.9553072452545166)
[2024-12-17 02:45:06,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,394][root][INFO] - Training Epoch: 2/2, step 1467/7134 completed (loss: 0.20702612400054932, acc: 0.9515151381492615)
[2024-12-17 02:45:06,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:06,796][root][INFO] - Training Epoch: 2/2, step 1468/7134 completed (loss: 0.25660526752471924, acc: 0.915730357170105)
[2024-12-17 02:45:06,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,193][root][INFO] - Training Epoch: 2/2, step 1469/7134 completed (loss: 0.10852193087339401, acc: 0.9659090638160706)
[2024-12-17 02:45:07,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,583][root][INFO] - Training Epoch: 2/2, step 1470/7134 completed (loss: 0.28015124797821045, acc: 0.9235668778419495)
[2024-12-17 02:45:07,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:07,948][root][INFO] - Training Epoch: 2/2, step 1471/7134 completed (loss: 0.41474494338035583, acc: 0.892307698726654)
[2024-12-17 02:45:08,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,342][root][INFO] - Training Epoch: 2/2, step 1472/7134 completed (loss: 0.13336725533008575, acc: 0.9707602262496948)
[2024-12-17 02:45:08,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:08,716][root][INFO] - Training Epoch: 2/2, step 1473/7134 completed (loss: 0.18056538701057434, acc: 0.9454545378684998)
[2024-12-17 02:45:08,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,092][root][INFO] - Training Epoch: 2/2, step 1474/7134 completed (loss: 0.2987176179885864, acc: 0.9034482836723328)
[2024-12-17 02:45:09,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,469][root][INFO] - Training Epoch: 2/2, step 1475/7134 completed (loss: 0.4483988881111145, acc: 0.9090909361839294)
[2024-12-17 02:45:09,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:09,818][root][INFO] - Training Epoch: 2/2, step 1476/7134 completed (loss: 0.28524231910705566, acc: 0.9399999976158142)
[2024-12-17 02:45:09,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,170][root][INFO] - Training Epoch: 2/2, step 1477/7134 completed (loss: 0.22798769176006317, acc: 0.9586206674575806)
[2024-12-17 02:45:10,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,555][root][INFO] - Training Epoch: 2/2, step 1478/7134 completed (loss: 0.26175832748413086, acc: 0.9407894611358643)
[2024-12-17 02:45:10,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:10,950][root][INFO] - Training Epoch: 2/2, step 1479/7134 completed (loss: 0.15333625674247742, acc: 0.9655172228813171)
[2024-12-17 02:45:11,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,348][root][INFO] - Training Epoch: 2/2, step 1480/7134 completed (loss: 0.12381180375814438, acc: 0.9723756909370422)
[2024-12-17 02:45:11,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:11,739][root][INFO] - Training Epoch: 2/2, step 1481/7134 completed (loss: 0.2383870631456375, acc: 0.9444444179534912)
[2024-12-17 02:45:11,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,133][root][INFO] - Training Epoch: 2/2, step 1482/7134 completed (loss: 0.3775492310523987, acc: 0.9112426042556763)
[2024-12-17 02:45:12,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,521][root][INFO] - Training Epoch: 2/2, step 1483/7134 completed (loss: 0.12248275429010391, acc: 0.9770992398262024)
[2024-12-17 02:45:12,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:12,911][root][INFO] - Training Epoch: 2/2, step 1484/7134 completed (loss: 0.3151751756668091, acc: 0.9156626462936401)
[2024-12-17 02:45:13,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,303][root][INFO] - Training Epoch: 2/2, step 1485/7134 completed (loss: 0.18861661851406097, acc: 0.9298245906829834)
[2024-12-17 02:45:13,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:13,682][root][INFO] - Training Epoch: 2/2, step 1486/7134 completed (loss: 0.12156541645526886, acc: 0.9685534834861755)
[2024-12-17 02:45:13,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,057][root][INFO] - Training Epoch: 2/2, step 1487/7134 completed (loss: 0.18265601992607117, acc: 0.9567567706108093)
[2024-12-17 02:45:14,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,441][root][INFO] - Training Epoch: 2/2, step 1488/7134 completed (loss: 0.2471584975719452, acc: 0.9255813956260681)
[2024-12-17 02:45:14,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:14,803][root][INFO] - Training Epoch: 2/2, step 1489/7134 completed (loss: 0.2656930983066559, acc: 0.9336734414100647)
[2024-12-17 02:45:14,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,200][root][INFO] - Training Epoch: 2/2, step 1490/7134 completed (loss: 0.33846309781074524, acc: 0.9292035102844238)
[2024-12-17 02:45:15,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,561][root][INFO] - Training Epoch: 2/2, step 1491/7134 completed (loss: 0.1535329967737198, acc: 0.9666666388511658)
[2024-12-17 02:45:15,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:15,945][root][INFO] - Training Epoch: 2/2, step 1492/7134 completed (loss: 0.24915239214897156, acc: 0.9431279897689819)
[2024-12-17 02:45:16,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,345][root][INFO] - Training Epoch: 2/2, step 1493/7134 completed (loss: 0.20125536620616913, acc: 0.9252336621284485)
[2024-12-17 02:45:16,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:16,736][root][INFO] - Training Epoch: 2/2, step 1494/7134 completed (loss: 0.2449239045381546, acc: 0.9119170904159546)
[2024-12-17 02:45:16,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,125][root][INFO] - Training Epoch: 2/2, step 1495/7134 completed (loss: 0.1749364733695984, acc: 0.9414634108543396)
[2024-12-17 02:45:17,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,512][root][INFO] - Training Epoch: 2/2, step 1496/7134 completed (loss: 0.1790086179971695, acc: 0.96875)
[2024-12-17 02:45:17,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:17,893][root][INFO] - Training Epoch: 2/2, step 1497/7134 completed (loss: 0.11362249404191971, acc: 0.9768518805503845)
[2024-12-17 02:45:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,264][root][INFO] - Training Epoch: 2/2, step 1498/7134 completed (loss: 0.21065998077392578, acc: 0.9405405521392822)
[2024-12-17 02:45:18,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:18,656][root][INFO] - Training Epoch: 2/2, step 1499/7134 completed (loss: 0.17129626870155334, acc: 0.9488372206687927)
[2024-12-17 02:45:18,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,018][root][INFO] - Training Epoch: 2/2, step 1500/7134 completed (loss: 0.4012264311313629, acc: 0.9109588861465454)
[2024-12-17 02:45:19,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,408][root][INFO] - Training Epoch: 2/2, step 1501/7134 completed (loss: 0.33683621883392334, acc: 0.9112426042556763)
[2024-12-17 02:45:19,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:19,796][root][INFO] - Training Epoch: 2/2, step 1502/7134 completed (loss: 0.25076985359191895, acc: 0.918181836605072)
[2024-12-17 02:45:19,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,166][root][INFO] - Training Epoch: 2/2, step 1503/7134 completed (loss: 0.3699488043785095, acc: 0.8971428275108337)
[2024-12-17 02:45:20,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,547][root][INFO] - Training Epoch: 2/2, step 1504/7134 completed (loss: 0.16121481359004974, acc: 0.9629629850387573)
[2024-12-17 02:45:20,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:20,920][root][INFO] - Training Epoch: 2/2, step 1505/7134 completed (loss: 0.2652428150177002, acc: 0.9240506291389465)
[2024-12-17 02:45:21,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,289][root][INFO] - Training Epoch: 2/2, step 1506/7134 completed (loss: 0.3242444694042206, acc: 0.893081784248352)
[2024-12-17 02:45:21,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:21,673][root][INFO] - Training Epoch: 2/2, step 1507/7134 completed (loss: 0.256344199180603, acc: 0.9322916865348816)
[2024-12-17 02:45:21,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,057][root][INFO] - Training Epoch: 2/2, step 1508/7134 completed (loss: 0.18104654550552368, acc: 0.9485981464385986)
[2024-12-17 02:45:22,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,443][root][INFO] - Training Epoch: 2/2, step 1509/7134 completed (loss: 0.15302175283432007, acc: 0.9444444179534912)
[2024-12-17 02:45:22,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:22,824][root][INFO] - Training Epoch: 2/2, step 1510/7134 completed (loss: 0.4632972478866577, acc: 0.896774172782898)
[2024-12-17 02:45:22,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,209][root][INFO] - Training Epoch: 2/2, step 1511/7134 completed (loss: 0.2736091911792755, acc: 0.9217877388000488)
[2024-12-17 02:45:23,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,582][root][INFO] - Training Epoch: 2/2, step 1512/7134 completed (loss: 0.14273858070373535, acc: 0.9666666388511658)
[2024-12-17 02:45:23,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:23,953][root][INFO] - Training Epoch: 2/2, step 1513/7134 completed (loss: 0.14970055222511292, acc: 0.950276255607605)
[2024-12-17 02:45:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,351][root][INFO] - Training Epoch: 2/2, step 1514/7134 completed (loss: 0.23826879262924194, acc: 0.9430052042007446)
[2024-12-17 02:45:24,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:24,742][root][INFO] - Training Epoch: 2/2, step 1515/7134 completed (loss: 0.24112780392169952, acc: 0.9729729890823364)
[2024-12-17 02:45:24,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,093][root][INFO] - Training Epoch: 2/2, step 1516/7134 completed (loss: 0.38693150877952576, acc: 0.925000011920929)
[2024-12-17 02:45:25,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,484][root][INFO] - Training Epoch: 2/2, step 1517/7134 completed (loss: 0.5556312203407288, acc: 0.8928571343421936)
[2024-12-17 02:45:25,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:25,886][root][INFO] - Training Epoch: 2/2, step 1518/7134 completed (loss: 0.28303253650665283, acc: 0.9175257682800293)
[2024-12-17 02:45:26,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,286][root][INFO] - Training Epoch: 2/2, step 1519/7134 completed (loss: 0.20402321219444275, acc: 0.9611650705337524)
[2024-12-17 02:45:26,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:26,674][root][INFO] - Training Epoch: 2/2, step 1520/7134 completed (loss: 0.19009700417518616, acc: 0.970802903175354)
[2024-12-17 02:45:26,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,070][root][INFO] - Training Epoch: 2/2, step 1521/7134 completed (loss: 0.8308137655258179, acc: 0.8161764740943909)
[2024-12-17 02:45:27,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,409][root][INFO] - Training Epoch: 2/2, step 1522/7134 completed (loss: 0.46785685420036316, acc: 0.8730158805847168)
[2024-12-17 02:45:27,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:27,777][root][INFO] - Training Epoch: 2/2, step 1523/7134 completed (loss: 0.7211171388626099, acc: 0.8552631735801697)
[2024-12-17 02:45:27,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,110][root][INFO] - Training Epoch: 2/2, step 1524/7134 completed (loss: 0.3730024993419647, acc: 0.931506872177124)
[2024-12-17 02:45:28,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,480][root][INFO] - Training Epoch: 2/2, step 1525/7134 completed (loss: 0.5706993341445923, acc: 0.8600000143051147)
[2024-12-17 02:45:28,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:28,873][root][INFO] - Training Epoch: 2/2, step 1526/7134 completed (loss: 0.6860918402671814, acc: 0.8231292366981506)
[2024-12-17 02:45:28,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,262][root][INFO] - Training Epoch: 2/2, step 1527/7134 completed (loss: 0.9447033405303955, acc: 0.8053097128868103)
[2024-12-17 02:45:29,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:29,658][root][INFO] - Training Epoch: 2/2, step 1528/7134 completed (loss: 0.5041896104812622, acc: 0.8695651888847351)
[2024-12-17 02:45:29,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,017][root][INFO] - Training Epoch: 2/2, step 1529/7134 completed (loss: 0.2823725938796997, acc: 0.9255319237709045)
[2024-12-17 02:45:30,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,441][root][INFO] - Training Epoch: 2/2, step 1530/7134 completed (loss: 0.37179896235466003, acc: 0.9107142686843872)
[2024-12-17 02:45:30,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:30,809][root][INFO] - Training Epoch: 2/2, step 1531/7134 completed (loss: 0.8603237867355347, acc: 0.7651515007019043)
[2024-12-17 02:45:30,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,220][root][INFO] - Training Epoch: 2/2, step 1532/7134 completed (loss: 0.2538500130176544, acc: 0.928205132484436)
[2024-12-17 02:45:31,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,628][root][INFO] - Training Epoch: 2/2, step 1533/7134 completed (loss: 0.3811444938182831, acc: 0.8975903391838074)
[2024-12-17 02:45:31,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:31,996][root][INFO] - Training Epoch: 2/2, step 1534/7134 completed (loss: 0.3000509738922119, acc: 0.9280575513839722)
[2024-12-17 02:45:32,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,385][root][INFO] - Training Epoch: 2/2, step 1535/7134 completed (loss: 0.24435004591941833, acc: 0.9314285516738892)
[2024-12-17 02:45:32,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:32,758][root][INFO] - Training Epoch: 2/2, step 1536/7134 completed (loss: 0.1914418488740921, acc: 0.9567901492118835)
[2024-12-17 02:45:32,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,112][root][INFO] - Training Epoch: 2/2, step 1537/7134 completed (loss: 0.3748001754283905, acc: 0.9122806787490845)
[2024-12-17 02:45:33,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,492][root][INFO] - Training Epoch: 2/2, step 1538/7134 completed (loss: 0.48445138335227966, acc: 0.9166666865348816)
[2024-12-17 02:45:33,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:33,884][root][INFO] - Training Epoch: 2/2, step 1539/7134 completed (loss: 0.274686723947525, acc: 0.9212121367454529)
[2024-12-17 02:45:34,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,267][root][INFO] - Training Epoch: 2/2, step 1540/7134 completed (loss: 0.307422012090683, acc: 0.9430379867553711)
[2024-12-17 02:45:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:34,650][root][INFO] - Training Epoch: 2/2, step 1541/7134 completed (loss: 0.3890841007232666, acc: 0.8947368264198303)
[2024-12-17 02:45:34,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,050][root][INFO] - Training Epoch: 2/2, step 1542/7134 completed (loss: 0.21176064014434814, acc: 0.9606741666793823)
[2024-12-17 02:45:35,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,424][root][INFO] - Training Epoch: 2/2, step 1543/7134 completed (loss: 0.268123596906662, acc: 0.938095211982727)
[2024-12-17 02:45:35,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:35,813][root][INFO] - Training Epoch: 2/2, step 1544/7134 completed (loss: 0.21318797767162323, acc: 0.9300000071525574)
[2024-12-17 02:45:35,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,217][root][INFO] - Training Epoch: 2/2, step 1545/7134 completed (loss: 0.28231772780418396, acc: 0.9226190447807312)
[2024-12-17 02:45:36,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:36,618][root][INFO] - Training Epoch: 2/2, step 1546/7134 completed (loss: 0.7441361546516418, acc: 0.8588235378265381)
[2024-12-17 02:45:36,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,008][root][INFO] - Training Epoch: 2/2, step 1547/7134 completed (loss: 0.4427841603755951, acc: 0.9012345671653748)
[2024-12-17 02:45:37,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,394][root][INFO] - Training Epoch: 2/2, step 1548/7134 completed (loss: 0.2772880494594574, acc: 0.9473684430122375)
[2024-12-17 02:45:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:37,786][root][INFO] - Training Epoch: 2/2, step 1549/7134 completed (loss: 0.13397254049777985, acc: 0.977142870426178)
[2024-12-17 02:45:37,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,164][root][INFO] - Training Epoch: 2/2, step 1550/7134 completed (loss: 0.18527287244796753, acc: 0.9352940917015076)
[2024-12-17 02:45:38,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,536][root][INFO] - Training Epoch: 2/2, step 1551/7134 completed (loss: 0.17028522491455078, acc: 0.9536423683166504)
[2024-12-17 02:45:38,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:38,917][root][INFO] - Training Epoch: 2/2, step 1552/7134 completed (loss: 0.10599140077829361, acc: 0.9897959232330322)
[2024-12-17 02:45:39,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,289][root][INFO] - Training Epoch: 2/2, step 1553/7134 completed (loss: 0.2605544924736023, acc: 0.9610389471054077)
[2024-12-17 02:45:39,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:39,690][root][INFO] - Training Epoch: 2/2, step 1554/7134 completed (loss: 0.3034237027168274, acc: 0.9248554706573486)
[2024-12-17 02:45:39,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,041][root][INFO] - Training Epoch: 2/2, step 1555/7134 completed (loss: 0.17675170302391052, acc: 0.949999988079071)
[2024-12-17 02:45:40,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,424][root][INFO] - Training Epoch: 2/2, step 1556/7134 completed (loss: 0.23301386833190918, acc: 0.9265536665916443)
[2024-12-17 02:45:40,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:40,811][root][INFO] - Training Epoch: 2/2, step 1557/7134 completed (loss: 0.198113352060318, acc: 0.9555555582046509)
[2024-12-17 02:45:40,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,203][root][INFO] - Training Epoch: 2/2, step 1558/7134 completed (loss: 0.2930566668510437, acc: 0.931506872177124)
[2024-12-17 02:45:41,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,567][root][INFO] - Training Epoch: 2/2, step 1559/7134 completed (loss: 0.2092779278755188, acc: 0.9485714435577393)
[2024-12-17 02:45:41,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:41,932][root][INFO] - Training Epoch: 2/2, step 1560/7134 completed (loss: 0.17415852844715118, acc: 0.9644669890403748)
[2024-12-17 02:45:42,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,304][root][INFO] - Training Epoch: 2/2, step 1561/7134 completed (loss: 0.5132723450660706, acc: 0.8663793206214905)
[2024-12-17 02:45:42,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:42,682][root][INFO] - Training Epoch: 2/2, step 1562/7134 completed (loss: 0.2490949034690857, acc: 0.9230769276618958)
[2024-12-17 02:45:42,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,067][root][INFO] - Training Epoch: 2/2, step 1563/7134 completed (loss: 0.3064701557159424, acc: 0.9313725233078003)
[2024-12-17 02:45:43,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,441][root][INFO] - Training Epoch: 2/2, step 1564/7134 completed (loss: 0.303747296333313, acc: 0.9158415794372559)
[2024-12-17 02:45:43,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:43,815][root][INFO] - Training Epoch: 2/2, step 1565/7134 completed (loss: 0.24860665202140808, acc: 0.955974817276001)
[2024-12-17 02:45:43,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,195][root][INFO] - Training Epoch: 2/2, step 1566/7134 completed (loss: 0.2816566526889801, acc: 0.9226519465446472)
[2024-12-17 02:45:44,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,592][root][INFO] - Training Epoch: 2/2, step 1567/7134 completed (loss: 0.5411590337753296, acc: 0.8926829099655151)
[2024-12-17 02:45:44,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:44,989][root][INFO] - Training Epoch: 2/2, step 1568/7134 completed (loss: 0.3675491213798523, acc: 0.9134615659713745)
[2024-12-17 02:45:45,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,363][root][INFO] - Training Epoch: 2/2, step 1569/7134 completed (loss: 0.47480329871177673, acc: 0.8909090757369995)
[2024-12-17 02:45:45,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:45,748][root][INFO] - Training Epoch: 2/2, step 1570/7134 completed (loss: 0.6313674449920654, acc: 0.8732394576072693)
[2024-12-17 02:45:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,112][root][INFO] - Training Epoch: 2/2, step 1571/7134 completed (loss: 0.37438490986824036, acc: 0.9124423861503601)
[2024-12-17 02:45:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,475][root][INFO] - Training Epoch: 2/2, step 1572/7134 completed (loss: 0.46327275037765503, acc: 0.934272289276123)
[2024-12-17 02:45:46,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:46,842][root][INFO] - Training Epoch: 2/2, step 1573/7134 completed (loss: 0.14058391749858856, acc: 0.970059871673584)
[2024-12-17 02:45:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,254][root][INFO] - Training Epoch: 2/2, step 1574/7134 completed (loss: 0.2799643576145172, acc: 0.9327354431152344)
[2024-12-17 02:45:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:47,627][root][INFO] - Training Epoch: 2/2, step 1575/7134 completed (loss: 0.32142549753189087, acc: 0.9409090876579285)
[2024-12-17 02:45:47,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,032][root][INFO] - Training Epoch: 2/2, step 1576/7134 completed (loss: 0.17775999009609222, acc: 0.9530516266822815)
[2024-12-17 02:45:48,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,370][root][INFO] - Training Epoch: 2/2, step 1577/7134 completed (loss: 0.24113042652606964, acc: 0.9323671460151672)
[2024-12-17 02:45:48,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:48,756][root][INFO] - Training Epoch: 2/2, step 1578/7134 completed (loss: 0.3352467119693756, acc: 0.9090909361839294)
[2024-12-17 02:45:48,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,136][root][INFO] - Training Epoch: 2/2, step 1579/7134 completed (loss: 0.26895537972450256, acc: 0.932692289352417)
[2024-12-17 02:45:49,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,503][root][INFO] - Training Epoch: 2/2, step 1580/7134 completed (loss: 0.4646095931529999, acc: 0.8840579986572266)
[2024-12-17 02:45:49,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:49,863][root][INFO] - Training Epoch: 2/2, step 1581/7134 completed (loss: 0.49292823672294617, acc: 0.8392857313156128)
[2024-12-17 02:45:49,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,242][root][INFO] - Training Epoch: 2/2, step 1582/7134 completed (loss: 0.544191837310791, acc: 0.8666666746139526)
[2024-12-17 02:45:50,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:50,613][root][INFO] - Training Epoch: 2/2, step 1583/7134 completed (loss: 0.2420251965522766, acc: 0.9371428489685059)
[2024-12-17 02:45:50,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,010][root][INFO] - Training Epoch: 2/2, step 1584/7134 completed (loss: 0.3339904844760895, acc: 0.9189189076423645)
[2024-12-17 02:45:51,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,405][root][INFO] - Training Epoch: 2/2, step 1585/7134 completed (loss: 0.2534373998641968, acc: 0.9126213788986206)
[2024-12-17 02:45:51,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:51,796][root][INFO] - Training Epoch: 2/2, step 1586/7134 completed (loss: 0.37319114804267883, acc: 0.9082125425338745)
[2024-12-17 02:45:51,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,181][root][INFO] - Training Epoch: 2/2, step 1587/7134 completed (loss: 0.22640852630138397, acc: 0.9490445852279663)
[2024-12-17 02:45:52,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,551][root][INFO] - Training Epoch: 2/2, step 1588/7134 completed (loss: 0.16878026723861694, acc: 0.9681528806686401)
[2024-12-17 02:45:52,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:52,913][root][INFO] - Training Epoch: 2/2, step 1589/7134 completed (loss: 0.20120550692081451, acc: 0.9512194991111755)
[2024-12-17 02:45:53,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,305][root][INFO] - Training Epoch: 2/2, step 1590/7134 completed (loss: 0.21043571829795837, acc: 0.9357143044471741)
[2024-12-17 02:45:53,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:53,768][root][INFO] - Training Epoch: 2/2, step 1591/7134 completed (loss: 0.19575844705104828, acc: 0.9689922332763672)
[2024-12-17 02:45:53,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,151][root][INFO] - Training Epoch: 2/2, step 1592/7134 completed (loss: 0.2686914801597595, acc: 0.9350649118423462)
[2024-12-17 02:45:54,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,574][root][INFO] - Training Epoch: 2/2, step 1593/7134 completed (loss: 0.16961604356765747, acc: 0.9572192430496216)
[2024-12-17 02:45:54,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:54,993][root][INFO] - Training Epoch: 2/2, step 1594/7134 completed (loss: 0.1635749638080597, acc: 0.9609375)
[2024-12-17 02:45:55,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,398][root][INFO] - Training Epoch: 2/2, step 1595/7134 completed (loss: 0.13878019154071808, acc: 0.9663865566253662)
[2024-12-17 02:45:55,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:55,797][root][INFO] - Training Epoch: 2/2, step 1596/7134 completed (loss: 0.32240030169487, acc: 0.9375)
[2024-12-17 02:45:55,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,186][root][INFO] - Training Epoch: 2/2, step 1597/7134 completed (loss: 0.14378610253334045, acc: 0.9602649211883545)
[2024-12-17 02:45:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,585][root][INFO] - Training Epoch: 2/2, step 1598/7134 completed (loss: 0.31362369656562805, acc: 0.9416666626930237)
[2024-12-17 02:45:56,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:56,980][root][INFO] - Training Epoch: 2/2, step 1599/7134 completed (loss: 0.3521690368652344, acc: 0.9034482836723328)
[2024-12-17 02:45:57,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,347][root][INFO] - Training Epoch: 2/2, step 1600/7134 completed (loss: 0.27706921100616455, acc: 0.9336734414100647)
[2024-12-17 02:45:57,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:57,751][root][INFO] - Training Epoch: 2/2, step 1601/7134 completed (loss: 0.11621862649917603, acc: 0.9696969985961914)
[2024-12-17 02:45:57,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,144][root][INFO] - Training Epoch: 2/2, step 1602/7134 completed (loss: 0.18188567459583282, acc: 0.9615384340286255)
[2024-12-17 02:45:58,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,495][root][INFO] - Training Epoch: 2/2, step 1603/7134 completed (loss: 0.2566557824611664, acc: 0.9156626462936401)
[2024-12-17 02:45:58,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:58,902][root][INFO] - Training Epoch: 2/2, step 1604/7134 completed (loss: 0.14391446113586426, acc: 0.9515151381492615)
[2024-12-17 02:45:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,305][root][INFO] - Training Epoch: 2/2, step 1605/7134 completed (loss: 0.17603427171707153, acc: 0.9588235020637512)
[2024-12-17 02:45:59,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,663][root][INFO] - Training Epoch: 2/2, step 1606/7134 completed (loss: 0.08030922710895538, acc: 0.9863945841789246)
[2024-12-17 02:45:59,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:45:59,998][root][INFO] - Training Epoch: 2/2, step 1607/7134 completed (loss: 0.1479177325963974, acc: 0.9636363387107849)
[2024-12-17 02:46:00,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,379][root][INFO] - Training Epoch: 2/2, step 1608/7134 completed (loss: 0.14972908794879913, acc: 0.960629940032959)
[2024-12-17 02:46:00,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:00,768][root][INFO] - Training Epoch: 2/2, step 1609/7134 completed (loss: 0.27117055654525757, acc: 0.9305555820465088)
[2024-12-17 02:46:00,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,130][root][INFO] - Training Epoch: 2/2, step 1610/7134 completed (loss: 0.15579983592033386, acc: 0.9312977194786072)
[2024-12-17 02:46:01,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,492][root][INFO] - Training Epoch: 2/2, step 1611/7134 completed (loss: 0.23413823544979095, acc: 0.9382715821266174)
[2024-12-17 02:46:01,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:01,848][root][INFO] - Training Epoch: 2/2, step 1612/7134 completed (loss: 0.205898255109787, acc: 0.9578313231468201)
[2024-12-17 02:46:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,211][root][INFO] - Training Epoch: 2/2, step 1613/7134 completed (loss: 0.21644850075244904, acc: 0.9316770434379578)
[2024-12-17 02:46:02,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,585][root][INFO] - Training Epoch: 2/2, step 1614/7134 completed (loss: 0.23793785274028778, acc: 0.9473684430122375)
[2024-12-17 02:46:02,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:02,964][root][INFO] - Training Epoch: 2/2, step 1615/7134 completed (loss: 0.18898917734622955, acc: 0.9337349534034729)
[2024-12-17 02:46:03,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,333][root][INFO] - Training Epoch: 2/2, step 1616/7134 completed (loss: 0.15718123316764832, acc: 0.9741935729980469)
[2024-12-17 02:46:03,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:03,689][root][INFO] - Training Epoch: 2/2, step 1617/7134 completed (loss: 0.13053877651691437, acc: 0.9640287756919861)
[2024-12-17 02:46:03,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,048][root][INFO] - Training Epoch: 2/2, step 1618/7134 completed (loss: 0.35998809337615967, acc: 0.9312977194786072)
[2024-12-17 02:46:04,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,399][root][INFO] - Training Epoch: 2/2, step 1619/7134 completed (loss: 0.3530394732952118, acc: 0.9085366129875183)
[2024-12-17 02:46:04,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:04,785][root][INFO] - Training Epoch: 2/2, step 1620/7134 completed (loss: 0.29097622632980347, acc: 0.9350649118423462)
[2024-12-17 02:46:04,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,211][root][INFO] - Training Epoch: 2/2, step 1621/7134 completed (loss: 0.39884015917778015, acc: 0.8627451062202454)
[2024-12-17 02:46:05,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,600][root][INFO] - Training Epoch: 2/2, step 1622/7134 completed (loss: 0.275126576423645, acc: 0.9346405267715454)
[2024-12-17 02:46:05,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:05,997][root][INFO] - Training Epoch: 2/2, step 1623/7134 completed (loss: 0.2713078558444977, acc: 0.8910256624221802)
[2024-12-17 02:46:06,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,394][root][INFO] - Training Epoch: 2/2, step 1624/7134 completed (loss: 0.33531832695007324, acc: 0.9220778942108154)
[2024-12-17 02:46:06,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:06,764][root][INFO] - Training Epoch: 2/2, step 1625/7134 completed (loss: 0.18000996112823486, acc: 0.9624999761581421)
[2024-12-17 02:46:06,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,140][root][INFO] - Training Epoch: 2/2, step 1626/7134 completed (loss: 0.4422527551651001, acc: 0.9175257682800293)
[2024-12-17 02:46:07,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,531][root][INFO] - Training Epoch: 2/2, step 1627/7134 completed (loss: 0.3129304349422455, acc: 0.9105691313743591)
[2024-12-17 02:46:07,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:07,910][root][INFO] - Training Epoch: 2/2, step 1628/7134 completed (loss: 0.1265881210565567, acc: 0.9753086566925049)
[2024-12-17 02:46:08,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,266][root][INFO] - Training Epoch: 2/2, step 1629/7134 completed (loss: 0.22705265879631042, acc: 0.9242424368858337)
[2024-12-17 02:46:08,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:08,668][root][INFO] - Training Epoch: 2/2, step 1630/7134 completed (loss: 0.298240602016449, acc: 0.9432623982429504)
[2024-12-17 02:46:08,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,073][root][INFO] - Training Epoch: 2/2, step 1631/7134 completed (loss: 0.49049893021583557, acc: 0.9064748287200928)
[2024-12-17 02:46:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,437][root][INFO] - Training Epoch: 2/2, step 1632/7134 completed (loss: 0.20722725987434387, acc: 0.9402984976768494)
[2024-12-17 02:46:09,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:09,815][root][INFO] - Training Epoch: 2/2, step 1633/7134 completed (loss: 0.3397546410560608, acc: 0.9071428775787354)
[2024-12-17 02:46:09,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,215][root][INFO] - Training Epoch: 2/2, step 1634/7134 completed (loss: 0.2236039787530899, acc: 0.9308176040649414)
[2024-12-17 02:46:10,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,597][root][INFO] - Training Epoch: 2/2, step 1635/7134 completed (loss: 0.26133081316947937, acc: 0.9259259104728699)
[2024-12-17 02:46:10,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:10,973][root][INFO] - Training Epoch: 2/2, step 1636/7134 completed (loss: 0.362021267414093, acc: 0.9357798099517822)
[2024-12-17 02:46:11,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,378][root][INFO] - Training Epoch: 2/2, step 1637/7134 completed (loss: 0.24847692251205444, acc: 0.9503105878829956)
[2024-12-17 02:46:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:11,767][root][INFO] - Training Epoch: 2/2, step 1638/7134 completed (loss: 0.510959804058075, acc: 0.8425197005271912)
[2024-12-17 02:46:11,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,133][root][INFO] - Training Epoch: 2/2, step 1639/7134 completed (loss: 0.6194770336151123, acc: 0.8695651888847351)
[2024-12-17 02:46:12,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,514][root][INFO] - Training Epoch: 2/2, step 1640/7134 completed (loss: 0.38186246156692505, acc: 0.8985507488250732)
[2024-12-17 02:46:12,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:12,872][root][INFO] - Training Epoch: 2/2, step 1641/7134 completed (loss: 0.32565101981163025, acc: 0.9210526347160339)
[2024-12-17 02:46:13,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,259][root][INFO] - Training Epoch: 2/2, step 1642/7134 completed (loss: 0.35580766201019287, acc: 0.893081784248352)
[2024-12-17 02:46:13,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:13,627][root][INFO] - Training Epoch: 2/2, step 1643/7134 completed (loss: 0.6877283453941345, acc: 0.8272727131843567)
[2024-12-17 02:46:13,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,013][root][INFO] - Training Epoch: 2/2, step 1644/7134 completed (loss: 0.3084310293197632, acc: 0.9056603908538818)
[2024-12-17 02:46:14,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,384][root][INFO] - Training Epoch: 2/2, step 1645/7134 completed (loss: 0.4142528176307678, acc: 0.9103448390960693)
[2024-12-17 02:46:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:14,775][root][INFO] - Training Epoch: 2/2, step 1646/7134 completed (loss: 0.29030436277389526, acc: 0.9225806593894958)
[2024-12-17 02:46:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,186][root][INFO] - Training Epoch: 2/2, step 1647/7134 completed (loss: 0.26760685443878174, acc: 0.920187771320343)
[2024-12-17 02:46:15,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,571][root][INFO] - Training Epoch: 2/2, step 1648/7134 completed (loss: 0.326647013425827, acc: 0.93034827709198)
[2024-12-17 02:46:15,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:15,939][root][INFO] - Training Epoch: 2/2, step 1649/7134 completed (loss: 0.21444013714790344, acc: 0.9424778819084167)
[2024-12-17 02:46:16,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,315][root][INFO] - Training Epoch: 2/2, step 1650/7134 completed (loss: 0.27652305364608765, acc: 0.9195979833602905)
[2024-12-17 02:46:16,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:16,708][root][INFO] - Training Epoch: 2/2, step 1651/7134 completed (loss: 0.3077656924724579, acc: 0.9272727370262146)
[2024-12-17 02:46:16,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,092][root][INFO] - Training Epoch: 2/2, step 1652/7134 completed (loss: 0.2541047930717468, acc: 0.9188033938407898)
[2024-12-17 02:46:17,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,486][root][INFO] - Training Epoch: 2/2, step 1653/7134 completed (loss: 0.24629123508930206, acc: 0.9344262480735779)
[2024-12-17 02:46:17,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:17,880][root][INFO] - Training Epoch: 2/2, step 1654/7134 completed (loss: 0.21357357501983643, acc: 0.9442059993743896)
[2024-12-17 02:46:17,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,269][root][INFO] - Training Epoch: 2/2, step 1655/7134 completed (loss: 0.143523707985878, acc: 0.9642857313156128)
[2024-12-17 02:46:18,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:18,650][root][INFO] - Training Epoch: 2/2, step 1656/7134 completed (loss: 0.3180611729621887, acc: 0.9282511472702026)
[2024-12-17 02:46:18,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,042][root][INFO] - Training Epoch: 2/2, step 1657/7134 completed (loss: 0.28285863995552063, acc: 0.9418604373931885)
[2024-12-17 02:46:19,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,439][root][INFO] - Training Epoch: 2/2, step 1658/7134 completed (loss: 0.26315903663635254, acc: 0.9336099624633789)
[2024-12-17 02:46:19,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:19,817][root][INFO] - Training Epoch: 2/2, step 1659/7134 completed (loss: 0.2929288446903229, acc: 0.9240000247955322)
[2024-12-17 02:46:19,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,217][root][INFO] - Training Epoch: 2/2, step 1660/7134 completed (loss: 0.23596273362636566, acc: 0.942307710647583)
[2024-12-17 02:46:20,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,581][root][INFO] - Training Epoch: 2/2, step 1661/7134 completed (loss: 0.25231003761291504, acc: 0.939393937587738)
[2024-12-17 02:46:20,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:20,949][root][INFO] - Training Epoch: 2/2, step 1662/7134 completed (loss: 0.13165737688541412, acc: 0.9620853066444397)
[2024-12-17 02:46:21,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,330][root][INFO] - Training Epoch: 2/2, step 1663/7134 completed (loss: 0.13064663112163544, acc: 0.9659574627876282)
[2024-12-17 02:46:21,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:21,716][root][INFO] - Training Epoch: 2/2, step 1664/7134 completed (loss: 0.15161330997943878, acc: 0.949999988079071)
[2024-12-17 02:46:21,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,124][root][INFO] - Training Epoch: 2/2, step 1665/7134 completed (loss: 0.15266039967536926, acc: 0.9447852969169617)
[2024-12-17 02:46:22,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,543][root][INFO] - Training Epoch: 2/2, step 1666/7134 completed (loss: 0.13653376698493958, acc: 0.9621848464012146)
[2024-12-17 02:46:22,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:22,940][root][INFO] - Training Epoch: 2/2, step 1667/7134 completed (loss: 0.25054699182510376, acc: 0.9242424368858337)
[2024-12-17 02:46:23,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,384][root][INFO] - Training Epoch: 2/2, step 1668/7134 completed (loss: 0.12252189218997955, acc: 0.9820627570152283)
[2024-12-17 02:46:23,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:23,883][root][INFO] - Training Epoch: 2/2, step 1669/7134 completed (loss: 0.1679942011833191, acc: 0.9580152630805969)
[2024-12-17 02:46:24,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,285][root][INFO] - Training Epoch: 2/2, step 1670/7134 completed (loss: 0.3399924337863922, acc: 0.9239543676376343)
[2024-12-17 02:46:24,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:24,651][root][INFO] - Training Epoch: 2/2, step 1671/7134 completed (loss: 0.18107637763023376, acc: 0.9642857313156128)
[2024-12-17 02:46:24,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,028][root][INFO] - Training Epoch: 2/2, step 1672/7134 completed (loss: 0.3529667854309082, acc: 0.9298245906829834)
[2024-12-17 02:46:25,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,401][root][INFO] - Training Epoch: 2/2, step 1673/7134 completed (loss: 0.3314754068851471, acc: 0.9254658222198486)
[2024-12-17 02:46:25,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:25,758][root][INFO] - Training Epoch: 2/2, step 1674/7134 completed (loss: 0.41110309958457947, acc: 0.9078947305679321)
[2024-12-17 02:46:25,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,149][root][INFO] - Training Epoch: 2/2, step 1675/7134 completed (loss: 0.3405633568763733, acc: 0.9178082346916199)
[2024-12-17 02:46:26,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,531][root][INFO] - Training Epoch: 2/2, step 1676/7134 completed (loss: 0.3653700053691864, acc: 0.9166666865348816)
[2024-12-17 02:46:26,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:26,885][root][INFO] - Training Epoch: 2/2, step 1677/7134 completed (loss: 0.432731568813324, acc: 0.9007092118263245)
[2024-12-17 02:46:27,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,279][root][INFO] - Training Epoch: 2/2, step 1678/7134 completed (loss: 0.26975226402282715, acc: 0.9341317415237427)
[2024-12-17 02:46:27,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:27,675][root][INFO] - Training Epoch: 2/2, step 1679/7134 completed (loss: 0.30842864513397217, acc: 0.9329268336296082)
[2024-12-17 02:46:27,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,080][root][INFO] - Training Epoch: 2/2, step 1680/7134 completed (loss: 0.2661941349506378, acc: 0.9235293865203857)
[2024-12-17 02:46:28,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,461][root][INFO] - Training Epoch: 2/2, step 1681/7134 completed (loss: 0.32414472103118896, acc: 0.9245283007621765)
[2024-12-17 02:46:28,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:28,859][root][INFO] - Training Epoch: 2/2, step 1682/7134 completed (loss: 0.32546839118003845, acc: 0.9178082346916199)
[2024-12-17 02:46:28,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,254][root][INFO] - Training Epoch: 2/2, step 1683/7134 completed (loss: 0.2285832315683365, acc: 0.931034505367279)
[2024-12-17 02:46:29,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:29,630][root][INFO] - Training Epoch: 2/2, step 1684/7134 completed (loss: 0.12282559275627136, acc: 0.9858155846595764)
[2024-12-17 02:46:29,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,022][root][INFO] - Training Epoch: 2/2, step 1685/7134 completed (loss: 0.24595196545124054, acc: 0.9575757384300232)
[2024-12-17 02:46:30,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,404][root][INFO] - Training Epoch: 2/2, step 1686/7134 completed (loss: 0.3569272458553314, acc: 0.932330846786499)
[2024-12-17 02:46:30,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:30,789][root][INFO] - Training Epoch: 2/2, step 1687/7134 completed (loss: 0.21992093324661255, acc: 0.9469026327133179)
[2024-12-17 02:46:30,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,140][root][INFO] - Training Epoch: 2/2, step 1688/7134 completed (loss: 0.17079856991767883, acc: 0.9589040875434875)
[2024-12-17 02:46:31,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,495][root][INFO] - Training Epoch: 2/2, step 1689/7134 completed (loss: 0.21224012970924377, acc: 0.9161290526390076)
[2024-12-17 02:46:31,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:31,862][root][INFO] - Training Epoch: 2/2, step 1690/7134 completed (loss: 0.15497638285160065, acc: 0.9469026327133179)
[2024-12-17 02:46:31,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,243][root][INFO] - Training Epoch: 2/2, step 1691/7134 completed (loss: 0.17435358464717865, acc: 0.957446813583374)
[2024-12-17 02:46:32,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:32,639][root][INFO] - Training Epoch: 2/2, step 1692/7134 completed (loss: 0.16650578379631042, acc: 0.9512194991111755)
[2024-12-17 02:46:32,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,020][root][INFO] - Training Epoch: 2/2, step 1693/7134 completed (loss: 0.167638897895813, acc: 0.9591836929321289)
[2024-12-17 02:46:33,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,378][root][INFO] - Training Epoch: 2/2, step 1694/7134 completed (loss: 0.34270423650741577, acc: 0.9172413945198059)
[2024-12-17 02:46:33,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:33,755][root][INFO] - Training Epoch: 2/2, step 1695/7134 completed (loss: 0.27922576665878296, acc: 0.924369752407074)
[2024-12-17 02:46:33,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,123][root][INFO] - Training Epoch: 2/2, step 1696/7134 completed (loss: 0.356886088848114, acc: 0.8947368264198303)
[2024-12-17 02:46:34,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,538][root][INFO] - Training Epoch: 2/2, step 1697/7134 completed (loss: 0.18921178579330444, acc: 0.9580419659614563)
[2024-12-17 02:46:34,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:34,952][root][INFO] - Training Epoch: 2/2, step 1698/7134 completed (loss: 0.07962281256914139, acc: 0.9860140085220337)
[2024-12-17 02:46:35,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,355][root][INFO] - Training Epoch: 2/2, step 1699/7134 completed (loss: 0.2086338847875595, acc: 0.9477611780166626)
[2024-12-17 02:46:35,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:35,756][root][INFO] - Training Epoch: 2/2, step 1700/7134 completed (loss: 0.2937876880168915, acc: 0.9104477763175964)
[2024-12-17 02:46:35,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,138][root][INFO] - Training Epoch: 2/2, step 1701/7134 completed (loss: 0.38358834385871887, acc: 0.8999999761581421)
[2024-12-17 02:46:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,540][root][INFO] - Training Epoch: 2/2, step 1702/7134 completed (loss: 0.27815815806388855, acc: 0.9281437397003174)
[2024-12-17 02:46:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:36,921][root][INFO] - Training Epoch: 2/2, step 1703/7134 completed (loss: 0.5407111644744873, acc: 0.8940397500991821)
[2024-12-17 02:46:37,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,314][root][INFO] - Training Epoch: 2/2, step 1704/7134 completed (loss: 0.5075517296791077, acc: 0.8780487775802612)
[2024-12-17 02:46:37,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:37,711][root][INFO] - Training Epoch: 2/2, step 1705/7134 completed (loss: 0.2805453836917877, acc: 0.9520000219345093)
[2024-12-17 02:46:37,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,109][root][INFO] - Training Epoch: 2/2, step 1706/7134 completed (loss: 0.30512258410453796, acc: 0.9571428298950195)
[2024-12-17 02:46:38,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,478][root][INFO] - Training Epoch: 2/2, step 1707/7134 completed (loss: 0.4484289884567261, acc: 0.931034505367279)
[2024-12-17 02:46:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:38,875][root][INFO] - Training Epoch: 2/2, step 1708/7134 completed (loss: 0.2354436218738556, acc: 0.9629629850387573)
[2024-12-17 02:46:39,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,242][root][INFO] - Training Epoch: 2/2, step 1709/7134 completed (loss: 0.3580596148967743, acc: 0.9066666960716248)
[2024-12-17 02:46:39,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:39,623][root][INFO] - Training Epoch: 2/2, step 1710/7134 completed (loss: 0.40796732902526855, acc: 0.8851351141929626)
[2024-12-17 02:46:39,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,000][root][INFO] - Training Epoch: 2/2, step 1711/7134 completed (loss: 0.2709851861000061, acc: 0.9596773982048035)
[2024-12-17 02:46:40,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,377][root][INFO] - Training Epoch: 2/2, step 1712/7134 completed (loss: 0.25040867924690247, acc: 0.9444444179534912)
[2024-12-17 02:46:40,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:40,762][root][INFO] - Training Epoch: 2/2, step 1713/7134 completed (loss: 0.3256976902484894, acc: 0.9238095283508301)
[2024-12-17 02:46:40,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,147][root][INFO] - Training Epoch: 2/2, step 1714/7134 completed (loss: 0.23326720297336578, acc: 0.9290780425071716)
[2024-12-17 02:46:41,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,517][root][INFO] - Training Epoch: 2/2, step 1715/7134 completed (loss: 0.17850027978420258, acc: 0.9716981053352356)
[2024-12-17 02:46:41,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:41,907][root][INFO] - Training Epoch: 2/2, step 1716/7134 completed (loss: 0.40539315342903137, acc: 0.9144737124443054)
[2024-12-17 02:46:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,241][root][INFO] - Training Epoch: 2/2, step 1717/7134 completed (loss: 0.25345346331596375, acc: 0.9224806427955627)
[2024-12-17 02:46:42,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,600][root][INFO] - Training Epoch: 2/2, step 1718/7134 completed (loss: 0.3263045847415924, acc: 0.9230769276618958)
[2024-12-17 02:46:42,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:42,992][root][INFO] - Training Epoch: 2/2, step 1719/7134 completed (loss: 0.27353695034980774, acc: 0.9526627063751221)
[2024-12-17 02:46:43,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,408][root][INFO] - Training Epoch: 2/2, step 1720/7134 completed (loss: 0.5810883641242981, acc: 0.8538461327552795)
[2024-12-17 02:46:43,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:43,769][root][INFO] - Training Epoch: 2/2, step 1721/7134 completed (loss: 0.20916272699832916, acc: 0.9453125)
[2024-12-17 02:46:43,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,181][root][INFO] - Training Epoch: 2/2, step 1722/7134 completed (loss: 0.14059098064899445, acc: 0.9696969985961914)
[2024-12-17 02:46:44,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,561][root][INFO] - Training Epoch: 2/2, step 1723/7134 completed (loss: 0.5359881520271301, acc: 0.895061731338501)
[2024-12-17 02:46:44,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:44,958][root][INFO] - Training Epoch: 2/2, step 1724/7134 completed (loss: 0.2972375452518463, acc: 0.9140625)
[2024-12-17 02:46:45,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,303][root][INFO] - Training Epoch: 2/2, step 1725/7134 completed (loss: 0.26138338446617126, acc: 0.9104477763175964)
[2024-12-17 02:46:45,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:45,669][root][INFO] - Training Epoch: 2/2, step 1726/7134 completed (loss: 0.19827482104301453, acc: 0.9354838728904724)
[2024-12-17 02:46:45,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,055][root][INFO] - Training Epoch: 2/2, step 1727/7134 completed (loss: 0.18767079710960388, acc: 0.9734513163566589)
[2024-12-17 02:46:46,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,454][root][INFO] - Training Epoch: 2/2, step 1728/7134 completed (loss: 0.16567429900169373, acc: 0.9538461565971375)
[2024-12-17 02:46:46,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:46,835][root][INFO] - Training Epoch: 2/2, step 1729/7134 completed (loss: 0.2895404100418091, acc: 0.9009009003639221)
[2024-12-17 02:46:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,228][root][INFO] - Training Epoch: 2/2, step 1730/7134 completed (loss: 0.22103527188301086, acc: 0.9532710313796997)
[2024-12-17 02:46:47,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,607][root][INFO] - Training Epoch: 2/2, step 1731/7134 completed (loss: 0.4875691533088684, acc: 0.8674699068069458)
[2024-12-17 02:46:47,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:47,977][root][INFO] - Training Epoch: 2/2, step 1732/7134 completed (loss: 0.22664019465446472, acc: 0.9444444179534912)
[2024-12-17 02:46:48,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,387][root][INFO] - Training Epoch: 2/2, step 1733/7134 completed (loss: 0.4059823155403137, acc: 0.8990825414657593)
[2024-12-17 02:46:48,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:48,756][root][INFO] - Training Epoch: 2/2, step 1734/7134 completed (loss: 0.4293183386325836, acc: 0.9156626462936401)
[2024-12-17 02:46:48,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,119][root][INFO] - Training Epoch: 2/2, step 1735/7134 completed (loss: 0.15385209023952484, acc: 0.9602649211883545)
[2024-12-17 02:46:49,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,486][root][INFO] - Training Epoch: 2/2, step 1736/7134 completed (loss: 0.26244524121284485, acc: 0.949367105960846)
[2024-12-17 02:46:49,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:49,879][root][INFO] - Training Epoch: 2/2, step 1737/7134 completed (loss: 0.2557331323623657, acc: 0.9333333373069763)
[2024-12-17 02:46:49,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,275][root][INFO] - Training Epoch: 2/2, step 1738/7134 completed (loss: 0.1311219483613968, acc: 0.9553072452545166)
[2024-12-17 02:46:50,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:50,656][root][INFO] - Training Epoch: 2/2, step 1739/7134 completed (loss: 0.2489720731973648, acc: 0.9248120188713074)
[2024-12-17 02:46:50,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,030][root][INFO] - Training Epoch: 2/2, step 1740/7134 completed (loss: 0.13552969694137573, acc: 0.9527027010917664)
[2024-12-17 02:46:51,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,423][root][INFO] - Training Epoch: 2/2, step 1741/7134 completed (loss: 0.25230252742767334, acc: 0.9440993666648865)
[2024-12-17 02:46:51,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:51,791][root][INFO] - Training Epoch: 2/2, step 1742/7134 completed (loss: 0.2898065447807312, acc: 0.9271523356437683)
[2024-12-17 02:46:51,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,177][root][INFO] - Training Epoch: 2/2, step 1743/7134 completed (loss: 0.44336825609207153, acc: 0.8979591727256775)
[2024-12-17 02:46:52,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,557][root][INFO] - Training Epoch: 2/2, step 1744/7134 completed (loss: 0.17585010826587677, acc: 0.9548872113227844)
[2024-12-17 02:46:52,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:52,943][root][INFO] - Training Epoch: 2/2, step 1745/7134 completed (loss: 0.1998181939125061, acc: 0.9529411792755127)
[2024-12-17 02:46:53,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,337][root][INFO] - Training Epoch: 2/2, step 1746/7134 completed (loss: 0.13267798721790314, acc: 0.9645389914512634)
[2024-12-17 02:46:53,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:53,730][root][INFO] - Training Epoch: 2/2, step 1747/7134 completed (loss: 0.2529612183570862, acc: 0.9207317233085632)
[2024-12-17 02:46:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,132][root][INFO] - Training Epoch: 2/2, step 1748/7134 completed (loss: 0.22032073140144348, acc: 0.929411768913269)
[2024-12-17 02:46:54,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,500][root][INFO] - Training Epoch: 2/2, step 1749/7134 completed (loss: 0.34039413928985596, acc: 0.9214659929275513)
[2024-12-17 02:46:54,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:54,901][root][INFO] - Training Epoch: 2/2, step 1750/7134 completed (loss: 0.29896679520606995, acc: 0.9408283829689026)
[2024-12-17 02:46:55,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,285][root][INFO] - Training Epoch: 2/2, step 1751/7134 completed (loss: 0.39547228813171387, acc: 0.8928571343421936)
[2024-12-17 02:46:55,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:55,680][root][INFO] - Training Epoch: 2/2, step 1752/7134 completed (loss: 0.37659233808517456, acc: 0.939393937587738)
[2024-12-17 02:46:55,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,068][root][INFO] - Training Epoch: 2/2, step 1753/7134 completed (loss: 0.35019299387931824, acc: 0.9205297827720642)
[2024-12-17 02:46:56,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,462][root][INFO] - Training Epoch: 2/2, step 1754/7134 completed (loss: 0.3761938214302063, acc: 0.9019607901573181)
[2024-12-17 02:46:56,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:56,851][root][INFO] - Training Epoch: 2/2, step 1755/7134 completed (loss: 0.27216634154319763, acc: 0.9215686321258545)
[2024-12-17 02:46:56,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,234][root][INFO] - Training Epoch: 2/2, step 1756/7134 completed (loss: 0.4017883241176605, acc: 0.8799999952316284)
[2024-12-17 02:46:57,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,598][root][INFO] - Training Epoch: 2/2, step 1757/7134 completed (loss: 0.20457978546619415, acc: 0.9504132270812988)
[2024-12-17 02:46:57,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:57,973][root][INFO] - Training Epoch: 2/2, step 1758/7134 completed (loss: 0.1280549019575119, acc: 0.9764705896377563)
[2024-12-17 02:46:58,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,350][root][INFO] - Training Epoch: 2/2, step 1759/7134 completed (loss: 0.14590536057949066, acc: 0.9736841917037964)
[2024-12-17 02:46:58,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:58,757][root][INFO] - Training Epoch: 2/2, step 1760/7134 completed (loss: 0.18102334439754486, acc: 0.9426229596138)
[2024-12-17 02:46:58,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,216][root][INFO] - Training Epoch: 2/2, step 1761/7134 completed (loss: 0.20507238805294037, acc: 0.9428571462631226)
[2024-12-17 02:46:59,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,647][root][INFO] - Training Epoch: 2/2, step 1762/7134 completed (loss: 0.3213258683681488, acc: 0.9223300814628601)
[2024-12-17 02:46:59,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:46:59,987][root][INFO] - Training Epoch: 2/2, step 1763/7134 completed (loss: 0.23520463705062866, acc: 0.9178082346916199)
[2024-12-17 02:47:00,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,318][root][INFO] - Training Epoch: 2/2, step 1764/7134 completed (loss: 0.27563121914863586, acc: 0.9274193644523621)
[2024-12-17 02:47:00,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:00,706][root][INFO] - Training Epoch: 2/2, step 1765/7134 completed (loss: 0.28558188676834106, acc: 0.9084967374801636)
[2024-12-17 02:47:00,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,070][root][INFO] - Training Epoch: 2/2, step 1766/7134 completed (loss: 0.3420162498950958, acc: 0.9025974273681641)
[2024-12-17 02:47:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,469][root][INFO] - Training Epoch: 2/2, step 1767/7134 completed (loss: 0.27350300550460815, acc: 0.9209039807319641)
[2024-12-17 02:47:01,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:01,837][root][INFO] - Training Epoch: 2/2, step 1768/7134 completed (loss: 0.12394208461046219, acc: 0.9732142686843872)
[2024-12-17 02:47:01,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,214][root][INFO] - Training Epoch: 2/2, step 1769/7134 completed (loss: 0.2238733470439911, acc: 0.95333331823349)
[2024-12-17 02:47:02,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,576][root][INFO] - Training Epoch: 2/2, step 1770/7134 completed (loss: 0.2923363745212555, acc: 0.9520547986030579)
[2024-12-17 02:47:02,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:02,972][root][INFO] - Training Epoch: 2/2, step 1771/7134 completed (loss: 0.33588218688964844, acc: 0.9285714030265808)
[2024-12-17 02:47:03,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,360][root][INFO] - Training Epoch: 2/2, step 1772/7134 completed (loss: 0.22088675200939178, acc: 0.949999988079071)
[2024-12-17 02:47:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:03,719][root][INFO] - Training Epoch: 2/2, step 1773/7134 completed (loss: 0.23835724592208862, acc: 0.9432623982429504)
[2024-12-17 02:47:03,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,097][root][INFO] - Training Epoch: 2/2, step 1774/7134 completed (loss: 0.10714374482631683, acc: 0.9772727489471436)
[2024-12-17 02:47:04,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,472][root][INFO] - Training Epoch: 2/2, step 1775/7134 completed (loss: 0.057937368750572205, acc: 0.9863013625144958)
[2024-12-17 02:47:04,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:04,839][root][INFO] - Training Epoch: 2/2, step 1776/7134 completed (loss: 0.1958051323890686, acc: 0.9586206674575806)
[2024-12-17 02:47:04,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,247][root][INFO] - Training Epoch: 2/2, step 1777/7134 completed (loss: 0.08699310570955276, acc: 0.9808917045593262)
[2024-12-17 02:47:05,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,611][root][INFO] - Training Epoch: 2/2, step 1778/7134 completed (loss: 0.2948068678379059, acc: 0.9371069073677063)
[2024-12-17 02:47:05,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:05,949][root][INFO] - Training Epoch: 2/2, step 1779/7134 completed (loss: 0.16053439676761627, acc: 0.9557521939277649)
[2024-12-17 02:47:06,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:06,330][root][INFO] - Training Epoch: 2/2, step 1780/7134 completed (loss: 0.18600600957870483, acc: 0.9580838084220886)
[2024-12-17 02:47:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:07,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:08,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:10,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:11,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:12,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:13,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:14,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:15,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:16,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:17,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:18,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:19,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:20,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:21,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:23,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:24,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:25,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:26,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:27,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:28,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:29,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:30,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:31,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:32,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:33,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:34,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:35,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:36,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:37,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:39,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:40,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:41,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:42,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:43,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:44,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:45,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:46,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:47,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:48,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:49,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:50,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:51,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:52,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:53,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:54,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:55,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:56,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:57,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:58,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:47:59,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:00,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:02,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:03,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:04,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:05,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:06,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:07,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:08,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:09,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:10,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:11,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:12,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:13,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:14,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:15,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:16,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:18,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:19,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:20,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:21,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:23,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:24,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:25,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:26,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:27,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:28,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:29,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:30,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:31,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:32,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:33,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:34,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:35,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:36,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:37,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:38,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:39,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:40,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:41,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:42,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:43,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:44,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:46,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:47,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:48,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:49,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:50,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:51,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:52,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:53,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:55,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:56,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:57,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:48:59,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:00,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:01,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:02,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:03,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:04,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:05,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:06,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:07,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:08,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:09,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:11,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:12,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:13,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:14,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:15,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:16,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:17,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:18,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:19,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:20,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:21,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:22,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:23,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:24,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:25,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:26,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:27,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:28,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:30,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:31,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:32,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:33,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:34,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:35,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:36,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:37,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:38,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:39,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:40,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:41,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:42,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:43,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:44,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:45,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:46,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:47,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:48,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:49,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:50,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:51,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:52,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:53,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:54,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:55,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:56,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:57,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:58,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:49:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:00,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:01,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:02,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:03,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:04,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:05,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:06,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:07,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:08,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:09,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:10,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:11,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:12,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:13,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:14,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:15,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:16,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:17,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:18,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:19,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:21,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:23,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:24,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:25,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:27,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:28,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:30,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:31,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:32,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:33,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:34,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:35,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:36,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:37,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:38,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:39,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:41,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:43,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:44,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:45,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:46,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:47,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:49,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:51,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:52,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:53,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:54,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:56,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:58,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:50:59,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:00,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:01,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:02,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:04,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:05,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:06,405][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.4726, device='cuda:0') eval_epoch_loss=tensor(0.3870, device='cuda:0') eval_epoch_acc=tensor(0.9091, device='cuda:0')
[2024-12-17 02:51:06,408][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 02:51:06,408][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 02:51:06,659][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_1781_loss_0.38700321316719055/model.pt
[2024-12-17 02:51:06,670][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 02:51:06,672][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.38700321316719055
[2024-12-17 02:51:06,673][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.909098744392395
[2024-12-17 02:51:06,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,116][root][INFO] - Training Epoch: 2/2, step 1781/7134 completed (loss: 0.17184053361415863, acc: 0.9664429426193237)
[2024-12-17 02:51:07,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,500][root][INFO] - Training Epoch: 2/2, step 1782/7134 completed (loss: 0.10547815263271332, acc: 0.9679487347602844)
[2024-12-17 02:51:07,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:07,902][root][INFO] - Training Epoch: 2/2, step 1783/7134 completed (loss: 0.22280894219875336, acc: 0.9248554706573486)
[2024-12-17 02:51:08,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,290][root][INFO] - Training Epoch: 2/2, step 1784/7134 completed (loss: 0.16504420340061188, acc: 0.9679487347602844)
[2024-12-17 02:51:08,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:08,691][root][INFO] - Training Epoch: 2/2, step 1785/7134 completed (loss: 0.24404166638851166, acc: 0.9216867685317993)
[2024-12-17 02:51:08,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,081][root][INFO] - Training Epoch: 2/2, step 1786/7134 completed (loss: 0.18454383313655853, acc: 0.9354838728904724)
[2024-12-17 02:51:09,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,479][root][INFO] - Training Epoch: 2/2, step 1787/7134 completed (loss: 0.2807425260543823, acc: 0.89552241563797)
[2024-12-17 02:51:09,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:09,873][root][INFO] - Training Epoch: 2/2, step 1788/7134 completed (loss: 0.26810914278030396, acc: 0.951724112033844)
[2024-12-17 02:51:09,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,260][root][INFO] - Training Epoch: 2/2, step 1789/7134 completed (loss: 0.17162561416625977, acc: 0.9539473652839661)
[2024-12-17 02:51:10,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:10,651][root][INFO] - Training Epoch: 2/2, step 1790/7134 completed (loss: 0.45548877120018005, acc: 0.9225806593894958)
[2024-12-17 02:51:10,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,011][root][INFO] - Training Epoch: 2/2, step 1791/7134 completed (loss: 0.4816744327545166, acc: 0.8834356069564819)
[2024-12-17 02:51:11,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,396][root][INFO] - Training Epoch: 2/2, step 1792/7134 completed (loss: 0.7948588132858276, acc: 0.8547486066818237)
[2024-12-17 02:51:11,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:11,784][root][INFO] - Training Epoch: 2/2, step 1793/7134 completed (loss: 0.6795879602432251, acc: 0.8698225021362305)
[2024-12-17 02:51:11,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,188][root][INFO] - Training Epoch: 2/2, step 1794/7134 completed (loss: 0.4395066201686859, acc: 0.8881579041481018)
[2024-12-17 02:51:12,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,584][root][INFO] - Training Epoch: 2/2, step 1795/7134 completed (loss: 0.7241437435150146, acc: 0.831250011920929)
[2024-12-17 02:51:12,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:12,965][root][INFO] - Training Epoch: 2/2, step 1796/7134 completed (loss: 0.5888229608535767, acc: 0.8813559412956238)
[2024-12-17 02:51:13,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,346][root][INFO] - Training Epoch: 2/2, step 1797/7134 completed (loss: 0.48169493675231934, acc: 0.8742856979370117)
[2024-12-17 02:51:13,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:13,723][root][INFO] - Training Epoch: 2/2, step 1798/7134 completed (loss: 0.4895114004611969, acc: 0.8759689927101135)
[2024-12-17 02:51:13,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,109][root][INFO] - Training Epoch: 2/2, step 1799/7134 completed (loss: 0.40685176849365234, acc: 0.9141414165496826)
[2024-12-17 02:51:14,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,494][root][INFO] - Training Epoch: 2/2, step 1800/7134 completed (loss: 0.4161733090877533, acc: 0.8999999761581421)
[2024-12-17 02:51:14,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:14,875][root][INFO] - Training Epoch: 2/2, step 1801/7134 completed (loss: 0.37465593218803406, acc: 0.9099099040031433)
[2024-12-17 02:51:14,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,249][root][INFO] - Training Epoch: 2/2, step 1802/7134 completed (loss: 0.3751610219478607, acc: 0.8936170339584351)
[2024-12-17 02:51:15,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:15,626][root][INFO] - Training Epoch: 2/2, step 1803/7134 completed (loss: 0.4092308580875397, acc: 0.8780487775802612)
[2024-12-17 02:51:15,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,002][root][INFO] - Training Epoch: 2/2, step 1804/7134 completed (loss: 0.2173858880996704, acc: 0.9523809552192688)
[2024-12-17 02:51:16,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,394][root][INFO] - Training Epoch: 2/2, step 1805/7134 completed (loss: 0.2778649926185608, acc: 0.9356725215911865)
[2024-12-17 02:51:16,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:16,760][root][INFO] - Training Epoch: 2/2, step 1806/7134 completed (loss: 0.29832789301872253, acc: 0.9180327653884888)
[2024-12-17 02:51:16,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,137][root][INFO] - Training Epoch: 2/2, step 1807/7134 completed (loss: 0.36799517273902893, acc: 0.891566276550293)
[2024-12-17 02:51:17,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,499][root][INFO] - Training Epoch: 2/2, step 1808/7134 completed (loss: 0.16077856719493866, acc: 0.9604519605636597)
[2024-12-17 02:51:17,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:17,893][root][INFO] - Training Epoch: 2/2, step 1809/7134 completed (loss: 0.20294716954231262, acc: 0.9364162087440491)
[2024-12-17 02:51:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,282][root][INFO] - Training Epoch: 2/2, step 1810/7134 completed (loss: 0.17094187438488007, acc: 0.9615384340286255)
[2024-12-17 02:51:18,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:18,686][root][INFO] - Training Epoch: 2/2, step 1811/7134 completed (loss: 0.3195895254611969, acc: 0.9095744490623474)
[2024-12-17 02:51:18,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,068][root][INFO] - Training Epoch: 2/2, step 1812/7134 completed (loss: 0.2539508640766144, acc: 0.9604519605636597)
[2024-12-17 02:51:19,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,447][root][INFO] - Training Epoch: 2/2, step 1813/7134 completed (loss: 0.3759195804595947, acc: 0.9337016344070435)
[2024-12-17 02:51:19,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:19,819][root][INFO] - Training Epoch: 2/2, step 1814/7134 completed (loss: 0.22867624461650848, acc: 0.9281768202781677)
[2024-12-17 02:51:19,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,184][root][INFO] - Training Epoch: 2/2, step 1815/7134 completed (loss: 0.279799222946167, acc: 0.9299362897872925)
[2024-12-17 02:51:20,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,550][root][INFO] - Training Epoch: 2/2, step 1816/7134 completed (loss: 0.3794349431991577, acc: 0.8819444179534912)
[2024-12-17 02:51:20,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:20,926][root][INFO] - Training Epoch: 2/2, step 1817/7134 completed (loss: 0.35709646344184875, acc: 0.90625)
[2024-12-17 02:51:21,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,301][root][INFO] - Training Epoch: 2/2, step 1818/7134 completed (loss: 0.21563661098480225, acc: 0.9319371581077576)
[2024-12-17 02:51:21,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:21,678][root][INFO] - Training Epoch: 2/2, step 1819/7134 completed (loss: 0.1599687933921814, acc: 0.9593023061752319)
[2024-12-17 02:51:21,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,123][root][INFO] - Training Epoch: 2/2, step 1820/7134 completed (loss: 0.19551436603069305, acc: 0.9433962106704712)
[2024-12-17 02:51:22,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,486][root][INFO] - Training Epoch: 2/2, step 1821/7134 completed (loss: 0.16265560686588287, acc: 0.9719626307487488)
[2024-12-17 02:51:22,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:22,835][root][INFO] - Training Epoch: 2/2, step 1822/7134 completed (loss: 0.22893624007701874, acc: 0.9407894611358643)
[2024-12-17 02:51:22,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,206][root][INFO] - Training Epoch: 2/2, step 1823/7134 completed (loss: 0.1985943764448166, acc: 0.9476743936538696)
[2024-12-17 02:51:23,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,582][root][INFO] - Training Epoch: 2/2, step 1824/7134 completed (loss: 0.19061541557312012, acc: 0.9398906826972961)
[2024-12-17 02:51:23,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:23,958][root][INFO] - Training Epoch: 2/2, step 1825/7134 completed (loss: 0.20158810913562775, acc: 0.9626168012619019)
[2024-12-17 02:51:24,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,327][root][INFO] - Training Epoch: 2/2, step 1826/7134 completed (loss: 0.13398602604866028, acc: 0.9649122953414917)
[2024-12-17 02:51:24,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:24,702][root][INFO] - Training Epoch: 2/2, step 1827/7134 completed (loss: 0.19884894788265228, acc: 0.9573459625244141)
[2024-12-17 02:51:24,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,077][root][INFO] - Training Epoch: 2/2, step 1828/7134 completed (loss: 0.12076364457607269, acc: 0.9666666388511658)
[2024-12-17 02:51:25,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,447][root][INFO] - Training Epoch: 2/2, step 1829/7134 completed (loss: 0.2511739134788513, acc: 0.9247311949729919)
[2024-12-17 02:51:25,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:25,822][root][INFO] - Training Epoch: 2/2, step 1830/7134 completed (loss: 0.27760183811187744, acc: 0.9481865167617798)
[2024-12-17 02:51:25,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,174][root][INFO] - Training Epoch: 2/2, step 1831/7134 completed (loss: 0.11248614639043808, acc: 0.9696969985961914)
[2024-12-17 02:51:26,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,526][root][INFO] - Training Epoch: 2/2, step 1832/7134 completed (loss: 0.4439358413219452, acc: 0.9147287011146545)
[2024-12-17 02:51:26,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:26,884][root][INFO] - Training Epoch: 2/2, step 1833/7134 completed (loss: 0.6352896094322205, acc: 0.8861788511276245)
[2024-12-17 02:51:26,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,254][root][INFO] - Training Epoch: 2/2, step 1834/7134 completed (loss: 0.1995527595281601, acc: 0.9615384340286255)
[2024-12-17 02:51:27,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:27,658][root][INFO] - Training Epoch: 2/2, step 1835/7134 completed (loss: 0.49873241782188416, acc: 0.9220778942108154)
[2024-12-17 02:51:27,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,041][root][INFO] - Training Epoch: 2/2, step 1836/7134 completed (loss: 0.2609591782093048, acc: 0.9251337051391602)
[2024-12-17 02:51:28,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,415][root][INFO] - Training Epoch: 2/2, step 1837/7134 completed (loss: 0.2248051017522812, acc: 0.9450549483299255)
[2024-12-17 02:51:28,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:28,751][root][INFO] - Training Epoch: 2/2, step 1838/7134 completed (loss: 0.21907855570316315, acc: 0.9541284441947937)
[2024-12-17 02:51:28,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,133][root][INFO] - Training Epoch: 2/2, step 1839/7134 completed (loss: 0.1648961752653122, acc: 0.9670329689979553)
[2024-12-17 02:51:29,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,513][root][INFO] - Training Epoch: 2/2, step 1840/7134 completed (loss: 0.3157685697078705, acc: 0.8797468543052673)
[2024-12-17 02:51:29,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:29,891][root][INFO] - Training Epoch: 2/2, step 1841/7134 completed (loss: 0.36549776792526245, acc: 0.918181836605072)
[2024-12-17 02:51:29,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,260][root][INFO] - Training Epoch: 2/2, step 1842/7134 completed (loss: 0.23261183500289917, acc: 0.9451219439506531)
[2024-12-17 02:51:30,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:30,632][root][INFO] - Training Epoch: 2/2, step 1843/7134 completed (loss: 0.303849995136261, acc: 0.9523809552192688)
[2024-12-17 02:51:30,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,009][root][INFO] - Training Epoch: 2/2, step 1844/7134 completed (loss: 0.11017990857362747, acc: 0.9503546357154846)
[2024-12-17 02:51:31,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,393][root][INFO] - Training Epoch: 2/2, step 1845/7134 completed (loss: 0.23713573813438416, acc: 0.9239130616188049)
[2024-12-17 02:51:31,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:31,773][root][INFO] - Training Epoch: 2/2, step 1846/7134 completed (loss: 0.28599515557289124, acc: 0.9487179517745972)
[2024-12-17 02:51:31,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,157][root][INFO] - Training Epoch: 2/2, step 1847/7134 completed (loss: 0.3137519657611847, acc: 0.9034090638160706)
[2024-12-17 02:51:32,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,539][root][INFO] - Training Epoch: 2/2, step 1848/7134 completed (loss: 0.3202972710132599, acc: 0.9202127456665039)
[2024-12-17 02:51:32,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:32,905][root][INFO] - Training Epoch: 2/2, step 1849/7134 completed (loss: 0.24816074967384338, acc: 0.9366196990013123)
[2024-12-17 02:51:32,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,278][root][INFO] - Training Epoch: 2/2, step 1850/7134 completed (loss: 0.4149360954761505, acc: 0.8969072103500366)
[2024-12-17 02:51:33,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:33,652][root][INFO] - Training Epoch: 2/2, step 1851/7134 completed (loss: 0.4631965458393097, acc: 0.8871794939041138)
[2024-12-17 02:51:33,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,018][root][INFO] - Training Epoch: 2/2, step 1852/7134 completed (loss: 0.363130658864975, acc: 0.8999999761581421)
[2024-12-17 02:51:34,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,386][root][INFO] - Training Epoch: 2/2, step 1853/7134 completed (loss: 0.2605169713497162, acc: 0.9497487545013428)
[2024-12-17 02:51:34,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:34,789][root][INFO] - Training Epoch: 2/2, step 1854/7134 completed (loss: 0.2169952243566513, acc: 0.9411764740943909)
[2024-12-17 02:51:34,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,188][root][INFO] - Training Epoch: 2/2, step 1855/7134 completed (loss: 0.2490978091955185, acc: 0.9383886456489563)
[2024-12-17 02:51:35,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,559][root][INFO] - Training Epoch: 2/2, step 1856/7134 completed (loss: 0.2673755884170532, acc: 0.9234693646430969)
[2024-12-17 02:51:35,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:35,950][root][INFO] - Training Epoch: 2/2, step 1857/7134 completed (loss: 0.44629761576652527, acc: 0.8921568393707275)
[2024-12-17 02:51:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,319][root][INFO] - Training Epoch: 2/2, step 1858/7134 completed (loss: 0.16265393793582916, acc: 0.9438775777816772)
[2024-12-17 02:51:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:36,696][root][INFO] - Training Epoch: 2/2, step 1859/7134 completed (loss: 0.18941332399845123, acc: 0.9473684430122375)
[2024-12-17 02:51:36,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,062][root][INFO] - Training Epoch: 2/2, step 1860/7134 completed (loss: 0.2186272144317627, acc: 0.9508196711540222)
[2024-12-17 02:51:37,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,426][root][INFO] - Training Epoch: 2/2, step 1861/7134 completed (loss: 0.20359577238559723, acc: 0.9685863852500916)
[2024-12-17 02:51:37,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:37,801][root][INFO] - Training Epoch: 2/2, step 1862/7134 completed (loss: 0.15534937381744385, acc: 0.9470899701118469)
[2024-12-17 02:51:37,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,179][root][INFO] - Training Epoch: 2/2, step 1863/7134 completed (loss: 0.21928340196609497, acc: 0.9507389068603516)
[2024-12-17 02:51:38,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,558][root][INFO] - Training Epoch: 2/2, step 1864/7134 completed (loss: 0.5961521863937378, acc: 0.8629441857337952)
[2024-12-17 02:51:38,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:38,916][root][INFO] - Training Epoch: 2/2, step 1865/7134 completed (loss: 0.34154507517814636, acc: 0.9328858852386475)
[2024-12-17 02:51:39,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,273][root][INFO] - Training Epoch: 2/2, step 1866/7134 completed (loss: 0.10896070301532745, acc: 0.9588235020637512)
[2024-12-17 02:51:39,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:39,663][root][INFO] - Training Epoch: 2/2, step 1867/7134 completed (loss: 0.23040424287319183, acc: 0.9318181872367859)
[2024-12-17 02:51:39,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,051][root][INFO] - Training Epoch: 2/2, step 1868/7134 completed (loss: 0.47754940390586853, acc: 0.8895705342292786)
[2024-12-17 02:51:40,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,419][root][INFO] - Training Epoch: 2/2, step 1869/7134 completed (loss: 0.25310757756233215, acc: 0.9246575236320496)
[2024-12-17 02:51:40,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:40,778][root][INFO] - Training Epoch: 2/2, step 1870/7134 completed (loss: 0.13250301778316498, acc: 0.9621621370315552)
[2024-12-17 02:51:40,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,153][root][INFO] - Training Epoch: 2/2, step 1871/7134 completed (loss: 0.39480891823768616, acc: 0.9419354796409607)
[2024-12-17 02:51:41,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,499][root][INFO] - Training Epoch: 2/2, step 1872/7134 completed (loss: 2.0101685523986816, acc: 0.5942028760910034)
[2024-12-17 02:51:41,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:41,878][root][INFO] - Training Epoch: 2/2, step 1873/7134 completed (loss: 0.836472749710083, acc: 0.8181818127632141)
[2024-12-17 02:51:41,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,247][root][INFO] - Training Epoch: 2/2, step 1874/7134 completed (loss: 0.18594364821910858, acc: 0.9655172228813171)
[2024-12-17 02:51:42,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,591][root][INFO] - Training Epoch: 2/2, step 1875/7134 completed (loss: 0.137106791138649, acc: 0.9732142686843872)
[2024-12-17 02:51:42,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:42,964][root][INFO] - Training Epoch: 2/2, step 1876/7134 completed (loss: 0.6159403920173645, acc: 0.845714271068573)
[2024-12-17 02:51:43,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,338][root][INFO] - Training Epoch: 2/2, step 1877/7134 completed (loss: 0.17557558417320251, acc: 0.9661017060279846)
[2024-12-17 02:51:43,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:43,703][root][INFO] - Training Epoch: 2/2, step 1878/7134 completed (loss: 0.18564745783805847, acc: 0.9673202633857727)
[2024-12-17 02:51:43,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,079][root][INFO] - Training Epoch: 2/2, step 1879/7134 completed (loss: 0.7887599468231201, acc: 0.8086419701576233)
[2024-12-17 02:51:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,425][root][INFO] - Training Epoch: 2/2, step 1880/7134 completed (loss: 0.5734774470329285, acc: 0.8780487775802612)
[2024-12-17 02:51:44,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:44,798][root][INFO] - Training Epoch: 2/2, step 1881/7134 completed (loss: 0.41954976320266724, acc: 0.8521126508712769)
[2024-12-17 02:51:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,145][root][INFO] - Training Epoch: 2/2, step 1882/7134 completed (loss: 0.47486644983291626, acc: 0.9130434989929199)
[2024-12-17 02:51:45,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,583][root][INFO] - Training Epoch: 2/2, step 1883/7134 completed (loss: 0.35600292682647705, acc: 0.9069767594337463)
[2024-12-17 02:51:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:45,969][root][INFO] - Training Epoch: 2/2, step 1884/7134 completed (loss: 0.34187743067741394, acc: 0.9189189076423645)
[2024-12-17 02:51:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,364][root][INFO] - Training Epoch: 2/2, step 1885/7134 completed (loss: 0.5194295644760132, acc: 0.8521126508712769)
[2024-12-17 02:51:46,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:46,746][root][INFO] - Training Epoch: 2/2, step 1886/7134 completed (loss: 0.6340615153312683, acc: 0.8888888955116272)
[2024-12-17 02:51:46,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,126][root][INFO] - Training Epoch: 2/2, step 1887/7134 completed (loss: 0.37832316756248474, acc: 0.9337748289108276)
[2024-12-17 02:51:47,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,520][root][INFO] - Training Epoch: 2/2, step 1888/7134 completed (loss: 0.2709614634513855, acc: 0.94017094373703)
[2024-12-17 02:51:47,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:47,909][root][INFO] - Training Epoch: 2/2, step 1889/7134 completed (loss: 0.22016991674900055, acc: 0.9590643048286438)
[2024-12-17 02:51:48,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,305][root][INFO] - Training Epoch: 2/2, step 1890/7134 completed (loss: 0.15742750465869904, acc: 0.940397322177887)
[2024-12-17 02:51:48,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:48,681][root][INFO] - Training Epoch: 2/2, step 1891/7134 completed (loss: 0.3905303478240967, acc: 0.8895348906517029)
[2024-12-17 02:51:48,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,070][root][INFO] - Training Epoch: 2/2, step 1892/7134 completed (loss: 0.3454090356826782, acc: 0.9341317415237427)
[2024-12-17 02:51:49,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,439][root][INFO] - Training Epoch: 2/2, step 1893/7134 completed (loss: 0.28577351570129395, acc: 0.9320987462997437)
[2024-12-17 02:51:49,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:49,838][root][INFO] - Training Epoch: 2/2, step 1894/7134 completed (loss: 0.42140135169029236, acc: 0.912162184715271)
[2024-12-17 02:51:49,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,187][root][INFO] - Training Epoch: 2/2, step 1895/7134 completed (loss: 0.9792591333389282, acc: 0.7977527976036072)
[2024-12-17 02:51:50,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,564][root][INFO] - Training Epoch: 2/2, step 1896/7134 completed (loss: 0.3683832585811615, acc: 0.8909090757369995)
[2024-12-17 02:51:50,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:50,942][root][INFO] - Training Epoch: 2/2, step 1897/7134 completed (loss: 0.27721497416496277, acc: 0.9366196990013123)
[2024-12-17 02:51:51,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,310][root][INFO] - Training Epoch: 2/2, step 1898/7134 completed (loss: 0.390056848526001, acc: 0.9103448390960693)
[2024-12-17 02:51:51,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:51,658][root][INFO] - Training Epoch: 2/2, step 1899/7134 completed (loss: 0.17809247970581055, acc: 0.939393937587738)
[2024-12-17 02:51:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,020][root][INFO] - Training Epoch: 2/2, step 1900/7134 completed (loss: 0.15775080025196075, acc: 0.9558823704719543)
[2024-12-17 02:51:52,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,410][root][INFO] - Training Epoch: 2/2, step 1901/7134 completed (loss: 0.31149932742118835, acc: 0.935251772403717)
[2024-12-17 02:51:52,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:52,765][root][INFO] - Training Epoch: 2/2, step 1902/7134 completed (loss: 0.1450698971748352, acc: 0.9640287756919861)
[2024-12-17 02:51:52,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,141][root][INFO] - Training Epoch: 2/2, step 1903/7134 completed (loss: 0.15970337390899658, acc: 0.9607843160629272)
[2024-12-17 02:51:53,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,494][root][INFO] - Training Epoch: 2/2, step 1904/7134 completed (loss: 0.2914462983608246, acc: 0.8761904835700989)
[2024-12-17 02:51:53,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:53,848][root][INFO] - Training Epoch: 2/2, step 1905/7134 completed (loss: 0.3150467276573181, acc: 0.9432623982429504)
[2024-12-17 02:51:53,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,201][root][INFO] - Training Epoch: 2/2, step 1906/7134 completed (loss: 0.22866685688495636, acc: 0.970802903175354)
[2024-12-17 02:51:54,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:54,567][root][INFO] - Training Epoch: 2/2, step 1907/7134 completed (loss: 0.2659249007701874, acc: 0.9251700639724731)
[2024-12-17 02:51:54,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,002][root][INFO] - Training Epoch: 2/2, step 1908/7134 completed (loss: 0.2778545320034027, acc: 0.9345794320106506)
[2024-12-17 02:51:55,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,395][root][INFO] - Training Epoch: 2/2, step 1909/7134 completed (loss: 0.27561724185943604, acc: 0.9234693646430969)
[2024-12-17 02:51:55,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:55,779][root][INFO] - Training Epoch: 2/2, step 1910/7134 completed (loss: 0.17341649532318115, acc: 0.9674418568611145)
[2024-12-17 02:51:55,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,157][root][INFO] - Training Epoch: 2/2, step 1911/7134 completed (loss: 0.1775645911693573, acc: 0.9644669890403748)
[2024-12-17 02:51:56,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,530][root][INFO] - Training Epoch: 2/2, step 1912/7134 completed (loss: 0.0648011788725853, acc: 0.9818181991577148)
[2024-12-17 02:51:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:56,890][root][INFO] - Training Epoch: 2/2, step 1913/7134 completed (loss: 0.38842377066612244, acc: 0.9291338324546814)
[2024-12-17 02:51:56,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,262][root][INFO] - Training Epoch: 2/2, step 1914/7134 completed (loss: 0.30886614322662354, acc: 0.9398906826972961)
[2024-12-17 02:51:57,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,626][root][INFO] - Training Epoch: 2/2, step 1915/7134 completed (loss: 0.1394977867603302, acc: 0.9650349617004395)
[2024-12-17 02:51:57,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:57,998][root][INFO] - Training Epoch: 2/2, step 1916/7134 completed (loss: 0.25750187039375305, acc: 0.9285714030265808)
[2024-12-17 02:51:58,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,389][root][INFO] - Training Epoch: 2/2, step 1917/7134 completed (loss: 0.24422232806682587, acc: 0.9575757384300232)
[2024-12-17 02:51:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:58,751][root][INFO] - Training Epoch: 2/2, step 1918/7134 completed (loss: 0.2633117437362671, acc: 0.9470198750495911)
[2024-12-17 02:51:58,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,133][root][INFO] - Training Epoch: 2/2, step 1919/7134 completed (loss: 0.15300726890563965, acc: 0.957317054271698)
[2024-12-17 02:51:59,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,506][root][INFO] - Training Epoch: 2/2, step 1920/7134 completed (loss: 0.23159395158290863, acc: 0.9523809552192688)
[2024-12-17 02:51:59,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:51:59,874][root][INFO] - Training Epoch: 2/2, step 1921/7134 completed (loss: 0.16515979170799255, acc: 0.9590643048286438)
[2024-12-17 02:51:59,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,260][root][INFO] - Training Epoch: 2/2, step 1922/7134 completed (loss: 0.12240125983953476, acc: 0.9631147384643555)
[2024-12-17 02:52:00,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:00,630][root][INFO] - Training Epoch: 2/2, step 1923/7134 completed (loss: 0.15668261051177979, acc: 0.9720279574394226)
[2024-12-17 02:52:00,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,005][root][INFO] - Training Epoch: 2/2, step 1924/7134 completed (loss: 0.22862477600574493, acc: 0.9375)
[2024-12-17 02:52:01,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,391][root][INFO] - Training Epoch: 2/2, step 1925/7134 completed (loss: 0.21188543736934662, acc: 0.9456067085266113)
[2024-12-17 02:52:01,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:01,772][root][INFO] - Training Epoch: 2/2, step 1926/7134 completed (loss: 0.06667082011699677, acc: 0.9776785969734192)
[2024-12-17 02:52:01,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,168][root][INFO] - Training Epoch: 2/2, step 1927/7134 completed (loss: 0.18145520985126495, acc: 0.9622641801834106)
[2024-12-17 02:52:02,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,576][root][INFO] - Training Epoch: 2/2, step 1928/7134 completed (loss: 0.2785531282424927, acc: 0.9345238208770752)
[2024-12-17 02:52:02,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:02,952][root][INFO] - Training Epoch: 2/2, step 1929/7134 completed (loss: 0.1891290247440338, acc: 0.9497206807136536)
[2024-12-17 02:52:03,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,338][root][INFO] - Training Epoch: 2/2, step 1930/7134 completed (loss: 0.37635529041290283, acc: 0.8937197923660278)
[2024-12-17 02:52:03,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:03,725][root][INFO] - Training Epoch: 2/2, step 1931/7134 completed (loss: 0.3442651629447937, acc: 0.9305555820465088)
[2024-12-17 02:52:03,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,091][root][INFO] - Training Epoch: 2/2, step 1932/7134 completed (loss: 0.4054301977157593, acc: 0.9050279259681702)
[2024-12-17 02:52:04,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,479][root][INFO] - Training Epoch: 2/2, step 1933/7134 completed (loss: 0.37656068801879883, acc: 0.8994975090026855)
[2024-12-17 02:52:04,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:04,847][root][INFO] - Training Epoch: 2/2, step 1934/7134 completed (loss: 0.19033654034137726, acc: 0.954285740852356)
[2024-12-17 02:52:04,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,244][root][INFO] - Training Epoch: 2/2, step 1935/7134 completed (loss: 0.5867338180541992, acc: 0.8963414430618286)
[2024-12-17 02:52:05,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:05,632][root][INFO] - Training Epoch: 2/2, step 1936/7134 completed (loss: 0.1087561622262001, acc: 0.9803921580314636)
[2024-12-17 02:52:05,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,016][root][INFO] - Training Epoch: 2/2, step 1937/7134 completed (loss: 0.30813315510749817, acc: 0.9268292784690857)
[2024-12-17 02:52:06,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,400][root][INFO] - Training Epoch: 2/2, step 1938/7134 completed (loss: 0.5097762942314148, acc: 0.9021739363670349)
[2024-12-17 02:52:06,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:06,834][root][INFO] - Training Epoch: 2/2, step 1939/7134 completed (loss: 0.23798052966594696, acc: 0.9482758641242981)
[2024-12-17 02:52:06,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,234][root][INFO] - Training Epoch: 2/2, step 1940/7134 completed (loss: 0.4977354407310486, acc: 0.8802395462989807)
[2024-12-17 02:52:07,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:07,660][root][INFO] - Training Epoch: 2/2, step 1941/7134 completed (loss: 0.20952896773815155, acc: 0.9467455744743347)
[2024-12-17 02:52:07,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,046][root][INFO] - Training Epoch: 2/2, step 1942/7134 completed (loss: 0.23241864144802094, acc: 0.9629629850387573)
[2024-12-17 02:52:08,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,422][root][INFO] - Training Epoch: 2/2, step 1943/7134 completed (loss: 0.3917780816555023, acc: 0.9368420839309692)
[2024-12-17 02:52:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:08,789][root][INFO] - Training Epoch: 2/2, step 1944/7134 completed (loss: 0.3514348566532135, acc: 0.9344262480735779)
[2024-12-17 02:52:08,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,155][root][INFO] - Training Epoch: 2/2, step 1945/7134 completed (loss: 0.3013858497142792, acc: 0.8951612710952759)
[2024-12-17 02:52:09,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,491][root][INFO] - Training Epoch: 2/2, step 1946/7134 completed (loss: 0.2871893048286438, acc: 0.8999999761581421)
[2024-12-17 02:52:09,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:09,915][root][INFO] - Training Epoch: 2/2, step 1947/7134 completed (loss: 0.24883301556110382, acc: 0.9075144529342651)
[2024-12-17 02:52:10,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,292][root][INFO] - Training Epoch: 2/2, step 1948/7134 completed (loss: 0.2486461102962494, acc: 0.9230769276618958)
[2024-12-17 02:52:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:10,648][root][INFO] - Training Epoch: 2/2, step 1949/7134 completed (loss: 0.13744604587554932, acc: 0.9740259647369385)
[2024-12-17 02:52:10,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,016][root][INFO] - Training Epoch: 2/2, step 1950/7134 completed (loss: 0.19658638536930084, acc: 0.95652174949646)
[2024-12-17 02:52:11,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,419][root][INFO] - Training Epoch: 2/2, step 1951/7134 completed (loss: 0.2781742215156555, acc: 0.9398496150970459)
[2024-12-17 02:52:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:11,809][root][INFO] - Training Epoch: 2/2, step 1952/7134 completed (loss: 0.3204067349433899, acc: 0.9096385836601257)
[2024-12-17 02:52:11,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,211][root][INFO] - Training Epoch: 2/2, step 1953/7134 completed (loss: 0.18349187076091766, acc: 0.9556962251663208)
[2024-12-17 02:52:12,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:12,594][root][INFO] - Training Epoch: 2/2, step 1954/7134 completed (loss: 0.17657096683979034, acc: 0.9607843160629272)
[2024-12-17 02:52:12,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,038][root][INFO] - Training Epoch: 2/2, step 1955/7134 completed (loss: 0.25121909379959106, acc: 0.9477611780166626)
[2024-12-17 02:52:13,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,420][root][INFO] - Training Epoch: 2/2, step 1956/7134 completed (loss: 0.06735427677631378, acc: 0.989130437374115)
[2024-12-17 02:52:13,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:13,804][root][INFO] - Training Epoch: 2/2, step 1957/7134 completed (loss: 0.21365097165107727, acc: 0.9398496150970459)
[2024-12-17 02:52:13,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,150][root][INFO] - Training Epoch: 2/2, step 1958/7134 completed (loss: 0.22780223190784454, acc: 0.9333333373069763)
[2024-12-17 02:52:14,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,499][root][INFO] - Training Epoch: 2/2, step 1959/7134 completed (loss: 0.27109628915786743, acc: 0.9196428656578064)
[2024-12-17 02:52:14,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:14,867][root][INFO] - Training Epoch: 2/2, step 1960/7134 completed (loss: 0.18644943833351135, acc: 0.9583333134651184)
[2024-12-17 02:52:15,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,258][root][INFO] - Training Epoch: 2/2, step 1961/7134 completed (loss: 0.20254886150360107, acc: 0.9620253443717957)
[2024-12-17 02:52:15,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:15,642][root][INFO] - Training Epoch: 2/2, step 1962/7134 completed (loss: 0.13870032131671906, acc: 0.9425287246704102)
[2024-12-17 02:52:15,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,026][root][INFO] - Training Epoch: 2/2, step 1963/7134 completed (loss: 0.3018854856491089, acc: 0.9271523356437683)
[2024-12-17 02:52:16,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,425][root][INFO] - Training Epoch: 2/2, step 1964/7134 completed (loss: 0.27333885431289673, acc: 0.9343434572219849)
[2024-12-17 02:52:16,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:16,824][root][INFO] - Training Epoch: 2/2, step 1965/7134 completed (loss: 0.28063321113586426, acc: 0.915730357170105)
[2024-12-17 02:52:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,212][root][INFO] - Training Epoch: 2/2, step 1966/7134 completed (loss: 0.33183422684669495, acc: 0.9363057613372803)
[2024-12-17 02:52:17,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:17,617][root][INFO] - Training Epoch: 2/2, step 1967/7134 completed (loss: 0.18211837112903595, acc: 0.942105233669281)
[2024-12-17 02:52:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,000][root][INFO] - Training Epoch: 2/2, step 1968/7134 completed (loss: 0.20308136940002441, acc: 0.936170220375061)
[2024-12-17 02:52:18,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,392][root][INFO] - Training Epoch: 2/2, step 1969/7134 completed (loss: 0.23258435726165771, acc: 0.9265536665916443)
[2024-12-17 02:52:18,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:18,761][root][INFO] - Training Epoch: 2/2, step 1970/7134 completed (loss: 0.2545079290866852, acc: 0.9408283829689026)
[2024-12-17 02:52:18,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,144][root][INFO] - Training Epoch: 2/2, step 1971/7134 completed (loss: 0.3740747570991516, acc: 0.9214659929275513)
[2024-12-17 02:52:19,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,530][root][INFO] - Training Epoch: 2/2, step 1972/7134 completed (loss: 0.9027706384658813, acc: 0.7894737124443054)
[2024-12-17 02:52:19,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:19,878][root][INFO] - Training Epoch: 2/2, step 1973/7134 completed (loss: 0.9556421637535095, acc: 0.8125)
[2024-12-17 02:52:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,272][root][INFO] - Training Epoch: 2/2, step 1974/7134 completed (loss: 0.21868903934955597, acc: 0.9536082744598389)
[2024-12-17 02:52:20,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:20,658][root][INFO] - Training Epoch: 2/2, step 1975/7134 completed (loss: 0.12289445102214813, acc: 0.9750000238418579)
[2024-12-17 02:52:20,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,051][root][INFO] - Training Epoch: 2/2, step 1976/7134 completed (loss: 0.34939563274383545, acc: 0.9038461446762085)
[2024-12-17 02:52:21,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,439][root][INFO] - Training Epoch: 2/2, step 1977/7134 completed (loss: 0.40748023986816406, acc: 0.9281437397003174)
[2024-12-17 02:52:21,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:21,851][root][INFO] - Training Epoch: 2/2, step 1978/7134 completed (loss: 0.09310184419155121, acc: 0.9825581312179565)
[2024-12-17 02:52:21,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,250][root][INFO] - Training Epoch: 2/2, step 1979/7134 completed (loss: 0.19613687694072723, acc: 0.9285714030265808)
[2024-12-17 02:52:22,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:22,638][root][INFO] - Training Epoch: 2/2, step 1980/7134 completed (loss: 0.23108580708503723, acc: 0.9528796076774597)
[2024-12-17 02:52:22,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,043][root][INFO] - Training Epoch: 2/2, step 1981/7134 completed (loss: 0.1330987811088562, acc: 0.9780219793319702)
[2024-12-17 02:52:23,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,442][root][INFO] - Training Epoch: 2/2, step 1982/7134 completed (loss: 0.16323311626911163, acc: 0.9589743614196777)
[2024-12-17 02:52:23,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:23,834][root][INFO] - Training Epoch: 2/2, step 1983/7134 completed (loss: 0.19068877398967743, acc: 0.9623655676841736)
[2024-12-17 02:52:23,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,231][root][INFO] - Training Epoch: 2/2, step 1984/7134 completed (loss: 0.16368085145950317, acc: 0.9593023061752319)
[2024-12-17 02:52:24,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,592][root][INFO] - Training Epoch: 2/2, step 1985/7134 completed (loss: 0.2515393793582916, acc: 0.9440993666648865)
[2024-12-17 02:52:24,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:24,975][root][INFO] - Training Epoch: 2/2, step 1986/7134 completed (loss: 0.11826372146606445, acc: 0.9720670580863953)
[2024-12-17 02:52:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,353][root][INFO] - Training Epoch: 2/2, step 1987/7134 completed (loss: 0.16136351227760315, acc: 0.9550561904907227)
[2024-12-17 02:52:25,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:25,747][root][INFO] - Training Epoch: 2/2, step 1988/7134 completed (loss: 0.22673861682415009, acc: 0.9575757384300232)
[2024-12-17 02:52:25,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,143][root][INFO] - Training Epoch: 2/2, step 1989/7134 completed (loss: 0.3764711320400238, acc: 0.9041095972061157)
[2024-12-17 02:52:26,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,544][root][INFO] - Training Epoch: 2/2, step 1990/7134 completed (loss: 0.19227802753448486, acc: 0.9668508172035217)
[2024-12-17 02:52:26,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:26,997][root][INFO] - Training Epoch: 2/2, step 1991/7134 completed (loss: 0.1387191265821457, acc: 0.975806474685669)
[2024-12-17 02:52:27,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,417][root][INFO] - Training Epoch: 2/2, step 1992/7134 completed (loss: 0.36683663725852966, acc: 0.8913043737411499)
[2024-12-17 02:52:27,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:27,824][root][INFO] - Training Epoch: 2/2, step 1993/7134 completed (loss: 0.33777469396591187, acc: 0.9130434989929199)
[2024-12-17 02:52:27,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,226][root][INFO] - Training Epoch: 2/2, step 1994/7134 completed (loss: 0.1845783144235611, acc: 0.9457364082336426)
[2024-12-17 02:52:28,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:28,631][root][INFO] - Training Epoch: 2/2, step 1995/7134 completed (loss: 0.11909525841474533, acc: 0.9724137783050537)
[2024-12-17 02:52:28,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,009][root][INFO] - Training Epoch: 2/2, step 1996/7134 completed (loss: 0.2511930763721466, acc: 0.9416058659553528)
[2024-12-17 02:52:29,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,388][root][INFO] - Training Epoch: 2/2, step 1997/7134 completed (loss: 0.2164599746465683, acc: 0.9357143044471741)
[2024-12-17 02:52:29,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:29,755][root][INFO] - Training Epoch: 2/2, step 1998/7134 completed (loss: 0.1805511713027954, acc: 0.9647887349128723)
[2024-12-17 02:52:29,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,159][root][INFO] - Training Epoch: 2/2, step 1999/7134 completed (loss: 0.21572160720825195, acc: 0.9230769276618958)
[2024-12-17 02:52:30,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,548][root][INFO] - Training Epoch: 2/2, step 2000/7134 completed (loss: 0.19569925963878632, acc: 0.9583333134651184)
[2024-12-17 02:52:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:30,918][root][INFO] - Training Epoch: 2/2, step 2001/7134 completed (loss: 0.09407036006450653, acc: 0.9862068891525269)
[2024-12-17 02:52:31,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,299][root][INFO] - Training Epoch: 2/2, step 2002/7134 completed (loss: 0.27013856172561646, acc: 0.9548872113227844)
[2024-12-17 02:52:31,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:31,659][root][INFO] - Training Epoch: 2/2, step 2003/7134 completed (loss: 0.10538137704133987, acc: 0.9649122953414917)
[2024-12-17 02:52:31,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,032][root][INFO] - Training Epoch: 2/2, step 2004/7134 completed (loss: 0.8984810709953308, acc: 0.8196721076965332)
[2024-12-17 02:52:32,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,480][root][INFO] - Training Epoch: 2/2, step 2005/7134 completed (loss: 0.39084184169769287, acc: 0.8877550959587097)
[2024-12-17 02:52:32,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:32,894][root][INFO] - Training Epoch: 2/2, step 2006/7134 completed (loss: 0.1536199003458023, acc: 0.9534883499145508)
[2024-12-17 02:52:33,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,262][root][INFO] - Training Epoch: 2/2, step 2007/7134 completed (loss: 0.12812235951423645, acc: 0.9663865566253662)
[2024-12-17 02:52:33,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,626][root][INFO] - Training Epoch: 2/2, step 2008/7134 completed (loss: 0.19989579916000366, acc: 0.9246575236320496)
[2024-12-17 02:52:33,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:33,994][root][INFO] - Training Epoch: 2/2, step 2009/7134 completed (loss: 0.10709808021783829, acc: 0.9629629850387573)
[2024-12-17 02:52:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,360][root][INFO] - Training Epoch: 2/2, step 2010/7134 completed (loss: 0.19694828987121582, acc: 0.9416058659553528)
[2024-12-17 02:52:34,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:34,755][root][INFO] - Training Epoch: 2/2, step 2011/7134 completed (loss: 0.12796823680400848, acc: 0.9603174328804016)
[2024-12-17 02:52:34,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,125][root][INFO] - Training Epoch: 2/2, step 2012/7134 completed (loss: 0.1741761863231659, acc: 0.9745762944221497)
[2024-12-17 02:52:35,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,515][root][INFO] - Training Epoch: 2/2, step 2013/7134 completed (loss: 0.1620347499847412, acc: 0.9426229596138)
[2024-12-17 02:52:35,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:35,897][root][INFO] - Training Epoch: 2/2, step 2014/7134 completed (loss: 0.14158512651920319, acc: 0.9629629850387573)
[2024-12-17 02:52:35,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,269][root][INFO] - Training Epoch: 2/2, step 2015/7134 completed (loss: 0.07976068556308746, acc: 0.9750000238418579)
[2024-12-17 02:52:36,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:36,645][root][INFO] - Training Epoch: 2/2, step 2016/7134 completed (loss: 0.2747545838356018, acc: 0.9319728016853333)
[2024-12-17 02:52:36,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,023][root][INFO] - Training Epoch: 2/2, step 2017/7134 completed (loss: 0.4413268268108368, acc: 0.9139072895050049)
[2024-12-17 02:52:37,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,395][root][INFO] - Training Epoch: 2/2, step 2018/7134 completed (loss: 0.1223420575261116, acc: 0.965753436088562)
[2024-12-17 02:52:37,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:37,772][root][INFO] - Training Epoch: 2/2, step 2019/7134 completed (loss: 0.23472082614898682, acc: 0.9470198750495911)
[2024-12-17 02:52:37,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,173][root][INFO] - Training Epoch: 2/2, step 2020/7134 completed (loss: 0.18597924709320068, acc: 0.942148745059967)
[2024-12-17 02:52:38,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,562][root][INFO] - Training Epoch: 2/2, step 2021/7134 completed (loss: 0.3128131926059723, acc: 0.9135135412216187)
[2024-12-17 02:52:38,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:38,912][root][INFO] - Training Epoch: 2/2, step 2022/7134 completed (loss: 0.26596155762672424, acc: 0.9328358173370361)
[2024-12-17 02:52:39,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,327][root][INFO] - Training Epoch: 2/2, step 2023/7134 completed (loss: 0.15306928753852844, acc: 0.9447852969169617)
[2024-12-17 02:52:39,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:39,787][root][INFO] - Training Epoch: 2/2, step 2024/7134 completed (loss: 0.1580146700143814, acc: 0.9651162624359131)
[2024-12-17 02:52:39,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,216][root][INFO] - Training Epoch: 2/2, step 2025/7134 completed (loss: 0.20956775546073914, acc: 0.9707602262496948)
[2024-12-17 02:52:40,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,609][root][INFO] - Training Epoch: 2/2, step 2026/7134 completed (loss: 0.14935429394245148, acc: 0.9473684430122375)
[2024-12-17 02:52:40,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:40,978][root][INFO] - Training Epoch: 2/2, step 2027/7134 completed (loss: 0.2423645257949829, acc: 0.9398496150970459)
[2024-12-17 02:52:41,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,353][root][INFO] - Training Epoch: 2/2, step 2028/7134 completed (loss: 0.2910795509815216, acc: 0.9202454090118408)
[2024-12-17 02:52:41,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:41,772][root][INFO] - Training Epoch: 2/2, step 2029/7134 completed (loss: 0.2506372630596161, acc: 0.9117646813392639)
[2024-12-17 02:52:41,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,145][root][INFO] - Training Epoch: 2/2, step 2030/7134 completed (loss: 0.2850453555583954, acc: 0.9096385836601257)
[2024-12-17 02:52:42,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,529][root][INFO] - Training Epoch: 2/2, step 2031/7134 completed (loss: 0.17333784699440002, acc: 0.939226508140564)
[2024-12-17 02:52:42,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:42,903][root][INFO] - Training Epoch: 2/2, step 2032/7134 completed (loss: 0.3853273093700409, acc: 0.9064327478408813)
[2024-12-17 02:52:42,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,291][root][INFO] - Training Epoch: 2/2, step 2033/7134 completed (loss: 0.12520991265773773, acc: 0.9389312863349915)
[2024-12-17 02:52:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:43,648][root][INFO] - Training Epoch: 2/2, step 2034/7134 completed (loss: 0.33658313751220703, acc: 0.9194630980491638)
[2024-12-17 02:52:43,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,028][root][INFO] - Training Epoch: 2/2, step 2035/7134 completed (loss: 0.19853359460830688, acc: 0.9301075339317322)
[2024-12-17 02:52:44,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,383][root][INFO] - Training Epoch: 2/2, step 2036/7134 completed (loss: 0.16486015915870667, acc: 0.9618320465087891)
[2024-12-17 02:52:44,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:44,760][root][INFO] - Training Epoch: 2/2, step 2037/7134 completed (loss: 0.22094197571277618, acc: 0.9386503100395203)
[2024-12-17 02:52:44,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,127][root][INFO] - Training Epoch: 2/2, step 2038/7134 completed (loss: 0.15780416131019592, acc: 0.9670329689979553)
[2024-12-17 02:52:45,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,483][root][INFO] - Training Epoch: 2/2, step 2039/7134 completed (loss: 0.12059026211500168, acc: 0.970802903175354)
[2024-12-17 02:52:45,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:45,839][root][INFO] - Training Epoch: 2/2, step 2040/7134 completed (loss: 0.26980799436569214, acc: 0.9655172228813171)
[2024-12-17 02:52:45,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,197][root][INFO] - Training Epoch: 2/2, step 2041/7134 completed (loss: 0.1169196143746376, acc: 0.9515151381492615)
[2024-12-17 02:52:46,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,576][root][INFO] - Training Epoch: 2/2, step 2042/7134 completed (loss: 0.4069141745567322, acc: 0.9406779408454895)
[2024-12-17 02:52:46,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:46,955][root][INFO] - Training Epoch: 2/2, step 2043/7134 completed (loss: 0.14471527934074402, acc: 0.9530201554298401)
[2024-12-17 02:52:47,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,342][root][INFO] - Training Epoch: 2/2, step 2044/7134 completed (loss: 0.12353339046239853, acc: 0.9679999947547913)
[2024-12-17 02:52:47,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:47,705][root][INFO] - Training Epoch: 2/2, step 2045/7134 completed (loss: 0.3662465810775757, acc: 0.8916666507720947)
[2024-12-17 02:52:47,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,058][root][INFO] - Training Epoch: 2/2, step 2046/7134 completed (loss: 0.3113277852535248, acc: 0.9159663915634155)
[2024-12-17 02:52:48,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,437][root][INFO] - Training Epoch: 2/2, step 2047/7134 completed (loss: 0.29640060663223267, acc: 0.9172413945198059)
[2024-12-17 02:52:48,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:48,812][root][INFO] - Training Epoch: 2/2, step 2048/7134 completed (loss: 0.4230431616306305, acc: 0.9047619104385376)
[2024-12-17 02:52:48,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,211][root][INFO] - Training Epoch: 2/2, step 2049/7134 completed (loss: 0.3610477149486542, acc: 0.9272727370262146)
[2024-12-17 02:52:49,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,569][root][INFO] - Training Epoch: 2/2, step 2050/7134 completed (loss: 0.2669936716556549, acc: 0.9178082346916199)
[2024-12-17 02:52:49,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:49,947][root][INFO] - Training Epoch: 2/2, step 2051/7134 completed (loss: 0.3301981985569, acc: 0.9292035102844238)
[2024-12-17 02:52:50,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,320][root][INFO] - Training Epoch: 2/2, step 2052/7134 completed (loss: 0.6056053638458252, acc: 0.9097222089767456)
[2024-12-17 02:52:50,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:50,690][root][INFO] - Training Epoch: 2/2, step 2053/7134 completed (loss: 0.4495754837989807, acc: 0.9007633328437805)
[2024-12-17 02:52:50,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,067][root][INFO] - Training Epoch: 2/2, step 2054/7134 completed (loss: 0.39559677243232727, acc: 0.9230769276618958)
[2024-12-17 02:52:51,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,432][root][INFO] - Training Epoch: 2/2, step 2055/7134 completed (loss: 0.49676769971847534, acc: 0.8561643958091736)
[2024-12-17 02:52:51,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:51,851][root][INFO] - Training Epoch: 2/2, step 2056/7134 completed (loss: 0.3984968960285187, acc: 0.8926553726196289)
[2024-12-17 02:52:51,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,233][root][INFO] - Training Epoch: 2/2, step 2057/7134 completed (loss: 0.28902962803840637, acc: 0.932584285736084)
[2024-12-17 02:52:52,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:52,620][root][INFO] - Training Epoch: 2/2, step 2058/7134 completed (loss: 0.3954841196537018, acc: 0.9190751314163208)
[2024-12-17 02:52:52,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,003][root][INFO] - Training Epoch: 2/2, step 2059/7134 completed (loss: 0.7250672578811646, acc: 0.8510638475418091)
[2024-12-17 02:52:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,385][root][INFO] - Training Epoch: 2/2, step 2060/7134 completed (loss: 0.3662833273410797, acc: 0.9171974658966064)
[2024-12-17 02:52:53,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:53,766][root][INFO] - Training Epoch: 2/2, step 2061/7134 completed (loss: 0.3256368637084961, acc: 0.8928571343421936)
[2024-12-17 02:52:53,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,142][root][INFO] - Training Epoch: 2/2, step 2062/7134 completed (loss: 0.3681110739707947, acc: 0.9140625)
[2024-12-17 02:52:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,493][root][INFO] - Training Epoch: 2/2, step 2063/7134 completed (loss: 0.28937649726867676, acc: 0.9007092118263245)
[2024-12-17 02:52:54,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:54,873][root][INFO] - Training Epoch: 2/2, step 2064/7134 completed (loss: 0.32638511061668396, acc: 0.9338235259056091)
[2024-12-17 02:52:54,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,238][root][INFO] - Training Epoch: 2/2, step 2065/7134 completed (loss: 0.29783985018730164, acc: 0.9285714030265808)
[2024-12-17 02:52:55,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,593][root][INFO] - Training Epoch: 2/2, step 2066/7134 completed (loss: 0.185654416680336, acc: 0.9512194991111755)
[2024-12-17 02:52:55,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:55,985][root][INFO] - Training Epoch: 2/2, step 2067/7134 completed (loss: 0.31242138147354126, acc: 0.925000011920929)
[2024-12-17 02:52:56,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,359][root][INFO] - Training Epoch: 2/2, step 2068/7134 completed (loss: 0.3209790289402008, acc: 0.9215686321258545)
[2024-12-17 02:52:56,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:56,748][root][INFO] - Training Epoch: 2/2, step 2069/7134 completed (loss: 0.22687144577503204, acc: 0.9194630980491638)
[2024-12-17 02:52:56,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,160][root][INFO] - Training Epoch: 2/2, step 2070/7134 completed (loss: 0.1316545307636261, acc: 0.9655172228813171)
[2024-12-17 02:52:57,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,531][root][INFO] - Training Epoch: 2/2, step 2071/7134 completed (loss: 0.12068212032318115, acc: 0.9611650705337524)
[2024-12-17 02:52:57,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:57,888][root][INFO] - Training Epoch: 2/2, step 2072/7134 completed (loss: 0.1959715038537979, acc: 0.9313725233078003)
[2024-12-17 02:52:57,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,254][root][INFO] - Training Epoch: 2/2, step 2073/7134 completed (loss: 0.1958150416612625, acc: 0.9504132270812988)
[2024-12-17 02:52:58,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:58,640][root][INFO] - Training Epoch: 2/2, step 2074/7134 completed (loss: 0.20657414197921753, acc: 0.9424083828926086)
[2024-12-17 02:52:58,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,038][root][INFO] - Training Epoch: 2/2, step 2075/7134 completed (loss: 0.3518289625644684, acc: 0.9119496941566467)
[2024-12-17 02:52:59,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,390][root][INFO] - Training Epoch: 2/2, step 2076/7134 completed (loss: 0.15448050200939178, acc: 0.9591836929321289)
[2024-12-17 02:52:59,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:52:59,780][root][INFO] - Training Epoch: 2/2, step 2077/7134 completed (loss: 0.2514503300189972, acc: 0.9378530979156494)
[2024-12-17 02:52:59,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,162][root][INFO] - Training Epoch: 2/2, step 2078/7134 completed (loss: 0.23904703557491302, acc: 0.9593908786773682)
[2024-12-17 02:53:00,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,538][root][INFO] - Training Epoch: 2/2, step 2079/7134 completed (loss: 0.1785464584827423, acc: 0.9457831382751465)
[2024-12-17 02:53:00,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:00,897][root][INFO] - Training Epoch: 2/2, step 2080/7134 completed (loss: 0.2095249593257904, acc: 0.9542483687400818)
[2024-12-17 02:53:01,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,319][root][INFO] - Training Epoch: 2/2, step 2081/7134 completed (loss: 0.2038375735282898, acc: 0.9617834687232971)
[2024-12-17 02:53:01,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:01,767][root][INFO] - Training Epoch: 2/2, step 2082/7134 completed (loss: 0.41435006260871887, acc: 0.9067796468734741)
[2024-12-17 02:53:01,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,116][root][INFO] - Training Epoch: 2/2, step 2083/7134 completed (loss: 0.22405938804149628, acc: 0.9457364082336426)
[2024-12-17 02:53:02,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,480][root][INFO] - Training Epoch: 2/2, step 2084/7134 completed (loss: 0.24713599681854248, acc: 0.9466666579246521)
[2024-12-17 02:53:02,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:02,930][root][INFO] - Training Epoch: 2/2, step 2085/7134 completed (loss: 0.07917683571577072, acc: 0.9837398529052734)
[2024-12-17 02:53:03,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,302][root][INFO] - Training Epoch: 2/2, step 2086/7134 completed (loss: 0.09920088201761246, acc: 0.9901960492134094)
[2024-12-17 02:53:03,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:03,723][root][INFO] - Training Epoch: 2/2, step 2087/7134 completed (loss: 0.08311115205287933, acc: 0.976190447807312)
[2024-12-17 02:53:03,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,125][root][INFO] - Training Epoch: 2/2, step 2088/7134 completed (loss: 0.29263561964035034, acc: 0.9526627063751221)
[2024-12-17 02:53:04,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,527][root][INFO] - Training Epoch: 2/2, step 2089/7134 completed (loss: 0.32074713706970215, acc: 0.9047619104385376)
[2024-12-17 02:53:04,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:04,904][root][INFO] - Training Epoch: 2/2, step 2090/7134 completed (loss: 0.10869139432907104, acc: 0.9673202633857727)
[2024-12-17 02:53:05,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,284][root][INFO] - Training Epoch: 2/2, step 2091/7134 completed (loss: 0.06478767096996307, acc: 0.9862068891525269)
[2024-12-17 02:53:05,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:05,681][root][INFO] - Training Epoch: 2/2, step 2092/7134 completed (loss: 0.12713342905044556, acc: 0.9735099077224731)
[2024-12-17 02:53:05,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,066][root][INFO] - Training Epoch: 2/2, step 2093/7134 completed (loss: 0.17243188619613647, acc: 0.9578947424888611)
[2024-12-17 02:53:06,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,449][root][INFO] - Training Epoch: 2/2, step 2094/7134 completed (loss: 0.3741514980792999, acc: 0.9328358173370361)
[2024-12-17 02:53:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:06,879][root][INFO] - Training Epoch: 2/2, step 2095/7134 completed (loss: 0.20667149126529694, acc: 0.9353233575820923)
[2024-12-17 02:53:07,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,280][root][INFO] - Training Epoch: 2/2, step 2096/7134 completed (loss: 0.11663395911455154, acc: 0.9580419659614563)
[2024-12-17 02:53:07,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:07,676][root][INFO] - Training Epoch: 2/2, step 2097/7134 completed (loss: 0.1297023892402649, acc: 0.9518072009086609)
[2024-12-17 02:53:07,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,047][root][INFO] - Training Epoch: 2/2, step 2098/7134 completed (loss: 0.1484164148569107, acc: 0.9605262875556946)
[2024-12-17 02:53:08,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,422][root][INFO] - Training Epoch: 2/2, step 2099/7134 completed (loss: 0.18442700803279877, acc: 0.9375)
[2024-12-17 02:53:08,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:08,809][root][INFO] - Training Epoch: 2/2, step 2100/7134 completed (loss: 0.2924481928348541, acc: 0.9371428489685059)
[2024-12-17 02:53:08,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,193][root][INFO] - Training Epoch: 2/2, step 2101/7134 completed (loss: 0.21620257198810577, acc: 0.9404761791229248)
[2024-12-17 02:53:09,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,555][root][INFO] - Training Epoch: 2/2, step 2102/7134 completed (loss: 0.15479324758052826, acc: 0.9567567706108093)
[2024-12-17 02:53:09,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:09,935][root][INFO] - Training Epoch: 2/2, step 2103/7134 completed (loss: 0.27116769552230835, acc: 0.9312499761581421)
[2024-12-17 02:53:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,323][root][INFO] - Training Epoch: 2/2, step 2104/7134 completed (loss: 0.1222003623843193, acc: 0.9714285731315613)
[2024-12-17 02:53:10,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:10,707][root][INFO] - Training Epoch: 2/2, step 2105/7134 completed (loss: 0.16210505366325378, acc: 0.9716312289237976)
[2024-12-17 02:53:10,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,103][root][INFO] - Training Epoch: 2/2, step 2106/7134 completed (loss: 0.23078301548957825, acc: 0.9539473652839661)
[2024-12-17 02:53:11,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,485][root][INFO] - Training Epoch: 2/2, step 2107/7134 completed (loss: 0.21163620054721832, acc: 0.950276255607605)
[2024-12-17 02:53:11,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:11,886][root][INFO] - Training Epoch: 2/2, step 2108/7134 completed (loss: 0.1874561607837677, acc: 0.9378882050514221)
[2024-12-17 02:53:11,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,250][root][INFO] - Training Epoch: 2/2, step 2109/7134 completed (loss: 0.2793130874633789, acc: 0.9492753744125366)
[2024-12-17 02:53:12,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:12,639][root][INFO] - Training Epoch: 2/2, step 2110/7134 completed (loss: 0.41624191403388977, acc: 0.9041916131973267)
[2024-12-17 02:53:12,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,009][root][INFO] - Training Epoch: 2/2, step 2111/7134 completed (loss: 0.2864004671573639, acc: 0.9119170904159546)
[2024-12-17 02:53:13,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,355][root][INFO] - Training Epoch: 2/2, step 2112/7134 completed (loss: 0.1341022551059723, acc: 0.9800000190734863)
[2024-12-17 02:53:13,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:13,728][root][INFO] - Training Epoch: 2/2, step 2113/7134 completed (loss: 0.2926657795906067, acc: 0.9466666579246521)
[2024-12-17 02:53:13,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,107][root][INFO] - Training Epoch: 2/2, step 2114/7134 completed (loss: 0.20930656790733337, acc: 0.9349112510681152)
[2024-12-17 02:53:14,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,482][root][INFO] - Training Epoch: 2/2, step 2115/7134 completed (loss: 0.24743972718715668, acc: 0.9482758641242981)
[2024-12-17 02:53:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:14,859][root][INFO] - Training Epoch: 2/2, step 2116/7134 completed (loss: 0.24873286485671997, acc: 0.9387755393981934)
[2024-12-17 02:53:14,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,231][root][INFO] - Training Epoch: 2/2, step 2117/7134 completed (loss: 0.33861100673675537, acc: 0.9435028433799744)
[2024-12-17 02:53:15,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,597][root][INFO] - Training Epoch: 2/2, step 2118/7134 completed (loss: 0.16792458295822144, acc: 0.9704142212867737)
[2024-12-17 02:53:15,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:15,973][root][INFO] - Training Epoch: 2/2, step 2119/7134 completed (loss: 0.25311750173568726, acc: 0.9364162087440491)
[2024-12-17 02:53:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,340][root][INFO] - Training Epoch: 2/2, step 2120/7134 completed (loss: 0.2916126847267151, acc: 0.9135802388191223)
[2024-12-17 02:53:16,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:16,690][root][INFO] - Training Epoch: 2/2, step 2121/7134 completed (loss: 0.270327091217041, acc: 0.9463087320327759)
[2024-12-17 02:53:16,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,070][root][INFO] - Training Epoch: 2/2, step 2122/7134 completed (loss: 0.31329452991485596, acc: 0.9435028433799744)
[2024-12-17 02:53:17,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,431][root][INFO] - Training Epoch: 2/2, step 2123/7134 completed (loss: 0.25435662269592285, acc: 0.9539473652839661)
[2024-12-17 02:53:17,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:17,810][root][INFO] - Training Epoch: 2/2, step 2124/7134 completed (loss: 0.26231181621551514, acc: 0.912162184715271)
[2024-12-17 02:53:17,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,186][root][INFO] - Training Epoch: 2/2, step 2125/7134 completed (loss: 0.08761011809110641, acc: 0.976047933101654)
[2024-12-17 02:53:18,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,566][root][INFO] - Training Epoch: 2/2, step 2126/7134 completed (loss: 0.2708300054073334, acc: 0.914893627166748)
[2024-12-17 02:53:18,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:18,923][root][INFO] - Training Epoch: 2/2, step 2127/7134 completed (loss: 0.1771308183670044, acc: 0.9638554453849792)
[2024-12-17 02:53:19,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,293][root][INFO] - Training Epoch: 2/2, step 2128/7134 completed (loss: 0.16982486844062805, acc: 0.9611111283302307)
[2024-12-17 02:53:19,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:19,666][root][INFO] - Training Epoch: 2/2, step 2129/7134 completed (loss: 0.23199740052223206, acc: 0.9585798978805542)
[2024-12-17 02:53:19,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,009][root][INFO] - Training Epoch: 2/2, step 2130/7134 completed (loss: 0.22725994884967804, acc: 0.9459459185600281)
[2024-12-17 02:53:20,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,348][root][INFO] - Training Epoch: 2/2, step 2131/7134 completed (loss: 0.11064775288105011, acc: 0.9693251252174377)
[2024-12-17 02:53:20,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:20,715][root][INFO] - Training Epoch: 2/2, step 2132/7134 completed (loss: 0.0685829445719719, acc: 0.9939024448394775)
[2024-12-17 02:53:20,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,096][root][INFO] - Training Epoch: 2/2, step 2133/7134 completed (loss: 0.21965494751930237, acc: 0.9532163739204407)
[2024-12-17 02:53:21,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,464][root][INFO] - Training Epoch: 2/2, step 2134/7134 completed (loss: 0.10821549594402313, acc: 0.977011501789093)
[2024-12-17 02:53:21,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:21,822][root][INFO] - Training Epoch: 2/2, step 2135/7134 completed (loss: 0.116519033908844, acc: 0.9668874144554138)
[2024-12-17 02:53:21,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,198][root][INFO] - Training Epoch: 2/2, step 2136/7134 completed (loss: 0.11524094641208649, acc: 0.9670329689979553)
[2024-12-17 02:53:22,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,631][root][INFO] - Training Epoch: 2/2, step 2137/7134 completed (loss: 0.19497041404247284, acc: 0.9468085169792175)
[2024-12-17 02:53:22,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:22,968][root][INFO] - Training Epoch: 2/2, step 2138/7134 completed (loss: 0.12789563834667206, acc: 0.9640718698501587)
[2024-12-17 02:53:23,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,341][root][INFO] - Training Epoch: 2/2, step 2139/7134 completed (loss: 0.10169308632612228, acc: 0.9651162624359131)
[2024-12-17 02:53:23,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:23,746][root][INFO] - Training Epoch: 2/2, step 2140/7134 completed (loss: 0.3571087718009949, acc: 0.909604549407959)
[2024-12-17 02:53:23,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,092][root][INFO] - Training Epoch: 2/2, step 2141/7134 completed (loss: 0.3972039222717285, acc: 0.914893627166748)
[2024-12-17 02:53:24,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,476][root][INFO] - Training Epoch: 2/2, step 2142/7134 completed (loss: 0.3184642493724823, acc: 0.9378530979156494)
[2024-12-17 02:53:24,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:24,849][root][INFO] - Training Epoch: 2/2, step 2143/7134 completed (loss: 0.10277125984430313, acc: 0.9724137783050537)
[2024-12-17 02:53:24,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,232][root][INFO] - Training Epoch: 2/2, step 2144/7134 completed (loss: 0.08596917986869812, acc: 0.9943181872367859)
[2024-12-17 02:53:25,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:25,603][root][INFO] - Training Epoch: 2/2, step 2145/7134 completed (loss: 0.26028743386268616, acc: 0.9360465407371521)
[2024-12-17 02:53:25,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,008][root][INFO] - Training Epoch: 2/2, step 2146/7134 completed (loss: 0.14264912903308868, acc: 0.9459459185600281)
[2024-12-17 02:53:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,397][root][INFO] - Training Epoch: 2/2, step 2147/7134 completed (loss: 0.27834856510162354, acc: 0.9292929172515869)
[2024-12-17 02:53:26,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:26,777][root][INFO] - Training Epoch: 2/2, step 2148/7134 completed (loss: 0.1703721284866333, acc: 0.9488636255264282)
[2024-12-17 02:53:26,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,163][root][INFO] - Training Epoch: 2/2, step 2149/7134 completed (loss: 0.13880598545074463, acc: 0.9532163739204407)
[2024-12-17 02:53:27,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,554][root][INFO] - Training Epoch: 2/2, step 2150/7134 completed (loss: 0.19350968301296234, acc: 0.9548022747039795)
[2024-12-17 02:53:27,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:27,948][root][INFO] - Training Epoch: 2/2, step 2151/7134 completed (loss: 0.21038730442523956, acc: 0.9518072009086609)
[2024-12-17 02:53:28,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,345][root][INFO] - Training Epoch: 2/2, step 2152/7134 completed (loss: 0.2389911711215973, acc: 0.9354838728904724)
[2024-12-17 02:53:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:28,752][root][INFO] - Training Epoch: 2/2, step 2153/7134 completed (loss: 0.2060123085975647, acc: 0.9411764740943909)
[2024-12-17 02:53:28,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,145][root][INFO] - Training Epoch: 2/2, step 2154/7134 completed (loss: 0.2690802812576294, acc: 0.9195402264595032)
[2024-12-17 02:53:29,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,528][root][INFO] - Training Epoch: 2/2, step 2155/7134 completed (loss: 0.29181623458862305, acc: 0.9102563858032227)
[2024-12-17 02:53:29,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:29,902][root][INFO] - Training Epoch: 2/2, step 2156/7134 completed (loss: 0.1966594010591507, acc: 0.970588207244873)
[2024-12-17 02:53:30,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,296][root][INFO] - Training Epoch: 2/2, step 2157/7134 completed (loss: 0.28410565853118896, acc: 0.9242424368858337)
[2024-12-17 02:53:30,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:30,702][root][INFO] - Training Epoch: 2/2, step 2158/7134 completed (loss: 0.2707103490829468, acc: 0.9432989954948425)
[2024-12-17 02:53:30,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,086][root][INFO] - Training Epoch: 2/2, step 2159/7134 completed (loss: 0.08762920647859573, acc: 0.9821428656578064)
[2024-12-17 02:53:31,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,466][root][INFO] - Training Epoch: 2/2, step 2160/7134 completed (loss: 0.17492572963237762, acc: 0.9451219439506531)
[2024-12-17 02:53:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:31,846][root][INFO] - Training Epoch: 2/2, step 2161/7134 completed (loss: 0.2233421951532364, acc: 0.9222221970558167)
[2024-12-17 02:53:31,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,220][root][INFO] - Training Epoch: 2/2, step 2162/7134 completed (loss: 0.17899024486541748, acc: 0.948387086391449)
[2024-12-17 02:53:32,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:32,640][root][INFO] - Training Epoch: 2/2, step 2163/7134 completed (loss: 0.21881099045276642, acc: 0.9466666579246521)
[2024-12-17 02:53:32,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,014][root][INFO] - Training Epoch: 2/2, step 2164/7134 completed (loss: 0.10777386277914047, acc: 0.9772727489471436)
[2024-12-17 02:53:33,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,399][root][INFO] - Training Epoch: 2/2, step 2165/7134 completed (loss: 0.1678909808397293, acc: 0.957317054271698)
[2024-12-17 02:53:33,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:33,781][root][INFO] - Training Epoch: 2/2, step 2166/7134 completed (loss: 0.14368973672389984, acc: 0.9604519605636597)
[2024-12-17 02:53:33,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,182][root][INFO] - Training Epoch: 2/2, step 2167/7134 completed (loss: 0.2742427587509155, acc: 0.9611650705337524)
[2024-12-17 02:53:34,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,531][root][INFO] - Training Epoch: 2/2, step 2168/7134 completed (loss: 0.11212682723999023, acc: 0.9856114983558655)
[2024-12-17 02:53:34,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:34,917][root][INFO] - Training Epoch: 2/2, step 2169/7134 completed (loss: 0.17345939576625824, acc: 0.9597989916801453)
[2024-12-17 02:53:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,293][root][INFO] - Training Epoch: 2/2, step 2170/7134 completed (loss: 0.15520203113555908, acc: 0.9477124214172363)
[2024-12-17 02:53:35,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:35,681][root][INFO] - Training Epoch: 2/2, step 2171/7134 completed (loss: 0.29219916462898254, acc: 0.9405405521392822)
[2024-12-17 02:53:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,070][root][INFO] - Training Epoch: 2/2, step 2172/7134 completed (loss: 0.13182225823402405, acc: 0.971563994884491)
[2024-12-17 02:53:36,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,440][root][INFO] - Training Epoch: 2/2, step 2173/7134 completed (loss: 0.21953190863132477, acc: 0.9452054500579834)
[2024-12-17 02:53:36,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:36,809][root][INFO] - Training Epoch: 2/2, step 2174/7134 completed (loss: 0.1180669441819191, acc: 0.970059871673584)
[2024-12-17 02:53:36,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,186][root][INFO] - Training Epoch: 2/2, step 2175/7134 completed (loss: 0.20398147404193878, acc: 0.9515151381492615)
[2024-12-17 02:53:37,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:37,582][root][INFO] - Training Epoch: 2/2, step 2176/7134 completed (loss: 0.16767524182796478, acc: 0.9510869383811951)
[2024-12-17 02:53:37,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,049][root][INFO] - Training Epoch: 2/2, step 2177/7134 completed (loss: 0.22426089644432068, acc: 0.9344262480735779)
[2024-12-17 02:53:38,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,429][root][INFO] - Training Epoch: 2/2, step 2178/7134 completed (loss: 0.15591134130954742, acc: 0.96875)
[2024-12-17 02:53:38,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:38,819][root][INFO] - Training Epoch: 2/2, step 2179/7134 completed (loss: 0.1357572227716446, acc: 0.9655172228813171)
[2024-12-17 02:53:38,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,210][root][INFO] - Training Epoch: 2/2, step 2180/7134 completed (loss: 0.17250996828079224, acc: 0.9560439586639404)
[2024-12-17 02:53:39,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:39,663][root][INFO] - Training Epoch: 2/2, step 2181/7134 completed (loss: 0.1527458280324936, acc: 0.9503105878829956)
[2024-12-17 02:53:39,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,055][root][INFO] - Training Epoch: 2/2, step 2182/7134 completed (loss: 0.23142516613006592, acc: 0.9538461565971375)
[2024-12-17 02:53:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,463][root][INFO] - Training Epoch: 2/2, step 2183/7134 completed (loss: 0.19140148162841797, acc: 0.9668508172035217)
[2024-12-17 02:53:40,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:40,862][root][INFO] - Training Epoch: 2/2, step 2184/7134 completed (loss: 0.1473187506198883, acc: 0.9647887349128723)
[2024-12-17 02:53:40,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,240][root][INFO] - Training Epoch: 2/2, step 2185/7134 completed (loss: 0.25826022028923035, acc: 0.9433962106704712)
[2024-12-17 02:53:41,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:41,632][root][INFO] - Training Epoch: 2/2, step 2186/7134 completed (loss: 0.45801976323127747, acc: 0.9200000166893005)
[2024-12-17 02:53:41,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,021][root][INFO] - Training Epoch: 2/2, step 2187/7134 completed (loss: 0.39030271768569946, acc: 0.9136690497398376)
[2024-12-17 02:53:42,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,418][root][INFO] - Training Epoch: 2/2, step 2188/7134 completed (loss: 0.12921878695487976, acc: 0.9515151381492615)
[2024-12-17 02:53:42,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:42,807][root][INFO] - Training Epoch: 2/2, step 2189/7134 completed (loss: 0.2967030107975006, acc: 0.9285714030265808)
[2024-12-17 02:53:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,212][root][INFO] - Training Epoch: 2/2, step 2190/7134 completed (loss: 0.28112131357192993, acc: 0.9329608678817749)
[2024-12-17 02:53:43,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:43,614][root][INFO] - Training Epoch: 2/2, step 2191/7134 completed (loss: 0.32348108291625977, acc: 0.9052631855010986)
[2024-12-17 02:53:43,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,016][root][INFO] - Training Epoch: 2/2, step 2192/7134 completed (loss: 0.1106233149766922, acc: 0.9777777791023254)
[2024-12-17 02:53:44,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,407][root][INFO] - Training Epoch: 2/2, step 2193/7134 completed (loss: 0.1985836923122406, acc: 0.9398906826972961)
[2024-12-17 02:53:44,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:44,798][root][INFO] - Training Epoch: 2/2, step 2194/7134 completed (loss: 0.18277406692504883, acc: 0.9407894611358643)
[2024-12-17 02:53:44,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,198][root][INFO] - Training Epoch: 2/2, step 2195/7134 completed (loss: 0.11891703307628632, acc: 0.9691358208656311)
[2024-12-17 02:53:45,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,591][root][INFO] - Training Epoch: 2/2, step 2196/7134 completed (loss: 0.21779358386993408, acc: 0.9285714030265808)
[2024-12-17 02:53:45,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:45,962][root][INFO] - Training Epoch: 2/2, step 2197/7134 completed (loss: 0.266051709651947, acc: 0.9448819160461426)
[2024-12-17 02:53:46,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,343][root][INFO] - Training Epoch: 2/2, step 2198/7134 completed (loss: 0.12571606040000916, acc: 0.9655172228813171)
[2024-12-17 02:53:46,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:46,736][root][INFO] - Training Epoch: 2/2, step 2199/7134 completed (loss: 0.12823039293289185, acc: 0.9810126423835754)
[2024-12-17 02:53:46,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,126][root][INFO] - Training Epoch: 2/2, step 2200/7134 completed (loss: 0.10637370496988297, acc: 0.9842519760131836)
[2024-12-17 02:53:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,511][root][INFO] - Training Epoch: 2/2, step 2201/7134 completed (loss: 0.11592940986156464, acc: 0.9662162065505981)
[2024-12-17 02:53:47,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:47,882][root][INFO] - Training Epoch: 2/2, step 2202/7134 completed (loss: 0.10972445458173752, acc: 0.970802903175354)
[2024-12-17 02:53:47,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,278][root][INFO] - Training Epoch: 2/2, step 2203/7134 completed (loss: 0.06544923782348633, acc: 0.9880239367485046)
[2024-12-17 02:53:48,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:48,677][root][INFO] - Training Epoch: 2/2, step 2204/7134 completed (loss: 0.13862550258636475, acc: 0.9655172228813171)
[2024-12-17 02:53:48,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,047][root][INFO] - Training Epoch: 2/2, step 2205/7134 completed (loss: 0.06358218938112259, acc: 0.9929078221321106)
[2024-12-17 02:53:49,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,420][root][INFO] - Training Epoch: 2/2, step 2206/7134 completed (loss: 0.13004541397094727, acc: 0.9731543660163879)
[2024-12-17 02:53:49,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:49,802][root][INFO] - Training Epoch: 2/2, step 2207/7134 completed (loss: 0.10251499712467194, acc: 0.9727891087532043)
[2024-12-17 02:53:49,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,152][root][INFO] - Training Epoch: 2/2, step 2208/7134 completed (loss: 0.09318318217992783, acc: 0.9806451797485352)
[2024-12-17 02:53:50,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,544][root][INFO] - Training Epoch: 2/2, step 2209/7134 completed (loss: 0.1655551642179489, acc: 0.9634146094322205)
[2024-12-17 02:53:50,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:50,912][root][INFO] - Training Epoch: 2/2, step 2210/7134 completed (loss: 0.2188243865966797, acc: 0.9390243887901306)
[2024-12-17 02:53:51,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,284][root][INFO] - Training Epoch: 2/2, step 2211/7134 completed (loss: 0.06423310190439224, acc: 0.9819276928901672)
[2024-12-17 02:53:51,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:51,657][root][INFO] - Training Epoch: 2/2, step 2212/7134 completed (loss: 0.08547065407037735, acc: 0.9885714054107666)
[2024-12-17 02:53:51,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,029][root][INFO] - Training Epoch: 2/2, step 2213/7134 completed (loss: 0.17133729159832, acc: 0.9588235020637512)
[2024-12-17 02:53:52,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,397][root][INFO] - Training Epoch: 2/2, step 2214/7134 completed (loss: 0.14528468251228333, acc: 0.9662162065505981)
[2024-12-17 02:53:52,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:52,772][root][INFO] - Training Epoch: 2/2, step 2215/7134 completed (loss: 0.09706738591194153, acc: 0.9620253443717957)
[2024-12-17 02:53:52,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,140][root][INFO] - Training Epoch: 2/2, step 2216/7134 completed (loss: 0.10969209671020508, acc: 0.9707602262496948)
[2024-12-17 02:53:53,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,502][root][INFO] - Training Epoch: 2/2, step 2217/7134 completed (loss: 0.09212427586317062, acc: 0.976047933101654)
[2024-12-17 02:53:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:53,941][root][INFO] - Training Epoch: 2/2, step 2218/7134 completed (loss: 0.18066568672657013, acc: 0.9444444179534912)
[2024-12-17 02:53:54,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,326][root][INFO] - Training Epoch: 2/2, step 2219/7134 completed (loss: 0.17106397449970245, acc: 0.949999988079071)
[2024-12-17 02:53:54,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:54,709][root][INFO] - Training Epoch: 2/2, step 2220/7134 completed (loss: 0.1551990807056427, acc: 0.9481481313705444)
[2024-12-17 02:53:54,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,089][root][INFO] - Training Epoch: 2/2, step 2221/7134 completed (loss: 0.21244309842586517, acc: 0.9316770434379578)
[2024-12-17 02:53:55,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,467][root][INFO] - Training Epoch: 2/2, step 2222/7134 completed (loss: 0.23530107736587524, acc: 0.9041095972061157)
[2024-12-17 02:53:55,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:55,844][root][INFO] - Training Epoch: 2/2, step 2223/7134 completed (loss: 0.21654178202152252, acc: 0.926174521446228)
[2024-12-17 02:53:55,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,228][root][INFO] - Training Epoch: 2/2, step 2224/7134 completed (loss: 0.3012736737728119, acc: 0.9303797483444214)
[2024-12-17 02:53:56,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:56,619][root][INFO] - Training Epoch: 2/2, step 2225/7134 completed (loss: 0.24849571287631989, acc: 0.9047619104385376)
[2024-12-17 02:53:56,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,004][root][INFO] - Training Epoch: 2/2, step 2226/7134 completed (loss: 0.15028874576091766, acc: 0.9463087320327759)
[2024-12-17 02:53:57,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,388][root][INFO] - Training Epoch: 2/2, step 2227/7134 completed (loss: 0.1007055938243866, acc: 0.9805194735527039)
[2024-12-17 02:53:57,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:57,750][root][INFO] - Training Epoch: 2/2, step 2228/7134 completed (loss: 0.14193592965602875, acc: 0.9534883499145508)
[2024-12-17 02:53:57,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,120][root][INFO] - Training Epoch: 2/2, step 2229/7134 completed (loss: 0.13417503237724304, acc: 0.9611650705337524)
[2024-12-17 02:53:58,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,475][root][INFO] - Training Epoch: 2/2, step 2230/7134 completed (loss: 0.06947345286607742, acc: 0.9856114983558655)
[2024-12-17 02:53:58,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:58,839][root][INFO] - Training Epoch: 2/2, step 2231/7134 completed (loss: 0.21501968801021576, acc: 0.9495798349380493)
[2024-12-17 02:53:58,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,224][root][INFO] - Training Epoch: 2/2, step 2232/7134 completed (loss: 0.15940679609775543, acc: 0.9425287246704102)
[2024-12-17 02:53:59,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,596][root][INFO] - Training Epoch: 2/2, step 2233/7134 completed (loss: 0.19902615249156952, acc: 0.9294871687889099)
[2024-12-17 02:53:59,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:53:59,981][root][INFO] - Training Epoch: 2/2, step 2234/7134 completed (loss: 0.0600343756377697, acc: 0.9870129823684692)
[2024-12-17 02:54:00,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,351][root][INFO] - Training Epoch: 2/2, step 2235/7134 completed (loss: 0.16721495985984802, acc: 0.9510489702224731)
[2024-12-17 02:54:00,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:00,710][root][INFO] - Training Epoch: 2/2, step 2236/7134 completed (loss: 0.15490411221981049, acc: 0.9599999785423279)
[2024-12-17 02:54:00,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,097][root][INFO] - Training Epoch: 2/2, step 2237/7134 completed (loss: 0.19102083146572113, acc: 0.9466666579246521)
[2024-12-17 02:54:01,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,471][root][INFO] - Training Epoch: 2/2, step 2238/7134 completed (loss: 0.2794036567211151, acc: 0.9320987462997437)
[2024-12-17 02:54:01,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:01,845][root][INFO] - Training Epoch: 2/2, step 2239/7134 completed (loss: 0.5018287301063538, acc: 0.8877005577087402)
[2024-12-17 02:54:01,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,269][root][INFO] - Training Epoch: 2/2, step 2240/7134 completed (loss: 0.2855548560619354, acc: 0.9204545617103577)
[2024-12-17 02:54:02,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,630][root][INFO] - Training Epoch: 2/2, step 2241/7134 completed (loss: 0.3722899258136749, acc: 0.9270833134651184)
[2024-12-17 02:54:02,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:02,995][root][INFO] - Training Epoch: 2/2, step 2242/7134 completed (loss: 0.5898003578186035, acc: 0.8888888955116272)
[2024-12-17 02:54:03,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,383][root][INFO] - Training Epoch: 2/2, step 2243/7134 completed (loss: 0.7276818156242371, acc: 0.85161292552948)
[2024-12-17 02:54:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:03,756][root][INFO] - Training Epoch: 2/2, step 2244/7134 completed (loss: 0.32925957441329956, acc: 0.9041095972061157)
[2024-12-17 02:54:03,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,097][root][INFO] - Training Epoch: 2/2, step 2245/7134 completed (loss: 0.41655418276786804, acc: 0.8954248428344727)
[2024-12-17 02:54:04,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,467][root][INFO] - Training Epoch: 2/2, step 2246/7134 completed (loss: 0.6738355755805969, acc: 0.8142076730728149)
[2024-12-17 02:54:04,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:04,837][root][INFO] - Training Epoch: 2/2, step 2247/7134 completed (loss: 0.5536513328552246, acc: 0.849711000919342)
[2024-12-17 02:54:04,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,202][root][INFO] - Training Epoch: 2/2, step 2248/7134 completed (loss: 0.49941858649253845, acc: 0.8786126971244812)
[2024-12-17 02:54:05,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,578][root][INFO] - Training Epoch: 2/2, step 2249/7134 completed (loss: 0.3577117621898651, acc: 0.9060773253440857)
[2024-12-17 02:54:05,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:05,962][root][INFO] - Training Epoch: 2/2, step 2250/7134 completed (loss: 0.3478006422519684, acc: 0.9042553305625916)
[2024-12-17 02:54:06,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,318][root][INFO] - Training Epoch: 2/2, step 2251/7134 completed (loss: 0.14612749218940735, acc: 0.9508196711540222)
[2024-12-17 02:54:06,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:06,753][root][INFO] - Training Epoch: 2/2, step 2252/7134 completed (loss: 0.21593183279037476, acc: 0.9510869383811951)
[2024-12-17 02:54:06,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,161][root][INFO] - Training Epoch: 2/2, step 2253/7134 completed (loss: 0.34864893555641174, acc: 0.9299362897872925)
[2024-12-17 02:54:07,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,566][root][INFO] - Training Epoch: 2/2, step 2254/7134 completed (loss: 0.5305551290512085, acc: 0.8629032373428345)
[2024-12-17 02:54:07,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:07,987][root][INFO] - Training Epoch: 2/2, step 2255/7134 completed (loss: 0.1598178744316101, acc: 0.955974817276001)
[2024-12-17 02:54:08,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,374][root][INFO] - Training Epoch: 2/2, step 2256/7134 completed (loss: 0.4829038381576538, acc: 0.8943089246749878)
[2024-12-17 02:54:08,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:08,805][root][INFO] - Training Epoch: 2/2, step 2257/7134 completed (loss: 0.2125404328107834, acc: 0.9444444179534912)
[2024-12-17 02:54:08,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,196][root][INFO] - Training Epoch: 2/2, step 2258/7134 completed (loss: 0.14384017884731293, acc: 0.9767441749572754)
[2024-12-17 02:54:09,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:09,607][root][INFO] - Training Epoch: 2/2, step 2259/7134 completed (loss: 0.29918837547302246, acc: 0.94017094373703)
[2024-12-17 02:54:09,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,010][root][INFO] - Training Epoch: 2/2, step 2260/7134 completed (loss: 0.39598390460014343, acc: 0.8831169009208679)
[2024-12-17 02:54:10,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,384][root][INFO] - Training Epoch: 2/2, step 2261/7134 completed (loss: 0.6000338196754456, acc: 0.8518518805503845)
[2024-12-17 02:54:10,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:10,732][root][INFO] - Training Epoch: 2/2, step 2262/7134 completed (loss: 0.27887529134750366, acc: 0.9172932505607605)
[2024-12-17 02:54:10,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,095][root][INFO] - Training Epoch: 2/2, step 2263/7134 completed (loss: 0.3587021231651306, acc: 0.9097744226455688)
[2024-12-17 02:54:11,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,450][root][INFO] - Training Epoch: 2/2, step 2264/7134 completed (loss: 0.35082244873046875, acc: 0.929729700088501)
[2024-12-17 02:54:11,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:11,835][root][INFO] - Training Epoch: 2/2, step 2265/7134 completed (loss: 0.445678174495697, acc: 0.8961039185523987)
[2024-12-17 02:54:11,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,212][root][INFO] - Training Epoch: 2/2, step 2266/7134 completed (loss: 0.31179648637771606, acc: 0.9226519465446472)
[2024-12-17 02:54:12,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,583][root][INFO] - Training Epoch: 2/2, step 2267/7134 completed (loss: 0.17364655435085297, acc: 0.934959352016449)
[2024-12-17 02:54:12,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:12,966][root][INFO] - Training Epoch: 2/2, step 2268/7134 completed (loss: 0.1811923384666443, acc: 0.9452054500579834)
[2024-12-17 02:54:13,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,350][root][INFO] - Training Epoch: 2/2, step 2269/7134 completed (loss: 0.2243838757276535, acc: 0.9441340565681458)
[2024-12-17 02:54:13,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:13,724][root][INFO] - Training Epoch: 2/2, step 2270/7134 completed (loss: 0.35838583111763, acc: 0.921875)
[2024-12-17 02:54:13,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,139][root][INFO] - Training Epoch: 2/2, step 2271/7134 completed (loss: 0.4355236291885376, acc: 0.8864864706993103)
[2024-12-17 02:54:14,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:14,545][root][INFO] - Training Epoch: 2/2, step 2272/7134 completed (loss: 0.27309849858283997, acc: 0.9193548560142517)
[2024-12-17 02:54:14,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,004][root][INFO] - Training Epoch: 2/2, step 2273/7134 completed (loss: 0.13545694947242737, acc: 0.9666666388511658)
[2024-12-17 02:54:15,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,408][root][INFO] - Training Epoch: 2/2, step 2274/7134 completed (loss: 0.542484700679779, acc: 0.892307698726654)
[2024-12-17 02:54:15,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:15,807][root][INFO] - Training Epoch: 2/2, step 2275/7134 completed (loss: 0.13671377301216125, acc: 0.9656862616539001)
[2024-12-17 02:54:15,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,199][root][INFO] - Training Epoch: 2/2, step 2276/7134 completed (loss: 0.2713780701160431, acc: 0.9312169551849365)
[2024-12-17 02:54:16,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:16,610][root][INFO] - Training Epoch: 2/2, step 2277/7134 completed (loss: 0.3425503969192505, acc: 0.928205132484436)
[2024-12-17 02:54:16,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,041][root][INFO] - Training Epoch: 2/2, step 2278/7134 completed (loss: 0.595947802066803, acc: 0.9096774458885193)
[2024-12-17 02:54:17,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,443][root][INFO] - Training Epoch: 2/2, step 2279/7134 completed (loss: 0.2515323758125305, acc: 0.9340101480484009)
[2024-12-17 02:54:17,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:17,824][root][INFO] - Training Epoch: 2/2, step 2280/7134 completed (loss: 0.2745400667190552, acc: 0.9266055226325989)
[2024-12-17 02:54:17,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,177][root][INFO] - Training Epoch: 2/2, step 2281/7134 completed (loss: 0.45749640464782715, acc: 0.8936170339584351)
[2024-12-17 02:54:18,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,559][root][INFO] - Training Epoch: 2/2, step 2282/7134 completed (loss: 0.16259761154651642, acc: 0.9631578922271729)
[2024-12-17 02:54:18,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:18,924][root][INFO] - Training Epoch: 2/2, step 2283/7134 completed (loss: 0.19176679849624634, acc: 0.9711538553237915)
[2024-12-17 02:54:19,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,285][root][INFO] - Training Epoch: 2/2, step 2284/7134 completed (loss: 0.1795247495174408, acc: 0.9419354796409607)
[2024-12-17 02:54:19,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:19,664][root][INFO] - Training Epoch: 2/2, step 2285/7134 completed (loss: 0.11955537647008896, acc: 0.9750000238418579)
[2024-12-17 02:54:19,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,035][root][INFO] - Training Epoch: 2/2, step 2286/7134 completed (loss: 0.3254341781139374, acc: 0.8908045887947083)
[2024-12-17 02:54:20,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,419][root][INFO] - Training Epoch: 2/2, step 2287/7134 completed (loss: 0.21262536942958832, acc: 0.9263803958892822)
[2024-12-17 02:54:20,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:20,798][root][INFO] - Training Epoch: 2/2, step 2288/7134 completed (loss: 0.1359521746635437, acc: 0.9670329689979553)
[2024-12-17 02:54:20,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,188][root][INFO] - Training Epoch: 2/2, step 2289/7134 completed (loss: 0.17414794862270355, acc: 0.9518716335296631)
[2024-12-17 02:54:21,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:21,639][root][INFO] - Training Epoch: 2/2, step 2290/7134 completed (loss: 0.24857929348945618, acc: 0.9408602118492126)
[2024-12-17 02:54:21,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,059][root][INFO] - Training Epoch: 2/2, step 2291/7134 completed (loss: 0.2872033715248108, acc: 0.9226519465446472)
[2024-12-17 02:54:22,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,472][root][INFO] - Training Epoch: 2/2, step 2292/7134 completed (loss: 0.3184656500816345, acc: 0.9141414165496826)
[2024-12-17 02:54:22,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:22,856][root][INFO] - Training Epoch: 2/2, step 2293/7134 completed (loss: 0.2320570945739746, acc: 0.922374427318573)
[2024-12-17 02:54:22,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,220][root][INFO] - Training Epoch: 2/2, step 2294/7134 completed (loss: 0.1547541320323944, acc: 0.9473684430122375)
[2024-12-17 02:54:23,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:23,614][root][INFO] - Training Epoch: 2/2, step 2295/7134 completed (loss: 0.23909974098205566, acc: 0.94140625)
[2024-12-17 02:54:23,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,004][root][INFO] - Training Epoch: 2/2, step 2296/7134 completed (loss: 0.20639429986476898, acc: 0.942307710647583)
[2024-12-17 02:54:24,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,420][root][INFO] - Training Epoch: 2/2, step 2297/7134 completed (loss: 0.12283060699701309, acc: 0.9716981053352356)
[2024-12-17 02:54:24,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:24,802][root][INFO] - Training Epoch: 2/2, step 2298/7134 completed (loss: 0.172085240483284, acc: 0.9523809552192688)
[2024-12-17 02:54:24,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,223][root][INFO] - Training Epoch: 2/2, step 2299/7134 completed (loss: 0.3620246946811676, acc: 0.9086021780967712)
[2024-12-17 02:54:25,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,578][root][INFO] - Training Epoch: 2/2, step 2300/7134 completed (loss: 0.16620491445064545, acc: 0.9545454382896423)
[2024-12-17 02:54:25,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:25,933][root][INFO] - Training Epoch: 2/2, step 2301/7134 completed (loss: 0.28549647331237793, acc: 0.89673912525177)
[2024-12-17 02:54:26,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,303][root][INFO] - Training Epoch: 2/2, step 2302/7134 completed (loss: 0.21103717386722565, acc: 0.9538461565971375)
[2024-12-17 02:54:26,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:26,678][root][INFO] - Training Epoch: 2/2, step 2303/7134 completed (loss: 0.2501883804798126, acc: 0.9447004795074463)
[2024-12-17 02:54:26,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,041][root][INFO] - Training Epoch: 2/2, step 2304/7134 completed (loss: 0.3462825417518616, acc: 0.907489001750946)
[2024-12-17 02:54:27,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,428][root][INFO] - Training Epoch: 2/2, step 2305/7134 completed (loss: 0.22221021354198456, acc: 0.948113203048706)
[2024-12-17 02:54:27,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:27,813][root][INFO] - Training Epoch: 2/2, step 2306/7134 completed (loss: 0.12656158208847046, acc: 0.9581395387649536)
[2024-12-17 02:54:27,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,191][root][INFO] - Training Epoch: 2/2, step 2307/7134 completed (loss: 0.14979884028434753, acc: 0.9661017060279846)
[2024-12-17 02:54:28,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,581][root][INFO] - Training Epoch: 2/2, step 2308/7134 completed (loss: 0.22344212234020233, acc: 0.9471365809440613)
[2024-12-17 02:54:28,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:28,968][root][INFO] - Training Epoch: 2/2, step 2309/7134 completed (loss: 0.08926648646593094, acc: 0.9788359999656677)
[2024-12-17 02:54:29,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,365][root][INFO] - Training Epoch: 2/2, step 2310/7134 completed (loss: 0.12886348366737366, acc: 0.961904764175415)
[2024-12-17 02:54:29,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:29,748][root][INFO] - Training Epoch: 2/2, step 2311/7134 completed (loss: 0.19835135340690613, acc: 0.9507389068603516)
[2024-12-17 02:54:29,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,167][root][INFO] - Training Epoch: 2/2, step 2312/7134 completed (loss: 0.16789229214191437, acc: 0.9436619877815247)
[2024-12-17 02:54:30,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,533][root][INFO] - Training Epoch: 2/2, step 2313/7134 completed (loss: 0.20829367637634277, acc: 0.9375)
[2024-12-17 02:54:30,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:30,922][root][INFO] - Training Epoch: 2/2, step 2314/7134 completed (loss: 0.16952592134475708, acc: 0.9587156176567078)
[2024-12-17 02:54:31,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,333][root][INFO] - Training Epoch: 2/2, step 2315/7134 completed (loss: 0.1994885504245758, acc: 0.934883713722229)
[2024-12-17 02:54:31,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:31,733][root][INFO] - Training Epoch: 2/2, step 2316/7134 completed (loss: 0.0711265429854393, acc: 0.9894179701805115)
[2024-12-17 02:54:31,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,204][root][INFO] - Training Epoch: 2/2, step 2317/7134 completed (loss: 0.1836070418357849, acc: 0.9579831957817078)
[2024-12-17 02:54:32,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:32,620][root][INFO] - Training Epoch: 2/2, step 2318/7134 completed (loss: 0.07228737324476242, acc: 0.9825327396392822)
[2024-12-17 02:54:32,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,052][root][INFO] - Training Epoch: 2/2, step 2319/7134 completed (loss: 0.10295324772596359, acc: 0.9729729890823364)
[2024-12-17 02:54:33,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,443][root][INFO] - Training Epoch: 2/2, step 2320/7134 completed (loss: 0.13004527986049652, acc: 0.9794871807098389)
[2024-12-17 02:54:33,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:33,840][root][INFO] - Training Epoch: 2/2, step 2321/7134 completed (loss: 0.09790751338005066, acc: 0.9823529124259949)
[2024-12-17 02:54:33,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,238][root][INFO] - Training Epoch: 2/2, step 2322/7134 completed (loss: 0.20611797273159027, acc: 0.9325153231620789)
[2024-12-17 02:54:34,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:34,596][root][INFO] - Training Epoch: 2/2, step 2323/7134 completed (loss: 0.2301865667104721, acc: 0.9171974658966064)
[2024-12-17 02:54:34,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,002][root][INFO] - Training Epoch: 2/2, step 2324/7134 completed (loss: 0.2790495753288269, acc: 0.9638554453849792)
[2024-12-17 02:54:35,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,388][root][INFO] - Training Epoch: 2/2, step 2325/7134 completed (loss: 0.246089905500412, acc: 0.9214285612106323)
[2024-12-17 02:54:35,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:35,743][root][INFO] - Training Epoch: 2/2, step 2326/7134 completed (loss: 0.10563060641288757, acc: 0.9846153855323792)
[2024-12-17 02:54:35,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,129][root][INFO] - Training Epoch: 2/2, step 2327/7134 completed (loss: 0.09897737950086594, acc: 0.9798657894134521)
[2024-12-17 02:54:36,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,519][root][INFO] - Training Epoch: 2/2, step 2328/7134 completed (loss: 0.25367268919944763, acc: 0.9395973086357117)
[2024-12-17 02:54:36,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:36,900][root][INFO] - Training Epoch: 2/2, step 2329/7134 completed (loss: 0.21899354457855225, acc: 0.9607843160629272)
[2024-12-17 02:54:37,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,245][root][INFO] - Training Epoch: 2/2, step 2330/7134 completed (loss: 0.08554328233003616, acc: 0.9818181991577148)
[2024-12-17 02:54:37,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:37,624][root][INFO] - Training Epoch: 2/2, step 2331/7134 completed (loss: 0.07058355957269669, acc: 0.9870967864990234)
[2024-12-17 02:54:37,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,007][root][INFO] - Training Epoch: 2/2, step 2332/7134 completed (loss: 0.11181013286113739, acc: 0.9636363387107849)
[2024-12-17 02:54:38,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,438][root][INFO] - Training Epoch: 2/2, step 2333/7134 completed (loss: 0.12884671986103058, acc: 0.9756097793579102)
[2024-12-17 02:54:38,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:38,837][root][INFO] - Training Epoch: 2/2, step 2334/7134 completed (loss: 0.2643137276172638, acc: 0.9426751732826233)
[2024-12-17 02:54:38,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,232][root][INFO] - Training Epoch: 2/2, step 2335/7134 completed (loss: 0.14947690069675446, acc: 0.9556962251663208)
[2024-12-17 02:54:39,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,591][root][INFO] - Training Epoch: 2/2, step 2336/7134 completed (loss: 0.06834456324577332, acc: 0.9865771532058716)
[2024-12-17 02:54:39,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:39,959][root][INFO] - Training Epoch: 2/2, step 2337/7134 completed (loss: 0.06391649693250656, acc: 0.9861111044883728)
[2024-12-17 02:54:40,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,344][root][INFO] - Training Epoch: 2/2, step 2338/7134 completed (loss: 0.10899149626493454, acc: 0.9675324559211731)
[2024-12-17 02:54:40,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:40,714][root][INFO] - Training Epoch: 2/2, step 2339/7134 completed (loss: 0.21240371465682983, acc: 0.9487179517745972)
[2024-12-17 02:54:40,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,112][root][INFO] - Training Epoch: 2/2, step 2340/7134 completed (loss: 0.07155146449804306, acc: 0.9805194735527039)
[2024-12-17 02:54:41,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,497][root][INFO] - Training Epoch: 2/2, step 2341/7134 completed (loss: 0.11327172070741653, acc: 0.9752066135406494)
[2024-12-17 02:54:41,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:41,844][root][INFO] - Training Epoch: 2/2, step 2342/7134 completed (loss: 0.08011444658041, acc: 0.976190447807312)
[2024-12-17 02:54:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,248][root][INFO] - Training Epoch: 2/2, step 2343/7134 completed (loss: 0.07433708012104034, acc: 0.9750000238418579)
[2024-12-17 02:54:42,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:42,664][root][INFO] - Training Epoch: 2/2, step 2344/7134 completed (loss: 0.11762617528438568, acc: 0.9506173133850098)
[2024-12-17 02:54:42,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,092][root][INFO] - Training Epoch: 2/2, step 2345/7134 completed (loss: 0.15638042986392975, acc: 0.9655172228813171)
[2024-12-17 02:54:43,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,497][root][INFO] - Training Epoch: 2/2, step 2346/7134 completed (loss: 0.10548634082078934, acc: 0.9779005646705627)
[2024-12-17 02:54:43,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:43,933][root][INFO] - Training Epoch: 2/2, step 2347/7134 completed (loss: 0.3386065661907196, acc: 0.9436619877815247)
[2024-12-17 02:54:44,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,335][root][INFO] - Training Epoch: 2/2, step 2348/7134 completed (loss: 0.533034086227417, acc: 0.8659793734550476)
[2024-12-17 02:54:44,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:44,725][root][INFO] - Training Epoch: 2/2, step 2349/7134 completed (loss: 0.3852800726890564, acc: 0.90625)
[2024-12-17 02:54:44,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,169][root][INFO] - Training Epoch: 2/2, step 2350/7134 completed (loss: 0.5173607468605042, acc: 0.892405092716217)
[2024-12-17 02:54:45,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,562][root][INFO] - Training Epoch: 2/2, step 2351/7134 completed (loss: 0.3144857883453369, acc: 0.9344262480735779)
[2024-12-17 02:54:45,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:45,934][root][INFO] - Training Epoch: 2/2, step 2352/7134 completed (loss: 0.349258154630661, acc: 0.896774172782898)
[2024-12-17 02:54:46,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,315][root][INFO] - Training Epoch: 2/2, step 2353/7134 completed (loss: 0.3021993935108185, acc: 0.9290322661399841)
[2024-12-17 02:54:46,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:46,685][root][INFO] - Training Epoch: 2/2, step 2354/7134 completed (loss: 0.1635105311870575, acc: 0.9562841653823853)
[2024-12-17 02:54:46,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,070][root][INFO] - Training Epoch: 2/2, step 2355/7134 completed (loss: 0.33797168731689453, acc: 0.9337016344070435)
[2024-12-17 02:54:47,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,459][root][INFO] - Training Epoch: 2/2, step 2356/7134 completed (loss: 0.39153870940208435, acc: 0.8913043737411499)
[2024-12-17 02:54:47,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:47,833][root][INFO] - Training Epoch: 2/2, step 2357/7134 completed (loss: 0.22973699867725372, acc: 0.9285714030265808)
[2024-12-17 02:54:47,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,197][root][INFO] - Training Epoch: 2/2, step 2358/7134 completed (loss: 0.35765698552131653, acc: 0.9081632494926453)
[2024-12-17 02:54:48,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,583][root][INFO] - Training Epoch: 2/2, step 2359/7134 completed (loss: 0.34095925092697144, acc: 0.893750011920929)
[2024-12-17 02:54:48,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:48,969][root][INFO] - Training Epoch: 2/2, step 2360/7134 completed (loss: 0.19532142579555511, acc: 0.949367105960846)
[2024-12-17 02:54:49,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,347][root][INFO] - Training Epoch: 2/2, step 2361/7134 completed (loss: 0.1924678087234497, acc: 0.9523809552192688)
[2024-12-17 02:54:49,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:49,706][root][INFO] - Training Epoch: 2/2, step 2362/7134 completed (loss: 0.3320081830024719, acc: 0.9189189076423645)
[2024-12-17 02:54:49,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,096][root][INFO] - Training Epoch: 2/2, step 2363/7134 completed (loss: 0.2325371503829956, acc: 0.9581151604652405)
[2024-12-17 02:54:50,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,484][root][INFO] - Training Epoch: 2/2, step 2364/7134 completed (loss: 0.1396939605474472, acc: 0.9477124214172363)
[2024-12-17 02:54:50,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:50,892][root][INFO] - Training Epoch: 2/2, step 2365/7134 completed (loss: 0.17271851003170013, acc: 0.9534883499145508)
[2024-12-17 02:54:50,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,266][root][INFO] - Training Epoch: 2/2, step 2366/7134 completed (loss: 0.12362378090620041, acc: 0.9743589758872986)
[2024-12-17 02:54:51,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:51,650][root][INFO] - Training Epoch: 2/2, step 2367/7134 completed (loss: 0.2391476035118103, acc: 0.939393937587738)
[2024-12-17 02:54:51,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,032][root][INFO] - Training Epoch: 2/2, step 2368/7134 completed (loss: 0.2932567000389099, acc: 0.9547738432884216)
[2024-12-17 02:54:52,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,405][root][INFO] - Training Epoch: 2/2, step 2369/7134 completed (loss: 0.18693627417087555, acc: 0.9575471878051758)
[2024-12-17 02:54:52,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:52,753][root][INFO] - Training Epoch: 2/2, step 2370/7134 completed (loss: 0.18189992010593414, acc: 0.9599999785423279)
[2024-12-17 02:54:52,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,127][root][INFO] - Training Epoch: 2/2, step 2371/7134 completed (loss: 0.24691931903362274, acc: 0.9378882050514221)
[2024-12-17 02:54:53,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,528][root][INFO] - Training Epoch: 2/2, step 2372/7134 completed (loss: 0.1232970803976059, acc: 0.9649999737739563)
[2024-12-17 02:54:53,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:53,868][root][INFO] - Training Epoch: 2/2, step 2373/7134 completed (loss: 0.12202365696430206, acc: 0.9740932583808899)
[2024-12-17 02:54:53,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,204][root][INFO] - Training Epoch: 2/2, step 2374/7134 completed (loss: 0.16275309026241302, acc: 0.9613259434700012)
[2024-12-17 02:54:54,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,587][root][INFO] - Training Epoch: 2/2, step 2375/7134 completed (loss: 0.22755783796310425, acc: 0.9515151381492615)
[2024-12-17 02:54:54,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:54,980][root][INFO] - Training Epoch: 2/2, step 2376/7134 completed (loss: 0.3262507915496826, acc: 0.9084967374801636)
[2024-12-17 02:54:55,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,355][root][INFO] - Training Epoch: 2/2, step 2377/7134 completed (loss: 0.2815796136856079, acc: 0.9392523169517517)
[2024-12-17 02:54:55,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:55,720][root][INFO] - Training Epoch: 2/2, step 2378/7134 completed (loss: 0.3858538269996643, acc: 0.9158415794372559)
[2024-12-17 02:54:55,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,098][root][INFO] - Training Epoch: 2/2, step 2379/7134 completed (loss: 0.5064078569412231, acc: 0.8520408272743225)
[2024-12-17 02:54:56,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,542][root][INFO] - Training Epoch: 2/2, step 2380/7134 completed (loss: 0.31909939646720886, acc: 0.91847825050354)
[2024-12-17 02:54:56,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:56,912][root][INFO] - Training Epoch: 2/2, step 2381/7134 completed (loss: 0.7076218724250793, acc: 0.8198757767677307)
[2024-12-17 02:54:57,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,290][root][INFO] - Training Epoch: 2/2, step 2382/7134 completed (loss: 0.25934258103370667, acc: 0.9444444179534912)
[2024-12-17 02:54:57,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:57,688][root][INFO] - Training Epoch: 2/2, step 2383/7134 completed (loss: 0.34774667024612427, acc: 0.9016393423080444)
[2024-12-17 02:54:57,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,052][root][INFO] - Training Epoch: 2/2, step 2384/7134 completed (loss: 0.32582369446754456, acc: 0.931034505367279)
[2024-12-17 02:54:58,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,407][root][INFO] - Training Epoch: 2/2, step 2385/7134 completed (loss: 0.1990673989057541, acc: 0.9615384340286255)
[2024-12-17 02:54:58,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:58,792][root][INFO] - Training Epoch: 2/2, step 2386/7134 completed (loss: 0.2931586802005768, acc: 0.9259259104728699)
[2024-12-17 02:54:58,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,196][root][INFO] - Training Epoch: 2/2, step 2387/7134 completed (loss: 0.32515233755111694, acc: 0.9333333373069763)
[2024-12-17 02:54:59,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:54:59,583][root][INFO] - Training Epoch: 2/2, step 2388/7134 completed (loss: 0.31076255440711975, acc: 0.942307710647583)
[2024-12-17 02:54:59,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,029][root][INFO] - Training Epoch: 2/2, step 2389/7134 completed (loss: 0.3295474946498871, acc: 0.9194312691688538)
[2024-12-17 02:55:00,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,407][root][INFO] - Training Epoch: 2/2, step 2390/7134 completed (loss: 0.3481716811656952, acc: 0.9146919250488281)
[2024-12-17 02:55:00,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:00,771][root][INFO] - Training Epoch: 2/2, step 2391/7134 completed (loss: 0.2844242453575134, acc: 0.9405405521392822)
[2024-12-17 02:55:00,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,160][root][INFO] - Training Epoch: 2/2, step 2392/7134 completed (loss: 0.28042563796043396, acc: 0.9289617538452148)
[2024-12-17 02:55:01,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,525][root][INFO] - Training Epoch: 2/2, step 2393/7134 completed (loss: 0.30895575881004333, acc: 0.9170984625816345)
[2024-12-17 02:55:01,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:01,921][root][INFO] - Training Epoch: 2/2, step 2394/7134 completed (loss: 0.2543046176433563, acc: 0.9336734414100647)
[2024-12-17 02:55:02,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,302][root][INFO] - Training Epoch: 2/2, step 2395/7134 completed (loss: 0.6286190152168274, acc: 0.8571428656578064)
[2024-12-17 02:55:02,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:02,702][root][INFO] - Training Epoch: 2/2, step 2396/7134 completed (loss: 0.6200516223907471, acc: 0.8333333134651184)
[2024-12-17 02:55:02,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,029][root][INFO] - Training Epoch: 2/2, step 2397/7134 completed (loss: 0.4974519610404968, acc: 0.8536585569381714)
[2024-12-17 02:55:03,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,385][root][INFO] - Training Epoch: 2/2, step 2398/7134 completed (loss: 0.20963485538959503, acc: 0.9351351261138916)
[2024-12-17 02:55:03,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:03,748][root][INFO] - Training Epoch: 2/2, step 2399/7134 completed (loss: 0.5953251123428345, acc: 0.8601036071777344)
[2024-12-17 02:55:03,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,174][root][INFO] - Training Epoch: 2/2, step 2400/7134 completed (loss: 0.5348049998283386, acc: 0.8844221234321594)
[2024-12-17 02:55:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,555][root][INFO] - Training Epoch: 2/2, step 2401/7134 completed (loss: 0.9737122654914856, acc: 0.75)
[2024-12-17 02:55:04,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:04,945][root][INFO] - Training Epoch: 2/2, step 2402/7134 completed (loss: 0.4902718961238861, acc: 0.8743961453437805)
[2024-12-17 02:55:05,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,316][root][INFO] - Training Epoch: 2/2, step 2403/7134 completed (loss: 0.3099914491176605, acc: 0.9281437397003174)
[2024-12-17 02:55:05,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,640][root][INFO] - Training Epoch: 2/2, step 2404/7134 completed (loss: 0.2205580174922943, acc: 0.9407894611358643)
[2024-12-17 02:55:05,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:05,962][root][INFO] - Training Epoch: 2/2, step 2405/7134 completed (loss: 0.3559182584285736, acc: 0.9299362897872925)
[2024-12-17 02:55:06,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,340][root][INFO] - Training Epoch: 2/2, step 2406/7134 completed (loss: 0.1226905956864357, acc: 0.9644970297813416)
[2024-12-17 02:55:06,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:06,704][root][INFO] - Training Epoch: 2/2, step 2407/7134 completed (loss: 0.2635605037212372, acc: 0.9477124214172363)
[2024-12-17 02:55:06,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,074][root][INFO] - Training Epoch: 2/2, step 2408/7134 completed (loss: 0.2726587653160095, acc: 0.9281768202781677)
[2024-12-17 02:55:07,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,430][root][INFO] - Training Epoch: 2/2, step 2409/7134 completed (loss: 0.24296128749847412, acc: 0.9437500238418579)
[2024-12-17 02:55:07,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:07,786][root][INFO] - Training Epoch: 2/2, step 2410/7134 completed (loss: 0.1403043419122696, acc: 0.9577465057373047)
[2024-12-17 02:55:07,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,137][root][INFO] - Training Epoch: 2/2, step 2411/7134 completed (loss: 0.10672242939472198, acc: 0.9723756909370422)
[2024-12-17 02:55:08,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,508][root][INFO] - Training Epoch: 2/2, step 2412/7134 completed (loss: 0.0890781581401825, acc: 0.9602272510528564)
[2024-12-17 02:55:08,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:08,872][root][INFO] - Training Epoch: 2/2, step 2413/7134 completed (loss: 0.14473141729831696, acc: 0.9545454382896423)
[2024-12-17 02:55:09,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,245][root][INFO] - Training Epoch: 2/2, step 2414/7134 completed (loss: 0.21062903106212616, acc: 0.9398906826972961)
[2024-12-17 02:55:09,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:09,637][root][INFO] - Training Epoch: 2/2, step 2415/7134 completed (loss: 0.5293439030647278, acc: 0.8963414430618286)
[2024-12-17 02:55:09,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,066][root][INFO] - Training Epoch: 2/2, step 2416/7134 completed (loss: 0.15782971680164337, acc: 0.9748427867889404)
[2024-12-17 02:55:10,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,462][root][INFO] - Training Epoch: 2/2, step 2417/7134 completed (loss: 0.2364046424627304, acc: 0.9463414549827576)
[2024-12-17 02:55:10,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:10,836][root][INFO] - Training Epoch: 2/2, step 2418/7134 completed (loss: 0.26484987139701843, acc: 0.9440559148788452)
[2024-12-17 02:55:10,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,179][root][INFO] - Training Epoch: 2/2, step 2419/7134 completed (loss: 0.2006777971982956, acc: 0.9631901979446411)
[2024-12-17 02:55:11,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,541][root][INFO] - Training Epoch: 2/2, step 2420/7134 completed (loss: 0.2175140231847763, acc: 0.9513888955116272)
[2024-12-17 02:55:11,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:11,928][root][INFO] - Training Epoch: 2/2, step 2421/7134 completed (loss: 0.17483922839164734, acc: 0.9567567706108093)
[2024-12-17 02:55:12,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,314][root][INFO] - Training Epoch: 2/2, step 2422/7134 completed (loss: 0.22269603610038757, acc: 0.9371428489685059)
[2024-12-17 02:55:12,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:12,686][root][INFO] - Training Epoch: 2/2, step 2423/7134 completed (loss: 0.17299261689186096, acc: 0.9464285969734192)
[2024-12-17 02:55:12,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,066][root][INFO] - Training Epoch: 2/2, step 2424/7134 completed (loss: 0.23114557564258575, acc: 0.9488636255264282)
[2024-12-17 02:55:13,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,427][root][INFO] - Training Epoch: 2/2, step 2425/7134 completed (loss: 0.2213536649942398, acc: 0.9438202381134033)
[2024-12-17 02:55:13,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:13,822][root][INFO] - Training Epoch: 2/2, step 2426/7134 completed (loss: 0.1537349671125412, acc: 0.959770143032074)
[2024-12-17 02:55:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,188][root][INFO] - Training Epoch: 2/2, step 2427/7134 completed (loss: 0.12226345390081406, acc: 0.96875)
[2024-12-17 02:55:14,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,565][root][INFO] - Training Epoch: 2/2, step 2428/7134 completed (loss: 0.14196215569972992, acc: 0.9578947424888611)
[2024-12-17 02:55:14,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:14,923][root][INFO] - Training Epoch: 2/2, step 2429/7134 completed (loss: 0.23127473890781403, acc: 0.9303797483444214)
[2024-12-17 02:55:15,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,326][root][INFO] - Training Epoch: 2/2, step 2430/7134 completed (loss: 0.14392228424549103, acc: 0.95333331823349)
[2024-12-17 02:55:15,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:15,726][root][INFO] - Training Epoch: 2/2, step 2431/7134 completed (loss: 0.1996433138847351, acc: 0.9510489702224731)
[2024-12-17 02:55:15,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,113][root][INFO] - Training Epoch: 2/2, step 2432/7134 completed (loss: 0.37745046615600586, acc: 0.8925619721412659)
[2024-12-17 02:55:16,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,512][root][INFO] - Training Epoch: 2/2, step 2433/7134 completed (loss: 0.31302133202552795, acc: 0.9208633303642273)
[2024-12-17 02:55:16,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:16,881][root][INFO] - Training Epoch: 2/2, step 2434/7134 completed (loss: 0.36346542835235596, acc: 0.9194630980491638)
[2024-12-17 02:55:17,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,244][root][INFO] - Training Epoch: 2/2, step 2435/7134 completed (loss: 0.33197593688964844, acc: 0.9271523356437683)
[2024-12-17 02:55:17,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,618][root][INFO] - Training Epoch: 2/2, step 2436/7134 completed (loss: 0.18392683565616608, acc: 0.9492385983467102)
[2024-12-17 02:55:17,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:17,997][root][INFO] - Training Epoch: 2/2, step 2437/7134 completed (loss: 0.19274011254310608, acc: 0.9647887349128723)
[2024-12-17 02:55:18,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,368][root][INFO] - Training Epoch: 2/2, step 2438/7134 completed (loss: 0.23259149491786957, acc: 0.9506173133850098)
[2024-12-17 02:55:18,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:18,748][root][INFO] - Training Epoch: 2/2, step 2439/7134 completed (loss: 0.20443782210350037, acc: 0.9465240836143494)
[2024-12-17 02:55:18,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,133][root][INFO] - Training Epoch: 2/2, step 2440/7134 completed (loss: 0.16288624703884125, acc: 0.9772727489471436)
[2024-12-17 02:55:19,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,520][root][INFO] - Training Epoch: 2/2, step 2441/7134 completed (loss: 0.6166508197784424, acc: 0.8640000224113464)
[2024-12-17 02:55:19,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:19,902][root][INFO] - Training Epoch: 2/2, step 2442/7134 completed (loss: 0.3305220603942871, acc: 0.9349112510681152)
[2024-12-17 02:55:20,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,263][root][INFO] - Training Epoch: 2/2, step 2443/7134 completed (loss: 0.3385978043079376, acc: 0.9202454090118408)
[2024-12-17 02:55:20,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,624][root][INFO] - Training Epoch: 2/2, step 2444/7134 completed (loss: 0.23721833527088165, acc: 0.9534883499145508)
[2024-12-17 02:55:20,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:20,992][root][INFO] - Training Epoch: 2/2, step 2445/7134 completed (loss: 0.28961023688316345, acc: 0.9235668778419495)
[2024-12-17 02:55:21,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,380][root][INFO] - Training Epoch: 2/2, step 2446/7134 completed (loss: 0.42573773860931396, acc: 0.8571428656578064)
[2024-12-17 02:55:21,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:21,766][root][INFO] - Training Epoch: 2/2, step 2447/7134 completed (loss: 0.1564880609512329, acc: 0.966292142868042)
[2024-12-17 02:55:21,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,127][root][INFO] - Training Epoch: 2/2, step 2448/7134 completed (loss: 0.233058363199234, acc: 0.9194630980491638)
[2024-12-17 02:55:22,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,471][root][INFO] - Training Epoch: 2/2, step 2449/7134 completed (loss: 0.3858071565628052, acc: 0.8895348906517029)
[2024-12-17 02:55:22,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:22,825][root][INFO] - Training Epoch: 2/2, step 2450/7134 completed (loss: 0.2193160355091095, acc: 0.9470587968826294)
[2024-12-17 02:55:22,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,179][root][INFO] - Training Epoch: 2/2, step 2451/7134 completed (loss: 0.17901211977005005, acc: 0.9572192430496216)
[2024-12-17 02:55:23,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,555][root][INFO] - Training Epoch: 2/2, step 2452/7134 completed (loss: 0.20122195780277252, acc: 0.9516128897666931)
[2024-12-17 02:55:23,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:23,921][root][INFO] - Training Epoch: 2/2, step 2453/7134 completed (loss: 0.30072736740112305, acc: 0.9222797751426697)
[2024-12-17 02:55:24,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,266][root][INFO] - Training Epoch: 2/2, step 2454/7134 completed (loss: 0.2056477963924408, acc: 0.9290780425071716)
[2024-12-17 02:55:24,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:24,658][root][INFO] - Training Epoch: 2/2, step 2455/7134 completed (loss: 0.11045591533184052, acc: 0.9754601120948792)
[2024-12-17 02:55:24,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,034][root][INFO] - Training Epoch: 2/2, step 2456/7134 completed (loss: 0.19229763746261597, acc: 0.9378238320350647)
[2024-12-17 02:55:25,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,442][root][INFO] - Training Epoch: 2/2, step 2457/7134 completed (loss: 0.25940895080566406, acc: 0.9215686321258545)
[2024-12-17 02:55:25,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:25,806][root][INFO] - Training Epoch: 2/2, step 2458/7134 completed (loss: 0.41955336928367615, acc: 0.925000011920929)
[2024-12-17 02:55:25,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,187][root][INFO] - Training Epoch: 2/2, step 2459/7134 completed (loss: 0.1415107399225235, acc: 0.9590643048286438)
[2024-12-17 02:55:26,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,574][root][INFO] - Training Epoch: 2/2, step 2460/7134 completed (loss: 0.1677873432636261, acc: 0.9670329689979553)
[2024-12-17 02:55:26,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:26,946][root][INFO] - Training Epoch: 2/2, step 2461/7134 completed (loss: 0.09444516152143478, acc: 0.9748427867889404)
[2024-12-17 02:55:27,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,331][root][INFO] - Training Epoch: 2/2, step 2462/7134 completed (loss: 0.3169276714324951, acc: 0.9333333373069763)
[2024-12-17 02:55:27,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:27,703][root][INFO] - Training Epoch: 2/2, step 2463/7134 completed (loss: 0.05503576993942261, acc: 0.987500011920929)
[2024-12-17 02:55:27,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,048][root][INFO] - Training Epoch: 2/2, step 2464/7134 completed (loss: 0.24601593613624573, acc: 0.949999988079071)
[2024-12-17 02:55:28,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,433][root][INFO] - Training Epoch: 2/2, step 2465/7134 completed (loss: 0.16224133968353271, acc: 0.9608938694000244)
[2024-12-17 02:55:28,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:28,837][root][INFO] - Training Epoch: 2/2, step 2466/7134 completed (loss: 0.10052349418401718, acc: 0.9640718698501587)
[2024-12-17 02:55:28,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,241][root][INFO] - Training Epoch: 2/2, step 2467/7134 completed (loss: 0.2704441249370575, acc: 0.9438202381134033)
[2024-12-17 02:55:29,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:29,641][root][INFO] - Training Epoch: 2/2, step 2468/7134 completed (loss: 0.20975154638290405, acc: 0.9418604373931885)
[2024-12-17 02:55:29,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,049][root][INFO] - Training Epoch: 2/2, step 2469/7134 completed (loss: 0.05753854289650917, acc: 0.9767441749572754)
[2024-12-17 02:55:30,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,416][root][INFO] - Training Epoch: 2/2, step 2470/7134 completed (loss: 0.25695890188217163, acc: 0.936170220375061)
[2024-12-17 02:55:30,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:30,770][root][INFO] - Training Epoch: 2/2, step 2471/7134 completed (loss: 0.22335298359394073, acc: 0.9432623982429504)
[2024-12-17 02:55:30,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,132][root][INFO] - Training Epoch: 2/2, step 2472/7134 completed (loss: 0.09188628941774368, acc: 0.9527027010917664)
[2024-12-17 02:55:31,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,477][root][INFO] - Training Epoch: 2/2, step 2473/7134 completed (loss: 0.0954086184501648, acc: 0.9719626307487488)
[2024-12-17 02:55:31,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:31,868][root][INFO] - Training Epoch: 2/2, step 2474/7134 completed (loss: 0.0694488137960434, acc: 0.9757575988769531)
[2024-12-17 02:55:31,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,223][root][INFO] - Training Epoch: 2/2, step 2475/7134 completed (loss: 0.10686830431222916, acc: 0.9754098653793335)
[2024-12-17 02:55:32,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,612][root][INFO] - Training Epoch: 2/2, step 2476/7134 completed (loss: 0.08397270739078522, acc: 0.9707602262496948)
[2024-12-17 02:55:32,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:32,946][root][INFO] - Training Epoch: 2/2, step 2477/7134 completed (loss: 0.10589991509914398, acc: 0.9814814925193787)
[2024-12-17 02:55:33,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,298][root][INFO] - Training Epoch: 2/2, step 2478/7134 completed (loss: 0.10137665271759033, acc: 0.9664429426193237)
[2024-12-17 02:55:33,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:33,687][root][INFO] - Training Epoch: 2/2, step 2479/7134 completed (loss: 0.39367610216140747, acc: 0.8775510191917419)
[2024-12-17 02:55:33,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,115][root][INFO] - Training Epoch: 2/2, step 2480/7134 completed (loss: 0.11609670519828796, acc: 0.9615384340286255)
[2024-12-17 02:55:34,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,502][root][INFO] - Training Epoch: 2/2, step 2481/7134 completed (loss: 0.1590484082698822, acc: 0.9615384340286255)
[2024-12-17 02:55:34,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:34,889][root][INFO] - Training Epoch: 2/2, step 2482/7134 completed (loss: 0.18200673162937164, acc: 0.948051929473877)
[2024-12-17 02:55:35,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,268][root][INFO] - Training Epoch: 2/2, step 2483/7134 completed (loss: 0.10963358730077744, acc: 0.970059871673584)
[2024-12-17 02:55:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:35,677][root][INFO] - Training Epoch: 2/2, step 2484/7134 completed (loss: 0.1318054348230362, acc: 0.9819276928901672)
[2024-12-17 02:55:35,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,051][root][INFO] - Training Epoch: 2/2, step 2485/7134 completed (loss: 0.1550789624452591, acc: 0.9555555582046509)
[2024-12-17 02:55:36,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,411][root][INFO] - Training Epoch: 2/2, step 2486/7134 completed (loss: 0.11537109315395355, acc: 0.9794520735740662)
[2024-12-17 02:55:36,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:36,824][root][INFO] - Training Epoch: 2/2, step 2487/7134 completed (loss: 0.2969059944152832, acc: 0.9652777910232544)
[2024-12-17 02:55:36,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,167][root][INFO] - Training Epoch: 2/2, step 2488/7134 completed (loss: 0.190679132938385, acc: 0.9696969985961914)
[2024-12-17 02:55:37,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,508][root][INFO] - Training Epoch: 2/2, step 2489/7134 completed (loss: 0.14077065885066986, acc: 0.9526627063751221)
[2024-12-17 02:55:37,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:37,883][root][INFO] - Training Epoch: 2/2, step 2490/7134 completed (loss: 0.1524258702993393, acc: 0.9805194735527039)
[2024-12-17 02:55:37,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,249][root][INFO] - Training Epoch: 2/2, step 2491/7134 completed (loss: 0.2350834459066391, acc: 0.9328358173370361)
[2024-12-17 02:55:38,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,608][root][INFO] - Training Epoch: 2/2, step 2492/7134 completed (loss: 0.1595277041196823, acc: 0.9496855139732361)
[2024-12-17 02:55:38,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:38,983][root][INFO] - Training Epoch: 2/2, step 2493/7134 completed (loss: 0.14594368636608124, acc: 0.9523809552192688)
[2024-12-17 02:55:39,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,304][root][INFO] - Training Epoch: 2/2, step 2494/7134 completed (loss: 0.19154056906700134, acc: 0.9382715821266174)
[2024-12-17 02:55:39,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:39,663][root][INFO] - Training Epoch: 2/2, step 2495/7134 completed (loss: 0.17960846424102783, acc: 0.9588235020637512)
[2024-12-17 02:55:39,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,022][root][INFO] - Training Epoch: 2/2, step 2496/7134 completed (loss: 0.16164788603782654, acc: 0.9430379867553711)
[2024-12-17 02:55:40,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,392][root][INFO] - Training Epoch: 2/2, step 2497/7134 completed (loss: 0.1624337136745453, acc: 0.9655172228813171)
[2024-12-17 02:55:40,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:40,742][root][INFO] - Training Epoch: 2/2, step 2498/7134 completed (loss: 0.12728260457515717, acc: 0.9714285731315613)
[2024-12-17 02:55:40,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,102][root][INFO] - Training Epoch: 2/2, step 2499/7134 completed (loss: 0.11531732231378555, acc: 0.9638554453849792)
[2024-12-17 02:55:41,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,440][root][INFO] - Training Epoch: 2/2, step 2500/7134 completed (loss: 0.13144183158874512, acc: 0.9527027010917664)
[2024-12-17 02:55:41,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:41,805][root][INFO] - Training Epoch: 2/2, step 2501/7134 completed (loss: 0.2835279107093811, acc: 0.9438202381134033)
[2024-12-17 02:55:41,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,174][root][INFO] - Training Epoch: 2/2, step 2502/7134 completed (loss: 0.09652212262153625, acc: 0.9914529919624329)
[2024-12-17 02:55:42,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,534][root][INFO] - Training Epoch: 2/2, step 2503/7134 completed (loss: 0.10890187323093414, acc: 0.9637681245803833)
[2024-12-17 02:55:42,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:42,914][root][INFO] - Training Epoch: 2/2, step 2504/7134 completed (loss: 0.18043094873428345, acc: 0.949367105960846)
[2024-12-17 02:55:43,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,278][root][INFO] - Training Epoch: 2/2, step 2505/7134 completed (loss: 0.14233678579330444, acc: 0.9709302186965942)
[2024-12-17 02:55:43,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:43,679][root][INFO] - Training Epoch: 2/2, step 2506/7134 completed (loss: 0.12382138520479202, acc: 0.9672130942344666)
[2024-12-17 02:55:43,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,051][root][INFO] - Training Epoch: 2/2, step 2507/7134 completed (loss: 0.04893263801932335, acc: 0.9833333492279053)
[2024-12-17 02:55:44,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,429][root][INFO] - Training Epoch: 2/2, step 2508/7134 completed (loss: 0.0772782415151596, acc: 0.9830508232116699)
[2024-12-17 02:55:44,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:44,805][root][INFO] - Training Epoch: 2/2, step 2509/7134 completed (loss: 0.09147392213344574, acc: 0.9764705896377563)
[2024-12-17 02:55:44,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,174][root][INFO] - Training Epoch: 2/2, step 2510/7134 completed (loss: 0.03775598108768463, acc: 0.9928571581840515)
[2024-12-17 02:55:45,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,598][root][INFO] - Training Epoch: 2/2, step 2511/7134 completed (loss: 0.2522396743297577, acc: 0.9617486596107483)
[2024-12-17 02:55:45,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:45,960][root][INFO] - Training Epoch: 2/2, step 2512/7134 completed (loss: 0.1889103651046753, acc: 0.9529411792755127)
[2024-12-17 02:55:46,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,347][root][INFO] - Training Epoch: 2/2, step 2513/7134 completed (loss: 0.10698245465755463, acc: 0.9731183052062988)
[2024-12-17 02:55:46,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:46,707][root][INFO] - Training Epoch: 2/2, step 2514/7134 completed (loss: 0.15778426826000214, acc: 0.9490445852279663)
[2024-12-17 02:55:46,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,078][root][INFO] - Training Epoch: 2/2, step 2515/7134 completed (loss: 0.11339591443538666, acc: 0.9805194735527039)
[2024-12-17 02:55:47,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,461][root][INFO] - Training Epoch: 2/2, step 2516/7134 completed (loss: 0.13147255778312683, acc: 0.9888268113136292)
[2024-12-17 02:55:47,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:47,833][root][INFO] - Training Epoch: 2/2, step 2517/7134 completed (loss: 0.15366780757904053, acc: 0.9666666388511658)
[2024-12-17 02:55:47,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,254][root][INFO] - Training Epoch: 2/2, step 2518/7134 completed (loss: 0.1276482790708542, acc: 0.9738562107086182)
[2024-12-17 02:55:48,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,628][root][INFO] - Training Epoch: 2/2, step 2519/7134 completed (loss: 0.0836988314986229, acc: 0.9741935729980469)
[2024-12-17 02:55:48,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:48,998][root][INFO] - Training Epoch: 2/2, step 2520/7134 completed (loss: 0.14360034465789795, acc: 0.9473684430122375)
[2024-12-17 02:55:49,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,389][root][INFO] - Training Epoch: 2/2, step 2521/7134 completed (loss: 0.2090613842010498, acc: 0.9615384340286255)
[2024-12-17 02:55:49,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:49,743][root][INFO] - Training Epoch: 2/2, step 2522/7134 completed (loss: 0.10661648958921432, acc: 0.9724137783050537)
[2024-12-17 02:55:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,086][root][INFO] - Training Epoch: 2/2, step 2523/7134 completed (loss: 0.15580014884471893, acc: 0.9693251252174377)
[2024-12-17 02:55:50,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,458][root][INFO] - Training Epoch: 2/2, step 2524/7134 completed (loss: 0.07047252357006073, acc: 0.9817073345184326)
[2024-12-17 02:55:50,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:50,829][root][INFO] - Training Epoch: 2/2, step 2525/7134 completed (loss: 0.13577169179916382, acc: 0.9589040875434875)
[2024-12-17 02:55:50,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,202][root][INFO] - Training Epoch: 2/2, step 2526/7134 completed (loss: 0.10591001063585281, acc: 0.9696969985961914)
[2024-12-17 02:55:51,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,593][root][INFO] - Training Epoch: 2/2, step 2527/7134 completed (loss: 0.09326702356338501, acc: 0.9726775884628296)
[2024-12-17 02:55:51,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:51,979][root][INFO] - Training Epoch: 2/2, step 2528/7134 completed (loss: 0.09561801701784134, acc: 0.9698795080184937)
[2024-12-17 02:55:52,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,371][root][INFO] - Training Epoch: 2/2, step 2529/7134 completed (loss: 0.09081590920686722, acc: 0.9821428656578064)
[2024-12-17 02:55:52,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:52,761][root][INFO] - Training Epoch: 2/2, step 2530/7134 completed (loss: 0.0925225168466568, acc: 0.9775280952453613)
[2024-12-17 02:55:52,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,130][root][INFO] - Training Epoch: 2/2, step 2531/7134 completed (loss: 0.05373530089855194, acc: 0.9759036302566528)
[2024-12-17 02:55:53,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,588][root][INFO] - Training Epoch: 2/2, step 2532/7134 completed (loss: 0.06612526625394821, acc: 0.9866666793823242)
[2024-12-17 02:55:53,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:53,964][root][INFO] - Training Epoch: 2/2, step 2533/7134 completed (loss: 0.15818525850772858, acc: 0.9551281929016113)
[2024-12-17 02:55:54,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,330][root][INFO] - Training Epoch: 2/2, step 2534/7134 completed (loss: 0.11319137364625931, acc: 0.9720670580863953)
[2024-12-17 02:55:54,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:54,711][root][INFO] - Training Epoch: 2/2, step 2535/7134 completed (loss: 0.08935143053531647, acc: 0.9745762944221497)
[2024-12-17 02:55:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,078][root][INFO] - Training Epoch: 2/2, step 2536/7134 completed (loss: 0.18034012615680695, acc: 0.9274611473083496)
[2024-12-17 02:55:55,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,441][root][INFO] - Training Epoch: 2/2, step 2537/7134 completed (loss: 0.20519380271434784, acc: 0.9520547986030579)
[2024-12-17 02:55:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:55,798][root][INFO] - Training Epoch: 2/2, step 2538/7134 completed (loss: 0.182167649269104, acc: 0.954023003578186)
[2024-12-17 02:55:55,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,170][root][INFO] - Training Epoch: 2/2, step 2539/7134 completed (loss: 0.14594526588916779, acc: 0.9849624037742615)
[2024-12-17 02:55:56,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,539][root][INFO] - Training Epoch: 2/2, step 2540/7134 completed (loss: 0.15420082211494446, acc: 0.9668874144554138)
[2024-12-17 02:55:56,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:56,906][root][INFO] - Training Epoch: 2/2, step 2541/7134 completed (loss: 0.07967598736286163, acc: 0.9926470518112183)
[2024-12-17 02:55:57,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,284][root][INFO] - Training Epoch: 2/2, step 2542/7134 completed (loss: 0.15761694312095642, acc: 0.956250011920929)
[2024-12-17 02:55:57,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:57,657][root][INFO] - Training Epoch: 2/2, step 2543/7134 completed (loss: 0.2252272069454193, acc: 0.9496855139732361)
[2024-12-17 02:55:57,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,046][root][INFO] - Training Epoch: 2/2, step 2544/7134 completed (loss: 0.14645712077617645, acc: 0.9642857313156128)
[2024-12-17 02:55:58,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,425][root][INFO] - Training Epoch: 2/2, step 2545/7134 completed (loss: 0.13717712461948395, acc: 0.9552238583564758)
[2024-12-17 02:55:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:58,813][root][INFO] - Training Epoch: 2/2, step 2546/7134 completed (loss: 0.37113431096076965, acc: 0.8979591727256775)
[2024-12-17 02:55:58,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,221][root][INFO] - Training Epoch: 2/2, step 2547/7134 completed (loss: 0.19526724517345428, acc: 0.935251772403717)
[2024-12-17 02:55:59,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:55:59,636][root][INFO] - Training Epoch: 2/2, step 2548/7134 completed (loss: 0.09473662078380585, acc: 0.9734513163566589)
[2024-12-17 02:55:59,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,031][root][INFO] - Training Epoch: 2/2, step 2549/7134 completed (loss: 0.2786574363708496, acc: 0.9105691313743591)
[2024-12-17 02:56:00,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,405][root][INFO] - Training Epoch: 2/2, step 2550/7134 completed (loss: 0.0731075257062912, acc: 0.9726027250289917)
[2024-12-17 02:56:00,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:00,780][root][INFO] - Training Epoch: 2/2, step 2551/7134 completed (loss: 0.2220548540353775, acc: 0.9420289993286133)
[2024-12-17 02:56:00,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,217][root][INFO] - Training Epoch: 2/2, step 2552/7134 completed (loss: 0.0635984018445015, acc: 0.9873417615890503)
[2024-12-17 02:56:01,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,562][root][INFO] - Training Epoch: 2/2, step 2553/7134 completed (loss: 0.3137071132659912, acc: 0.9473684430122375)
[2024-12-17 02:56:01,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:01,937][root][INFO] - Training Epoch: 2/2, step 2554/7134 completed (loss: 0.24783776700496674, acc: 0.9527559280395508)
[2024-12-17 02:56:02,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,307][root][INFO] - Training Epoch: 2/2, step 2555/7134 completed (loss: 0.18284785747528076, acc: 0.9369369149208069)
[2024-12-17 02:56:02,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:02,662][root][INFO] - Training Epoch: 2/2, step 2556/7134 completed (loss: 0.14927572011947632, acc: 0.9700000286102295)
[2024-12-17 02:56:02,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,060][root][INFO] - Training Epoch: 2/2, step 2557/7134 completed (loss: 0.1779194325208664, acc: 0.9387755393981934)
[2024-12-17 02:56:03,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,453][root][INFO] - Training Epoch: 2/2, step 2558/7134 completed (loss: 0.07259311527013779, acc: 0.9781022071838379)
[2024-12-17 02:56:03,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:03,858][root][INFO] - Training Epoch: 2/2, step 2559/7134 completed (loss: 0.1110558956861496, acc: 0.9750000238418579)
[2024-12-17 02:56:03,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,249][root][INFO] - Training Epoch: 2/2, step 2560/7134 completed (loss: 0.09574127942323685, acc: 0.9797297120094299)
[2024-12-17 02:56:04,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,597][root][INFO] - Training Epoch: 2/2, step 2561/7134 completed (loss: 0.14626584947109222, acc: 0.9583333134651184)
[2024-12-17 02:56:04,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:04,946][root][INFO] - Training Epoch: 2/2, step 2562/7134 completed (loss: 0.07418385148048401, acc: 0.9679999947547913)
[2024-12-17 02:56:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,316][root][INFO] - Training Epoch: 2/2, step 2563/7134 completed (loss: 0.115718774497509, acc: 0.9585798978805542)
[2024-12-17 02:56:05,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:05,674][root][INFO] - Training Epoch: 2/2, step 2564/7134 completed (loss: 0.40661269426345825, acc: 0.8992805480957031)
[2024-12-17 02:56:05,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,036][root][INFO] - Training Epoch: 2/2, step 2565/7134 completed (loss: 0.08334821462631226, acc: 0.9856114983558655)
[2024-12-17 02:56:06,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,399][root][INFO] - Training Epoch: 2/2, step 2566/7134 completed (loss: 0.12527237832546234, acc: 0.9759036302566528)
[2024-12-17 02:56:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:06,783][root][INFO] - Training Epoch: 2/2, step 2567/7134 completed (loss: 0.0983595997095108, acc: 0.9774436354637146)
[2024-12-17 02:56:06,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,215][root][INFO] - Training Epoch: 2/2, step 2568/7134 completed (loss: 0.1930256187915802, acc: 0.942307710647583)
[2024-12-17 02:56:07,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,581][root][INFO] - Training Epoch: 2/2, step 2569/7134 completed (loss: 0.07075443863868713, acc: 0.9788732528686523)
[2024-12-17 02:56:07,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:07,964][root][INFO] - Training Epoch: 2/2, step 2570/7134 completed (loss: 0.07764538377523422, acc: 0.9801324605941772)
[2024-12-17 02:56:08,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,338][root][INFO] - Training Epoch: 2/2, step 2571/7134 completed (loss: 0.08111856877803802, acc: 0.9754098653793335)
[2024-12-17 02:56:08,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:08,722][root][INFO] - Training Epoch: 2/2, step 2572/7134 completed (loss: 0.11471535265445709, acc: 0.9727891087532043)
[2024-12-17 02:56:08,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,096][root][INFO] - Training Epoch: 2/2, step 2573/7134 completed (loss: 0.15434813499450684, acc: 0.971222996711731)
[2024-12-17 02:56:09,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,474][root][INFO] - Training Epoch: 2/2, step 2574/7134 completed (loss: 0.11641005426645279, acc: 0.9696969985961914)
[2024-12-17 02:56:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:09,829][root][INFO] - Training Epoch: 2/2, step 2575/7134 completed (loss: 0.14213818311691284, acc: 0.9754098653793335)
[2024-12-17 02:56:09,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,213][root][INFO] - Training Epoch: 2/2, step 2576/7134 completed (loss: 0.08227366209030151, acc: 0.9918699264526367)
[2024-12-17 02:56:10,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,588][root][INFO] - Training Epoch: 2/2, step 2577/7134 completed (loss: 0.32779285311698914, acc: 0.9527559280395508)
[2024-12-17 02:56:10,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:10,975][root][INFO] - Training Epoch: 2/2, step 2578/7134 completed (loss: 0.40046226978302, acc: 0.9281045794487)
[2024-12-17 02:56:11,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,333][root][INFO] - Training Epoch: 2/2, step 2579/7134 completed (loss: 0.33640456199645996, acc: 0.8974359035491943)
[2024-12-17 02:56:11,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:11,681][root][INFO] - Training Epoch: 2/2, step 2580/7134 completed (loss: 0.2727040946483612, acc: 0.9421965479850769)
[2024-12-17 02:56:11,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,094][root][INFO] - Training Epoch: 2/2, step 2581/7134 completed (loss: 0.2576502561569214, acc: 0.9378530979156494)
[2024-12-17 02:56:12,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,473][root][INFO] - Training Epoch: 2/2, step 2582/7134 completed (loss: 0.27683013677597046, acc: 0.9209039807319641)
[2024-12-17 02:56:12,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:12,834][root][INFO] - Training Epoch: 2/2, step 2583/7134 completed (loss: 0.3521149456501007, acc: 0.9137930870056152)
[2024-12-17 02:56:12,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,239][root][INFO] - Training Epoch: 2/2, step 2584/7134 completed (loss: 0.36039838194847107, acc: 0.9078013896942139)
[2024-12-17 02:56:13,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,609][root][INFO] - Training Epoch: 2/2, step 2585/7134 completed (loss: 0.3026415705680847, acc: 0.940397322177887)
[2024-12-17 02:56:13,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:13,981][root][INFO] - Training Epoch: 2/2, step 2586/7134 completed (loss: 0.2855682075023651, acc: 0.9153845906257629)
[2024-12-17 02:56:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,355][root][INFO] - Training Epoch: 2/2, step 2587/7134 completed (loss: 0.24842369556427002, acc: 0.96875)
[2024-12-17 02:56:14,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:14,732][root][INFO] - Training Epoch: 2/2, step 2588/7134 completed (loss: 0.15413205325603485, acc: 0.9523809552192688)
[2024-12-17 02:56:14,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,110][root][INFO] - Training Epoch: 2/2, step 2589/7134 completed (loss: 0.283080518245697, acc: 0.89682537317276)
[2024-12-17 02:56:15,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,495][root][INFO] - Training Epoch: 2/2, step 2590/7134 completed (loss: 0.2588807940483093, acc: 0.9185185432434082)
[2024-12-17 02:56:15,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:15,894][root][INFO] - Training Epoch: 2/2, step 2591/7134 completed (loss: 0.4590991139411926, acc: 0.8888888955116272)
[2024-12-17 02:56:16,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,294][root][INFO] - Training Epoch: 2/2, step 2592/7134 completed (loss: 0.300134539604187, acc: 0.9217877388000488)
[2024-12-17 02:56:16,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:16,693][root][INFO] - Training Epoch: 2/2, step 2593/7134 completed (loss: 0.1705162525177002, acc: 0.9695122241973877)
[2024-12-17 02:56:16,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,094][root][INFO] - Training Epoch: 2/2, step 2594/7134 completed (loss: 0.34239551424980164, acc: 0.915032684803009)
[2024-12-17 02:56:17,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,479][root][INFO] - Training Epoch: 2/2, step 2595/7134 completed (loss: 0.15189038217067719, acc: 0.9634146094322205)
[2024-12-17 02:56:17,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:17,883][root][INFO] - Training Epoch: 2/2, step 2596/7134 completed (loss: 0.1936272531747818, acc: 0.9352940917015076)
[2024-12-17 02:56:18,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,306][root][INFO] - Training Epoch: 2/2, step 2597/7134 completed (loss: 0.22458480298519135, acc: 0.9491525292396545)
[2024-12-17 02:56:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:18,694][root][INFO] - Training Epoch: 2/2, step 2598/7134 completed (loss: 0.3583545684814453, acc: 0.8940397500991821)
[2024-12-17 02:56:18,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,149][root][INFO] - Training Epoch: 2/2, step 2599/7134 completed (loss: 0.03628231957554817, acc: 0.9937106966972351)
[2024-12-17 02:56:19,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,516][root][INFO] - Training Epoch: 2/2, step 2600/7134 completed (loss: 0.3332020938396454, acc: 0.932584285736084)
[2024-12-17 02:56:19,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:19,916][root][INFO] - Training Epoch: 2/2, step 2601/7134 completed (loss: 0.2799898087978363, acc: 0.9290322661399841)
[2024-12-17 02:56:20,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,326][root][INFO] - Training Epoch: 2/2, step 2602/7134 completed (loss: 0.19738872349262238, acc: 0.9404761791229248)
[2024-12-17 02:56:20,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:20,737][root][INFO] - Training Epoch: 2/2, step 2603/7134 completed (loss: 0.21632996201515198, acc: 0.9411764740943909)
[2024-12-17 02:56:20,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,121][root][INFO] - Training Epoch: 2/2, step 2604/7134 completed (loss: 0.29857489466667175, acc: 0.9153439402580261)
[2024-12-17 02:56:21,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,482][root][INFO] - Training Epoch: 2/2, step 2605/7134 completed (loss: 0.23068323731422424, acc: 0.9292035102844238)
[2024-12-17 02:56:21,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:21,857][root][INFO] - Training Epoch: 2/2, step 2606/7134 completed (loss: 0.26193568110466003, acc: 0.9200000166893005)
[2024-12-17 02:56:22,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,265][root][INFO] - Training Epoch: 2/2, step 2607/7134 completed (loss: 0.29809004068374634, acc: 0.949438214302063)
[2024-12-17 02:56:22,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,628][root][INFO] - Training Epoch: 2/2, step 2608/7134 completed (loss: 0.3251723647117615, acc: 0.9153439402580261)
[2024-12-17 02:56:22,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:22,997][root][INFO] - Training Epoch: 2/2, step 2609/7134 completed (loss: 0.3131077289581299, acc: 0.9084967374801636)
[2024-12-17 02:56:23,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,328][root][INFO] - Training Epoch: 2/2, step 2610/7134 completed (loss: 0.28183114528656006, acc: 0.9424460530281067)
[2024-12-17 02:56:23,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:23,696][root][INFO] - Training Epoch: 2/2, step 2611/7134 completed (loss: 0.41099441051483154, acc: 0.9050279259681702)
[2024-12-17 02:56:23,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,108][root][INFO] - Training Epoch: 2/2, step 2612/7134 completed (loss: 0.3949745297431946, acc: 0.8899999856948853)
[2024-12-17 02:56:24,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,515][root][INFO] - Training Epoch: 2/2, step 2613/7134 completed (loss: 0.22092382609844208, acc: 0.9345238208770752)
[2024-12-17 02:56:24,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:24,919][root][INFO] - Training Epoch: 2/2, step 2614/7134 completed (loss: 0.41421306133270264, acc: 0.8936170339584351)
[2024-12-17 02:56:25,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,331][root][INFO] - Training Epoch: 2/2, step 2615/7134 completed (loss: 0.2237197607755661, acc: 0.9438202381134033)
[2024-12-17 02:56:25,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:25,759][root][INFO] - Training Epoch: 2/2, step 2616/7134 completed (loss: 0.352096825838089, acc: 0.9495798349380493)
[2024-12-17 02:56:25,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,175][root][INFO] - Training Epoch: 2/2, step 2617/7134 completed (loss: 0.3835768401622772, acc: 0.8984771370887756)
[2024-12-17 02:56:26,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,563][root][INFO] - Training Epoch: 2/2, step 2618/7134 completed (loss: 0.2120254933834076, acc: 0.9316239356994629)
[2024-12-17 02:56:26,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:26,924][root][INFO] - Training Epoch: 2/2, step 2619/7134 completed (loss: 0.21456098556518555, acc: 0.95652174949646)
[2024-12-17 02:56:27,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,287][root][INFO] - Training Epoch: 2/2, step 2620/7134 completed (loss: 0.26888540387153625, acc: 0.9312169551849365)
[2024-12-17 02:56:27,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:27,703][root][INFO] - Training Epoch: 2/2, step 2621/7134 completed (loss: 0.32002657651901245, acc: 0.9090909361839294)
[2024-12-17 02:56:27,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,097][root][INFO] - Training Epoch: 2/2, step 2622/7134 completed (loss: 0.28698956966400146, acc: 0.9109588861465454)
[2024-12-17 02:56:28,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,477][root][INFO] - Training Epoch: 2/2, step 2623/7134 completed (loss: 0.32743480801582336, acc: 0.89449542760849)
[2024-12-17 02:56:28,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:28,927][root][INFO] - Training Epoch: 2/2, step 2624/7134 completed (loss: 0.3763483762741089, acc: 0.8999999761581421)
[2024-12-17 02:56:29,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,328][root][INFO] - Training Epoch: 2/2, step 2625/7134 completed (loss: 0.3117077648639679, acc: 0.898809552192688)
[2024-12-17 02:56:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:29,731][root][INFO] - Training Epoch: 2/2, step 2626/7134 completed (loss: 0.22854800522327423, acc: 0.9425287246704102)
[2024-12-17 02:56:29,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,116][root][INFO] - Training Epoch: 2/2, step 2627/7134 completed (loss: 0.24609534442424774, acc: 0.9386503100395203)
[2024-12-17 02:56:30,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,476][root][INFO] - Training Epoch: 2/2, step 2628/7134 completed (loss: 0.32085561752319336, acc: 0.9333333373069763)
[2024-12-17 02:56:30,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:30,925][root][INFO] - Training Epoch: 2/2, step 2629/7134 completed (loss: 0.1407967507839203, acc: 0.9520958065986633)
[2024-12-17 02:56:31,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,320][root][INFO] - Training Epoch: 2/2, step 2630/7134 completed (loss: 0.18704518675804138, acc: 0.95652174949646)
[2024-12-17 02:56:31,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:31,736][root][INFO] - Training Epoch: 2/2, step 2631/7134 completed (loss: 0.30610358715057373, acc: 0.9289340376853943)
[2024-12-17 02:56:31,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,151][root][INFO] - Training Epoch: 2/2, step 2632/7134 completed (loss: 0.14384925365447998, acc: 0.9739130139350891)
[2024-12-17 02:56:32,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,553][root][INFO] - Training Epoch: 2/2, step 2633/7134 completed (loss: 0.341678649187088, acc: 0.9340659379959106)
[2024-12-17 02:56:32,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:32,927][root][INFO] - Training Epoch: 2/2, step 2634/7134 completed (loss: 0.0899943932890892, acc: 0.976331353187561)
[2024-12-17 02:56:33,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,323][root][INFO] - Training Epoch: 2/2, step 2635/7134 completed (loss: 0.4857208728790283, acc: 0.894444465637207)
[2024-12-17 02:56:33,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:33,752][root][INFO] - Training Epoch: 2/2, step 2636/7134 completed (loss: 0.43483230471611023, acc: 0.910614550113678)
[2024-12-17 02:56:33,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,122][root][INFO] - Training Epoch: 2/2, step 2637/7134 completed (loss: 0.464988648891449, acc: 0.8895705342292786)
[2024-12-17 02:56:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,532][root][INFO] - Training Epoch: 2/2, step 2638/7134 completed (loss: 0.4612451493740082, acc: 0.9104477763175964)
[2024-12-17 02:56:34,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:34,945][root][INFO] - Training Epoch: 2/2, step 2639/7134 completed (loss: 0.6356604695320129, acc: 0.8345864415168762)
[2024-12-17 02:56:35,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,357][root][INFO] - Training Epoch: 2/2, step 2640/7134 completed (loss: 0.46910080313682556, acc: 0.9054726362228394)
[2024-12-17 02:56:35,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:35,753][root][INFO] - Training Epoch: 2/2, step 2641/7134 completed (loss: 0.40935927629470825, acc: 0.9314285516738892)
[2024-12-17 02:56:35,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,108][root][INFO] - Training Epoch: 2/2, step 2642/7134 completed (loss: 0.7461621165275574, acc: 0.863095223903656)
[2024-12-17 02:56:36,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,517][root][INFO] - Training Epoch: 2/2, step 2643/7134 completed (loss: 0.5165429711341858, acc: 0.8779069781303406)
[2024-12-17 02:56:36,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:36,961][root][INFO] - Training Epoch: 2/2, step 2644/7134 completed (loss: 0.36233943700790405, acc: 0.9259259104728699)
[2024-12-17 02:56:37,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,367][root][INFO] - Training Epoch: 2/2, step 2645/7134 completed (loss: 0.28726422786712646, acc: 0.9428571462631226)
[2024-12-17 02:56:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:37,754][root][INFO] - Training Epoch: 2/2, step 2646/7134 completed (loss: 0.3891848623752594, acc: 0.9192546606063843)
[2024-12-17 02:56:37,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,107][root][INFO] - Training Epoch: 2/2, step 2647/7134 completed (loss: 0.24663834273815155, acc: 0.9239130616188049)
[2024-12-17 02:56:38,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,468][root][INFO] - Training Epoch: 2/2, step 2648/7134 completed (loss: 0.3898707330226898, acc: 0.905940592288971)
[2024-12-17 02:56:38,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:38,858][root][INFO] - Training Epoch: 2/2, step 2649/7134 completed (loss: 0.5810206532478333, acc: 0.8594594597816467)
[2024-12-17 02:56:38,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,241][root][INFO] - Training Epoch: 2/2, step 2650/7134 completed (loss: 0.6539618372917175, acc: 0.8294117450714111)
[2024-12-17 02:56:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:39,600][root][INFO] - Training Epoch: 2/2, step 2651/7134 completed (loss: 0.18179984390735626, acc: 0.9658536314964294)
[2024-12-17 02:56:39,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,008][root][INFO] - Training Epoch: 2/2, step 2652/7134 completed (loss: 0.2570556104183197, acc: 0.9438202381134033)
[2024-12-17 02:56:40,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,411][root][INFO] - Training Epoch: 2/2, step 2653/7134 completed (loss: 0.22999832034111023, acc: 0.9411764740943909)
[2024-12-17 02:56:40,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:40,799][root][INFO] - Training Epoch: 2/2, step 2654/7134 completed (loss: 0.27473482489585876, acc: 0.9214285612106323)
[2024-12-17 02:56:40,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,203][root][INFO] - Training Epoch: 2/2, step 2655/7134 completed (loss: 0.2244989573955536, acc: 0.9440993666648865)
[2024-12-17 02:56:41,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,582][root][INFO] - Training Epoch: 2/2, step 2656/7134 completed (loss: 0.2747791111469269, acc: 0.9534883499145508)
[2024-12-17 02:56:41,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:41,968][root][INFO] - Training Epoch: 2/2, step 2657/7134 completed (loss: 0.22447049617767334, acc: 0.9367088675498962)
[2024-12-17 02:56:42,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,387][root][INFO] - Training Epoch: 2/2, step 2658/7134 completed (loss: 0.3611917495727539, acc: 0.9191918969154358)
[2024-12-17 02:56:42,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:42,800][root][INFO] - Training Epoch: 2/2, step 2659/7134 completed (loss: 0.31260594725608826, acc: 0.9402984976768494)
[2024-12-17 02:56:42,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,227][root][INFO] - Training Epoch: 2/2, step 2660/7134 completed (loss: 0.44730961322784424, acc: 0.8803418874740601)
[2024-12-17 02:56:43,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,593][root][INFO] - Training Epoch: 2/2, step 2661/7134 completed (loss: 0.0935342088341713, acc: 0.976331353187561)
[2024-12-17 02:56:43,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:43,967][root][INFO] - Training Epoch: 2/2, step 2662/7134 completed (loss: 0.27283310890197754, acc: 0.9259259104728699)
[2024-12-17 02:56:44,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,382][root][INFO] - Training Epoch: 2/2, step 2663/7134 completed (loss: 0.26904037594795227, acc: 0.9430052042007446)
[2024-12-17 02:56:44,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:44,793][root][INFO] - Training Epoch: 2/2, step 2664/7134 completed (loss: 0.25723135471343994, acc: 0.9360465407371521)
[2024-12-17 02:56:44,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,215][root][INFO] - Training Epoch: 2/2, step 2665/7134 completed (loss: 0.09796319156885147, acc: 0.9819276928901672)
[2024-12-17 02:56:45,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:45,643][root][INFO] - Training Epoch: 2/2, step 2666/7134 completed (loss: 0.07267799228429794, acc: 0.9825581312179565)
[2024-12-17 02:56:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,012][root][INFO] - Training Epoch: 2/2, step 2667/7134 completed (loss: 0.048496101051568985, acc: 0.9936708807945251)
[2024-12-17 02:56:46,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,374][root][INFO] - Training Epoch: 2/2, step 2668/7134 completed (loss: 0.05035598576068878, acc: 0.9942857027053833)
[2024-12-17 02:56:46,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:46,762][root][INFO] - Training Epoch: 2/2, step 2669/7134 completed (loss: 0.07687186449766159, acc: 0.9800994992256165)
[2024-12-17 02:56:46,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,172][root][INFO] - Training Epoch: 2/2, step 2670/7134 completed (loss: 0.14700180292129517, acc: 0.9485714435577393)
[2024-12-17 02:56:47,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,559][root][INFO] - Training Epoch: 2/2, step 2671/7134 completed (loss: 0.14728577435016632, acc: 0.954285740852356)
[2024-12-17 02:56:47,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:47,937][root][INFO] - Training Epoch: 2/2, step 2672/7134 completed (loss: 0.043772969394922256, acc: 0.9879518151283264)
[2024-12-17 02:56:48,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,303][root][INFO] - Training Epoch: 2/2, step 2673/7134 completed (loss: 0.08601130545139313, acc: 0.988950252532959)
[2024-12-17 02:56:48,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:48,686][root][INFO] - Training Epoch: 2/2, step 2674/7134 completed (loss: 0.11168025434017181, acc: 0.9753086566925049)
[2024-12-17 02:56:48,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,098][root][INFO] - Training Epoch: 2/2, step 2675/7134 completed (loss: 0.03395668789744377, acc: 0.9939393997192383)
[2024-12-17 02:56:49,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,467][root][INFO] - Training Epoch: 2/2, step 2676/7134 completed (loss: 0.08922269940376282, acc: 0.9659090638160706)
[2024-12-17 02:56:49,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:49,839][root][INFO] - Training Epoch: 2/2, step 2677/7134 completed (loss: 0.050994403660297394, acc: 0.987730085849762)
[2024-12-17 02:56:49,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,236][root][INFO] - Training Epoch: 2/2, step 2678/7134 completed (loss: 0.03221001476049423, acc: 0.994350254535675)
[2024-12-17 02:56:50,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,618][root][INFO] - Training Epoch: 2/2, step 2679/7134 completed (loss: 0.06230765953660011, acc: 0.9797979593276978)
[2024-12-17 02:56:50,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:50,996][root][INFO] - Training Epoch: 2/2, step 2680/7134 completed (loss: 0.1717284768819809, acc: 0.9670329689979553)
[2024-12-17 02:56:51,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,374][root][INFO] - Training Epoch: 2/2, step 2681/7134 completed (loss: 0.08790316432714462, acc: 0.9873417615890503)
[2024-12-17 02:56:51,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:51,735][root][INFO] - Training Epoch: 2/2, step 2682/7134 completed (loss: 0.090090811252594, acc: 0.9731543660163879)
[2024-12-17 02:56:51,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,118][root][INFO] - Training Epoch: 2/2, step 2683/7134 completed (loss: 0.062186211347579956, acc: 0.9668874144554138)
[2024-12-17 02:56:52,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,527][root][INFO] - Training Epoch: 2/2, step 2684/7134 completed (loss: 0.2616870105266571, acc: 0.9375)
[2024-12-17 02:56:52,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:52,878][root][INFO] - Training Epoch: 2/2, step 2685/7134 completed (loss: 0.06806916743516922, acc: 0.9881656765937805)
[2024-12-17 02:56:52,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,279][root][INFO] - Training Epoch: 2/2, step 2686/7134 completed (loss: 0.18007872998714447, acc: 0.9549999833106995)
[2024-12-17 02:56:53,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:53,643][root][INFO] - Training Epoch: 2/2, step 2687/7134 completed (loss: 0.2243162840604782, acc: 0.9411764740943909)
[2024-12-17 02:56:53,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,002][root][INFO] - Training Epoch: 2/2, step 2688/7134 completed (loss: 0.3590860664844513, acc: 0.902255654335022)
[2024-12-17 02:56:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,302][root][INFO] - Training Epoch: 2/2, step 2689/7134 completed (loss: 0.24075466394424438, acc: 0.9430894255638123)
[2024-12-17 02:56:54,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:54,678][root][INFO] - Training Epoch: 2/2, step 2690/7134 completed (loss: 0.21368660032749176, acc: 0.9496402740478516)
[2024-12-17 02:56:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,059][root][INFO] - Training Epoch: 2/2, step 2691/7134 completed (loss: 0.3293001055717468, acc: 0.9203540086746216)
[2024-12-17 02:56:55,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,426][root][INFO] - Training Epoch: 2/2, step 2692/7134 completed (loss: 0.43372824788093567, acc: 0.9008264541625977)
[2024-12-17 02:56:55,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:55,764][root][INFO] - Training Epoch: 2/2, step 2693/7134 completed (loss: 0.39360305666923523, acc: 0.9115044474601746)
[2024-12-17 02:56:55,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,111][root][INFO] - Training Epoch: 2/2, step 2694/7134 completed (loss: 0.32241299748420715, acc: 0.9271523356437683)
[2024-12-17 02:56:56,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,488][root][INFO] - Training Epoch: 2/2, step 2695/7134 completed (loss: 0.2922326922416687, acc: 0.9259259104728699)
[2024-12-17 02:56:56,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:56,857][root][INFO] - Training Epoch: 2/2, step 2696/7134 completed (loss: 0.27673500776290894, acc: 0.9571428298950195)
[2024-12-17 02:56:56,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,180][root][INFO] - Training Epoch: 2/2, step 2697/7134 completed (loss: 0.30662479996681213, acc: 0.9155844449996948)
[2024-12-17 02:56:57,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,552][root][INFO] - Training Epoch: 2/2, step 2698/7134 completed (loss: 0.35112351179122925, acc: 0.9115646481513977)
[2024-12-17 02:56:57,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:57,928][root][INFO] - Training Epoch: 2/2, step 2699/7134 completed (loss: 0.22405196726322174, acc: 0.9396551847457886)
[2024-12-17 02:56:58,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,271][root][INFO] - Training Epoch: 2/2, step 2700/7134 completed (loss: 0.3921310007572174, acc: 0.8714285492897034)
[2024-12-17 02:56:58,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,666][root][INFO] - Training Epoch: 2/2, step 2701/7134 completed (loss: 0.2259332835674286, acc: 0.9248120188713074)
[2024-12-17 02:56:58,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:58,985][root][INFO] - Training Epoch: 2/2, step 2702/7134 completed (loss: 0.4903278350830078, acc: 0.8518518805503845)
[2024-12-17 02:56:59,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,327][root][INFO] - Training Epoch: 2/2, step 2703/7134 completed (loss: 0.1273375004529953, acc: 0.9599999785423279)
[2024-12-17 02:56:59,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:56:59,672][root][INFO] - Training Epoch: 2/2, step 2704/7134 completed (loss: 0.21754659712314606, acc: 0.9285714030265808)
[2024-12-17 02:56:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,044][root][INFO] - Training Epoch: 2/2, step 2705/7134 completed (loss: 0.35838642716407776, acc: 0.8802816867828369)
[2024-12-17 02:57:00,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,451][root][INFO] - Training Epoch: 2/2, step 2706/7134 completed (loss: 0.16320732235908508, acc: 0.9589040875434875)
[2024-12-17 02:57:00,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:00,813][root][INFO] - Training Epoch: 2/2, step 2707/7134 completed (loss: 0.30721694231033325, acc: 0.925000011920929)
[2024-12-17 02:57:00,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,205][root][INFO] - Training Epoch: 2/2, step 2708/7134 completed (loss: 0.28989413380622864, acc: 0.9371428489685059)
[2024-12-17 02:57:01,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,587][root][INFO] - Training Epoch: 2/2, step 2709/7134 completed (loss: 0.1440751999616623, acc: 0.9507042169570923)
[2024-12-17 02:57:01,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:01,949][root][INFO] - Training Epoch: 2/2, step 2710/7134 completed (loss: 0.37522223591804504, acc: 0.9100000262260437)
[2024-12-17 02:57:02,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,317][root][INFO] - Training Epoch: 2/2, step 2711/7134 completed (loss: 0.09452790021896362, acc: 0.969072163105011)
[2024-12-17 02:57:02,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:02,700][root][INFO] - Training Epoch: 2/2, step 2712/7134 completed (loss: 0.2931084632873535, acc: 0.9042553305625916)
[2024-12-17 02:57:02,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,083][root][INFO] - Training Epoch: 2/2, step 2713/7134 completed (loss: 0.1635090857744217, acc: 0.949999988079071)
[2024-12-17 02:57:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,419][root][INFO] - Training Epoch: 2/2, step 2714/7134 completed (loss: 0.13337060809135437, acc: 0.970588207244873)
[2024-12-17 02:57:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:03,779][root][INFO] - Training Epoch: 2/2, step 2715/7134 completed (loss: 0.15437749028205872, acc: 0.9379310607910156)
[2024-12-17 02:57:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,164][root][INFO] - Training Epoch: 2/2, step 2716/7134 completed (loss: 0.1321442723274231, acc: 0.9476743936538696)
[2024-12-17 02:57:04,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,528][root][INFO] - Training Epoch: 2/2, step 2717/7134 completed (loss: 0.21908211708068848, acc: 0.9316239356994629)
[2024-12-17 02:57:04,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:04,914][root][INFO] - Training Epoch: 2/2, step 2718/7134 completed (loss: 0.38247111439704895, acc: 0.9236111044883728)
[2024-12-17 02:57:05,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,300][root][INFO] - Training Epoch: 2/2, step 2719/7134 completed (loss: 0.2491731494665146, acc: 0.9424460530281067)
[2024-12-17 02:57:05,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,682][root][INFO] - Training Epoch: 2/2, step 2720/7134 completed (loss: 0.3329658806324005, acc: 0.8978102207183838)
[2024-12-17 02:57:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:05,992][root][INFO] - Training Epoch: 2/2, step 2721/7134 completed (loss: 0.26478418707847595, acc: 0.9735099077224731)
[2024-12-17 02:57:06,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,332][root][INFO] - Training Epoch: 2/2, step 2722/7134 completed (loss: 0.1528349369764328, acc: 0.9468085169792175)
[2024-12-17 02:57:06,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:06,720][root][INFO] - Training Epoch: 2/2, step 2723/7134 completed (loss: 0.41725456714630127, acc: 0.8922155499458313)
[2024-12-17 02:57:06,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,102][root][INFO] - Training Epoch: 2/2, step 2724/7134 completed (loss: 0.1268487572669983, acc: 0.9604519605636597)
[2024-12-17 02:57:07,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,461][root][INFO] - Training Epoch: 2/2, step 2725/7134 completed (loss: 0.15062396228313446, acc: 0.9402984976768494)
[2024-12-17 02:57:07,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:07,840][root][INFO] - Training Epoch: 2/2, step 2726/7134 completed (loss: 0.33683517575263977, acc: 0.934959352016449)
[2024-12-17 02:57:07,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,222][root][INFO] - Training Epoch: 2/2, step 2727/7134 completed (loss: 0.13440310955047607, acc: 0.9561403393745422)
[2024-12-17 02:57:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,602][root][INFO] - Training Epoch: 2/2, step 2728/7134 completed (loss: 0.6927131414413452, acc: 0.8296296000480652)
[2024-12-17 02:57:08,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:08,953][root][INFO] - Training Epoch: 2/2, step 2729/7134 completed (loss: 0.4933242201805115, acc: 0.8857142925262451)
[2024-12-17 02:57:09,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,301][root][INFO] - Training Epoch: 2/2, step 2730/7134 completed (loss: 0.3793877065181732, acc: 0.8938053250312805)
[2024-12-17 02:57:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:09,662][root][INFO] - Training Epoch: 2/2, step 2731/7134 completed (loss: 0.5260893702507019, acc: 0.8834951519966125)
[2024-12-17 02:57:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,039][root][INFO] - Training Epoch: 2/2, step 2732/7134 completed (loss: 0.46242842078208923, acc: 0.8823529481887817)
[2024-12-17 02:57:10,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,446][root][INFO] - Training Epoch: 2/2, step 2733/7134 completed (loss: 0.3183881640434265, acc: 0.9055555462837219)
[2024-12-17 02:57:10,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:10,809][root][INFO] - Training Epoch: 2/2, step 2734/7134 completed (loss: 0.3999706208705902, acc: 0.9256198406219482)
[2024-12-17 02:57:10,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,192][root][INFO] - Training Epoch: 2/2, step 2735/7134 completed (loss: 0.27620983123779297, acc: 0.9207317233085632)
[2024-12-17 02:57:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,561][root][INFO] - Training Epoch: 2/2, step 2736/7134 completed (loss: 0.4123258888721466, acc: 0.9182389974594116)
[2024-12-17 02:57:11,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:11,936][root][INFO] - Training Epoch: 2/2, step 2737/7134 completed (loss: 0.383609801530838, acc: 0.9142857193946838)
[2024-12-17 02:57:12,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,302][root][INFO] - Training Epoch: 2/2, step 2738/7134 completed (loss: 0.3415163457393646, acc: 0.8982036113739014)
[2024-12-17 02:57:12,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:12,685][root][INFO] - Training Epoch: 2/2, step 2739/7134 completed (loss: 0.39180243015289307, acc: 0.9057971239089966)
[2024-12-17 02:57:12,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,068][root][INFO] - Training Epoch: 2/2, step 2740/7134 completed (loss: 0.25096645951271057, acc: 0.9251700639724731)
[2024-12-17 02:57:13,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,434][root][INFO] - Training Epoch: 2/2, step 2741/7134 completed (loss: 0.1508452296257019, acc: 0.9741379022598267)
[2024-12-17 02:57:13,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:13,807][root][INFO] - Training Epoch: 2/2, step 2742/7134 completed (loss: 0.23811715841293335, acc: 0.924369752407074)
[2024-12-17 02:57:13,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,131][root][INFO] - Training Epoch: 2/2, step 2743/7134 completed (loss: 0.10657666623592377, acc: 0.957446813583374)
[2024-12-17 02:57:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,456][root][INFO] - Training Epoch: 2/2, step 2744/7134 completed (loss: 0.18178141117095947, acc: 0.9354838728904724)
[2024-12-17 02:57:14,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:14,806][root][INFO] - Training Epoch: 2/2, step 2745/7134 completed (loss: 0.59432452917099, acc: 0.8690476417541504)
[2024-12-17 02:57:14,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,153][root][INFO] - Training Epoch: 2/2, step 2746/7134 completed (loss: 0.3482806384563446, acc: 0.9090909361839294)
[2024-12-17 02:57:15,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,477][root][INFO] - Training Epoch: 2/2, step 2747/7134 completed (loss: 0.3898996114730835, acc: 0.9074074029922485)
[2024-12-17 02:57:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:15,845][root][INFO] - Training Epoch: 2/2, step 2748/7134 completed (loss: 0.17666283249855042, acc: 0.9610389471054077)
[2024-12-17 02:57:15,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,202][root][INFO] - Training Epoch: 2/2, step 2749/7134 completed (loss: 0.31056109070777893, acc: 0.9175257682800293)
[2024-12-17 02:57:16,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,562][root][INFO] - Training Epoch: 2/2, step 2750/7134 completed (loss: 0.20438851416110992, acc: 0.9638554453849792)
[2024-12-17 02:57:16,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:16,920][root][INFO] - Training Epoch: 2/2, step 2751/7134 completed (loss: 0.4765095114707947, acc: 0.9099099040031433)
[2024-12-17 02:57:17,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,289][root][INFO] - Training Epoch: 2/2, step 2752/7134 completed (loss: 0.31801924109458923, acc: 0.9343065619468689)
[2024-12-17 02:57:17,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:17,652][root][INFO] - Training Epoch: 2/2, step 2753/7134 completed (loss: 0.3451045751571655, acc: 0.9159663915634155)
[2024-12-17 02:57:17,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,020][root][INFO] - Training Epoch: 2/2, step 2754/7134 completed (loss: 0.23151449859142303, acc: 0.925000011920929)
[2024-12-17 02:57:18,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,375][root][INFO] - Training Epoch: 2/2, step 2755/7134 completed (loss: 0.25910812616348267, acc: 0.9609375)
[2024-12-17 02:57:18,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:18,708][root][INFO] - Training Epoch: 2/2, step 2756/7134 completed (loss: 0.23589088022708893, acc: 0.9189189076423645)
[2024-12-17 02:57:18,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,081][root][INFO] - Training Epoch: 2/2, step 2757/7134 completed (loss: 0.2519596219062805, acc: 0.9347826242446899)
[2024-12-17 02:57:19,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,463][root][INFO] - Training Epoch: 2/2, step 2758/7134 completed (loss: 0.3097434341907501, acc: 0.9262295365333557)
[2024-12-17 02:57:19,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:19,804][root][INFO] - Training Epoch: 2/2, step 2759/7134 completed (loss: 0.18221551179885864, acc: 0.9428571462631226)
[2024-12-17 02:57:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,198][root][INFO] - Training Epoch: 2/2, step 2760/7134 completed (loss: 0.27951934933662415, acc: 0.9555555582046509)
[2024-12-17 02:57:20,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:20,592][root][INFO] - Training Epoch: 2/2, step 2761/7134 completed (loss: 0.3787277638912201, acc: 0.8947368264198303)
[2024-12-17 02:57:20,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,048][root][INFO] - Training Epoch: 2/2, step 2762/7134 completed (loss: 0.33670774102211, acc: 0.9261083602905273)
[2024-12-17 02:57:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,486][root][INFO] - Training Epoch: 2/2, step 2763/7134 completed (loss: 0.1951354742050171, acc: 0.9562841653823853)
[2024-12-17 02:57:21,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:21,858][root][INFO] - Training Epoch: 2/2, step 2764/7134 completed (loss: 0.2746266722679138, acc: 0.9166666865348816)
[2024-12-17 02:57:21,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,250][root][INFO] - Training Epoch: 2/2, step 2765/7134 completed (loss: 0.19992081820964813, acc: 0.9647058844566345)
[2024-12-17 02:57:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:22,648][root][INFO] - Training Epoch: 2/2, step 2766/7134 completed (loss: 0.11657463014125824, acc: 0.9681528806686401)
[2024-12-17 02:57:22,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,037][root][INFO] - Training Epoch: 2/2, step 2767/7134 completed (loss: 0.27878743410110474, acc: 0.9350000023841858)
[2024-12-17 02:57:23,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,411][root][INFO] - Training Epoch: 2/2, step 2768/7134 completed (loss: 0.1836453676223755, acc: 0.9578313231468201)
[2024-12-17 02:57:23,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:23,777][root][INFO] - Training Epoch: 2/2, step 2769/7134 completed (loss: 0.11911109834909439, acc: 0.9578947424888611)
[2024-12-17 02:57:23,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,202][root][INFO] - Training Epoch: 2/2, step 2770/7134 completed (loss: 0.18649351596832275, acc: 0.9444444179534912)
[2024-12-17 02:57:24,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,612][root][INFO] - Training Epoch: 2/2, step 2771/7134 completed (loss: 0.4577077329158783, acc: 0.9099525809288025)
[2024-12-17 02:57:24,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:24,978][root][INFO] - Training Epoch: 2/2, step 2772/7134 completed (loss: 0.26314178109169006, acc: 0.9399999976158142)
[2024-12-17 02:57:25,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,371][root][INFO] - Training Epoch: 2/2, step 2773/7134 completed (loss: 0.24806863069534302, acc: 0.9396985173225403)
[2024-12-17 02:57:25,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:25,758][root][INFO] - Training Epoch: 2/2, step 2774/7134 completed (loss: 0.33659419417381287, acc: 0.9170731902122498)
[2024-12-17 02:57:25,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,098][root][INFO] - Training Epoch: 2/2, step 2775/7134 completed (loss: 0.2561737298965454, acc: 0.9289617538452148)
[2024-12-17 02:57:26,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,491][root][INFO] - Training Epoch: 2/2, step 2776/7134 completed (loss: 0.16240613162517548, acc: 0.9653679728507996)
[2024-12-17 02:57:26,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:26,861][root][INFO] - Training Epoch: 2/2, step 2777/7134 completed (loss: 0.08476106822490692, acc: 0.977142870426178)
[2024-12-17 02:57:26,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,226][root][INFO] - Training Epoch: 2/2, step 2778/7134 completed (loss: 0.2242705374956131, acc: 0.9545454382896423)
[2024-12-17 02:57:27,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,614][root][INFO] - Training Epoch: 2/2, step 2779/7134 completed (loss: 0.2220519483089447, acc: 0.9360730648040771)
[2024-12-17 02:57:27,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:27,986][root][INFO] - Training Epoch: 2/2, step 2780/7134 completed (loss: 0.26535114645957947, acc: 0.9336283206939697)
[2024-12-17 02:57:28,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,342][root][INFO] - Training Epoch: 2/2, step 2781/7134 completed (loss: 0.19846029579639435, acc: 0.9510869383811951)
[2024-12-17 02:57:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:28,708][root][INFO] - Training Epoch: 2/2, step 2782/7134 completed (loss: 0.11353737860918045, acc: 0.9732142686843872)
[2024-12-17 02:57:28,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,078][root][INFO] - Training Epoch: 2/2, step 2783/7134 completed (loss: 0.1790890395641327, acc: 0.9659863710403442)
[2024-12-17 02:57:29,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,463][root][INFO] - Training Epoch: 2/2, step 2784/7134 completed (loss: 0.1632474660873413, acc: 0.9710144996643066)
[2024-12-17 02:57:29,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:29,854][root][INFO] - Training Epoch: 2/2, step 2785/7134 completed (loss: 0.23946517705917358, acc: 0.9563106894493103)
[2024-12-17 02:57:29,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,202][root][INFO] - Training Epoch: 2/2, step 2786/7134 completed (loss: 0.3075007200241089, acc: 0.9200000166893005)
[2024-12-17 02:57:30,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,589][root][INFO] - Training Epoch: 2/2, step 2787/7134 completed (loss: 0.1888660341501236, acc: 0.9479768872261047)
[2024-12-17 02:57:30,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:30,974][root][INFO] - Training Epoch: 2/2, step 2788/7134 completed (loss: 0.26924577355384827, acc: 0.9299362897872925)
[2024-12-17 02:57:31,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,343][root][INFO] - Training Epoch: 2/2, step 2789/7134 completed (loss: 1.6718659400939941, acc: 0.6285714507102966)
[2024-12-17 02:57:31,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:31,693][root][INFO] - Training Epoch: 2/2, step 2790/7134 completed (loss: 1.0748826265335083, acc: 0.7333333492279053)
[2024-12-17 02:57:31,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,068][root][INFO] - Training Epoch: 2/2, step 2791/7134 completed (loss: 0.5166179537773132, acc: 0.887417197227478)
[2024-12-17 02:57:32,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,465][root][INFO] - Training Epoch: 2/2, step 2792/7134 completed (loss: 0.1940036565065384, acc: 0.9593023061752319)
[2024-12-17 02:57:32,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:32,869][root][INFO] - Training Epoch: 2/2, step 2793/7134 completed (loss: 0.14814667403697968, acc: 0.976047933101654)
[2024-12-17 02:57:32,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,186][root][INFO] - Training Epoch: 2/2, step 2794/7134 completed (loss: 0.30652448534965515, acc: 0.939393937587738)
[2024-12-17 02:57:33,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,548][root][INFO] - Training Epoch: 2/2, step 2795/7134 completed (loss: 0.6437058448791504, acc: 0.8518518805503845)
[2024-12-17 02:57:33,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:33,890][root][INFO] - Training Epoch: 2/2, step 2796/7134 completed (loss: 0.5281570553779602, acc: 0.8780487775802612)
[2024-12-17 02:57:34,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,307][root][INFO] - Training Epoch: 2/2, step 2797/7134 completed (loss: 0.6230865716934204, acc: 0.8536585569381714)
[2024-12-17 02:57:34,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:34,671][root][INFO] - Training Epoch: 2/2, step 2798/7134 completed (loss: 0.4974835515022278, acc: 0.8833333253860474)
[2024-12-17 02:57:34,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,012][root][INFO] - Training Epoch: 2/2, step 2799/7134 completed (loss: 0.5235029458999634, acc: 0.8671875)
[2024-12-17 02:57:35,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,387][root][INFO] - Training Epoch: 2/2, step 2800/7134 completed (loss: 0.26754555106163025, acc: 0.9343065619468689)
[2024-12-17 02:57:35,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:35,773][root][INFO] - Training Epoch: 2/2, step 2801/7134 completed (loss: 0.33705148100852966, acc: 0.9180327653884888)
[2024-12-17 02:57:35,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,155][root][INFO] - Training Epoch: 2/2, step 2802/7134 completed (loss: 0.31798726320266724, acc: 0.9145728349685669)
[2024-12-17 02:57:36,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,504][root][INFO] - Training Epoch: 2/2, step 2803/7134 completed (loss: 0.1104106679558754, acc: 0.9753086566925049)
[2024-12-17 02:57:36,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:36,888][root][INFO] - Training Epoch: 2/2, step 2804/7134 completed (loss: 0.22046791017055511, acc: 0.9653179049491882)
[2024-12-17 02:57:37,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,272][root][INFO] - Training Epoch: 2/2, step 2805/7134 completed (loss: 0.13097451627254486, acc: 0.9767441749572754)
[2024-12-17 02:57:37,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:37,663][root][INFO] - Training Epoch: 2/2, step 2806/7134 completed (loss: 0.14812366664409637, acc: 0.9632353186607361)
[2024-12-17 02:57:37,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,032][root][INFO] - Training Epoch: 2/2, step 2807/7134 completed (loss: 0.30483537912368774, acc: 0.9126213788986206)
[2024-12-17 02:57:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,418][root][INFO] - Training Epoch: 2/2, step 2808/7134 completed (loss: 0.24794621765613556, acc: 0.9497487545013428)
[2024-12-17 02:57:38,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:38,818][root][INFO] - Training Epoch: 2/2, step 2809/7134 completed (loss: 0.29003000259399414, acc: 0.9055117964744568)
[2024-12-17 02:57:38,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,224][root][INFO] - Training Epoch: 2/2, step 2810/7134 completed (loss: 0.11555273830890656, acc: 0.9562841653823853)
[2024-12-17 02:57:39,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,604][root][INFO] - Training Epoch: 2/2, step 2811/7134 completed (loss: 0.07506374269723892, acc: 0.9834254384040833)
[2024-12-17 02:57:39,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:39,970][root][INFO] - Training Epoch: 2/2, step 2812/7134 completed (loss: 0.08367916196584702, acc: 0.9933775067329407)
[2024-12-17 02:57:40,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,398][root][INFO] - Training Epoch: 2/2, step 2813/7134 completed (loss: 0.16542798280715942, acc: 0.9425287246704102)
[2024-12-17 02:57:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:40,814][root][INFO] - Training Epoch: 2/2, step 2814/7134 completed (loss: 0.2587544620037079, acc: 0.9534883499145508)
[2024-12-17 02:57:40,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,210][root][INFO] - Training Epoch: 2/2, step 2815/7134 completed (loss: 0.16118383407592773, acc: 0.9505494236946106)
[2024-12-17 02:57:41,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:41,637][root][INFO] - Training Epoch: 2/2, step 2816/7134 completed (loss: 0.14677074551582336, acc: 0.9542483687400818)
[2024-12-17 02:57:41,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,006][root][INFO] - Training Epoch: 2/2, step 2817/7134 completed (loss: 0.15899786353111267, acc: 0.9695431590080261)
[2024-12-17 02:57:42,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,395][root][INFO] - Training Epoch: 2/2, step 2818/7134 completed (loss: 0.13804815709590912, acc: 0.957446813583374)
[2024-12-17 02:57:42,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:42,757][root][INFO] - Training Epoch: 2/2, step 2819/7134 completed (loss: 0.13279148936271667, acc: 0.9589040875434875)
[2024-12-17 02:57:42,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,138][root][INFO] - Training Epoch: 2/2, step 2820/7134 completed (loss: 0.3879575729370117, acc: 0.8895705342292786)
[2024-12-17 02:57:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,530][root][INFO] - Training Epoch: 2/2, step 2821/7134 completed (loss: 0.33570340275764465, acc: 0.9119170904159546)
[2024-12-17 02:57:43,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:43,931][root][INFO] - Training Epoch: 2/2, step 2822/7134 completed (loss: 0.43528831005096436, acc: 0.9027026891708374)
[2024-12-17 02:57:44,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,330][root][INFO] - Training Epoch: 2/2, step 2823/7134 completed (loss: 0.2915933132171631, acc: 0.9192546606063843)
[2024-12-17 02:57:44,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:44,730][root][INFO] - Training Epoch: 2/2, step 2824/7134 completed (loss: 0.506371021270752, acc: 0.893081784248352)
[2024-12-17 02:57:44,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,135][root][INFO] - Training Epoch: 2/2, step 2825/7134 completed (loss: 0.1887090504169464, acc: 0.9555555582046509)
[2024-12-17 02:57:45,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,587][root][INFO] - Training Epoch: 2/2, step 2826/7134 completed (loss: 0.3180767893791199, acc: 0.9022988677024841)
[2024-12-17 02:57:45,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:45,986][root][INFO] - Training Epoch: 2/2, step 2827/7134 completed (loss: 0.24321000277996063, acc: 0.9521530866622925)
[2024-12-17 02:57:46,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,416][root][INFO] - Training Epoch: 2/2, step 2828/7134 completed (loss: 0.17747537791728973, acc: 0.949367105960846)
[2024-12-17 02:57:46,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:46,821][root][INFO] - Training Epoch: 2/2, step 2829/7134 completed (loss: 0.2865612506866455, acc: 0.9523809552192688)
[2024-12-17 02:57:46,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,233][root][INFO] - Training Epoch: 2/2, step 2830/7134 completed (loss: 0.06672156602144241, acc: 0.9850746393203735)
[2024-12-17 02:57:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:47,636][root][INFO] - Training Epoch: 2/2, step 2831/7134 completed (loss: 0.21944335103034973, acc: 0.9594594836235046)
[2024-12-17 02:57:47,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,028][root][INFO] - Training Epoch: 2/2, step 2832/7134 completed (loss: 0.24763990938663483, acc: 0.9408602118492126)
[2024-12-17 02:57:48,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,409][root][INFO] - Training Epoch: 2/2, step 2833/7134 completed (loss: 0.22449079155921936, acc: 0.9576719403266907)
[2024-12-17 02:57:48,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:48,784][root][INFO] - Training Epoch: 2/2, step 2834/7134 completed (loss: 0.24486421048641205, acc: 0.9333333373069763)
[2024-12-17 02:57:48,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,157][root][INFO] - Training Epoch: 2/2, step 2835/7134 completed (loss: 0.21792201697826385, acc: 0.9144737124443054)
[2024-12-17 02:57:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,535][root][INFO] - Training Epoch: 2/2, step 2836/7134 completed (loss: 0.3673599660396576, acc: 0.9100000262260437)
[2024-12-17 02:57:49,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:49,937][root][INFO] - Training Epoch: 2/2, step 2837/7134 completed (loss: 0.16320820152759552, acc: 0.9590643048286438)
[2024-12-17 02:57:50,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,325][root][INFO] - Training Epoch: 2/2, step 2838/7134 completed (loss: 0.31038567423820496, acc: 0.9211822748184204)
[2024-12-17 02:57:50,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:50,722][root][INFO] - Training Epoch: 2/2, step 2839/7134 completed (loss: 0.24213910102844238, acc: 0.9477611780166626)
[2024-12-17 02:57:50,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,121][root][INFO] - Training Epoch: 2/2, step 2840/7134 completed (loss: 0.17009003460407257, acc: 0.9588235020637512)
[2024-12-17 02:57:51,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,484][root][INFO] - Training Epoch: 2/2, step 2841/7134 completed (loss: 0.16950373351573944, acc: 0.9716981053352356)
[2024-12-17 02:57:51,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:51,894][root][INFO] - Training Epoch: 2/2, step 2842/7134 completed (loss: 0.2648983895778656, acc: 0.9375)
[2024-12-17 02:57:51,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,269][root][INFO] - Training Epoch: 2/2, step 2843/7134 completed (loss: 0.1999857872724533, acc: 0.9496855139732361)
[2024-12-17 02:57:52,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,621][root][INFO] - Training Epoch: 2/2, step 2844/7134 completed (loss: 0.41902485489845276, acc: 0.89673912525177)
[2024-12-17 02:57:52,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:52,974][root][INFO] - Training Epoch: 2/2, step 2845/7134 completed (loss: 0.2593870759010315, acc: 0.9391891956329346)
[2024-12-17 02:57:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,324][root][INFO] - Training Epoch: 2/2, step 2846/7134 completed (loss: 0.22624483704566956, acc: 0.9673202633857727)
[2024-12-17 02:57:53,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:53,732][root][INFO] - Training Epoch: 2/2, step 2847/7134 completed (loss: 0.23402157425880432, acc: 0.9299362897872925)
[2024-12-17 02:57:53,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,136][root][INFO] - Training Epoch: 2/2, step 2848/7134 completed (loss: 0.19798000156879425, acc: 0.9541284441947937)
[2024-12-17 02:57:54,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,507][root][INFO] - Training Epoch: 2/2, step 2849/7134 completed (loss: 0.2198754847049713, acc: 0.9428571462631226)
[2024-12-17 02:57:54,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:54,880][root][INFO] - Training Epoch: 2/2, step 2850/7134 completed (loss: 0.43591946363449097, acc: 0.8888888955116272)
[2024-12-17 02:57:55,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,273][root][INFO] - Training Epoch: 2/2, step 2851/7134 completed (loss: 0.2545354664325714, acc: 0.9481481313705444)
[2024-12-17 02:57:55,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,611][root][INFO] - Training Epoch: 2/2, step 2852/7134 completed (loss: 0.2172071784734726, acc: 0.9512194991111755)
[2024-12-17 02:57:55,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:55,961][root][INFO] - Training Epoch: 2/2, step 2853/7134 completed (loss: 0.20472754538059235, acc: 0.9591836929321289)
[2024-12-17 02:57:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,340][root][INFO] - Training Epoch: 2/2, step 2854/7134 completed (loss: 0.2974259853363037, acc: 0.918367326259613)
[2024-12-17 02:57:56,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:56,739][root][INFO] - Training Epoch: 2/2, step 2855/7134 completed (loss: 0.19049474596977234, acc: 0.9391891956329346)
[2024-12-17 02:57:56,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,188][root][INFO] - Training Epoch: 2/2, step 2856/7134 completed (loss: 0.19142919778823853, acc: 0.95652174949646)
[2024-12-17 02:57:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:57,597][root][INFO] - Training Epoch: 2/2, step 2857/7134 completed (loss: 0.21705953776836395, acc: 0.940119743347168)
[2024-12-17 02:57:57,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,009][root][INFO] - Training Epoch: 2/2, step 2858/7134 completed (loss: 0.12304522842168808, acc: 0.9545454382896423)
[2024-12-17 02:57:58,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,438][root][INFO] - Training Epoch: 2/2, step 2859/7134 completed (loss: 0.3217215836048126, acc: 0.9226190447807312)
[2024-12-17 02:57:58,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:58,874][root][INFO] - Training Epoch: 2/2, step 2860/7134 completed (loss: 0.2944648563861847, acc: 0.9296875)
[2024-12-17 02:57:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,334][root][INFO] - Training Epoch: 2/2, step 2861/7134 completed (loss: 0.21346023678779602, acc: 0.9375)
[2024-12-17 02:57:59,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:57:59,706][root][INFO] - Training Epoch: 2/2, step 2862/7134 completed (loss: 0.19225278496742249, acc: 0.969924807548523)
[2024-12-17 02:57:59,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,095][root][INFO] - Training Epoch: 2/2, step 2863/7134 completed (loss: 0.12446790933609009, acc: 0.9613259434700012)
[2024-12-17 02:58:00,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,423][root][INFO] - Training Epoch: 2/2, step 2864/7134 completed (loss: 0.15204744040966034, acc: 0.9578947424888611)
[2024-12-17 02:58:00,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:00,859][root][INFO] - Training Epoch: 2/2, step 2865/7134 completed (loss: 0.13221418857574463, acc: 0.947826087474823)
[2024-12-17 02:58:01,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,282][root][INFO] - Training Epoch: 2/2, step 2866/7134 completed (loss: 0.1790575385093689, acc: 0.9548386931419373)
[2024-12-17 02:58:01,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:01,677][root][INFO] - Training Epoch: 2/2, step 2867/7134 completed (loss: 0.16527917981147766, acc: 0.9259259104728699)
[2024-12-17 02:58:01,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,036][root][INFO] - Training Epoch: 2/2, step 2868/7134 completed (loss: 0.26375317573547363, acc: 0.929411768913269)
[2024-12-17 02:58:02,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,419][root][INFO] - Training Epoch: 2/2, step 2869/7134 completed (loss: 0.2524310350418091, acc: 0.9448275566101074)
[2024-12-17 02:58:02,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:02,849][root][INFO] - Training Epoch: 2/2, step 2870/7134 completed (loss: 0.5582350492477417, acc: 0.8636363744735718)
[2024-12-17 02:58:02,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,224][root][INFO] - Training Epoch: 2/2, step 2871/7134 completed (loss: 0.16526968777179718, acc: 0.9586206674575806)
[2024-12-17 02:58:03,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:03,627][root][INFO] - Training Epoch: 2/2, step 2872/7134 completed (loss: 0.08662193268537521, acc: 0.9734513163566589)
[2024-12-17 02:58:03,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,005][root][INFO] - Training Epoch: 2/2, step 2873/7134 completed (loss: 0.16965974867343903, acc: 0.9534883499145508)
[2024-12-17 02:58:04,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,390][root][INFO] - Training Epoch: 2/2, step 2874/7134 completed (loss: 0.06118950620293617, acc: 0.9861111044883728)
[2024-12-17 02:58:04,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:04,841][root][INFO] - Training Epoch: 2/2, step 2875/7134 completed (loss: 0.2218741476535797, acc: 0.9464285969734192)
[2024-12-17 02:58:04,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,263][root][INFO] - Training Epoch: 2/2, step 2876/7134 completed (loss: 0.339570015668869, acc: 0.9056603908538818)
[2024-12-17 02:58:05,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:05,688][root][INFO] - Training Epoch: 2/2, step 2877/7134 completed (loss: 0.10320492833852768, acc: 0.9914529919624329)
[2024-12-17 02:58:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,094][root][INFO] - Training Epoch: 2/2, step 2878/7134 completed (loss: 0.14736302196979523, acc: 0.9736841917037964)
[2024-12-17 02:58:06,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,480][root][INFO] - Training Epoch: 2/2, step 2879/7134 completed (loss: 0.12026221305131912, acc: 0.9659863710403442)
[2024-12-17 02:58:06,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:06,886][root][INFO] - Training Epoch: 2/2, step 2880/7134 completed (loss: 0.0983855277299881, acc: 0.9726027250289917)
[2024-12-17 02:58:07,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,297][root][INFO] - Training Epoch: 2/2, step 2881/7134 completed (loss: 0.24731303751468658, acc: 0.9365079402923584)
[2024-12-17 02:58:07,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:07,735][root][INFO] - Training Epoch: 2/2, step 2882/7134 completed (loss: 0.4086216390132904, acc: 0.8670520186424255)
[2024-12-17 02:58:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,156][root][INFO] - Training Epoch: 2/2, step 2883/7134 completed (loss: 0.3820567727088928, acc: 0.8802395462989807)
[2024-12-17 02:58:08,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,537][root][INFO] - Training Epoch: 2/2, step 2884/7134 completed (loss: 0.4197555184364319, acc: 0.8969696760177612)
[2024-12-17 02:58:08,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:08,898][root][INFO] - Training Epoch: 2/2, step 2885/7134 completed (loss: 0.6696654558181763, acc: 0.8303030133247375)
[2024-12-17 02:58:08,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,268][root][INFO] - Training Epoch: 2/2, step 2886/7134 completed (loss: 0.4020856022834778, acc: 0.9117646813392639)
[2024-12-17 02:58:09,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:09,661][root][INFO] - Training Epoch: 2/2, step 2887/7134 completed (loss: 0.37251782417297363, acc: 0.9082969427108765)
[2024-12-17 02:58:09,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,052][root][INFO] - Training Epoch: 2/2, step 2888/7134 completed (loss: 0.31071314215660095, acc: 0.9157894849777222)
[2024-12-17 02:58:10,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,437][root][INFO] - Training Epoch: 2/2, step 2889/7134 completed (loss: 0.24094510078430176, acc: 0.9441340565681458)
[2024-12-17 02:58:10,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:10,825][root][INFO] - Training Epoch: 2/2, step 2890/7134 completed (loss: 0.24465198814868927, acc: 0.928205132484436)
[2024-12-17 02:58:10,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,201][root][INFO] - Training Epoch: 2/2, step 2891/7134 completed (loss: 0.25186923146247864, acc: 0.9259259104728699)
[2024-12-17 02:58:11,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,613][root][INFO] - Training Epoch: 2/2, step 2892/7134 completed (loss: 0.34554025530815125, acc: 0.9171597361564636)
[2024-12-17 02:58:11,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:11,994][root][INFO] - Training Epoch: 2/2, step 2893/7134 completed (loss: 0.37508463859558105, acc: 0.8907103538513184)
[2024-12-17 02:58:12,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,361][root][INFO] - Training Epoch: 2/2, step 2894/7134 completed (loss: 0.33022114634513855, acc: 0.8962963223457336)
[2024-12-17 02:58:12,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:12,744][root][INFO] - Training Epoch: 2/2, step 2895/7134 completed (loss: 0.11185277253389359, acc: 0.9661017060279846)
[2024-12-17 02:58:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,157][root][INFO] - Training Epoch: 2/2, step 2896/7134 completed (loss: 0.1906421184539795, acc: 0.9580838084220886)
[2024-12-17 02:58:13,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,513][root][INFO] - Training Epoch: 2/2, step 2897/7134 completed (loss: 0.464054137468338, acc: 0.902255654335022)
[2024-12-17 02:58:13,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:13,873][root][INFO] - Training Epoch: 2/2, step 2898/7134 completed (loss: 0.2412656843662262, acc: 0.9510869383811951)
[2024-12-17 02:58:13,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,231][root][INFO] - Training Epoch: 2/2, step 2899/7134 completed (loss: 0.17975036799907684, acc: 0.9520958065986633)
[2024-12-17 02:58:14,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,603][root][INFO] - Training Epoch: 2/2, step 2900/7134 completed (loss: 0.21592706441879272, acc: 0.9414893388748169)
[2024-12-17 02:58:14,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:14,981][root][INFO] - Training Epoch: 2/2, step 2901/7134 completed (loss: 0.14420399069786072, acc: 0.9594594836235046)
[2024-12-17 02:58:15,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,339][root][INFO] - Training Epoch: 2/2, step 2902/7134 completed (loss: 0.16185234487056732, acc: 0.9572649598121643)
[2024-12-17 02:58:15,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:15,729][root][INFO] - Training Epoch: 2/2, step 2903/7134 completed (loss: 0.1548418402671814, acc: 0.949438214302063)
[2024-12-17 02:58:15,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,104][root][INFO] - Training Epoch: 2/2, step 2904/7134 completed (loss: 0.1276107281446457, acc: 0.9675675630569458)
[2024-12-17 02:58:16,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,462][root][INFO] - Training Epoch: 2/2, step 2905/7134 completed (loss: 0.21444280445575714, acc: 0.9358288645744324)
[2024-12-17 02:58:16,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:16,830][root][INFO] - Training Epoch: 2/2, step 2906/7134 completed (loss: 0.13437393307685852, acc: 0.9738219976425171)
[2024-12-17 02:58:16,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,206][root][INFO] - Training Epoch: 2/2, step 2907/7134 completed (loss: 0.23108451068401337, acc: 0.9221556782722473)
[2024-12-17 02:58:17,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:17,574][root][INFO] - Training Epoch: 2/2, step 2908/7134 completed (loss: 0.14621803164482117, acc: 0.9655172228813171)
[2024-12-17 02:58:17,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,003][root][INFO] - Training Epoch: 2/2, step 2909/7134 completed (loss: 0.17339396476745605, acc: 0.9562841653823853)
[2024-12-17 02:58:18,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,381][root][INFO] - Training Epoch: 2/2, step 2910/7134 completed (loss: 0.19450820982456207, acc: 0.9411764740943909)
[2024-12-17 02:58:18,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:18,766][root][INFO] - Training Epoch: 2/2, step 2911/7134 completed (loss: 0.19781148433685303, acc: 0.9440559148788452)
[2024-12-17 02:58:18,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,144][root][INFO] - Training Epoch: 2/2, step 2912/7134 completed (loss: 0.17481087148189545, acc: 0.9520547986030579)
[2024-12-17 02:58:19,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,512][root][INFO] - Training Epoch: 2/2, step 2913/7134 completed (loss: 0.21003957092761993, acc: 0.9568345546722412)
[2024-12-17 02:58:19,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:19,864][root][INFO] - Training Epoch: 2/2, step 2914/7134 completed (loss: 0.16740621626377106, acc: 0.9454545378684998)
[2024-12-17 02:58:19,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,239][root][INFO] - Training Epoch: 2/2, step 2915/7134 completed (loss: 0.4558381140232086, acc: 0.8965517282485962)
[2024-12-17 02:58:20,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:20,610][root][INFO] - Training Epoch: 2/2, step 2916/7134 completed (loss: 0.25234293937683105, acc: 0.9298245906829834)
[2024-12-17 02:58:20,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,036][root][INFO] - Training Epoch: 2/2, step 2917/7134 completed (loss: 0.1483832746744156, acc: 0.9561403393745422)
[2024-12-17 02:58:21,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,393][root][INFO] - Training Epoch: 2/2, step 2918/7134 completed (loss: 0.21629808843135834, acc: 0.9356725215911865)
[2024-12-17 02:58:21,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:21,760][root][INFO] - Training Epoch: 2/2, step 2919/7134 completed (loss: 0.1882638931274414, acc: 0.9518072009086609)
[2024-12-17 02:58:21,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,151][root][INFO] - Training Epoch: 2/2, step 2920/7134 completed (loss: 0.21465596556663513, acc: 0.9496855139732361)
[2024-12-17 02:58:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,554][root][INFO] - Training Epoch: 2/2, step 2921/7134 completed (loss: 0.14872930943965912, acc: 0.9571428298950195)
[2024-12-17 02:58:22,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:22,962][root][INFO] - Training Epoch: 2/2, step 2922/7134 completed (loss: 0.34937161207199097, acc: 0.9141104221343994)
[2024-12-17 02:58:23,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,372][root][INFO] - Training Epoch: 2/2, step 2923/7134 completed (loss: 0.6932539939880371, acc: 0.8943662047386169)
[2024-12-17 02:58:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:23,771][root][INFO] - Training Epoch: 2/2, step 2924/7134 completed (loss: 0.19848093390464783, acc: 0.9451219439506531)
[2024-12-17 02:58:23,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,188][root][INFO] - Training Epoch: 2/2, step 2925/7134 completed (loss: 0.2471860945224762, acc: 0.9470587968826294)
[2024-12-17 02:58:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,591][root][INFO] - Training Epoch: 2/2, step 2926/7134 completed (loss: 0.3982139825820923, acc: 0.9447236061096191)
[2024-12-17 02:58:24,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:24,998][root][INFO] - Training Epoch: 2/2, step 2927/7134 completed (loss: 0.1302935779094696, acc: 0.9653179049491882)
[2024-12-17 02:58:25,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,408][root][INFO] - Training Epoch: 2/2, step 2928/7134 completed (loss: 0.27882954478263855, acc: 0.9236111044883728)
[2024-12-17 02:58:25,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:25,810][root][INFO] - Training Epoch: 2/2, step 2929/7134 completed (loss: 0.1193036362528801, acc: 0.9702380895614624)
[2024-12-17 02:58:25,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,220][root][INFO] - Training Epoch: 2/2, step 2930/7134 completed (loss: 0.2490880787372589, acc: 0.9455782175064087)
[2024-12-17 02:58:26,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:26,608][root][INFO] - Training Epoch: 2/2, step 2931/7134 completed (loss: 0.3598864674568176, acc: 0.8974359035491943)
[2024-12-17 02:58:26,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,000][root][INFO] - Training Epoch: 2/2, step 2932/7134 completed (loss: 0.21546785533428192, acc: 0.9358288645744324)
[2024-12-17 02:58:27,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,387][root][INFO] - Training Epoch: 2/2, step 2933/7134 completed (loss: 0.17003436386585236, acc: 0.970802903175354)
[2024-12-17 02:58:27,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:27,826][root][INFO] - Training Epoch: 2/2, step 2934/7134 completed (loss: 0.13374026119709015, acc: 0.9714285731315613)
[2024-12-17 02:58:27,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,201][root][INFO] - Training Epoch: 2/2, step 2935/7134 completed (loss: 0.11607449501752853, acc: 0.9629629850387573)
[2024-12-17 02:58:28,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,586][root][INFO] - Training Epoch: 2/2, step 2936/7134 completed (loss: 0.26647016406059265, acc: 0.9380530714988708)
[2024-12-17 02:58:28,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:28,971][root][INFO] - Training Epoch: 2/2, step 2937/7134 completed (loss: 0.2631699740886688, acc: 0.9191176295280457)
[2024-12-17 02:58:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,350][root][INFO] - Training Epoch: 2/2, step 2938/7134 completed (loss: 0.2056976556777954, acc: 0.9453551769256592)
[2024-12-17 02:58:29,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:29,740][root][INFO] - Training Epoch: 2/2, step 2939/7134 completed (loss: 0.12710292637348175, acc: 0.9801324605941772)
[2024-12-17 02:58:29,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,118][root][INFO] - Training Epoch: 2/2, step 2940/7134 completed (loss: 0.17693018913269043, acc: 0.9726775884628296)
[2024-12-17 02:58:30,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,481][root][INFO] - Training Epoch: 2/2, step 2941/7134 completed (loss: 0.20889444649219513, acc: 0.9382022619247437)
[2024-12-17 02:58:30,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:30,836][root][INFO] - Training Epoch: 2/2, step 2942/7134 completed (loss: 0.16063682734966278, acc: 0.9575757384300232)
[2024-12-17 02:58:30,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,278][root][INFO] - Training Epoch: 2/2, step 2943/7134 completed (loss: 0.16779522597789764, acc: 0.9459459185600281)
[2024-12-17 02:58:31,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:31,677][root][INFO] - Training Epoch: 2/2, step 2944/7134 completed (loss: 0.1898815780878067, acc: 0.9397590160369873)
[2024-12-17 02:58:31,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,133][root][INFO] - Training Epoch: 2/2, step 2945/7134 completed (loss: 0.2666497230529785, acc: 0.926174521446228)
[2024-12-17 02:58:32,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,527][root][INFO] - Training Epoch: 2/2, step 2946/7134 completed (loss: 0.28941693902015686, acc: 0.9444444179534912)
[2024-12-17 02:58:32,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:32,934][root][INFO] - Training Epoch: 2/2, step 2947/7134 completed (loss: 0.26947757601737976, acc: 0.9375)
[2024-12-17 02:58:33,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,343][root][INFO] - Training Epoch: 2/2, step 2948/7134 completed (loss: 0.317190021276474, acc: 0.9166666865348816)
[2024-12-17 02:58:33,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:33,740][root][INFO] - Training Epoch: 2/2, step 2949/7134 completed (loss: 0.09075389057397842, acc: 0.9803921580314636)
[2024-12-17 02:58:33,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,128][root][INFO] - Training Epoch: 2/2, step 2950/7134 completed (loss: 0.18087942898273468, acc: 0.9553072452545166)
[2024-12-17 02:58:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,498][root][INFO] - Training Epoch: 2/2, step 2951/7134 completed (loss: 0.13691270351409912, acc: 0.95652174949646)
[2024-12-17 02:58:34,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:34,844][root][INFO] - Training Epoch: 2/2, step 2952/7134 completed (loss: 0.11101140826940536, acc: 0.9808917045593262)
[2024-12-17 02:58:34,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,222][root][INFO] - Training Epoch: 2/2, step 2953/7134 completed (loss: 0.18783681094646454, acc: 0.9591836929321289)
[2024-12-17 02:58:35,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:35,658][root][INFO] - Training Epoch: 2/2, step 2954/7134 completed (loss: 0.1768811047077179, acc: 0.969072163105011)
[2024-12-17 02:58:35,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,018][root][INFO] - Training Epoch: 2/2, step 2955/7134 completed (loss: 0.16721045970916748, acc: 0.9575757384300232)
[2024-12-17 02:58:36,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,419][root][INFO] - Training Epoch: 2/2, step 2956/7134 completed (loss: 0.11966278403997421, acc: 0.9509202241897583)
[2024-12-17 02:58:36,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:36,815][root][INFO] - Training Epoch: 2/2, step 2957/7134 completed (loss: 0.10638535022735596, acc: 0.9655172228813171)
[2024-12-17 02:58:36,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,193][root][INFO] - Training Epoch: 2/2, step 2958/7134 completed (loss: 0.153367280960083, acc: 0.9791666865348816)
[2024-12-17 02:58:37,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,570][root][INFO] - Training Epoch: 2/2, step 2959/7134 completed (loss: 0.1277700811624527, acc: 0.9556962251663208)
[2024-12-17 02:58:37,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:37,968][root][INFO] - Training Epoch: 2/2, step 2960/7134 completed (loss: 0.1231842115521431, acc: 0.9725274443626404)
[2024-12-17 02:58:38,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,380][root][INFO] - Training Epoch: 2/2, step 2961/7134 completed (loss: 0.1707960069179535, acc: 0.9520958065986633)
[2024-12-17 02:58:38,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:38,755][root][INFO] - Training Epoch: 2/2, step 2962/7134 completed (loss: 0.13839423656463623, acc: 0.9583333134651184)
[2024-12-17 02:58:38,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,162][root][INFO] - Training Epoch: 2/2, step 2963/7134 completed (loss: 0.14067985117435455, acc: 0.9608938694000244)
[2024-12-17 02:58:39,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,559][root][INFO] - Training Epoch: 2/2, step 2964/7134 completed (loss: 0.07462028414011002, acc: 0.9800000190734863)
[2024-12-17 02:58:39,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:39,949][root][INFO] - Training Epoch: 2/2, step 2965/7134 completed (loss: 0.22399120032787323, acc: 0.9375)
[2024-12-17 02:58:40,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,358][root][INFO] - Training Epoch: 2/2, step 2966/7134 completed (loss: 0.056729190051555634, acc: 0.9829059839248657)
[2024-12-17 02:58:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:40,746][root][INFO] - Training Epoch: 2/2, step 2967/7134 completed (loss: 0.45205041766166687, acc: 0.8579235076904297)
[2024-12-17 02:58:40,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,146][root][INFO] - Training Epoch: 2/2, step 2968/7134 completed (loss: 0.5329563021659851, acc: 0.856249988079071)
[2024-12-17 02:58:41,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,553][root][INFO] - Training Epoch: 2/2, step 2969/7134 completed (loss: 1.297559380531311, acc: 0.7961165308952332)
[2024-12-17 02:58:41,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:41,971][root][INFO] - Training Epoch: 2/2, step 2970/7134 completed (loss: 1.2630239725112915, acc: 0.7686567306518555)
[2024-12-17 02:58:42,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,404][root][INFO] - Training Epoch: 2/2, step 2971/7134 completed (loss: 0.28920286893844604, acc: 0.9171270728111267)
[2024-12-17 02:58:42,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:42,793][root][INFO] - Training Epoch: 2/2, step 2972/7134 completed (loss: 0.3494766652584076, acc: 0.9066666960716248)
[2024-12-17 02:58:42,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,182][root][INFO] - Training Epoch: 2/2, step 2973/7134 completed (loss: 0.2294771671295166, acc: 0.939393937587738)
[2024-12-17 02:58:43,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,559][root][INFO] - Training Epoch: 2/2, step 2974/7134 completed (loss: 0.32070088386535645, acc: 0.9181286692619324)
[2024-12-17 02:58:43,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:43,918][root][INFO] - Training Epoch: 2/2, step 2975/7134 completed (loss: 0.23908361792564392, acc: 0.9418604373931885)
[2024-12-17 02:58:44,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,313][root][INFO] - Training Epoch: 2/2, step 2976/7134 completed (loss: 0.22701188921928406, acc: 0.948113203048706)
[2024-12-17 02:58:44,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:44,682][root][INFO] - Training Epoch: 2/2, step 2977/7134 completed (loss: 0.22259438037872314, acc: 0.931034505367279)
[2024-12-17 02:58:44,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,042][root][INFO] - Training Epoch: 2/2, step 2978/7134 completed (loss: 0.3013207018375397, acc: 0.9216867685317993)
[2024-12-17 02:58:45,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,418][root][INFO] - Training Epoch: 2/2, step 2979/7134 completed (loss: 0.2171148806810379, acc: 0.9448275566101074)
[2024-12-17 02:58:45,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:45,811][root][INFO] - Training Epoch: 2/2, step 2980/7134 completed (loss: 0.2897811532020569, acc: 0.9371428489685059)
[2024-12-17 02:58:45,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,232][root][INFO] - Training Epoch: 2/2, step 2981/7134 completed (loss: 0.3981207013130188, acc: 0.8908045887947083)
[2024-12-17 02:58:46,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,611][root][INFO] - Training Epoch: 2/2, step 2982/7134 completed (loss: 0.44325751066207886, acc: 0.8846153616905212)
[2024-12-17 02:58:46,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:46,997][root][INFO] - Training Epoch: 2/2, step 2983/7134 completed (loss: 0.2520088851451874, acc: 0.9447852969169617)
[2024-12-17 02:58:47,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,384][root][INFO] - Training Epoch: 2/2, step 2984/7134 completed (loss: 0.29236286878585815, acc: 0.9175823926925659)
[2024-12-17 02:58:47,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:47,753][root][INFO] - Training Epoch: 2/2, step 2985/7134 completed (loss: 0.15546371042728424, acc: 0.9609755873680115)
[2024-12-17 02:58:47,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,150][root][INFO] - Training Epoch: 2/2, step 2986/7134 completed (loss: 0.19631804525852203, acc: 0.9536082744598389)
[2024-12-17 02:58:48,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,553][root][INFO] - Training Epoch: 2/2, step 2987/7134 completed (loss: 0.2292478382587433, acc: 0.9402173757553101)
[2024-12-17 02:58:48,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:48,977][root][INFO] - Training Epoch: 2/2, step 2988/7134 completed (loss: 0.25455859303474426, acc: 0.9351351261138916)
[2024-12-17 02:58:49,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,357][root][INFO] - Training Epoch: 2/2, step 2989/7134 completed (loss: 0.19089451432228088, acc: 0.946107804775238)
[2024-12-17 02:58:49,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:49,720][root][INFO] - Training Epoch: 2/2, step 2990/7134 completed (loss: 0.4156865179538727, acc: 0.8986486196517944)
[2024-12-17 02:58:49,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,097][root][INFO] - Training Epoch: 2/2, step 2991/7134 completed (loss: 0.8721343874931335, acc: 0.796875)
[2024-12-17 02:58:50,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,453][root][INFO] - Training Epoch: 2/2, step 2992/7134 completed (loss: 0.3992287516593933, acc: 0.9245283007621765)
[2024-12-17 02:58:50,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:50,851][root][INFO] - Training Epoch: 2/2, step 2993/7134 completed (loss: 0.2456371933221817, acc: 0.9346733689308167)
[2024-12-17 02:58:50,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,211][root][INFO] - Training Epoch: 2/2, step 2994/7134 completed (loss: 0.146369069814682, acc: 0.9603174328804016)
[2024-12-17 02:58:51,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,586][root][INFO] - Training Epoch: 2/2, step 2995/7134 completed (loss: 0.1697555035352707, acc: 0.9417475461959839)
[2024-12-17 02:58:51,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:51,941][root][INFO] - Training Epoch: 2/2, step 2996/7134 completed (loss: 0.21527889370918274, acc: 0.9536082744598389)
[2024-12-17 02:58:52,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,313][root][INFO] - Training Epoch: 2/2, step 2997/7134 completed (loss: 0.09617817401885986, acc: 0.9811320900917053)
[2024-12-17 02:58:52,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:52,675][root][INFO] - Training Epoch: 2/2, step 2998/7134 completed (loss: 0.15568937361240387, acc: 0.976190447807312)
[2024-12-17 02:58:52,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,080][root][INFO] - Training Epoch: 2/2, step 2999/7134 completed (loss: 0.17126807570457458, acc: 0.949999988079071)
[2024-12-17 02:58:53,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,472][root][INFO] - Training Epoch: 2/2, step 3000/7134 completed (loss: 0.307229220867157, acc: 0.9166666865348816)
[2024-12-17 02:58:53,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:53,882][root][INFO] - Training Epoch: 2/2, step 3001/7134 completed (loss: 0.21438513696193695, acc: 0.9492385983467102)
[2024-12-17 02:58:54,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,297][root][INFO] - Training Epoch: 2/2, step 3002/7134 completed (loss: 0.2168068289756775, acc: 0.9539170265197754)
[2024-12-17 02:58:54,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:54,682][root][INFO] - Training Epoch: 2/2, step 3003/7134 completed (loss: 0.040814563632011414, acc: 0.9949238300323486)
[2024-12-17 02:58:54,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,079][root][INFO] - Training Epoch: 2/2, step 3004/7134 completed (loss: 0.0836377888917923, acc: 0.9801980257034302)
[2024-12-17 02:58:55,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,492][root][INFO] - Training Epoch: 2/2, step 3005/7134 completed (loss: 0.05216334015130997, acc: 0.9896373152732849)
[2024-12-17 02:58:55,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:55,881][root][INFO] - Training Epoch: 2/2, step 3006/7134 completed (loss: 0.072622150182724, acc: 0.9885714054107666)
[2024-12-17 02:58:56,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,275][root][INFO] - Training Epoch: 2/2, step 3007/7134 completed (loss: 0.17365926504135132, acc: 0.9593023061752319)
[2024-12-17 02:58:56,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:56,670][root][INFO] - Training Epoch: 2/2, step 3008/7134 completed (loss: 0.262669175863266, acc: 0.9319728016853333)
[2024-12-17 02:58:56,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,060][root][INFO] - Training Epoch: 2/2, step 3009/7134 completed (loss: 0.30992045998573303, acc: 0.9345238208770752)
[2024-12-17 02:58:57,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,438][root][INFO] - Training Epoch: 2/2, step 3010/7134 completed (loss: 0.1287030726671219, acc: 0.977142870426178)
[2024-12-17 02:58:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:57,801][root][INFO] - Training Epoch: 2/2, step 3011/7134 completed (loss: 0.5072081685066223, acc: 0.8969696760177612)
[2024-12-17 02:58:57,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,178][root][INFO] - Training Epoch: 2/2, step 3012/7134 completed (loss: 0.41465428471565247, acc: 0.9208633303642273)
[2024-12-17 02:58:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,589][root][INFO] - Training Epoch: 2/2, step 3013/7134 completed (loss: 0.07057718932628632, acc: 0.9825581312179565)
[2024-12-17 02:58:58,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:58,961][root][INFO] - Training Epoch: 2/2, step 3014/7134 completed (loss: 0.15262797474861145, acc: 0.9746835231781006)
[2024-12-17 02:58:59,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,339][root][INFO] - Training Epoch: 2/2, step 3015/7134 completed (loss: 0.11736968159675598, acc: 0.9647887349128723)
[2024-12-17 02:58:59,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:58:59,735][root][INFO] - Training Epoch: 2/2, step 3016/7134 completed (loss: 0.12221336364746094, acc: 0.9726027250289917)
[2024-12-17 02:58:59,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,134][root][INFO] - Training Epoch: 2/2, step 3017/7134 completed (loss: 0.09564758837223053, acc: 0.9752066135406494)
[2024-12-17 02:59:00,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,503][root][INFO] - Training Epoch: 2/2, step 3018/7134 completed (loss: 0.1165434867143631, acc: 0.9694656729698181)
[2024-12-17 02:59:00,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:00,872][root][INFO] - Training Epoch: 2/2, step 3019/7134 completed (loss: 0.15858769416809082, acc: 0.9558823704719543)
[2024-12-17 02:59:01,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,276][root][INFO] - Training Epoch: 2/2, step 3020/7134 completed (loss: 0.13922011852264404, acc: 0.971222996711731)
[2024-12-17 02:59:01,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:01,616][root][INFO] - Training Epoch: 2/2, step 3021/7134 completed (loss: 0.17301934957504272, acc: 0.9545454382896423)
[2024-12-17 02:59:01,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,020][root][INFO] - Training Epoch: 2/2, step 3022/7134 completed (loss: 0.15862780809402466, acc: 0.9624060392379761)
[2024-12-17 02:59:02,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,472][root][INFO] - Training Epoch: 2/2, step 3023/7134 completed (loss: 0.22059749066829681, acc: 0.9538461565971375)
[2024-12-17 02:59:02,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:02,928][root][INFO] - Training Epoch: 2/2, step 3024/7134 completed (loss: 0.18740174174308777, acc: 0.949999988079071)
[2024-12-17 02:59:03,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,320][root][INFO] - Training Epoch: 2/2, step 3025/7134 completed (loss: 0.24683059751987457, acc: 0.9538461565971375)
[2024-12-17 02:59:03,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:03,696][root][INFO] - Training Epoch: 2/2, step 3026/7134 completed (loss: 0.11758872121572495, acc: 0.9754098653793335)
[2024-12-17 02:59:03,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,076][root][INFO] - Training Epoch: 2/2, step 3027/7134 completed (loss: 0.2389822155237198, acc: 0.9479166865348816)
[2024-12-17 02:59:04,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,484][root][INFO] - Training Epoch: 2/2, step 3028/7134 completed (loss: 0.058070432394742966, acc: 1.0)
[2024-12-17 02:59:04,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:04,871][root][INFO] - Training Epoch: 2/2, step 3029/7134 completed (loss: 0.2434062957763672, acc: 0.9520547986030579)
[2024-12-17 02:59:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,265][root][INFO] - Training Epoch: 2/2, step 3030/7134 completed (loss: 0.17233802378177643, acc: 0.9594594836235046)
[2024-12-17 02:59:05,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:05,615][root][INFO] - Training Epoch: 2/2, step 3031/7134 completed (loss: 0.11245428025722504, acc: 0.9595959782600403)
[2024-12-17 02:59:05,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,023][root][INFO] - Training Epoch: 2/2, step 3032/7134 completed (loss: 0.1894112229347229, acc: 0.9435483813285828)
[2024-12-17 02:59:06,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,433][root][INFO] - Training Epoch: 2/2, step 3033/7134 completed (loss: 0.1307051181793213, acc: 0.9609375)
[2024-12-17 02:59:06,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:06,811][root][INFO] - Training Epoch: 2/2, step 3034/7134 completed (loss: 0.15598487854003906, acc: 0.9729729890823364)
[2024-12-17 02:59:06,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,219][root][INFO] - Training Epoch: 2/2, step 3035/7134 completed (loss: 0.1313590407371521, acc: 0.9591836929321289)
[2024-12-17 02:59:07,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:07,607][root][INFO] - Training Epoch: 2/2, step 3036/7134 completed (loss: 0.2732788026332855, acc: 0.9359999895095825)
[2024-12-17 02:59:07,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,008][root][INFO] - Training Epoch: 2/2, step 3037/7134 completed (loss: 0.1815444678068161, acc: 0.9597315192222595)
[2024-12-17 02:59:08,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,392][root][INFO] - Training Epoch: 2/2, step 3038/7134 completed (loss: 0.18864960968494415, acc: 0.9402984976768494)
[2024-12-17 02:59:08,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:08,782][root][INFO] - Training Epoch: 2/2, step 3039/7134 completed (loss: 0.11934330314397812, acc: 0.9662162065505981)
[2024-12-17 02:59:08,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,146][root][INFO] - Training Epoch: 2/2, step 3040/7134 completed (loss: 0.14408068358898163, acc: 0.961240291595459)
[2024-12-17 02:59:09,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,490][root][INFO] - Training Epoch: 2/2, step 3041/7134 completed (loss: 0.2947160601615906, acc: 0.9285714030265808)
[2024-12-17 02:59:09,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:09,868][root][INFO] - Training Epoch: 2/2, step 3042/7134 completed (loss: 0.10225085914134979, acc: 0.9743589758872986)
[2024-12-17 02:59:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,259][root][INFO] - Training Epoch: 2/2, step 3043/7134 completed (loss: 0.10929714888334274, acc: 0.9642857313156128)
[2024-12-17 02:59:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:10,699][root][INFO] - Training Epoch: 2/2, step 3044/7134 completed (loss: 0.1910713016986847, acc: 0.9624060392379761)
[2024-12-17 02:59:10,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,072][root][INFO] - Training Epoch: 2/2, step 3045/7134 completed (loss: 0.06759634613990784, acc: 0.9767441749572754)
[2024-12-17 02:59:11,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,459][root][INFO] - Training Epoch: 2/2, step 3046/7134 completed (loss: 0.143964022397995, acc: 0.9644970297813416)
[2024-12-17 02:59:11,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:11,823][root][INFO] - Training Epoch: 2/2, step 3047/7134 completed (loss: 0.19781994819641113, acc: 0.9491525292396545)
[2024-12-17 02:59:11,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,251][root][INFO] - Training Epoch: 2/2, step 3048/7134 completed (loss: 0.22046799957752228, acc: 0.9263157844543457)
[2024-12-17 02:59:12,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,620][root][INFO] - Training Epoch: 2/2, step 3049/7134 completed (loss: 0.2233954221010208, acc: 0.918749988079071)
[2024-12-17 02:59:12,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:12,984][root][INFO] - Training Epoch: 2/2, step 3050/7134 completed (loss: 0.19375161826610565, acc: 0.9289340376853943)
[2024-12-17 02:59:13,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,370][root][INFO] - Training Epoch: 2/2, step 3051/7134 completed (loss: 0.3349573314189911, acc: 0.9345238208770752)
[2024-12-17 02:59:13,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:13,734][root][INFO] - Training Epoch: 2/2, step 3052/7134 completed (loss: 0.16641652584075928, acc: 0.9621621370315552)
[2024-12-17 02:59:13,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,097][root][INFO] - Training Epoch: 2/2, step 3053/7134 completed (loss: 0.11395489424467087, acc: 0.9751243591308594)
[2024-12-17 02:59:14,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,489][root][INFO] - Training Epoch: 2/2, step 3054/7134 completed (loss: 0.06772871315479279, acc: 0.9840425252914429)
[2024-12-17 02:59:14,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:14,871][root][INFO] - Training Epoch: 2/2, step 3055/7134 completed (loss: 0.10531001538038254, acc: 0.9662162065505981)
[2024-12-17 02:59:14,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,242][root][INFO] - Training Epoch: 2/2, step 3056/7134 completed (loss: 0.09038825333118439, acc: 0.9729729890823364)
[2024-12-17 02:59:15,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:15,624][root][INFO] - Training Epoch: 2/2, step 3057/7134 completed (loss: 0.1265113800764084, acc: 0.9693251252174377)
[2024-12-17 02:59:15,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,013][root][INFO] - Training Epoch: 2/2, step 3058/7134 completed (loss: 0.262106716632843, acc: 0.9368420839309692)
[2024-12-17 02:59:16,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,393][root][INFO] - Training Epoch: 2/2, step 3059/7134 completed (loss: 0.045330822467803955, acc: 0.9828571677207947)
[2024-12-17 02:59:16,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:16,812][root][INFO] - Training Epoch: 2/2, step 3060/7134 completed (loss: 0.17580677568912506, acc: 0.9476439952850342)
[2024-12-17 02:59:16,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,195][root][INFO] - Training Epoch: 2/2, step 3061/7134 completed (loss: 0.13854612410068512, acc: 0.956250011920929)
[2024-12-17 02:59:17,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,548][root][INFO] - Training Epoch: 2/2, step 3062/7134 completed (loss: 0.07256857305765152, acc: 0.9748427867889404)
[2024-12-17 02:59:17,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:17,934][root][INFO] - Training Epoch: 2/2, step 3063/7134 completed (loss: 0.2287779450416565, acc: 0.9318181872367859)
[2024-12-17 02:59:18,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,299][root][INFO] - Training Epoch: 2/2, step 3064/7134 completed (loss: 0.08749783784151077, acc: 0.976331353187561)
[2024-12-17 02:59:18,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:18,688][root][INFO] - Training Epoch: 2/2, step 3065/7134 completed (loss: 0.05428112670779228, acc: 0.9887640476226807)
[2024-12-17 02:59:18,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,045][root][INFO] - Training Epoch: 2/2, step 3066/7134 completed (loss: 0.07372727245092392, acc: 0.9801324605941772)
[2024-12-17 02:59:19,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,389][root][INFO] - Training Epoch: 2/2, step 3067/7134 completed (loss: 0.1088980957865715, acc: 0.970588207244873)
[2024-12-17 02:59:19,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:19,763][root][INFO] - Training Epoch: 2/2, step 3068/7134 completed (loss: 0.19951719045639038, acc: 0.9441340565681458)
[2024-12-17 02:59:19,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,136][root][INFO] - Training Epoch: 2/2, step 3069/7134 completed (loss: 0.04759544879198074, acc: 0.9897959232330322)
[2024-12-17 02:59:20,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,531][root][INFO] - Training Epoch: 2/2, step 3070/7134 completed (loss: 0.0279013030230999, acc: 0.9952152967453003)
[2024-12-17 02:59:20,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:20,935][root][INFO] - Training Epoch: 2/2, step 3071/7134 completed (loss: 0.06317080557346344, acc: 0.9777777791023254)
[2024-12-17 02:59:21,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,309][root][INFO] - Training Epoch: 2/2, step 3072/7134 completed (loss: 0.08984123915433884, acc: 0.9812206625938416)
[2024-12-17 02:59:21,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:21,662][root][INFO] - Training Epoch: 2/2, step 3073/7134 completed (loss: 0.0797528475522995, acc: 0.9717513918876648)
[2024-12-17 02:59:21,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,047][root][INFO] - Training Epoch: 2/2, step 3074/7134 completed (loss: 0.0479993112385273, acc: 0.9933775067329407)
[2024-12-17 02:59:22,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,394][root][INFO] - Training Epoch: 2/2, step 3075/7134 completed (loss: 0.08776900172233582, acc: 0.9753086566925049)
[2024-12-17 02:59:22,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:22,765][root][INFO] - Training Epoch: 2/2, step 3076/7134 completed (loss: 0.1192774847149849, acc: 0.9784946441650391)
[2024-12-17 02:59:22,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,161][root][INFO] - Training Epoch: 2/2, step 3077/7134 completed (loss: 0.2738845646381378, acc: 0.9319371581077576)
[2024-12-17 02:59:23,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,542][root][INFO] - Training Epoch: 2/2, step 3078/7134 completed (loss: 0.16635605692863464, acc: 0.9427083134651184)
[2024-12-17 02:59:23,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:23,926][root][INFO] - Training Epoch: 2/2, step 3079/7134 completed (loss: 0.21292434632778168, acc: 0.9470899701118469)
[2024-12-17 02:59:24,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,300][root][INFO] - Training Epoch: 2/2, step 3080/7134 completed (loss: 0.24896033108234406, acc: 0.9351851940155029)
[2024-12-17 02:59:24,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:24,687][root][INFO] - Training Epoch: 2/2, step 3081/7134 completed (loss: 0.30488425493240356, acc: 0.9504950642585754)
[2024-12-17 02:59:24,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,050][root][INFO] - Training Epoch: 2/2, step 3082/7134 completed (loss: 0.43080654740333557, acc: 0.8756219148635864)
[2024-12-17 02:59:25,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,421][root][INFO] - Training Epoch: 2/2, step 3083/7134 completed (loss: 0.1996072232723236, acc: 0.9567567706108093)
[2024-12-17 02:59:25,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:25,791][root][INFO] - Training Epoch: 2/2, step 3084/7134 completed (loss: 0.31479310989379883, acc: 0.9214659929275513)
[2024-12-17 02:59:25,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,173][root][INFO] - Training Epoch: 2/2, step 3085/7134 completed (loss: 0.2979516386985779, acc: 0.9290322661399841)
[2024-12-17 02:59:26,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,574][root][INFO] - Training Epoch: 2/2, step 3086/7134 completed (loss: 0.2680819034576416, acc: 0.922374427318573)
[2024-12-17 02:59:26,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:26,935][root][INFO] - Training Epoch: 2/2, step 3087/7134 completed (loss: 0.16444213688373566, acc: 0.9467455744743347)
[2024-12-17 02:59:27,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,318][root][INFO] - Training Epoch: 2/2, step 3088/7134 completed (loss: 0.26884856820106506, acc: 0.9345794320106506)
[2024-12-17 02:59:27,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:27,712][root][INFO] - Training Epoch: 2/2, step 3089/7134 completed (loss: 0.18097585439682007, acc: 0.9534883499145508)
[2024-12-17 02:59:27,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,080][root][INFO] - Training Epoch: 2/2, step 3090/7134 completed (loss: 0.4580829441547394, acc: 0.887005627155304)
[2024-12-17 02:59:28,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,474][root][INFO] - Training Epoch: 2/2, step 3091/7134 completed (loss: 0.4661270081996918, acc: 0.8626609444618225)
[2024-12-17 02:59:28,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:28,841][root][INFO] - Training Epoch: 2/2, step 3092/7134 completed (loss: 0.44246014952659607, acc: 0.885496199131012)
[2024-12-17 02:59:28,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,182][root][INFO] - Training Epoch: 2/2, step 3093/7134 completed (loss: 0.2858147919178009, acc: 0.9295774698257446)
[2024-12-17 02:59:29,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,572][root][INFO] - Training Epoch: 2/2, step 3094/7134 completed (loss: 0.13606968522071838, acc: 0.9710982441902161)
[2024-12-17 02:59:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:29,959][root][INFO] - Training Epoch: 2/2, step 3095/7134 completed (loss: 0.2963417172431946, acc: 0.9388889074325562)
[2024-12-17 02:59:30,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,335][root][INFO] - Training Epoch: 2/2, step 3096/7134 completed (loss: 0.34747642278671265, acc: 0.8900523781776428)
[2024-12-17 02:59:30,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:30,706][root][INFO] - Training Epoch: 2/2, step 3097/7134 completed (loss: 0.26695677638053894, acc: 0.9207317233085632)
[2024-12-17 02:59:30,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,090][root][INFO] - Training Epoch: 2/2, step 3098/7134 completed (loss: 0.2020014524459839, acc: 0.9411764740943909)
[2024-12-17 02:59:31,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,465][root][INFO] - Training Epoch: 2/2, step 3099/7134 completed (loss: 0.168741837143898, acc: 0.9416058659553528)
[2024-12-17 02:59:31,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:31,847][root][INFO] - Training Epoch: 2/2, step 3100/7134 completed (loss: 0.13205359876155853, acc: 0.9641255736351013)
[2024-12-17 02:59:31,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,260][root][INFO] - Training Epoch: 2/2, step 3101/7134 completed (loss: 0.24868731200695038, acc: 0.9390863180160522)
[2024-12-17 02:59:32,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:32,649][root][INFO] - Training Epoch: 2/2, step 3102/7134 completed (loss: 0.1489405781030655, acc: 0.9570552110671997)
[2024-12-17 02:59:32,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,091][root][INFO] - Training Epoch: 2/2, step 3103/7134 completed (loss: 0.2333700954914093, acc: 0.943965494632721)
[2024-12-17 02:59:33,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,558][root][INFO] - Training Epoch: 2/2, step 3104/7134 completed (loss: 0.1305430680513382, acc: 0.9457364082336426)
[2024-12-17 02:59:33,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:33,946][root][INFO] - Training Epoch: 2/2, step 3105/7134 completed (loss: 0.2947317659854889, acc: 0.9130434989929199)
[2024-12-17 02:59:34,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,303][root][INFO] - Training Epoch: 2/2, step 3106/7134 completed (loss: 0.16116885840892792, acc: 0.9530201554298401)
[2024-12-17 02:59:34,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:34,664][root][INFO] - Training Epoch: 2/2, step 3107/7134 completed (loss: 0.11758261173963547, acc: 0.9709302186965942)
[2024-12-17 02:59:34,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,006][root][INFO] - Training Epoch: 2/2, step 3108/7134 completed (loss: 0.1366240531206131, acc: 0.9727891087532043)
[2024-12-17 02:59:35,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,374][root][INFO] - Training Epoch: 2/2, step 3109/7134 completed (loss: 0.23729769885540009, acc: 0.9307692050933838)
[2024-12-17 02:59:35,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:35,766][root][INFO] - Training Epoch: 2/2, step 3110/7134 completed (loss: 0.18354375660419464, acc: 0.9708737730979919)
[2024-12-17 02:59:35,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,161][root][INFO] - Training Epoch: 2/2, step 3111/7134 completed (loss: 0.5173730254173279, acc: 0.8695651888847351)
[2024-12-17 02:59:36,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,514][root][INFO] - Training Epoch: 2/2, step 3112/7134 completed (loss: 0.43487775325775146, acc: 0.8905109763145447)
[2024-12-17 02:59:36,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:36,889][root][INFO] - Training Epoch: 2/2, step 3113/7134 completed (loss: 0.20622888207435608, acc: 0.9634146094322205)
[2024-12-17 02:59:37,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,258][root][INFO] - Training Epoch: 2/2, step 3114/7134 completed (loss: 0.2657245397567749, acc: 0.9548872113227844)
[2024-12-17 02:59:37,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,609][root][INFO] - Training Epoch: 2/2, step 3115/7134 completed (loss: 0.17002375423908234, acc: 0.9736841917037964)
[2024-12-17 02:59:37,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:37,967][root][INFO] - Training Epoch: 2/2, step 3116/7134 completed (loss: 0.2936478555202484, acc: 0.9378530979156494)
[2024-12-17 02:59:38,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,329][root][INFO] - Training Epoch: 2/2, step 3117/7134 completed (loss: 0.30488231778144836, acc: 0.9269663095474243)
[2024-12-17 02:59:38,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:38,711][root][INFO] - Training Epoch: 2/2, step 3118/7134 completed (loss: 0.24313539266586304, acc: 0.939226508140564)
[2024-12-17 02:59:38,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,059][root][INFO] - Training Epoch: 2/2, step 3119/7134 completed (loss: 0.18341509997844696, acc: 0.9523809552192688)
[2024-12-17 02:59:39,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,415][root][INFO] - Training Epoch: 2/2, step 3120/7134 completed (loss: 0.34806180000305176, acc: 0.9382715821266174)
[2024-12-17 02:59:39,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:39,775][root][INFO] - Training Epoch: 2/2, step 3121/7134 completed (loss: 0.18388432264328003, acc: 0.9602272510528564)
[2024-12-17 02:59:39,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,152][root][INFO] - Training Epoch: 2/2, step 3122/7134 completed (loss: 0.20552311837673187, acc: 0.9210526347160339)
[2024-12-17 02:59:40,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,532][root][INFO] - Training Epoch: 2/2, step 3123/7134 completed (loss: 0.19837649166584015, acc: 0.929729700088501)
[2024-12-17 02:59:40,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:40,888][root][INFO] - Training Epoch: 2/2, step 3124/7134 completed (loss: 0.30194714665412903, acc: 0.9166666865348816)
[2024-12-17 02:59:41,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,277][root][INFO] - Training Epoch: 2/2, step 3125/7134 completed (loss: 0.1230790913105011, acc: 0.9795918464660645)
[2024-12-17 02:59:41,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:41,667][root][INFO] - Training Epoch: 2/2, step 3126/7134 completed (loss: 0.2813339829444885, acc: 0.9385474920272827)
[2024-12-17 02:59:41,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,041][root][INFO] - Training Epoch: 2/2, step 3127/7134 completed (loss: 0.18290862441062927, acc: 0.9436619877815247)
[2024-12-17 02:59:42,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,431][root][INFO] - Training Epoch: 2/2, step 3128/7134 completed (loss: 0.17629805207252502, acc: 0.9786096215248108)
[2024-12-17 02:59:42,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:42,812][root][INFO] - Training Epoch: 2/2, step 3129/7134 completed (loss: 0.18280939757823944, acc: 0.9431818127632141)
[2024-12-17 02:59:42,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,243][root][INFO] - Training Epoch: 2/2, step 3130/7134 completed (loss: 0.11556292325258255, acc: 0.9695431590080261)
[2024-12-17 02:59:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,622][root][INFO] - Training Epoch: 2/2, step 3131/7134 completed (loss: 0.2892959415912628, acc: 0.9322034120559692)
[2024-12-17 02:59:43,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:43,977][root][INFO] - Training Epoch: 2/2, step 3132/7134 completed (loss: 0.0740944966673851, acc: 0.991150438785553)
[2024-12-17 02:59:44,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,361][root][INFO] - Training Epoch: 2/2, step 3133/7134 completed (loss: 0.4031095504760742, acc: 0.9261363744735718)
[2024-12-17 02:59:44,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:44,737][root][INFO] - Training Epoch: 2/2, step 3134/7134 completed (loss: 0.21858206391334534, acc: 0.9375)
[2024-12-17 02:59:44,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,115][root][INFO] - Training Epoch: 2/2, step 3135/7134 completed (loss: 0.18342189490795135, acc: 0.938144326210022)
[2024-12-17 02:59:45,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,497][root][INFO] - Training Epoch: 2/2, step 3136/7134 completed (loss: 0.22301802039146423, acc: 0.9389312863349915)
[2024-12-17 02:59:45,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:45,868][root][INFO] - Training Epoch: 2/2, step 3137/7134 completed (loss: 0.3142705261707306, acc: 0.914893627166748)
[2024-12-17 02:59:45,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,241][root][INFO] - Training Epoch: 2/2, step 3138/7134 completed (loss: 0.31496739387512207, acc: 0.9111111164093018)
[2024-12-17 02:59:46,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,609][root][INFO] - Training Epoch: 2/2, step 3139/7134 completed (loss: 0.3542522192001343, acc: 0.9136690497398376)
[2024-12-17 02:59:46,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:46,987][root][INFO] - Training Epoch: 2/2, step 3140/7134 completed (loss: 0.21851740777492523, acc: 0.9452054500579834)
[2024-12-17 02:59:47,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,355][root][INFO] - Training Epoch: 2/2, step 3141/7134 completed (loss: 0.2299034744501114, acc: 0.9527027010917664)
[2024-12-17 02:59:47,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:47,738][root][INFO] - Training Epoch: 2/2, step 3142/7134 completed (loss: 0.14300964772701263, acc: 0.9520958065986633)
[2024-12-17 02:59:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,131][root][INFO] - Training Epoch: 2/2, step 3143/7134 completed (loss: 0.21665851771831512, acc: 0.9290322661399841)
[2024-12-17 02:59:48,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,504][root][INFO] - Training Epoch: 2/2, step 3144/7134 completed (loss: 0.2670596241950989, acc: 0.942307710647583)
[2024-12-17 02:59:48,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:48,859][root][INFO] - Training Epoch: 2/2, step 3145/7134 completed (loss: 0.17545528709888458, acc: 0.954954981803894)
[2024-12-17 02:59:48,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,200][root][INFO] - Training Epoch: 2/2, step 3146/7134 completed (loss: 0.22441351413726807, acc: 0.9494949579238892)
[2024-12-17 02:59:49,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,554][root][INFO] - Training Epoch: 2/2, step 3147/7134 completed (loss: 0.18817049264907837, acc: 0.9726027250289917)
[2024-12-17 02:59:49,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:49,951][root][INFO] - Training Epoch: 2/2, step 3148/7134 completed (loss: 0.1687265783548355, acc: 0.9720670580863953)
[2024-12-17 02:59:50,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,312][root][INFO] - Training Epoch: 2/2, step 3149/7134 completed (loss: 0.08544915169477463, acc: 0.9935483932495117)
[2024-12-17 02:59:50,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:50,687][root][INFO] - Training Epoch: 2/2, step 3150/7134 completed (loss: 0.8367776870727539, acc: 0.8071428537368774)
[2024-12-17 02:59:50,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,058][root][INFO] - Training Epoch: 2/2, step 3151/7134 completed (loss: 0.5133231282234192, acc: 0.885496199131012)
[2024-12-17 02:59:51,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,416][root][INFO] - Training Epoch: 2/2, step 3152/7134 completed (loss: 0.20834411680698395, acc: 0.9436619877815247)
[2024-12-17 02:59:51,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:51,780][root][INFO] - Training Epoch: 2/2, step 3153/7134 completed (loss: 0.1592755764722824, acc: 0.966292142868042)
[2024-12-17 02:59:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,176][root][INFO] - Training Epoch: 2/2, step 3154/7134 completed (loss: 0.31535059213638306, acc: 0.9398496150970459)
[2024-12-17 02:59:52,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,536][root][INFO] - Training Epoch: 2/2, step 3155/7134 completed (loss: 0.5244317650794983, acc: 0.8947368264198303)
[2024-12-17 02:59:52,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:52,924][root][INFO] - Training Epoch: 2/2, step 3156/7134 completed (loss: 0.40163829922676086, acc: 0.9186046719551086)
[2024-12-17 02:59:53,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,289][root][INFO] - Training Epoch: 2/2, step 3157/7134 completed (loss: 0.3414156138896942, acc: 0.9217391014099121)
[2024-12-17 02:59:53,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:53,739][root][INFO] - Training Epoch: 2/2, step 3158/7134 completed (loss: 0.17715542018413544, acc: 0.957446813583374)
[2024-12-17 02:59:53,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,116][root][INFO] - Training Epoch: 2/2, step 3159/7134 completed (loss: 0.24986685812473297, acc: 0.9484536051750183)
[2024-12-17 02:59:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,493][root][INFO] - Training Epoch: 2/2, step 3160/7134 completed (loss: 0.11973515897989273, acc: 0.9679487347602844)
[2024-12-17 02:59:54,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:54,888][root][INFO] - Training Epoch: 2/2, step 3161/7134 completed (loss: 0.19854934513568878, acc: 0.9617834687232971)
[2024-12-17 02:59:55,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,274][root][INFO] - Training Epoch: 2/2, step 3162/7134 completed (loss: 0.0889957994222641, acc: 0.9931507110595703)
[2024-12-17 02:59:55,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:55,640][root][INFO] - Training Epoch: 2/2, step 3163/7134 completed (loss: 0.1412009447813034, acc: 0.9672130942344666)
[2024-12-17 02:59:55,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,008][root][INFO] - Training Epoch: 2/2, step 3164/7134 completed (loss: 0.30989357829093933, acc: 0.95652174949646)
[2024-12-17 02:59:56,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,379][root][INFO] - Training Epoch: 2/2, step 3165/7134 completed (loss: 0.19974961876869202, acc: 0.9300699234008789)
[2024-12-17 02:59:56,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:56,763][root][INFO] - Training Epoch: 2/2, step 3166/7134 completed (loss: 0.32829907536506653, acc: 0.9177215099334717)
[2024-12-17 02:59:56,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,158][root][INFO] - Training Epoch: 2/2, step 3167/7134 completed (loss: 0.35697054862976074, acc: 0.9012345671653748)
[2024-12-17 02:59:57,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,530][root][INFO] - Training Epoch: 2/2, step 3168/7134 completed (loss: 0.3713099956512451, acc: 0.9084967374801636)
[2024-12-17 02:59:57,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:57,899][root][INFO] - Training Epoch: 2/2, step 3169/7134 completed (loss: 0.2528187036514282, acc: 0.9262295365333557)
[2024-12-17 02:59:58,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,283][root][INFO] - Training Epoch: 2/2, step 3170/7134 completed (loss: 0.24156062304973602, acc: 0.9191176295280457)
[2024-12-17 02:59:58,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:58,672][root][INFO] - Training Epoch: 2/2, step 3171/7134 completed (loss: 0.19940805435180664, acc: 0.9395604133605957)
[2024-12-17 02:59:58,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,031][root][INFO] - Training Epoch: 2/2, step 3172/7134 completed (loss: 0.10541881620883942, acc: 0.9682539701461792)
[2024-12-17 02:59:59,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,430][root][INFO] - Training Epoch: 2/2, step 3173/7134 completed (loss: 0.14844287931919098, acc: 0.9696969985961914)
[2024-12-17 02:59:59,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 02:59:59,830][root][INFO] - Training Epoch: 2/2, step 3174/7134 completed (loss: 0.27571621537208557, acc: 0.9397590160369873)
[2024-12-17 02:59:59,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,201][root][INFO] - Training Epoch: 2/2, step 3175/7134 completed (loss: 0.20379702746868134, acc: 0.9476743936538696)
[2024-12-17 03:00:00,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,589][root][INFO] - Training Epoch: 2/2, step 3176/7134 completed (loss: 0.3599715232849121, acc: 0.9011628031730652)
[2024-12-17 03:00:00,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:00,978][root][INFO] - Training Epoch: 2/2, step 3177/7134 completed (loss: 0.2675347328186035, acc: 0.9506173133850098)
[2024-12-17 03:00:01,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,339][root][INFO] - Training Epoch: 2/2, step 3178/7134 completed (loss: 0.19329561293125153, acc: 0.9466666579246521)
[2024-12-17 03:00:01,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:01,704][root][INFO] - Training Epoch: 2/2, step 3179/7134 completed (loss: 0.28154152631759644, acc: 0.9642857313156128)
[2024-12-17 03:00:01,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,051][root][INFO] - Training Epoch: 2/2, step 3180/7134 completed (loss: 0.1820918768644333, acc: 0.9691358208656311)
[2024-12-17 03:00:02,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,425][root][INFO] - Training Epoch: 2/2, step 3181/7134 completed (loss: 0.3135426938533783, acc: 0.9281768202781677)
[2024-12-17 03:00:02,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:02,782][root][INFO] - Training Epoch: 2/2, step 3182/7134 completed (loss: 0.22257137298583984, acc: 0.957317054271698)
[2024-12-17 03:00:02,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,133][root][INFO] - Training Epoch: 2/2, step 3183/7134 completed (loss: 0.26638951897621155, acc: 0.9416058659553528)
[2024-12-17 03:00:03,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,500][root][INFO] - Training Epoch: 2/2, step 3184/7134 completed (loss: 0.20453748106956482, acc: 0.96875)
[2024-12-17 03:00:03,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:03,863][root][INFO] - Training Epoch: 2/2, step 3185/7134 completed (loss: 0.07850822061300278, acc: 0.9811320900917053)
[2024-12-17 03:00:03,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,280][root][INFO] - Training Epoch: 2/2, step 3186/7134 completed (loss: 0.1597430258989334, acc: 0.9487179517745972)
[2024-12-17 03:00:04,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:04,667][root][INFO] - Training Epoch: 2/2, step 3187/7134 completed (loss: 0.19107182323932648, acc: 0.9357143044471741)
[2024-12-17 03:00:04,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,051][root][INFO] - Training Epoch: 2/2, step 3188/7134 completed (loss: 0.12981286644935608, acc: 0.9664804339408875)
[2024-12-17 03:00:05,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,419][root][INFO] - Training Epoch: 2/2, step 3189/7134 completed (loss: 0.1569105088710785, acc: 0.9567901492118835)
[2024-12-17 03:00:05,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:05,804][root][INFO] - Training Epoch: 2/2, step 3190/7134 completed (loss: 0.20028476417064667, acc: 0.9624999761581421)
[2024-12-17 03:00:05,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,155][root][INFO] - Training Epoch: 2/2, step 3191/7134 completed (loss: 0.096689373254776, acc: 0.9875776171684265)
[2024-12-17 03:00:06,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,526][root][INFO] - Training Epoch: 2/2, step 3192/7134 completed (loss: 0.3647214472293854, acc: 0.9124087691307068)
[2024-12-17 03:00:06,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:06,915][root][INFO] - Training Epoch: 2/2, step 3193/7134 completed (loss: 0.26187968254089355, acc: 0.929729700088501)
[2024-12-17 03:00:07,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,283][root][INFO] - Training Epoch: 2/2, step 3194/7134 completed (loss: 0.30287155508995056, acc: 0.9212121367454529)
[2024-12-17 03:00:07,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:07,637][root][INFO] - Training Epoch: 2/2, step 3195/7134 completed (loss: 0.3345753252506256, acc: 0.9068322777748108)
[2024-12-17 03:00:07,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,015][root][INFO] - Training Epoch: 2/2, step 3196/7134 completed (loss: 0.14413900673389435, acc: 0.9637681245803833)
[2024-12-17 03:00:08,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,376][root][INFO] - Training Epoch: 2/2, step 3197/7134 completed (loss: 0.23316748440265656, acc: 0.9341317415237427)
[2024-12-17 03:00:08,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:08,753][root][INFO] - Training Epoch: 2/2, step 3198/7134 completed (loss: 0.18732818961143494, acc: 0.9437500238418579)
[2024-12-17 03:00:08,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,149][root][INFO] - Training Epoch: 2/2, step 3199/7134 completed (loss: 0.11289416998624802, acc: 0.9767441749572754)
[2024-12-17 03:00:09,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,525][root][INFO] - Training Epoch: 2/2, step 3200/7134 completed (loss: 0.19526968896389008, acc: 0.9503546357154846)
[2024-12-17 03:00:09,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:09,926][root][INFO] - Training Epoch: 2/2, step 3201/7134 completed (loss: 0.3743093013763428, acc: 0.9212598204612732)
[2024-12-17 03:00:10,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,296][root][INFO] - Training Epoch: 2/2, step 3202/7134 completed (loss: 0.18077464401721954, acc: 0.949438214302063)
[2024-12-17 03:00:10,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:10,637][root][INFO] - Training Epoch: 2/2, step 3203/7134 completed (loss: 0.19315344095230103, acc: 0.949999988079071)
[2024-12-17 03:00:10,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,025][root][INFO] - Training Epoch: 2/2, step 3204/7134 completed (loss: 0.1614864617586136, acc: 0.965753436088562)
[2024-12-17 03:00:11,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,397][root][INFO] - Training Epoch: 2/2, step 3205/7134 completed (loss: 0.1268666684627533, acc: 0.9645389914512634)
[2024-12-17 03:00:11,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:11,800][root][INFO] - Training Epoch: 2/2, step 3206/7134 completed (loss: 0.17032049596309662, acc: 0.9454545378684998)
[2024-12-17 03:00:11,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,170][root][INFO] - Training Epoch: 2/2, step 3207/7134 completed (loss: 0.2163664698600769, acc: 0.9386503100395203)
[2024-12-17 03:00:12,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,563][root][INFO] - Training Epoch: 2/2, step 3208/7134 completed (loss: 0.14636217057704926, acc: 0.9640287756919861)
[2024-12-17 03:00:12,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:12,946][root][INFO] - Training Epoch: 2/2, step 3209/7134 completed (loss: 0.15619215369224548, acc: 0.9624999761581421)
[2024-12-17 03:00:13,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,351][root][INFO] - Training Epoch: 2/2, step 3210/7134 completed (loss: 0.11754009127616882, acc: 0.9677419066429138)
[2024-12-17 03:00:13,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:13,730][root][INFO] - Training Epoch: 2/2, step 3211/7134 completed (loss: 0.19710135459899902, acc: 0.9495798349380493)
[2024-12-17 03:00:13,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,118][root][INFO] - Training Epoch: 2/2, step 3212/7134 completed (loss: 0.15493106842041016, acc: 0.9590643048286438)
[2024-12-17 03:00:14,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,506][root][INFO] - Training Epoch: 2/2, step 3213/7134 completed (loss: 0.2264781892299652, acc: 0.9523809552192688)
[2024-12-17 03:00:14,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:14,898][root][INFO] - Training Epoch: 2/2, step 3214/7134 completed (loss: 0.18574930727481842, acc: 0.9649122953414917)
[2024-12-17 03:00:15,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,277][root][INFO] - Training Epoch: 2/2, step 3215/7134 completed (loss: 0.1299898475408554, acc: 0.9585798978805542)
[2024-12-17 03:00:15,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:15,657][root][INFO] - Training Epoch: 2/2, step 3216/7134 completed (loss: 0.2476842701435089, acc: 0.9444444179534912)
[2024-12-17 03:00:15,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,049][root][INFO] - Training Epoch: 2/2, step 3217/7134 completed (loss: 0.1613299697637558, acc: 0.966292142868042)
[2024-12-17 03:00:16,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,411][root][INFO] - Training Epoch: 2/2, step 3218/7134 completed (loss: 0.12025637179613113, acc: 0.9677419066429138)
[2024-12-17 03:00:16,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:16,788][root][INFO] - Training Epoch: 2/2, step 3219/7134 completed (loss: 0.24075673520565033, acc: 0.9047619104385376)
[2024-12-17 03:00:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,161][root][INFO] - Training Epoch: 2/2, step 3220/7134 completed (loss: 0.15705052018165588, acc: 0.9491525292396545)
[2024-12-17 03:00:17,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,532][root][INFO] - Training Epoch: 2/2, step 3221/7134 completed (loss: 0.15025824308395386, acc: 0.9569892287254333)
[2024-12-17 03:00:17,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:17,899][root][INFO] - Training Epoch: 2/2, step 3222/7134 completed (loss: 0.2803327143192291, acc: 0.9104477763175964)
[2024-12-17 03:00:18,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,285][root][INFO] - Training Epoch: 2/2, step 3223/7134 completed (loss: 0.3239183723926544, acc: 0.9263803958892822)
[2024-12-17 03:00:18,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:18,681][root][INFO] - Training Epoch: 2/2, step 3224/7134 completed (loss: 0.31657397747039795, acc: 0.9190751314163208)
[2024-12-17 03:00:18,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,067][root][INFO] - Training Epoch: 2/2, step 3225/7134 completed (loss: 0.12644033133983612, acc: 0.9549999833106995)
[2024-12-17 03:00:19,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,442][root][INFO] - Training Epoch: 2/2, step 3226/7134 completed (loss: 0.2293066531419754, acc: 0.9337748289108276)
[2024-12-17 03:00:19,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:19,836][root][INFO] - Training Epoch: 2/2, step 3227/7134 completed (loss: 0.31889188289642334, acc: 0.9300411343574524)
[2024-12-17 03:00:19,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,226][root][INFO] - Training Epoch: 2/2, step 3228/7134 completed (loss: 0.18230897188186646, acc: 0.9444444179534912)
[2024-12-17 03:00:20,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:20,646][root][INFO] - Training Epoch: 2/2, step 3229/7134 completed (loss: 0.2701423764228821, acc: 0.9444444179534912)
[2024-12-17 03:00:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,063][root][INFO] - Training Epoch: 2/2, step 3230/7134 completed (loss: 0.16332778334617615, acc: 0.949999988079071)
[2024-12-17 03:00:21,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,470][root][INFO] - Training Epoch: 2/2, step 3231/7134 completed (loss: 0.3899518847465515, acc: 0.901098906993866)
[2024-12-17 03:00:21,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:21,849][root][INFO] - Training Epoch: 2/2, step 3232/7134 completed (loss: 0.09600996971130371, acc: 0.9768518805503845)
[2024-12-17 03:00:21,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,222][root][INFO] - Training Epoch: 2/2, step 3233/7134 completed (loss: 0.3089720904827118, acc: 0.9291338324546814)
[2024-12-17 03:00:22,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,590][root][INFO] - Training Epoch: 2/2, step 3234/7134 completed (loss: 0.14788846671581268, acc: 0.9622641801834106)
[2024-12-17 03:00:22,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:22,961][root][INFO] - Training Epoch: 2/2, step 3235/7134 completed (loss: 0.1488310694694519, acc: 0.957446813583374)
[2024-12-17 03:00:23,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,332][root][INFO] - Training Epoch: 2/2, step 3236/7134 completed (loss: 0.2648877799510956, acc: 0.9265536665916443)
[2024-12-17 03:00:23,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:23,711][root][INFO] - Training Epoch: 2/2, step 3237/7134 completed (loss: 0.2149973213672638, acc: 0.9545454382896423)
[2024-12-17 03:00:23,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,117][root][INFO] - Training Epoch: 2/2, step 3238/7134 completed (loss: 0.19242940843105316, acc: 0.9388889074325562)
[2024-12-17 03:00:24,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,506][root][INFO] - Training Epoch: 2/2, step 3239/7134 completed (loss: 0.11407493054866791, acc: 0.9695122241973877)
[2024-12-17 03:00:24,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:24,891][root][INFO] - Training Epoch: 2/2, step 3240/7134 completed (loss: 0.10577674210071564, acc: 0.9497206807136536)
[2024-12-17 03:00:25,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,271][root][INFO] - Training Epoch: 2/2, step 3241/7134 completed (loss: 0.14007484912872314, acc: 0.9647058844566345)
[2024-12-17 03:00:25,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,619][root][INFO] - Training Epoch: 2/2, step 3242/7134 completed (loss: 0.051131706684827805, acc: 0.9870129823684692)
[2024-12-17 03:00:25,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:25,992][root][INFO] - Training Epoch: 2/2, step 3243/7134 completed (loss: 0.10782255232334137, acc: 0.9786096215248108)
[2024-12-17 03:00:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,355][root][INFO] - Training Epoch: 2/2, step 3244/7134 completed (loss: 0.17720931768417358, acc: 0.9595375657081604)
[2024-12-17 03:00:26,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:26,744][root][INFO] - Training Epoch: 2/2, step 3245/7134 completed (loss: 0.16190825402736664, acc: 0.9589743614196777)
[2024-12-17 03:00:26,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,137][root][INFO] - Training Epoch: 2/2, step 3246/7134 completed (loss: 0.17604340612888336, acc: 0.9589743614196777)
[2024-12-17 03:00:27,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,547][root][INFO] - Training Epoch: 2/2, step 3247/7134 completed (loss: 0.10599979758262634, acc: 0.9807692170143127)
[2024-12-17 03:00:27,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:27,928][root][INFO] - Training Epoch: 2/2, step 3248/7134 completed (loss: 0.09792473912239075, acc: 0.985401451587677)
[2024-12-17 03:00:28,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,293][root][INFO] - Training Epoch: 2/2, step 3249/7134 completed (loss: 0.10161334276199341, acc: 0.9704142212867737)
[2024-12-17 03:00:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:28,685][root][INFO] - Training Epoch: 2/2, step 3250/7134 completed (loss: 0.23866546154022217, acc: 0.9580838084220886)
[2024-12-17 03:00:28,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,061][root][INFO] - Training Epoch: 2/2, step 3251/7134 completed (loss: 0.15020541846752167, acc: 0.9551281929016113)
[2024-12-17 03:00:29,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,436][root][INFO] - Training Epoch: 2/2, step 3252/7134 completed (loss: 0.06263799220323563, acc: 0.9879518151283264)
[2024-12-17 03:00:29,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:29,806][root][INFO] - Training Epoch: 2/2, step 3253/7134 completed (loss: 0.0985567718744278, acc: 0.9736841917037964)
[2024-12-17 03:00:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,187][root][INFO] - Training Epoch: 2/2, step 3254/7134 completed (loss: 0.1317109316587448, acc: 0.9610389471054077)
[2024-12-17 03:00:30,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,586][root][INFO] - Training Epoch: 2/2, step 3255/7134 completed (loss: 0.1681201308965683, acc: 0.9659090638160706)
[2024-12-17 03:00:30,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:30,953][root][INFO] - Training Epoch: 2/2, step 3256/7134 completed (loss: 0.11415857076644897, acc: 0.9751552939414978)
[2024-12-17 03:00:31,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,331][root][INFO] - Training Epoch: 2/2, step 3257/7134 completed (loss: 0.2732224762439728, acc: 0.9515151381492615)
[2024-12-17 03:00:31,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:31,709][root][INFO] - Training Epoch: 2/2, step 3258/7134 completed (loss: 0.3909599781036377, acc: 0.9186992049217224)
[2024-12-17 03:00:31,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,077][root][INFO] - Training Epoch: 2/2, step 3259/7134 completed (loss: 0.21474669873714447, acc: 0.9192546606063843)
[2024-12-17 03:00:32,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,433][root][INFO] - Training Epoch: 2/2, step 3260/7134 completed (loss: 0.3223629891872406, acc: 0.9586206674575806)
[2024-12-17 03:00:32,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:32,807][root][INFO] - Training Epoch: 2/2, step 3261/7134 completed (loss: 0.27783986926078796, acc: 0.9197080135345459)
[2024-12-17 03:00:32,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,157][root][INFO] - Training Epoch: 2/2, step 3262/7134 completed (loss: 0.20900782942771912, acc: 0.9506173133850098)
[2024-12-17 03:00:33,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,558][root][INFO] - Training Epoch: 2/2, step 3263/7134 completed (loss: 0.28870517015457153, acc: 0.9467455744743347)
[2024-12-17 03:00:33,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:33,919][root][INFO] - Training Epoch: 2/2, step 3264/7134 completed (loss: 0.2404177188873291, acc: 0.9268292784690857)
[2024-12-17 03:00:34,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,291][root][INFO] - Training Epoch: 2/2, step 3265/7134 completed (loss: 0.22285708785057068, acc: 0.9426751732826233)
[2024-12-17 03:00:34,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:34,634][root][INFO] - Training Epoch: 2/2, step 3266/7134 completed (loss: 0.2432987540960312, acc: 0.9448275566101074)
[2024-12-17 03:00:34,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,005][root][INFO] - Training Epoch: 2/2, step 3267/7134 completed (loss: 0.21462777256965637, acc: 0.939393937587738)
[2024-12-17 03:00:35,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,399][root][INFO] - Training Epoch: 2/2, step 3268/7134 completed (loss: 0.17012032866477966, acc: 0.965753436088562)
[2024-12-17 03:00:35,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:35,769][root][INFO] - Training Epoch: 2/2, step 3269/7134 completed (loss: 0.1752760261297226, acc: 0.9521276354789734)
[2024-12-17 03:00:35,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,152][root][INFO] - Training Epoch: 2/2, step 3270/7134 completed (loss: 0.11041434109210968, acc: 0.9729729890823364)
[2024-12-17 03:00:36,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,535][root][INFO] - Training Epoch: 2/2, step 3271/7134 completed (loss: 0.1141834408044815, acc: 0.98591548204422)
[2024-12-17 03:00:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:36,919][root][INFO] - Training Epoch: 2/2, step 3272/7134 completed (loss: 0.1165032833814621, acc: 0.9666666388511658)
[2024-12-17 03:00:37,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,302][root][INFO] - Training Epoch: 2/2, step 3273/7134 completed (loss: 0.1089688092470169, acc: 0.977142870426178)
[2024-12-17 03:00:37,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:37,691][root][INFO] - Training Epoch: 2/2, step 3274/7134 completed (loss: 0.22162041068077087, acc: 0.9503105878829956)
[2024-12-17 03:00:37,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,070][root][INFO] - Training Epoch: 2/2, step 3275/7134 completed (loss: 0.6743133068084717, acc: 0.8682634830474854)
[2024-12-17 03:00:38,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,454][root][INFO] - Training Epoch: 2/2, step 3276/7134 completed (loss: 0.24906612932682037, acc: 0.9411764740943909)
[2024-12-17 03:00:38,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:38,828][root][INFO] - Training Epoch: 2/2, step 3277/7134 completed (loss: 0.23633460700511932, acc: 0.9640287756919861)
[2024-12-17 03:00:38,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,164][root][INFO] - Training Epoch: 2/2, step 3278/7134 completed (loss: 0.3358626067638397, acc: 0.9193548560142517)
[2024-12-17 03:00:39,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,526][root][INFO] - Training Epoch: 2/2, step 3279/7134 completed (loss: 0.251670241355896, acc: 0.9411764740943909)
[2024-12-17 03:00:39,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:39,861][root][INFO] - Training Epoch: 2/2, step 3280/7134 completed (loss: 0.48150840401649475, acc: 0.875)
[2024-12-17 03:00:39,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,234][root][INFO] - Training Epoch: 2/2, step 3281/7134 completed (loss: 0.24755358695983887, acc: 0.9523809552192688)
[2024-12-17 03:00:40,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,566][root][INFO] - Training Epoch: 2/2, step 3282/7134 completed (loss: 0.15647386014461517, acc: 0.9618320465087891)
[2024-12-17 03:00:40,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:40,912][root][INFO] - Training Epoch: 2/2, step 3283/7134 completed (loss: 0.16553081572055817, acc: 0.9411764740943909)
[2024-12-17 03:00:41,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,294][root][INFO] - Training Epoch: 2/2, step 3284/7134 completed (loss: 0.18617641925811768, acc: 0.9724137783050537)
[2024-12-17 03:00:41,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,630][root][INFO] - Training Epoch: 2/2, step 3285/7134 completed (loss: 0.2781118154525757, acc: 0.9264705777168274)
[2024-12-17 03:00:41,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:41,995][root][INFO] - Training Epoch: 2/2, step 3286/7134 completed (loss: 0.17334946990013123, acc: 0.9615384340286255)
[2024-12-17 03:00:42,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,322][root][INFO] - Training Epoch: 2/2, step 3287/7134 completed (loss: 0.20663245022296906, acc: 0.9481481313705444)
[2024-12-17 03:00:42,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:42,710][root][INFO] - Training Epoch: 2/2, step 3288/7134 completed (loss: 0.21511438488960266, acc: 0.9568345546722412)
[2024-12-17 03:00:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,078][root][INFO] - Training Epoch: 2/2, step 3289/7134 completed (loss: 0.33223897218704224, acc: 0.9264705777168274)
[2024-12-17 03:00:43,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,414][root][INFO] - Training Epoch: 2/2, step 3290/7134 completed (loss: 0.21285304427146912, acc: 0.9579831957817078)
[2024-12-17 03:00:43,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:43,782][root][INFO] - Training Epoch: 2/2, step 3291/7134 completed (loss: 0.2894017696380615, acc: 0.9603960514068604)
[2024-12-17 03:00:43,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,137][root][INFO] - Training Epoch: 2/2, step 3292/7134 completed (loss: 0.2511594593524933, acc: 0.9411764740943909)
[2024-12-17 03:00:44,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,530][root][INFO] - Training Epoch: 2/2, step 3293/7134 completed (loss: 0.21513128280639648, acc: 0.939393937587738)
[2024-12-17 03:00:44,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:44,914][root][INFO] - Training Epoch: 2/2, step 3294/7134 completed (loss: 0.3724876642227173, acc: 0.9090909361839294)
[2024-12-17 03:00:45,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,284][root][INFO] - Training Epoch: 2/2, step 3295/7134 completed (loss: 0.0590171255171299, acc: 0.9919354915618896)
[2024-12-17 03:00:45,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:45,665][root][INFO] - Training Epoch: 2/2, step 3296/7134 completed (loss: 0.26434019207954407, acc: 0.9230769276618958)
[2024-12-17 03:00:45,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,045][root][INFO] - Training Epoch: 2/2, step 3297/7134 completed (loss: 0.25108855962753296, acc: 0.9433962106704712)
[2024-12-17 03:00:46,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,419][root][INFO] - Training Epoch: 2/2, step 3298/7134 completed (loss: 0.30068206787109375, acc: 0.9473684430122375)
[2024-12-17 03:00:46,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:46,816][root][INFO] - Training Epoch: 2/2, step 3299/7134 completed (loss: 0.2387050837278366, acc: 0.9370078444480896)
[2024-12-17 03:00:46,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,191][root][INFO] - Training Epoch: 2/2, step 3300/7134 completed (loss: 0.24246321618556976, acc: 0.9248120188713074)
[2024-12-17 03:00:47,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,574][root][INFO] - Training Epoch: 2/2, step 3301/7134 completed (loss: 0.19530224800109863, acc: 0.9514563083648682)
[2024-12-17 03:00:47,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:47,963][root][INFO] - Training Epoch: 2/2, step 3302/7134 completed (loss: 0.29905763268470764, acc: 0.9440559148788452)
[2024-12-17 03:00:48,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,324][root][INFO] - Training Epoch: 2/2, step 3303/7134 completed (loss: 0.3405836820602417, acc: 0.9405940771102905)
[2024-12-17 03:00:48,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:48,715][root][INFO] - Training Epoch: 2/2, step 3304/7134 completed (loss: 0.11971808224916458, acc: 0.963302731513977)
[2024-12-17 03:00:48,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,082][root][INFO] - Training Epoch: 2/2, step 3305/7134 completed (loss: 0.20987945795059204, acc: 0.9622641801834106)
[2024-12-17 03:00:49,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,453][root][INFO] - Training Epoch: 2/2, step 3306/7134 completed (loss: 0.17599160969257355, acc: 0.9367815852165222)
[2024-12-17 03:00:49,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:49,824][root][INFO] - Training Epoch: 2/2, step 3307/7134 completed (loss: 0.1114455834031105, acc: 0.9629629850387573)
[2024-12-17 03:00:49,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,180][root][INFO] - Training Epoch: 2/2, step 3308/7134 completed (loss: 0.3070886433124542, acc: 0.9235293865203857)
[2024-12-17 03:00:50,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,564][root][INFO] - Training Epoch: 2/2, step 3309/7134 completed (loss: 0.34004518389701843, acc: 0.9358974099159241)
[2024-12-17 03:00:50,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:50,942][root][INFO] - Training Epoch: 2/2, step 3310/7134 completed (loss: 0.16881079971790314, acc: 0.9454545378684998)
[2024-12-17 03:00:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,330][root][INFO] - Training Epoch: 2/2, step 3311/7134 completed (loss: 0.27668631076812744, acc: 0.9207921028137207)
[2024-12-17 03:00:51,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:51,704][root][INFO] - Training Epoch: 2/2, step 3312/7134 completed (loss: 0.33228734135627747, acc: 0.9473684430122375)
[2024-12-17 03:00:51,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,043][root][INFO] - Training Epoch: 2/2, step 3313/7134 completed (loss: 0.329023152589798, acc: 0.8979591727256775)
[2024-12-17 03:00:52,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,418][root][INFO] - Training Epoch: 2/2, step 3314/7134 completed (loss: 0.2508648931980133, acc: 0.9541284441947937)
[2024-12-17 03:00:52,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:52,807][root][INFO] - Training Epoch: 2/2, step 3315/7134 completed (loss: 0.2613127529621124, acc: 0.9230769276618958)
[2024-12-17 03:00:52,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,195][root][INFO] - Training Epoch: 2/2, step 3316/7134 completed (loss: 0.23508401215076447, acc: 0.9477611780166626)
[2024-12-17 03:00:53,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,577][root][INFO] - Training Epoch: 2/2, step 3317/7134 completed (loss: 0.32775211334228516, acc: 0.93388432264328)
[2024-12-17 03:00:53,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:53,916][root][INFO] - Training Epoch: 2/2, step 3318/7134 completed (loss: 0.2759363353252411, acc: 0.9152542352676392)
[2024-12-17 03:00:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,289][root][INFO] - Training Epoch: 2/2, step 3319/7134 completed (loss: 0.2375985085964203, acc: 0.9275362491607666)
[2024-12-17 03:00:54,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:54,667][root][INFO] - Training Epoch: 2/2, step 3320/7134 completed (loss: 0.29304155707359314, acc: 0.9322034120559692)
[2024-12-17 03:00:54,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,069][root][INFO] - Training Epoch: 2/2, step 3321/7134 completed (loss: 0.3261868357658386, acc: 0.9071428775787354)
[2024-12-17 03:00:55,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,445][root][INFO] - Training Epoch: 2/2, step 3322/7134 completed (loss: 0.3065090775489807, acc: 0.9210526347160339)
[2024-12-17 03:00:55,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:55,810][root][INFO] - Training Epoch: 2/2, step 3323/7134 completed (loss: 0.2826139032840729, acc: 0.9181286692619324)
[2024-12-17 03:00:55,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,168][root][INFO] - Training Epoch: 2/2, step 3324/7134 completed (loss: 0.3252805769443512, acc: 0.9015544056892395)
[2024-12-17 03:00:56,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,543][root][INFO] - Training Epoch: 2/2, step 3325/7134 completed (loss: 0.18314231932163239, acc: 0.9580838084220886)
[2024-12-17 03:00:56,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:56,906][root][INFO] - Training Epoch: 2/2, step 3326/7134 completed (loss: 0.2690853476524353, acc: 0.9272727370262146)
[2024-12-17 03:00:57,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,291][root][INFO] - Training Epoch: 2/2, step 3327/7134 completed (loss: 0.23957976698875427, acc: 0.939226508140564)
[2024-12-17 03:00:57,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:57,681][root][INFO] - Training Epoch: 2/2, step 3328/7134 completed (loss: 0.1725105196237564, acc: 0.9627659320831299)
[2024-12-17 03:00:57,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,045][root][INFO] - Training Epoch: 2/2, step 3329/7134 completed (loss: 0.2798994779586792, acc: 0.9270833134651184)
[2024-12-17 03:00:58,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,412][root][INFO] - Training Epoch: 2/2, step 3330/7134 completed (loss: 0.17662477493286133, acc: 0.9538461565971375)
[2024-12-17 03:00:58,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:58,796][root][INFO] - Training Epoch: 2/2, step 3331/7134 completed (loss: 0.46740448474884033, acc: 0.8639053106307983)
[2024-12-17 03:00:58,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,189][root][INFO] - Training Epoch: 2/2, step 3332/7134 completed (loss: 0.34509962797164917, acc: 0.9399999976158142)
[2024-12-17 03:00:59,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,570][root][INFO] - Training Epoch: 2/2, step 3333/7134 completed (loss: 0.34849461913108826, acc: 0.9217391014099121)
[2024-12-17 03:00:59,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:00:59,960][root][INFO] - Training Epoch: 2/2, step 3334/7134 completed (loss: 0.208542600274086, acc: 0.9402173757553101)
[2024-12-17 03:01:00,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,330][root][INFO] - Training Epoch: 2/2, step 3335/7134 completed (loss: 0.13324910402297974, acc: 0.9466666579246521)
[2024-12-17 03:01:00,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:00,696][root][INFO] - Training Epoch: 2/2, step 3336/7134 completed (loss: 0.10078109055757523, acc: 0.970059871673584)
[2024-12-17 03:01:00,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,082][root][INFO] - Training Epoch: 2/2, step 3337/7134 completed (loss: 0.07540318369865417, acc: 0.9915966391563416)
[2024-12-17 03:01:01,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,460][root][INFO] - Training Epoch: 2/2, step 3338/7134 completed (loss: 0.09272127598524094, acc: 0.9637305736541748)
[2024-12-17 03:01:01,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:01,865][root][INFO] - Training Epoch: 2/2, step 3339/7134 completed (loss: 0.2990008294582367, acc: 0.9371980428695679)
[2024-12-17 03:01:01,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,215][root][INFO] - Training Epoch: 2/2, step 3340/7134 completed (loss: 0.26881200075149536, acc: 0.9404761791229248)
[2024-12-17 03:01:02,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,586][root][INFO] - Training Epoch: 2/2, step 3341/7134 completed (loss: 0.188331738114357, acc: 0.9341317415237427)
[2024-12-17 03:01:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:02,969][root][INFO] - Training Epoch: 2/2, step 3342/7134 completed (loss: 0.18003927171230316, acc: 0.9520547986030579)
[2024-12-17 03:01:03,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,377][root][INFO] - Training Epoch: 2/2, step 3343/7134 completed (loss: 0.1442968100309372, acc: 0.9741379022598267)
[2024-12-17 03:01:03,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:03,748][root][INFO] - Training Epoch: 2/2, step 3344/7134 completed (loss: 0.22447335720062256, acc: 0.9558823704719543)
[2024-12-17 03:01:03,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,132][root][INFO] - Training Epoch: 2/2, step 3345/7134 completed (loss: 0.22659534215927124, acc: 0.9580419659614563)
[2024-12-17 03:01:04,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,510][root][INFO] - Training Epoch: 2/2, step 3346/7134 completed (loss: 0.14891420304775238, acc: 0.957317054271698)
[2024-12-17 03:01:04,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:04,847][root][INFO] - Training Epoch: 2/2, step 3347/7134 completed (loss: 0.363703191280365, acc: 0.9346405267715454)
[2024-12-17 03:01:04,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,177][root][INFO] - Training Epoch: 2/2, step 3348/7134 completed (loss: 0.16026505827903748, acc: 0.949367105960846)
[2024-12-17 03:01:05,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,556][root][INFO] - Training Epoch: 2/2, step 3349/7134 completed (loss: 0.20419533550739288, acc: 0.9689922332763672)
[2024-12-17 03:01:05,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:05,936][root][INFO] - Training Epoch: 2/2, step 3350/7134 completed (loss: 0.14409945905208588, acc: 0.9752066135406494)
[2024-12-17 03:01:06,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,333][root][INFO] - Training Epoch: 2/2, step 3351/7134 completed (loss: 0.41067394614219666, acc: 0.8936170339584351)
[2024-12-17 03:01:06,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:06,715][root][INFO] - Training Epoch: 2/2, step 3352/7134 completed (loss: 0.1766401082277298, acc: 0.970370352268219)
[2024-12-17 03:01:06,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,078][root][INFO] - Training Epoch: 2/2, step 3353/7134 completed (loss: 0.18490689992904663, acc: 0.9512194991111755)
[2024-12-17 03:01:07,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,448][root][INFO] - Training Epoch: 2/2, step 3354/7134 completed (loss: 0.07191605865955353, acc: 0.9873417615890503)
[2024-12-17 03:01:07,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:07,827][root][INFO] - Training Epoch: 2/2, step 3355/7134 completed (loss: 0.03897540271282196, acc: 0.9939024448394775)
[2024-12-17 03:01:07,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,225][root][INFO] - Training Epoch: 2/2, step 3356/7134 completed (loss: 0.04244399443268776, acc: 0.9925925731658936)
[2024-12-17 03:01:08,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,618][root][INFO] - Training Epoch: 2/2, step 3357/7134 completed (loss: 0.09984513372182846, acc: 0.9880239367485046)
[2024-12-17 03:01:08,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:08,998][root][INFO] - Training Epoch: 2/2, step 3358/7134 completed (loss: 0.4338986873626709, acc: 0.8970588445663452)
[2024-12-17 03:01:09,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,395][root][INFO] - Training Epoch: 2/2, step 3359/7134 completed (loss: 0.20351071655750275, acc: 0.931506872177124)
[2024-12-17 03:01:09,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:09,762][root][INFO] - Training Epoch: 2/2, step 3360/7134 completed (loss: 0.27559879422187805, acc: 0.9217391014099121)
[2024-12-17 03:01:09,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,137][root][INFO] - Training Epoch: 2/2, step 3361/7134 completed (loss: 0.2848163843154907, acc: 0.9017857313156128)
[2024-12-17 03:01:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,500][root][INFO] - Training Epoch: 2/2, step 3362/7134 completed (loss: 0.292080819606781, acc: 0.9090909361839294)
[2024-12-17 03:01:10,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:10,858][root][INFO] - Training Epoch: 2/2, step 3363/7134 completed (loss: 0.2409370243549347, acc: 0.9439252614974976)
[2024-12-17 03:01:10,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,226][root][INFO] - Training Epoch: 2/2, step 3364/7134 completed (loss: 0.455942839384079, acc: 0.8954248428344727)
[2024-12-17 03:01:11,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,624][root][INFO] - Training Epoch: 2/2, step 3365/7134 completed (loss: 0.1965363472700119, acc: 0.9026548862457275)
[2024-12-17 03:01:11,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:11,988][root][INFO] - Training Epoch: 2/2, step 3366/7134 completed (loss: 0.172127828001976, acc: 0.9629629850387573)
[2024-12-17 03:01:12,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,350][root][INFO] - Training Epoch: 2/2, step 3367/7134 completed (loss: 0.28216326236724854, acc: 0.9251337051391602)
[2024-12-17 03:01:12,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:12,728][root][INFO] - Training Epoch: 2/2, step 3368/7134 completed (loss: 0.2911839783191681, acc: 0.9254658222198486)
[2024-12-17 03:01:12,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,107][root][INFO] - Training Epoch: 2/2, step 3369/7134 completed (loss: 0.22217625379562378, acc: 0.9459459185600281)
[2024-12-17 03:01:13,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,465][root][INFO] - Training Epoch: 2/2, step 3370/7134 completed (loss: 0.17152337729930878, acc: 0.9693251252174377)
[2024-12-17 03:01:13,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:13,840][root][INFO] - Training Epoch: 2/2, step 3371/7134 completed (loss: 0.21186085045337677, acc: 0.9652777910232544)
[2024-12-17 03:01:13,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,228][root][INFO] - Training Epoch: 2/2, step 3372/7134 completed (loss: 0.19928891956806183, acc: 0.9659863710403442)
[2024-12-17 03:01:14,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,610][root][INFO] - Training Epoch: 2/2, step 3373/7134 completed (loss: 0.11777365207672119, acc: 0.9738562107086182)
[2024-12-17 03:01:14,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:14,977][root][INFO] - Training Epoch: 2/2, step 3374/7134 completed (loss: 0.07593663036823273, acc: 0.9885714054107666)
[2024-12-17 03:01:15,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,366][root][INFO] - Training Epoch: 2/2, step 3375/7134 completed (loss: 0.1882457286119461, acc: 0.946107804775238)
[2024-12-17 03:01:15,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:15,741][root][INFO] - Training Epoch: 2/2, step 3376/7134 completed (loss: 0.0736699253320694, acc: 0.9788359999656677)
[2024-12-17 03:01:15,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,124][root][INFO] - Training Epoch: 2/2, step 3377/7134 completed (loss: 0.11111974716186523, acc: 0.9648241400718689)
[2024-12-17 03:01:16,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,502][root][INFO] - Training Epoch: 2/2, step 3378/7134 completed (loss: 0.08118801563978195, acc: 0.9868420958518982)
[2024-12-17 03:01:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:16,871][root][INFO] - Training Epoch: 2/2, step 3379/7134 completed (loss: 0.13016244769096375, acc: 0.9662162065505981)
[2024-12-17 03:01:16,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,231][root][INFO] - Training Epoch: 2/2, step 3380/7134 completed (loss: 0.17116080224514008, acc: 0.9492753744125366)
[2024-12-17 03:01:17,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,615][root][INFO] - Training Epoch: 2/2, step 3381/7134 completed (loss: 0.15455323457717896, acc: 0.9634146094322205)
[2024-12-17 03:01:17,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:17,970][root][INFO] - Training Epoch: 2/2, step 3382/7134 completed (loss: 0.16721662878990173, acc: 0.9453125)
[2024-12-17 03:01:18,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,386][root][INFO] - Training Epoch: 2/2, step 3383/7134 completed (loss: 0.13653762638568878, acc: 0.9510489702224731)
[2024-12-17 03:01:18,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:18,751][root][INFO] - Training Epoch: 2/2, step 3384/7134 completed (loss: 0.26850250363349915, acc: 0.9416058659553528)
[2024-12-17 03:01:18,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,151][root][INFO] - Training Epoch: 2/2, step 3385/7134 completed (loss: 0.13768745958805084, acc: 0.9652777910232544)
[2024-12-17 03:01:19,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,566][root][INFO] - Training Epoch: 2/2, step 3386/7134 completed (loss: 0.10417449474334717, acc: 0.9644970297813416)
[2024-12-17 03:01:19,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:19,919][root][INFO] - Training Epoch: 2/2, step 3387/7134 completed (loss: 0.18831519782543182, acc: 0.930232584476471)
[2024-12-17 03:01:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,293][root][INFO] - Training Epoch: 2/2, step 3388/7134 completed (loss: 0.13213910162448883, acc: 0.9487179517745972)
[2024-12-17 03:01:20,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:20,663][root][INFO] - Training Epoch: 2/2, step 3389/7134 completed (loss: 0.12016662955284119, acc: 0.9562841653823853)
[2024-12-17 03:01:20,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,051][root][INFO] - Training Epoch: 2/2, step 3390/7134 completed (loss: 0.0860467180609703, acc: 0.9829545617103577)
[2024-12-17 03:01:21,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,407][root][INFO] - Training Epoch: 2/2, step 3391/7134 completed (loss: 0.1193980947136879, acc: 0.9817073345184326)
[2024-12-17 03:01:21,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:21,773][root][INFO] - Training Epoch: 2/2, step 3392/7134 completed (loss: 0.11412078887224197, acc: 0.9694656729698181)
[2024-12-17 03:01:21,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,134][root][INFO] - Training Epoch: 2/2, step 3393/7134 completed (loss: 0.1913786083459854, acc: 0.9440559148788452)
[2024-12-17 03:01:22,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,533][root][INFO] - Training Epoch: 2/2, step 3394/7134 completed (loss: 0.21453112363815308, acc: 0.9428571462631226)
[2024-12-17 03:01:22,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:22,923][root][INFO] - Training Epoch: 2/2, step 3395/7134 completed (loss: 0.2696985602378845, acc: 0.9078947305679321)
[2024-12-17 03:01:23,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,322][root][INFO] - Training Epoch: 2/2, step 3396/7134 completed (loss: 0.1712125986814499, acc: 0.9663461446762085)
[2024-12-17 03:01:23,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:23,714][root][INFO] - Training Epoch: 2/2, step 3397/7134 completed (loss: 0.09914710372686386, acc: 0.96517413854599)
[2024-12-17 03:01:23,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,088][root][INFO] - Training Epoch: 2/2, step 3398/7134 completed (loss: 0.1805967539548874, acc: 0.95652174949646)
[2024-12-17 03:01:24,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,458][root][INFO] - Training Epoch: 2/2, step 3399/7134 completed (loss: 0.3789575695991516, acc: 0.9027777910232544)
[2024-12-17 03:01:24,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:24,836][root][INFO] - Training Epoch: 2/2, step 3400/7134 completed (loss: 0.31182196736335754, acc: 0.9055117964744568)
[2024-12-17 03:01:24,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,220][root][INFO] - Training Epoch: 2/2, step 3401/7134 completed (loss: 0.23747961223125458, acc: 0.9455782175064087)
[2024-12-17 03:01:25,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:25,615][root][INFO] - Training Epoch: 2/2, step 3402/7134 completed (loss: 0.4259728789329529, acc: 0.9251337051391602)
[2024-12-17 03:01:25,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,002][root][INFO] - Training Epoch: 2/2, step 3403/7134 completed (loss: 0.30258265137672424, acc: 0.9292929172515869)
[2024-12-17 03:01:26,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,352][root][INFO] - Training Epoch: 2/2, step 3404/7134 completed (loss: 0.1402948796749115, acc: 0.955974817276001)
[2024-12-17 03:01:26,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:26,708][root][INFO] - Training Epoch: 2/2, step 3405/7134 completed (loss: 0.3484923541545868, acc: 0.9117646813392639)
[2024-12-17 03:01:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,074][root][INFO] - Training Epoch: 2/2, step 3406/7134 completed (loss: 0.3261464834213257, acc: 0.8949999809265137)
[2024-12-17 03:01:27,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,431][root][INFO] - Training Epoch: 2/2, step 3407/7134 completed (loss: 0.21730275452136993, acc: 0.9447852969169617)
[2024-12-17 03:01:27,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:27,786][root][INFO] - Training Epoch: 2/2, step 3408/7134 completed (loss: 0.14542178809642792, acc: 0.9622641801834106)
[2024-12-17 03:01:27,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,161][root][INFO] - Training Epoch: 2/2, step 3409/7134 completed (loss: 0.2276020050048828, acc: 0.959770143032074)
[2024-12-17 03:01:28,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,564][root][INFO] - Training Epoch: 2/2, step 3410/7134 completed (loss: 0.26806217432022095, acc: 0.9390243887901306)
[2024-12-17 03:01:28,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:28,943][root][INFO] - Training Epoch: 2/2, step 3411/7134 completed (loss: 0.2299581915140152, acc: 0.9450549483299255)
[2024-12-17 03:01:29,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,303][root][INFO] - Training Epoch: 2/2, step 3412/7134 completed (loss: 0.28287366032600403, acc: 0.9166666865348816)
[2024-12-17 03:01:29,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:29,678][root][INFO] - Training Epoch: 2/2, step 3413/7134 completed (loss: 0.2170778512954712, acc: 0.9572649598121643)
[2024-12-17 03:01:29,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,012][root][INFO] - Training Epoch: 2/2, step 3414/7134 completed (loss: 0.09690763801336288, acc: 0.9652777910232544)
[2024-12-17 03:01:30,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,392][root][INFO] - Training Epoch: 2/2, step 3415/7134 completed (loss: 0.1366661638021469, acc: 0.9714285731315613)
[2024-12-17 03:01:30,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:30,796][root][INFO] - Training Epoch: 2/2, step 3416/7134 completed (loss: 0.24462173879146576, acc: 0.9508196711540222)
[2024-12-17 03:01:30,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,205][root][INFO] - Training Epoch: 2/2, step 3417/7134 completed (loss: 0.1439286321401596, acc: 0.970059871673584)
[2024-12-17 03:01:31,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,576][root][INFO] - Training Epoch: 2/2, step 3418/7134 completed (loss: 0.23732301592826843, acc: 0.9386503100395203)
[2024-12-17 03:01:31,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:31,954][root][INFO] - Training Epoch: 2/2, step 3419/7134 completed (loss: 0.13294722139835358, acc: 0.9638554453849792)
[2024-12-17 03:01:32,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,335][root][INFO] - Training Epoch: 2/2, step 3420/7134 completed (loss: 0.07785990089178085, acc: 0.9801324605941772)
[2024-12-17 03:01:32,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:32,714][root][INFO] - Training Epoch: 2/2, step 3421/7134 completed (loss: 0.17384618520736694, acc: 0.9743589758872986)
[2024-12-17 03:01:32,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,091][root][INFO] - Training Epoch: 2/2, step 3422/7134 completed (loss: 0.09234137833118439, acc: 0.970588207244873)
[2024-12-17 03:01:33,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,497][root][INFO] - Training Epoch: 2/2, step 3423/7134 completed (loss: 0.03452856466174126, acc: 0.9934210777282715)
[2024-12-17 03:01:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:33,890][root][INFO] - Training Epoch: 2/2, step 3424/7134 completed (loss: 0.2782759368419647, acc: 0.9399999976158142)
[2024-12-17 03:01:34,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,290][root][INFO] - Training Epoch: 2/2, step 3425/7134 completed (loss: 0.3479212820529938, acc: 0.9368420839309692)
[2024-12-17 03:01:34,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:34,725][root][INFO] - Training Epoch: 2/2, step 3426/7134 completed (loss: 0.24253776669502258, acc: 0.9702380895614624)
[2024-12-17 03:01:34,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,137][root][INFO] - Training Epoch: 2/2, step 3427/7134 completed (loss: 0.15115855634212494, acc: 0.9740259647369385)
[2024-12-17 03:01:35,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,543][root][INFO] - Training Epoch: 2/2, step 3428/7134 completed (loss: 0.14660470187664032, acc: 0.970588207244873)
[2024-12-17 03:01:35,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:35,986][root][INFO] - Training Epoch: 2/2, step 3429/7134 completed (loss: 0.22312462329864502, acc: 0.9366196990013123)
[2024-12-17 03:01:36,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,366][root][INFO] - Training Epoch: 2/2, step 3430/7134 completed (loss: 0.2359488308429718, acc: 0.9520547986030579)
[2024-12-17 03:01:36,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:36,788][root][INFO] - Training Epoch: 2/2, step 3431/7134 completed (loss: 0.1545102745294571, acc: 0.9710144996643066)
[2024-12-17 03:01:36,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,162][root][INFO] - Training Epoch: 2/2, step 3432/7134 completed (loss: 0.11292030662298203, acc: 0.9754601120948792)
[2024-12-17 03:01:37,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,544][root][INFO] - Training Epoch: 2/2, step 3433/7134 completed (loss: 0.2652016282081604, acc: 0.9338235259056091)
[2024-12-17 03:01:37,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:37,907][root][INFO] - Training Epoch: 2/2, step 3434/7134 completed (loss: 0.3186359405517578, acc: 0.9285714030265808)
[2024-12-17 03:01:38,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,281][root][INFO] - Training Epoch: 2/2, step 3435/7134 completed (loss: 0.18645937740802765, acc: 0.951724112033844)
[2024-12-17 03:01:38,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:38,677][root][INFO] - Training Epoch: 2/2, step 3436/7134 completed (loss: 0.17520105838775635, acc: 0.956204354763031)
[2024-12-17 03:01:38,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,105][root][INFO] - Training Epoch: 2/2, step 3437/7134 completed (loss: 0.2891217768192291, acc: 0.9256198406219482)
[2024-12-17 03:01:39,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,485][root][INFO] - Training Epoch: 2/2, step 3438/7134 completed (loss: 0.23775798082351685, acc: 0.9473684430122375)
[2024-12-17 03:01:39,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:39,829][root][INFO] - Training Epoch: 2/2, step 3439/7134 completed (loss: 0.3940802812576294, acc: 0.9047619104385376)
[2024-12-17 03:01:39,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,196][root][INFO] - Training Epoch: 2/2, step 3440/7134 completed (loss: 0.45291316509246826, acc: 0.9051724076271057)
[2024-12-17 03:01:40,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,551][root][INFO] - Training Epoch: 2/2, step 3441/7134 completed (loss: 0.35790079832077026, acc: 0.9069767594337463)
[2024-12-17 03:01:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:40,914][root][INFO] - Training Epoch: 2/2, step 3442/7134 completed (loss: 0.13169898092746735, acc: 0.9645389914512634)
[2024-12-17 03:01:41,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,352][root][INFO] - Training Epoch: 2/2, step 3443/7134 completed (loss: 0.3244183361530304, acc: 0.9438202381134033)
[2024-12-17 03:01:41,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:41,753][root][INFO] - Training Epoch: 2/2, step 3444/7134 completed (loss: 0.2476355880498886, acc: 0.9363057613372803)
[2024-12-17 03:01:41,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,142][root][INFO] - Training Epoch: 2/2, step 3445/7134 completed (loss: 0.4258902370929718, acc: 0.8872180581092834)
[2024-12-17 03:01:42,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,542][root][INFO] - Training Epoch: 2/2, step 3446/7134 completed (loss: 0.34051090478897095, acc: 0.9133333563804626)
[2024-12-17 03:01:42,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:42,943][root][INFO] - Training Epoch: 2/2, step 3447/7134 completed (loss: 0.38142141699790955, acc: 0.8888888955116272)
[2024-12-17 03:01:43,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,339][root][INFO] - Training Epoch: 2/2, step 3448/7134 completed (loss: 0.3130853772163391, acc: 0.913294792175293)
[2024-12-17 03:01:43,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:43,733][root][INFO] - Training Epoch: 2/2, step 3449/7134 completed (loss: 0.16554996371269226, acc: 0.9306930899620056)
[2024-12-17 03:01:43,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,105][root][INFO] - Training Epoch: 2/2, step 3450/7134 completed (loss: 0.2519039809703827, acc: 0.9117646813392639)
[2024-12-17 03:01:44,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,467][root][INFO] - Training Epoch: 2/2, step 3451/7134 completed (loss: 0.31596678495407104, acc: 0.914893627166748)
[2024-12-17 03:01:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:44,866][root][INFO] - Training Epoch: 2/2, step 3452/7134 completed (loss: 0.4421613812446594, acc: 0.9105691313743591)
[2024-12-17 03:01:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,278][root][INFO] - Training Epoch: 2/2, step 3453/7134 completed (loss: 0.2624138593673706, acc: 0.9444444179534912)
[2024-12-17 03:01:45,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:45,654][root][INFO] - Training Epoch: 2/2, step 3454/7134 completed (loss: 0.19923126697540283, acc: 0.9518072009086609)
[2024-12-17 03:01:45,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,057][root][INFO] - Training Epoch: 2/2, step 3455/7134 completed (loss: 0.13573244214057922, acc: 0.95652174949646)
[2024-12-17 03:01:46,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,465][root][INFO] - Training Epoch: 2/2, step 3456/7134 completed (loss: 0.11870437860488892, acc: 0.9698492288589478)
[2024-12-17 03:01:46,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:46,834][root][INFO] - Training Epoch: 2/2, step 3457/7134 completed (loss: 0.08232290297746658, acc: 0.98591548204422)
[2024-12-17 03:01:46,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,220][root][INFO] - Training Epoch: 2/2, step 3458/7134 completed (loss: 0.28566333651542664, acc: 0.9450549483299255)
[2024-12-17 03:01:47,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,617][root][INFO] - Training Epoch: 2/2, step 3459/7134 completed (loss: 0.2368556261062622, acc: 0.9308176040649414)
[2024-12-17 03:01:47,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:47,969][root][INFO] - Training Epoch: 2/2, step 3460/7134 completed (loss: 0.8013637661933899, acc: 0.8181818127632141)
[2024-12-17 03:01:48,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,335][root][INFO] - Training Epoch: 2/2, step 3461/7134 completed (loss: 0.8710651397705078, acc: 0.8307692408561707)
[2024-12-17 03:01:48,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:48,683][root][INFO] - Training Epoch: 2/2, step 3462/7134 completed (loss: 0.3335440754890442, acc: 0.9239766001701355)
[2024-12-17 03:01:48,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,077][root][INFO] - Training Epoch: 2/2, step 3463/7134 completed (loss: 0.09028560668230057, acc: 0.9876543283462524)
[2024-12-17 03:01:49,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,481][root][INFO] - Training Epoch: 2/2, step 3464/7134 completed (loss: 0.11715583503246307, acc: 0.9775280952453613)
[2024-12-17 03:01:49,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:49,832][root][INFO] - Training Epoch: 2/2, step 3465/7134 completed (loss: 0.21142850816249847, acc: 0.9481481313705444)
[2024-12-17 03:01:49,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,194][root][INFO] - Training Epoch: 2/2, step 3466/7134 completed (loss: 0.24121540784835815, acc: 0.9382715821266174)
[2024-12-17 03:01:50,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,579][root][INFO] - Training Epoch: 2/2, step 3467/7134 completed (loss: 0.05188008397817612, acc: 0.9830508232116699)
[2024-12-17 03:01:50,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:50,958][root][INFO] - Training Epoch: 2/2, step 3468/7134 completed (loss: 0.06412498652935028, acc: 0.9868420958518982)
[2024-12-17 03:01:51,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,323][root][INFO] - Training Epoch: 2/2, step 3469/7134 completed (loss: 0.15876613557338715, acc: 0.9548872113227844)
[2024-12-17 03:01:51,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:51,678][root][INFO] - Training Epoch: 2/2, step 3470/7134 completed (loss: 0.06900054216384888, acc: 0.9814814925193787)
[2024-12-17 03:01:51,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,034][root][INFO] - Training Epoch: 2/2, step 3471/7134 completed (loss: 0.16218066215515137, acc: 0.9333333373069763)
[2024-12-17 03:01:52,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,411][root][INFO] - Training Epoch: 2/2, step 3472/7134 completed (loss: 0.06020217388868332, acc: 0.987261176109314)
[2024-12-17 03:01:52,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:52,840][root][INFO] - Training Epoch: 2/2, step 3473/7134 completed (loss: 0.09082090109586716, acc: 0.9736841917037964)
[2024-12-17 03:01:52,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,273][root][INFO] - Training Epoch: 2/2, step 3474/7134 completed (loss: 0.17119282484054565, acc: 0.95652174949646)
[2024-12-17 03:01:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:53,633][root][INFO] - Training Epoch: 2/2, step 3475/7134 completed (loss: 0.1852400302886963, acc: 0.9696969985961914)
[2024-12-17 03:01:53,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,001][root][INFO] - Training Epoch: 2/2, step 3476/7134 completed (loss: 0.25880318880081177, acc: 0.9452054500579834)
[2024-12-17 03:01:54,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,366][root][INFO] - Training Epoch: 2/2, step 3477/7134 completed (loss: 0.14765682816505432, acc: 0.9662162065505981)
[2024-12-17 03:01:54,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:54,781][root][INFO] - Training Epoch: 2/2, step 3478/7134 completed (loss: 0.06355751305818558, acc: 0.9880239367485046)
[2024-12-17 03:01:54,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,161][root][INFO] - Training Epoch: 2/2, step 3479/7134 completed (loss: 0.021123772487044334, acc: 1.0)
[2024-12-17 03:01:55,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,552][root][INFO] - Training Epoch: 2/2, step 3480/7134 completed (loss: 0.19631381332874298, acc: 0.9560439586639404)
[2024-12-17 03:01:55,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:55,943][root][INFO] - Training Epoch: 2/2, step 3481/7134 completed (loss: 0.08352428674697876, acc: 0.9774436354637146)
[2024-12-17 03:01:56,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,304][root][INFO] - Training Epoch: 2/2, step 3482/7134 completed (loss: 0.023727620020508766, acc: 0.9921875)
[2024-12-17 03:01:56,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:56,669][root][INFO] - Training Epoch: 2/2, step 3483/7134 completed (loss: 0.06264588236808777, acc: 0.9935483932495117)
[2024-12-17 03:01:56,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,012][root][INFO] - Training Epoch: 2/2, step 3484/7134 completed (loss: 0.3174445629119873, acc: 0.976190447807312)
[2024-12-17 03:01:57,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,384][root][INFO] - Training Epoch: 2/2, step 3485/7134 completed (loss: 0.15359272062778473, acc: 0.9575757384300232)
[2024-12-17 03:01:57,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:57,749][root][INFO] - Training Epoch: 2/2, step 3486/7134 completed (loss: 0.3798747956752777, acc: 0.94017094373703)
[2024-12-17 03:01:57,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,114][root][INFO] - Training Epoch: 2/2, step 3487/7134 completed (loss: 0.23715455830097198, acc: 0.9457831382751465)
[2024-12-17 03:01:58,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,510][root][INFO] - Training Epoch: 2/2, step 3488/7134 completed (loss: 0.26602619886398315, acc: 0.9357143044471741)
[2024-12-17 03:01:58,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:58,879][root][INFO] - Training Epoch: 2/2, step 3489/7134 completed (loss: 0.38659119606018066, acc: 0.8962963223457336)
[2024-12-17 03:01:58,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,267][root][INFO] - Training Epoch: 2/2, step 3490/7134 completed (loss: 0.19950643181800842, acc: 0.9790209531784058)
[2024-12-17 03:01:59,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:01:59,653][root][INFO] - Training Epoch: 2/2, step 3491/7134 completed (loss: 0.24668551981449127, acc: 0.9299362897872925)
[2024-12-17 03:01:59,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,019][root][INFO] - Training Epoch: 2/2, step 3492/7134 completed (loss: 0.15879420936107635, acc: 0.963302731513977)
[2024-12-17 03:02:00,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,417][root][INFO] - Training Epoch: 2/2, step 3493/7134 completed (loss: 0.16116492450237274, acc: 0.9506173133850098)
[2024-12-17 03:02:00,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:00,785][root][INFO] - Training Epoch: 2/2, step 3494/7134 completed (loss: 0.18750861287117004, acc: 0.9527027010917664)
[2024-12-17 03:02:00,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,171][root][INFO] - Training Epoch: 2/2, step 3495/7134 completed (loss: 0.2216011881828308, acc: 0.938144326210022)
[2024-12-17 03:02:01,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,525][root][INFO] - Training Epoch: 2/2, step 3496/7134 completed (loss: 0.17162419855594635, acc: 0.970588207244873)
[2024-12-17 03:02:01,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:01,912][root][INFO] - Training Epoch: 2/2, step 3497/7134 completed (loss: 0.19467401504516602, acc: 0.9430379867553711)
[2024-12-17 03:02:02,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,310][root][INFO] - Training Epoch: 2/2, step 3498/7134 completed (loss: 0.2847279906272888, acc: 0.9240506291389465)
[2024-12-17 03:02:02,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:02,746][root][INFO] - Training Epoch: 2/2, step 3499/7134 completed (loss: 0.251365602016449, acc: 0.9477124214172363)
[2024-12-17 03:02:02,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,174][root][INFO] - Training Epoch: 2/2, step 3500/7134 completed (loss: 0.28624987602233887, acc: 0.9415204524993896)
[2024-12-17 03:02:03,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,548][root][INFO] - Training Epoch: 2/2, step 3501/7134 completed (loss: 0.2818034291267395, acc: 0.9318181872367859)
[2024-12-17 03:02:03,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:03,899][root][INFO] - Training Epoch: 2/2, step 3502/7134 completed (loss: 0.36760762333869934, acc: 0.8918918967247009)
[2024-12-17 03:02:04,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,309][root][INFO] - Training Epoch: 2/2, step 3503/7134 completed (loss: 0.5064659118652344, acc: 0.8920863270759583)
[2024-12-17 03:02:04,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:04,700][root][INFO] - Training Epoch: 2/2, step 3504/7134 completed (loss: 0.06252982467412949, acc: 0.9800000190734863)
[2024-12-17 03:02:04,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,080][root][INFO] - Training Epoch: 2/2, step 3505/7134 completed (loss: 0.10814737528562546, acc: 0.9603174328804016)
[2024-12-17 03:02:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,438][root][INFO] - Training Epoch: 2/2, step 3506/7134 completed (loss: 0.17559443414211273, acc: 0.961240291595459)
[2024-12-17 03:02:05,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:05,828][root][INFO] - Training Epoch: 2/2, step 3507/7134 completed (loss: 0.10476054251194, acc: 0.9722222089767456)
[2024-12-17 03:02:05,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,253][root][INFO] - Training Epoch: 2/2, step 3508/7134 completed (loss: 0.10022171586751938, acc: 0.9735099077224731)
[2024-12-17 03:02:06,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,663][root][INFO] - Training Epoch: 2/2, step 3509/7134 completed (loss: 0.25941702723503113, acc: 0.9631901979446411)
[2024-12-17 03:02:06,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:06,990][root][INFO] - Training Epoch: 2/2, step 3510/7134 completed (loss: 0.13016833364963531, acc: 0.9548872113227844)
[2024-12-17 03:02:07,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,395][root][INFO] - Training Epoch: 2/2, step 3511/7134 completed (loss: 0.03269281983375549, acc: 0.9926470518112183)
[2024-12-17 03:02:07,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:07,817][root][INFO] - Training Epoch: 2/2, step 3512/7134 completed (loss: 0.2538939118385315, acc: 0.9615384340286255)
[2024-12-17 03:02:07,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,208][root][INFO] - Training Epoch: 2/2, step 3513/7134 completed (loss: 0.12478648871183395, acc: 0.95652174949646)
[2024-12-17 03:02:08,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:08,604][root][INFO] - Training Epoch: 2/2, step 3514/7134 completed (loss: 0.12704306840896606, acc: 0.9712918400764465)
[2024-12-17 03:02:08,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,047][root][INFO] - Training Epoch: 2/2, step 3515/7134 completed (loss: 0.05836972966790199, acc: 0.9887005686759949)
[2024-12-17 03:02:09,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,462][root][INFO] - Training Epoch: 2/2, step 3516/7134 completed (loss: 0.07038213312625885, acc: 0.9912280440330505)
[2024-12-17 03:02:09,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:09,843][root][INFO] - Training Epoch: 2/2, step 3517/7134 completed (loss: 0.09461238235235214, acc: 0.9747474789619446)
[2024-12-17 03:02:09,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,224][root][INFO] - Training Epoch: 2/2, step 3518/7134 completed (loss: 0.22680610418319702, acc: 0.9481481313705444)
[2024-12-17 03:02:10,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,602][root][INFO] - Training Epoch: 2/2, step 3519/7134 completed (loss: 0.12173262983560562, acc: 0.9733333587646484)
[2024-12-17 03:02:10,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:10,990][root][INFO] - Training Epoch: 2/2, step 3520/7134 completed (loss: 0.20728623867034912, acc: 0.9545454382896423)
[2024-12-17 03:02:11,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,374][root][INFO] - Training Epoch: 2/2, step 3521/7134 completed (loss: 0.06865886598825455, acc: 0.9820359349250793)
[2024-12-17 03:02:11,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:11,718][root][INFO] - Training Epoch: 2/2, step 3522/7134 completed (loss: 0.060524147003889084, acc: 1.0)
[2024-12-17 03:02:11,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,103][root][INFO] - Training Epoch: 2/2, step 3523/7134 completed (loss: 0.03631897643208504, acc: 0.9933775067329407)
[2024-12-17 03:02:12,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,518][root][INFO] - Training Epoch: 2/2, step 3524/7134 completed (loss: 0.0946604311466217, acc: 0.9835164546966553)
[2024-12-17 03:02:12,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:12,890][root][INFO] - Training Epoch: 2/2, step 3525/7134 completed (loss: 0.053759217262268066, acc: 0.9932432174682617)
[2024-12-17 03:02:12,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,267][root][INFO] - Training Epoch: 2/2, step 3526/7134 completed (loss: 0.1525346040725708, acc: 0.9595959782600403)
[2024-12-17 03:02:13,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:13,656][root][INFO] - Training Epoch: 2/2, step 3527/7134 completed (loss: 0.19236263632774353, acc: 0.9627659320831299)
[2024-12-17 03:02:13,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,027][root][INFO] - Training Epoch: 2/2, step 3528/7134 completed (loss: 0.03983229026198387, acc: 0.995192289352417)
[2024-12-17 03:02:14,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,399][root][INFO] - Training Epoch: 2/2, step 3529/7134 completed (loss: 0.13077595829963684, acc: 0.9727272987365723)
[2024-12-17 03:02:14,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:14,839][root][INFO] - Training Epoch: 2/2, step 3530/7134 completed (loss: 0.2146681845188141, acc: 0.9469026327133179)
[2024-12-17 03:02:14,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,241][root][INFO] - Training Epoch: 2/2, step 3531/7134 completed (loss: 0.14541977643966675, acc: 0.949999988079071)
[2024-12-17 03:02:15,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:15,635][root][INFO] - Training Epoch: 2/2, step 3532/7134 completed (loss: 0.07005965709686279, acc: 0.9729729890823364)
[2024-12-17 03:02:15,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,033][root][INFO] - Training Epoch: 2/2, step 3533/7134 completed (loss: 0.1036556214094162, acc: 0.9644444584846497)
[2024-12-17 03:02:16,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,394][root][INFO] - Training Epoch: 2/2, step 3534/7134 completed (loss: 0.15153245627880096, acc: 0.9649122953414917)
[2024-12-17 03:02:16,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:16,794][root][INFO] - Training Epoch: 2/2, step 3535/7134 completed (loss: 0.16965562105178833, acc: 0.9640287756919861)
[2024-12-17 03:02:16,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,246][root][INFO] - Training Epoch: 2/2, step 3536/7134 completed (loss: 0.1920396238565445, acc: 0.9444444179534912)
[2024-12-17 03:02:17,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:17,675][root][INFO] - Training Epoch: 2/2, step 3537/7134 completed (loss: 0.18619616329669952, acc: 0.9609375)
[2024-12-17 03:02:17,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,069][root][INFO] - Training Epoch: 2/2, step 3538/7134 completed (loss: 0.06688724458217621, acc: 0.9915966391563416)
[2024-12-17 03:02:18,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,449][root][INFO] - Training Epoch: 2/2, step 3539/7134 completed (loss: 0.16894234716892242, acc: 0.9655172228813171)
[2024-12-17 03:02:18,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:18,846][root][INFO] - Training Epoch: 2/2, step 3540/7134 completed (loss: 0.17557261884212494, acc: 0.9615384340286255)
[2024-12-17 03:02:18,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,242][root][INFO] - Training Epoch: 2/2, step 3541/7134 completed (loss: 0.18904763460159302, acc: 0.9399999976158142)
[2024-12-17 03:02:19,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:19,705][root][INFO] - Training Epoch: 2/2, step 3542/7134 completed (loss: 0.07480241358280182, acc: 0.9726027250289917)
[2024-12-17 03:02:19,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,058][root][INFO] - Training Epoch: 2/2, step 3543/7134 completed (loss: 0.2489970624446869, acc: 0.9436619877815247)
[2024-12-17 03:02:20,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,421][root][INFO] - Training Epoch: 2/2, step 3544/7134 completed (loss: 0.25472986698150635, acc: 0.9337748289108276)
[2024-12-17 03:02:20,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:20,828][root][INFO] - Training Epoch: 2/2, step 3545/7134 completed (loss: 0.07536926865577698, acc: 0.9791666865348816)
[2024-12-17 03:02:20,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,215][root][INFO] - Training Epoch: 2/2, step 3546/7134 completed (loss: 0.19645413756370544, acc: 0.9568345546722412)
[2024-12-17 03:02:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:21,674][root][INFO] - Training Epoch: 2/2, step 3547/7134 completed (loss: 0.3043837547302246, acc: 0.9322034120559692)
[2024-12-17 03:02:21,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,102][root][INFO] - Training Epoch: 2/2, step 3548/7134 completed (loss: 0.13374416530132294, acc: 0.963302731513977)
[2024-12-17 03:02:22,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,516][root][INFO] - Training Epoch: 2/2, step 3549/7134 completed (loss: 0.1812247484922409, acc: 0.9548872113227844)
[2024-12-17 03:02:22,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:22,940][root][INFO] - Training Epoch: 2/2, step 3550/7134 completed (loss: 0.2554134726524353, acc: 0.9197080135345459)
[2024-12-17 03:02:23,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,357][root][INFO] - Training Epoch: 2/2, step 3551/7134 completed (loss: 0.40365150570869446, acc: 0.884353756904602)
[2024-12-17 03:02:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:23,794][root][INFO] - Training Epoch: 2/2, step 3552/7134 completed (loss: 0.28848689794540405, acc: 0.9212598204612732)
[2024-12-17 03:02:23,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,197][root][INFO] - Training Epoch: 2/2, step 3553/7134 completed (loss: 0.178725466132164, acc: 0.9485294222831726)
[2024-12-17 03:02:24,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:24,615][root][INFO] - Training Epoch: 2/2, step 3554/7134 completed (loss: 0.3886444866657257, acc: 0.907975435256958)
[2024-12-17 03:02:24,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,018][root][INFO] - Training Epoch: 2/2, step 3555/7134 completed (loss: 0.4703570604324341, acc: 0.896774172782898)
[2024-12-17 03:02:25,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,387][root][INFO] - Training Epoch: 2/2, step 3556/7134 completed (loss: 0.22413629293441772, acc: 0.9318181872367859)
[2024-12-17 03:02:25,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:25,807][root][INFO] - Training Epoch: 2/2, step 3557/7134 completed (loss: 0.2790490388870239, acc: 0.9290780425071716)
[2024-12-17 03:02:25,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,212][root][INFO] - Training Epoch: 2/2, step 3558/7134 completed (loss: 0.425161212682724, acc: 0.9039999842643738)
[2024-12-17 03:02:26,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:26,658][root][INFO] - Training Epoch: 2/2, step 3559/7134 completed (loss: 0.21747687458992004, acc: 0.9345238208770752)
[2024-12-17 03:02:26,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,046][root][INFO] - Training Epoch: 2/2, step 3560/7134 completed (loss: 0.19201017916202545, acc: 0.9562841653823853)
[2024-12-17 03:02:27,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,460][root][INFO] - Training Epoch: 2/2, step 3561/7134 completed (loss: 0.1447315365076065, acc: 0.9661017060279846)
[2024-12-17 03:02:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:27,860][root][INFO] - Training Epoch: 2/2, step 3562/7134 completed (loss: 0.1391945481300354, acc: 0.9632353186607361)
[2024-12-17 03:02:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:28,208][root][INFO] - Training Epoch: 2/2, step 3563/7134 completed (loss: 0.21210841834545135, acc: 0.936170220375061)
[2024-12-17 03:02:29,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:29,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:30,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:31,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:32,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:34,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:35,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:36,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:37,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:38,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:39,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:40,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:41,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:42,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:43,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:44,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:45,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:46,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:47,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:48,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:49,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:50,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:51,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:52,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:53,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:54,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:55,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:56,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:57,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:58,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:02:59,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:00,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:01,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:02,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:03,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:04,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:05,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:06,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:07,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:08,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:09,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:10,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:11,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:12,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:13,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:14,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:15,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:16,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:17,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:18,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:19,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:20,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:21,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:22,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:23,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:24,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:25,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:26,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:27,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:28,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:29,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:31,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:32,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:33,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:34,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:35,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:36,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:37,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:38,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:39,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:40,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:41,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:42,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:43,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:44,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:45,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:46,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:47,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:48,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:49,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:50,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:52,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:53,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:54,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:55,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:56,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:57,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:58,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:03:59,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:00,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:02,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:03,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:04,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:05,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:06,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:07,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:08,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:09,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:10,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:11,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:12,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:14,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:15,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:16,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:17,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:18,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:19,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:20,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:21,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:22,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:23,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:26,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:27,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:28,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:29,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:30,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:31,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:32,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:33,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:34,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:35,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:36,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:37,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:38,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:39,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:40,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:41,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:42,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:43,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:44,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:46,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:47,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:48,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:50,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:51,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:52,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:54,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:55,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:56,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:57,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:58,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:04:59,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:00,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:01,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:02,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:04,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:05,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:06,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:07,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:08,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:09,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:10,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:11,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:12,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:13,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:14,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:15,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:16,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:17,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:18,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:19,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:20,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:21,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:23,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:24,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:25,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:26,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:27,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:28,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:29,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:31,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:32,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:33,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:34,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:35,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:36,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:37,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:38,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:39,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:40,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:41,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:42,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:43,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:44,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:45,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:46,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:47,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:48,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:49,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:50,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:51,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:52,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:53,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:54,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:55,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:56,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:57,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:58,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:05:59,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:02,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:03,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:04,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:05,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:06,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:07,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:08,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:09,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:10,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:12,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:13,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:14,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:15,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:16,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:17,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:18,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:19,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:20,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:21,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:22,858][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.3301, device='cuda:0') eval_epoch_loss=tensor(0.2853, device='cuda:0') eval_epoch_acc=tensor(0.9317, device='cuda:0')
[2024-12-17 03:06:22,860][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 03:06:22,861][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:06:23,123][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_3564_loss_0.2852884829044342/model.pt
[2024-12-17 03:06:23,128][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 03:06:23,129][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.2852884829044342
[2024-12-17 03:06:23,129][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9316714406013489
[2024-12-17 03:06:23,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,580][root][INFO] - Training Epoch: 2/2, step 3564/7134 completed (loss: 0.23187845945358276, acc: 0.9126983880996704)
[2024-12-17 03:06:23,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:23,958][root][INFO] - Training Epoch: 2/2, step 3565/7134 completed (loss: 0.29183337092399597, acc: 0.904411792755127)
[2024-12-17 03:06:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,340][root][INFO] - Training Epoch: 2/2, step 3566/7134 completed (loss: 0.3276088237762451, acc: 0.9159663915634155)
[2024-12-17 03:06:24,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:24,704][root][INFO] - Training Epoch: 2/2, step 3567/7134 completed (loss: 0.21583211421966553, acc: 0.9606741666793823)
[2024-12-17 03:06:24,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,098][root][INFO] - Training Epoch: 2/2, step 3568/7134 completed (loss: 0.2722189128398895, acc: 0.9290780425071716)
[2024-12-17 03:06:25,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,478][root][INFO] - Training Epoch: 2/2, step 3569/7134 completed (loss: 0.2773241400718689, acc: 0.949999988079071)
[2024-12-17 03:06:25,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:25,825][root][INFO] - Training Epoch: 2/2, step 3570/7134 completed (loss: 0.43283379077911377, acc: 0.875)
[2024-12-17 03:06:25,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,180][root][INFO] - Training Epoch: 2/2, step 3571/7134 completed (loss: 0.4862244427204132, acc: 0.8932584524154663)
[2024-12-17 03:06:26,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,571][root][INFO] - Training Epoch: 2/2, step 3572/7134 completed (loss: 0.1272398829460144, acc: 0.9583333134651184)
[2024-12-17 03:06:26,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:26,958][root][INFO] - Training Epoch: 2/2, step 3573/7134 completed (loss: 0.237451434135437, acc: 0.9671052694320679)
[2024-12-17 03:06:27,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,315][root][INFO] - Training Epoch: 2/2, step 3574/7134 completed (loss: 0.45086002349853516, acc: 0.9008264541625977)
[2024-12-17 03:06:27,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:27,686][root][INFO] - Training Epoch: 2/2, step 3575/7134 completed (loss: 0.5536608099937439, acc: 0.8947368264198303)
[2024-12-17 03:06:27,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,058][root][INFO] - Training Epoch: 2/2, step 3576/7134 completed (loss: 0.272499680519104, acc: 0.9402984976768494)
[2024-12-17 03:06:28,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,461][root][INFO] - Training Epoch: 2/2, step 3577/7134 completed (loss: 0.232904851436615, acc: 0.9226804375648499)
[2024-12-17 03:06:28,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:28,827][root][INFO] - Training Epoch: 2/2, step 3578/7134 completed (loss: 0.11136621236801147, acc: 0.9698795080184937)
[2024-12-17 03:06:28,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,181][root][INFO] - Training Epoch: 2/2, step 3579/7134 completed (loss: 0.26219919323921204, acc: 0.9244186282157898)
[2024-12-17 03:06:29,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,565][root][INFO] - Training Epoch: 2/2, step 3580/7134 completed (loss: 0.490614652633667, acc: 0.8786126971244812)
[2024-12-17 03:06:29,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:29,952][root][INFO] - Training Epoch: 2/2, step 3581/7134 completed (loss: 0.3988645672798157, acc: 0.8941176533699036)
[2024-12-17 03:06:30,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,326][root][INFO] - Training Epoch: 2/2, step 3582/7134 completed (loss: 0.3451274037361145, acc: 0.8974359035491943)
[2024-12-17 03:06:30,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:30,716][root][INFO] - Training Epoch: 2/2, step 3583/7134 completed (loss: 0.28798454999923706, acc: 0.9281437397003174)
[2024-12-17 03:06:30,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,071][root][INFO] - Training Epoch: 2/2, step 3584/7134 completed (loss: 0.28083696961402893, acc: 0.9255319237709045)
[2024-12-17 03:06:31,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,437][root][INFO] - Training Epoch: 2/2, step 3585/7134 completed (loss: 0.25888505578041077, acc: 0.9386503100395203)
[2024-12-17 03:06:31,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:31,793][root][INFO] - Training Epoch: 2/2, step 3586/7134 completed (loss: 0.2848409414291382, acc: 0.9426751732826233)
[2024-12-17 03:06:31,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,162][root][INFO] - Training Epoch: 2/2, step 3587/7134 completed (loss: 0.29649534821510315, acc: 0.9370629191398621)
[2024-12-17 03:06:32,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,548][root][INFO] - Training Epoch: 2/2, step 3588/7134 completed (loss: 0.3001764118671417, acc: 0.9248554706573486)
[2024-12-17 03:06:32,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:32,932][root][INFO] - Training Epoch: 2/2, step 3589/7134 completed (loss: 0.2852526605129242, acc: 0.9617486596107483)
[2024-12-17 03:06:33,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,321][root][INFO] - Training Epoch: 2/2, step 3590/7134 completed (loss: 0.1364004909992218, acc: 0.9777777791023254)
[2024-12-17 03:06:33,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:33,682][root][INFO] - Training Epoch: 2/2, step 3591/7134 completed (loss: 0.25264379382133484, acc: 0.9356725215911865)
[2024-12-17 03:06:33,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,077][root][INFO] - Training Epoch: 2/2, step 3592/7134 completed (loss: 0.08094052970409393, acc: 0.9785714149475098)
[2024-12-17 03:06:34,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,461][root][INFO] - Training Epoch: 2/2, step 3593/7134 completed (loss: 0.3612704873085022, acc: 0.9154929518699646)
[2024-12-17 03:06:34,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:34,833][root][INFO] - Training Epoch: 2/2, step 3594/7134 completed (loss: 0.2097707837820053, acc: 0.940397322177887)
[2024-12-17 03:06:34,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,222][root][INFO] - Training Epoch: 2/2, step 3595/7134 completed (loss: 0.23602284491062164, acc: 0.9411764740943909)
[2024-12-17 03:06:35,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,598][root][INFO] - Training Epoch: 2/2, step 3596/7134 completed (loss: 0.3491404950618744, acc: 0.9176470637321472)
[2024-12-17 03:06:35,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:35,938][root][INFO] - Training Epoch: 2/2, step 3597/7134 completed (loss: 0.22961285710334778, acc: 0.9473684430122375)
[2024-12-17 03:06:36,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,330][root][INFO] - Training Epoch: 2/2, step 3598/7134 completed (loss: 0.2620369493961334, acc: 0.928909957408905)
[2024-12-17 03:06:36,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:36,681][root][INFO] - Training Epoch: 2/2, step 3599/7134 completed (loss: 0.2765616774559021, acc: 0.9243243336677551)
[2024-12-17 03:06:36,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,044][root][INFO] - Training Epoch: 2/2, step 3600/7134 completed (loss: 0.31443729996681213, acc: 0.9326424598693848)
[2024-12-17 03:06:37,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,400][root][INFO] - Training Epoch: 2/2, step 3601/7134 completed (loss: 0.600125789642334, acc: 0.8651685118675232)
[2024-12-17 03:06:37,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:37,769][root][INFO] - Training Epoch: 2/2, step 3602/7134 completed (loss: 0.49319732189178467, acc: 0.8790697455406189)
[2024-12-17 03:06:37,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,138][root][INFO] - Training Epoch: 2/2, step 3603/7134 completed (loss: 0.25611868500709534, acc: 0.9371069073677063)
[2024-12-17 03:06:38,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,480][root][INFO] - Training Epoch: 2/2, step 3604/7134 completed (loss: 0.3388959765434265, acc: 0.8976377844810486)
[2024-12-17 03:06:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:38,854][root][INFO] - Training Epoch: 2/2, step 3605/7134 completed (loss: 0.2824898362159729, acc: 0.9372197389602661)
[2024-12-17 03:06:38,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,230][root][INFO] - Training Epoch: 2/2, step 3606/7134 completed (loss: 0.4692305028438568, acc: 0.8904109597206116)
[2024-12-17 03:06:39,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:39,614][root][INFO] - Training Epoch: 2/2, step 3607/7134 completed (loss: 0.219417542219162, acc: 0.9178082346916199)
[2024-12-17 03:06:39,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,003][root][INFO] - Training Epoch: 2/2, step 3608/7134 completed (loss: 0.35709521174430847, acc: 0.9320388436317444)
[2024-12-17 03:06:40,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,393][root][INFO] - Training Epoch: 2/2, step 3609/7134 completed (loss: 0.16435232758522034, acc: 0.9526315927505493)
[2024-12-17 03:06:40,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:40,779][root][INFO] - Training Epoch: 2/2, step 3610/7134 completed (loss: 0.3628818690776825, acc: 0.9285714030265808)
[2024-12-17 03:06:40,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,159][root][INFO] - Training Epoch: 2/2, step 3611/7134 completed (loss: 0.2745766043663025, acc: 0.9314285516738892)
[2024-12-17 03:06:41,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,532][root][INFO] - Training Epoch: 2/2, step 3612/7134 completed (loss: 0.44479796290397644, acc: 0.8836206793785095)
[2024-12-17 03:06:41,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:41,910][root][INFO] - Training Epoch: 2/2, step 3613/7134 completed (loss: 0.23682540655136108, acc: 0.9344262480735779)
[2024-12-17 03:06:42,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,288][root][INFO] - Training Epoch: 2/2, step 3614/7134 completed (loss: 0.16993309557437897, acc: 0.957446813583374)
[2024-12-17 03:06:42,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:42,658][root][INFO] - Training Epoch: 2/2, step 3615/7134 completed (loss: 0.19484905898571014, acc: 0.9594594836235046)
[2024-12-17 03:06:42,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,031][root][INFO] - Training Epoch: 2/2, step 3616/7134 completed (loss: 0.327363520860672, acc: 0.9192546606063843)
[2024-12-17 03:06:43,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,389][root][INFO] - Training Epoch: 2/2, step 3617/7134 completed (loss: 0.19938057661056519, acc: 0.929729700088501)
[2024-12-17 03:06:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:43,781][root][INFO] - Training Epoch: 2/2, step 3618/7134 completed (loss: 0.31107401847839355, acc: 0.9141104221343994)
[2024-12-17 03:06:43,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,164][root][INFO] - Training Epoch: 2/2, step 3619/7134 completed (loss: 0.43357568979263306, acc: 0.8820960521697998)
[2024-12-17 03:06:44,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,548][root][INFO] - Training Epoch: 2/2, step 3620/7134 completed (loss: 0.28030145168304443, acc: 0.9341317415237427)
[2024-12-17 03:06:44,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:44,933][root][INFO] - Training Epoch: 2/2, step 3621/7134 completed (loss: 0.20347896218299866, acc: 0.9426751732826233)
[2024-12-17 03:06:45,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,320][root][INFO] - Training Epoch: 2/2, step 3622/7134 completed (loss: 0.16600468754768372, acc: 0.9415584206581116)
[2024-12-17 03:06:45,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:45,661][root][INFO] - Training Epoch: 2/2, step 3623/7134 completed (loss: 0.1719048172235489, acc: 0.9464285969734192)
[2024-12-17 03:06:45,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,028][root][INFO] - Training Epoch: 2/2, step 3624/7134 completed (loss: 0.19718772172927856, acc: 0.971222996711731)
[2024-12-17 03:06:46,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,380][root][INFO] - Training Epoch: 2/2, step 3625/7134 completed (loss: 0.5048614740371704, acc: 0.8823529481887817)
[2024-12-17 03:06:46,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:46,732][root][INFO] - Training Epoch: 2/2, step 3626/7134 completed (loss: 0.5074590444564819, acc: 0.898876428604126)
[2024-12-17 03:06:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,089][root][INFO] - Training Epoch: 2/2, step 3627/7134 completed (loss: 0.4176104962825775, acc: 0.8773584961891174)
[2024-12-17 03:06:47,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,454][root][INFO] - Training Epoch: 2/2, step 3628/7134 completed (loss: 0.36190780997276306, acc: 0.9047619104385376)
[2024-12-17 03:06:47,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:47,798][root][INFO] - Training Epoch: 2/2, step 3629/7134 completed (loss: 0.3592996299266815, acc: 0.8951612710952759)
[2024-12-17 03:06:47,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,143][root][INFO] - Training Epoch: 2/2, step 3630/7134 completed (loss: 0.2127217799425125, acc: 0.9569892287254333)
[2024-12-17 03:06:48,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,506][root][INFO] - Training Epoch: 2/2, step 3631/7134 completed (loss: 0.2841116487979889, acc: 0.9142857193946838)
[2024-12-17 03:06:48,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:48,862][root][INFO] - Training Epoch: 2/2, step 3632/7134 completed (loss: 0.19624187052249908, acc: 0.9754098653793335)
[2024-12-17 03:06:48,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,223][root][INFO] - Training Epoch: 2/2, step 3633/7134 completed (loss: 0.23399503529071808, acc: 0.9426751732826233)
[2024-12-17 03:06:49,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,580][root][INFO] - Training Epoch: 2/2, step 3634/7134 completed (loss: 0.3092672824859619, acc: 0.9345794320106506)
[2024-12-17 03:06:49,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:49,952][root][INFO] - Training Epoch: 2/2, step 3635/7134 completed (loss: 0.22607985138893127, acc: 0.9482758641242981)
[2024-12-17 03:06:50,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,352][root][INFO] - Training Epoch: 2/2, step 3636/7134 completed (loss: 0.18826131522655487, acc: 0.9528301954269409)
[2024-12-17 03:06:50,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:50,735][root][INFO] - Training Epoch: 2/2, step 3637/7134 completed (loss: 0.29393020272254944, acc: 0.9272727370262146)
[2024-12-17 03:06:50,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,087][root][INFO] - Training Epoch: 2/2, step 3638/7134 completed (loss: 0.19558051228523254, acc: 0.9560439586639404)
[2024-12-17 03:06:51,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,475][root][INFO] - Training Epoch: 2/2, step 3639/7134 completed (loss: 0.2071162462234497, acc: 0.9680851101875305)
[2024-12-17 03:06:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:51,866][root][INFO] - Training Epoch: 2/2, step 3640/7134 completed (loss: 0.21936611831188202, acc: 0.9504132270812988)
[2024-12-17 03:06:51,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,225][root][INFO] - Training Epoch: 2/2, step 3641/7134 completed (loss: 0.10454173386096954, acc: 0.975806474685669)
[2024-12-17 03:06:52,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,612][root][INFO] - Training Epoch: 2/2, step 3642/7134 completed (loss: 0.08097269386053085, acc: 0.9664429426193237)
[2024-12-17 03:06:52,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:52,981][root][INFO] - Training Epoch: 2/2, step 3643/7134 completed (loss: 0.17551667988300323, acc: 0.9375)
[2024-12-17 03:06:53,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,358][root][INFO] - Training Epoch: 2/2, step 3644/7134 completed (loss: 0.3026651442050934, acc: 0.9324324131011963)
[2024-12-17 03:06:53,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:53,741][root][INFO] - Training Epoch: 2/2, step 3645/7134 completed (loss: 0.4127354919910431, acc: 0.90625)
[2024-12-17 03:06:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,103][root][INFO] - Training Epoch: 2/2, step 3646/7134 completed (loss: 0.41524770855903625, acc: 0.8787878751754761)
[2024-12-17 03:06:54,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,487][root][INFO] - Training Epoch: 2/2, step 3647/7134 completed (loss: 0.15697771310806274, acc: 0.9775280952453613)
[2024-12-17 03:06:54,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:54,873][root][INFO] - Training Epoch: 2/2, step 3648/7134 completed (loss: 0.27592116594314575, acc: 0.9171597361564636)
[2024-12-17 03:06:55,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,256][root][INFO] - Training Epoch: 2/2, step 3649/7134 completed (loss: 0.3095172643661499, acc: 0.9194630980491638)
[2024-12-17 03:06:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:55,641][root][INFO] - Training Epoch: 2/2, step 3650/7134 completed (loss: 0.20128285884857178, acc: 0.9289940595626831)
[2024-12-17 03:06:55,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,014][root][INFO] - Training Epoch: 2/2, step 3651/7134 completed (loss: 0.3025948405265808, acc: 0.9337349534034729)
[2024-12-17 03:06:56,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,367][root][INFO] - Training Epoch: 2/2, step 3652/7134 completed (loss: 0.2567990720272064, acc: 0.9319728016853333)
[2024-12-17 03:06:56,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:56,729][root][INFO] - Training Epoch: 2/2, step 3653/7134 completed (loss: 0.37320250272750854, acc: 0.9202454090118408)
[2024-12-17 03:06:56,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,115][root][INFO] - Training Epoch: 2/2, step 3654/7134 completed (loss: 0.12202636152505875, acc: 0.9599999785423279)
[2024-12-17 03:06:57,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,492][root][INFO] - Training Epoch: 2/2, step 3655/7134 completed (loss: 0.43925708532333374, acc: 0.8922155499458313)
[2024-12-17 03:06:57,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:57,843][root][INFO] - Training Epoch: 2/2, step 3656/7134 completed (loss: 0.41941922903060913, acc: 0.9202898740768433)
[2024-12-17 03:06:57,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,228][root][INFO] - Training Epoch: 2/2, step 3657/7134 completed (loss: 0.140219047665596, acc: 0.9440559148788452)
[2024-12-17 03:06:58,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,586][root][INFO] - Training Epoch: 2/2, step 3658/7134 completed (loss: 0.23722243309020996, acc: 0.9444444179534912)
[2024-12-17 03:06:58,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:58,949][root][INFO] - Training Epoch: 2/2, step 3659/7134 completed (loss: 0.30919110774993896, acc: 0.9455782175064087)
[2024-12-17 03:06:59,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,293][root][INFO] - Training Epoch: 2/2, step 3660/7134 completed (loss: 0.40647727251052856, acc: 0.8765432238578796)
[2024-12-17 03:06:59,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:06:59,645][root][INFO] - Training Epoch: 2/2, step 3661/7134 completed (loss: 0.23809406161308289, acc: 0.9571428298950195)
[2024-12-17 03:06:59,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,027][root][INFO] - Training Epoch: 2/2, step 3662/7134 completed (loss: 0.4587010443210602, acc: 0.8944099545478821)
[2024-12-17 03:07:00,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,422][root][INFO] - Training Epoch: 2/2, step 3663/7134 completed (loss: 0.3889378309249878, acc: 0.8671875)
[2024-12-17 03:07:00,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:00,835][root][INFO] - Training Epoch: 2/2, step 3664/7134 completed (loss: 0.4373905062675476, acc: 0.8831169009208679)
[2024-12-17 03:07:00,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,214][root][INFO] - Training Epoch: 2/2, step 3665/7134 completed (loss: 0.2864733636379242, acc: 0.9256756901741028)
[2024-12-17 03:07:01,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,590][root][INFO] - Training Epoch: 2/2, step 3666/7134 completed (loss: 0.3152827322483063, acc: 0.9178082346916199)
[2024-12-17 03:07:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:01,948][root][INFO] - Training Epoch: 2/2, step 3667/7134 completed (loss: 0.5792889595031738, acc: 0.8682170510292053)
[2024-12-17 03:07:02,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,318][root][INFO] - Training Epoch: 2/2, step 3668/7134 completed (loss: 0.3066319525241852, acc: 0.9241379499435425)
[2024-12-17 03:07:02,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:02,677][root][INFO] - Training Epoch: 2/2, step 3669/7134 completed (loss: 0.15380431711673737, acc: 0.942148745059967)
[2024-12-17 03:07:02,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,021][root][INFO] - Training Epoch: 2/2, step 3670/7134 completed (loss: 0.1008264347910881, acc: 0.9638554453849792)
[2024-12-17 03:07:03,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,384][root][INFO] - Training Epoch: 2/2, step 3671/7134 completed (loss: 0.13440679013729095, acc: 0.9746835231781006)
[2024-12-17 03:07:03,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:03,784][root][INFO] - Training Epoch: 2/2, step 3672/7134 completed (loss: 0.14796662330627441, acc: 0.9613259434700012)
[2024-12-17 03:07:03,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,154][root][INFO] - Training Epoch: 2/2, step 3673/7134 completed (loss: 0.21064965426921844, acc: 0.951724112033844)
[2024-12-17 03:07:04,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,500][root][INFO] - Training Epoch: 2/2, step 3674/7134 completed (loss: 0.08677458018064499, acc: 0.9729729890823364)
[2024-12-17 03:07:04,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:04,868][root][INFO] - Training Epoch: 2/2, step 3675/7134 completed (loss: 0.14990761876106262, acc: 0.9668508172035217)
[2024-12-17 03:07:04,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,217][root][INFO] - Training Epoch: 2/2, step 3676/7134 completed (loss: 0.2274508774280548, acc: 0.9551281929016113)
[2024-12-17 03:07:05,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,613][root][INFO] - Training Epoch: 2/2, step 3677/7134 completed (loss: 0.3210562765598297, acc: 0.9261363744735718)
[2024-12-17 03:07:05,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:05,992][root][INFO] - Training Epoch: 2/2, step 3678/7134 completed (loss: 0.23290276527404785, acc: 0.9430379867553711)
[2024-12-17 03:07:06,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,368][root][INFO] - Training Epoch: 2/2, step 3679/7134 completed (loss: 0.20021699368953705, acc: 0.9307692050933838)
[2024-12-17 03:07:06,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:06,751][root][INFO] - Training Epoch: 2/2, step 3680/7134 completed (loss: 0.2506582736968994, acc: 0.9399999976158142)
[2024-12-17 03:07:06,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,133][root][INFO] - Training Epoch: 2/2, step 3681/7134 completed (loss: 0.12241250276565552, acc: 0.9750000238418579)
[2024-12-17 03:07:07,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,499][root][INFO] - Training Epoch: 2/2, step 3682/7134 completed (loss: 0.15594975650310516, acc: 0.9702380895614624)
[2024-12-17 03:07:07,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:07,888][root][INFO] - Training Epoch: 2/2, step 3683/7134 completed (loss: 0.08556551486253738, acc: 0.9926470518112183)
[2024-12-17 03:07:08,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,265][root][INFO] - Training Epoch: 2/2, step 3684/7134 completed (loss: 0.054166022688150406, acc: 0.9934210777282715)
[2024-12-17 03:07:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,603][root][INFO] - Training Epoch: 2/2, step 3685/7134 completed (loss: 0.12480158358812332, acc: 0.9756097793579102)
[2024-12-17 03:07:08,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:08,941][root][INFO] - Training Epoch: 2/2, step 3686/7134 completed (loss: 0.10704538226127625, acc: 0.9647887349128723)
[2024-12-17 03:07:09,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,320][root][INFO] - Training Epoch: 2/2, step 3687/7134 completed (loss: 0.12242110818624496, acc: 0.9627329111099243)
[2024-12-17 03:07:09,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:09,683][root][INFO] - Training Epoch: 2/2, step 3688/7134 completed (loss: 0.10615850985050201, acc: 0.9833333492279053)
[2024-12-17 03:07:09,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,046][root][INFO] - Training Epoch: 2/2, step 3689/7134 completed (loss: 0.2727435827255249, acc: 0.9503546357154846)
[2024-12-17 03:07:10,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,421][root][INFO] - Training Epoch: 2/2, step 3690/7134 completed (loss: 0.10896018892526627, acc: 0.9810126423835754)
[2024-12-17 03:07:10,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:10,794][root][INFO] - Training Epoch: 2/2, step 3691/7134 completed (loss: 0.29065561294555664, acc: 0.9405940771102905)
[2024-12-17 03:07:10,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,178][root][INFO] - Training Epoch: 2/2, step 3692/7134 completed (loss: 0.1449938416481018, acc: 0.9509202241897583)
[2024-12-17 03:07:11,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,547][root][INFO] - Training Epoch: 2/2, step 3693/7134 completed (loss: 0.061092499643564224, acc: 0.9924242496490479)
[2024-12-17 03:07:11,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:11,905][root][INFO] - Training Epoch: 2/2, step 3694/7134 completed (loss: 0.15197007358074188, acc: 0.96875)
[2024-12-17 03:07:12,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,262][root][INFO] - Training Epoch: 2/2, step 3695/7134 completed (loss: 0.08416637778282166, acc: 0.9745222926139832)
[2024-12-17 03:07:12,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:12,630][root][INFO] - Training Epoch: 2/2, step 3696/7134 completed (loss: 0.12073260545730591, acc: 0.982758641242981)
[2024-12-17 03:07:12,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,000][root][INFO] - Training Epoch: 2/2, step 3697/7134 completed (loss: 0.0866989716887474, acc: 0.9817073345184326)
[2024-12-17 03:07:13,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,382][root][INFO] - Training Epoch: 2/2, step 3698/7134 completed (loss: 0.053066685795784, acc: 0.9862068891525269)
[2024-12-17 03:07:13,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:13,750][root][INFO] - Training Epoch: 2/2, step 3699/7134 completed (loss: 0.08260872960090637, acc: 0.9842519760131836)
[2024-12-17 03:07:13,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,142][root][INFO] - Training Epoch: 2/2, step 3700/7134 completed (loss: 0.07252978533506393, acc: 0.9685534834861755)
[2024-12-17 03:07:14,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,537][root][INFO] - Training Epoch: 2/2, step 3701/7134 completed (loss: 0.11070552468299866, acc: 0.970802903175354)
[2024-12-17 03:07:14,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:14,924][root][INFO] - Training Epoch: 2/2, step 3702/7134 completed (loss: 0.12477806210517883, acc: 0.9757575988769531)
[2024-12-17 03:07:15,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,284][root][INFO] - Training Epoch: 2/2, step 3703/7134 completed (loss: 0.10344982892274857, acc: 0.9886363744735718)
[2024-12-17 03:07:15,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:15,657][root][INFO] - Training Epoch: 2/2, step 3704/7134 completed (loss: 0.16275709867477417, acc: 0.9702970385551453)
[2024-12-17 03:07:15,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,036][root][INFO] - Training Epoch: 2/2, step 3705/7134 completed (loss: 0.30871930718421936, acc: 0.9325153231620789)
[2024-12-17 03:07:16,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,427][root][INFO] - Training Epoch: 2/2, step 3706/7134 completed (loss: 0.3430941104888916, acc: 0.9356435537338257)
[2024-12-17 03:07:16,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:16,821][root][INFO] - Training Epoch: 2/2, step 3707/7134 completed (loss: 0.08675527572631836, acc: 0.9866666793823242)
[2024-12-17 03:07:16,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,205][root][INFO] - Training Epoch: 2/2, step 3708/7134 completed (loss: 0.2556345760822296, acc: 0.9384615421295166)
[2024-12-17 03:07:17,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,586][root][INFO] - Training Epoch: 2/2, step 3709/7134 completed (loss: 0.13659964501857758, acc: 0.9675925970077515)
[2024-12-17 03:07:17,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:17,979][root][INFO] - Training Epoch: 2/2, step 3710/7134 completed (loss: 0.16891001164913177, acc: 0.9537037014961243)
[2024-12-17 03:07:18,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,345][root][INFO] - Training Epoch: 2/2, step 3711/7134 completed (loss: 0.15765754878520966, acc: 0.9670329689979553)
[2024-12-17 03:07:18,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:18,711][root][INFO] - Training Epoch: 2/2, step 3712/7134 completed (loss: 0.3197208344936371, acc: 0.9130434989929199)
[2024-12-17 03:07:18,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,061][root][INFO] - Training Epoch: 2/2, step 3713/7134 completed (loss: 0.1808462291955948, acc: 0.9568345546722412)
[2024-12-17 03:07:19,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,443][root][INFO] - Training Epoch: 2/2, step 3714/7134 completed (loss: 0.24244247376918793, acc: 0.9326424598693848)
[2024-12-17 03:07:19,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:19,783][root][INFO] - Training Epoch: 2/2, step 3715/7134 completed (loss: 0.16018983721733093, acc: 0.9627659320831299)
[2024-12-17 03:07:19,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,143][root][INFO] - Training Epoch: 2/2, step 3716/7134 completed (loss: 0.24977010488510132, acc: 0.9390863180160522)
[2024-12-17 03:07:20,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,485][root][INFO] - Training Epoch: 2/2, step 3717/7134 completed (loss: 0.16606169939041138, acc: 0.9451219439506531)
[2024-12-17 03:07:20,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:20,849][root][INFO] - Training Epoch: 2/2, step 3718/7134 completed (loss: 0.23955774307250977, acc: 0.9739583134651184)
[2024-12-17 03:07:20,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,238][root][INFO] - Training Epoch: 2/2, step 3719/7134 completed (loss: 0.25333088636398315, acc: 0.9473684430122375)
[2024-12-17 03:07:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:21,616][root][INFO] - Training Epoch: 2/2, step 3720/7134 completed (loss: 0.07568110525608063, acc: 0.9810126423835754)
[2024-12-17 03:07:21,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,007][root][INFO] - Training Epoch: 2/2, step 3721/7134 completed (loss: 0.17679280042648315, acc: 0.9479768872261047)
[2024-12-17 03:07:22,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,378][root][INFO] - Training Epoch: 2/2, step 3722/7134 completed (loss: 0.18771933019161224, acc: 0.9533678889274597)
[2024-12-17 03:07:22,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:22,741][root][INFO] - Training Epoch: 2/2, step 3723/7134 completed (loss: 0.1703089475631714, acc: 0.9419354796409607)
[2024-12-17 03:07:22,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,106][root][INFO] - Training Epoch: 2/2, step 3724/7134 completed (loss: 0.09444079548120499, acc: 0.9819276928901672)
[2024-12-17 03:07:23,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,491][root][INFO] - Training Epoch: 2/2, step 3725/7134 completed (loss: 0.37071582674980164, acc: 0.9512194991111755)
[2024-12-17 03:07:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:23,891][root][INFO] - Training Epoch: 2/2, step 3726/7134 completed (loss: 0.1901743859052658, acc: 0.9547738432884216)
[2024-12-17 03:07:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,258][root][INFO] - Training Epoch: 2/2, step 3727/7134 completed (loss: 0.16525927186012268, acc: 0.9479768872261047)
[2024-12-17 03:07:24,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:24,644][root][INFO] - Training Epoch: 2/2, step 3728/7134 completed (loss: 0.13775067031383514, acc: 0.9605911374092102)
[2024-12-17 03:07:24,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,017][root][INFO] - Training Epoch: 2/2, step 3729/7134 completed (loss: 0.1546989530324936, acc: 0.9622641801834106)
[2024-12-17 03:07:25,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,389][root][INFO] - Training Epoch: 2/2, step 3730/7134 completed (loss: 0.15835638344287872, acc: 0.9636363387107849)
[2024-12-17 03:07:25,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:25,746][root][INFO] - Training Epoch: 2/2, step 3731/7134 completed (loss: 0.140875443816185, acc: 0.954023003578186)
[2024-12-17 03:07:25,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,123][root][INFO] - Training Epoch: 2/2, step 3732/7134 completed (loss: 0.10687190294265747, acc: 0.9794871807098389)
[2024-12-17 03:07:26,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,493][root][INFO] - Training Epoch: 2/2, step 3733/7134 completed (loss: 0.21198038756847382, acc: 0.9627329111099243)
[2024-12-17 03:07:26,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:26,856][root][INFO] - Training Epoch: 2/2, step 3734/7134 completed (loss: 0.3598806858062744, acc: 0.8974359035491943)
[2024-12-17 03:07:26,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,219][root][INFO] - Training Epoch: 2/2, step 3735/7134 completed (loss: 0.25889477133750916, acc: 0.9350649118423462)
[2024-12-17 03:07:27,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,598][root][INFO] - Training Epoch: 2/2, step 3736/7134 completed (loss: 0.20800353586673737, acc: 0.9411764740943909)
[2024-12-17 03:07:27,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:27,987][root][INFO] - Training Epoch: 2/2, step 3737/7134 completed (loss: 0.18685241043567657, acc: 0.9333333373069763)
[2024-12-17 03:07:28,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,369][root][INFO] - Training Epoch: 2/2, step 3738/7134 completed (loss: 0.07444030791521072, acc: 0.9861111044883728)
[2024-12-17 03:07:28,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:28,732][root][INFO] - Training Epoch: 2/2, step 3739/7134 completed (loss: 0.24276036024093628, acc: 0.9255319237709045)
[2024-12-17 03:07:28,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,108][root][INFO] - Training Epoch: 2/2, step 3740/7134 completed (loss: 0.1754937320947647, acc: 0.9426751732826233)
[2024-12-17 03:07:29,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,497][root][INFO] - Training Epoch: 2/2, step 3741/7134 completed (loss: 0.18110911548137665, acc: 0.9655172228813171)
[2024-12-17 03:07:29,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:29,846][root][INFO] - Training Epoch: 2/2, step 3742/7134 completed (loss: 0.24107368290424347, acc: 0.9455782175064087)
[2024-12-17 03:07:29,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,229][root][INFO] - Training Epoch: 2/2, step 3743/7134 completed (loss: 0.19350385665893555, acc: 0.9529411792755127)
[2024-12-17 03:07:30,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,612][root][INFO] - Training Epoch: 2/2, step 3744/7134 completed (loss: 0.19955064356327057, acc: 0.9534883499145508)
[2024-12-17 03:07:30,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:30,958][root][INFO] - Training Epoch: 2/2, step 3745/7134 completed (loss: 0.30475687980651855, acc: 0.9523809552192688)
[2024-12-17 03:07:31,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,304][root][INFO] - Training Epoch: 2/2, step 3746/7134 completed (loss: 0.18752606213092804, acc: 0.9717513918876648)
[2024-12-17 03:07:31,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:31,699][root][INFO] - Training Epoch: 2/2, step 3747/7134 completed (loss: 0.16618169844150543, acc: 0.9388889074325562)
[2024-12-17 03:07:31,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,065][root][INFO] - Training Epoch: 2/2, step 3748/7134 completed (loss: 0.2095974087715149, acc: 0.9466666579246521)
[2024-12-17 03:07:32,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,426][root][INFO] - Training Epoch: 2/2, step 3749/7134 completed (loss: 0.2697526514530182, acc: 0.9404761791229248)
[2024-12-17 03:07:32,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:32,822][root][INFO] - Training Epoch: 2/2, step 3750/7134 completed (loss: 0.07959368824958801, acc: 0.987730085849762)
[2024-12-17 03:07:32,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,205][root][INFO] - Training Epoch: 2/2, step 3751/7134 completed (loss: 0.17840071022510529, acc: 0.9337349534034729)
[2024-12-17 03:07:33,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,587][root][INFO] - Training Epoch: 2/2, step 3752/7134 completed (loss: 0.2812659442424774, acc: 0.9371069073677063)
[2024-12-17 03:07:33,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:33,956][root][INFO] - Training Epoch: 2/2, step 3753/7134 completed (loss: 0.3505442142486572, acc: 0.9018405079841614)
[2024-12-17 03:07:34,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,338][root][INFO] - Training Epoch: 2/2, step 3754/7134 completed (loss: 0.07246823608875275, acc: 0.9806451797485352)
[2024-12-17 03:07:34,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:34,702][root][INFO] - Training Epoch: 2/2, step 3755/7134 completed (loss: 0.17744803428649902, acc: 0.9504132270812988)
[2024-12-17 03:07:34,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,068][root][INFO] - Training Epoch: 2/2, step 3756/7134 completed (loss: 0.2807002365589142, acc: 0.9248554706573486)
[2024-12-17 03:07:35,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,451][root][INFO] - Training Epoch: 2/2, step 3757/7134 completed (loss: 0.38656821846961975, acc: 0.9025974273681641)
[2024-12-17 03:07:35,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:35,792][root][INFO] - Training Epoch: 2/2, step 3758/7134 completed (loss: 0.1951676607131958, acc: 0.9448819160461426)
[2024-12-17 03:07:35,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,162][root][INFO] - Training Epoch: 2/2, step 3759/7134 completed (loss: 0.24845470488071442, acc: 0.9370629191398621)
[2024-12-17 03:07:36,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,534][root][INFO] - Training Epoch: 2/2, step 3760/7134 completed (loss: 0.29761824011802673, acc: 0.9390243887901306)
[2024-12-17 03:07:36,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:36,902][root][INFO] - Training Epoch: 2/2, step 3761/7134 completed (loss: 0.11551377177238464, acc: 0.9696969985961914)
[2024-12-17 03:07:37,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,272][root][INFO] - Training Epoch: 2/2, step 3762/7134 completed (loss: 0.17223426699638367, acc: 0.9605262875556946)
[2024-12-17 03:07:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:37,654][root][INFO] - Training Epoch: 2/2, step 3763/7134 completed (loss: 0.09556484967470169, acc: 0.9714285731315613)
[2024-12-17 03:07:37,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,033][root][INFO] - Training Epoch: 2/2, step 3764/7134 completed (loss: 0.1213371604681015, acc: 0.970059871673584)
[2024-12-17 03:07:38,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,427][root][INFO] - Training Epoch: 2/2, step 3765/7134 completed (loss: 0.17546699941158295, acc: 0.9602272510528564)
[2024-12-17 03:07:38,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:38,797][root][INFO] - Training Epoch: 2/2, step 3766/7134 completed (loss: 0.1963566541671753, acc: 0.9530201554298401)
[2024-12-17 03:07:38,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,176][root][INFO] - Training Epoch: 2/2, step 3767/7134 completed (loss: 0.22078700363636017, acc: 0.9329608678817749)
[2024-12-17 03:07:39,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,545][root][INFO] - Training Epoch: 2/2, step 3768/7134 completed (loss: 0.18840628862380981, acc: 0.9519230723381042)
[2024-12-17 03:07:39,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:39,932][root][INFO] - Training Epoch: 2/2, step 3769/7134 completed (loss: 0.20846936106681824, acc: 0.929411768913269)
[2024-12-17 03:07:40,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,309][root][INFO] - Training Epoch: 2/2, step 3770/7134 completed (loss: 0.12610077857971191, acc: 0.9664429426193237)
[2024-12-17 03:07:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:40,681][root][INFO] - Training Epoch: 2/2, step 3771/7134 completed (loss: 0.06235694885253906, acc: 0.9934210777282715)
[2024-12-17 03:07:40,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,059][root][INFO] - Training Epoch: 2/2, step 3772/7134 completed (loss: 0.16836512088775635, acc: 0.949999988079071)
[2024-12-17 03:07:41,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,421][root][INFO] - Training Epoch: 2/2, step 3773/7134 completed (loss: 0.12167885154485703, acc: 0.9680851101875305)
[2024-12-17 03:07:41,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:41,773][root][INFO] - Training Epoch: 2/2, step 3774/7134 completed (loss: 0.200607568025589, acc: 0.9450549483299255)
[2024-12-17 03:07:41,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,138][root][INFO] - Training Epoch: 2/2, step 3775/7134 completed (loss: 0.15612980723381042, acc: 0.9440993666648865)
[2024-12-17 03:07:42,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,528][root][INFO] - Training Epoch: 2/2, step 3776/7134 completed (loss: 0.24450458586215973, acc: 0.9551281929016113)
[2024-12-17 03:07:42,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:42,878][root][INFO] - Training Epoch: 2/2, step 3777/7134 completed (loss: 0.14045993983745575, acc: 0.9470587968826294)
[2024-12-17 03:07:42,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,243][root][INFO] - Training Epoch: 2/2, step 3778/7134 completed (loss: 0.1985742598772049, acc: 0.9593023061752319)
[2024-12-17 03:07:43,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,601][root][INFO] - Training Epoch: 2/2, step 3779/7134 completed (loss: 0.2005365788936615, acc: 0.949999988079071)
[2024-12-17 03:07:43,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:43,961][root][INFO] - Training Epoch: 2/2, step 3780/7134 completed (loss: 0.09955311566591263, acc: 0.9757575988769531)
[2024-12-17 03:07:44,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,340][root][INFO] - Training Epoch: 2/2, step 3781/7134 completed (loss: 0.22122500836849213, acc: 0.9503105878829956)
[2024-12-17 03:07:44,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:44,711][root][INFO] - Training Epoch: 2/2, step 3782/7134 completed (loss: 0.17443381249904633, acc: 0.9433962106704712)
[2024-12-17 03:07:44,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,091][root][INFO] - Training Epoch: 2/2, step 3783/7134 completed (loss: 0.22973988950252533, acc: 0.9289940595626831)
[2024-12-17 03:07:45,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,484][root][INFO] - Training Epoch: 2/2, step 3784/7134 completed (loss: 0.24384456872940063, acc: 0.9530201554298401)
[2024-12-17 03:07:45,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:45,851][root][INFO] - Training Epoch: 2/2, step 3785/7134 completed (loss: 0.14914169907569885, acc: 0.9645389914512634)
[2024-12-17 03:07:45,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,233][root][INFO] - Training Epoch: 2/2, step 3786/7134 completed (loss: 0.1143508180975914, acc: 0.976190447807312)
[2024-12-17 03:07:46,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,569][root][INFO] - Training Epoch: 2/2, step 3787/7134 completed (loss: 0.12329775094985962, acc: 0.9615384340286255)
[2024-12-17 03:07:46,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:46,944][root][INFO] - Training Epoch: 2/2, step 3788/7134 completed (loss: 0.23986205458641052, acc: 0.9570552110671997)
[2024-12-17 03:07:47,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,306][root][INFO] - Training Epoch: 2/2, step 3789/7134 completed (loss: 0.20246319472789764, acc: 0.9352940917015076)
[2024-12-17 03:07:47,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:47,681][root][INFO] - Training Epoch: 2/2, step 3790/7134 completed (loss: 0.42066216468811035, acc: 0.8999999761581421)
[2024-12-17 03:07:47,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,034][root][INFO] - Training Epoch: 2/2, step 3791/7134 completed (loss: 0.1535509079694748, acc: 0.9595375657081604)
[2024-12-17 03:07:48,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,375][root][INFO] - Training Epoch: 2/2, step 3792/7134 completed (loss: 0.13893213868141174, acc: 0.969924807548523)
[2024-12-17 03:07:48,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:48,755][root][INFO] - Training Epoch: 2/2, step 3793/7134 completed (loss: 0.17692439258098602, acc: 0.959770143032074)
[2024-12-17 03:07:48,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,125][root][INFO] - Training Epoch: 2/2, step 3794/7134 completed (loss: 0.3913628160953522, acc: 0.9166666865348816)
[2024-12-17 03:07:49,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,527][root][INFO] - Training Epoch: 2/2, step 3795/7134 completed (loss: 0.2221439629793167, acc: 0.9444444179534912)
[2024-12-17 03:07:49,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:49,898][root][INFO] - Training Epoch: 2/2, step 3796/7134 completed (loss: 0.16340041160583496, acc: 0.9532163739204407)
[2024-12-17 03:07:50,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,255][root][INFO] - Training Epoch: 2/2, step 3797/7134 completed (loss: 0.13808180391788483, acc: 0.9636363387107849)
[2024-12-17 03:07:50,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:50,652][root][INFO] - Training Epoch: 2/2, step 3798/7134 completed (loss: 0.3860870599746704, acc: 0.9056603908538818)
[2024-12-17 03:07:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,040][root][INFO] - Training Epoch: 2/2, step 3799/7134 completed (loss: 0.3303793966770172, acc: 0.9378530979156494)
[2024-12-17 03:07:51,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,415][root][INFO] - Training Epoch: 2/2, step 3800/7134 completed (loss: 0.4056580066680908, acc: 0.9172413945198059)
[2024-12-17 03:07:51,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:51,789][root][INFO] - Training Epoch: 2/2, step 3801/7134 completed (loss: 0.2400495558977127, acc: 0.9613259434700012)
[2024-12-17 03:07:51,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,160][root][INFO] - Training Epoch: 2/2, step 3802/7134 completed (loss: 0.2169923335313797, acc: 0.9322916865348816)
[2024-12-17 03:07:52,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,515][root][INFO] - Training Epoch: 2/2, step 3803/7134 completed (loss: 0.20375072956085205, acc: 0.9426751732826233)
[2024-12-17 03:07:52,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:52,865][root][INFO] - Training Epoch: 2/2, step 3804/7134 completed (loss: 0.272027850151062, acc: 0.9436619877815247)
[2024-12-17 03:07:52,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,242][root][INFO] - Training Epoch: 2/2, step 3805/7134 completed (loss: 0.19446107745170593, acc: 0.9599999785423279)
[2024-12-17 03:07:53,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,585][root][INFO] - Training Epoch: 2/2, step 3806/7134 completed (loss: 0.19308052957057953, acc: 0.9444444179534912)
[2024-12-17 03:07:53,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:53,975][root][INFO] - Training Epoch: 2/2, step 3807/7134 completed (loss: 0.16903935372829437, acc: 0.9589040875434875)
[2024-12-17 03:07:54,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,362][root][INFO] - Training Epoch: 2/2, step 3808/7134 completed (loss: 0.191567063331604, acc: 0.95652174949646)
[2024-12-17 03:07:54,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:54,725][root][INFO] - Training Epoch: 2/2, step 3809/7134 completed (loss: 0.1991804987192154, acc: 0.9593023061752319)
[2024-12-17 03:07:54,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,081][root][INFO] - Training Epoch: 2/2, step 3810/7134 completed (loss: 0.204257994890213, acc: 0.9415584206581116)
[2024-12-17 03:07:55,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,447][root][INFO] - Training Epoch: 2/2, step 3811/7134 completed (loss: 0.38030150532722473, acc: 0.916167676448822)
[2024-12-17 03:07:55,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:55,821][root][INFO] - Training Epoch: 2/2, step 3812/7134 completed (loss: 0.3655686378479004, acc: 0.918367326259613)
[2024-12-17 03:07:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,194][root][INFO] - Training Epoch: 2/2, step 3813/7134 completed (loss: 0.3866044282913208, acc: 0.929729700088501)
[2024-12-17 03:07:56,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,568][root][INFO] - Training Epoch: 2/2, step 3814/7134 completed (loss: 0.11588722467422485, acc: 0.977142870426178)
[2024-12-17 03:07:56,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:56,961][root][INFO] - Training Epoch: 2/2, step 3815/7134 completed (loss: 0.1792452335357666, acc: 0.9539473652839661)
[2024-12-17 03:07:57,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,321][root][INFO] - Training Epoch: 2/2, step 3816/7134 completed (loss: 0.19435478746891022, acc: 0.9701492786407471)
[2024-12-17 03:07:57,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:57,688][root][INFO] - Training Epoch: 2/2, step 3817/7134 completed (loss: 0.2544189989566803, acc: 0.9438202381134033)
[2024-12-17 03:07:57,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,099][root][INFO] - Training Epoch: 2/2, step 3818/7134 completed (loss: 0.32769638299942017, acc: 0.9210526347160339)
[2024-12-17 03:07:58,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,450][root][INFO] - Training Epoch: 2/2, step 3819/7134 completed (loss: 0.16289566457271576, acc: 0.9571428298950195)
[2024-12-17 03:07:58,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:58,814][root][INFO] - Training Epoch: 2/2, step 3820/7134 completed (loss: 0.28372982144355774, acc: 0.9537037014961243)
[2024-12-17 03:07:58,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,172][root][INFO] - Training Epoch: 2/2, step 3821/7134 completed (loss: 0.14805303514003754, acc: 0.9589040875434875)
[2024-12-17 03:07:59,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,565][root][INFO] - Training Epoch: 2/2, step 3822/7134 completed (loss: 0.13995032012462616, acc: 0.9622641801834106)
[2024-12-17 03:07:59,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:07:59,942][root][INFO] - Training Epoch: 2/2, step 3823/7134 completed (loss: 0.06699617207050323, acc: 0.9865771532058716)
[2024-12-17 03:08:00,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,285][root][INFO] - Training Epoch: 2/2, step 3824/7134 completed (loss: 0.20512938499450684, acc: 0.9609375)
[2024-12-17 03:08:00,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:00,674][root][INFO] - Training Epoch: 2/2, step 3825/7134 completed (loss: 0.16406190395355225, acc: 0.9537037014961243)
[2024-12-17 03:08:00,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,047][root][INFO] - Training Epoch: 2/2, step 3826/7134 completed (loss: 0.14513851702213287, acc: 0.9647887349128723)
[2024-12-17 03:08:01,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,419][root][INFO] - Training Epoch: 2/2, step 3827/7134 completed (loss: 0.09832707047462463, acc: 0.987261176109314)
[2024-12-17 03:08:01,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:01,786][root][INFO] - Training Epoch: 2/2, step 3828/7134 completed (loss: 0.19126056134700775, acc: 0.949999988079071)
[2024-12-17 03:08:01,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,161][root][INFO] - Training Epoch: 2/2, step 3829/7134 completed (loss: 0.22596512734889984, acc: 0.9140625)
[2024-12-17 03:08:02,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,526][root][INFO] - Training Epoch: 2/2, step 3830/7134 completed (loss: 0.2665405869483948, acc: 0.9555555582046509)
[2024-12-17 03:08:02,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:02,885][root][INFO] - Training Epoch: 2/2, step 3831/7134 completed (loss: 0.26319870352745056, acc: 0.9276315569877625)
[2024-12-17 03:08:02,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,213][root][INFO] - Training Epoch: 2/2, step 3832/7134 completed (loss: 0.10359788686037064, acc: 0.9910714030265808)
[2024-12-17 03:08:03,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,573][root][INFO] - Training Epoch: 2/2, step 3833/7134 completed (loss: 0.09219443053007126, acc: 0.9562841653823853)
[2024-12-17 03:08:03,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:03,949][root][INFO] - Training Epoch: 2/2, step 3834/7134 completed (loss: 0.039492037147283554, acc: 0.9939024448394775)
[2024-12-17 03:08:04,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,309][root][INFO] - Training Epoch: 2/2, step 3835/7134 completed (loss: 0.07166533917188644, acc: 0.9739583134651184)
[2024-12-17 03:08:04,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:04,668][root][INFO] - Training Epoch: 2/2, step 3836/7134 completed (loss: 0.25999513268470764, acc: 0.9629629850387573)
[2024-12-17 03:08:04,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,017][root][INFO] - Training Epoch: 2/2, step 3837/7134 completed (loss: 0.15607528388500214, acc: 0.9745222926139832)
[2024-12-17 03:08:05,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,393][root][INFO] - Training Epoch: 2/2, step 3838/7134 completed (loss: 0.07284804433584213, acc: 0.9775280952453613)
[2024-12-17 03:08:05,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:05,801][root][INFO] - Training Epoch: 2/2, step 3839/7134 completed (loss: 0.09617965668439865, acc: 0.9751552939414978)
[2024-12-17 03:08:05,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,209][root][INFO] - Training Epoch: 2/2, step 3840/7134 completed (loss: 0.07515769451856613, acc: 0.9757575988769531)
[2024-12-17 03:08:06,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,630][root][INFO] - Training Epoch: 2/2, step 3841/7134 completed (loss: 0.1761612594127655, acc: 0.9396985173225403)
[2024-12-17 03:08:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:06,997][root][INFO] - Training Epoch: 2/2, step 3842/7134 completed (loss: 0.03355585038661957, acc: 1.0)
[2024-12-17 03:08:07,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,394][root][INFO] - Training Epoch: 2/2, step 3843/7134 completed (loss: 0.172271266579628, acc: 0.9639639854431152)
[2024-12-17 03:08:07,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:07,780][root][INFO] - Training Epoch: 2/2, step 3844/7134 completed (loss: 0.2845975160598755, acc: 0.9214659929275513)
[2024-12-17 03:08:07,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,197][root][INFO] - Training Epoch: 2/2, step 3845/7134 completed (loss: 0.186641126871109, acc: 0.9642857313156128)
[2024-12-17 03:08:08,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:08,587][root][INFO] - Training Epoch: 2/2, step 3846/7134 completed (loss: 0.10057814419269562, acc: 0.956204354763031)
[2024-12-17 03:08:08,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,014][root][INFO] - Training Epoch: 2/2, step 3847/7134 completed (loss: 0.10741640627384186, acc: 0.9716312289237976)
[2024-12-17 03:08:09,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,417][root][INFO] - Training Epoch: 2/2, step 3848/7134 completed (loss: 0.13911525905132294, acc: 0.9715909361839294)
[2024-12-17 03:08:09,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:09,785][root][INFO] - Training Epoch: 2/2, step 3849/7134 completed (loss: 0.16891101002693176, acc: 0.9555555582046509)
[2024-12-17 03:08:09,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,144][root][INFO] - Training Epoch: 2/2, step 3850/7134 completed (loss: 0.20783066749572754, acc: 0.9453551769256592)
[2024-12-17 03:08:10,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,518][root][INFO] - Training Epoch: 2/2, step 3851/7134 completed (loss: 0.18525618314743042, acc: 0.9226190447807312)
[2024-12-17 03:08:10,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:10,867][root][INFO] - Training Epoch: 2/2, step 3852/7134 completed (loss: 0.07227534800767899, acc: 0.9784172773361206)
[2024-12-17 03:08:10,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,229][root][INFO] - Training Epoch: 2/2, step 3853/7134 completed (loss: 0.26024743914604187, acc: 0.9273743033409119)
[2024-12-17 03:08:11,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,585][root][INFO] - Training Epoch: 2/2, step 3854/7134 completed (loss: 0.2335740178823471, acc: 0.9363057613372803)
[2024-12-17 03:08:11,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:11,956][root][INFO] - Training Epoch: 2/2, step 3855/7134 completed (loss: 0.2428973764181137, acc: 0.9520958065986633)
[2024-12-17 03:08:12,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,300][root][INFO] - Training Epoch: 2/2, step 3856/7134 completed (loss: 0.1728421449661255, acc: 0.9554139971733093)
[2024-12-17 03:08:12,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:12,688][root][INFO] - Training Epoch: 2/2, step 3857/7134 completed (loss: 0.22013674676418304, acc: 0.9391891956329346)
[2024-12-17 03:08:12,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,046][root][INFO] - Training Epoch: 2/2, step 3858/7134 completed (loss: 0.3031659722328186, acc: 0.918749988079071)
[2024-12-17 03:08:13,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,440][root][INFO] - Training Epoch: 2/2, step 3859/7134 completed (loss: 0.24347682297229767, acc: 0.9322034120559692)
[2024-12-17 03:08:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:13,802][root][INFO] - Training Epoch: 2/2, step 3860/7134 completed (loss: 0.10240405052900314, acc: 0.9685863852500916)
[2024-12-17 03:08:13,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,161][root][INFO] - Training Epoch: 2/2, step 3861/7134 completed (loss: 0.2086833417415619, acc: 0.9411764740943909)
[2024-12-17 03:08:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,509][root][INFO] - Training Epoch: 2/2, step 3862/7134 completed (loss: 0.18604722619056702, acc: 0.9461538195610046)
[2024-12-17 03:08:14,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:14,886][root][INFO] - Training Epoch: 2/2, step 3863/7134 completed (loss: 0.08535938709974289, acc: 0.9767441749572754)
[2024-12-17 03:08:14,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,230][root][INFO] - Training Epoch: 2/2, step 3864/7134 completed (loss: 0.19288645684719086, acc: 0.948051929473877)
[2024-12-17 03:08:15,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,599][root][INFO] - Training Epoch: 2/2, step 3865/7134 completed (loss: 0.32186585664749146, acc: 0.9107142686843872)
[2024-12-17 03:08:15,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:15,958][root][INFO] - Training Epoch: 2/2, step 3866/7134 completed (loss: 0.20068685710430145, acc: 0.9549999833106995)
[2024-12-17 03:08:16,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,316][root][INFO] - Training Epoch: 2/2, step 3867/7134 completed (loss: 0.11247781664133072, acc: 0.9636363387107849)
[2024-12-17 03:08:16,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:16,668][root][INFO] - Training Epoch: 2/2, step 3868/7134 completed (loss: 0.12218138575553894, acc: 0.970588207244873)
[2024-12-17 03:08:16,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,001][root][INFO] - Training Epoch: 2/2, step 3869/7134 completed (loss: 0.18530625104904175, acc: 0.9370629191398621)
[2024-12-17 03:08:17,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,358][root][INFO] - Training Epoch: 2/2, step 3870/7134 completed (loss: 0.3009413480758667, acc: 0.9542483687400818)
[2024-12-17 03:08:17,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:17,720][root][INFO] - Training Epoch: 2/2, step 3871/7134 completed (loss: 0.19553634524345398, acc: 0.959770143032074)
[2024-12-17 03:08:17,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,073][root][INFO] - Training Epoch: 2/2, step 3872/7134 completed (loss: 0.16465283930301666, acc: 0.9646464586257935)
[2024-12-17 03:08:18,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,469][root][INFO] - Training Epoch: 2/2, step 3873/7134 completed (loss: 0.14968566596508026, acc: 0.9575757384300232)
[2024-12-17 03:08:18,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:18,806][root][INFO] - Training Epoch: 2/2, step 3874/7134 completed (loss: 0.1733478158712387, acc: 0.9649122953414917)
[2024-12-17 03:08:18,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,177][root][INFO] - Training Epoch: 2/2, step 3875/7134 completed (loss: 0.17356517910957336, acc: 0.9430379867553711)
[2024-12-17 03:08:19,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,506][root][INFO] - Training Epoch: 2/2, step 3876/7134 completed (loss: 0.09982893615961075, acc: 0.984000027179718)
[2024-12-17 03:08:19,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:19,896][root][INFO] - Training Epoch: 2/2, step 3877/7134 completed (loss: 0.1405208557844162, acc: 0.9651162624359131)
[2024-12-17 03:08:20,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,257][root][INFO] - Training Epoch: 2/2, step 3878/7134 completed (loss: 0.5786239504814148, acc: 0.8837209343910217)
[2024-12-17 03:08:20,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:20,640][root][INFO] - Training Epoch: 2/2, step 3879/7134 completed (loss: 0.20399360358715057, acc: 0.9477611780166626)
[2024-12-17 03:08:20,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,019][root][INFO] - Training Epoch: 2/2, step 3880/7134 completed (loss: 0.1785273253917694, acc: 0.9679487347602844)
[2024-12-17 03:08:21,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,364][root][INFO] - Training Epoch: 2/2, step 3881/7134 completed (loss: 0.32356157898902893, acc: 0.9304812550544739)
[2024-12-17 03:08:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:21,731][root][INFO] - Training Epoch: 2/2, step 3882/7134 completed (loss: 0.3016291856765747, acc: 0.9123711585998535)
[2024-12-17 03:08:21,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,100][root][INFO] - Training Epoch: 2/2, step 3883/7134 completed (loss: 0.24834105372428894, acc: 0.9673202633857727)
[2024-12-17 03:08:22,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,466][root][INFO] - Training Epoch: 2/2, step 3884/7134 completed (loss: 0.1654040515422821, acc: 0.9657142758369446)
[2024-12-17 03:08:22,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:22,817][root][INFO] - Training Epoch: 2/2, step 3885/7134 completed (loss: 0.06325491517782211, acc: 0.987261176109314)
[2024-12-17 03:08:22,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,203][root][INFO] - Training Epoch: 2/2, step 3886/7134 completed (loss: 0.18194353580474854, acc: 0.9523809552192688)
[2024-12-17 03:08:23,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,565][root][INFO] - Training Epoch: 2/2, step 3887/7134 completed (loss: 0.19300365447998047, acc: 0.955974817276001)
[2024-12-17 03:08:23,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:23,931][root][INFO] - Training Epoch: 2/2, step 3888/7134 completed (loss: 0.21603171527385712, acc: 0.930232584476471)
[2024-12-17 03:08:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,290][root][INFO] - Training Epoch: 2/2, step 3889/7134 completed (loss: 0.09709913283586502, acc: 0.9830508232116699)
[2024-12-17 03:08:24,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:24,666][root][INFO] - Training Epoch: 2/2, step 3890/7134 completed (loss: 0.1470463126897812, acc: 0.9536082744598389)
[2024-12-17 03:08:24,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,050][root][INFO] - Training Epoch: 2/2, step 3891/7134 completed (loss: 0.08695880323648453, acc: 0.9884393215179443)
[2024-12-17 03:08:25,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,431][root][INFO] - Training Epoch: 2/2, step 3892/7134 completed (loss: 0.21431991457939148, acc: 0.95333331823349)
[2024-12-17 03:08:25,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:25,797][root][INFO] - Training Epoch: 2/2, step 3893/7134 completed (loss: 0.25039592385292053, acc: 0.9484536051750183)
[2024-12-17 03:08:25,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,143][root][INFO] - Training Epoch: 2/2, step 3894/7134 completed (loss: 0.14294151961803436, acc: 0.9556962251663208)
[2024-12-17 03:08:26,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,503][root][INFO] - Training Epoch: 2/2, step 3895/7134 completed (loss: 0.25103023648262024, acc: 0.939226508140564)
[2024-12-17 03:08:26,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:26,893][root][INFO] - Training Epoch: 2/2, step 3896/7134 completed (loss: 0.17986994981765747, acc: 0.9620853066444397)
[2024-12-17 03:08:27,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,293][root][INFO] - Training Epoch: 2/2, step 3897/7134 completed (loss: 0.3294437825679779, acc: 0.9476743936538696)
[2024-12-17 03:08:27,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:27,662][root][INFO] - Training Epoch: 2/2, step 3898/7134 completed (loss: 0.2522996962070465, acc: 0.9655172228813171)
[2024-12-17 03:08:27,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,040][root][INFO] - Training Epoch: 2/2, step 3899/7134 completed (loss: 0.17477887868881226, acc: 0.9479768872261047)
[2024-12-17 03:08:28,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,452][root][INFO] - Training Epoch: 2/2, step 3900/7134 completed (loss: 0.1325460821390152, acc: 0.9639175534248352)
[2024-12-17 03:08:28,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:28,790][root][INFO] - Training Epoch: 2/2, step 3901/7134 completed (loss: 0.3631657063961029, acc: 0.9397590160369873)
[2024-12-17 03:08:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,161][root][INFO] - Training Epoch: 2/2, step 3902/7134 completed (loss: 0.4243673086166382, acc: 0.9010416865348816)
[2024-12-17 03:08:29,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,543][root][INFO] - Training Epoch: 2/2, step 3903/7134 completed (loss: 0.4822874069213867, acc: 0.8963730335235596)
[2024-12-17 03:08:29,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:29,867][root][INFO] - Training Epoch: 2/2, step 3904/7134 completed (loss: 0.29187634587287903, acc: 0.9239766001701355)
[2024-12-17 03:08:29,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,233][root][INFO] - Training Epoch: 2/2, step 3905/7134 completed (loss: 0.11033382266759872, acc: 0.9722222089767456)
[2024-12-17 03:08:30,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,597][root][INFO] - Training Epoch: 2/2, step 3906/7134 completed (loss: 0.14312684535980225, acc: 0.9719101190567017)
[2024-12-17 03:08:30,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:30,952][root][INFO] - Training Epoch: 2/2, step 3907/7134 completed (loss: 0.10133801400661469, acc: 0.9793814420700073)
[2024-12-17 03:08:31,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,309][root][INFO] - Training Epoch: 2/2, step 3908/7134 completed (loss: 0.23714372515678406, acc: 0.9537572264671326)
[2024-12-17 03:08:31,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:31,652][root][INFO] - Training Epoch: 2/2, step 3909/7134 completed (loss: 0.13711513578891754, acc: 0.9685534834861755)
[2024-12-17 03:08:31,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,004][root][INFO] - Training Epoch: 2/2, step 3910/7134 completed (loss: 0.15029892325401306, acc: 0.9431818127632141)
[2024-12-17 03:08:32,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,378][root][INFO] - Training Epoch: 2/2, step 3911/7134 completed (loss: 0.1616227924823761, acc: 0.9622641801834106)
[2024-12-17 03:08:32,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:32,734][root][INFO] - Training Epoch: 2/2, step 3912/7134 completed (loss: 0.0590970441699028, acc: 0.9823529124259949)
[2024-12-17 03:08:32,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,134][root][INFO] - Training Epoch: 2/2, step 3913/7134 completed (loss: 0.10718598961830139, acc: 0.9797979593276978)
[2024-12-17 03:08:33,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,513][root][INFO] - Training Epoch: 2/2, step 3914/7134 completed (loss: 0.1209019348025322, acc: 0.9622641801834106)
[2024-12-17 03:08:33,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:33,869][root][INFO] - Training Epoch: 2/2, step 3915/7134 completed (loss: 0.06858494132757187, acc: 0.982758641242981)
[2024-12-17 03:08:33,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,237][root][INFO] - Training Epoch: 2/2, step 3916/7134 completed (loss: 0.08760512620210648, acc: 0.9744898080825806)
[2024-12-17 03:08:34,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,602][root][INFO] - Training Epoch: 2/2, step 3917/7134 completed (loss: 0.06961525976657867, acc: 0.9767441749572754)
[2024-12-17 03:08:34,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:34,986][root][INFO] - Training Epoch: 2/2, step 3918/7134 completed (loss: 0.13946504890918732, acc: 0.9571428298950195)
[2024-12-17 03:08:35,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,375][root][INFO] - Training Epoch: 2/2, step 3919/7134 completed (loss: 0.273586630821228, acc: 0.9467455744743347)
[2024-12-17 03:08:35,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:35,737][root][INFO] - Training Epoch: 2/2, step 3920/7134 completed (loss: 0.37476542592048645, acc: 0.8922155499458313)
[2024-12-17 03:08:35,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,113][root][INFO] - Training Epoch: 2/2, step 3921/7134 completed (loss: 0.2636852562427521, acc: 0.922535240650177)
[2024-12-17 03:08:36,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,478][root][INFO] - Training Epoch: 2/2, step 3922/7134 completed (loss: 0.36397480964660645, acc: 0.9285714030265808)
[2024-12-17 03:08:36,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:36,917][root][INFO] - Training Epoch: 2/2, step 3923/7134 completed (loss: 0.37143462896347046, acc: 0.9107142686843872)
[2024-12-17 03:08:37,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,288][root][INFO] - Training Epoch: 2/2, step 3924/7134 completed (loss: 0.24587692320346832, acc: 0.9432989954948425)
[2024-12-17 03:08:37,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:37,670][root][INFO] - Training Epoch: 2/2, step 3925/7134 completed (loss: 0.2361067682504654, acc: 0.939226508140564)
[2024-12-17 03:08:37,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,027][root][INFO] - Training Epoch: 2/2, step 3926/7134 completed (loss: 0.16026368737220764, acc: 0.9556962251663208)
[2024-12-17 03:08:38,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,415][root][INFO] - Training Epoch: 2/2, step 3927/7134 completed (loss: 0.18904003500938416, acc: 0.9575757384300232)
[2024-12-17 03:08:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:38,786][root][INFO] - Training Epoch: 2/2, step 3928/7134 completed (loss: 0.33411890268325806, acc: 0.940119743347168)
[2024-12-17 03:08:38,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,141][root][INFO] - Training Epoch: 2/2, step 3929/7134 completed (loss: 0.1278233677148819, acc: 0.9740259647369385)
[2024-12-17 03:08:39,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,493][root][INFO] - Training Epoch: 2/2, step 3930/7134 completed (loss: 0.27048826217651367, acc: 0.9661017060279846)
[2024-12-17 03:08:39,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:39,846][root][INFO] - Training Epoch: 2/2, step 3931/7134 completed (loss: 0.1347266137599945, acc: 0.9556962251663208)
[2024-12-17 03:08:39,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,278][root][INFO] - Training Epoch: 2/2, step 3932/7134 completed (loss: 0.11636483669281006, acc: 0.9636363387107849)
[2024-12-17 03:08:40,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,623][root][INFO] - Training Epoch: 2/2, step 3933/7134 completed (loss: 0.05446123331785202, acc: 0.9857142567634583)
[2024-12-17 03:08:40,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:40,995][root][INFO] - Training Epoch: 2/2, step 3934/7134 completed (loss: 0.0922074243426323, acc: 0.9814814925193787)
[2024-12-17 03:08:41,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,350][root][INFO] - Training Epoch: 2/2, step 3935/7134 completed (loss: 0.1412690430879593, acc: 0.9589040875434875)
[2024-12-17 03:08:41,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:41,735][root][INFO] - Training Epoch: 2/2, step 3936/7134 completed (loss: 0.12706194818019867, acc: 0.9677419066429138)
[2024-12-17 03:08:41,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,106][root][INFO] - Training Epoch: 2/2, step 3937/7134 completed (loss: 0.38725900650024414, acc: 0.9152542352676392)
[2024-12-17 03:08:42,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,471][root][INFO] - Training Epoch: 2/2, step 3938/7134 completed (loss: 0.2591659724712372, acc: 0.9459459185600281)
[2024-12-17 03:08:42,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:42,824][root][INFO] - Training Epoch: 2/2, step 3939/7134 completed (loss: 0.24531546235084534, acc: 0.9407407641410828)
[2024-12-17 03:08:42,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,182][root][INFO] - Training Epoch: 2/2, step 3940/7134 completed (loss: 0.16824331879615784, acc: 0.95652174949646)
[2024-12-17 03:08:43,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,545][root][INFO] - Training Epoch: 2/2, step 3941/7134 completed (loss: 0.2337377816438675, acc: 0.9268292784690857)
[2024-12-17 03:08:43,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:43,893][root][INFO] - Training Epoch: 2/2, step 3942/7134 completed (loss: 0.14293348789215088, acc: 0.9679999947547913)
[2024-12-17 03:08:44,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,258][root][INFO] - Training Epoch: 2/2, step 3943/7134 completed (loss: 0.17183923721313477, acc: 0.9718309640884399)
[2024-12-17 03:08:44,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:44,628][root][INFO] - Training Epoch: 2/2, step 3944/7134 completed (loss: 0.2026786059141159, acc: 0.9477611780166626)
[2024-12-17 03:08:44,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,013][root][INFO] - Training Epoch: 2/2, step 3945/7134 completed (loss: 0.06642957776784897, acc: 0.9868420958518982)
[2024-12-17 03:08:45,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,398][root][INFO] - Training Epoch: 2/2, step 3946/7134 completed (loss: 0.16800154745578766, acc: 0.9375)
[2024-12-17 03:08:45,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:45,759][root][INFO] - Training Epoch: 2/2, step 3947/7134 completed (loss: 0.04927363246679306, acc: 0.9890109896659851)
[2024-12-17 03:08:45,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,144][root][INFO] - Training Epoch: 2/2, step 3948/7134 completed (loss: 0.03700440004467964, acc: 1.0)
[2024-12-17 03:08:46,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,524][root][INFO] - Training Epoch: 2/2, step 3949/7134 completed (loss: 0.14942027628421783, acc: 0.9609375)
[2024-12-17 03:08:46,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:46,886][root][INFO] - Training Epoch: 2/2, step 3950/7134 completed (loss: 0.14033861458301544, acc: 0.9824561476707458)
[2024-12-17 03:08:47,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,262][root][INFO] - Training Epoch: 2/2, step 3951/7134 completed (loss: 0.03626791015267372, acc: 0.9896907210350037)
[2024-12-17 03:08:47,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:47,624][root][INFO] - Training Epoch: 2/2, step 3952/7134 completed (loss: 0.16518709063529968, acc: 0.9489796161651611)
[2024-12-17 03:08:47,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,004][root][INFO] - Training Epoch: 2/2, step 3953/7134 completed (loss: 0.06507903337478638, acc: 0.9927536249160767)
[2024-12-17 03:08:48,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,374][root][INFO] - Training Epoch: 2/2, step 3954/7134 completed (loss: 0.03186027705669403, acc: 1.0)
[2024-12-17 03:08:48,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:48,700][root][INFO] - Training Epoch: 2/2, step 3955/7134 completed (loss: 0.10919144004583359, acc: 0.9685039520263672)
[2024-12-17 03:08:48,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,052][root][INFO] - Training Epoch: 2/2, step 3956/7134 completed (loss: 0.17996962368488312, acc: 0.9542483687400818)
[2024-12-17 03:08:49,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,407][root][INFO] - Training Epoch: 2/2, step 3957/7134 completed (loss: 0.06750191748142242, acc: 0.9829059839248657)
[2024-12-17 03:08:49,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:49,759][root][INFO] - Training Epoch: 2/2, step 3958/7134 completed (loss: 0.1779988557100296, acc: 0.9404761791229248)
[2024-12-17 03:08:49,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,144][root][INFO] - Training Epoch: 2/2, step 3959/7134 completed (loss: 0.08771231025457382, acc: 0.982758641242981)
[2024-12-17 03:08:50,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,520][root][INFO] - Training Epoch: 2/2, step 3960/7134 completed (loss: 0.1387437880039215, acc: 0.9720670580863953)
[2024-12-17 03:08:50,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:50,903][root][INFO] - Training Epoch: 2/2, step 3961/7134 completed (loss: 0.05920220538973808, acc: 0.9814814925193787)
[2024-12-17 03:08:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:51,289][root][INFO] - Training Epoch: 2/2, step 3962/7134 completed (loss: 0.10603133589029312, acc: 0.9597315192222595)
[2024-12-17 03:08:51,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:51,652][root][INFO] - Training Epoch: 2/2, step 3963/7134 completed (loss: 0.21379728615283966, acc: 0.95652174949646)
[2024-12-17 03:08:51,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,009][root][INFO] - Training Epoch: 2/2, step 3964/7134 completed (loss: 0.2818757891654968, acc: 0.9461538195610046)
[2024-12-17 03:08:52,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,368][root][INFO] - Training Epoch: 2/2, step 3965/7134 completed (loss: 0.1611466109752655, acc: 0.9636363387107849)
[2024-12-17 03:08:52,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:52,722][root][INFO] - Training Epoch: 2/2, step 3966/7134 completed (loss: 0.22505725920200348, acc: 0.953125)
[2024-12-17 03:08:52,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,099][root][INFO] - Training Epoch: 2/2, step 3967/7134 completed (loss: 0.39767947793006897, acc: 0.9347826242446899)
[2024-12-17 03:08:53,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,490][root][INFO] - Training Epoch: 2/2, step 3968/7134 completed (loss: 0.03968522697687149, acc: 0.994413435459137)
[2024-12-17 03:08:53,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:53,833][root][INFO] - Training Epoch: 2/2, step 3969/7134 completed (loss: 0.298564076423645, acc: 0.9339622855186462)
[2024-12-17 03:08:53,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,210][root][INFO] - Training Epoch: 2/2, step 3970/7134 completed (loss: 0.26652103662490845, acc: 0.9421965479850769)
[2024-12-17 03:08:54,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,598][root][INFO] - Training Epoch: 2/2, step 3971/7134 completed (loss: 0.6050658822059631, acc: 0.8974359035491943)
[2024-12-17 03:08:54,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:54,971][root][INFO] - Training Epoch: 2/2, step 3972/7134 completed (loss: 0.90164715051651, acc: 0.7980769276618958)
[2024-12-17 03:08:55,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:55,362][root][INFO] - Training Epoch: 2/2, step 3973/7134 completed (loss: 0.2994682788848877, acc: 0.9295774698257446)
[2024-12-17 03:08:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:55,747][root][INFO] - Training Epoch: 2/2, step 3974/7134 completed (loss: 0.3603529632091522, acc: 0.8871794939041138)
[2024-12-17 03:08:55,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,080][root][INFO] - Training Epoch: 2/2, step 3975/7134 completed (loss: 0.23908713459968567, acc: 0.9314285516738892)
[2024-12-17 03:08:56,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,451][root][INFO] - Training Epoch: 2/2, step 3976/7134 completed (loss: 0.5578665733337402, acc: 0.891566276550293)
[2024-12-17 03:08:56,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:56,835][root][INFO] - Training Epoch: 2/2, step 3977/7134 completed (loss: 0.17977279424667358, acc: 0.9492753744125366)
[2024-12-17 03:08:56,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,208][root][INFO] - Training Epoch: 2/2, step 3978/7134 completed (loss: 0.08862775564193726, acc: 0.9751243591308594)
[2024-12-17 03:08:57,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,576][root][INFO] - Training Epoch: 2/2, step 3979/7134 completed (loss: 0.1961248368024826, acc: 0.9635036587715149)
[2024-12-17 03:08:57,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:57,948][root][INFO] - Training Epoch: 2/2, step 3980/7134 completed (loss: 0.11319857090711594, acc: 0.9677419066429138)
[2024-12-17 03:08:58,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:58,297][root][INFO] - Training Epoch: 2/2, step 3981/7134 completed (loss: 0.2539561986923218, acc: 0.9277108311653137)
[2024-12-17 03:08:58,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:58,688][root][INFO] - Training Epoch: 2/2, step 3982/7134 completed (loss: 0.4294423460960388, acc: 0.9127907156944275)
[2024-12-17 03:08:58,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,042][root][INFO] - Training Epoch: 2/2, step 3983/7134 completed (loss: 0.9185283780097961, acc: 0.8217054009437561)
[2024-12-17 03:08:59,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,414][root][INFO] - Training Epoch: 2/2, step 3984/7134 completed (loss: 0.4105992913246155, acc: 0.8936170339584351)
[2024-12-17 03:08:59,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:08:59,808][root][INFO] - Training Epoch: 2/2, step 3985/7134 completed (loss: 0.1494283527135849, acc: 0.9307692050933838)
[2024-12-17 03:08:59,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,176][root][INFO] - Training Epoch: 2/2, step 3986/7134 completed (loss: 0.6327467560768127, acc: 0.8693181872367859)
[2024-12-17 03:09:00,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,551][root][INFO] - Training Epoch: 2/2, step 3987/7134 completed (loss: 0.2232753038406372, acc: 0.9285714030265808)
[2024-12-17 03:09:00,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:00,923][root][INFO] - Training Epoch: 2/2, step 3988/7134 completed (loss: 0.29144901037216187, acc: 0.9234449863433838)
[2024-12-17 03:09:01,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:01,272][root][INFO] - Training Epoch: 2/2, step 3989/7134 completed (loss: 0.34017258882522583, acc: 0.8925619721412659)
[2024-12-17 03:09:01,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:01,658][root][INFO] - Training Epoch: 2/2, step 3990/7134 completed (loss: 0.2742009460926056, acc: 0.9337748289108276)
[2024-12-17 03:09:01,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,013][root][INFO] - Training Epoch: 2/2, step 3991/7134 completed (loss: 0.2069239616394043, acc: 0.9466666579246521)
[2024-12-17 03:09:02,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,353][root][INFO] - Training Epoch: 2/2, step 3992/7134 completed (loss: 0.24582897126674652, acc: 0.9560439586639404)
[2024-12-17 03:09:02,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:02,694][root][INFO] - Training Epoch: 2/2, step 3993/7134 completed (loss: 0.28701135516166687, acc: 0.9166666865348816)
[2024-12-17 03:09:02,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,066][root][INFO] - Training Epoch: 2/2, step 3994/7134 completed (loss: 0.2107848972082138, acc: 0.970588207244873)
[2024-12-17 03:09:03,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,422][root][INFO] - Training Epoch: 2/2, step 3995/7134 completed (loss: 0.4851185381412506, acc: 0.8604651093482971)
[2024-12-17 03:09:03,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:03,798][root][INFO] - Training Epoch: 2/2, step 3996/7134 completed (loss: 0.21548213064670563, acc: 0.93388432264328)
[2024-12-17 03:09:03,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,163][root][INFO] - Training Epoch: 2/2, step 3997/7134 completed (loss: 0.36449408531188965, acc: 0.931034505367279)
[2024-12-17 03:09:04,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,483][root][INFO] - Training Epoch: 2/2, step 3998/7134 completed (loss: 0.4409932494163513, acc: 0.8846153616905212)
[2024-12-17 03:09:04,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:04,867][root][INFO] - Training Epoch: 2/2, step 3999/7134 completed (loss: 0.22108802199363708, acc: 0.9435483813285828)
[2024-12-17 03:09:04,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,253][root][INFO] - Training Epoch: 2/2, step 4000/7134 completed (loss: 0.21594098210334778, acc: 0.9512194991111755)
[2024-12-17 03:09:05,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,600][root][INFO] - Training Epoch: 2/2, step 4001/7134 completed (loss: 0.41439342498779297, acc: 0.8790322542190552)
[2024-12-17 03:09:05,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:05,988][root][INFO] - Training Epoch: 2/2, step 4002/7134 completed (loss: 0.4161578118801117, acc: 0.8878504633903503)
[2024-12-17 03:09:06,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:06,384][root][INFO] - Training Epoch: 2/2, step 4003/7134 completed (loss: 0.5055180788040161, acc: 0.8796992301940918)
[2024-12-17 03:09:06,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:06,779][root][INFO] - Training Epoch: 2/2, step 4004/7134 completed (loss: 0.30007505416870117, acc: 0.9100000262260437)
[2024-12-17 03:09:06,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,125][root][INFO] - Training Epoch: 2/2, step 4005/7134 completed (loss: 0.2084653079509735, acc: 0.9281045794487)
[2024-12-17 03:09:07,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,508][root][INFO] - Training Epoch: 2/2, step 4006/7134 completed (loss: 0.10879465192556381, acc: 0.9729729890823364)
[2024-12-17 03:09:07,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:07,863][root][INFO] - Training Epoch: 2/2, step 4007/7134 completed (loss: 0.19833429157733917, acc: 0.976190447807312)
[2024-12-17 03:09:07,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,219][root][INFO] - Training Epoch: 2/2, step 4008/7134 completed (loss: 0.08474276214838028, acc: 0.9820627570152283)
[2024-12-17 03:09:08,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,613][root][INFO] - Training Epoch: 2/2, step 4009/7134 completed (loss: 0.09267239272594452, acc: 0.9664804339408875)
[2024-12-17 03:09:08,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:08,983][root][INFO] - Training Epoch: 2/2, step 4010/7134 completed (loss: 0.12864398956298828, acc: 0.9712918400764465)
[2024-12-17 03:09:09,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:09,347][root][INFO] - Training Epoch: 2/2, step 4011/7134 completed (loss: 0.2112148553133011, acc: 0.9371428489685059)
[2024-12-17 03:09:09,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:09,705][root][INFO] - Training Epoch: 2/2, step 4012/7134 completed (loss: 0.13426171243190765, acc: 0.9578313231468201)
[2024-12-17 03:09:09,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,082][root][INFO] - Training Epoch: 2/2, step 4013/7134 completed (loss: 0.05068878456950188, acc: 0.9790209531784058)
[2024-12-17 03:09:10,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,469][root][INFO] - Training Epoch: 2/2, step 4014/7134 completed (loss: 0.09686227142810822, acc: 0.9733333587646484)
[2024-12-17 03:09:10,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:10,830][root][INFO] - Training Epoch: 2/2, step 4015/7134 completed (loss: 0.08174563199281693, acc: 0.9793103337287903)
[2024-12-17 03:09:10,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,224][root][INFO] - Training Epoch: 2/2, step 4016/7134 completed (loss: 0.29984408617019653, acc: 0.9378238320350647)
[2024-12-17 03:09:11,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,604][root][INFO] - Training Epoch: 2/2, step 4017/7134 completed (loss: 0.13370341062545776, acc: 0.9742268323898315)
[2024-12-17 03:09:11,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:11,987][root][INFO] - Training Epoch: 2/2, step 4018/7134 completed (loss: 0.1947029083967209, acc: 0.9468598961830139)
[2024-12-17 03:09:12,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:12,342][root][INFO] - Training Epoch: 2/2, step 4019/7134 completed (loss: 0.10020065307617188, acc: 0.9833333492279053)
[2024-12-17 03:09:12,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:12,711][root][INFO] - Training Epoch: 2/2, step 4020/7134 completed (loss: 0.19335484504699707, acc: 0.9318181872367859)
[2024-12-17 03:09:12,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,077][root][INFO] - Training Epoch: 2/2, step 4021/7134 completed (loss: 0.10626868903636932, acc: 0.970588207244873)
[2024-12-17 03:09:13,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,446][root][INFO] - Training Epoch: 2/2, step 4022/7134 completed (loss: 0.11198367178440094, acc: 0.9663461446762085)
[2024-12-17 03:09:13,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:13,848][root][INFO] - Training Epoch: 2/2, step 4023/7134 completed (loss: 0.19311030209064484, acc: 0.9428571462631226)
[2024-12-17 03:09:13,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,218][root][INFO] - Training Epoch: 2/2, step 4024/7134 completed (loss: 0.13982641696929932, acc: 0.959770143032074)
[2024-12-17 03:09:14,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,571][root][INFO] - Training Epoch: 2/2, step 4025/7134 completed (loss: 0.2100512683391571, acc: 0.9371727705001831)
[2024-12-17 03:09:14,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:14,971][root][INFO] - Training Epoch: 2/2, step 4026/7134 completed (loss: 0.2864411473274231, acc: 0.9440993666648865)
[2024-12-17 03:09:15,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:15,318][root][INFO] - Training Epoch: 2/2, step 4027/7134 completed (loss: 0.19363930821418762, acc: 0.9438202381134033)
[2024-12-17 03:09:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:15,687][root][INFO] - Training Epoch: 2/2, step 4028/7134 completed (loss: 0.2842971980571747, acc: 0.9055117964744568)
[2024-12-17 03:09:15,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:16,068][root][INFO] - Training Epoch: 2/2, step 4029/7134 completed (loss: 0.10601706802845001, acc: 0.9675675630569458)
[2024-12-17 03:09:16,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:16,461][root][INFO] - Training Epoch: 2/2, step 4030/7134 completed (loss: 0.11137227714061737, acc: 0.9519230723381042)
[2024-12-17 03:09:16,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:16,792][root][INFO] - Training Epoch: 2/2, step 4031/7134 completed (loss: 0.07605033367872238, acc: 0.9813664555549622)
[2024-12-17 03:09:16,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,142][root][INFO] - Training Epoch: 2/2, step 4032/7134 completed (loss: 0.14781995117664337, acc: 0.9593023061752319)
[2024-12-17 03:09:17,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,499][root][INFO] - Training Epoch: 2/2, step 4033/7134 completed (loss: 0.08388087153434753, acc: 0.9786096215248108)
[2024-12-17 03:09:17,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:17,851][root][INFO] - Training Epoch: 2/2, step 4034/7134 completed (loss: 0.11508382856845856, acc: 0.9744898080825806)
[2024-12-17 03:09:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,271][root][INFO] - Training Epoch: 2/2, step 4035/7134 completed (loss: 0.34481731057167053, acc: 0.9073171019554138)
[2024-12-17 03:09:18,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,611][root][INFO] - Training Epoch: 2/2, step 4036/7134 completed (loss: 0.2077970951795578, acc: 0.9461538195610046)
[2024-12-17 03:09:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:18,988][root][INFO] - Training Epoch: 2/2, step 4037/7134 completed (loss: 0.14279918372631073, acc: 0.9583333134651184)
[2024-12-17 03:09:19,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:19,347][root][INFO] - Training Epoch: 2/2, step 4038/7134 completed (loss: 0.19291327893733978, acc: 0.9545454382896423)
[2024-12-17 03:09:19,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:19,712][root][INFO] - Training Epoch: 2/2, step 4039/7134 completed (loss: 0.30210384726524353, acc: 0.9289940595626831)
[2024-12-17 03:09:19,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,098][root][INFO] - Training Epoch: 2/2, step 4040/7134 completed (loss: 0.13455453515052795, acc: 0.9726775884628296)
[2024-12-17 03:09:20,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,548][root][INFO] - Training Epoch: 2/2, step 4041/7134 completed (loss: 0.2115195393562317, acc: 0.9537572264671326)
[2024-12-17 03:09:20,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:20,924][root][INFO] - Training Epoch: 2/2, step 4042/7134 completed (loss: 0.16133619844913483, acc: 0.9594594836235046)
[2024-12-17 03:09:21,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:21,268][root][INFO] - Training Epoch: 2/2, step 4043/7134 completed (loss: 0.2261652946472168, acc: 0.9367088675498962)
[2024-12-17 03:09:21,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:21,630][root][INFO] - Training Epoch: 2/2, step 4044/7134 completed (loss: 0.12891988456249237, acc: 0.9670329689979553)
[2024-12-17 03:09:21,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,012][root][INFO] - Training Epoch: 2/2, step 4045/7134 completed (loss: 0.16077402234077454, acc: 0.954285740852356)
[2024-12-17 03:09:22,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,377][root][INFO] - Training Epoch: 2/2, step 4046/7134 completed (loss: 0.17273692786693573, acc: 0.9532163739204407)
[2024-12-17 03:09:22,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:22,763][root][INFO] - Training Epoch: 2/2, step 4047/7134 completed (loss: 0.31878262758255005, acc: 0.9398906826972961)
[2024-12-17 03:09:22,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,145][root][INFO] - Training Epoch: 2/2, step 4048/7134 completed (loss: 0.07076875865459442, acc: 0.9746192693710327)
[2024-12-17 03:09:23,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,533][root][INFO] - Training Epoch: 2/2, step 4049/7134 completed (loss: 0.19384247064590454, acc: 0.9552238583564758)
[2024-12-17 03:09:23,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:23,895][root][INFO] - Training Epoch: 2/2, step 4050/7134 completed (loss: 0.2225562036037445, acc: 0.949999988079071)
[2024-12-17 03:09:24,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,281][root][INFO] - Training Epoch: 2/2, step 4051/7134 completed (loss: 0.19632288813591003, acc: 0.9441340565681458)
[2024-12-17 03:09:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,609][root][INFO] - Training Epoch: 2/2, step 4052/7134 completed (loss: 0.15098442137241364, acc: 0.9717513918876648)
[2024-12-17 03:09:24,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:24,974][root][INFO] - Training Epoch: 2/2, step 4053/7134 completed (loss: 0.22601275146007538, acc: 0.9345238208770752)
[2024-12-17 03:09:25,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:25,330][root][INFO] - Training Epoch: 2/2, step 4054/7134 completed (loss: 0.2808254063129425, acc: 0.9304347634315491)
[2024-12-17 03:09:25,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:25,698][root][INFO] - Training Epoch: 2/2, step 4055/7134 completed (loss: 0.1646089255809784, acc: 0.9734042286872864)
[2024-12-17 03:09:25,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,079][root][INFO] - Training Epoch: 2/2, step 4056/7134 completed (loss: 0.1135423481464386, acc: 0.9894737005233765)
[2024-12-17 03:09:26,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,444][root][INFO] - Training Epoch: 2/2, step 4057/7134 completed (loss: 0.16838449239730835, acc: 0.9647058844566345)
[2024-12-17 03:09:26,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:26,780][root][INFO] - Training Epoch: 2/2, step 4058/7134 completed (loss: 0.3423978090286255, acc: 0.9090909361839294)
[2024-12-17 03:09:26,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,151][root][INFO] - Training Epoch: 2/2, step 4059/7134 completed (loss: 0.13122397661209106, acc: 0.9701492786407471)
[2024-12-17 03:09:27,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,514][root][INFO] - Training Epoch: 2/2, step 4060/7134 completed (loss: 0.05237441509962082, acc: 1.0)
[2024-12-17 03:09:27,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:27,898][root][INFO] - Training Epoch: 2/2, step 4061/7134 completed (loss: 0.045738935470581055, acc: 0.9883720874786377)
[2024-12-17 03:09:28,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:28,276][root][INFO] - Training Epoch: 2/2, step 4062/7134 completed (loss: 0.04931224510073662, acc: 0.9934210777282715)
[2024-12-17 03:09:28,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:28,647][root][INFO] - Training Epoch: 2/2, step 4063/7134 completed (loss: 0.07353765517473221, acc: 0.969924807548523)
[2024-12-17 03:09:28,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,021][root][INFO] - Training Epoch: 2/2, step 4064/7134 completed (loss: 0.11866433918476105, acc: 0.9803921580314636)
[2024-12-17 03:09:29,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,410][root][INFO] - Training Epoch: 2/2, step 4065/7134 completed (loss: 0.10173195600509644, acc: 0.9741935729980469)
[2024-12-17 03:09:29,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:29,805][root][INFO] - Training Epoch: 2/2, step 4066/7134 completed (loss: 0.030056405812501907, acc: 1.0)
[2024-12-17 03:09:29,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,188][root][INFO] - Training Epoch: 2/2, step 4067/7134 completed (loss: 0.15157261490821838, acc: 0.9452054500579834)
[2024-12-17 03:09:30,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,535][root][INFO] - Training Epoch: 2/2, step 4068/7134 completed (loss: 0.2841661870479584, acc: 0.942148745059967)
[2024-12-17 03:09:30,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:30,875][root][INFO] - Training Epoch: 2/2, step 4069/7134 completed (loss: 0.17666937410831451, acc: 0.9507042169570923)
[2024-12-17 03:09:30,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,259][root][INFO] - Training Epoch: 2/2, step 4070/7134 completed (loss: 0.213339701294899, acc: 0.9470198750495911)
[2024-12-17 03:09:31,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,640][root][INFO] - Training Epoch: 2/2, step 4071/7134 completed (loss: 0.11554296314716339, acc: 0.9726027250289917)
[2024-12-17 03:09:31,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:31,984][root][INFO] - Training Epoch: 2/2, step 4072/7134 completed (loss: 0.10374283045530319, acc: 0.9817073345184326)
[2024-12-17 03:09:32,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,378][root][INFO] - Training Epoch: 2/2, step 4073/7134 completed (loss: 0.035350501537323, acc: 0.9939758777618408)
[2024-12-17 03:09:32,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:32,770][root][INFO] - Training Epoch: 2/2, step 4074/7134 completed (loss: 0.14894476532936096, acc: 0.9536423683166504)
[2024-12-17 03:09:32,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,167][root][INFO] - Training Epoch: 2/2, step 4075/7134 completed (loss: 0.04266364872455597, acc: 0.9933333396911621)
[2024-12-17 03:09:33,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,537][root][INFO] - Training Epoch: 2/2, step 4076/7134 completed (loss: 0.05247161537408829, acc: 0.9878048896789551)
[2024-12-17 03:09:33,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:33,888][root][INFO] - Training Epoch: 2/2, step 4077/7134 completed (loss: 0.0901976078748703, acc: 0.9659863710403442)
[2024-12-17 03:09:34,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:34,292][root][INFO] - Training Epoch: 2/2, step 4078/7134 completed (loss: 0.11100468039512634, acc: 0.9622641801834106)
[2024-12-17 03:09:34,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:34,671][root][INFO] - Training Epoch: 2/2, step 4079/7134 completed (loss: 0.06803373247385025, acc: 0.9923664331436157)
[2024-12-17 03:09:34,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,115][root][INFO] - Training Epoch: 2/2, step 4080/7134 completed (loss: 0.03678426519036293, acc: 0.9862068891525269)
[2024-12-17 03:09:35,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,495][root][INFO] - Training Epoch: 2/2, step 4081/7134 completed (loss: 0.04163334146142006, acc: 0.9861111044883728)
[2024-12-17 03:09:35,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:35,846][root][INFO] - Training Epoch: 2/2, step 4082/7134 completed (loss: 0.3868679404258728, acc: 0.9210526347160339)
[2024-12-17 03:09:35,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,228][root][INFO] - Training Epoch: 2/2, step 4083/7134 completed (loss: 0.40924271941185, acc: 0.8947368264198303)
[2024-12-17 03:09:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,589][root][INFO] - Training Epoch: 2/2, step 4084/7134 completed (loss: 0.4180813431739807, acc: 0.8926174640655518)
[2024-12-17 03:09:36,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:36,927][root][INFO] - Training Epoch: 2/2, step 4085/7134 completed (loss: 0.16829144954681396, acc: 0.9526315927505493)
[2024-12-17 03:09:37,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:37,296][root][INFO] - Training Epoch: 2/2, step 4086/7134 completed (loss: 0.3116169571876526, acc: 0.9230769276618958)
[2024-12-17 03:09:37,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:37,660][root][INFO] - Training Epoch: 2/2, step 4087/7134 completed (loss: 0.12076202780008316, acc: 0.9784946441650391)
[2024-12-17 03:09:37,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,046][root][INFO] - Training Epoch: 2/2, step 4088/7134 completed (loss: 0.3041301965713501, acc: 0.913705587387085)
[2024-12-17 03:09:38,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,406][root][INFO] - Training Epoch: 2/2, step 4089/7134 completed (loss: 0.38553285598754883, acc: 0.9318181872367859)
[2024-12-17 03:09:38,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:38,771][root][INFO] - Training Epoch: 2/2, step 4090/7134 completed (loss: 0.5016051530838013, acc: 0.8899521827697754)
[2024-12-17 03:09:38,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,138][root][INFO] - Training Epoch: 2/2, step 4091/7134 completed (loss: 0.6026766896247864, acc: 0.8651685118675232)
[2024-12-17 03:09:39,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,545][root][INFO] - Training Epoch: 2/2, step 4092/7134 completed (loss: 0.22503533959388733, acc: 0.9528796076774597)
[2024-12-17 03:09:39,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:39,909][root][INFO] - Training Epoch: 2/2, step 4093/7134 completed (loss: 0.1957322657108307, acc: 0.9440000057220459)
[2024-12-17 03:09:40,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:40,308][root][INFO] - Training Epoch: 2/2, step 4094/7134 completed (loss: 0.3038053512573242, acc: 0.9329268336296082)
[2024-12-17 03:09:40,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:40,713][root][INFO] - Training Epoch: 2/2, step 4095/7134 completed (loss: 0.14536574482917786, acc: 0.9617834687232971)
[2024-12-17 03:09:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,084][root][INFO] - Training Epoch: 2/2, step 4096/7134 completed (loss: 0.32197484374046326, acc: 0.8961039185523987)
[2024-12-17 03:09:41,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,467][root][INFO] - Training Epoch: 2/2, step 4097/7134 completed (loss: 0.2804141938686371, acc: 0.9399999976158142)
[2024-12-17 03:09:41,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:41,830][root][INFO] - Training Epoch: 2/2, step 4098/7134 completed (loss: 0.1554378867149353, acc: 0.959770143032074)
[2024-12-17 03:09:41,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,210][root][INFO] - Training Epoch: 2/2, step 4099/7134 completed (loss: 0.14409323036670685, acc: 0.9848484992980957)
[2024-12-17 03:09:42,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,602][root][INFO] - Training Epoch: 2/2, step 4100/7134 completed (loss: 0.06227036938071251, acc: 0.9803921580314636)
[2024-12-17 03:09:42,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:42,975][root][INFO] - Training Epoch: 2/2, step 4101/7134 completed (loss: 0.20452332496643066, acc: 0.9440000057220459)
[2024-12-17 03:09:43,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:43,358][root][INFO] - Training Epoch: 2/2, step 4102/7134 completed (loss: 0.18443995714187622, acc: 0.9674796462059021)
[2024-12-17 03:09:43,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:43,718][root][INFO] - Training Epoch: 2/2, step 4103/7134 completed (loss: 0.10887715965509415, acc: 0.9673202633857727)
[2024-12-17 03:09:43,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,093][root][INFO] - Training Epoch: 2/2, step 4104/7134 completed (loss: 0.16556088626384735, acc: 0.9420289993286133)
[2024-12-17 03:09:44,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,464][root][INFO] - Training Epoch: 2/2, step 4105/7134 completed (loss: 0.09752596169710159, acc: 0.9800000190734863)
[2024-12-17 03:09:44,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:44,830][root][INFO] - Training Epoch: 2/2, step 4106/7134 completed (loss: 0.10329076647758484, acc: 0.9659863710403442)
[2024-12-17 03:09:44,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,179][root][INFO] - Training Epoch: 2/2, step 4107/7134 completed (loss: 0.14612619578838348, acc: 0.9632353186607361)
[2024-12-17 03:09:45,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,540][root][INFO] - Training Epoch: 2/2, step 4108/7134 completed (loss: 0.12476646155118942, acc: 0.9523809552192688)
[2024-12-17 03:09:45,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:45,924][root][INFO] - Training Epoch: 2/2, step 4109/7134 completed (loss: 0.05973329395055771, acc: 0.9863945841789246)
[2024-12-17 03:09:46,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:46,288][root][INFO] - Training Epoch: 2/2, step 4110/7134 completed (loss: 0.058775920420885086, acc: 0.9922480583190918)
[2024-12-17 03:09:46,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:46,675][root][INFO] - Training Epoch: 2/2, step 4111/7134 completed (loss: 0.1213454157114029, acc: 0.9655172228813171)
[2024-12-17 03:09:46,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,074][root][INFO] - Training Epoch: 2/2, step 4112/7134 completed (loss: 0.13311780989170074, acc: 0.961240291595459)
[2024-12-17 03:09:47,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,450][root][INFO] - Training Epoch: 2/2, step 4113/7134 completed (loss: 0.09523440897464752, acc: 0.9790209531784058)
[2024-12-17 03:09:47,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:47,828][root][INFO] - Training Epoch: 2/2, step 4114/7134 completed (loss: 0.3466305732727051, acc: 0.895652174949646)
[2024-12-17 03:09:47,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,205][root][INFO] - Training Epoch: 2/2, step 4115/7134 completed (loss: 0.4129422605037689, acc: 0.8813559412956238)
[2024-12-17 03:09:48,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,599][root][INFO] - Training Epoch: 2/2, step 4116/7134 completed (loss: 0.15463517606258392, acc: 0.9847328066825867)
[2024-12-17 03:09:48,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:48,941][root][INFO] - Training Epoch: 2/2, step 4117/7134 completed (loss: 0.06332200020551682, acc: 0.9861111044883728)
[2024-12-17 03:09:49,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:49,285][root][INFO] - Training Epoch: 2/2, step 4118/7134 completed (loss: 0.05329187214374542, acc: 0.9895833134651184)
[2024-12-17 03:09:49,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:49,667][root][INFO] - Training Epoch: 2/2, step 4119/7134 completed (loss: 0.17203332483768463, acc: 0.9662162065505981)
[2024-12-17 03:09:49,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,057][root][INFO] - Training Epoch: 2/2, step 4120/7134 completed (loss: 0.112875796854496, acc: 0.9924812316894531)
[2024-12-17 03:09:50,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,427][root][INFO] - Training Epoch: 2/2, step 4121/7134 completed (loss: 0.12114308774471283, acc: 0.9817073345184326)
[2024-12-17 03:09:50,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:50,793][root][INFO] - Training Epoch: 2/2, step 4122/7134 completed (loss: 0.06511112302541733, acc: 0.9831932783126831)
[2024-12-17 03:09:50,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,166][root][INFO] - Training Epoch: 2/2, step 4123/7134 completed (loss: 0.06817847490310669, acc: 0.9805194735527039)
[2024-12-17 03:09:51,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,549][root][INFO] - Training Epoch: 2/2, step 4124/7134 completed (loss: 0.06971647590398788, acc: 0.9750000238418579)
[2024-12-17 03:09:51,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:51,908][root][INFO] - Training Epoch: 2/2, step 4125/7134 completed (loss: 0.10482235252857208, acc: 0.9748427867889404)
[2024-12-17 03:09:52,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:52,282][root][INFO] - Training Epoch: 2/2, step 4126/7134 completed (loss: 0.08960960805416107, acc: 0.9605262875556946)
[2024-12-17 03:09:52,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:52,634][root][INFO] - Training Epoch: 2/2, step 4127/7134 completed (loss: 0.12424910813570023, acc: 0.9731543660163879)
[2024-12-17 03:09:52,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:52,997][root][INFO] - Training Epoch: 2/2, step 4128/7134 completed (loss: 0.05770406499505043, acc: 0.9924812316894531)
[2024-12-17 03:09:53,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:53,378][root][INFO] - Training Epoch: 2/2, step 4129/7134 completed (loss: 0.06639304757118225, acc: 0.9798657894134521)
[2024-12-17 03:09:53,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:53,726][root][INFO] - Training Epoch: 2/2, step 4130/7134 completed (loss: 0.12885771691799164, acc: 0.9655172228813171)
[2024-12-17 03:09:53,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,115][root][INFO] - Training Epoch: 2/2, step 4131/7134 completed (loss: 0.13559366762638092, acc: 0.9555555582046509)
[2024-12-17 03:09:54,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,473][root][INFO] - Training Epoch: 2/2, step 4132/7134 completed (loss: 0.04575434327125549, acc: 0.9907407164573669)
[2024-12-17 03:09:54,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:54,851][root][INFO] - Training Epoch: 2/2, step 4133/7134 completed (loss: 0.251707524061203, acc: 0.9440559148788452)
[2024-12-17 03:09:54,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,216][root][INFO] - Training Epoch: 2/2, step 4134/7134 completed (loss: 0.5284466743469238, acc: 0.8909090757369995)
[2024-12-17 03:09:55,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,599][root][INFO] - Training Epoch: 2/2, step 4135/7134 completed (loss: 0.04755920171737671, acc: 0.9857142567634583)
[2024-12-17 03:09:55,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:55,998][root][INFO] - Training Epoch: 2/2, step 4136/7134 completed (loss: 0.13389964401721954, acc: 0.9548872113227844)
[2024-12-17 03:09:56,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:56,380][root][INFO] - Training Epoch: 2/2, step 4137/7134 completed (loss: 0.078456349670887, acc: 0.970588207244873)
[2024-12-17 03:09:56,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:56,742][root][INFO] - Training Epoch: 2/2, step 4138/7134 completed (loss: 0.24504415690898895, acc: 0.9346405267715454)
[2024-12-17 03:09:56,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,107][root][INFO] - Training Epoch: 2/2, step 4139/7134 completed (loss: 0.20089562237262726, acc: 0.9333333373069763)
[2024-12-17 03:09:57,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,468][root][INFO] - Training Epoch: 2/2, step 4140/7134 completed (loss: 0.22889231145381927, acc: 0.9322034120559692)
[2024-12-17 03:09:57,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:57,824][root][INFO] - Training Epoch: 2/2, step 4141/7134 completed (loss: 0.28603020310401917, acc: 0.8974359035491943)
[2024-12-17 03:09:57,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,194][root][INFO] - Training Epoch: 2/2, step 4142/7134 completed (loss: 0.2973802089691162, acc: 0.9100000262260437)
[2024-12-17 03:09:58,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,569][root][INFO] - Training Epoch: 2/2, step 4143/7134 completed (loss: 0.17584720253944397, acc: 0.9694322943687439)
[2024-12-17 03:09:58,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:58,963][root][INFO] - Training Epoch: 2/2, step 4144/7134 completed (loss: 0.26946717500686646, acc: 0.9076923131942749)
[2024-12-17 03:09:59,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:59,331][root][INFO] - Training Epoch: 2/2, step 4145/7134 completed (loss: 0.33620983362197876, acc: 0.9067796468734741)
[2024-12-17 03:09:59,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:09:59,712][root][INFO] - Training Epoch: 2/2, step 4146/7134 completed (loss: 0.5377117395401001, acc: 0.8482142686843872)
[2024-12-17 03:09:59,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:00,078][root][INFO] - Training Epoch: 2/2, step 4147/7134 completed (loss: 0.7155024409294128, acc: 0.7966101765632629)
[2024-12-17 03:10:00,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:00,463][root][INFO] - Training Epoch: 2/2, step 4148/7134 completed (loss: 0.9694045186042786, acc: 0.818791925907135)
[2024-12-17 03:10:00,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:00,799][root][INFO] - Training Epoch: 2/2, step 4149/7134 completed (loss: 0.6919352412223816, acc: 0.8488371968269348)
[2024-12-17 03:10:00,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,171][root][INFO] - Training Epoch: 2/2, step 4150/7134 completed (loss: 0.8777594566345215, acc: 0.8205128312110901)
[2024-12-17 03:10:01,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,531][root][INFO] - Training Epoch: 2/2, step 4151/7134 completed (loss: 0.43605029582977295, acc: 0.93388432264328)
[2024-12-17 03:10:01,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:01,937][root][INFO] - Training Epoch: 2/2, step 4152/7134 completed (loss: 0.38179731369018555, acc: 0.9047619104385376)
[2024-12-17 03:10:02,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,317][root][INFO] - Training Epoch: 2/2, step 4153/7134 completed (loss: 0.338926762342453, acc: 0.9285714030265808)
[2024-12-17 03:10:02,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:02,705][root][INFO] - Training Epoch: 2/2, step 4154/7134 completed (loss: 0.3331548273563385, acc: 0.89952152967453)
[2024-12-17 03:10:02,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:03,055][root][INFO] - Training Epoch: 2/2, step 4155/7134 completed (loss: 0.3720736503601074, acc: 0.926174521446228)
[2024-12-17 03:10:03,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:03,425][root][INFO] - Training Epoch: 2/2, step 4156/7134 completed (loss: 0.4403131604194641, acc: 0.9181286692619324)
[2024-12-17 03:10:03,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:03,815][root][INFO] - Training Epoch: 2/2, step 4157/7134 completed (loss: 0.19254493713378906, acc: 0.9663865566253662)
[2024-12-17 03:10:03,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,166][root][INFO] - Training Epoch: 2/2, step 4158/7134 completed (loss: 0.4963253140449524, acc: 0.901098906993866)
[2024-12-17 03:10:04,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,521][root][INFO] - Training Epoch: 2/2, step 4159/7134 completed (loss: 0.22744032740592957, acc: 0.9548872113227844)
[2024-12-17 03:10:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:04,875][root][INFO] - Training Epoch: 2/2, step 4160/7134 completed (loss: 0.28685829043388367, acc: 0.9411764740943909)
[2024-12-17 03:10:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,237][root][INFO] - Training Epoch: 2/2, step 4161/7134 completed (loss: 0.14718666672706604, acc: 0.9741379022598267)
[2024-12-17 03:10:05,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:05,665][root][INFO] - Training Epoch: 2/2, step 4162/7134 completed (loss: 0.23565948009490967, acc: 0.946107804775238)
[2024-12-17 03:10:05,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,063][root][INFO] - Training Epoch: 2/2, step 4163/7134 completed (loss: 0.27692317962646484, acc: 0.926174521446228)
[2024-12-17 03:10:06,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,440][root][INFO] - Training Epoch: 2/2, step 4164/7134 completed (loss: 0.24523018300533295, acc: 0.9378882050514221)
[2024-12-17 03:10:06,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:06,845][root][INFO] - Training Epoch: 2/2, step 4165/7134 completed (loss: 0.222188800573349, acc: 0.9354838728904724)
[2024-12-17 03:10:06,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,230][root][INFO] - Training Epoch: 2/2, step 4166/7134 completed (loss: 0.3575059473514557, acc: 0.9230769276618958)
[2024-12-17 03:10:07,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,581][root][INFO] - Training Epoch: 2/2, step 4167/7134 completed (loss: 0.23659905791282654, acc: 0.9268292784690857)
[2024-12-17 03:10:07,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:07,947][root][INFO] - Training Epoch: 2/2, step 4168/7134 completed (loss: 0.2390342652797699, acc: 0.9248120188713074)
[2024-12-17 03:10:08,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:08,337][root][INFO] - Training Epoch: 2/2, step 4169/7134 completed (loss: 0.26896655559539795, acc: 0.9493087530136108)
[2024-12-17 03:10:08,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:08,705][root][INFO] - Training Epoch: 2/2, step 4170/7134 completed (loss: 0.19647161662578583, acc: 0.9523809552192688)
[2024-12-17 03:10:08,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,082][root][INFO] - Training Epoch: 2/2, step 4171/7134 completed (loss: 0.12600435316562653, acc: 0.9704433679580688)
[2024-12-17 03:10:09,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,517][root][INFO] - Training Epoch: 2/2, step 4172/7134 completed (loss: 0.21172881126403809, acc: 0.9388889074325562)
[2024-12-17 03:10:09,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:09,897][root][INFO] - Training Epoch: 2/2, step 4173/7134 completed (loss: 0.3192356824874878, acc: 0.9074074029922485)
[2024-12-17 03:10:09,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:10,259][root][INFO] - Training Epoch: 2/2, step 4174/7134 completed (loss: 0.027078701183199883, acc: 0.9920634627342224)
[2024-12-17 03:10:10,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:10,652][root][INFO] - Training Epoch: 2/2, step 4175/7134 completed (loss: 0.15297767519950867, acc: 0.9507042169570923)
[2024-12-17 03:10:10,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,078][root][INFO] - Training Epoch: 2/2, step 4176/7134 completed (loss: 0.09692252427339554, acc: 0.9806451797485352)
[2024-12-17 03:10:11,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,467][root][INFO] - Training Epoch: 2/2, step 4177/7134 completed (loss: 0.09273746609687805, acc: 0.9707602262496948)
[2024-12-17 03:10:11,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:11,878][root][INFO] - Training Epoch: 2/2, step 4178/7134 completed (loss: 0.17107664048671722, acc: 0.9736841917037964)
[2024-12-17 03:10:12,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:12,290][root][INFO] - Training Epoch: 2/2, step 4179/7134 completed (loss: 0.04492172226309776, acc: 0.9937499761581421)
[2024-12-17 03:10:12,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:12,705][root][INFO] - Training Epoch: 2/2, step 4180/7134 completed (loss: 0.09959112107753754, acc: 0.9750000238418579)
[2024-12-17 03:10:12,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,103][root][INFO] - Training Epoch: 2/2, step 4181/7134 completed (loss: 0.06760342419147491, acc: 0.97826087474823)
[2024-12-17 03:10:13,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,478][root][INFO] - Training Epoch: 2/2, step 4182/7134 completed (loss: 0.059263575822114944, acc: 0.9870129823684692)
[2024-12-17 03:10:13,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:13,861][root][INFO] - Training Epoch: 2/2, step 4183/7134 completed (loss: 0.11574041098356247, acc: 0.9693251252174377)
[2024-12-17 03:10:13,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:14,282][root][INFO] - Training Epoch: 2/2, step 4184/7134 completed (loss: 0.08817385882139206, acc: 0.9764705896377563)
[2024-12-17 03:10:14,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:14,672][root][INFO] - Training Epoch: 2/2, step 4185/7134 completed (loss: 0.16120946407318115, acc: 0.9714285731315613)
[2024-12-17 03:10:14,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,069][root][INFO] - Training Epoch: 2/2, step 4186/7134 completed (loss: 0.15758484601974487, acc: 0.9793814420700073)
[2024-12-17 03:10:15,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,440][root][INFO] - Training Epoch: 2/2, step 4187/7134 completed (loss: 0.04040202870965004, acc: 0.9919354915618896)
[2024-12-17 03:10:15,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:15,830][root][INFO] - Training Epoch: 2/2, step 4188/7134 completed (loss: 0.04072166234254837, acc: 0.9947368502616882)
[2024-12-17 03:10:15,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:16,237][root][INFO] - Training Epoch: 2/2, step 4189/7134 completed (loss: 0.0929766520857811, acc: 0.976047933101654)
[2024-12-17 03:10:16,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:16,670][root][INFO] - Training Epoch: 2/2, step 4190/7134 completed (loss: 0.15656059980392456, acc: 0.9649122953414917)
[2024-12-17 03:10:16,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,067][root][INFO] - Training Epoch: 2/2, step 4191/7134 completed (loss: 0.1581575870513916, acc: 0.9711538553237915)
[2024-12-17 03:10:17,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,459][root][INFO] - Training Epoch: 2/2, step 4192/7134 completed (loss: 0.05369686335325241, acc: 0.9931507110595703)
[2024-12-17 03:10:17,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:17,859][root][INFO] - Training Epoch: 2/2, step 4193/7134 completed (loss: 0.09019484370946884, acc: 0.9776536226272583)
[2024-12-17 03:10:18,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:18,275][root][INFO] - Training Epoch: 2/2, step 4194/7134 completed (loss: 0.04142699018120766, acc: 0.9871794581413269)
[2024-12-17 03:10:18,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:18,653][root][INFO] - Training Epoch: 2/2, step 4195/7134 completed (loss: 0.21009789407253265, acc: 0.9485714435577393)
[2024-12-17 03:10:18,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,006][root][INFO] - Training Epoch: 2/2, step 4196/7134 completed (loss: 0.15292367339134216, acc: 0.9784172773361206)
[2024-12-17 03:10:19,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,391][root][INFO] - Training Epoch: 2/2, step 4197/7134 completed (loss: 0.17350533604621887, acc: 0.97826087474823)
[2024-12-17 03:10:19,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:19,802][root][INFO] - Training Epoch: 2/2, step 4198/7134 completed (loss: 0.16798250377178192, acc: 0.977142870426178)
[2024-12-17 03:10:19,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,157][root][INFO] - Training Epoch: 2/2, step 4199/7134 completed (loss: 0.19495142996311188, acc: 0.9577465057373047)
[2024-12-17 03:10:20,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,526][root][INFO] - Training Epoch: 2/2, step 4200/7134 completed (loss: 0.17631672322750092, acc: 0.951724112033844)
[2024-12-17 03:10:20,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:20,908][root][INFO] - Training Epoch: 2/2, step 4201/7134 completed (loss: 0.07385224103927612, acc: 0.9858155846595764)
[2024-12-17 03:10:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:21,336][root][INFO] - Training Epoch: 2/2, step 4202/7134 completed (loss: 0.1294575035572052, acc: 0.969924807548523)
[2024-12-17 03:10:21,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:21,711][root][INFO] - Training Epoch: 2/2, step 4203/7134 completed (loss: 0.11291871964931488, acc: 0.9683544039726257)
[2024-12-17 03:10:21,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,118][root][INFO] - Training Epoch: 2/2, step 4204/7134 completed (loss: 0.25878992676734924, acc: 0.9314285516738892)
[2024-12-17 03:10:22,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,485][root][INFO] - Training Epoch: 2/2, step 4205/7134 completed (loss: 0.18625770509243011, acc: 0.9529411792755127)
[2024-12-17 03:10:22,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:22,872][root][INFO] - Training Epoch: 2/2, step 4206/7134 completed (loss: 0.21502342820167542, acc: 0.9731183052062988)
[2024-12-17 03:10:22,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,251][root][INFO] - Training Epoch: 2/2, step 4207/7134 completed (loss: 0.1712961494922638, acc: 0.9748427867889404)
[2024-12-17 03:10:23,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,628][root][INFO] - Training Epoch: 2/2, step 4208/7134 completed (loss: 0.24098336696624756, acc: 0.9482758641242981)
[2024-12-17 03:10:23,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:23,989][root][INFO] - Training Epoch: 2/2, step 4209/7134 completed (loss: 0.16510984301567078, acc: 0.9668508172035217)
[2024-12-17 03:10:24,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:24,352][root][INFO] - Training Epoch: 2/2, step 4210/7134 completed (loss: 0.13652260601520538, acc: 0.9736841917037964)
[2024-12-17 03:10:24,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:24,719][root][INFO] - Training Epoch: 2/2, step 4211/7134 completed (loss: 0.09790448844432831, acc: 0.9836065769195557)
[2024-12-17 03:10:24,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,103][root][INFO] - Training Epoch: 2/2, step 4212/7134 completed (loss: 0.15725816786289215, acc: 0.9548386931419373)
[2024-12-17 03:10:25,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,467][root][INFO] - Training Epoch: 2/2, step 4213/7134 completed (loss: 0.04704602435231209, acc: 0.9942528605461121)
[2024-12-17 03:10:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:25,843][root][INFO] - Training Epoch: 2/2, step 4214/7134 completed (loss: 0.16682161390781403, acc: 0.9707602262496948)
[2024-12-17 03:10:25,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,187][root][INFO] - Training Epoch: 2/2, step 4215/7134 completed (loss: 0.11989816278219223, acc: 0.9763779640197754)
[2024-12-17 03:10:26,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,531][root][INFO] - Training Epoch: 2/2, step 4216/7134 completed (loss: 0.09679017961025238, acc: 0.9846153855323792)
[2024-12-17 03:10:26,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:26,867][root][INFO] - Training Epoch: 2/2, step 4217/7134 completed (loss: 0.06732765585184097, acc: 0.9833333492279053)
[2024-12-17 03:10:26,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,204][root][INFO] - Training Epoch: 2/2, step 4218/7134 completed (loss: 0.16313576698303223, acc: 0.9850746393203735)
[2024-12-17 03:10:27,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,576][root][INFO] - Training Epoch: 2/2, step 4219/7134 completed (loss: 0.10027070343494415, acc: 0.9710144996643066)
[2024-12-17 03:10:27,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:27,946][root][INFO] - Training Epoch: 2/2, step 4220/7134 completed (loss: 0.20832347869873047, acc: 0.9545454382896423)
[2024-12-17 03:10:28,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:28,324][root][INFO] - Training Epoch: 2/2, step 4221/7134 completed (loss: 0.18577685952186584, acc: 0.9594594836235046)
[2024-12-17 03:10:28,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:28,721][root][INFO] - Training Epoch: 2/2, step 4222/7134 completed (loss: 0.4389236569404602, acc: 0.9210526347160339)
[2024-12-17 03:10:28,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,084][root][INFO] - Training Epoch: 2/2, step 4223/7134 completed (loss: 0.34118059277534485, acc: 0.929648220539093)
[2024-12-17 03:10:29,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,413][root][INFO] - Training Epoch: 2/2, step 4224/7134 completed (loss: 0.21487706899642944, acc: 0.9516128897666931)
[2024-12-17 03:10:29,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:29,765][root][INFO] - Training Epoch: 2/2, step 4225/7134 completed (loss: 0.28231480717658997, acc: 0.9230769276618958)
[2024-12-17 03:10:29,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,136][root][INFO] - Training Epoch: 2/2, step 4226/7134 completed (loss: 0.34024444222450256, acc: 0.9238578677177429)
[2024-12-17 03:10:30,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,458][root][INFO] - Training Epoch: 2/2, step 4227/7134 completed (loss: 0.5148261189460754, acc: 0.8679245114326477)
[2024-12-17 03:10:30,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:30,817][root][INFO] - Training Epoch: 2/2, step 4228/7134 completed (loss: 0.5214337706565857, acc: 0.8846153616905212)
[2024-12-17 03:10:30,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,166][root][INFO] - Training Epoch: 2/2, step 4229/7134 completed (loss: 0.4317283630371094, acc: 0.9039999842643738)
[2024-12-17 03:10:31,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,520][root][INFO] - Training Epoch: 2/2, step 4230/7134 completed (loss: 0.4012639820575714, acc: 0.9186046719551086)
[2024-12-17 03:10:31,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:31,888][root][INFO] - Training Epoch: 2/2, step 4231/7134 completed (loss: 0.5999453663825989, acc: 0.8859060406684875)
[2024-12-17 03:10:32,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:32,277][root][INFO] - Training Epoch: 2/2, step 4232/7134 completed (loss: 0.33392828702926636, acc: 0.9222221970558167)
[2024-12-17 03:10:32,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:32,673][root][INFO] - Training Epoch: 2/2, step 4233/7134 completed (loss: 0.27686065435409546, acc: 0.9503546357154846)
[2024-12-17 03:10:32,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,060][root][INFO] - Training Epoch: 2/2, step 4234/7134 completed (loss: 0.16895711421966553, acc: 0.978723406791687)
[2024-12-17 03:10:33,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,442][root][INFO] - Training Epoch: 2/2, step 4235/7134 completed (loss: 0.1792617291212082, acc: 0.9637681245803833)
[2024-12-17 03:10:33,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:33,804][root][INFO] - Training Epoch: 2/2, step 4236/7134 completed (loss: 0.08932581543922424, acc: 0.9784946441650391)
[2024-12-17 03:10:33,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:34,171][root][INFO] - Training Epoch: 2/2, step 4237/7134 completed (loss: 0.1332584023475647, acc: 0.9532710313796997)
[2024-12-17 03:10:34,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:34,562][root][INFO] - Training Epoch: 2/2, step 4238/7134 completed (loss: 0.17191463708877563, acc: 0.9692307710647583)
[2024-12-17 03:10:34,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:34,945][root][INFO] - Training Epoch: 2/2, step 4239/7134 completed (loss: 0.11623524129390717, acc: 0.9599999785423279)
[2024-12-17 03:10:35,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:35,314][root][INFO] - Training Epoch: 2/2, step 4240/7134 completed (loss: 0.2203603982925415, acc: 0.9577465057373047)
[2024-12-17 03:10:35,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:35,717][root][INFO] - Training Epoch: 2/2, step 4241/7134 completed (loss: 0.05133119225502014, acc: 1.0)
[2024-12-17 03:10:35,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,099][root][INFO] - Training Epoch: 2/2, step 4242/7134 completed (loss: 0.1484365612268448, acc: 0.9897959232330322)
[2024-12-17 03:10:36,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,510][root][INFO] - Training Epoch: 2/2, step 4243/7134 completed (loss: 0.1901298463344574, acc: 0.942148745059967)
[2024-12-17 03:10:36,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:36,878][root][INFO] - Training Epoch: 2/2, step 4244/7134 completed (loss: 0.05683363974094391, acc: 1.0)
[2024-12-17 03:10:37,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:37,252][root][INFO] - Training Epoch: 2/2, step 4245/7134 completed (loss: 0.12564048171043396, acc: 0.9578947424888611)
[2024-12-17 03:10:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:37,640][root][INFO] - Training Epoch: 2/2, step 4246/7134 completed (loss: 0.12488429248332977, acc: 0.9794520735740662)
[2024-12-17 03:10:37,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,025][root][INFO] - Training Epoch: 2/2, step 4247/7134 completed (loss: 0.11530324816703796, acc: 0.9760000109672546)
[2024-12-17 03:10:38,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,414][root][INFO] - Training Epoch: 2/2, step 4248/7134 completed (loss: 0.209936261177063, acc: 0.965753436088562)
[2024-12-17 03:10:38,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:38,831][root][INFO] - Training Epoch: 2/2, step 4249/7134 completed (loss: 0.23401165008544922, acc: 0.9485294222831726)
[2024-12-17 03:10:38,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,219][root][INFO] - Training Epoch: 2/2, step 4250/7134 completed (loss: 0.36369726061820984, acc: 0.9454545378684998)
[2024-12-17 03:10:39,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,597][root][INFO] - Training Epoch: 2/2, step 4251/7134 completed (loss: 0.15173719823360443, acc: 0.9473684430122375)
[2024-12-17 03:10:39,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:39,973][root][INFO] - Training Epoch: 2/2, step 4252/7134 completed (loss: 0.2175571769475937, acc: 0.9435483813285828)
[2024-12-17 03:10:40,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:40,346][root][INFO] - Training Epoch: 2/2, step 4253/7134 completed (loss: 0.1528390496969223, acc: 0.9652174115180969)
[2024-12-17 03:10:40,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:40,715][root][INFO] - Training Epoch: 2/2, step 4254/7134 completed (loss: 0.0808725506067276, acc: 0.9886363744735718)
[2024-12-17 03:10:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,113][root][INFO] - Training Epoch: 2/2, step 4255/7134 completed (loss: 0.23210492730140686, acc: 0.9384615421295166)
[2024-12-17 03:10:41,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,489][root][INFO] - Training Epoch: 2/2, step 4256/7134 completed (loss: 0.11286672204732895, acc: 0.9658119678497314)
[2024-12-17 03:10:41,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:41,867][root][INFO] - Training Epoch: 2/2, step 4257/7134 completed (loss: 0.06477965414524078, acc: 0.9772727489471436)
[2024-12-17 03:10:41,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,253][root][INFO] - Training Epoch: 2/2, step 4258/7134 completed (loss: 0.04896906390786171, acc: 0.9913793206214905)
[2024-12-17 03:10:42,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:42,642][root][INFO] - Training Epoch: 2/2, step 4259/7134 completed (loss: 0.2211543619632721, acc: 0.9312499761581421)
[2024-12-17 03:10:42,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,035][root][INFO] - Training Epoch: 2/2, step 4260/7134 completed (loss: 0.12581060826778412, acc: 0.9541284441947937)
[2024-12-17 03:10:43,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,408][root][INFO] - Training Epoch: 2/2, step 4261/7134 completed (loss: 0.12619562447071075, acc: 0.947826087474823)
[2024-12-17 03:10:43,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:43,785][root][INFO] - Training Epoch: 2/2, step 4262/7134 completed (loss: 0.26443934440612793, acc: 0.9160839319229126)
[2024-12-17 03:10:43,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,152][root][INFO] - Training Epoch: 2/2, step 4263/7134 completed (loss: 0.1753663271665573, acc: 0.9629629850387573)
[2024-12-17 03:10:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,522][root][INFO] - Training Epoch: 2/2, step 4264/7134 completed (loss: 0.2545115351676941, acc: 0.9382022619247437)
[2024-12-17 03:10:44,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:44,889][root][INFO] - Training Epoch: 2/2, step 4265/7134 completed (loss: 0.2837527394294739, acc: 0.9360465407371521)
[2024-12-17 03:10:45,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:45,286][root][INFO] - Training Epoch: 2/2, step 4266/7134 completed (loss: 0.10709521174430847, acc: 0.9581151604652405)
[2024-12-17 03:10:45,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:45,671][root][INFO] - Training Epoch: 2/2, step 4267/7134 completed (loss: 0.1598936915397644, acc: 0.939393937587738)
[2024-12-17 03:10:45,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,032][root][INFO] - Training Epoch: 2/2, step 4268/7134 completed (loss: 0.22212833166122437, acc: 0.9512194991111755)
[2024-12-17 03:10:46,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,403][root][INFO] - Training Epoch: 2/2, step 4269/7134 completed (loss: 0.47620031237602234, acc: 0.8786126971244812)
[2024-12-17 03:10:46,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:46,767][root][INFO] - Training Epoch: 2/2, step 4270/7134 completed (loss: 0.2079026848077774, acc: 0.9427083134651184)
[2024-12-17 03:10:46,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,147][root][INFO] - Training Epoch: 2/2, step 4271/7134 completed (loss: 0.11560453474521637, acc: 0.9783783555030823)
[2024-12-17 03:10:47,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,524][root][INFO] - Training Epoch: 2/2, step 4272/7134 completed (loss: 0.2139514535665512, acc: 0.9353233575820923)
[2024-12-17 03:10:47,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:47,933][root][INFO] - Training Epoch: 2/2, step 4273/7134 completed (loss: 0.11056823283433914, acc: 0.9735449552536011)
[2024-12-17 03:10:48,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:48,343][root][INFO] - Training Epoch: 2/2, step 4274/7134 completed (loss: 0.2932388484477997, acc: 0.9166666865348816)
[2024-12-17 03:10:48,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:48,725][root][INFO] - Training Epoch: 2/2, step 4275/7134 completed (loss: 0.11691901087760925, acc: 0.9776536226272583)
[2024-12-17 03:10:48,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,108][root][INFO] - Training Epoch: 2/2, step 4276/7134 completed (loss: 0.25934329628944397, acc: 0.9567567706108093)
[2024-12-17 03:10:49,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,460][root][INFO] - Training Epoch: 2/2, step 4277/7134 completed (loss: 0.07770565897226334, acc: 0.9647887349128723)
[2024-12-17 03:10:49,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:49,820][root][INFO] - Training Epoch: 2/2, step 4278/7134 completed (loss: 0.1162051260471344, acc: 0.9693877696990967)
[2024-12-17 03:10:49,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,175][root][INFO] - Training Epoch: 2/2, step 4279/7134 completed (loss: 0.08270207047462463, acc: 0.9751552939414978)
[2024-12-17 03:10:50,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,543][root][INFO] - Training Epoch: 2/2, step 4280/7134 completed (loss: 0.043373264372348785, acc: 0.9858155846595764)
[2024-12-17 03:10:50,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:50,918][root][INFO] - Training Epoch: 2/2, step 4281/7134 completed (loss: 0.15371455252170563, acc: 0.9623655676841736)
[2024-12-17 03:10:51,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:51,290][root][INFO] - Training Epoch: 2/2, step 4282/7134 completed (loss: 0.09996457397937775, acc: 0.9655172228813171)
[2024-12-17 03:10:51,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:51,678][root][INFO] - Training Epoch: 2/2, step 4283/7134 completed (loss: 0.09785986691713333, acc: 0.9744898080825806)
[2024-12-17 03:10:51,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,053][root][INFO] - Training Epoch: 2/2, step 4284/7134 completed (loss: 0.23566098511219025, acc: 0.9534883499145508)
[2024-12-17 03:10:52,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,435][root][INFO] - Training Epoch: 2/2, step 4285/7134 completed (loss: 0.0655670166015625, acc: 0.9844961166381836)
[2024-12-17 03:10:52,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:52,775][root][INFO] - Training Epoch: 2/2, step 4286/7134 completed (loss: 0.15783047676086426, acc: 0.9495798349380493)
[2024-12-17 03:10:52,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,149][root][INFO] - Training Epoch: 2/2, step 4287/7134 completed (loss: 0.23118871450424194, acc: 0.9402173757553101)
[2024-12-17 03:10:53,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,523][root][INFO] - Training Epoch: 2/2, step 4288/7134 completed (loss: 0.2943874001502991, acc: 0.9058823585510254)
[2024-12-17 03:10:53,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:53,902][root][INFO] - Training Epoch: 2/2, step 4289/7134 completed (loss: 0.23697321116924286, acc: 0.9570552110671997)
[2024-12-17 03:10:54,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:54,289][root][INFO] - Training Epoch: 2/2, step 4290/7134 completed (loss: 0.12734545767307281, acc: 0.9710982441902161)
[2024-12-17 03:10:54,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:54,675][root][INFO] - Training Epoch: 2/2, step 4291/7134 completed (loss: 0.07146315276622772, acc: 0.9768785834312439)
[2024-12-17 03:10:54,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,097][root][INFO] - Training Epoch: 2/2, step 4292/7134 completed (loss: 0.13592882454395294, acc: 0.9806451797485352)
[2024-12-17 03:10:55,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,466][root][INFO] - Training Epoch: 2/2, step 4293/7134 completed (loss: 0.10599438846111298, acc: 0.9666666388511658)
[2024-12-17 03:10:55,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:55,855][root][INFO] - Training Epoch: 2/2, step 4294/7134 completed (loss: 0.17716512084007263, acc: 0.9599999785423279)
[2024-12-17 03:10:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:56,237][root][INFO] - Training Epoch: 2/2, step 4295/7134 completed (loss: 0.22534675896167755, acc: 0.949999988079071)
[2024-12-17 03:10:56,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:56,627][root][INFO] - Training Epoch: 2/2, step 4296/7134 completed (loss: 0.07111304998397827, acc: 0.9801980257034302)
[2024-12-17 03:10:56,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,013][root][INFO] - Training Epoch: 2/2, step 4297/7134 completed (loss: 0.03398139402270317, acc: 1.0)
[2024-12-17 03:10:57,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,390][root][INFO] - Training Epoch: 2/2, step 4298/7134 completed (loss: 0.14147883653640747, acc: 0.9545454382896423)
[2024-12-17 03:10:57,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:57,746][root][INFO] - Training Epoch: 2/2, step 4299/7134 completed (loss: 0.15307003259658813, acc: 0.9516128897666931)
[2024-12-17 03:10:57,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,100][root][INFO] - Training Epoch: 2/2, step 4300/7134 completed (loss: 0.27952149510383606, acc: 0.9327731132507324)
[2024-12-17 03:10:58,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,464][root][INFO] - Training Epoch: 2/2, step 4301/7134 completed (loss: 0.0959630236029625, acc: 0.9788732528686523)
[2024-12-17 03:10:58,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:58,829][root][INFO] - Training Epoch: 2/2, step 4302/7134 completed (loss: 0.15756435692310333, acc: 0.9745222926139832)
[2024-12-17 03:10:58,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,205][root][INFO] - Training Epoch: 2/2, step 4303/7134 completed (loss: 0.2112312912940979, acc: 0.9504950642585754)
[2024-12-17 03:10:59,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,587][root][INFO] - Training Epoch: 2/2, step 4304/7134 completed (loss: 0.13019980490207672, acc: 0.9408283829689026)
[2024-12-17 03:10:59,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:10:59,946][root][INFO] - Training Epoch: 2/2, step 4305/7134 completed (loss: 0.20315155386924744, acc: 0.9399999976158142)
[2024-12-17 03:11:00,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:00,302][root][INFO] - Training Epoch: 2/2, step 4306/7134 completed (loss: 0.21180051565170288, acc: 0.9476439952850342)
[2024-12-17 03:11:00,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:00,701][root][INFO] - Training Epoch: 2/2, step 4307/7134 completed (loss: 0.14551430940628052, acc: 0.9673202633857727)
[2024-12-17 03:11:00,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,100][root][INFO] - Training Epoch: 2/2, step 4308/7134 completed (loss: 0.1323472559452057, acc: 0.9679144620895386)
[2024-12-17 03:11:01,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,477][root][INFO] - Training Epoch: 2/2, step 4309/7134 completed (loss: 0.17481279373168945, acc: 0.9545454382896423)
[2024-12-17 03:11:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:01,837][root][INFO] - Training Epoch: 2/2, step 4310/7134 completed (loss: 0.1804993599653244, acc: 0.9441624283790588)
[2024-12-17 03:11:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,188][root][INFO] - Training Epoch: 2/2, step 4311/7134 completed (loss: 0.11797888576984406, acc: 0.978723406791687)
[2024-12-17 03:11:02,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,536][root][INFO] - Training Epoch: 2/2, step 4312/7134 completed (loss: 0.16299380362033844, acc: 0.9570552110671997)
[2024-12-17 03:11:02,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:02,898][root][INFO] - Training Epoch: 2/2, step 4313/7134 completed (loss: 0.07400897890329361, acc: 0.9757575988769531)
[2024-12-17 03:11:03,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:03,259][root][INFO] - Training Epoch: 2/2, step 4314/7134 completed (loss: 0.13589103519916534, acc: 0.9673202633857727)
[2024-12-17 03:11:03,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:03,639][root][INFO] - Training Epoch: 2/2, step 4315/7134 completed (loss: 0.12183475494384766, acc: 0.976190447807312)
[2024-12-17 03:11:03,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,005][root][INFO] - Training Epoch: 2/2, step 4316/7134 completed (loss: 0.10581565648317337, acc: 0.976047933101654)
[2024-12-17 03:11:04,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,375][root][INFO] - Training Epoch: 2/2, step 4317/7134 completed (loss: 0.09432384371757507, acc: 0.9767441749572754)
[2024-12-17 03:11:04,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:04,759][root][INFO] - Training Epoch: 2/2, step 4318/7134 completed (loss: 0.170773446559906, acc: 0.9642857313156128)
[2024-12-17 03:11:04,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,152][root][INFO] - Training Epoch: 2/2, step 4319/7134 completed (loss: 0.0974612906575203, acc: 0.9704433679580688)
[2024-12-17 03:11:05,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,516][root][INFO] - Training Epoch: 2/2, step 4320/7134 completed (loss: 0.15133705735206604, acc: 0.9487179517745972)
[2024-12-17 03:11:05,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:05,867][root][INFO] - Training Epoch: 2/2, step 4321/7134 completed (loss: 0.4193670153617859, acc: 0.9405940771102905)
[2024-12-17 03:11:05,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,242][root][INFO] - Training Epoch: 2/2, step 4322/7134 completed (loss: 0.2592509388923645, acc: 0.9308176040649414)
[2024-12-17 03:11:06,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,616][root][INFO] - Training Epoch: 2/2, step 4323/7134 completed (loss: 0.13514220714569092, acc: 0.9624060392379761)
[2024-12-17 03:11:06,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:06,979][root][INFO] - Training Epoch: 2/2, step 4324/7134 completed (loss: 0.13910940289497375, acc: 0.9739130139350891)
[2024-12-17 03:11:07,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:07,347][root][INFO] - Training Epoch: 2/2, step 4325/7134 completed (loss: 0.20810002088546753, acc: 0.9589040875434875)
[2024-12-17 03:11:07,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:07,721][root][INFO] - Training Epoch: 2/2, step 4326/7134 completed (loss: 0.2647947669029236, acc: 0.9469696879386902)
[2024-12-17 03:11:07,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,102][root][INFO] - Training Epoch: 2/2, step 4327/7134 completed (loss: 0.10443822294473648, acc: 0.9781022071838379)
[2024-12-17 03:11:08,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,504][root][INFO] - Training Epoch: 2/2, step 4328/7134 completed (loss: 0.12509748339653015, acc: 0.953125)
[2024-12-17 03:11:08,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:08,892][root][INFO] - Training Epoch: 2/2, step 4329/7134 completed (loss: 0.18306784331798553, acc: 0.9649122953414917)
[2024-12-17 03:11:09,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:09,295][root][INFO] - Training Epoch: 2/2, step 4330/7134 completed (loss: 0.13694016635417938, acc: 0.9639639854431152)
[2024-12-17 03:11:09,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:09,684][root][INFO] - Training Epoch: 2/2, step 4331/7134 completed (loss: 0.059967294335365295, acc: 1.0)
[2024-12-17 03:11:09,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,067][root][INFO] - Training Epoch: 2/2, step 4332/7134 completed (loss: 0.16279301047325134, acc: 0.9444444179534912)
[2024-12-17 03:11:10,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,452][root][INFO] - Training Epoch: 2/2, step 4333/7134 completed (loss: 0.10187526047229767, acc: 0.9750000238418579)
[2024-12-17 03:11:10,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:10,814][root][INFO] - Training Epoch: 2/2, step 4334/7134 completed (loss: 0.20821541547775269, acc: 0.9631901979446411)
[2024-12-17 03:11:10,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,191][root][INFO] - Training Epoch: 2/2, step 4335/7134 completed (loss: 0.1501004993915558, acc: 0.9752066135406494)
[2024-12-17 03:11:11,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,587][root][INFO] - Training Epoch: 2/2, step 4336/7134 completed (loss: 0.027115680277347565, acc: 1.0)
[2024-12-17 03:11:11,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:11,942][root][INFO] - Training Epoch: 2/2, step 4337/7134 completed (loss: 0.07099487632513046, acc: 0.9860140085220337)
[2024-12-17 03:11:12,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:12,287][root][INFO] - Training Epoch: 2/2, step 4338/7134 completed (loss: 0.1466384381055832, acc: 0.9575757384300232)
[2024-12-17 03:11:12,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:12,675][root][INFO] - Training Epoch: 2/2, step 4339/7134 completed (loss: 0.11671625822782516, acc: 0.9647058844566345)
[2024-12-17 03:11:12,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,059][root][INFO] - Training Epoch: 2/2, step 4340/7134 completed (loss: 0.15294058620929718, acc: 0.9379310607910156)
[2024-12-17 03:11:13,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,435][root][INFO] - Training Epoch: 2/2, step 4341/7134 completed (loss: 0.13005037605762482, acc: 0.9591836929321289)
[2024-12-17 03:11:13,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:13,832][root][INFO] - Training Epoch: 2/2, step 4342/7134 completed (loss: 0.21586962044239044, acc: 0.9337748289108276)
[2024-12-17 03:11:13,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,200][root][INFO] - Training Epoch: 2/2, step 4343/7134 completed (loss: 0.1821344941854477, acc: 0.970370352268219)
[2024-12-17 03:11:14,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:14,627][root][INFO] - Training Epoch: 2/2, step 4344/7134 completed (loss: 0.20198862254619598, acc: 0.9652174115180969)
[2024-12-17 03:11:14,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,011][root][INFO] - Training Epoch: 2/2, step 4345/7134 completed (loss: 0.08257690817117691, acc: 0.9909909963607788)
[2024-12-17 03:11:15,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,398][root][INFO] - Training Epoch: 2/2, step 4346/7134 completed (loss: 0.09253452718257904, acc: 0.9819819927215576)
[2024-12-17 03:11:15,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:15,782][root][INFO] - Training Epoch: 2/2, step 4347/7134 completed (loss: 0.2360636293888092, acc: 0.9408283829689026)
[2024-12-17 03:11:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,158][root][INFO] - Training Epoch: 2/2, step 4348/7134 completed (loss: 0.1529654711484909, acc: 0.9659863710403442)
[2024-12-17 03:11:16,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,577][root][INFO] - Training Epoch: 2/2, step 4349/7134 completed (loss: 0.11450892686843872, acc: 0.9791666865348816)
[2024-12-17 03:11:16,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:16,940][root][INFO] - Training Epoch: 2/2, step 4350/7134 completed (loss: 0.18512295186519623, acc: 0.9719101190567017)
[2024-12-17 03:11:17,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:17,308][root][INFO] - Training Epoch: 2/2, step 4351/7134 completed (loss: 0.14534549415111542, acc: 0.9679487347602844)
[2024-12-17 03:11:17,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:17,700][root][INFO] - Training Epoch: 2/2, step 4352/7134 completed (loss: 0.24834780395030975, acc: 0.9378882050514221)
[2024-12-17 03:11:17,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:18,106][root][INFO] - Training Epoch: 2/2, step 4353/7134 completed (loss: 0.12291807681322098, acc: 0.9640718698501587)
[2024-12-17 03:11:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:18,480][root][INFO] - Training Epoch: 2/2, step 4354/7134 completed (loss: 0.09866185486316681, acc: 0.9631901979446411)
[2024-12-17 03:11:18,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:18,851][root][INFO] - Training Epoch: 2/2, step 4355/7134 completed (loss: 0.22697249054908752, acc: 0.9503105878829956)
[2024-12-17 03:11:18,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,239][root][INFO] - Training Epoch: 2/2, step 4356/7134 completed (loss: 0.10708653926849365, acc: 0.9593023061752319)
[2024-12-17 03:11:19,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,593][root][INFO] - Training Epoch: 2/2, step 4357/7134 completed (loss: 0.33443400263786316, acc: 0.9127516746520996)
[2024-12-17 03:11:19,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:19,983][root][INFO] - Training Epoch: 2/2, step 4358/7134 completed (loss: 0.22487188875675201, acc: 0.9390243887901306)
[2024-12-17 03:11:20,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:20,365][root][INFO] - Training Epoch: 2/2, step 4359/7134 completed (loss: 0.11431485414505005, acc: 0.9603174328804016)
[2024-12-17 03:11:20,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:20,746][root][INFO] - Training Epoch: 2/2, step 4360/7134 completed (loss: 0.09880528599023819, acc: 0.987261176109314)
[2024-12-17 03:11:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,107][root][INFO] - Training Epoch: 2/2, step 4361/7134 completed (loss: 0.12153653055429459, acc: 0.9735099077224731)
[2024-12-17 03:11:21,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,477][root][INFO] - Training Epoch: 2/2, step 4362/7134 completed (loss: 0.10151530057191849, acc: 0.97826087474823)
[2024-12-17 03:11:21,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:21,840][root][INFO] - Training Epoch: 2/2, step 4363/7134 completed (loss: 0.17623455822467804, acc: 0.9621211886405945)
[2024-12-17 03:11:21,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,216][root][INFO] - Training Epoch: 2/2, step 4364/7134 completed (loss: 0.10080989450216293, acc: 0.9844961166381836)
[2024-12-17 03:11:22,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,598][root][INFO] - Training Epoch: 2/2, step 4365/7134 completed (loss: 0.0979093611240387, acc: 0.9856114983558655)
[2024-12-17 03:11:22,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:22,985][root][INFO] - Training Epoch: 2/2, step 4366/7134 completed (loss: 0.15449370443820953, acc: 0.9534883499145508)
[2024-12-17 03:11:23,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:23,344][root][INFO] - Training Epoch: 2/2, step 4367/7134 completed (loss: 0.1465264856815338, acc: 0.9530201554298401)
[2024-12-17 03:11:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:23,741][root][INFO] - Training Epoch: 2/2, step 4368/7134 completed (loss: 0.0762743428349495, acc: 0.9880239367485046)
[2024-12-17 03:11:23,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,119][root][INFO] - Training Epoch: 2/2, step 4369/7134 completed (loss: 0.10481297224760056, acc: 0.9837398529052734)
[2024-12-17 03:11:24,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,509][root][INFO] - Training Epoch: 2/2, step 4370/7134 completed (loss: 0.1932191401720047, acc: 0.9767441749572754)
[2024-12-17 03:11:24,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:24,887][root][INFO] - Training Epoch: 2/2, step 4371/7134 completed (loss: 0.11981052160263062, acc: 0.9634146094322205)
[2024-12-17 03:11:25,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,259][root][INFO] - Training Epoch: 2/2, step 4372/7134 completed (loss: 0.11330021172761917, acc: 0.9672130942344666)
[2024-12-17 03:11:25,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,616][root][INFO] - Training Epoch: 2/2, step 4373/7134 completed (loss: 0.17819301784038544, acc: 0.9558011293411255)
[2024-12-17 03:11:25,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:25,960][root][INFO] - Training Epoch: 2/2, step 4374/7134 completed (loss: 0.18871814012527466, acc: 0.9390243887901306)
[2024-12-17 03:11:26,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:26,344][root][INFO] - Training Epoch: 2/2, step 4375/7134 completed (loss: 0.14797285199165344, acc: 0.9642857313156128)
[2024-12-17 03:11:26,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:26,687][root][INFO] - Training Epoch: 2/2, step 4376/7134 completed (loss: 0.13880643248558044, acc: 0.9583333134651184)
[2024-12-17 03:11:26,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,061][root][INFO] - Training Epoch: 2/2, step 4377/7134 completed (loss: 0.22628585994243622, acc: 0.9647058844566345)
[2024-12-17 03:11:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,462][root][INFO] - Training Epoch: 2/2, step 4378/7134 completed (loss: 0.18416263163089752, acc: 0.9548872113227844)
[2024-12-17 03:11:27,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:27,847][root][INFO] - Training Epoch: 2/2, step 4379/7134 completed (loss: 0.36360105872154236, acc: 0.9191176295280457)
[2024-12-17 03:11:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,195][root][INFO] - Training Epoch: 2/2, step 4380/7134 completed (loss: 0.20294705033302307, acc: 0.9300699234008789)
[2024-12-17 03:11:28,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,571][root][INFO] - Training Epoch: 2/2, step 4381/7134 completed (loss: 0.16399917006492615, acc: 0.970059871673584)
[2024-12-17 03:11:28,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:28,940][root][INFO] - Training Epoch: 2/2, step 4382/7134 completed (loss: 0.2003389298915863, acc: 0.9354838728904724)
[2024-12-17 03:11:29,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:29,304][root][INFO] - Training Epoch: 2/2, step 4383/7134 completed (loss: 0.20849013328552246, acc: 0.9441624283790588)
[2024-12-17 03:11:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:29,652][root][INFO] - Training Epoch: 2/2, step 4384/7134 completed (loss: 0.12423325330018997, acc: 0.9715909361839294)
[2024-12-17 03:11:29,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,005][root][INFO] - Training Epoch: 2/2, step 4385/7134 completed (loss: 0.2872193455696106, acc: 0.9222797751426697)
[2024-12-17 03:11:30,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,365][root][INFO] - Training Epoch: 2/2, step 4386/7134 completed (loss: 0.15492306649684906, acc: 0.9563106894493103)
[2024-12-17 03:11:30,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:30,756][root][INFO] - Training Epoch: 2/2, step 4387/7134 completed (loss: 0.20795483887195587, acc: 0.9470587968826294)
[2024-12-17 03:11:30,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,138][root][INFO] - Training Epoch: 2/2, step 4388/7134 completed (loss: 0.35808485746383667, acc: 0.8831169009208679)
[2024-12-17 03:11:31,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,517][root][INFO] - Training Epoch: 2/2, step 4389/7134 completed (loss: 0.33530309796333313, acc: 0.9057971239089966)
[2024-12-17 03:11:31,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:31,896][root][INFO] - Training Epoch: 2/2, step 4390/7134 completed (loss: 0.3034336268901825, acc: 0.9263803958892822)
[2024-12-17 03:11:32,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,260][root][INFO] - Training Epoch: 2/2, step 4391/7134 completed (loss: 0.363616019487381, acc: 0.9109588861465454)
[2024-12-17 03:11:32,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,634][root][INFO] - Training Epoch: 2/2, step 4392/7134 completed (loss: 0.11253602057695389, acc: 0.9788359999656677)
[2024-12-17 03:11:32,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:32,984][root][INFO] - Training Epoch: 2/2, step 4393/7134 completed (loss: 0.08616746217012405, acc: 0.9800000190734863)
[2024-12-17 03:11:33,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:33,349][root][INFO] - Training Epoch: 2/2, step 4394/7134 completed (loss: 0.20269857347011566, acc: 0.9463087320327759)
[2024-12-17 03:11:33,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:33,736][root][INFO] - Training Epoch: 2/2, step 4395/7134 completed (loss: 0.21311289072036743, acc: 0.95652174949646)
[2024-12-17 03:11:33,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,090][root][INFO] - Training Epoch: 2/2, step 4396/7134 completed (loss: 0.4311741888523102, acc: 0.9153439402580261)
[2024-12-17 03:11:34,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,479][root][INFO] - Training Epoch: 2/2, step 4397/7134 completed (loss: 0.6394916772842407, acc: 0.8738738894462585)
[2024-12-17 03:11:34,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:34,849][root][INFO] - Training Epoch: 2/2, step 4398/7134 completed (loss: 0.19718876481056213, acc: 0.9666666388511658)
[2024-12-17 03:11:34,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,238][root][INFO] - Training Epoch: 2/2, step 4399/7134 completed (loss: 0.20284368097782135, acc: 0.9791666865348816)
[2024-12-17 03:11:35,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,612][root][INFO] - Training Epoch: 2/2, step 4400/7134 completed (loss: 0.2036193460226059, acc: 0.9684210419654846)
[2024-12-17 03:11:35,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:35,949][root][INFO] - Training Epoch: 2/2, step 4401/7134 completed (loss: 0.27633705735206604, acc: 0.9290322661399841)
[2024-12-17 03:11:36,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:36,323][root][INFO] - Training Epoch: 2/2, step 4402/7134 completed (loss: 0.4235108494758606, acc: 0.8827160596847534)
[2024-12-17 03:11:36,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:36,708][root][INFO] - Training Epoch: 2/2, step 4403/7134 completed (loss: 0.685868501663208, acc: 0.8454545736312866)
[2024-12-17 03:11:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,044][root][INFO] - Training Epoch: 2/2, step 4404/7134 completed (loss: 0.40833231806755066, acc: 0.907216489315033)
[2024-12-17 03:11:37,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,426][root][INFO] - Training Epoch: 2/2, step 4405/7134 completed (loss: 0.2403637170791626, acc: 0.9405940771102905)
[2024-12-17 03:11:37,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:37,809][root][INFO] - Training Epoch: 2/2, step 4406/7134 completed (loss: 0.1276824176311493, acc: 0.9707317352294922)
[2024-12-17 03:11:37,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,188][root][INFO] - Training Epoch: 2/2, step 4407/7134 completed (loss: 0.21839146316051483, acc: 0.9489796161651611)
[2024-12-17 03:11:38,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,550][root][INFO] - Training Epoch: 2/2, step 4408/7134 completed (loss: 0.3373858332633972, acc: 0.8990384340286255)
[2024-12-17 03:11:38,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:38,918][root][INFO] - Training Epoch: 2/2, step 4409/7134 completed (loss: 0.2305440455675125, acc: 0.9322916865348816)
[2024-12-17 03:11:39,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:39,293][root][INFO] - Training Epoch: 2/2, step 4410/7134 completed (loss: 0.38495519757270813, acc: 0.9370629191398621)
[2024-12-17 03:11:39,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:39,646][root][INFO] - Training Epoch: 2/2, step 4411/7134 completed (loss: 0.42684850096702576, acc: 0.897849440574646)
[2024-12-17 03:11:39,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,029][root][INFO] - Training Epoch: 2/2, step 4412/7134 completed (loss: 0.7703054547309875, acc: 0.839195966720581)
[2024-12-17 03:11:40,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,388][root][INFO] - Training Epoch: 2/2, step 4413/7134 completed (loss: 0.44485780596733093, acc: 0.9067357778549194)
[2024-12-17 03:11:40,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:40,778][root][INFO] - Training Epoch: 2/2, step 4414/7134 completed (loss: 0.2092776894569397, acc: 0.9569892287254333)
[2024-12-17 03:11:40,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,160][root][INFO] - Training Epoch: 2/2, step 4415/7134 completed (loss: 0.2523495852947235, acc: 0.915730357170105)
[2024-12-17 03:11:41,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,578][root][INFO] - Training Epoch: 2/2, step 4416/7134 completed (loss: 0.1561923325061798, acc: 0.9430052042007446)
[2024-12-17 03:11:41,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:41,954][root][INFO] - Training Epoch: 2/2, step 4417/7134 completed (loss: 0.41272464394569397, acc: 0.9191918969154358)
[2024-12-17 03:11:42,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:42,342][root][INFO] - Training Epoch: 2/2, step 4418/7134 completed (loss: 0.2362598180770874, acc: 0.9347826242446899)
[2024-12-17 03:11:42,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:42,717][root][INFO] - Training Epoch: 2/2, step 4419/7134 completed (loss: 0.3227643668651581, acc: 0.9121951460838318)
[2024-12-17 03:11:42,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,102][root][INFO] - Training Epoch: 2/2, step 4420/7134 completed (loss: 0.34865203499794006, acc: 0.9119170904159546)
[2024-12-17 03:11:43,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,465][root][INFO] - Training Epoch: 2/2, step 4421/7134 completed (loss: 0.26256585121154785, acc: 0.9357798099517822)
[2024-12-17 03:11:43,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:43,837][root][INFO] - Training Epoch: 2/2, step 4422/7134 completed (loss: 0.31086266040802, acc: 0.916167676448822)
[2024-12-17 03:11:43,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,212][root][INFO] - Training Epoch: 2/2, step 4423/7134 completed (loss: 0.2926426827907562, acc: 0.9107142686843872)
[2024-12-17 03:11:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,606][root][INFO] - Training Epoch: 2/2, step 4424/7134 completed (loss: 0.18928904831409454, acc: 0.9602272510528564)
[2024-12-17 03:11:44,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:44,994][root][INFO] - Training Epoch: 2/2, step 4425/7134 completed (loss: 0.2009524405002594, acc: 0.9554455280303955)
[2024-12-17 03:11:45,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:45,384][root][INFO] - Training Epoch: 2/2, step 4426/7134 completed (loss: 0.32909882068634033, acc: 0.9079999923706055)
[2024-12-17 03:11:45,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:45,735][root][INFO] - Training Epoch: 2/2, step 4427/7134 completed (loss: 0.680798351764679, acc: 0.8620689511299133)
[2024-12-17 03:11:45,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,117][root][INFO] - Training Epoch: 2/2, step 4428/7134 completed (loss: 0.1683373600244522, acc: 0.9653179049491882)
[2024-12-17 03:11:46,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,444][root][INFO] - Training Epoch: 2/2, step 4429/7134 completed (loss: 0.315691202878952, acc: 0.8857142925262451)
[2024-12-17 03:11:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:46,810][root][INFO] - Training Epoch: 2/2, step 4430/7134 completed (loss: 0.19866366684436798, acc: 0.932584285736084)
[2024-12-17 03:11:46,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,174][root][INFO] - Training Epoch: 2/2, step 4431/7134 completed (loss: 0.1607743203639984, acc: 0.9476743936538696)
[2024-12-17 03:11:47,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,540][root][INFO] - Training Epoch: 2/2, step 4432/7134 completed (loss: 0.1990576535463333, acc: 0.9617834687232971)
[2024-12-17 03:11:47,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:47,916][root][INFO] - Training Epoch: 2/2, step 4433/7134 completed (loss: 0.1440892368555069, acc: 0.961904764175415)
[2024-12-17 03:11:48,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:48,287][root][INFO] - Training Epoch: 2/2, step 4434/7134 completed (loss: 0.28020966053009033, acc: 0.9314285516738892)
[2024-12-17 03:11:48,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:48,633][root][INFO] - Training Epoch: 2/2, step 4435/7134 completed (loss: 0.2489839643239975, acc: 0.9305555820465088)
[2024-12-17 03:11:48,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,007][root][INFO] - Training Epoch: 2/2, step 4436/7134 completed (loss: 0.24619805812835693, acc: 0.9112426042556763)
[2024-12-17 03:11:49,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,369][root][INFO] - Training Epoch: 2/2, step 4437/7134 completed (loss: 0.0795644149184227, acc: 0.9617486596107483)
[2024-12-17 03:11:49,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:49,725][root][INFO] - Training Epoch: 2/2, step 4438/7134 completed (loss: 0.23861005902290344, acc: 0.9701492786407471)
[2024-12-17 03:11:49,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,078][root][INFO] - Training Epoch: 2/2, step 4439/7134 completed (loss: 0.044506680220365524, acc: 1.0)
[2024-12-17 03:11:50,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,441][root][INFO] - Training Epoch: 2/2, step 4440/7134 completed (loss: 0.11277544498443604, acc: 0.9578313231468201)
[2024-12-17 03:11:50,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:50,847][root][INFO] - Training Epoch: 2/2, step 4441/7134 completed (loss: 0.10258070379495621, acc: 0.9748427867889404)
[2024-12-17 03:11:50,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,217][root][INFO] - Training Epoch: 2/2, step 4442/7134 completed (loss: 0.27977728843688965, acc: 0.9382022619247437)
[2024-12-17 03:11:51,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,584][root][INFO] - Training Epoch: 2/2, step 4443/7134 completed (loss: 0.17824944853782654, acc: 0.9529411792755127)
[2024-12-17 03:11:51,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:51,963][root][INFO] - Training Epoch: 2/2, step 4444/7134 completed (loss: 0.13494594395160675, acc: 0.956204354763031)
[2024-12-17 03:11:52,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:52,328][root][INFO] - Training Epoch: 2/2, step 4445/7134 completed (loss: 0.28211942315101624, acc: 0.9349112510681152)
[2024-12-17 03:11:52,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:52,694][root][INFO] - Training Epoch: 2/2, step 4446/7134 completed (loss: 0.10689470916986465, acc: 0.9767441749572754)
[2024-12-17 03:11:52,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,087][root][INFO] - Training Epoch: 2/2, step 4447/7134 completed (loss: 0.12039275467395782, acc: 0.9712643623352051)
[2024-12-17 03:11:53,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,489][root][INFO] - Training Epoch: 2/2, step 4448/7134 completed (loss: 0.22806182503700256, acc: 0.9457364082336426)
[2024-12-17 03:11:53,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:53,871][root][INFO] - Training Epoch: 2/2, step 4449/7134 completed (loss: 0.2511381506919861, acc: 0.9491525292396545)
[2024-12-17 03:11:54,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:54,256][root][INFO] - Training Epoch: 2/2, step 4450/7134 completed (loss: 0.19324207305908203, acc: 0.9255319237709045)
[2024-12-17 03:11:54,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:54,635][root][INFO] - Training Epoch: 2/2, step 4451/7134 completed (loss: 0.3864899277687073, acc: 0.9235668778419495)
[2024-12-17 03:11:54,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,006][root][INFO] - Training Epoch: 2/2, step 4452/7134 completed (loss: 0.22492188215255737, acc: 0.9481481313705444)
[2024-12-17 03:11:55,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,382][root][INFO] - Training Epoch: 2/2, step 4453/7134 completed (loss: 0.13822482526302338, acc: 0.9673202633857727)
[2024-12-17 03:11:55,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:55,745][root][INFO] - Training Epoch: 2/2, step 4454/7134 completed (loss: 0.2352406084537506, acc: 0.95652174949646)
[2024-12-17 03:11:55,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,130][root][INFO] - Training Epoch: 2/2, step 4455/7134 completed (loss: 0.31048092246055603, acc: 0.9351851940155029)
[2024-12-17 03:11:56,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,510][root][INFO] - Training Epoch: 2/2, step 4456/7134 completed (loss: 0.06291743367910385, acc: 0.9878787994384766)
[2024-12-17 03:11:56,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:56,850][root][INFO] - Training Epoch: 2/2, step 4457/7134 completed (loss: 0.11941298097372055, acc: 0.9740259647369385)
[2024-12-17 03:11:56,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,232][root][INFO] - Training Epoch: 2/2, step 4458/7134 completed (loss: 0.06355520337820053, acc: 0.9860140085220337)
[2024-12-17 03:11:57,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,592][root][INFO] - Training Epoch: 2/2, step 4459/7134 completed (loss: 0.10797184705734253, acc: 0.9883720874786377)
[2024-12-17 03:11:57,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:57,928][root][INFO] - Training Epoch: 2/2, step 4460/7134 completed (loss: 0.0981675311923027, acc: 0.9753694534301758)
[2024-12-17 03:11:58,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:58,305][root][INFO] - Training Epoch: 2/2, step 4461/7134 completed (loss: 0.12813659012317657, acc: 0.9635416865348816)
[2024-12-17 03:11:58,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:58,683][root][INFO] - Training Epoch: 2/2, step 4462/7134 completed (loss: 0.12652090191841125, acc: 0.9657142758369446)
[2024-12-17 03:11:58,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,055][root][INFO] - Training Epoch: 2/2, step 4463/7134 completed (loss: 0.07568629831075668, acc: 0.9788359999656677)
[2024-12-17 03:11:59,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,437][root][INFO] - Training Epoch: 2/2, step 4464/7134 completed (loss: 0.18652205169200897, acc: 0.9589040875434875)
[2024-12-17 03:11:59,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:11:59,816][root][INFO] - Training Epoch: 2/2, step 4465/7134 completed (loss: 0.12534703314304352, acc: 0.9747474789619446)
[2024-12-17 03:11:59,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,191][root][INFO] - Training Epoch: 2/2, step 4466/7134 completed (loss: 0.09047472476959229, acc: 0.9797979593276978)
[2024-12-17 03:12:00,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,573][root][INFO] - Training Epoch: 2/2, step 4467/7134 completed (loss: 0.0905444398522377, acc: 0.9679144620895386)
[2024-12-17 03:12:00,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:00,930][root][INFO] - Training Epoch: 2/2, step 4468/7134 completed (loss: 0.0491216816008091, acc: 0.9839572310447693)
[2024-12-17 03:12:01,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:01,305][root][INFO] - Training Epoch: 2/2, step 4469/7134 completed (loss: 0.06232844665646553, acc: 0.9851484894752502)
[2024-12-17 03:12:01,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:01,693][root][INFO] - Training Epoch: 2/2, step 4470/7134 completed (loss: 0.07636407017707825, acc: 0.9759615659713745)
[2024-12-17 03:12:01,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,078][root][INFO] - Training Epoch: 2/2, step 4471/7134 completed (loss: 0.07442688196897507, acc: 0.9696969985961914)
[2024-12-17 03:12:02,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,443][root][INFO] - Training Epoch: 2/2, step 4472/7134 completed (loss: 0.0696394294500351, acc: 0.9833333492279053)
[2024-12-17 03:12:02,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:02,830][root][INFO] - Training Epoch: 2/2, step 4473/7134 completed (loss: 0.15059614181518555, acc: 0.9467455744743347)
[2024-12-17 03:12:02,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:03,208][root][INFO] - Training Epoch: 2/2, step 4474/7134 completed (loss: 0.15465757250785828, acc: 0.9627329111099243)
[2024-12-17 03:12:03,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:03,660][root][INFO] - Training Epoch: 2/2, step 4475/7134 completed (loss: 0.33744925260543823, acc: 0.9095744490623474)
[2024-12-17 03:12:03,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,079][root][INFO] - Training Epoch: 2/2, step 4476/7134 completed (loss: 0.1932157725095749, acc: 0.9395604133605957)
[2024-12-17 03:12:04,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,507][root][INFO] - Training Epoch: 2/2, step 4477/7134 completed (loss: 0.06057106703519821, acc: 0.9846938848495483)
[2024-12-17 03:12:04,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:04,928][root][INFO] - Training Epoch: 2/2, step 4478/7134 completed (loss: 0.10164489597082138, acc: 0.9685863852500916)
[2024-12-17 03:12:05,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:05,320][root][INFO] - Training Epoch: 2/2, step 4479/7134 completed (loss: 0.12980544567108154, acc: 0.9777777791023254)
[2024-12-17 03:12:05,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:05,759][root][INFO] - Training Epoch: 2/2, step 4480/7134 completed (loss: 0.21350854635238647, acc: 0.9653465151786804)
[2024-12-17 03:12:05,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,136][root][INFO] - Training Epoch: 2/2, step 4481/7134 completed (loss: 0.19954054057598114, acc: 0.9599999785423279)
[2024-12-17 03:12:06,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,507][root][INFO] - Training Epoch: 2/2, step 4482/7134 completed (loss: 0.08577091991901398, acc: 0.9801980257034302)
[2024-12-17 03:12:06,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:06,892][root][INFO] - Training Epoch: 2/2, step 4483/7134 completed (loss: 0.24222780764102936, acc: 0.9440993666648865)
[2024-12-17 03:12:07,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:07,287][root][INFO] - Training Epoch: 2/2, step 4484/7134 completed (loss: 0.09866959601640701, acc: 0.9772727489471436)
[2024-12-17 03:12:07,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:07,665][root][INFO] - Training Epoch: 2/2, step 4485/7134 completed (loss: 0.0899321585893631, acc: 0.9803921580314636)
[2024-12-17 03:12:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,037][root][INFO] - Training Epoch: 2/2, step 4486/7134 completed (loss: 0.0495075099170208, acc: 0.9937888383865356)
[2024-12-17 03:12:08,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,407][root][INFO] - Training Epoch: 2/2, step 4487/7134 completed (loss: 0.1416437178850174, acc: 0.9754601120948792)
[2024-12-17 03:12:08,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:08,768][root][INFO] - Training Epoch: 2/2, step 4488/7134 completed (loss: 0.1067984327673912, acc: 0.9689922332763672)
[2024-12-17 03:12:08,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,139][root][INFO] - Training Epoch: 2/2, step 4489/7134 completed (loss: 0.10830190032720566, acc: 0.9586206674575806)
[2024-12-17 03:12:09,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,527][root][INFO] - Training Epoch: 2/2, step 4490/7134 completed (loss: 0.1169019490480423, acc: 0.9760000109672546)
[2024-12-17 03:12:09,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:09,896][root][INFO] - Training Epoch: 2/2, step 4491/7134 completed (loss: 0.0834936872124672, acc: 0.9923664331436157)
[2024-12-17 03:12:09,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:10,266][root][INFO] - Training Epoch: 2/2, step 4492/7134 completed (loss: 0.14746686816215515, acc: 0.9774436354637146)
[2024-12-17 03:12:10,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:10,706][root][INFO] - Training Epoch: 2/2, step 4493/7134 completed (loss: 0.14981861412525177, acc: 0.9593023061752319)
[2024-12-17 03:12:10,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,074][root][INFO] - Training Epoch: 2/2, step 4494/7134 completed (loss: 0.08722631633281708, acc: 0.983146071434021)
[2024-12-17 03:12:11,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,450][root][INFO] - Training Epoch: 2/2, step 4495/7134 completed (loss: 0.07189816236495972, acc: 0.9793814420700073)
[2024-12-17 03:12:11,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:11,829][root][INFO] - Training Epoch: 2/2, step 4496/7134 completed (loss: 0.09546256810426712, acc: 0.9707602262496948)
[2024-12-17 03:12:11,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,187][root][INFO] - Training Epoch: 2/2, step 4497/7134 completed (loss: 0.07109358161687851, acc: 0.9788359999656677)
[2024-12-17 03:12:12,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,565][root][INFO] - Training Epoch: 2/2, step 4498/7134 completed (loss: 0.036649465560913086, acc: 0.9884393215179443)
[2024-12-17 03:12:12,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:12,894][root][INFO] - Training Epoch: 2/2, step 4499/7134 completed (loss: 0.10660766810178757, acc: 0.9716312289237976)
[2024-12-17 03:12:12,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:13,272][root][INFO] - Training Epoch: 2/2, step 4500/7134 completed (loss: 0.06949373334646225, acc: 0.9839572310447693)
[2024-12-17 03:12:13,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:13,639][root][INFO] - Training Epoch: 2/2, step 4501/7134 completed (loss: 0.0524262860417366, acc: 0.9834254384040833)
[2024-12-17 03:12:13,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:14,045][root][INFO] - Training Epoch: 2/2, step 4502/7134 completed (loss: 0.042010754346847534, acc: 1.0)
[2024-12-17 03:12:14,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:14,402][root][INFO] - Training Epoch: 2/2, step 4503/7134 completed (loss: 0.01938740722835064, acc: 1.0)
[2024-12-17 03:12:14,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:14,783][root][INFO] - Training Epoch: 2/2, step 4504/7134 completed (loss: 0.22399939596652985, acc: 0.9254658222198486)
[2024-12-17 03:12:14,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,156][root][INFO] - Training Epoch: 2/2, step 4505/7134 completed (loss: 0.16463004052639008, acc: 0.9567567706108093)
[2024-12-17 03:12:15,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,494][root][INFO] - Training Epoch: 2/2, step 4506/7134 completed (loss: 0.15150019526481628, acc: 0.9631901979446411)
[2024-12-17 03:12:15,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:15,842][root][INFO] - Training Epoch: 2/2, step 4507/7134 completed (loss: 0.16254955530166626, acc: 0.9805194735527039)
[2024-12-17 03:12:15,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,175][root][INFO] - Training Epoch: 2/2, step 4508/7134 completed (loss: 0.16930073499679565, acc: 0.9378882050514221)
[2024-12-17 03:12:16,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,550][root][INFO] - Training Epoch: 2/2, step 4509/7134 completed (loss: 0.10972519963979721, acc: 0.9696969985961914)
[2024-12-17 03:12:16,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:16,923][root][INFO] - Training Epoch: 2/2, step 4510/7134 completed (loss: 0.18915346264839172, acc: 0.9642857313156128)
[2024-12-17 03:12:17,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:17,311][root][INFO] - Training Epoch: 2/2, step 4511/7134 completed (loss: 0.23084260523319244, acc: 0.9318181872367859)
[2024-12-17 03:12:17,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:17,701][root][INFO] - Training Epoch: 2/2, step 4512/7134 completed (loss: 0.2660791873931885, acc: 0.9111111164093018)
[2024-12-17 03:12:17,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,071][root][INFO] - Training Epoch: 2/2, step 4513/7134 completed (loss: 0.18098540604114532, acc: 0.9590643048286438)
[2024-12-17 03:12:18,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,452][root][INFO] - Training Epoch: 2/2, step 4514/7134 completed (loss: 0.33863791823387146, acc: 0.9306358098983765)
[2024-12-17 03:12:18,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:18,849][root][INFO] - Training Epoch: 2/2, step 4515/7134 completed (loss: 0.18724657595157623, acc: 0.9605262875556946)
[2024-12-17 03:12:18,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,219][root][INFO] - Training Epoch: 2/2, step 4516/7134 completed (loss: 0.1737663298845291, acc: 0.9465240836143494)
[2024-12-17 03:12:19,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,586][root][INFO] - Training Epoch: 2/2, step 4517/7134 completed (loss: 0.15719649195671082, acc: 0.949999988079071)
[2024-12-17 03:12:19,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:19,956][root][INFO] - Training Epoch: 2/2, step 4518/7134 completed (loss: 0.16177037358283997, acc: 0.9587628841400146)
[2024-12-17 03:12:20,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:20,319][root][INFO] - Training Epoch: 2/2, step 4519/7134 completed (loss: 0.08064275979995728, acc: 0.9850746393203735)
[2024-12-17 03:12:20,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:20,681][root][INFO] - Training Epoch: 2/2, step 4520/7134 completed (loss: 0.11317703127861023, acc: 0.9839572310447693)
[2024-12-17 03:12:20,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,030][root][INFO] - Training Epoch: 2/2, step 4521/7134 completed (loss: 0.1783571094274521, acc: 0.9649999737739563)
[2024-12-17 03:12:21,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,398][root][INFO] - Training Epoch: 2/2, step 4522/7134 completed (loss: 0.12855486571788788, acc: 0.9620853066444397)
[2024-12-17 03:12:21,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:21,758][root][INFO] - Training Epoch: 2/2, step 4523/7134 completed (loss: 0.10325821489095688, acc: 0.9718309640884399)
[2024-12-17 03:12:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,124][root][INFO] - Training Epoch: 2/2, step 4524/7134 completed (loss: 0.14175865054130554, acc: 0.9685863852500916)
[2024-12-17 03:12:22,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,469][root][INFO] - Training Epoch: 2/2, step 4525/7134 completed (loss: 0.170158252120018, acc: 0.9507389068603516)
[2024-12-17 03:12:22,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:22,821][root][INFO] - Training Epoch: 2/2, step 4526/7134 completed (loss: 0.22933343052864075, acc: 0.9505494236946106)
[2024-12-17 03:12:22,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,202][root][INFO] - Training Epoch: 2/2, step 4527/7134 completed (loss: 0.17787565290927887, acc: 0.9551569223403931)
[2024-12-17 03:12:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,583][root][INFO] - Training Epoch: 2/2, step 4528/7134 completed (loss: 0.3432914912700653, acc: 0.931034505367279)
[2024-12-17 03:12:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:23,929][root][INFO] - Training Epoch: 2/2, step 4529/7134 completed (loss: 0.18716998398303986, acc: 0.9581151604652405)
[2024-12-17 03:12:24,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:24,287][root][INFO] - Training Epoch: 2/2, step 4530/7134 completed (loss: 0.042079292237758636, acc: 0.9878048896789551)
[2024-12-17 03:12:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:24,663][root][INFO] - Training Epoch: 2/2, step 4531/7134 completed (loss: 0.12263879925012589, acc: 0.9609375)
[2024-12-17 03:12:24,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,037][root][INFO] - Training Epoch: 2/2, step 4532/7134 completed (loss: 0.22264401614665985, acc: 0.945147693157196)
[2024-12-17 03:12:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,400][root][INFO] - Training Epoch: 2/2, step 4533/7134 completed (loss: 0.06879875808954239, acc: 0.9861111044883728)
[2024-12-17 03:12:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:25,769][root][INFO] - Training Epoch: 2/2, step 4534/7134 completed (loss: 0.10781452059745789, acc: 0.9695431590080261)
[2024-12-17 03:12:25,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,127][root][INFO] - Training Epoch: 2/2, step 4535/7134 completed (loss: 0.07776324450969696, acc: 0.9759615659713745)
[2024-12-17 03:12:26,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,497][root][INFO] - Training Epoch: 2/2, step 4536/7134 completed (loss: 0.05748607963323593, acc: 0.9799196720123291)
[2024-12-17 03:12:26,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:26,863][root][INFO] - Training Epoch: 2/2, step 4537/7134 completed (loss: 0.037657517939805984, acc: 0.9954751133918762)
[2024-12-17 03:12:26,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,234][root][INFO] - Training Epoch: 2/2, step 4538/7134 completed (loss: 0.08844687044620514, acc: 0.990338146686554)
[2024-12-17 03:12:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,606][root][INFO] - Training Epoch: 2/2, step 4539/7134 completed (loss: 0.09112819284200668, acc: 0.9765258431434631)
[2024-12-17 03:12:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:27,979][root][INFO] - Training Epoch: 2/2, step 4540/7134 completed (loss: 0.21849609911441803, acc: 0.9404761791229248)
[2024-12-17 03:12:28,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:28,341][root][INFO] - Training Epoch: 2/2, step 4541/7134 completed (loss: 0.23429617285728455, acc: 0.9098360538482666)
[2024-12-17 03:12:28,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:28,722][root][INFO] - Training Epoch: 2/2, step 4542/7134 completed (loss: 0.30559882521629333, acc: 0.9210526347160339)
[2024-12-17 03:12:28,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,098][root][INFO] - Training Epoch: 2/2, step 4543/7134 completed (loss: 0.38319131731987, acc: 0.9025974273681641)
[2024-12-17 03:12:29,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,473][root][INFO] - Training Epoch: 2/2, step 4544/7134 completed (loss: 0.16656887531280518, acc: 0.9729729890823364)
[2024-12-17 03:12:29,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:29,831][root][INFO] - Training Epoch: 2/2, step 4545/7134 completed (loss: 0.11386583745479584, acc: 0.9722222089767456)
[2024-12-17 03:12:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:30,193][root][INFO] - Training Epoch: 2/2, step 4546/7134 completed (loss: 0.22136764228343964, acc: 0.9527559280395508)
[2024-12-17 03:12:30,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:30,557][root][INFO] - Training Epoch: 2/2, step 4547/7134 completed (loss: 0.11685393750667572, acc: 0.9576271176338196)
[2024-12-17 03:12:30,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:30,950][root][INFO] - Training Epoch: 2/2, step 4548/7134 completed (loss: 0.21432296931743622, acc: 0.9448819160461426)
[2024-12-17 03:12:31,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:31,293][root][INFO] - Training Epoch: 2/2, step 4549/7134 completed (loss: 0.23872970044612885, acc: 0.9298245906829834)
[2024-12-17 03:12:31,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:31,694][root][INFO] - Training Epoch: 2/2, step 4550/7134 completed (loss: 0.15961751341819763, acc: 0.969924807548523)
[2024-12-17 03:12:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,057][root][INFO] - Training Epoch: 2/2, step 4551/7134 completed (loss: 0.23904450237751007, acc: 0.9391891956329346)
[2024-12-17 03:12:32,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,417][root][INFO] - Training Epoch: 2/2, step 4552/7134 completed (loss: 0.16134192049503326, acc: 0.9561403393745422)
[2024-12-17 03:12:32,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:32,769][root][INFO] - Training Epoch: 2/2, step 4553/7134 completed (loss: 0.08885112404823303, acc: 0.9924242496490479)
[2024-12-17 03:12:32,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,117][root][INFO] - Training Epoch: 2/2, step 4554/7134 completed (loss: 0.21411995589733124, acc: 0.970802903175354)
[2024-12-17 03:12:33,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,481][root][INFO] - Training Epoch: 2/2, step 4555/7134 completed (loss: 0.300223171710968, acc: 0.90625)
[2024-12-17 03:12:33,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:33,869][root][INFO] - Training Epoch: 2/2, step 4556/7134 completed (loss: 0.3254944980144501, acc: 0.9290322661399841)
[2024-12-17 03:12:33,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,240][root][INFO] - Training Epoch: 2/2, step 4557/7134 completed (loss: 0.0687333196401596, acc: 1.0)
[2024-12-17 03:12:34,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,575][root][INFO] - Training Epoch: 2/2, step 4558/7134 completed (loss: 0.24311643838882446, acc: 0.9224806427955627)
[2024-12-17 03:12:34,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:34,982][root][INFO] - Training Epoch: 2/2, step 4559/7134 completed (loss: 0.2525440752506256, acc: 0.939393937587738)
[2024-12-17 03:12:35,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:35,373][root][INFO] - Training Epoch: 2/2, step 4560/7134 completed (loss: 0.14910447597503662, acc: 0.9435483813285828)
[2024-12-17 03:12:35,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:35,749][root][INFO] - Training Epoch: 2/2, step 4561/7134 completed (loss: 0.1693456768989563, acc: 0.9590163826942444)
[2024-12-17 03:12:35,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,106][root][INFO] - Training Epoch: 2/2, step 4562/7134 completed (loss: 0.23938427865505219, acc: 0.9268292784690857)
[2024-12-17 03:12:36,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,508][root][INFO] - Training Epoch: 2/2, step 4563/7134 completed (loss: 0.14939312636852264, acc: 0.9503546357154846)
[2024-12-17 03:12:36,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:36,876][root][INFO] - Training Epoch: 2/2, step 4564/7134 completed (loss: 0.3354414403438568, acc: 0.9350649118423462)
[2024-12-17 03:12:36,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,219][root][INFO] - Training Epoch: 2/2, step 4565/7134 completed (loss: 0.2367234230041504, acc: 0.9557521939277649)
[2024-12-17 03:12:37,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,584][root][INFO] - Training Epoch: 2/2, step 4566/7134 completed (loss: 0.201018288731575, acc: 0.9398496150970459)
[2024-12-17 03:12:37,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:37,922][root][INFO] - Training Epoch: 2/2, step 4567/7134 completed (loss: 0.05919133871793747, acc: 0.9909909963607788)
[2024-12-17 03:12:38,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:38,282][root][INFO] - Training Epoch: 2/2, step 4568/7134 completed (loss: 0.2798205316066742, acc: 0.9578947424888611)
[2024-12-17 03:12:38,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:38,649][root][INFO] - Training Epoch: 2/2, step 4569/7134 completed (loss: 0.08153171837329865, acc: 0.982300877571106)
[2024-12-17 03:12:38,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,017][root][INFO] - Training Epoch: 2/2, step 4570/7134 completed (loss: 0.1459892988204956, acc: 0.9740259647369385)
[2024-12-17 03:12:39,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,387][root][INFO] - Training Epoch: 2/2, step 4571/7134 completed (loss: 0.11406440287828445, acc: 0.977011501789093)
[2024-12-17 03:12:39,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:39,747][root][INFO] - Training Epoch: 2/2, step 4572/7134 completed (loss: 0.18299131095409393, acc: 0.9539473652839661)
[2024-12-17 03:12:39,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,127][root][INFO] - Training Epoch: 2/2, step 4573/7134 completed (loss: 0.13089215755462646, acc: 0.9615384340286255)
[2024-12-17 03:12:40,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,511][root][INFO] - Training Epoch: 2/2, step 4574/7134 completed (loss: 0.08837657421827316, acc: 0.9696969985961914)
[2024-12-17 03:12:40,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:40,886][root][INFO] - Training Epoch: 2/2, step 4575/7134 completed (loss: 0.1061614528298378, acc: 0.9779005646705627)
[2024-12-17 03:12:40,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:41,265][root][INFO] - Training Epoch: 2/2, step 4576/7134 completed (loss: 0.0893879160284996, acc: 0.9714285731315613)
[2024-12-17 03:12:41,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:41,640][root][INFO] - Training Epoch: 2/2, step 4577/7134 completed (loss: 0.19716429710388184, acc: 0.930232584476471)
[2024-12-17 03:12:41,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,017][root][INFO] - Training Epoch: 2/2, step 4578/7134 completed (loss: 0.08239255845546722, acc: 0.9818181991577148)
[2024-12-17 03:12:42,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,418][root][INFO] - Training Epoch: 2/2, step 4579/7134 completed (loss: 0.2218160331249237, acc: 0.9683544039726257)
[2024-12-17 03:12:42,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:42,781][root][INFO] - Training Epoch: 2/2, step 4580/7134 completed (loss: 0.13453857600688934, acc: 0.9620253443717957)
[2024-12-17 03:12:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,146][root][INFO] - Training Epoch: 2/2, step 4581/7134 completed (loss: 0.058289289474487305, acc: 0.9790209531784058)
[2024-12-17 03:12:43,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,515][root][INFO] - Training Epoch: 2/2, step 4582/7134 completed (loss: 0.11095667630434036, acc: 0.9722222089767456)
[2024-12-17 03:12:43,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:43,864][root][INFO] - Training Epoch: 2/2, step 4583/7134 completed (loss: 0.10714543610811234, acc: 0.9666666388511658)
[2024-12-17 03:12:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,228][root][INFO] - Training Epoch: 2/2, step 4584/7134 completed (loss: 0.09999340027570724, acc: 0.9655172228813171)
[2024-12-17 03:12:44,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,595][root][INFO] - Training Epoch: 2/2, step 4585/7134 completed (loss: 0.09802483022212982, acc: 0.9807692170143127)
[2024-12-17 03:12:44,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:44,972][root][INFO] - Training Epoch: 2/2, step 4586/7134 completed (loss: 0.09048004448413849, acc: 0.9644970297813416)
[2024-12-17 03:12:45,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:45,357][root][INFO] - Training Epoch: 2/2, step 4587/7134 completed (loss: 0.2580351233482361, acc: 0.9476743936538696)
[2024-12-17 03:12:45,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:45,748][root][INFO] - Training Epoch: 2/2, step 4588/7134 completed (loss: 0.17402121424674988, acc: 0.949999988079071)
[2024-12-17 03:12:45,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,117][root][INFO] - Training Epoch: 2/2, step 4589/7134 completed (loss: 0.1299123615026474, acc: 0.977011501789093)
[2024-12-17 03:12:46,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,482][root][INFO] - Training Epoch: 2/2, step 4590/7134 completed (loss: 0.16456012427806854, acc: 0.9583333134651184)
[2024-12-17 03:12:46,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:46,855][root][INFO] - Training Epoch: 2/2, step 4591/7134 completed (loss: 0.20032550394535065, acc: 0.9488636255264282)
[2024-12-17 03:12:46,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,215][root][INFO] - Training Epoch: 2/2, step 4592/7134 completed (loss: 0.13700203597545624, acc: 0.9634146094322205)
[2024-12-17 03:12:47,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,607][root][INFO] - Training Epoch: 2/2, step 4593/7134 completed (loss: 0.1966734677553177, acc: 0.9407894611358643)
[2024-12-17 03:12:47,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:47,969][root][INFO] - Training Epoch: 2/2, step 4594/7134 completed (loss: 0.3272392749786377, acc: 0.9047619104385376)
[2024-12-17 03:12:48,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:48,361][root][INFO] - Training Epoch: 2/2, step 4595/7134 completed (loss: 0.14814849197864532, acc: 0.9620253443717957)
[2024-12-17 03:12:48,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:48,749][root][INFO] - Training Epoch: 2/2, step 4596/7134 completed (loss: 0.15066421031951904, acc: 0.9624999761581421)
[2024-12-17 03:12:48,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,123][root][INFO] - Training Epoch: 2/2, step 4597/7134 completed (loss: 0.189804345369339, acc: 0.9538461565971375)
[2024-12-17 03:12:49,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,493][root][INFO] - Training Epoch: 2/2, step 4598/7134 completed (loss: 0.2419188767671585, acc: 0.9405405521392822)
[2024-12-17 03:12:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:49,863][root][INFO] - Training Epoch: 2/2, step 4599/7134 completed (loss: 0.05402569845318794, acc: 0.9710144996643066)
[2024-12-17 03:12:49,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,239][root][INFO] - Training Epoch: 2/2, step 4600/7134 completed (loss: 0.12153401225805283, acc: 0.9748427867889404)
[2024-12-17 03:12:50,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,618][root][INFO] - Training Epoch: 2/2, step 4601/7134 completed (loss: 0.09819824993610382, acc: 0.9717513918876648)
[2024-12-17 03:12:50,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:50,980][root][INFO] - Training Epoch: 2/2, step 4602/7134 completed (loss: 0.1531355232000351, acc: 0.949999988079071)
[2024-12-17 03:12:51,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:51,339][root][INFO] - Training Epoch: 2/2, step 4603/7134 completed (loss: 0.17785732448101044, acc: 0.9534883499145508)
[2024-12-17 03:12:51,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:51,705][root][INFO] - Training Epoch: 2/2, step 4604/7134 completed (loss: 0.11454343795776367, acc: 0.9650349617004395)
[2024-12-17 03:12:51,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:52,070][root][INFO] - Training Epoch: 2/2, step 4605/7134 completed (loss: 0.17677459120750427, acc: 0.9363636374473572)
[2024-12-17 03:12:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:52,446][root][INFO] - Training Epoch: 2/2, step 4606/7134 completed (loss: 0.16828280687332153, acc: 0.9496855139732361)
[2024-12-17 03:12:52,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:52,812][root][INFO] - Training Epoch: 2/2, step 4607/7134 completed (loss: 0.15513074398040771, acc: 0.957446813583374)
[2024-12-17 03:12:52,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,219][root][INFO] - Training Epoch: 2/2, step 4608/7134 completed (loss: 0.1109110489487648, acc: 0.9707602262496948)
[2024-12-17 03:12:53,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,599][root][INFO] - Training Epoch: 2/2, step 4609/7134 completed (loss: 0.09349296987056732, acc: 0.9694656729698181)
[2024-12-17 03:12:53,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:53,971][root][INFO] - Training Epoch: 2/2, step 4610/7134 completed (loss: 0.052698977291584015, acc: 0.9832402467727661)
[2024-12-17 03:12:54,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:54,357][root][INFO] - Training Epoch: 2/2, step 4611/7134 completed (loss: 0.03893090784549713, acc: 1.0)
[2024-12-17 03:12:54,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:54,739][root][INFO] - Training Epoch: 2/2, step 4612/7134 completed (loss: 0.15196707844734192, acc: 0.9629629850387573)
[2024-12-17 03:12:54,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,111][root][INFO] - Training Epoch: 2/2, step 4613/7134 completed (loss: 0.1032053604722023, acc: 0.9876543283462524)
[2024-12-17 03:12:55,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,466][root][INFO] - Training Epoch: 2/2, step 4614/7134 completed (loss: 0.1289878934621811, acc: 0.9615384340286255)
[2024-12-17 03:12:55,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:55,837][root][INFO] - Training Epoch: 2/2, step 4615/7134 completed (loss: 0.16151227056980133, acc: 0.9520958065986633)
[2024-12-17 03:12:55,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,220][root][INFO] - Training Epoch: 2/2, step 4616/7134 completed (loss: 0.24075445532798767, acc: 0.9244186282157898)
[2024-12-17 03:12:56,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,558][root][INFO] - Training Epoch: 2/2, step 4617/7134 completed (loss: 0.2962212860584259, acc: 0.9341317415237427)
[2024-12-17 03:12:56,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:56,932][root][INFO] - Training Epoch: 2/2, step 4618/7134 completed (loss: 0.23381955921649933, acc: 0.9224806427955627)
[2024-12-17 03:12:57,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:57,320][root][INFO] - Training Epoch: 2/2, step 4619/7134 completed (loss: 0.30614811182022095, acc: 0.9375)
[2024-12-17 03:12:57,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:57,696][root][INFO] - Training Epoch: 2/2, step 4620/7134 completed (loss: 0.07878218591213226, acc: 0.9764705896377563)
[2024-12-17 03:12:57,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,058][root][INFO] - Training Epoch: 2/2, step 4621/7134 completed (loss: 0.10553137958049774, acc: 0.9634146094322205)
[2024-12-17 03:12:58,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,416][root][INFO] - Training Epoch: 2/2, step 4622/7134 completed (loss: 0.11945510655641556, acc: 0.9611111283302307)
[2024-12-17 03:12:58,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:58,807][root][INFO] - Training Epoch: 2/2, step 4623/7134 completed (loss: 0.1824652999639511, acc: 0.9647058844566345)
[2024-12-17 03:12:58,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:59,252][root][INFO] - Training Epoch: 2/2, step 4624/7134 completed (loss: 0.23919659852981567, acc: 0.9411764740943909)
[2024-12-17 03:12:59,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:12:59,628][root][INFO] - Training Epoch: 2/2, step 4625/7134 completed (loss: 0.390386700630188, acc: 0.8834356069564819)
[2024-12-17 03:12:59,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,006][root][INFO] - Training Epoch: 2/2, step 4626/7134 completed (loss: 0.3889734745025635, acc: 0.9021739363670349)
[2024-12-17 03:13:00,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,339][root][INFO] - Training Epoch: 2/2, step 4627/7134 completed (loss: 0.25838741660118103, acc: 0.9419354796409607)
[2024-12-17 03:13:00,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:00,720][root][INFO] - Training Epoch: 2/2, step 4628/7134 completed (loss: 0.23022286593914032, acc: 0.957317054271698)
[2024-12-17 03:13:00,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,071][root][INFO] - Training Epoch: 2/2, step 4629/7134 completed (loss: 0.24090692400932312, acc: 0.9220778942108154)
[2024-12-17 03:13:01,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,450][root][INFO] - Training Epoch: 2/2, step 4630/7134 completed (loss: 0.17626692354679108, acc: 0.9722222089767456)
[2024-12-17 03:13:01,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:01,831][root][INFO] - Training Epoch: 2/2, step 4631/7134 completed (loss: 0.23055806756019592, acc: 0.9488372206687927)
[2024-12-17 03:13:01,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,211][root][INFO] - Training Epoch: 2/2, step 4632/7134 completed (loss: 0.20577464997768402, acc: 0.9457831382751465)
[2024-12-17 03:13:02,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,596][root][INFO] - Training Epoch: 2/2, step 4633/7134 completed (loss: 0.2718682885169983, acc: 0.9406392574310303)
[2024-12-17 03:13:02,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:02,975][root][INFO] - Training Epoch: 2/2, step 4634/7134 completed (loss: 0.1714823693037033, acc: 0.9481481313705444)
[2024-12-17 03:13:03,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:03,330][root][INFO] - Training Epoch: 2/2, step 4635/7134 completed (loss: 0.2567555606365204, acc: 0.9695122241973877)
[2024-12-17 03:13:03,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:03,655][root][INFO] - Training Epoch: 2/2, step 4636/7134 completed (loss: 0.04727436974644661, acc: 0.9893617033958435)
[2024-12-17 03:13:03,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,024][root][INFO] - Training Epoch: 2/2, step 4637/7134 completed (loss: 0.18700186908245087, acc: 0.9603174328804016)
[2024-12-17 03:13:04,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,375][root][INFO] - Training Epoch: 2/2, step 4638/7134 completed (loss: 0.18825700879096985, acc: 0.9653179049491882)
[2024-12-17 03:13:04,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:04,785][root][INFO] - Training Epoch: 2/2, step 4639/7134 completed (loss: 0.12113700807094574, acc: 0.9621621370315552)
[2024-12-17 03:13:04,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:05,177][root][INFO] - Training Epoch: 2/2, step 4640/7134 completed (loss: 0.17633908987045288, acc: 0.9523809552192688)
[2024-12-17 03:13:05,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:05,599][root][INFO] - Training Epoch: 2/2, step 4641/7134 completed (loss: 0.1256895661354065, acc: 0.9652777910232544)
[2024-12-17 03:13:05,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,038][root][INFO] - Training Epoch: 2/2, step 4642/7134 completed (loss: 0.07695440202951431, acc: 0.9774011373519897)
[2024-12-17 03:13:06,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,441][root][INFO] - Training Epoch: 2/2, step 4643/7134 completed (loss: 0.06450540572404861, acc: 0.9804878234863281)
[2024-12-17 03:13:06,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:06,835][root][INFO] - Training Epoch: 2/2, step 4644/7134 completed (loss: 0.06810684502124786, acc: 0.9753694534301758)
[2024-12-17 03:13:06,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,191][root][INFO] - Training Epoch: 2/2, step 4645/7134 completed (loss: 0.05064510554075241, acc: 0.9878048896789551)
[2024-12-17 03:13:07,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,563][root][INFO] - Training Epoch: 2/2, step 4646/7134 completed (loss: 0.14043137431144714, acc: 0.9571428298950195)
[2024-12-17 03:13:07,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:07,949][root][INFO] - Training Epoch: 2/2, step 4647/7134 completed (loss: 0.25132256746292114, acc: 0.9562841653823853)
[2024-12-17 03:13:08,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:08,326][root][INFO] - Training Epoch: 2/2, step 4648/7134 completed (loss: 0.2526008188724518, acc: 0.9426751732826233)
[2024-12-17 03:13:08,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:08,711][root][INFO] - Training Epoch: 2/2, step 4649/7134 completed (loss: 0.1769026219844818, acc: 0.934959352016449)
[2024-12-17 03:13:08,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,093][root][INFO] - Training Epoch: 2/2, step 4650/7134 completed (loss: 0.1730177402496338, acc: 0.9324324131011963)
[2024-12-17 03:13:09,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,416][root][INFO] - Training Epoch: 2/2, step 4651/7134 completed (loss: 0.2785818576812744, acc: 0.9553072452545166)
[2024-12-17 03:13:09,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:09,772][root][INFO] - Training Epoch: 2/2, step 4652/7134 completed (loss: 0.09796112030744553, acc: 0.9567901492118835)
[2024-12-17 03:13:09,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,147][root][INFO] - Training Epoch: 2/2, step 4653/7134 completed (loss: 0.12119133770465851, acc: 0.9758453965187073)
[2024-12-17 03:13:10,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,523][root][INFO] - Training Epoch: 2/2, step 4654/7134 completed (loss: 0.30680474638938904, acc: 0.929729700088501)
[2024-12-17 03:13:10,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:10,903][root][INFO] - Training Epoch: 2/2, step 4655/7134 completed (loss: 0.29336073994636536, acc: 0.9371428489685059)
[2024-12-17 03:13:11,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:11,309][root][INFO] - Training Epoch: 2/2, step 4656/7134 completed (loss: 0.21395047008991241, acc: 0.9322034120559692)
[2024-12-17 03:13:11,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:11,673][root][INFO] - Training Epoch: 2/2, step 4657/7134 completed (loss: 0.1704319417476654, acc: 0.959770143032074)
[2024-12-17 03:13:11,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:12,049][root][INFO] - Training Epoch: 2/2, step 4658/7134 completed (loss: 0.17037516832351685, acc: 0.9375)
[2024-12-17 03:13:12,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:12,440][root][INFO] - Training Epoch: 2/2, step 4659/7134 completed (loss: 0.24166293442249298, acc: 0.9365079402923584)
[2024-12-17 03:13:12,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:12,807][root][INFO] - Training Epoch: 2/2, step 4660/7134 completed (loss: 0.27442076802253723, acc: 0.942307710647583)
[2024-12-17 03:13:12,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,158][root][INFO] - Training Epoch: 2/2, step 4661/7134 completed (loss: 0.23602722585201263, acc: 0.9325153231620789)
[2024-12-17 03:13:13,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,517][root][INFO] - Training Epoch: 2/2, step 4662/7134 completed (loss: 0.40468013286590576, acc: 0.9219858050346375)
[2024-12-17 03:13:13,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:13,937][root][INFO] - Training Epoch: 2/2, step 4663/7134 completed (loss: 0.25241512060165405, acc: 0.9125683307647705)
[2024-12-17 03:13:14,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:14,340][root][INFO] - Training Epoch: 2/2, step 4664/7134 completed (loss: 0.192535400390625, acc: 0.9567567706108093)
[2024-12-17 03:13:14,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:14,718][root][INFO] - Training Epoch: 2/2, step 4665/7134 completed (loss: 0.16816844046115875, acc: 0.9670329689979553)
[2024-12-17 03:13:14,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,109][root][INFO] - Training Epoch: 2/2, step 4666/7134 completed (loss: 0.2831754982471466, acc: 0.9326424598693848)
[2024-12-17 03:13:15,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,459][root][INFO] - Training Epoch: 2/2, step 4667/7134 completed (loss: 0.25324195623397827, acc: 0.9459459185600281)
[2024-12-17 03:13:15,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:15,812][root][INFO] - Training Epoch: 2/2, step 4668/7134 completed (loss: 0.17610052227973938, acc: 0.9395973086357117)
[2024-12-17 03:13:15,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,178][root][INFO] - Training Epoch: 2/2, step 4669/7134 completed (loss: 0.16539978981018066, acc: 0.9548022747039795)
[2024-12-17 03:13:16,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,528][root][INFO] - Training Epoch: 2/2, step 4670/7134 completed (loss: 0.1372796595096588, acc: 0.9626865386962891)
[2024-12-17 03:13:16,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:16,890][root][INFO] - Training Epoch: 2/2, step 4671/7134 completed (loss: 0.17716556787490845, acc: 0.9398906826972961)
[2024-12-17 03:13:16,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:17,245][root][INFO] - Training Epoch: 2/2, step 4672/7134 completed (loss: 0.11085003614425659, acc: 0.9724137783050537)
[2024-12-17 03:13:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:17,625][root][INFO] - Training Epoch: 2/2, step 4673/7134 completed (loss: 0.15142793953418732, acc: 0.955974817276001)
[2024-12-17 03:13:17,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:17,981][root][INFO] - Training Epoch: 2/2, step 4674/7134 completed (loss: 0.11084555089473724, acc: 0.9805194735527039)
[2024-12-17 03:13:18,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:18,360][root][INFO] - Training Epoch: 2/2, step 4675/7134 completed (loss: 0.18278548121452332, acc: 0.964102566242218)
[2024-12-17 03:13:18,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:18,736][root][INFO] - Training Epoch: 2/2, step 4676/7134 completed (loss: 0.12781304121017456, acc: 0.9740259647369385)
[2024-12-17 03:13:18,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,095][root][INFO] - Training Epoch: 2/2, step 4677/7134 completed (loss: 0.08102197200059891, acc: 0.9831932783126831)
[2024-12-17 03:13:19,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,461][root][INFO] - Training Epoch: 2/2, step 4678/7134 completed (loss: 0.2156853824853897, acc: 0.9640718698501587)
[2024-12-17 03:13:19,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:19,808][root][INFO] - Training Epoch: 2/2, step 4679/7134 completed (loss: 0.09205784648656845, acc: 0.9942196607589722)
[2024-12-17 03:13:19,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,163][root][INFO] - Training Epoch: 2/2, step 4680/7134 completed (loss: 0.21739760041236877, acc: 0.9272727370262146)
[2024-12-17 03:13:20,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,516][root][INFO] - Training Epoch: 2/2, step 4681/7134 completed (loss: 0.22130951285362244, acc: 0.9285714030265808)
[2024-12-17 03:13:20,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:20,900][root][INFO] - Training Epoch: 2/2, step 4682/7134 completed (loss: 0.15792454779148102, acc: 0.950276255607605)
[2024-12-17 03:13:21,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:21,245][root][INFO] - Training Epoch: 2/2, step 4683/7134 completed (loss: 0.2195235937833786, acc: 0.9333333373069763)
[2024-12-17 03:13:21,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:21,626][root][INFO] - Training Epoch: 2/2, step 4684/7134 completed (loss: 0.19302578270435333, acc: 0.938144326210022)
[2024-12-17 03:13:21,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:21,989][root][INFO] - Training Epoch: 2/2, step 4685/7134 completed (loss: 0.1122221052646637, acc: 0.9704433679580688)
[2024-12-17 03:13:22,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:22,372][root][INFO] - Training Epoch: 2/2, step 4686/7134 completed (loss: 0.1429225206375122, acc: 0.9735449552536011)
[2024-12-17 03:13:22,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:22,711][root][INFO] - Training Epoch: 2/2, step 4687/7134 completed (loss: 0.5325478911399841, acc: 0.8695651888847351)
[2024-12-17 03:13:22,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,076][root][INFO] - Training Epoch: 2/2, step 4688/7134 completed (loss: 0.7042478322982788, acc: 0.875)
[2024-12-17 03:13:23,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,455][root][INFO] - Training Epoch: 2/2, step 4689/7134 completed (loss: 0.4213847517967224, acc: 0.8965517282485962)
[2024-12-17 03:13:23,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:23,815][root][INFO] - Training Epoch: 2/2, step 4690/7134 completed (loss: 0.5612305402755737, acc: 0.9122806787490845)
[2024-12-17 03:13:23,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,148][root][INFO] - Training Epoch: 2/2, step 4691/7134 completed (loss: 0.1814410537481308, acc: 0.9692307710647583)
[2024-12-17 03:13:24,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,519][root][INFO] - Training Epoch: 2/2, step 4692/7134 completed (loss: 0.7277007699012756, acc: 0.817460298538208)
[2024-12-17 03:13:24,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:24,915][root][INFO] - Training Epoch: 2/2, step 4693/7134 completed (loss: 0.6582289338111877, acc: 0.8742856979370117)
[2024-12-17 03:13:25,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:25,293][root][INFO] - Training Epoch: 2/2, step 4694/7134 completed (loss: 0.5715093612670898, acc: 0.8730158805847168)
[2024-12-17 03:13:25,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:25,674][root][INFO] - Training Epoch: 2/2, step 4695/7134 completed (loss: 0.4735347032546997, acc: 0.9066666960716248)
[2024-12-17 03:13:25,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,056][root][INFO] - Training Epoch: 2/2, step 4696/7134 completed (loss: 0.0974087193608284, acc: 0.9696969985961914)
[2024-12-17 03:13:26,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,446][root][INFO] - Training Epoch: 2/2, step 4697/7134 completed (loss: 0.17431659996509552, acc: 0.976190447807312)
[2024-12-17 03:13:26,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:26,810][root][INFO] - Training Epoch: 2/2, step 4698/7134 completed (loss: 0.46901315450668335, acc: 0.8928571343421936)
[2024-12-17 03:13:26,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,186][root][INFO] - Training Epoch: 2/2, step 4699/7134 completed (loss: 0.41040197014808655, acc: 0.8848921060562134)
[2024-12-17 03:13:27,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,571][root][INFO] - Training Epoch: 2/2, step 4700/7134 completed (loss: 0.327991247177124, acc: 0.9230769276618958)
[2024-12-17 03:13:27,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:27,910][root][INFO] - Training Epoch: 2/2, step 4701/7134 completed (loss: 0.6787866353988647, acc: 0.8500000238418579)
[2024-12-17 03:13:28,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:28,282][root][INFO] - Training Epoch: 2/2, step 4702/7134 completed (loss: 0.181624174118042, acc: 0.9419354796409607)
[2024-12-17 03:13:28,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:28,660][root][INFO] - Training Epoch: 2/2, step 4703/7134 completed (loss: 0.1092139333486557, acc: 0.9823529124259949)
[2024-12-17 03:13:28,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,011][root][INFO] - Training Epoch: 2/2, step 4704/7134 completed (loss: 0.11866481602191925, acc: 0.964102566242218)
[2024-12-17 03:13:29,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,397][root][INFO] - Training Epoch: 2/2, step 4705/7134 completed (loss: 0.22500893473625183, acc: 0.9458128213882446)
[2024-12-17 03:13:29,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:29,779][root][INFO] - Training Epoch: 2/2, step 4706/7134 completed (loss: 0.2801761329174042, acc: 0.9358974099159241)
[2024-12-17 03:13:29,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,150][root][INFO] - Training Epoch: 2/2, step 4707/7134 completed (loss: 0.7399014830589294, acc: 0.8616352081298828)
[2024-12-17 03:13:30,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,491][root][INFO] - Training Epoch: 2/2, step 4708/7134 completed (loss: 0.23216871917247772, acc: 0.929648220539093)
[2024-12-17 03:13:30,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:30,876][root][INFO] - Training Epoch: 2/2, step 4709/7134 completed (loss: 0.11858292669057846, acc: 0.9729729890823364)
[2024-12-17 03:13:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:31,239][root][INFO] - Training Epoch: 2/2, step 4710/7134 completed (loss: 0.18494051694869995, acc: 0.939393937587738)
[2024-12-17 03:13:31,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:31,619][root][INFO] - Training Epoch: 2/2, step 4711/7134 completed (loss: 0.26267361640930176, acc: 0.9324324131011963)
[2024-12-17 03:13:31,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:32,004][root][INFO] - Training Epoch: 2/2, step 4712/7134 completed (loss: 0.4689342975616455, acc: 0.9019607901573181)
[2024-12-17 03:13:32,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:32,381][root][INFO] - Training Epoch: 2/2, step 4713/7134 completed (loss: 0.18920636177062988, acc: 0.9626865386962891)
[2024-12-17 03:13:32,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:32,671][root][INFO] - Training Epoch: 2/2, step 4714/7134 completed (loss: 0.3027247488498688, acc: 0.9389312863349915)
[2024-12-17 03:13:32,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,029][root][INFO] - Training Epoch: 2/2, step 4715/7134 completed (loss: 0.4685477018356323, acc: 0.9333333373069763)
[2024-12-17 03:13:33,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,377][root][INFO] - Training Epoch: 2/2, step 4716/7134 completed (loss: 0.1464957296848297, acc: 0.9741935729980469)
[2024-12-17 03:13:33,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:33,742][root][INFO] - Training Epoch: 2/2, step 4717/7134 completed (loss: 0.11134593933820724, acc: 0.9599999785423279)
[2024-12-17 03:13:33,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,102][root][INFO] - Training Epoch: 2/2, step 4718/7134 completed (loss: 0.06562606990337372, acc: 0.9928057789802551)
[2024-12-17 03:13:34,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,464][root][INFO] - Training Epoch: 2/2, step 4719/7134 completed (loss: 0.13465715944766998, acc: 0.9704142212867737)
[2024-12-17 03:13:34,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:34,852][root][INFO] - Training Epoch: 2/2, step 4720/7134 completed (loss: 0.04681744426488876, acc: 0.987500011920929)
[2024-12-17 03:13:34,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,228][root][INFO] - Training Epoch: 2/2, step 4721/7134 completed (loss: 0.032658759504556656, acc: 0.9938271641731262)
[2024-12-17 03:13:35,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,606][root][INFO] - Training Epoch: 2/2, step 4722/7134 completed (loss: 0.1547817885875702, acc: 0.955974817276001)
[2024-12-17 03:13:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:35,961][root][INFO] - Training Epoch: 2/2, step 4723/7134 completed (loss: 0.11556054651737213, acc: 0.9745222926139832)
[2024-12-17 03:13:36,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:36,318][root][INFO] - Training Epoch: 2/2, step 4724/7134 completed (loss: 0.15154562890529633, acc: 0.9756097793579102)
[2024-12-17 03:13:36,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:36,697][root][INFO] - Training Epoch: 2/2, step 4725/7134 completed (loss: 0.1992512345314026, acc: 0.9418604373931885)
[2024-12-17 03:13:36,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,087][root][INFO] - Training Epoch: 2/2, step 4726/7134 completed (loss: 0.43853574991226196, acc: 0.8735632300376892)
[2024-12-17 03:13:37,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,440][root][INFO] - Training Epoch: 2/2, step 4727/7134 completed (loss: 0.20796501636505127, acc: 0.940397322177887)
[2024-12-17 03:13:37,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:37,801][root][INFO] - Training Epoch: 2/2, step 4728/7134 completed (loss: 0.1891394406557083, acc: 0.9536423683166504)
[2024-12-17 03:13:37,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,137][root][INFO] - Training Epoch: 2/2, step 4729/7134 completed (loss: 0.11055745929479599, acc: 0.9710982441902161)
[2024-12-17 03:13:38,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,515][root][INFO] - Training Epoch: 2/2, step 4730/7134 completed (loss: 0.165917307138443, acc: 0.9590643048286438)
[2024-12-17 03:13:38,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:38,894][root][INFO] - Training Epoch: 2/2, step 4731/7134 completed (loss: 0.3035307824611664, acc: 0.9379310607910156)
[2024-12-17 03:13:39,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:39,250][root][INFO] - Training Epoch: 2/2, step 4732/7134 completed (loss: 0.2019541710615158, acc: 0.9411764740943909)
[2024-12-17 03:13:39,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:39,631][root][INFO] - Training Epoch: 2/2, step 4733/7134 completed (loss: 0.21218568086624146, acc: 0.9492753744125366)
[2024-12-17 03:13:39,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:40,012][root][INFO] - Training Epoch: 2/2, step 4734/7134 completed (loss: 0.30451998114585876, acc: 0.9308176040649414)
[2024-12-17 03:13:40,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:40,394][root][INFO] - Training Epoch: 2/2, step 4735/7134 completed (loss: 0.16255052387714386, acc: 0.9685534834861755)
[2024-12-17 03:13:40,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:40,715][root][INFO] - Training Epoch: 2/2, step 4736/7134 completed (loss: 0.3277125656604767, acc: 0.9583333134651184)
[2024-12-17 03:13:40,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,097][root][INFO] - Training Epoch: 2/2, step 4737/7134 completed (loss: 0.20145006477832794, acc: 0.9448275566101074)
[2024-12-17 03:13:41,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,487][root][INFO] - Training Epoch: 2/2, step 4738/7134 completed (loss: 0.1951100081205368, acc: 0.9375)
[2024-12-17 03:13:41,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:41,864][root][INFO] - Training Epoch: 2/2, step 4739/7134 completed (loss: 0.4786030054092407, acc: 0.9044944047927856)
[2024-12-17 03:13:41,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:42,244][root][INFO] - Training Epoch: 2/2, step 4740/7134 completed (loss: 0.26213353872299194, acc: 0.9555555582046509)
[2024-12-17 03:13:42,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:42,638][root][INFO] - Training Epoch: 2/2, step 4741/7134 completed (loss: 0.21271157264709473, acc: 0.9571428298950195)
[2024-12-17 03:13:42,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,004][root][INFO] - Training Epoch: 2/2, step 4742/7134 completed (loss: 0.532450795173645, acc: 0.8787878751754761)
[2024-12-17 03:13:43,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,402][root][INFO] - Training Epoch: 2/2, step 4743/7134 completed (loss: 0.34260135889053345, acc: 0.9210526347160339)
[2024-12-17 03:13:43,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:43,739][root][INFO] - Training Epoch: 2/2, step 4744/7134 completed (loss: 0.15534700453281403, acc: 0.9449541568756104)
[2024-12-17 03:13:43,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,120][root][INFO] - Training Epoch: 2/2, step 4745/7134 completed (loss: 0.46428579092025757, acc: 0.9166666865348816)
[2024-12-17 03:13:44,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,495][root][INFO] - Training Epoch: 2/2, step 4746/7134 completed (loss: 0.16561658680438995, acc: 0.9689922332763672)
[2024-12-17 03:13:44,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:44,871][root][INFO] - Training Epoch: 2/2, step 4747/7134 completed (loss: 0.19080057740211487, acc: 0.9360465407371521)
[2024-12-17 03:13:44,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,226][root][INFO] - Training Epoch: 2/2, step 4748/7134 completed (loss: 0.3143298029899597, acc: 0.8994082808494568)
[2024-12-17 03:13:45,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,567][root][INFO] - Training Epoch: 2/2, step 4749/7134 completed (loss: 0.1428958624601364, acc: 0.9418604373931885)
[2024-12-17 03:13:45,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:45,918][root][INFO] - Training Epoch: 2/2, step 4750/7134 completed (loss: 0.23290032148361206, acc: 0.9593495726585388)
[2024-12-17 03:13:46,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:46,286][root][INFO] - Training Epoch: 2/2, step 4751/7134 completed (loss: 0.11087782680988312, acc: 0.9756097793579102)
[2024-12-17 03:13:46,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:46,641][root][INFO] - Training Epoch: 2/2, step 4752/7134 completed (loss: 0.2939663231372833, acc: 0.9378882050514221)
[2024-12-17 03:13:46,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,000][root][INFO] - Training Epoch: 2/2, step 4753/7134 completed (loss: 0.23522770404815674, acc: 0.9585798978805542)
[2024-12-17 03:13:47,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,384][root][INFO] - Training Epoch: 2/2, step 4754/7134 completed (loss: 0.07045315206050873, acc: 0.9870129823684692)
[2024-12-17 03:13:47,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:47,767][root][INFO] - Training Epoch: 2/2, step 4755/7134 completed (loss: 0.2444380670785904, acc: 0.9450549483299255)
[2024-12-17 03:13:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,115][root][INFO] - Training Epoch: 2/2, step 4756/7134 completed (loss: 0.19300255179405212, acc: 0.9435483813285828)
[2024-12-17 03:13:48,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,505][root][INFO] - Training Epoch: 2/2, step 4757/7134 completed (loss: 0.09281107038259506, acc: 0.9700000286102295)
[2024-12-17 03:13:48,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:48,894][root][INFO] - Training Epoch: 2/2, step 4758/7134 completed (loss: 0.10571657121181488, acc: 0.9779005646705627)
[2024-12-17 03:13:49,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,263][root][INFO] - Training Epoch: 2/2, step 4759/7134 completed (loss: 0.04449717700481415, acc: 0.9858155846595764)
[2024-12-17 03:13:49,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,617][root][INFO] - Training Epoch: 2/2, step 4760/7134 completed (loss: 0.14002388715744019, acc: 0.9495798349380493)
[2024-12-17 03:13:49,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:49,962][root][INFO] - Training Epoch: 2/2, step 4761/7134 completed (loss: 0.158485546708107, acc: 0.9634146094322205)
[2024-12-17 03:13:50,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:50,338][root][INFO] - Training Epoch: 2/2, step 4762/7134 completed (loss: 0.23988987505435944, acc: 0.9450549483299255)
[2024-12-17 03:13:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:50,714][root][INFO] - Training Epoch: 2/2, step 4763/7134 completed (loss: 0.15945744514465332, acc: 0.9470198750495911)
[2024-12-17 03:13:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,086][root][INFO] - Training Epoch: 2/2, step 4764/7134 completed (loss: 0.17841404676437378, acc: 0.969072163105011)
[2024-12-17 03:13:51,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,447][root][INFO] - Training Epoch: 2/2, step 4765/7134 completed (loss: 0.37065476179122925, acc: 0.9333333373069763)
[2024-12-17 03:13:51,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:51,820][root][INFO] - Training Epoch: 2/2, step 4766/7134 completed (loss: 0.15699180960655212, acc: 0.9722222089767456)
[2024-12-17 03:13:51,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,144][root][INFO] - Training Epoch: 2/2, step 4767/7134 completed (loss: 0.119915671646595, acc: 0.9795918464660645)
[2024-12-17 03:13:52,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,521][root][INFO] - Training Epoch: 2/2, step 4768/7134 completed (loss: 0.12297772616147995, acc: 0.9647058844566345)
[2024-12-17 03:13:52,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:52,866][root][INFO] - Training Epoch: 2/2, step 4769/7134 completed (loss: 0.18667641282081604, acc: 0.9473684430122375)
[2024-12-17 03:13:52,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,243][root][INFO] - Training Epoch: 2/2, step 4770/7134 completed (loss: 0.11897434294223785, acc: 0.9599999785423279)
[2024-12-17 03:13:53,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,618][root][INFO] - Training Epoch: 2/2, step 4771/7134 completed (loss: 0.2860964834690094, acc: 0.9263803958892822)
[2024-12-17 03:13:53,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:53,954][root][INFO] - Training Epoch: 2/2, step 4772/7134 completed (loss: 0.21971622109413147, acc: 0.9548386931419373)
[2024-12-17 03:13:54,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:54,283][root][INFO] - Training Epoch: 2/2, step 4773/7134 completed (loss: 0.1388646513223648, acc: 0.9615384340286255)
[2024-12-17 03:13:54,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:54,653][root][INFO] - Training Epoch: 2/2, step 4774/7134 completed (loss: 0.1475393921136856, acc: 0.9822485446929932)
[2024-12-17 03:13:54,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,018][root][INFO] - Training Epoch: 2/2, step 4775/7134 completed (loss: 0.24924084544181824, acc: 0.955974817276001)
[2024-12-17 03:13:55,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,399][root][INFO] - Training Epoch: 2/2, step 4776/7134 completed (loss: 0.28912192583084106, acc: 0.9366196990013123)
[2024-12-17 03:13:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:55,775][root][INFO] - Training Epoch: 2/2, step 4777/7134 completed (loss: 0.25912031531333923, acc: 0.9178082346916199)
[2024-12-17 03:13:55,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,134][root][INFO] - Training Epoch: 2/2, step 4778/7134 completed (loss: 0.11268726736307144, acc: 0.9642857313156128)
[2024-12-17 03:13:56,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,507][root][INFO] - Training Epoch: 2/2, step 4779/7134 completed (loss: 0.15804626047611237, acc: 0.9555555582046509)
[2024-12-17 03:13:56,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:56,869][root][INFO] - Training Epoch: 2/2, step 4780/7134 completed (loss: 0.05567425861954689, acc: 0.9743589758872986)
[2024-12-17 03:13:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:57,248][root][INFO] - Training Epoch: 2/2, step 4781/7134 completed (loss: 0.11234220862388611, acc: 0.9838709831237793)
[2024-12-17 03:13:57,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:57,628][root][INFO] - Training Epoch: 2/2, step 4782/7134 completed (loss: 0.13111069798469543, acc: 0.981249988079071)
[2024-12-17 03:13:57,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,020][root][INFO] - Training Epoch: 2/2, step 4783/7134 completed (loss: 0.2878091335296631, acc: 0.9275362491607666)
[2024-12-17 03:13:58,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,408][root][INFO] - Training Epoch: 2/2, step 4784/7134 completed (loss: 0.22464364767074585, acc: 0.949999988079071)
[2024-12-17 03:13:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:58,796][root][INFO] - Training Epoch: 2/2, step 4785/7134 completed (loss: 0.22501501441001892, acc: 0.9626865386962891)
[2024-12-17 03:13:58,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,166][root][INFO] - Training Epoch: 2/2, step 4786/7134 completed (loss: 0.09680283814668655, acc: 0.9567901492118835)
[2024-12-17 03:13:59,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,544][root][INFO] - Training Epoch: 2/2, step 4787/7134 completed (loss: 0.18949323892593384, acc: 0.9748427867889404)
[2024-12-17 03:13:59,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:13:59,926][root][INFO] - Training Epoch: 2/2, step 4788/7134 completed (loss: 0.04717447981238365, acc: 0.9923076629638672)
[2024-12-17 03:14:00,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:00,304][root][INFO] - Training Epoch: 2/2, step 4789/7134 completed (loss: 0.24084945023059845, acc: 0.942307710647583)
[2024-12-17 03:14:00,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:00,672][root][INFO] - Training Epoch: 2/2, step 4790/7134 completed (loss: 0.12578044831752777, acc: 0.9719101190567017)
[2024-12-17 03:14:00,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,021][root][INFO] - Training Epoch: 2/2, step 4791/7134 completed (loss: 0.06746545433998108, acc: 0.9776119589805603)
[2024-12-17 03:14:01,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,403][root][INFO] - Training Epoch: 2/2, step 4792/7134 completed (loss: 0.051411911845207214, acc: 0.9864864945411682)
[2024-12-17 03:14:01,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:01,732][root][INFO] - Training Epoch: 2/2, step 4793/7134 completed (loss: 0.21700944006443024, acc: 0.9473684430122375)
[2024-12-17 03:14:01,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,100][root][INFO] - Training Epoch: 2/2, step 4794/7134 completed (loss: 0.32159703969955444, acc: 0.9219858050346375)
[2024-12-17 03:14:02,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,495][root][INFO] - Training Epoch: 2/2, step 4795/7134 completed (loss: 0.11751195043325424, acc: 0.9754601120948792)
[2024-12-17 03:14:02,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:02,871][root][INFO] - Training Epoch: 2/2, step 4796/7134 completed (loss: 0.21663057804107666, acc: 0.9605262875556946)
[2024-12-17 03:14:02,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,219][root][INFO] - Training Epoch: 2/2, step 4797/7134 completed (loss: 0.0946793258190155, acc: 0.9726775884628296)
[2024-12-17 03:14:03,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,595][root][INFO] - Training Epoch: 2/2, step 4798/7134 completed (loss: 0.14916720986366272, acc: 0.976047933101654)
[2024-12-17 03:14:03,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:03,971][root][INFO] - Training Epoch: 2/2, step 4799/7134 completed (loss: 0.21418513357639313, acc: 0.9545454382896423)
[2024-12-17 03:14:04,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:04,346][root][INFO] - Training Epoch: 2/2, step 4800/7134 completed (loss: 0.1732597053050995, acc: 0.9605262875556946)
[2024-12-17 03:14:04,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:04,718][root][INFO] - Training Epoch: 2/2, step 4801/7134 completed (loss: 0.07944473624229431, acc: 0.9744898080825806)
[2024-12-17 03:14:04,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,111][root][INFO] - Training Epoch: 2/2, step 4802/7134 completed (loss: 0.225742906332016, acc: 0.9484536051750183)
[2024-12-17 03:14:05,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,487][root][INFO] - Training Epoch: 2/2, step 4803/7134 completed (loss: 0.17933326959609985, acc: 0.939393937587738)
[2024-12-17 03:14:05,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:05,858][root][INFO] - Training Epoch: 2/2, step 4804/7134 completed (loss: 0.2909480333328247, acc: 0.9277108311653137)
[2024-12-17 03:14:05,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,214][root][INFO] - Training Epoch: 2/2, step 4805/7134 completed (loss: 0.11955810338258743, acc: 0.9801324605941772)
[2024-12-17 03:14:06,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,622][root][INFO] - Training Epoch: 2/2, step 4806/7134 completed (loss: 0.1647564023733139, acc: 0.9510489702224731)
[2024-12-17 03:14:06,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:06,998][root][INFO] - Training Epoch: 2/2, step 4807/7134 completed (loss: 0.19190575182437897, acc: 0.9746835231781006)
[2024-12-17 03:14:07,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:07,364][root][INFO] - Training Epoch: 2/2, step 4808/7134 completed (loss: 0.18412137031555176, acc: 0.939393937587738)
[2024-12-17 03:14:07,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:07,737][root][INFO] - Training Epoch: 2/2, step 4809/7134 completed (loss: 0.14525192975997925, acc: 0.9448275566101074)
[2024-12-17 03:14:07,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,101][root][INFO] - Training Epoch: 2/2, step 4810/7134 completed (loss: 0.1930968314409256, acc: 0.9529411792755127)
[2024-12-17 03:14:08,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,446][root][INFO] - Training Epoch: 2/2, step 4811/7134 completed (loss: 0.14994995296001434, acc: 0.9754098653793335)
[2024-12-17 03:14:08,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:08,820][root][INFO] - Training Epoch: 2/2, step 4812/7134 completed (loss: 0.2579982578754425, acc: 0.9548022747039795)
[2024-12-17 03:14:08,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,190][root][INFO] - Training Epoch: 2/2, step 4813/7134 completed (loss: 0.06635866314172745, acc: 0.9791666865348816)
[2024-12-17 03:14:09,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,562][root][INFO] - Training Epoch: 2/2, step 4814/7134 completed (loss: 0.13224446773529053, acc: 0.945652186870575)
[2024-12-17 03:14:09,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:09,959][root][INFO] - Training Epoch: 2/2, step 4815/7134 completed (loss: 0.01263559889048338, acc: 1.0)
[2024-12-17 03:14:10,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:10,337][root][INFO] - Training Epoch: 2/2, step 4816/7134 completed (loss: 0.03957675024867058, acc: 0.9949748516082764)
[2024-12-17 03:14:10,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:10,673][root][INFO] - Training Epoch: 2/2, step 4817/7134 completed (loss: 0.0968102440237999, acc: 0.9797979593276978)
[2024-12-17 03:14:10,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,052][root][INFO] - Training Epoch: 2/2, step 4818/7134 completed (loss: 0.08316681534051895, acc: 0.9795918464660645)
[2024-12-17 03:14:11,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,406][root][INFO] - Training Epoch: 2/2, step 4819/7134 completed (loss: 0.06426818668842316, acc: 0.9833333492279053)
[2024-12-17 03:14:11,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:11,782][root][INFO] - Training Epoch: 2/2, step 4820/7134 completed (loss: 0.09945009648799896, acc: 0.9679144620895386)
[2024-12-17 03:14:11,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,157][root][INFO] - Training Epoch: 2/2, step 4821/7134 completed (loss: 0.10052184015512466, acc: 0.9768785834312439)
[2024-12-17 03:14:12,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,527][root][INFO] - Training Epoch: 2/2, step 4822/7134 completed (loss: 0.058836475014686584, acc: 0.9852941036224365)
[2024-12-17 03:14:12,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:12,894][root][INFO] - Training Epoch: 2/2, step 4823/7134 completed (loss: 0.18402749300003052, acc: 0.9496855139732361)
[2024-12-17 03:14:12,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:13,228][root][INFO] - Training Epoch: 2/2, step 4824/7134 completed (loss: 0.21038834750652313, acc: 0.9237288236618042)
[2024-12-17 03:14:13,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:13,634][root][INFO] - Training Epoch: 2/2, step 4825/7134 completed (loss: 0.08585048466920853, acc: 0.9779411554336548)
[2024-12-17 03:14:13,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:14,009][root][INFO] - Training Epoch: 2/2, step 4826/7134 completed (loss: 0.1171901524066925, acc: 0.9669421315193176)
[2024-12-17 03:14:14,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:14,389][root][INFO] - Training Epoch: 2/2, step 4827/7134 completed (loss: 0.2870940864086151, acc: 0.948387086391449)
[2024-12-17 03:14:14,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:14,762][root][INFO] - Training Epoch: 2/2, step 4828/7134 completed (loss: 0.09828363358974457, acc: 0.9591836929321289)
[2024-12-17 03:14:14,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,141][root][INFO] - Training Epoch: 2/2, step 4829/7134 completed (loss: 0.030299687758088112, acc: 0.9950494766235352)
[2024-12-17 03:14:15,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,526][root][INFO] - Training Epoch: 2/2, step 4830/7134 completed (loss: 0.04077209532260895, acc: 0.9939393997192383)
[2024-12-17 03:14:15,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:15,904][root][INFO] - Training Epoch: 2/2, step 4831/7134 completed (loss: 0.03490707650780678, acc: 0.9885714054107666)
[2024-12-17 03:14:16,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:16,269][root][INFO] - Training Epoch: 2/2, step 4832/7134 completed (loss: 0.03865823522210121, acc: 0.9934640526771545)
[2024-12-17 03:14:16,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:16,660][root][INFO] - Training Epoch: 2/2, step 4833/7134 completed (loss: 0.06387224793434143, acc: 0.9796954393386841)
[2024-12-17 03:14:16,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:17,020][root][INFO] - Training Epoch: 2/2, step 4834/7134 completed (loss: 0.09680823236703873, acc: 0.9720930457115173)
[2024-12-17 03:14:17,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:17,368][root][INFO] - Training Epoch: 2/2, step 4835/7134 completed (loss: 0.06492786109447479, acc: 0.9743589758872986)
[2024-12-17 03:14:17,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:17,753][root][INFO] - Training Epoch: 2/2, step 4836/7134 completed (loss: 0.07751993834972382, acc: 0.9876543283462524)
[2024-12-17 03:14:17,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,143][root][INFO] - Training Epoch: 2/2, step 4837/7134 completed (loss: 0.292430579662323, acc: 0.9357143044471741)
[2024-12-17 03:14:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,521][root][INFO] - Training Epoch: 2/2, step 4838/7134 completed (loss: 0.31791943311691284, acc: 0.935251772403717)
[2024-12-17 03:14:18,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:18,891][root][INFO] - Training Epoch: 2/2, step 4839/7134 completed (loss: 0.20205020904541016, acc: 0.9534883499145508)
[2024-12-17 03:14:19,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:19,270][root][INFO] - Training Epoch: 2/2, step 4840/7134 completed (loss: 0.15464216470718384, acc: 0.9671052694320679)
[2024-12-17 03:14:19,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:19,627][root][INFO] - Training Epoch: 2/2, step 4841/7134 completed (loss: 0.13473670184612274, acc: 0.9444444179534912)
[2024-12-17 03:14:19,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:20,001][root][INFO] - Training Epoch: 2/2, step 4842/7134 completed (loss: 0.1677238941192627, acc: 0.9555555582046509)
[2024-12-17 03:14:20,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:20,368][root][INFO] - Training Epoch: 2/2, step 4843/7134 completed (loss: 0.1984660029411316, acc: 0.9371069073677063)
[2024-12-17 03:14:20,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:20,724][root][INFO] - Training Epoch: 2/2, step 4844/7134 completed (loss: 0.13610441982746124, acc: 0.9461538195610046)
[2024-12-17 03:14:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,073][root][INFO] - Training Epoch: 2/2, step 4845/7134 completed (loss: 0.17123101651668549, acc: 0.956250011920929)
[2024-12-17 03:14:21,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,452][root][INFO] - Training Epoch: 2/2, step 4846/7134 completed (loss: 0.23427996039390564, acc: 0.9437500238418579)
[2024-12-17 03:14:21,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:21,813][root][INFO] - Training Epoch: 2/2, step 4847/7134 completed (loss: 0.13573606312274933, acc: 0.9644970297813416)
[2024-12-17 03:14:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,181][root][INFO] - Training Epoch: 2/2, step 4848/7134 completed (loss: 0.1466558277606964, acc: 0.9567901492118835)
[2024-12-17 03:14:22,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,548][root][INFO] - Training Epoch: 2/2, step 4849/7134 completed (loss: 0.08609289675951004, acc: 0.9931507110595703)
[2024-12-17 03:14:22,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:22,914][root][INFO] - Training Epoch: 2/2, step 4850/7134 completed (loss: 0.1889537125825882, acc: 0.9553072452545166)
[2024-12-17 03:14:23,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:23,279][root][INFO] - Training Epoch: 2/2, step 4851/7134 completed (loss: 0.21373693645000458, acc: 0.9513513445854187)
[2024-12-17 03:14:23,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:23,645][root][INFO] - Training Epoch: 2/2, step 4852/7134 completed (loss: 0.26654917001724243, acc: 0.9360465407371521)
[2024-12-17 03:14:23,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,012][root][INFO] - Training Epoch: 2/2, step 4853/7134 completed (loss: 0.4093855023384094, acc: 0.8982036113739014)
[2024-12-17 03:14:24,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,363][root][INFO] - Training Epoch: 2/2, step 4854/7134 completed (loss: 0.10260214656591415, acc: 0.9731543660163879)
[2024-12-17 03:14:24,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:24,726][root][INFO] - Training Epoch: 2/2, step 4855/7134 completed (loss: 0.14109940826892853, acc: 0.9655172228813171)
[2024-12-17 03:14:24,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,097][root][INFO] - Training Epoch: 2/2, step 4856/7134 completed (loss: 0.12551143765449524, acc: 0.9642857313156128)
[2024-12-17 03:14:25,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,454][root][INFO] - Training Epoch: 2/2, step 4857/7134 completed (loss: 0.11278645694255829, acc: 0.9629629850387573)
[2024-12-17 03:14:25,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:25,827][root][INFO] - Training Epoch: 2/2, step 4858/7134 completed (loss: 0.305500328540802, acc: 0.9382715821266174)
[2024-12-17 03:14:25,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,212][root][INFO] - Training Epoch: 2/2, step 4859/7134 completed (loss: 0.11258865892887115, acc: 0.976190447807312)
[2024-12-17 03:14:26,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,590][root][INFO] - Training Epoch: 2/2, step 4860/7134 completed (loss: 0.12082382291555405, acc: 0.9590643048286438)
[2024-12-17 03:14:26,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:26,958][root][INFO] - Training Epoch: 2/2, step 4861/7134 completed (loss: 0.13245712220668793, acc: 0.9704142212867737)
[2024-12-17 03:14:27,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:27,333][root][INFO] - Training Epoch: 2/2, step 4862/7134 completed (loss: 0.1371414065361023, acc: 0.9802631735801697)
[2024-12-17 03:14:27,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:27,709][root][INFO] - Training Epoch: 2/2, step 4863/7134 completed (loss: 0.179207444190979, acc: 0.9689922332763672)
[2024-12-17 03:14:27,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,087][root][INFO] - Training Epoch: 2/2, step 4864/7134 completed (loss: 0.11477566510438919, acc: 0.9745222926139832)
[2024-12-17 03:14:28,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,457][root][INFO] - Training Epoch: 2/2, step 4865/7134 completed (loss: 0.1991259902715683, acc: 0.9569892287254333)
[2024-12-17 03:14:28,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:28,830][root][INFO] - Training Epoch: 2/2, step 4866/7134 completed (loss: 0.12859438359737396, acc: 0.9651162624359131)
[2024-12-17 03:14:28,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:29,210][root][INFO] - Training Epoch: 2/2, step 4867/7134 completed (loss: 0.1980419009923935, acc: 0.9497206807136536)
[2024-12-17 03:14:29,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:29,569][root][INFO] - Training Epoch: 2/2, step 4868/7134 completed (loss: 0.13673198223114014, acc: 0.9579831957817078)
[2024-12-17 03:14:29,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:29,941][root][INFO] - Training Epoch: 2/2, step 4869/7134 completed (loss: 0.14977741241455078, acc: 0.9795918464660645)
[2024-12-17 03:14:30,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:30,363][root][INFO] - Training Epoch: 2/2, step 4870/7134 completed (loss: 0.07829462736845016, acc: 0.9891892075538635)
[2024-12-17 03:14:30,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:30,726][root][INFO] - Training Epoch: 2/2, step 4871/7134 completed (loss: 0.11401081085205078, acc: 0.9868420958518982)
[2024-12-17 03:14:30,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,093][root][INFO] - Training Epoch: 2/2, step 4872/7134 completed (loss: 0.04062714800238609, acc: 0.9940476417541504)
[2024-12-17 03:14:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,479][root][INFO] - Training Epoch: 2/2, step 4873/7134 completed (loss: 0.13524429500102997, acc: 0.9617486596107483)
[2024-12-17 03:14:31,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:31,841][root][INFO] - Training Epoch: 2/2, step 4874/7134 completed (loss: 0.13249194622039795, acc: 0.9756097793579102)
[2024-12-17 03:14:31,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,221][root][INFO] - Training Epoch: 2/2, step 4875/7134 completed (loss: 0.076276995241642, acc: 0.9875776171684265)
[2024-12-17 03:14:32,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,556][root][INFO] - Training Epoch: 2/2, step 4876/7134 completed (loss: 0.15963385999202728, acc: 0.9444444179534912)
[2024-12-17 03:14:32,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:32,925][root][INFO] - Training Epoch: 2/2, step 4877/7134 completed (loss: 0.1501019299030304, acc: 0.9743589758872986)
[2024-12-17 03:14:33,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:33,274][root][INFO] - Training Epoch: 2/2, step 4878/7134 completed (loss: 0.14947035908699036, acc: 0.9610389471054077)
[2024-12-17 03:14:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:33,657][root][INFO] - Training Epoch: 2/2, step 4879/7134 completed (loss: 0.09047500789165497, acc: 0.9743589758872986)
[2024-12-17 03:14:33,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,039][root][INFO] - Training Epoch: 2/2, step 4880/7134 completed (loss: 0.07583650946617126, acc: 0.9823529124259949)
[2024-12-17 03:14:34,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,424][root][INFO] - Training Epoch: 2/2, step 4881/7134 completed (loss: 0.2516555190086365, acc: 0.9530201554298401)
[2024-12-17 03:14:34,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:34,782][root][INFO] - Training Epoch: 2/2, step 4882/7134 completed (loss: 0.1132940873503685, acc: 0.9806451797485352)
[2024-12-17 03:14:34,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,169][root][INFO] - Training Epoch: 2/2, step 4883/7134 completed (loss: 0.12214453518390656, acc: 0.9666666388511658)
[2024-12-17 03:14:35,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,548][root][INFO] - Training Epoch: 2/2, step 4884/7134 completed (loss: 0.11598292738199234, acc: 0.9607843160629272)
[2024-12-17 03:14:35,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:35,933][root][INFO] - Training Epoch: 2/2, step 4885/7134 completed (loss: 0.06866054236888885, acc: 0.9892473220825195)
[2024-12-17 03:14:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:36,291][root][INFO] - Training Epoch: 2/2, step 4886/7134 completed (loss: 0.15992461144924164, acc: 0.9711538553237915)
[2024-12-17 03:14:36,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:36,676][root][INFO] - Training Epoch: 2/2, step 4887/7134 completed (loss: 0.08494817465543747, acc: 0.9790576100349426)
[2024-12-17 03:14:36,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,059][root][INFO] - Training Epoch: 2/2, step 4888/7134 completed (loss: 0.11540431529283524, acc: 0.9615384340286255)
[2024-12-17 03:14:37,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,460][root][INFO] - Training Epoch: 2/2, step 4889/7134 completed (loss: 0.035935960710048676, acc: 0.9893048405647278)
[2024-12-17 03:14:37,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:37,837][root][INFO] - Training Epoch: 2/2, step 4890/7134 completed (loss: 0.22486132383346558, acc: 0.9622641801834106)
[2024-12-17 03:14:37,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,226][root][INFO] - Training Epoch: 2/2, step 4891/7134 completed (loss: 0.10430908203125, acc: 0.9693877696990967)
[2024-12-17 03:14:38,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,606][root][INFO] - Training Epoch: 2/2, step 4892/7134 completed (loss: 0.13669168949127197, acc: 0.9545454382896423)
[2024-12-17 03:14:38,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:38,979][root][INFO] - Training Epoch: 2/2, step 4893/7134 completed (loss: 0.5511019229888916, acc: 0.8965517282485962)
[2024-12-17 03:14:39,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:39,358][root][INFO] - Training Epoch: 2/2, step 4894/7134 completed (loss: 0.07074388116598129, acc: 0.9941176176071167)
[2024-12-17 03:14:39,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:39,740][root][INFO] - Training Epoch: 2/2, step 4895/7134 completed (loss: 0.09895298629999161, acc: 0.9591836929321289)
[2024-12-17 03:14:39,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,094][root][INFO] - Training Epoch: 2/2, step 4896/7134 completed (loss: 0.1214844286441803, acc: 0.9832402467727661)
[2024-12-17 03:14:40,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,462][root][INFO] - Training Epoch: 2/2, step 4897/7134 completed (loss: 0.09158293157815933, acc: 0.9852216839790344)
[2024-12-17 03:14:40,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:40,839][root][INFO] - Training Epoch: 2/2, step 4898/7134 completed (loss: 0.10943558067083359, acc: 0.9569892287254333)
[2024-12-17 03:14:40,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,202][root][INFO] - Training Epoch: 2/2, step 4899/7134 completed (loss: 0.09338948875665665, acc: 0.9817073345184326)
[2024-12-17 03:14:41,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,578][root][INFO] - Training Epoch: 2/2, step 4900/7134 completed (loss: 0.11509529501199722, acc: 0.9893048405647278)
[2024-12-17 03:14:41,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:41,954][root][INFO] - Training Epoch: 2/2, step 4901/7134 completed (loss: 0.09992711991071701, acc: 0.9695122241973877)
[2024-12-17 03:14:42,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:42,340][root][INFO] - Training Epoch: 2/2, step 4902/7134 completed (loss: 0.05418582260608673, acc: 0.9743589758872986)
[2024-12-17 03:14:42,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:42,711][root][INFO] - Training Epoch: 2/2, step 4903/7134 completed (loss: 0.13513405621051788, acc: 0.970802903175354)
[2024-12-17 03:14:42,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,084][root][INFO] - Training Epoch: 2/2, step 4904/7134 completed (loss: 0.07135354727506638, acc: 0.9823529124259949)
[2024-12-17 03:14:43,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,479][root][INFO] - Training Epoch: 2/2, step 4905/7134 completed (loss: 0.027185916900634766, acc: 0.9934640526771545)
[2024-12-17 03:14:43,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:43,850][root][INFO] - Training Epoch: 2/2, step 4906/7134 completed (loss: 0.042190466076135635, acc: 0.9924812316894531)
[2024-12-17 03:14:43,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,209][root][INFO] - Training Epoch: 2/2, step 4907/7134 completed (loss: 0.06607735902070999, acc: 0.9931972622871399)
[2024-12-17 03:14:44,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,573][root][INFO] - Training Epoch: 2/2, step 4908/7134 completed (loss: 0.020298412069678307, acc: 1.0)
[2024-12-17 03:14:44,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:44,950][root][INFO] - Training Epoch: 2/2, step 4909/7134 completed (loss: 0.027043644338846207, acc: 0.9865771532058716)
[2024-12-17 03:14:45,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:45,340][root][INFO] - Training Epoch: 2/2, step 4910/7134 completed (loss: 0.12433881312608719, acc: 0.9612902998924255)
[2024-12-17 03:14:45,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:45,721][root][INFO] - Training Epoch: 2/2, step 4911/7134 completed (loss: 0.04725583642721176, acc: 0.9893048405647278)
[2024-12-17 03:14:45,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:46,077][root][INFO] - Training Epoch: 2/2, step 4912/7134 completed (loss: 0.04954851046204567, acc: 0.9900497794151306)
[2024-12-17 03:14:46,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:46,455][root][INFO] - Training Epoch: 2/2, step 4913/7134 completed (loss: 0.0803050622344017, acc: 0.9580419659614563)
[2024-12-17 03:14:46,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:46,821][root][INFO] - Training Epoch: 2/2, step 4914/7134 completed (loss: 0.07754378765821457, acc: 0.9741935729980469)
[2024-12-17 03:14:46,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,219][root][INFO] - Training Epoch: 2/2, step 4915/7134 completed (loss: 0.016440054401755333, acc: 1.0)
[2024-12-17 03:14:47,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,584][root][INFO] - Training Epoch: 2/2, step 4916/7134 completed (loss: 0.19706933200359344, acc: 0.95652174949646)
[2024-12-17 03:14:47,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:47,969][root][INFO] - Training Epoch: 2/2, step 4917/7134 completed (loss: 0.09524593502283096, acc: 0.9745222926139832)
[2024-12-17 03:14:48,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:48,303][root][INFO] - Training Epoch: 2/2, step 4918/7134 completed (loss: 0.029673628509044647, acc: 0.9938271641731262)
[2024-12-17 03:14:48,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:48,711][root][INFO] - Training Epoch: 2/2, step 4919/7134 completed (loss: 0.04203839972615242, acc: 1.0)
[2024-12-17 03:14:48,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,086][root][INFO] - Training Epoch: 2/2, step 4920/7134 completed (loss: 0.11758212000131607, acc: 0.9751552939414978)
[2024-12-17 03:14:49,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,442][root][INFO] - Training Epoch: 2/2, step 4921/7134 completed (loss: 0.1254761517047882, acc: 0.9635036587715149)
[2024-12-17 03:14:49,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:49,827][root][INFO] - Training Epoch: 2/2, step 4922/7134 completed (loss: 0.06691162288188934, acc: 0.9813664555549622)
[2024-12-17 03:14:49,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,209][root][INFO] - Training Epoch: 2/2, step 4923/7134 completed (loss: 0.06223315745592117, acc: 0.9855072498321533)
[2024-12-17 03:14:50,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,551][root][INFO] - Training Epoch: 2/2, step 4924/7134 completed (loss: 0.0980614423751831, acc: 0.9708737730979919)
[2024-12-17 03:14:50,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:50,930][root][INFO] - Training Epoch: 2/2, step 4925/7134 completed (loss: 0.1294129192829132, acc: 0.9731543660163879)
[2024-12-17 03:14:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,287][root][INFO] - Training Epoch: 2/2, step 4926/7134 completed (loss: 0.04450928047299385, acc: 0.9798657894134521)
[2024-12-17 03:14:51,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,642][root][INFO] - Training Epoch: 2/2, step 4927/7134 completed (loss: 0.0698874220252037, acc: 0.9870967864990234)
[2024-12-17 03:14:51,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:51,978][root][INFO] - Training Epoch: 2/2, step 4928/7134 completed (loss: 0.06397305428981781, acc: 0.9789473414421082)
[2024-12-17 03:14:52,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:52,372][root][INFO] - Training Epoch: 2/2, step 4929/7134 completed (loss: 0.045311737805604935, acc: 0.9934210777282715)
[2024-12-17 03:14:52,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:52,745][root][INFO] - Training Epoch: 2/2, step 4930/7134 completed (loss: 0.0940229743719101, acc: 0.9797297120094299)
[2024-12-17 03:14:52,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,113][root][INFO] - Training Epoch: 2/2, step 4931/7134 completed (loss: 0.12177092581987381, acc: 0.9509202241897583)
[2024-12-17 03:14:53,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,494][root][INFO] - Training Epoch: 2/2, step 4932/7134 completed (loss: 0.08192354440689087, acc: 0.9823529124259949)
[2024-12-17 03:14:53,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:53,855][root][INFO] - Training Epoch: 2/2, step 4933/7134 completed (loss: 0.1244182363152504, acc: 0.963350772857666)
[2024-12-17 03:14:53,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,227][root][INFO] - Training Epoch: 2/2, step 4934/7134 completed (loss: 0.062203310430049896, acc: 0.9764705896377563)
[2024-12-17 03:14:54,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,596][root][INFO] - Training Epoch: 2/2, step 4935/7134 completed (loss: 0.08760029077529907, acc: 0.970588207244873)
[2024-12-17 03:14:54,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:54,970][root][INFO] - Training Epoch: 2/2, step 4936/7134 completed (loss: 0.03627801686525345, acc: 0.9863945841789246)
[2024-12-17 03:14:55,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:55,338][root][INFO] - Training Epoch: 2/2, step 4937/7134 completed (loss: 0.10212825983762741, acc: 0.9650349617004395)
[2024-12-17 03:14:55,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:55,690][root][INFO] - Training Epoch: 2/2, step 4938/7134 completed (loss: 0.031640730798244476, acc: 0.9938271641731262)
[2024-12-17 03:14:55,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,060][root][INFO] - Training Epoch: 2/2, step 4939/7134 completed (loss: 0.05260525271296501, acc: 0.9928571581840515)
[2024-12-17 03:14:56,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,416][root][INFO] - Training Epoch: 2/2, step 4940/7134 completed (loss: 0.15164420008659363, acc: 0.961240291595459)
[2024-12-17 03:14:56,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:56,786][root][INFO] - Training Epoch: 2/2, step 4941/7134 completed (loss: 0.11809489876031876, acc: 0.976047933101654)
[2024-12-17 03:14:56,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,166][root][INFO] - Training Epoch: 2/2, step 4942/7134 completed (loss: 0.13873551785945892, acc: 0.9556962251663208)
[2024-12-17 03:14:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,513][root][INFO] - Training Epoch: 2/2, step 4943/7134 completed (loss: 0.1601804494857788, acc: 0.9624999761581421)
[2024-12-17 03:14:57,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:57,903][root][INFO] - Training Epoch: 2/2, step 4944/7134 completed (loss: 0.18294799327850342, acc: 0.9327731132507324)
[2024-12-17 03:14:58,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,270][root][INFO] - Training Epoch: 2/2, step 4945/7134 completed (loss: 0.1848953664302826, acc: 0.9469696879386902)
[2024-12-17 03:14:58,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,620][root][INFO] - Training Epoch: 2/2, step 4946/7134 completed (loss: 0.1321224570274353, acc: 0.96875)
[2024-12-17 03:14:58,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:58,991][root][INFO] - Training Epoch: 2/2, step 4947/7134 completed (loss: 0.1622752547264099, acc: 0.9652174115180969)
[2024-12-17 03:14:59,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:59,365][root][INFO] - Training Epoch: 2/2, step 4948/7134 completed (loss: 0.13810282945632935, acc: 0.9714285731315613)
[2024-12-17 03:14:59,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:14:59,763][root][INFO] - Training Epoch: 2/2, step 4949/7134 completed (loss: 0.1442403495311737, acc: 0.9753086566925049)
[2024-12-17 03:14:59,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,131][root][INFO] - Training Epoch: 2/2, step 4950/7134 completed (loss: 0.07348158955574036, acc: 0.9863945841789246)
[2024-12-17 03:15:00,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,511][root][INFO] - Training Epoch: 2/2, step 4951/7134 completed (loss: 0.2371082305908203, acc: 0.9213483333587646)
[2024-12-17 03:15:00,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:00,925][root][INFO] - Training Epoch: 2/2, step 4952/7134 completed (loss: 0.1288771629333496, acc: 0.9662162065505981)
[2024-12-17 03:15:01,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:01,270][root][INFO] - Training Epoch: 2/2, step 4953/7134 completed (loss: 0.1538187861442566, acc: 0.9459459185600281)
[2024-12-17 03:15:01,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:01,649][root][INFO] - Training Epoch: 2/2, step 4954/7134 completed (loss: 0.11976984888315201, acc: 0.9489796161651611)
[2024-12-17 03:15:01,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,015][root][INFO] - Training Epoch: 2/2, step 4955/7134 completed (loss: 0.18504981696605682, acc: 0.9270833134651184)
[2024-12-17 03:15:02,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,382][root][INFO] - Training Epoch: 2/2, step 4956/7134 completed (loss: 0.17068970203399658, acc: 0.9588235020637512)
[2024-12-17 03:15:02,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:02,763][root][INFO] - Training Epoch: 2/2, step 4957/7134 completed (loss: 0.2054593563079834, acc: 0.957446813583374)
[2024-12-17 03:15:02,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,122][root][INFO] - Training Epoch: 2/2, step 4958/7134 completed (loss: 0.11171568930149078, acc: 0.9748427867889404)
[2024-12-17 03:15:03,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,502][root][INFO] - Training Epoch: 2/2, step 4959/7134 completed (loss: 0.12163541465997696, acc: 0.9759036302566528)
[2024-12-17 03:15:03,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:03,874][root][INFO] - Training Epoch: 2/2, step 4960/7134 completed (loss: 0.18508777022361755, acc: 0.9632353186607361)
[2024-12-17 03:15:04,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:04,267][root][INFO] - Training Epoch: 2/2, step 4961/7134 completed (loss: 0.18518993258476257, acc: 0.9375)
[2024-12-17 03:15:04,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:04,639][root][INFO] - Training Epoch: 2/2, step 4962/7134 completed (loss: 0.10545888543128967, acc: 0.9695122241973877)
[2024-12-17 03:15:04,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,000][root][INFO] - Training Epoch: 2/2, step 4963/7134 completed (loss: 0.12635642290115356, acc: 0.9741935729980469)
[2024-12-17 03:15:05,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,368][root][INFO] - Training Epoch: 2/2, step 4964/7134 completed (loss: 0.19861304759979248, acc: 0.9496402740478516)
[2024-12-17 03:15:05,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:05,728][root][INFO] - Training Epoch: 2/2, step 4965/7134 completed (loss: 0.03147287294268608, acc: 1.0)
[2024-12-17 03:15:05,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,067][root][INFO] - Training Epoch: 2/2, step 4966/7134 completed (loss: 0.23218435049057007, acc: 0.9560439586639404)
[2024-12-17 03:15:06,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,426][root][INFO] - Training Epoch: 2/2, step 4967/7134 completed (loss: 0.11548062413930893, acc: 0.9844961166381836)
[2024-12-17 03:15:06,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:06,811][root][INFO] - Training Epoch: 2/2, step 4968/7134 completed (loss: 0.3361870348453522, acc: 0.8865247964859009)
[2024-12-17 03:15:06,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,211][root][INFO] - Training Epoch: 2/2, step 4969/7134 completed (loss: 0.16034771502017975, acc: 0.9655172228813171)
[2024-12-17 03:15:07,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,594][root][INFO] - Training Epoch: 2/2, step 4970/7134 completed (loss: 0.0935763567686081, acc: 0.9724137783050537)
[2024-12-17 03:15:07,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:07,977][root][INFO] - Training Epoch: 2/2, step 4971/7134 completed (loss: 0.06007036566734314, acc: 0.9801324605941772)
[2024-12-17 03:15:08,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:08,385][root][INFO] - Training Epoch: 2/2, step 4972/7134 completed (loss: 0.19271868467330933, acc: 0.925000011920929)
[2024-12-17 03:15:08,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:08,762][root][INFO] - Training Epoch: 2/2, step 4973/7134 completed (loss: 0.09637296944856644, acc: 0.9696969985961914)
[2024-12-17 03:15:08,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,146][root][INFO] - Training Epoch: 2/2, step 4974/7134 completed (loss: 0.16902898252010345, acc: 0.9469696879386902)
[2024-12-17 03:15:09,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,525][root][INFO] - Training Epoch: 2/2, step 4975/7134 completed (loss: 0.3503740131855011, acc: 0.931034505367279)
[2024-12-17 03:15:09,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:09,861][root][INFO] - Training Epoch: 2/2, step 4976/7134 completed (loss: 0.2865521013736725, acc: 0.9368420839309692)
[2024-12-17 03:15:09,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,219][root][INFO] - Training Epoch: 2/2, step 4977/7134 completed (loss: 0.30103299021720886, acc: 0.9417475461959839)
[2024-12-17 03:15:10,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,608][root][INFO] - Training Epoch: 2/2, step 4978/7134 completed (loss: 0.06495033949613571, acc: 0.982758641242981)
[2024-12-17 03:15:10,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:10,970][root][INFO] - Training Epoch: 2/2, step 4979/7134 completed (loss: 0.280607134103775, acc: 0.9370629191398621)
[2024-12-17 03:15:11,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:11,368][root][INFO] - Training Epoch: 2/2, step 4980/7134 completed (loss: 0.293362557888031, acc: 0.9428571462631226)
[2024-12-17 03:15:11,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:11,762][root][INFO] - Training Epoch: 2/2, step 4981/7134 completed (loss: 0.15179604291915894, acc: 0.949999988079071)
[2024-12-17 03:15:11,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,136][root][INFO] - Training Epoch: 2/2, step 4982/7134 completed (loss: 0.1878204047679901, acc: 0.9459459185600281)
[2024-12-17 03:15:12,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,577][root][INFO] - Training Epoch: 2/2, step 4983/7134 completed (loss: 0.12418702989816666, acc: 0.9784172773361206)
[2024-12-17 03:15:12,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:12,980][root][INFO] - Training Epoch: 2/2, step 4984/7134 completed (loss: 0.2180231511592865, acc: 0.9811320900917053)
[2024-12-17 03:15:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:13,326][root][INFO] - Training Epoch: 2/2, step 4985/7134 completed (loss: 0.12337854504585266, acc: 0.9594594836235046)
[2024-12-17 03:15:13,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:13,725][root][INFO] - Training Epoch: 2/2, step 4986/7134 completed (loss: 0.11599262058734894, acc: 0.9860140085220337)
[2024-12-17 03:15:13,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,092][root][INFO] - Training Epoch: 2/2, step 4987/7134 completed (loss: 0.07431589066982269, acc: 0.9905660152435303)
[2024-12-17 03:15:14,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,453][root][INFO] - Training Epoch: 2/2, step 4988/7134 completed (loss: 0.05874473601579666, acc: 0.982758641242981)
[2024-12-17 03:15:14,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:14,845][root][INFO] - Training Epoch: 2/2, step 4989/7134 completed (loss: 0.07417204231023788, acc: 0.9882352948188782)
[2024-12-17 03:15:14,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,219][root][INFO] - Training Epoch: 2/2, step 4990/7134 completed (loss: 0.05290684849023819, acc: 0.9829059839248657)
[2024-12-17 03:15:15,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,582][root][INFO] - Training Epoch: 2/2, step 4991/7134 completed (loss: 0.09045720100402832, acc: 0.9774436354637146)
[2024-12-17 03:15:15,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:15,988][root][INFO] - Training Epoch: 2/2, step 4992/7134 completed (loss: 0.10576106607913971, acc: 0.9741379022598267)
[2024-12-17 03:15:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:16,327][root][INFO] - Training Epoch: 2/2, step 4993/7134 completed (loss: 0.05655688792467117, acc: 1.0)
[2024-12-17 03:15:16,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:16,714][root][INFO] - Training Epoch: 2/2, step 4994/7134 completed (loss: 0.10547981411218643, acc: 0.9735099077224731)
[2024-12-17 03:15:16,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,137][root][INFO] - Training Epoch: 2/2, step 4995/7134 completed (loss: 0.15281635522842407, acc: 0.9629629850387573)
[2024-12-17 03:15:17,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,520][root][INFO] - Training Epoch: 2/2, step 4996/7134 completed (loss: 0.06299890577793121, acc: 0.9833333492279053)
[2024-12-17 03:15:17,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:17,962][root][INFO] - Training Epoch: 2/2, step 4997/7134 completed (loss: 0.08400054275989532, acc: 0.9694656729698181)
[2024-12-17 03:15:18,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:18,318][root][INFO] - Training Epoch: 2/2, step 4998/7134 completed (loss: 0.14349427819252014, acc: 0.9733333587646484)
[2024-12-17 03:15:18,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:18,671][root][INFO] - Training Epoch: 2/2, step 4999/7134 completed (loss: 0.12905000150203705, acc: 0.960629940032959)
[2024-12-17 03:15:18,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,043][root][INFO] - Training Epoch: 2/2, step 5000/7134 completed (loss: 0.1049417108297348, acc: 0.969072163105011)
[2024-12-17 03:15:19,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,415][root][INFO] - Training Epoch: 2/2, step 5001/7134 completed (loss: 0.25524231791496277, acc: 0.9591836929321289)
[2024-12-17 03:15:19,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:19,815][root][INFO] - Training Epoch: 2/2, step 5002/7134 completed (loss: 0.10610894113779068, acc: 0.982300877571106)
[2024-12-17 03:15:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,169][root][INFO] - Training Epoch: 2/2, step 5003/7134 completed (loss: 0.061743784695863724, acc: 0.9925925731658936)
[2024-12-17 03:15:20,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,542][root][INFO] - Training Epoch: 2/2, step 5004/7134 completed (loss: 0.026775607839226723, acc: 0.9906542301177979)
[2024-12-17 03:15:20,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:20,917][root][INFO] - Training Epoch: 2/2, step 5005/7134 completed (loss: 0.14126072824001312, acc: 0.9890109896659851)
[2024-12-17 03:15:21,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:21,257][root][INFO] - Training Epoch: 2/2, step 5006/7134 completed (loss: 0.0855841189622879, acc: 0.9802631735801697)
[2024-12-17 03:15:21,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:21,625][root][INFO] - Training Epoch: 2/2, step 5007/7134 completed (loss: 0.11964631825685501, acc: 0.9753086566925049)
[2024-12-17 03:15:21,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,037][root][INFO] - Training Epoch: 2/2, step 5008/7134 completed (loss: 0.21255633234977722, acc: 0.9666666388511658)
[2024-12-17 03:15:22,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,413][root][INFO] - Training Epoch: 2/2, step 5009/7134 completed (loss: 0.30796006321907043, acc: 0.9175257682800293)
[2024-12-17 03:15:22,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:22,824][root][INFO] - Training Epoch: 2/2, step 5010/7134 completed (loss: 0.12566295266151428, acc: 0.9658119678497314)
[2024-12-17 03:15:22,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,214][root][INFO] - Training Epoch: 2/2, step 5011/7134 completed (loss: 0.10764078795909882, acc: 0.9724137783050537)
[2024-12-17 03:15:23,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,557][root][INFO] - Training Epoch: 2/2, step 5012/7134 completed (loss: 0.041653960943222046, acc: 0.987500011920929)
[2024-12-17 03:15:23,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:23,898][root][INFO] - Training Epoch: 2/2, step 5013/7134 completed (loss: 0.068058542907238, acc: 0.9914529919624329)
[2024-12-17 03:15:23,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:24,278][root][INFO] - Training Epoch: 2/2, step 5014/7134 completed (loss: 0.10878901928663254, acc: 0.9807692170143127)
[2024-12-17 03:15:24,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:24,648][root][INFO] - Training Epoch: 2/2, step 5015/7134 completed (loss: 0.25480592250823975, acc: 0.9570552110671997)
[2024-12-17 03:15:24,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,045][root][INFO] - Training Epoch: 2/2, step 5016/7134 completed (loss: 0.28147396445274353, acc: 0.9465649127960205)
[2024-12-17 03:15:25,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,423][root][INFO] - Training Epoch: 2/2, step 5017/7134 completed (loss: 0.12457790970802307, acc: 0.9696969985961914)
[2024-12-17 03:15:25,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:25,823][root][INFO] - Training Epoch: 2/2, step 5018/7134 completed (loss: 0.16701717674732208, acc: 0.9548872113227844)
[2024-12-17 03:15:25,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,199][root][INFO] - Training Epoch: 2/2, step 5019/7134 completed (loss: 0.3716726005077362, acc: 0.9209039807319641)
[2024-12-17 03:15:26,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,571][root][INFO] - Training Epoch: 2/2, step 5020/7134 completed (loss: 0.2976265549659729, acc: 0.920634925365448)
[2024-12-17 03:15:26,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:26,939][root][INFO] - Training Epoch: 2/2, step 5021/7134 completed (loss: 0.10042320191860199, acc: 0.9904761910438538)
[2024-12-17 03:15:27,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:27,325][root][INFO] - Training Epoch: 2/2, step 5022/7134 completed (loss: 0.07964031398296356, acc: 0.9927536249160767)
[2024-12-17 03:15:27,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:27,674][root][INFO] - Training Epoch: 2/2, step 5023/7134 completed (loss: 0.0943555235862732, acc: 0.9741935729980469)
[2024-12-17 03:15:27,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,072][root][INFO] - Training Epoch: 2/2, step 5024/7134 completed (loss: 0.05901231989264488, acc: 0.9879518151283264)
[2024-12-17 03:15:28,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,489][root][INFO] - Training Epoch: 2/2, step 5025/7134 completed (loss: 0.12014696002006531, acc: 0.9846153855323792)
[2024-12-17 03:15:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:28,850][root][INFO] - Training Epoch: 2/2, step 5026/7134 completed (loss: 0.14322058856487274, acc: 0.9618320465087891)
[2024-12-17 03:15:28,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:29,213][root][INFO] - Training Epoch: 2/2, step 5027/7134 completed (loss: 0.10166749358177185, acc: 0.9767441749572754)
[2024-12-17 03:15:29,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:29,606][root][INFO] - Training Epoch: 2/2, step 5028/7134 completed (loss: 0.11199606955051422, acc: 0.9718309640884399)
[2024-12-17 03:15:29,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,009][root][INFO] - Training Epoch: 2/2, step 5029/7134 completed (loss: 0.1072525605559349, acc: 0.9923076629638672)
[2024-12-17 03:15:30,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,402][root][INFO] - Training Epoch: 2/2, step 5030/7134 completed (loss: 0.07803353667259216, acc: 0.9820359349250793)
[2024-12-17 03:15:30,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:30,862][root][INFO] - Training Epoch: 2/2, step 5031/7134 completed (loss: 0.3168926537036896, acc: 0.9347826242446899)
[2024-12-17 03:15:30,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:31,247][root][INFO] - Training Epoch: 2/2, step 5032/7134 completed (loss: 0.10825453698635101, acc: 0.9788732528686523)
[2024-12-17 03:15:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:31,689][root][INFO] - Training Epoch: 2/2, step 5033/7134 completed (loss: 0.11081374436616898, acc: 0.9718309640884399)
[2024-12-17 03:15:31,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,097][root][INFO] - Training Epoch: 2/2, step 5034/7134 completed (loss: 0.051420584321022034, acc: 0.9849624037742615)
[2024-12-17 03:15:32,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,469][root][INFO] - Training Epoch: 2/2, step 5035/7134 completed (loss: 0.017101308330893517, acc: 1.0)
[2024-12-17 03:15:32,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:32,854][root][INFO] - Training Epoch: 2/2, step 5036/7134 completed (loss: 0.2493729442358017, acc: 0.9519230723381042)
[2024-12-17 03:15:32,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:33,237][root][INFO] - Training Epoch: 2/2, step 5037/7134 completed (loss: 0.09866224229335785, acc: 0.9823529124259949)
[2024-12-17 03:15:33,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:33,709][root][INFO] - Training Epoch: 2/2, step 5038/7134 completed (loss: 0.4159752428531647, acc: 0.895652174949646)
[2024-12-17 03:15:33,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,109][root][INFO] - Training Epoch: 2/2, step 5039/7134 completed (loss: 0.08417773991823196, acc: 0.978723406791687)
[2024-12-17 03:15:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,512][root][INFO] - Training Epoch: 2/2, step 5040/7134 completed (loss: 0.10148387402296066, acc: 0.9833333492279053)
[2024-12-17 03:15:34,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:34,873][root][INFO] - Training Epoch: 2/2, step 5041/7134 completed (loss: 0.027022825554013252, acc: 1.0)
[2024-12-17 03:15:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:35,290][root][INFO] - Training Epoch: 2/2, step 5042/7134 completed (loss: 0.22293786704540253, acc: 0.9708737730979919)
[2024-12-17 03:15:35,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:35,645][root][INFO] - Training Epoch: 2/2, step 5043/7134 completed (loss: 0.12931467592716217, acc: 0.9469026327133179)
[2024-12-17 03:15:35,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,040][root][INFO] - Training Epoch: 2/2, step 5044/7134 completed (loss: 0.09580298513174057, acc: 0.9745222926139832)
[2024-12-17 03:15:36,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,439][root][INFO] - Training Epoch: 2/2, step 5045/7134 completed (loss: 0.12362963706254959, acc: 0.9675675630569458)
[2024-12-17 03:15:36,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:36,831][root][INFO] - Training Epoch: 2/2, step 5046/7134 completed (loss: 0.28294000029563904, acc: 0.9354838728904724)
[2024-12-17 03:15:36,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,208][root][INFO] - Training Epoch: 2/2, step 5047/7134 completed (loss: 0.294137179851532, acc: 0.9270073175430298)
[2024-12-17 03:15:37,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,571][root][INFO] - Training Epoch: 2/2, step 5048/7134 completed (loss: 0.14505451917648315, acc: 0.9785714149475098)
[2024-12-17 03:15:37,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:37,919][root][INFO] - Training Epoch: 2/2, step 5049/7134 completed (loss: 0.193033367395401, acc: 0.9554139971733093)
[2024-12-17 03:15:38,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:38,288][root][INFO] - Training Epoch: 2/2, step 5050/7134 completed (loss: 0.23000779747962952, acc: 0.96875)
[2024-12-17 03:15:38,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:38,657][root][INFO] - Training Epoch: 2/2, step 5051/7134 completed (loss: 0.22696569561958313, acc: 0.9455782175064087)
[2024-12-17 03:15:38,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,018][root][INFO] - Training Epoch: 2/2, step 5052/7134 completed (loss: 0.17246899008750916, acc: 0.9615384340286255)
[2024-12-17 03:15:39,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,377][root][INFO] - Training Epoch: 2/2, step 5053/7134 completed (loss: 0.29208770394325256, acc: 0.9333333373069763)
[2024-12-17 03:15:39,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:39,754][root][INFO] - Training Epoch: 2/2, step 5054/7134 completed (loss: 0.25698384642601013, acc: 0.9407407641410828)
[2024-12-17 03:15:39,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,101][root][INFO] - Training Epoch: 2/2, step 5055/7134 completed (loss: 0.21298281848430634, acc: 0.9557521939277649)
[2024-12-17 03:15:40,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,456][root][INFO] - Training Epoch: 2/2, step 5056/7134 completed (loss: 0.21370135247707367, acc: 0.9328858852386475)
[2024-12-17 03:15:40,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:40,821][root][INFO] - Training Epoch: 2/2, step 5057/7134 completed (loss: 0.2859192192554474, acc: 0.9490445852279663)
[2024-12-17 03:15:40,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,182][root][INFO] - Training Epoch: 2/2, step 5058/7134 completed (loss: 0.26706844568252563, acc: 0.9451219439506531)
[2024-12-17 03:15:41,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,551][root][INFO] - Training Epoch: 2/2, step 5059/7134 completed (loss: 0.15040706098079681, acc: 0.946107804775238)
[2024-12-17 03:15:41,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:41,910][root][INFO] - Training Epoch: 2/2, step 5060/7134 completed (loss: 0.14273466169834137, acc: 0.9733333587646484)
[2024-12-17 03:15:42,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,245][root][INFO] - Training Epoch: 2/2, step 5061/7134 completed (loss: 0.3000156879425049, acc: 0.9238095283508301)
[2024-12-17 03:15:42,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,614][root][INFO] - Training Epoch: 2/2, step 5062/7134 completed (loss: 0.09685061872005463, acc: 0.9629629850387573)
[2024-12-17 03:15:42,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:42,981][root][INFO] - Training Epoch: 2/2, step 5063/7134 completed (loss: 0.1708281934261322, acc: 0.9580419659614563)
[2024-12-17 03:15:43,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:43,328][root][INFO] - Training Epoch: 2/2, step 5064/7134 completed (loss: 0.105894073843956, acc: 0.9714285731315613)
[2024-12-17 03:15:43,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:43,702][root][INFO] - Training Epoch: 2/2, step 5065/7134 completed (loss: 0.18446360528469086, acc: 0.9622641801834106)
[2024-12-17 03:15:43,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,038][root][INFO] - Training Epoch: 2/2, step 5066/7134 completed (loss: 0.19437441229820251, acc: 0.9448275566101074)
[2024-12-17 03:15:44,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,401][root][INFO] - Training Epoch: 2/2, step 5067/7134 completed (loss: 0.09516018629074097, acc: 0.9754098653793335)
[2024-12-17 03:15:44,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:44,766][root][INFO] - Training Epoch: 2/2, step 5068/7134 completed (loss: 0.20642130076885223, acc: 0.9366196990013123)
[2024-12-17 03:15:44,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,139][root][INFO] - Training Epoch: 2/2, step 5069/7134 completed (loss: 0.06777393817901611, acc: 0.9662162065505981)
[2024-12-17 03:15:45,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,494][root][INFO] - Training Epoch: 2/2, step 5070/7134 completed (loss: 0.03336171805858612, acc: 1.0)
[2024-12-17 03:15:45,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:45,847][root][INFO] - Training Epoch: 2/2, step 5071/7134 completed (loss: 0.17278407514095306, acc: 0.9588235020637512)
[2024-12-17 03:15:45,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,214][root][INFO] - Training Epoch: 2/2, step 5072/7134 completed (loss: 0.2636730968952179, acc: 0.9505494236946106)
[2024-12-17 03:15:46,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,583][root][INFO] - Training Epoch: 2/2, step 5073/7134 completed (loss: 0.21509908139705658, acc: 0.9236640930175781)
[2024-12-17 03:15:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:46,974][root][INFO] - Training Epoch: 2/2, step 5074/7134 completed (loss: 0.17302776873111725, acc: 0.961240291595459)
[2024-12-17 03:15:47,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:47,329][root][INFO] - Training Epoch: 2/2, step 5075/7134 completed (loss: 0.21096913516521454, acc: 0.947826087474823)
[2024-12-17 03:15:47,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:47,731][root][INFO] - Training Epoch: 2/2, step 5076/7134 completed (loss: 0.17190688848495483, acc: 0.9462365508079529)
[2024-12-17 03:15:47,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,106][root][INFO] - Training Epoch: 2/2, step 5077/7134 completed (loss: 0.12474748492240906, acc: 0.9632353186607361)
[2024-12-17 03:15:48,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,460][root][INFO] - Training Epoch: 2/2, step 5078/7134 completed (loss: 0.3244149386882782, acc: 0.9416666626930237)
[2024-12-17 03:15:48,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:48,818][root][INFO] - Training Epoch: 2/2, step 5079/7134 completed (loss: 0.14791239798069, acc: 0.9666666388511658)
[2024-12-17 03:15:48,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,213][root][INFO] - Training Epoch: 2/2, step 5080/7134 completed (loss: 0.07418704032897949, acc: 0.9803921580314636)
[2024-12-17 03:15:49,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,574][root][INFO] - Training Epoch: 2/2, step 5081/7134 completed (loss: 0.07747812569141388, acc: 0.9768785834312439)
[2024-12-17 03:15:49,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:49,970][root][INFO] - Training Epoch: 2/2, step 5082/7134 completed (loss: 0.1690828800201416, acc: 0.9724137783050537)
[2024-12-17 03:15:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:50,362][root][INFO] - Training Epoch: 2/2, step 5083/7134 completed (loss: 0.19893932342529297, acc: 0.9585798978805542)
[2024-12-17 03:15:50,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:50,749][root][INFO] - Training Epoch: 2/2, step 5084/7134 completed (loss: 0.10278730094432831, acc: 0.9603960514068604)
[2024-12-17 03:15:50,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,153][root][INFO] - Training Epoch: 2/2, step 5085/7134 completed (loss: 0.11510255187749863, acc: 0.969072163105011)
[2024-12-17 03:15:51,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,537][root][INFO] - Training Epoch: 2/2, step 5086/7134 completed (loss: 0.11474568396806717, acc: 0.9723756909370422)
[2024-12-17 03:15:51,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:51,936][root][INFO] - Training Epoch: 2/2, step 5087/7134 completed (loss: 0.06597654521465302, acc: 0.9783783555030823)
[2024-12-17 03:15:52,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:52,343][root][INFO] - Training Epoch: 2/2, step 5088/7134 completed (loss: 0.03210732340812683, acc: 0.9940828680992126)
[2024-12-17 03:15:52,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:52,711][root][INFO] - Training Epoch: 2/2, step 5089/7134 completed (loss: 0.10060320049524307, acc: 0.9744898080825806)
[2024-12-17 03:15:52,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,081][root][INFO] - Training Epoch: 2/2, step 5090/7134 completed (loss: 0.03257489949464798, acc: 0.9902912378311157)
[2024-12-17 03:15:53,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,474][root][INFO] - Training Epoch: 2/2, step 5091/7134 completed (loss: 0.13376538455486298, acc: 0.9615384340286255)
[2024-12-17 03:15:53,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:53,861][root][INFO] - Training Epoch: 2/2, step 5092/7134 completed (loss: 0.11143579334020615, acc: 0.9836956262588501)
[2024-12-17 03:15:53,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,232][root][INFO] - Training Epoch: 2/2, step 5093/7134 completed (loss: 0.11037742346525192, acc: 0.9659090638160706)
[2024-12-17 03:15:54,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,614][root][INFO] - Training Epoch: 2/2, step 5094/7134 completed (loss: 0.13885197043418884, acc: 0.9769230484962463)
[2024-12-17 03:15:54,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:54,966][root][INFO] - Training Epoch: 2/2, step 5095/7134 completed (loss: 0.19998371601104736, acc: 0.9426751732826233)
[2024-12-17 03:15:55,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:55,363][root][INFO] - Training Epoch: 2/2, step 5096/7134 completed (loss: 0.11197937279939651, acc: 0.9627659320831299)
[2024-12-17 03:15:55,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:55,736][root][INFO] - Training Epoch: 2/2, step 5097/7134 completed (loss: 0.07014475017786026, acc: 0.9839572310447693)
[2024-12-17 03:15:55,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,110][root][INFO] - Training Epoch: 2/2, step 5098/7134 completed (loss: 0.16667813062667847, acc: 0.9438775777816772)
[2024-12-17 03:15:56,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,466][root][INFO] - Training Epoch: 2/2, step 5099/7134 completed (loss: 0.10148190706968307, acc: 0.9682539701461792)
[2024-12-17 03:15:56,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:56,894][root][INFO] - Training Epoch: 2/2, step 5100/7134 completed (loss: 0.14455333352088928, acc: 0.9607843160629272)
[2024-12-17 03:15:57,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:57,265][root][INFO] - Training Epoch: 2/2, step 5101/7134 completed (loss: 0.051757220178842545, acc: 0.9842932224273682)
[2024-12-17 03:15:57,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:57,629][root][INFO] - Training Epoch: 2/2, step 5102/7134 completed (loss: 0.12959058582782745, acc: 0.9695122241973877)
[2024-12-17 03:15:57,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,038][root][INFO] - Training Epoch: 2/2, step 5103/7134 completed (loss: 0.08707615733146667, acc: 0.9714285731315613)
[2024-12-17 03:15:58,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,425][root][INFO] - Training Epoch: 2/2, step 5104/7134 completed (loss: 0.08467306941747665, acc: 0.9736841917037964)
[2024-12-17 03:15:58,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:58,780][root][INFO] - Training Epoch: 2/2, step 5105/7134 completed (loss: 0.14338764548301697, acc: 0.9668874144554138)
[2024-12-17 03:15:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,178][root][INFO] - Training Epoch: 2/2, step 5106/7134 completed (loss: 0.21748760342597961, acc: 0.9589040875434875)
[2024-12-17 03:15:59,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,615][root][INFO] - Training Epoch: 2/2, step 5107/7134 completed (loss: 0.2852439880371094, acc: 0.9455782175064087)
[2024-12-17 03:15:59,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:15:59,997][root][INFO] - Training Epoch: 2/2, step 5108/7134 completed (loss: 0.5081996321678162, acc: 0.8652482032775879)
[2024-12-17 03:16:00,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:00,403][root][INFO] - Training Epoch: 2/2, step 5109/7134 completed (loss: 0.3905014395713806, acc: 0.9195979833602905)
[2024-12-17 03:16:00,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:00,804][root][INFO] - Training Epoch: 2/2, step 5110/7134 completed (loss: 0.23699410259723663, acc: 0.9395604133605957)
[2024-12-17 03:16:00,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:01,223][root][INFO] - Training Epoch: 2/2, step 5111/7134 completed (loss: 0.17404881119728088, acc: 0.9482758641242981)
[2024-12-17 03:16:01,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:01,640][root][INFO] - Training Epoch: 2/2, step 5112/7134 completed (loss: 0.25521308183670044, acc: 0.9405405521392822)
[2024-12-17 03:16:01,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,036][root][INFO] - Training Epoch: 2/2, step 5113/7134 completed (loss: 0.2539779841899872, acc: 0.9271523356437683)
[2024-12-17 03:16:02,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,438][root][INFO] - Training Epoch: 2/2, step 5114/7134 completed (loss: 0.16698895394802094, acc: 0.9470198750495911)
[2024-12-17 03:16:02,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:02,864][root][INFO] - Training Epoch: 2/2, step 5115/7134 completed (loss: 0.11731617152690887, acc: 0.9682539701461792)
[2024-12-17 03:16:03,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,262][root][INFO] - Training Epoch: 2/2, step 5116/7134 completed (loss: 0.07037857919931412, acc: 0.9788359999656677)
[2024-12-17 03:16:03,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,632][root][INFO] - Training Epoch: 2/2, step 5117/7134 completed (loss: 0.11362101882696152, acc: 0.9779005646705627)
[2024-12-17 03:16:03,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:03,981][root][INFO] - Training Epoch: 2/2, step 5118/7134 completed (loss: 0.16358821094036102, acc: 0.9638554453849792)
[2024-12-17 03:16:04,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:04,344][root][INFO] - Training Epoch: 2/2, step 5119/7134 completed (loss: 0.1510416865348816, acc: 0.977011501789093)
[2024-12-17 03:16:04,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:04,751][root][INFO] - Training Epoch: 2/2, step 5120/7134 completed (loss: 0.21065756678581238, acc: 0.9365079402923584)
[2024-12-17 03:16:04,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,159][root][INFO] - Training Epoch: 2/2, step 5121/7134 completed (loss: 0.05552128702402115, acc: 0.9878787994384766)
[2024-12-17 03:16:05,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,573][root][INFO] - Training Epoch: 2/2, step 5122/7134 completed (loss: 0.21559002995491028, acc: 0.9534883499145508)
[2024-12-17 03:16:05,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:05,964][root][INFO] - Training Epoch: 2/2, step 5123/7134 completed (loss: 0.11877472698688507, acc: 0.9801980257034302)
[2024-12-17 03:16:06,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:06,360][root][INFO] - Training Epoch: 2/2, step 5124/7134 completed (loss: 0.1673833727836609, acc: 0.9458128213882446)
[2024-12-17 03:16:06,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:06,735][root][INFO] - Training Epoch: 2/2, step 5125/7134 completed (loss: 0.04882092401385307, acc: 0.9869281053543091)
[2024-12-17 03:16:06,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,100][root][INFO] - Training Epoch: 2/2, step 5126/7134 completed (loss: 0.11251933872699738, acc: 0.9724137783050537)
[2024-12-17 03:16:07,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,468][root][INFO] - Training Epoch: 2/2, step 5127/7134 completed (loss: 0.20982441306114197, acc: 0.9482758641242981)
[2024-12-17 03:16:07,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:07,895][root][INFO] - Training Epoch: 2/2, step 5128/7134 completed (loss: 0.10600132495164871, acc: 0.9655172228813171)
[2024-12-17 03:16:08,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:08,268][root][INFO] - Training Epoch: 2/2, step 5129/7134 completed (loss: 0.19605699181556702, acc: 0.9457364082336426)
[2024-12-17 03:16:08,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:08,667][root][INFO] - Training Epoch: 2/2, step 5130/7134 completed (loss: 0.08544269949197769, acc: 0.9610389471054077)
[2024-12-17 03:16:08,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,049][root][INFO] - Training Epoch: 2/2, step 5131/7134 completed (loss: 0.1979602724313736, acc: 0.9487179517745972)
[2024-12-17 03:16:09,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,413][root][INFO] - Training Epoch: 2/2, step 5132/7134 completed (loss: 0.160375714302063, acc: 0.953125)
[2024-12-17 03:16:09,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:09,827][root][INFO] - Training Epoch: 2/2, step 5133/7134 completed (loss: 0.2091483324766159, acc: 0.9451219439506531)
[2024-12-17 03:16:09,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:10,222][root][INFO] - Training Epoch: 2/2, step 5134/7134 completed (loss: 0.10209876298904419, acc: 0.9710144996643066)
[2024-12-17 03:16:10,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:10,637][root][INFO] - Training Epoch: 2/2, step 5135/7134 completed (loss: 0.25669005513191223, acc: 0.9768785834312439)
[2024-12-17 03:16:10,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,010][root][INFO] - Training Epoch: 2/2, step 5136/7134 completed (loss: 0.07956524938344955, acc: 0.9838709831237793)
[2024-12-17 03:16:11,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,377][root][INFO] - Training Epoch: 2/2, step 5137/7134 completed (loss: 0.2076466977596283, acc: 0.95652174949646)
[2024-12-17 03:16:11,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:11,762][root][INFO] - Training Epoch: 2/2, step 5138/7134 completed (loss: 0.22823597490787506, acc: 0.957446813583374)
[2024-12-17 03:16:11,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:12,095][root][INFO] - Training Epoch: 2/2, step 5139/7134 completed (loss: 0.15280281007289886, acc: 0.9647058844566345)
[2024-12-17 03:16:12,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:12,447][root][INFO] - Training Epoch: 2/2, step 5140/7134 completed (loss: 0.1669183224439621, acc: 0.9416666626930237)
[2024-12-17 03:16:12,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:12,783][root][INFO] - Training Epoch: 2/2, step 5141/7134 completed (loss: 0.17676803469657898, acc: 0.9836065769195557)
[2024-12-17 03:16:12,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,130][root][INFO] - Training Epoch: 2/2, step 5142/7134 completed (loss: 0.1195860505104065, acc: 0.9701492786407471)
[2024-12-17 03:16:13,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,496][root][INFO] - Training Epoch: 2/2, step 5143/7134 completed (loss: 0.125486359000206, acc: 0.9552238583564758)
[2024-12-17 03:16:13,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:13,858][root][INFO] - Training Epoch: 2/2, step 5144/7134 completed (loss: 0.0752665102481842, acc: 0.9788359999656677)
[2024-12-17 03:16:13,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,240][root][INFO] - Training Epoch: 2/2, step 5145/7134 completed (loss: 0.11343161016702652, acc: 0.96875)
[2024-12-17 03:16:14,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,612][root][INFO] - Training Epoch: 2/2, step 5146/7134 completed (loss: 0.17715789377689362, acc: 0.9672130942344666)
[2024-12-17 03:16:14,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:14,954][root][INFO] - Training Epoch: 2/2, step 5147/7134 completed (loss: 0.0761304721236229, acc: 0.9679487347602844)
[2024-12-17 03:16:15,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:15,292][root][INFO] - Training Epoch: 2/2, step 5148/7134 completed (loss: 0.2496478259563446, acc: 0.949999988079071)
[2024-12-17 03:16:15,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:15,679][root][INFO] - Training Epoch: 2/2, step 5149/7134 completed (loss: 0.12751919031143188, acc: 0.9683257937431335)
[2024-12-17 03:16:15,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,092][root][INFO] - Training Epoch: 2/2, step 5150/7134 completed (loss: 0.21087564527988434, acc: 0.940119743347168)
[2024-12-17 03:16:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,447][root][INFO] - Training Epoch: 2/2, step 5151/7134 completed (loss: 0.2477237433195114, acc: 0.9485714435577393)
[2024-12-17 03:16:16,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:16,807][root][INFO] - Training Epoch: 2/2, step 5152/7134 completed (loss: 0.11955577880144119, acc: 0.970588207244873)
[2024-12-17 03:16:16,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,194][root][INFO] - Training Epoch: 2/2, step 5153/7134 completed (loss: 0.14409379661083221, acc: 0.9542483687400818)
[2024-12-17 03:16:17,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,569][root][INFO] - Training Epoch: 2/2, step 5154/7134 completed (loss: 0.10357638448476791, acc: 0.9750000238418579)
[2024-12-17 03:16:17,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:17,961][root][INFO] - Training Epoch: 2/2, step 5155/7134 completed (loss: 0.27827826142311096, acc: 0.9635036587715149)
[2024-12-17 03:16:18,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:18,350][root][INFO] - Training Epoch: 2/2, step 5156/7134 completed (loss: 0.10249734669923782, acc: 0.9814814925193787)
[2024-12-17 03:16:18,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:18,719][root][INFO] - Training Epoch: 2/2, step 5157/7134 completed (loss: 0.12145661562681198, acc: 0.9772727489471436)
[2024-12-17 03:16:18,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,073][root][INFO] - Training Epoch: 2/2, step 5158/7134 completed (loss: 0.21176978945732117, acc: 0.942307710647583)
[2024-12-17 03:16:19,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,447][root][INFO] - Training Epoch: 2/2, step 5159/7134 completed (loss: 0.1899147778749466, acc: 0.9494949579238892)
[2024-12-17 03:16:19,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:19,827][root][INFO] - Training Epoch: 2/2, step 5160/7134 completed (loss: 0.20350337028503418, acc: 0.9555555582046509)
[2024-12-17 03:16:19,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:20,212][root][INFO] - Training Epoch: 2/2, step 5161/7134 completed (loss: 0.21670100092887878, acc: 0.9462365508079529)
[2024-12-17 03:16:20,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:20,621][root][INFO] - Training Epoch: 2/2, step 5162/7134 completed (loss: 0.2122601568698883, acc: 0.9428571462631226)
[2024-12-17 03:16:20,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:20,999][root][INFO] - Training Epoch: 2/2, step 5163/7134 completed (loss: 0.15167376399040222, acc: 0.9408602118492126)
[2024-12-17 03:16:21,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:21,340][root][INFO] - Training Epoch: 2/2, step 5164/7134 completed (loss: 0.0681750699877739, acc: 0.9741935729980469)
[2024-12-17 03:16:21,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:21,709][root][INFO] - Training Epoch: 2/2, step 5165/7134 completed (loss: 0.12494552880525589, acc: 0.9696969985961914)
[2024-12-17 03:16:21,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,049][root][INFO] - Training Epoch: 2/2, step 5166/7134 completed (loss: 0.2268725037574768, acc: 0.9382715821266174)
[2024-12-17 03:16:22,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,408][root][INFO] - Training Epoch: 2/2, step 5167/7134 completed (loss: 0.24619445204734802, acc: 0.9337016344070435)
[2024-12-17 03:16:22,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:22,773][root][INFO] - Training Epoch: 2/2, step 5168/7134 completed (loss: 0.24763530492782593, acc: 0.9593023061752319)
[2024-12-17 03:16:22,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,149][root][INFO] - Training Epoch: 2/2, step 5169/7134 completed (loss: 0.24476872384548187, acc: 0.9512194991111755)
[2024-12-17 03:16:23,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,514][root][INFO] - Training Epoch: 2/2, step 5170/7134 completed (loss: 0.34262460470199585, acc: 0.9326424598693848)
[2024-12-17 03:16:23,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:23,853][root][INFO] - Training Epoch: 2/2, step 5171/7134 completed (loss: 0.1733984500169754, acc: 0.9593495726585388)
[2024-12-17 03:16:23,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,234][root][INFO] - Training Epoch: 2/2, step 5172/7134 completed (loss: 0.40771275758743286, acc: 0.9268292784690857)
[2024-12-17 03:16:24,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,591][root][INFO] - Training Epoch: 2/2, step 5173/7134 completed (loss: 0.20674966275691986, acc: 0.9570552110671997)
[2024-12-17 03:16:24,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:24,961][root][INFO] - Training Epoch: 2/2, step 5174/7134 completed (loss: 0.10170172899961472, acc: 0.9768785834312439)
[2024-12-17 03:16:25,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,353][root][INFO] - Training Epoch: 2/2, step 5175/7134 completed (loss: 0.11625365167856216, acc: 0.976047933101654)
[2024-12-17 03:16:25,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:25,732][root][INFO] - Training Epoch: 2/2, step 5176/7134 completed (loss: 0.17560827732086182, acc: 0.9407894611358643)
[2024-12-17 03:16:25,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,138][root][INFO] - Training Epoch: 2/2, step 5177/7134 completed (loss: 0.26232361793518066, acc: 0.9266666769981384)
[2024-12-17 03:16:26,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,507][root][INFO] - Training Epoch: 2/2, step 5178/7134 completed (loss: 0.35172173380851746, acc: 0.9133333563804626)
[2024-12-17 03:16:26,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:26,892][root][INFO] - Training Epoch: 2/2, step 5179/7134 completed (loss: 0.2122432142496109, acc: 0.9345238208770752)
[2024-12-17 03:16:26,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,269][root][INFO] - Training Epoch: 2/2, step 5180/7134 completed (loss: 0.30675172805786133, acc: 0.9290780425071716)
[2024-12-17 03:16:27,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,611][root][INFO] - Training Epoch: 2/2, step 5181/7134 completed (loss: 0.42488977313041687, acc: 0.932584285736084)
[2024-12-17 03:16:27,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:27,958][root][INFO] - Training Epoch: 2/2, step 5182/7134 completed (loss: 0.7367985844612122, acc: 0.8503937125205994)
[2024-12-17 03:16:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:28,313][root][INFO] - Training Epoch: 2/2, step 5183/7134 completed (loss: 0.26585114002227783, acc: 0.9558823704719543)
[2024-12-17 03:16:28,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:28,665][root][INFO] - Training Epoch: 2/2, step 5184/7134 completed (loss: 0.15257947146892548, acc: 0.9711538553237915)
[2024-12-17 03:16:28,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,082][root][INFO] - Training Epoch: 2/2, step 5185/7134 completed (loss: 0.1953336000442505, acc: 0.9504950642585754)
[2024-12-17 03:16:29,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,444][root][INFO] - Training Epoch: 2/2, step 5186/7134 completed (loss: 0.1479300707578659, acc: 0.960629940032959)
[2024-12-17 03:16:29,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:29,803][root][INFO] - Training Epoch: 2/2, step 5187/7134 completed (loss: 0.11315510421991348, acc: 0.9760000109672546)
[2024-12-17 03:16:29,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,191][root][INFO] - Training Epoch: 2/2, step 5188/7134 completed (loss: 0.1996508091688156, acc: 0.95652174949646)
[2024-12-17 03:16:30,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,507][root][INFO] - Training Epoch: 2/2, step 5189/7134 completed (loss: 0.29487839341163635, acc: 0.9603960514068604)
[2024-12-17 03:16:30,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:30,818][root][INFO] - Training Epoch: 2/2, step 5190/7134 completed (loss: 0.16872859001159668, acc: 0.9636363387107849)
[2024-12-17 03:16:30,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,201][root][INFO] - Training Epoch: 2/2, step 5191/7134 completed (loss: 0.2274193912744522, acc: 0.9444444179534912)
[2024-12-17 03:16:31,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,598][root][INFO] - Training Epoch: 2/2, step 5192/7134 completed (loss: 0.2170410305261612, acc: 0.9595959782600403)
[2024-12-17 03:16:31,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:31,949][root][INFO] - Training Epoch: 2/2, step 5193/7134 completed (loss: 0.055176183581352234, acc: 0.9833333492279053)
[2024-12-17 03:16:32,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:32,318][root][INFO] - Training Epoch: 2/2, step 5194/7134 completed (loss: 0.21430522203445435, acc: 0.9426751732826233)
[2024-12-17 03:16:32,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:32,692][root][INFO] - Training Epoch: 2/2, step 5195/7134 completed (loss: 0.2770560383796692, acc: 0.9629629850387573)
[2024-12-17 03:16:32,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,074][root][INFO] - Training Epoch: 2/2, step 5196/7134 completed (loss: 0.29941651225090027, acc: 0.949999988079071)
[2024-12-17 03:16:33,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,422][root][INFO] - Training Epoch: 2/2, step 5197/7134 completed (loss: 0.1611282229423523, acc: 0.9523809552192688)
[2024-12-17 03:16:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:33,787][root][INFO] - Training Epoch: 2/2, step 5198/7134 completed (loss: 0.20463792979717255, acc: 0.9426229596138)
[2024-12-17 03:16:33,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,168][root][INFO] - Training Epoch: 2/2, step 5199/7134 completed (loss: 0.21187759935855865, acc: 0.9593023061752319)
[2024-12-17 03:16:34,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,533][root][INFO] - Training Epoch: 2/2, step 5200/7134 completed (loss: 0.1258622407913208, acc: 0.9523809552192688)
[2024-12-17 03:16:34,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:34,907][root][INFO] - Training Epoch: 2/2, step 5201/7134 completed (loss: 0.19436612725257874, acc: 0.9613526463508606)
[2024-12-17 03:16:35,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:35,278][root][INFO] - Training Epoch: 2/2, step 5202/7134 completed (loss: 0.16141840815544128, acc: 0.96875)
[2024-12-17 03:16:35,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:35,655][root][INFO] - Training Epoch: 2/2, step 5203/7134 completed (loss: 0.08404732495546341, acc: 0.9780219793319702)
[2024-12-17 03:16:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,017][root][INFO] - Training Epoch: 2/2, step 5204/7134 completed (loss: 0.0665704533457756, acc: 0.9918032884597778)
[2024-12-17 03:16:36,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,310][root][INFO] - Training Epoch: 2/2, step 5205/7134 completed (loss: 0.09316346794366837, acc: 0.9759036302566528)
[2024-12-17 03:16:36,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:36,736][root][INFO] - Training Epoch: 2/2, step 5206/7134 completed (loss: 0.1608993113040924, acc: 0.9766082167625427)
[2024-12-17 03:16:36,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:37,101][root][INFO] - Training Epoch: 2/2, step 5207/7134 completed (loss: 0.4566361904144287, acc: 0.9126983880996704)
[2024-12-17 03:16:37,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:37,489][root][INFO] - Training Epoch: 2/2, step 5208/7134 completed (loss: 0.10375235229730606, acc: 0.977011501789093)
[2024-12-17 03:16:37,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:37,861][root][INFO] - Training Epoch: 2/2, step 5209/7134 completed (loss: 0.17620202898979187, acc: 0.9398496150970459)
[2024-12-17 03:16:37,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,245][root][INFO] - Training Epoch: 2/2, step 5210/7134 completed (loss: 0.12328840047121048, acc: 0.9585798978805542)
[2024-12-17 03:16:38,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,621][root][INFO] - Training Epoch: 2/2, step 5211/7134 completed (loss: 0.1571073681116104, acc: 0.9603174328804016)
[2024-12-17 03:16:38,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:38,987][root][INFO] - Training Epoch: 2/2, step 5212/7134 completed (loss: 0.15676435828208923, acc: 0.948051929473877)
[2024-12-17 03:16:39,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:39,371][root][INFO] - Training Epoch: 2/2, step 5213/7134 completed (loss: 0.18690189719200134, acc: 0.9629629850387573)
[2024-12-17 03:16:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:39,730][root][INFO] - Training Epoch: 2/2, step 5214/7134 completed (loss: 0.30090174078941345, acc: 0.9327731132507324)
[2024-12-17 03:16:39,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,117][root][INFO] - Training Epoch: 2/2, step 5215/7134 completed (loss: 0.24128010869026184, acc: 0.9405940771102905)
[2024-12-17 03:16:40,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,485][root][INFO] - Training Epoch: 2/2, step 5216/7134 completed (loss: 0.23794998228549957, acc: 0.9166666865348816)
[2024-12-17 03:16:40,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:40,946][root][INFO] - Training Epoch: 2/2, step 5217/7134 completed (loss: 0.26643431186676025, acc: 0.9347826242446899)
[2024-12-17 03:16:41,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:41,342][root][INFO] - Training Epoch: 2/2, step 5218/7134 completed (loss: 0.25943833589553833, acc: 0.9504950642585754)
[2024-12-17 03:16:41,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:41,709][root][INFO] - Training Epoch: 2/2, step 5219/7134 completed (loss: 0.2438390552997589, acc: 0.9722222089767456)
[2024-12-17 03:16:41,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,065][root][INFO] - Training Epoch: 2/2, step 5220/7134 completed (loss: 0.13560974597930908, acc: 0.965753436088562)
[2024-12-17 03:16:42,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,433][root][INFO] - Training Epoch: 2/2, step 5221/7134 completed (loss: 0.18055102229118347, acc: 0.9629629850387573)
[2024-12-17 03:16:42,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:42,811][root][INFO] - Training Epoch: 2/2, step 5222/7134 completed (loss: 0.23532463610172272, acc: 0.9523809552192688)
[2024-12-17 03:16:42,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,173][root][INFO] - Training Epoch: 2/2, step 5223/7134 completed (loss: 0.06878961622714996, acc: 0.991150438785553)
[2024-12-17 03:16:43,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,551][root][INFO] - Training Epoch: 2/2, step 5224/7134 completed (loss: 0.14957092702388763, acc: 0.9555555582046509)
[2024-12-17 03:16:43,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:43,939][root][INFO] - Training Epoch: 2/2, step 5225/7134 completed (loss: 0.18163128197193146, acc: 0.9539473652839661)
[2024-12-17 03:16:44,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:44,363][root][INFO] - Training Epoch: 2/2, step 5226/7134 completed (loss: 0.15984410047531128, acc: 0.9615384340286255)
[2024-12-17 03:16:44,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:44,804][root][INFO] - Training Epoch: 2/2, step 5227/7134 completed (loss: 0.159606471657753, acc: 0.9589743614196777)
[2024-12-17 03:16:44,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:45,259][root][INFO] - Training Epoch: 2/2, step 5228/7134 completed (loss: 0.09422338008880615, acc: 0.9714285731315613)
[2024-12-17 03:16:45,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:45,651][root][INFO] - Training Epoch: 2/2, step 5229/7134 completed (loss: 0.06522125750780106, acc: 0.9806451797485352)
[2024-12-17 03:16:45,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,043][root][INFO] - Training Epoch: 2/2, step 5230/7134 completed (loss: 0.04903697595000267, acc: 0.9779005646705627)
[2024-12-17 03:16:46,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,420][root][INFO] - Training Epoch: 2/2, step 5231/7134 completed (loss: 0.07691849768161774, acc: 0.9793814420700073)
[2024-12-17 03:16:46,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:46,823][root][INFO] - Training Epoch: 2/2, step 5232/7134 completed (loss: 0.07683796435594559, acc: 0.994350254535675)
[2024-12-17 03:16:46,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:47,235][root][INFO] - Training Epoch: 2/2, step 5233/7134 completed (loss: 0.13877767324447632, acc: 0.963302731513977)
[2024-12-17 03:16:47,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:47,627][root][INFO] - Training Epoch: 2/2, step 5234/7134 completed (loss: 0.11568651348352432, acc: 0.9631578922271729)
[2024-12-17 03:16:47,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,037][root][INFO] - Training Epoch: 2/2, step 5235/7134 completed (loss: 0.044329892843961716, acc: 0.9864864945411682)
[2024-12-17 03:16:48,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,419][root][INFO] - Training Epoch: 2/2, step 5236/7134 completed (loss: 0.05256687104701996, acc: 0.985401451587677)
[2024-12-17 03:16:48,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:48,820][root][INFO] - Training Epoch: 2/2, step 5237/7134 completed (loss: 0.06476657837629318, acc: 0.98591548204422)
[2024-12-17 03:16:48,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,190][root][INFO] - Training Epoch: 2/2, step 5238/7134 completed (loss: 0.08490629494190216, acc: 0.9776119589805603)
[2024-12-17 03:16:49,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,556][root][INFO] - Training Epoch: 2/2, step 5239/7134 completed (loss: 0.10152331739664078, acc: 0.9579831957817078)
[2024-12-17 03:16:49,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:49,931][root][INFO] - Training Epoch: 2/2, step 5240/7134 completed (loss: 0.05335152894258499, acc: 0.9883720874786377)
[2024-12-17 03:16:50,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:50,322][root][INFO] - Training Epoch: 2/2, step 5241/7134 completed (loss: 0.20295074582099915, acc: 0.9612902998924255)
[2024-12-17 03:16:50,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:50,746][root][INFO] - Training Epoch: 2/2, step 5242/7134 completed (loss: 0.07448135316371918, acc: 0.9736841917037964)
[2024-12-17 03:16:50,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,187][root][INFO] - Training Epoch: 2/2, step 5243/7134 completed (loss: 0.033992569893598557, acc: 1.0)
[2024-12-17 03:16:51,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,561][root][INFO] - Training Epoch: 2/2, step 5244/7134 completed (loss: 0.12069245427846909, acc: 0.9651162624359131)
[2024-12-17 03:16:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:51,980][root][INFO] - Training Epoch: 2/2, step 5245/7134 completed (loss: 0.08886679261922836, acc: 0.9841269850730896)
[2024-12-17 03:16:52,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,355][root][INFO] - Training Epoch: 2/2, step 5246/7134 completed (loss: 0.12445085495710373, acc: 0.9620253443717957)
[2024-12-17 03:16:52,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:52,728][root][INFO] - Training Epoch: 2/2, step 5247/7134 completed (loss: 0.126140296459198, acc: 0.9555555582046509)
[2024-12-17 03:16:52,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,108][root][INFO] - Training Epoch: 2/2, step 5248/7134 completed (loss: 0.1348484754562378, acc: 0.9618320465087891)
[2024-12-17 03:16:53,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,481][root][INFO] - Training Epoch: 2/2, step 5249/7134 completed (loss: 0.055320411920547485, acc: 0.993630588054657)
[2024-12-17 03:16:53,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:53,874][root][INFO] - Training Epoch: 2/2, step 5250/7134 completed (loss: 0.07109683752059937, acc: 0.9836956262588501)
[2024-12-17 03:16:53,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,253][root][INFO] - Training Epoch: 2/2, step 5251/7134 completed (loss: 0.10466409474611282, acc: 0.9739583134651184)
[2024-12-17 03:16:54,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,599][root][INFO] - Training Epoch: 2/2, step 5252/7134 completed (loss: 0.22679685056209564, acc: 0.9557521939277649)
[2024-12-17 03:16:54,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:54,974][root][INFO] - Training Epoch: 2/2, step 5253/7134 completed (loss: 0.09016300737857819, acc: 0.9791666865348816)
[2024-12-17 03:16:55,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,355][root][INFO] - Training Epoch: 2/2, step 5254/7134 completed (loss: 0.2701345980167389, acc: 0.9370629191398621)
[2024-12-17 03:16:55,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:55,737][root][INFO] - Training Epoch: 2/2, step 5255/7134 completed (loss: 0.13980771601200104, acc: 0.959770143032074)
[2024-12-17 03:16:55,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,120][root][INFO] - Training Epoch: 2/2, step 5256/7134 completed (loss: 0.1838473230600357, acc: 0.9599999785423279)
[2024-12-17 03:16:56,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,502][root][INFO] - Training Epoch: 2/2, step 5257/7134 completed (loss: 0.2972012460231781, acc: 0.916167676448822)
[2024-12-17 03:16:56,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:56,916][root][INFO] - Training Epoch: 2/2, step 5258/7134 completed (loss: 0.20446789264678955, acc: 0.9417989253997803)
[2024-12-17 03:16:57,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:57,309][root][INFO] - Training Epoch: 2/2, step 5259/7134 completed (loss: 0.20837455987930298, acc: 0.9424460530281067)
[2024-12-17 03:16:57,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:57,676][root][INFO] - Training Epoch: 2/2, step 5260/7134 completed (loss: 0.11791140586137772, acc: 0.9629629850387573)
[2024-12-17 03:16:57,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,036][root][INFO] - Training Epoch: 2/2, step 5261/7134 completed (loss: 0.19912339746952057, acc: 0.9300699234008789)
[2024-12-17 03:16:58,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,419][root][INFO] - Training Epoch: 2/2, step 5262/7134 completed (loss: 0.13702192902565002, acc: 0.9698795080184937)
[2024-12-17 03:16:58,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:58,799][root][INFO] - Training Epoch: 2/2, step 5263/7134 completed (loss: 0.19816966354846954, acc: 0.9647887349128723)
[2024-12-17 03:16:58,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,178][root][INFO] - Training Epoch: 2/2, step 5264/7134 completed (loss: 0.09055538475513458, acc: 0.9744898080825806)
[2024-12-17 03:16:59,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,566][root][INFO] - Training Epoch: 2/2, step 5265/7134 completed (loss: 0.14758573472499847, acc: 0.9617486596107483)
[2024-12-17 03:16:59,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:16:59,929][root][INFO] - Training Epoch: 2/2, step 5266/7134 completed (loss: 0.059959616512060165, acc: 0.9814814925193787)
[2024-12-17 03:17:00,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:00,284][root][INFO] - Training Epoch: 2/2, step 5267/7134 completed (loss: 0.38578176498413086, acc: 0.8765432238578796)
[2024-12-17 03:17:00,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:00,727][root][INFO] - Training Epoch: 2/2, step 5268/7134 completed (loss: 0.2401178479194641, acc: 0.930232584476471)
[2024-12-17 03:17:00,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,114][root][INFO] - Training Epoch: 2/2, step 5269/7134 completed (loss: 0.19498340785503387, acc: 0.9642857313156128)
[2024-12-17 03:17:01,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,515][root][INFO] - Training Epoch: 2/2, step 5270/7134 completed (loss: 0.1469496786594391, acc: 0.954023003578186)
[2024-12-17 03:17:01,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:01,899][root][INFO] - Training Epoch: 2/2, step 5271/7134 completed (loss: 0.10845275968313217, acc: 0.9640287756919861)
[2024-12-17 03:17:02,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:02,280][root][INFO] - Training Epoch: 2/2, step 5272/7134 completed (loss: 0.11854656040668488, acc: 0.9710982441902161)
[2024-12-17 03:17:02,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:02,677][root][INFO] - Training Epoch: 2/2, step 5273/7134 completed (loss: 0.21733787655830383, acc: 0.9375)
[2024-12-17 03:17:02,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,054][root][INFO] - Training Epoch: 2/2, step 5274/7134 completed (loss: 0.23082111775875092, acc: 0.9487179517745972)
[2024-12-17 03:17:03,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,413][root][INFO] - Training Epoch: 2/2, step 5275/7134 completed (loss: 0.09534504264593124, acc: 0.9756097793579102)
[2024-12-17 03:17:03,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:03,811][root][INFO] - Training Epoch: 2/2, step 5276/7134 completed (loss: 0.203312486410141, acc: 0.9605262875556946)
[2024-12-17 03:17:03,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,185][root][INFO] - Training Epoch: 2/2, step 5277/7134 completed (loss: 0.11493432521820068, acc: 0.9617834687232971)
[2024-12-17 03:17:04,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,569][root][INFO] - Training Epoch: 2/2, step 5278/7134 completed (loss: 0.32425087690353394, acc: 0.9272727370262146)
[2024-12-17 03:17:04,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:04,957][root][INFO] - Training Epoch: 2/2, step 5279/7134 completed (loss: 0.0500718392431736, acc: 0.9918699264526367)
[2024-12-17 03:17:05,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:05,328][root][INFO] - Training Epoch: 2/2, step 5280/7134 completed (loss: 0.18253059685230255, acc: 0.9571428298950195)
[2024-12-17 03:17:05,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:05,688][root][INFO] - Training Epoch: 2/2, step 5281/7134 completed (loss: 0.1527111828327179, acc: 0.9710144996643066)
[2024-12-17 03:17:05,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,037][root][INFO] - Training Epoch: 2/2, step 5282/7134 completed (loss: 0.2501031160354614, acc: 0.9418604373931885)
[2024-12-17 03:17:06,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,396][root][INFO] - Training Epoch: 2/2, step 5283/7134 completed (loss: 0.14081275463104248, acc: 0.9562841653823853)
[2024-12-17 03:17:06,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:06,733][root][INFO] - Training Epoch: 2/2, step 5284/7134 completed (loss: 0.2390976846218109, acc: 0.9624999761581421)
[2024-12-17 03:17:06,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,097][root][INFO] - Training Epoch: 2/2, step 5285/7134 completed (loss: 0.1779823750257492, acc: 0.9569892287254333)
[2024-12-17 03:17:07,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,461][root][INFO] - Training Epoch: 2/2, step 5286/7134 completed (loss: 0.19862626492977142, acc: 0.9865771532058716)
[2024-12-17 03:17:07,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:07,834][root][INFO] - Training Epoch: 2/2, step 5287/7134 completed (loss: 0.2476108968257904, acc: 0.9494949579238892)
[2024-12-17 03:17:07,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,197][root][INFO] - Training Epoch: 2/2, step 5288/7134 completed (loss: 0.15579240024089813, acc: 0.9750000238418579)
[2024-12-17 03:17:08,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,584][root][INFO] - Training Epoch: 2/2, step 5289/7134 completed (loss: 0.16189007461071014, acc: 0.9545454382896423)
[2024-12-17 03:17:08,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:08,963][root][INFO] - Training Epoch: 2/2, step 5290/7134 completed (loss: 0.21804600954055786, acc: 0.9417989253997803)
[2024-12-17 03:17:09,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:09,352][root][INFO] - Training Epoch: 2/2, step 5291/7134 completed (loss: 0.040154874324798584, acc: 0.9891892075538635)
[2024-12-17 03:17:09,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:09,722][root][INFO] - Training Epoch: 2/2, step 5292/7134 completed (loss: 0.06084276735782623, acc: 0.9830508232116699)
[2024-12-17 03:17:09,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,098][root][INFO] - Training Epoch: 2/2, step 5293/7134 completed (loss: 0.07490880787372589, acc: 0.987261176109314)
[2024-12-17 03:17:10,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,554][root][INFO] - Training Epoch: 2/2, step 5294/7134 completed (loss: 0.11392922699451447, acc: 0.9585798978805542)
[2024-12-17 03:17:10,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:10,983][root][INFO] - Training Epoch: 2/2, step 5295/7134 completed (loss: 0.2106115072965622, acc: 0.9689922332763672)
[2024-12-17 03:17:11,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:11,363][root][INFO] - Training Epoch: 2/2, step 5296/7134 completed (loss: 0.09469519555568695, acc: 0.9717513918876648)
[2024-12-17 03:17:11,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:11,724][root][INFO] - Training Epoch: 2/2, step 5297/7134 completed (loss: 0.1340707540512085, acc: 0.9578313231468201)
[2024-12-17 03:17:11,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,133][root][INFO] - Training Epoch: 2/2, step 5298/7134 completed (loss: 0.11677203327417374, acc: 0.9503546357154846)
[2024-12-17 03:17:12,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,591][root][INFO] - Training Epoch: 2/2, step 5299/7134 completed (loss: 0.0669231191277504, acc: 0.9794520735740662)
[2024-12-17 03:17:12,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:12,952][root][INFO] - Training Epoch: 2/2, step 5300/7134 completed (loss: 0.06709812581539154, acc: 0.9819276928901672)
[2024-12-17 03:17:13,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:13,321][root][INFO] - Training Epoch: 2/2, step 5301/7134 completed (loss: 0.09414532035589218, acc: 0.9756097793579102)
[2024-12-17 03:17:13,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:13,692][root][INFO] - Training Epoch: 2/2, step 5302/7134 completed (loss: 0.20717951655387878, acc: 0.9497206807136536)
[2024-12-17 03:17:13,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,074][root][INFO] - Training Epoch: 2/2, step 5303/7134 completed (loss: 0.3628387451171875, acc: 0.9166666865348816)
[2024-12-17 03:17:14,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,451][root][INFO] - Training Epoch: 2/2, step 5304/7134 completed (loss: 0.578331708908081, acc: 0.8698630332946777)
[2024-12-17 03:17:14,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:14,819][root][INFO] - Training Epoch: 2/2, step 5305/7134 completed (loss: 0.23296710848808289, acc: 0.9125000238418579)
[2024-12-17 03:17:14,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,192][root][INFO] - Training Epoch: 2/2, step 5306/7134 completed (loss: 0.16926680505275726, acc: 0.9666666388511658)
[2024-12-17 03:17:15,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,548][root][INFO] - Training Epoch: 2/2, step 5307/7134 completed (loss: 0.3707473874092102, acc: 0.9356725215911865)
[2024-12-17 03:17:15,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:15,910][root][INFO] - Training Epoch: 2/2, step 5308/7134 completed (loss: 0.16830481588840485, acc: 0.9691358208656311)
[2024-12-17 03:17:16,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,272][root][INFO] - Training Epoch: 2/2, step 5309/7134 completed (loss: 0.47300490736961365, acc: 0.8881118893623352)
[2024-12-17 03:17:16,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,618][root][INFO] - Training Epoch: 2/2, step 5310/7134 completed (loss: 0.325565904378891, acc: 0.9261363744735718)
[2024-12-17 03:17:16,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:16,981][root][INFO] - Training Epoch: 2/2, step 5311/7134 completed (loss: 0.3080747723579407, acc: 0.9254658222198486)
[2024-12-17 03:17:17,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:17,335][root][INFO] - Training Epoch: 2/2, step 5312/7134 completed (loss: 0.2682437002658844, acc: 0.9365079402923584)
[2024-12-17 03:17:17,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:17,685][root][INFO] - Training Epoch: 2/2, step 5313/7134 completed (loss: 0.19947591423988342, acc: 0.9508196711540222)
[2024-12-17 03:17:17,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,043][root][INFO] - Training Epoch: 2/2, step 5314/7134 completed (loss: 0.2373650074005127, acc: 0.9285714030265808)
[2024-12-17 03:17:18,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,413][root][INFO] - Training Epoch: 2/2, step 5315/7134 completed (loss: 0.10074567794799805, acc: 0.9784172773361206)
[2024-12-17 03:17:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:18,772][root][INFO] - Training Epoch: 2/2, step 5316/7134 completed (loss: 0.1006324291229248, acc: 0.9666666388511658)
[2024-12-17 03:17:18,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,119][root][INFO] - Training Epoch: 2/2, step 5317/7134 completed (loss: 0.12728598713874817, acc: 0.976190447807312)
[2024-12-17 03:17:19,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,472][root][INFO] - Training Epoch: 2/2, step 5318/7134 completed (loss: 0.062426820397377014, acc: 0.9745222926139832)
[2024-12-17 03:17:19,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:19,837][root][INFO] - Training Epoch: 2/2, step 5319/7134 completed (loss: 0.2356887310743332, acc: 0.9473684430122375)
[2024-12-17 03:17:19,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,212][root][INFO] - Training Epoch: 2/2, step 5320/7134 completed (loss: 0.2639063596725464, acc: 0.9182389974594116)
[2024-12-17 03:17:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,584][root][INFO] - Training Epoch: 2/2, step 5321/7134 completed (loss: 0.1350870430469513, acc: 0.9610389471054077)
[2024-12-17 03:17:20,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:20,976][root][INFO] - Training Epoch: 2/2, step 5322/7134 completed (loss: 0.14234070479869843, acc: 0.95333331823349)
[2024-12-17 03:17:21,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:21,361][root][INFO] - Training Epoch: 2/2, step 5323/7134 completed (loss: 0.22123201191425323, acc: 0.9328858852386475)
[2024-12-17 03:17:21,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:21,725][root][INFO] - Training Epoch: 2/2, step 5324/7134 completed (loss: 0.18440409004688263, acc: 0.9407894611358643)
[2024-12-17 03:17:21,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,114][root][INFO] - Training Epoch: 2/2, step 5325/7134 completed (loss: 0.10022422671318054, acc: 0.97826087474823)
[2024-12-17 03:17:22,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,488][root][INFO] - Training Epoch: 2/2, step 5326/7134 completed (loss: 0.17235812544822693, acc: 0.951724112033844)
[2024-12-17 03:17:22,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:22,844][root][INFO] - Training Epoch: 2/2, step 5327/7134 completed (loss: 0.13105854392051697, acc: 0.9741935729980469)
[2024-12-17 03:17:22,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,222][root][INFO] - Training Epoch: 2/2, step 5328/7134 completed (loss: 0.13287557661533356, acc: 0.969924807548523)
[2024-12-17 03:17:23,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,596][root][INFO] - Training Epoch: 2/2, step 5329/7134 completed (loss: 0.14153018593788147, acc: 0.9599999785423279)
[2024-12-17 03:17:23,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:23,971][root][INFO] - Training Epoch: 2/2, step 5330/7134 completed (loss: 0.16388177871704102, acc: 0.9620253443717957)
[2024-12-17 03:17:24,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:24,363][root][INFO] - Training Epoch: 2/2, step 5331/7134 completed (loss: 0.1878923773765564, acc: 0.9259259104728699)
[2024-12-17 03:17:24,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:24,781][root][INFO] - Training Epoch: 2/2, step 5332/7134 completed (loss: 0.1706109493970871, acc: 0.9726027250289917)
[2024-12-17 03:17:24,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:25,160][root][INFO] - Training Epoch: 2/2, step 5333/7134 completed (loss: 0.058235105127096176, acc: 0.9868420958518982)
[2024-12-17 03:17:25,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:25,536][root][INFO] - Training Epoch: 2/2, step 5334/7134 completed (loss: 0.15770474076271057, acc: 0.949999988079071)
[2024-12-17 03:17:25,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:25,888][root][INFO] - Training Epoch: 2/2, step 5335/7134 completed (loss: 0.13104690611362457, acc: 0.9798657894134521)
[2024-12-17 03:17:25,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:26,271][root][INFO] - Training Epoch: 2/2, step 5336/7134 completed (loss: 0.15027998387813568, acc: 0.9647887349128723)
[2024-12-17 03:17:26,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:26,649][root][INFO] - Training Epoch: 2/2, step 5337/7134 completed (loss: 0.15464547276496887, acc: 0.9579439163208008)
[2024-12-17 03:17:26,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,035][root][INFO] - Training Epoch: 2/2, step 5338/7134 completed (loss: 0.11023000627756119, acc: 0.9763033390045166)
[2024-12-17 03:17:27,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,384][root][INFO] - Training Epoch: 2/2, step 5339/7134 completed (loss: 0.2472788393497467, acc: 0.9450549483299255)
[2024-12-17 03:17:27,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:27,782][root][INFO] - Training Epoch: 2/2, step 5340/7134 completed (loss: 0.22302015125751495, acc: 0.9395973086357117)
[2024-12-17 03:17:27,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,143][root][INFO] - Training Epoch: 2/2, step 5341/7134 completed (loss: 0.16793541610240936, acc: 0.9549999833106995)
[2024-12-17 03:17:28,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,520][root][INFO] - Training Epoch: 2/2, step 5342/7134 completed (loss: 0.3800811767578125, acc: 0.8894736766815186)
[2024-12-17 03:17:28,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:28,884][root][INFO] - Training Epoch: 2/2, step 5343/7134 completed (loss: 0.20965710282325745, acc: 0.9459459185600281)
[2024-12-17 03:17:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,252][root][INFO] - Training Epoch: 2/2, step 5344/7134 completed (loss: 0.24334675073623657, acc: 0.9254385828971863)
[2024-12-17 03:17:29,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,616][root][INFO] - Training Epoch: 2/2, step 5345/7134 completed (loss: 0.22944307327270508, acc: 0.939393937587738)
[2024-12-17 03:17:29,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:29,992][root][INFO] - Training Epoch: 2/2, step 5346/7134 completed (loss: 0.20544923841953278, acc: 0.9403669834136963)
[2024-12-17 03:17:30,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:31,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:32,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:33,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:34,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:35,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:36,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:37,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:38,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:39,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:40,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:41,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:42,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:44,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:45,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:47,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:48,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:48,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:49,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:50,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:51,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:53,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:54,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:55,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:56,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:57,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:58,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:17:59,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:00,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:02,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:03,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:04,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:05,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:06,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:07,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:08,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:09,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:10,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:11,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:12,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:13,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:14,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:15,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:16,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:17,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:18,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:18,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:19,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:21,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:22,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:23,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:24,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:25,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:26,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:26,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:27,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:28,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:29,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:30,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:31,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:32,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:33,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:34,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:34,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:34,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:35,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:36,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:37,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:38,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:39,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:40,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:41,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:42,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:43,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:44,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:45,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:46,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:47,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:48,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:49,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:49,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:49,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:50,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:51,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:52,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:53,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:54,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:55,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:56,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:56,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:57,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:58,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:18:59,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:00,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:01,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:03,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:03,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:04,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:05,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:06,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:08,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:08,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:08,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:09,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:09,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:10,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:10,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:10,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:11,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:12,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:13,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:14,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:16,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:17,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:18,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:19,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:20,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:21,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:21,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:22,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:23,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:24,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:24,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:25,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:26,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:27,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:27,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:28,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:29,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:30,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:31,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:32,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:33,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:34,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:34,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:35,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:36,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:37,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:37,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:38,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:39,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:40,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:41,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:42,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:43,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:44,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:45,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:46,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:47,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:48,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:49,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:50,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:51,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:52,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:53,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:54,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:57,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:58,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:19:59,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:00,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:00,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:02,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:02,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:03,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:04,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:05,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:06,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:07,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:08,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:09,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:10,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:10,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:10,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:11,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:12,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:13,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:14,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:15,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:15,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:16,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:17,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:18,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:19,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:20,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:21,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:22,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:22,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:23,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:23,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:23,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:24,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:24,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:25,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:26,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:27,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:27,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:28,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:29,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:30,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:31,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:32,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:33,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:34,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:35,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:36,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:37,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:38,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:39,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:40,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:41,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:41,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:41,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:42,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:42,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:43,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:43,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:43,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:44,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:44,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:44,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:45,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:45,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:45,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:46,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:46,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:47,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:47,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:47,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:48,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:48,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:49,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:49,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:49,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:50,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:50,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:50,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:51,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:52,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:52,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:52,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:53,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:53,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:53,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:54,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:54,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:54,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:55,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:55,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:55,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:56,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:56,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:56,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:57,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:57,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:57,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:58,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:58,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:58,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:59,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:59,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:20:59,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:00,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:00,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:00,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:01,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:01,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:01,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:02,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:02,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:03,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:03,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:03,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:04,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:04,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:04,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:05,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:05,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:06,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:06,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:07,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:07,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:08,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:08,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:09,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:09,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:09,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:10,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:10,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:10,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:11,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:11,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:11,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:12,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:12,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:12,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:13,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:13,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:13,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:14,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:14,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:14,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:15,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:15,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:15,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:16,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:16,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:16,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:17,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:17,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:17,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:18,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:18,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:18,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:19,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:19,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:19,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:20,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:20,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:20,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:21,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:21,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:22,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:22,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:23,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:23,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:24,141][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.2926, device='cuda:0') eval_epoch_loss=tensor(0.2567, device='cuda:0') eval_epoch_acc=tensor(0.9401, device='cuda:0')
[2024-12-17 03:21:24,143][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 03:21:24,143][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:21:24,363][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_5347_loss_0.25665825605392456/model.pt
[2024-12-17 03:21:24,366][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 03:21:24,367][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.25665825605392456
[2024-12-17 03:21:24,367][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9400559663772583
[2024-12-17 03:21:24,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:24,808][root][INFO] - Training Epoch: 2/2, step 5347/7134 completed (loss: 0.20907831192016602, acc: 0.9516128897666931)
[2024-12-17 03:21:24,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:25,187][root][INFO] - Training Epoch: 2/2, step 5348/7134 completed (loss: 0.24524083733558655, acc: 0.9277108311653137)
[2024-12-17 03:21:25,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:25,561][root][INFO] - Training Epoch: 2/2, step 5349/7134 completed (loss: 0.3264821171760559, acc: 0.9142857193946838)
[2024-12-17 03:21:25,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:25,930][root][INFO] - Training Epoch: 2/2, step 5350/7134 completed (loss: 0.16684621572494507, acc: 0.9352940917015076)
[2024-12-17 03:21:26,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:26,269][root][INFO] - Training Epoch: 2/2, step 5351/7134 completed (loss: 0.19003553688526154, acc: 0.9405405521392822)
[2024-12-17 03:21:26,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:26,616][root][INFO] - Training Epoch: 2/2, step 5352/7134 completed (loss: 0.15748649835586548, acc: 0.9520958065986633)
[2024-12-17 03:21:26,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:27,040][root][INFO] - Training Epoch: 2/2, step 5353/7134 completed (loss: 0.17990334331989288, acc: 0.9444444179534912)
[2024-12-17 03:21:27,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:27,457][root][INFO] - Training Epoch: 2/2, step 5354/7134 completed (loss: 0.1910249888896942, acc: 0.9583333134651184)
[2024-12-17 03:21:27,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:27,873][root][INFO] - Training Epoch: 2/2, step 5355/7134 completed (loss: 0.24117183685302734, acc: 0.953125)
[2024-12-17 03:21:28,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:28,270][root][INFO] - Training Epoch: 2/2, step 5356/7134 completed (loss: 0.19789324700832367, acc: 0.9521276354789734)
[2024-12-17 03:21:28,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:28,657][root][INFO] - Training Epoch: 2/2, step 5357/7134 completed (loss: 0.14256997406482697, acc: 0.957446813583374)
[2024-12-17 03:21:28,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:29,079][root][INFO] - Training Epoch: 2/2, step 5358/7134 completed (loss: 0.3365742266178131, acc: 0.9340659379959106)
[2024-12-17 03:21:29,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:29,486][root][INFO] - Training Epoch: 2/2, step 5359/7134 completed (loss: 0.11352822929620743, acc: 0.9605911374092102)
[2024-12-17 03:21:29,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:29,877][root][INFO] - Training Epoch: 2/2, step 5360/7134 completed (loss: 0.12663868069648743, acc: 0.9712643623352051)
[2024-12-17 03:21:30,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:30,285][root][INFO] - Training Epoch: 2/2, step 5361/7134 completed (loss: 0.2644404470920563, acc: 0.9390863180160522)
[2024-12-17 03:21:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:30,658][root][INFO] - Training Epoch: 2/2, step 5362/7134 completed (loss: 0.29356950521469116, acc: 0.9459459185600281)
[2024-12-17 03:21:30,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:31,063][root][INFO] - Training Epoch: 2/2, step 5363/7134 completed (loss: 0.14086788892745972, acc: 0.9634146094322205)
[2024-12-17 03:21:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:31,458][root][INFO] - Training Epoch: 2/2, step 5364/7134 completed (loss: 0.0996803417801857, acc: 0.9884393215179443)
[2024-12-17 03:21:31,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:31,870][root][INFO] - Training Epoch: 2/2, step 5365/7134 completed (loss: 0.09064043313264847, acc: 0.9696969985961914)
[2024-12-17 03:21:32,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:32,268][root][INFO] - Training Epoch: 2/2, step 5366/7134 completed (loss: 0.25796687602996826, acc: 0.9626865386962891)
[2024-12-17 03:21:32,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:32,777][root][INFO] - Training Epoch: 2/2, step 5367/7134 completed (loss: 0.13232854008674622, acc: 0.97826087474823)
[2024-12-17 03:21:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:33,196][root][INFO] - Training Epoch: 2/2, step 5368/7134 completed (loss: 0.1474427729845047, acc: 0.9844961166381836)
[2024-12-17 03:21:33,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:33,580][root][INFO] - Training Epoch: 2/2, step 5369/7134 completed (loss: 0.18885453045368195, acc: 0.9661017060279846)
[2024-12-17 03:21:33,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:33,976][root][INFO] - Training Epoch: 2/2, step 5370/7134 completed (loss: 0.21437959372997284, acc: 0.9610389471054077)
[2024-12-17 03:21:34,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:34,385][root][INFO] - Training Epoch: 2/2, step 5371/7134 completed (loss: 0.398173063993454, acc: 0.9133333563804626)
[2024-12-17 03:21:34,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:34,782][root][INFO] - Training Epoch: 2/2, step 5372/7134 completed (loss: 0.09203403443098068, acc: 0.9748427867889404)
[2024-12-17 03:21:34,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:35,145][root][INFO] - Training Epoch: 2/2, step 5373/7134 completed (loss: 0.09809722751379013, acc: 0.9603174328804016)
[2024-12-17 03:21:35,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:35,560][root][INFO] - Training Epoch: 2/2, step 5374/7134 completed (loss: 0.0395440012216568, acc: 1.0)
[2024-12-17 03:21:35,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:35,983][root][INFO] - Training Epoch: 2/2, step 5375/7134 completed (loss: 0.0613311305642128, acc: 1.0)
[2024-12-17 03:21:36,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:36,412][root][INFO] - Training Epoch: 2/2, step 5376/7134 completed (loss: 0.08517596870660782, acc: 0.9729729890823364)
[2024-12-17 03:21:36,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:36,828][root][INFO] - Training Epoch: 2/2, step 5377/7134 completed (loss: 0.08820253610610962, acc: 0.9814814925193787)
[2024-12-17 03:21:36,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:37,244][root][INFO] - Training Epoch: 2/2, step 5378/7134 completed (loss: 0.0429501086473465, acc: 0.9894737005233765)
[2024-12-17 03:21:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:37,645][root][INFO] - Training Epoch: 2/2, step 5379/7134 completed (loss: 0.040771763771772385, acc: 0.9947916865348816)
[2024-12-17 03:21:37,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:38,037][root][INFO] - Training Epoch: 2/2, step 5380/7134 completed (loss: 0.11750572919845581, acc: 0.9851852059364319)
[2024-12-17 03:21:38,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:38,417][root][INFO] - Training Epoch: 2/2, step 5381/7134 completed (loss: 0.05137370899319649, acc: 0.9887005686759949)
[2024-12-17 03:21:38,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:38,834][root][INFO] - Training Epoch: 2/2, step 5382/7134 completed (loss: 0.06281741708517075, acc: 0.9855072498321533)
[2024-12-17 03:21:38,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:39,227][root][INFO] - Training Epoch: 2/2, step 5383/7134 completed (loss: 0.07341961562633514, acc: 0.9838709831237793)
[2024-12-17 03:21:39,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:39,618][root][INFO] - Training Epoch: 2/2, step 5384/7134 completed (loss: 0.061285294592380524, acc: 0.989847719669342)
[2024-12-17 03:21:39,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:40,041][root][INFO] - Training Epoch: 2/2, step 5385/7134 completed (loss: 0.08320876210927963, acc: 0.9709302186965942)
[2024-12-17 03:21:40,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:40,444][root][INFO] - Training Epoch: 2/2, step 5386/7134 completed (loss: 0.0609445720911026, acc: 0.9780219793319702)
[2024-12-17 03:21:40,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:40,836][root][INFO] - Training Epoch: 2/2, step 5387/7134 completed (loss: 0.03586022928357124, acc: 0.9918032884597778)
[2024-12-17 03:21:40,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:41,232][root][INFO] - Training Epoch: 2/2, step 5388/7134 completed (loss: 0.04315440356731415, acc: 0.9888268113136292)
[2024-12-17 03:21:41,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:41,622][root][INFO] - Training Epoch: 2/2, step 5389/7134 completed (loss: 0.05389104038476944, acc: 0.9863945841789246)
[2024-12-17 03:21:41,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:42,007][root][INFO] - Training Epoch: 2/2, step 5390/7134 completed (loss: 0.11758255213499069, acc: 0.955974817276001)
[2024-12-17 03:21:42,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:42,385][root][INFO] - Training Epoch: 2/2, step 5391/7134 completed (loss: 0.13188685476779938, acc: 0.971222996711731)
[2024-12-17 03:21:42,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:42,769][root][INFO] - Training Epoch: 2/2, step 5392/7134 completed (loss: 0.16885851323604584, acc: 0.9602272510528564)
[2024-12-17 03:21:42,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:43,205][root][INFO] - Training Epoch: 2/2, step 5393/7134 completed (loss: 0.16260157525539398, acc: 0.9750000238418579)
[2024-12-17 03:21:43,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:43,623][root][INFO] - Training Epoch: 2/2, step 5394/7134 completed (loss: 0.39006510376930237, acc: 0.8984375)
[2024-12-17 03:21:43,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:44,007][root][INFO] - Training Epoch: 2/2, step 5395/7134 completed (loss: 0.10215476900339127, acc: 0.9797297120094299)
[2024-12-17 03:21:44,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:44,380][root][INFO] - Training Epoch: 2/2, step 5396/7134 completed (loss: 0.15230309963226318, acc: 0.9671052694320679)
[2024-12-17 03:21:44,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:44,759][root][INFO] - Training Epoch: 2/2, step 5397/7134 completed (loss: 0.12047331780195236, acc: 0.9716312289237976)
[2024-12-17 03:21:44,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:45,127][root][INFO] - Training Epoch: 2/2, step 5398/7134 completed (loss: 0.10374011844396591, acc: 0.9698795080184937)
[2024-12-17 03:21:45,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:45,506][root][INFO] - Training Epoch: 2/2, step 5399/7134 completed (loss: 0.1368231177330017, acc: 0.9657142758369446)
[2024-12-17 03:21:45,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:45,888][root][INFO] - Training Epoch: 2/2, step 5400/7134 completed (loss: 0.3722700774669647, acc: 0.9448275566101074)
[2024-12-17 03:21:45,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:46,272][root][INFO] - Training Epoch: 2/2, step 5401/7134 completed (loss: 0.09670895338058472, acc: 0.9652777910232544)
[2024-12-17 03:21:46,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:46,642][root][INFO] - Training Epoch: 2/2, step 5402/7134 completed (loss: 0.1280277967453003, acc: 0.9726027250289917)
[2024-12-17 03:21:46,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:46,991][root][INFO] - Training Epoch: 2/2, step 5403/7134 completed (loss: 0.18875166773796082, acc: 0.9426229596138)
[2024-12-17 03:21:47,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:47,358][root][INFO] - Training Epoch: 2/2, step 5404/7134 completed (loss: 0.3224601447582245, acc: 0.9328858852386475)
[2024-12-17 03:21:47,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:47,745][root][INFO] - Training Epoch: 2/2, step 5405/7134 completed (loss: 0.1604589819908142, acc: 0.939130425453186)
[2024-12-17 03:21:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:48,129][root][INFO] - Training Epoch: 2/2, step 5406/7134 completed (loss: 0.11008157581090927, acc: 0.9639639854431152)
[2024-12-17 03:21:48,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:48,472][root][INFO] - Training Epoch: 2/2, step 5407/7134 completed (loss: 0.2279403656721115, acc: 0.9450549483299255)
[2024-12-17 03:21:48,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:48,829][root][INFO] - Training Epoch: 2/2, step 5408/7134 completed (loss: 0.27948692440986633, acc: 0.9432623982429504)
[2024-12-17 03:21:48,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:49,218][root][INFO] - Training Epoch: 2/2, step 5409/7134 completed (loss: 0.2652789056301117, acc: 0.9440559148788452)
[2024-12-17 03:21:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:49,585][root][INFO] - Training Epoch: 2/2, step 5410/7134 completed (loss: 0.11618547886610031, acc: 0.9638554453849792)
[2024-12-17 03:21:49,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:49,954][root][INFO] - Training Epoch: 2/2, step 5411/7134 completed (loss: 0.36293625831604004, acc: 0.9295774698257446)
[2024-12-17 03:21:50,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:50,367][root][INFO] - Training Epoch: 2/2, step 5412/7134 completed (loss: 0.31282690167427063, acc: 0.9557521939277649)
[2024-12-17 03:21:50,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:50,802][root][INFO] - Training Epoch: 2/2, step 5413/7134 completed (loss: 0.2804334759712219, acc: 0.9027777910232544)
[2024-12-17 03:21:50,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:51,205][root][INFO] - Training Epoch: 2/2, step 5414/7134 completed (loss: 0.3813503682613373, acc: 0.8982036113739014)
[2024-12-17 03:21:51,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:51,581][root][INFO] - Training Epoch: 2/2, step 5415/7134 completed (loss: 0.3179211914539337, acc: 0.9415584206581116)
[2024-12-17 03:21:51,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:51,977][root][INFO] - Training Epoch: 2/2, step 5416/7134 completed (loss: 0.2525924742221832, acc: 0.9144384860992432)
[2024-12-17 03:21:52,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:52,348][root][INFO] - Training Epoch: 2/2, step 5417/7134 completed (loss: 0.12488067895174026, acc: 0.9615384340286255)
[2024-12-17 03:21:52,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:52,763][root][INFO] - Training Epoch: 2/2, step 5418/7134 completed (loss: 0.31934404373168945, acc: 0.9097222089767456)
[2024-12-17 03:21:52,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:53,153][root][INFO] - Training Epoch: 2/2, step 5419/7134 completed (loss: 0.41678735613822937, acc: 0.9051094651222229)
[2024-12-17 03:21:53,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:53,534][root][INFO] - Training Epoch: 2/2, step 5420/7134 completed (loss: 0.4840589761734009, acc: 0.8872180581092834)
[2024-12-17 03:21:53,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:53,902][root][INFO] - Training Epoch: 2/2, step 5421/7134 completed (loss: 0.4380621016025543, acc: 0.8999999761581421)
[2024-12-17 03:21:54,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:54,287][root][INFO] - Training Epoch: 2/2, step 5422/7134 completed (loss: 0.19139987230300903, acc: 0.9444444179534912)
[2024-12-17 03:21:54,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:54,634][root][INFO] - Training Epoch: 2/2, step 5423/7134 completed (loss: 0.20983156561851501, acc: 0.949999988079071)
[2024-12-17 03:21:54,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:55,034][root][INFO] - Training Epoch: 2/2, step 5424/7134 completed (loss: 0.19536088407039642, acc: 0.9461538195610046)
[2024-12-17 03:21:55,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:55,396][root][INFO] - Training Epoch: 2/2, step 5425/7134 completed (loss: 0.20847594738006592, acc: 0.953125)
[2024-12-17 03:21:55,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:55,763][root][INFO] - Training Epoch: 2/2, step 5426/7134 completed (loss: 0.2528998851776123, acc: 0.9672130942344666)
[2024-12-17 03:21:55,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:56,131][root][INFO] - Training Epoch: 2/2, step 5427/7134 completed (loss: 0.1212228387594223, acc: 0.9803921580314636)
[2024-12-17 03:21:56,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:56,502][root][INFO] - Training Epoch: 2/2, step 5428/7134 completed (loss: 0.19889099895954132, acc: 0.9379310607910156)
[2024-12-17 03:21:56,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:56,864][root][INFO] - Training Epoch: 2/2, step 5429/7134 completed (loss: 0.20142130553722382, acc: 0.9597315192222595)
[2024-12-17 03:21:56,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:57,231][root][INFO] - Training Epoch: 2/2, step 5430/7134 completed (loss: 0.2577263116836548, acc: 0.948051929473877)
[2024-12-17 03:21:57,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:57,618][root][INFO] - Training Epoch: 2/2, step 5431/7134 completed (loss: 0.21189995110034943, acc: 0.932330846786499)
[2024-12-17 03:21:57,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:58,004][root][INFO] - Training Epoch: 2/2, step 5432/7134 completed (loss: 0.09295203536748886, acc: 0.96875)
[2024-12-17 03:21:58,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:58,389][root][INFO] - Training Epoch: 2/2, step 5433/7134 completed (loss: 0.27070024609565735, acc: 0.9327731132507324)
[2024-12-17 03:21:58,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:58,768][root][INFO] - Training Epoch: 2/2, step 5434/7134 completed (loss: 0.31852930784225464, acc: 0.9354838728904724)
[2024-12-17 03:21:58,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:59,149][root][INFO] - Training Epoch: 2/2, step 5435/7134 completed (loss: 0.1874103844165802, acc: 0.9520000219345093)
[2024-12-17 03:21:59,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:59,488][root][INFO] - Training Epoch: 2/2, step 5436/7134 completed (loss: 0.1729028970003128, acc: 0.9612902998924255)
[2024-12-17 03:21:59,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:21:59,866][root][INFO] - Training Epoch: 2/2, step 5437/7134 completed (loss: 0.16273939609527588, acc: 0.969924807548523)
[2024-12-17 03:21:59,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:00,239][root][INFO] - Training Epoch: 2/2, step 5438/7134 completed (loss: 0.2500539720058441, acc: 0.9388889074325562)
[2024-12-17 03:22:00,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:00,616][root][INFO] - Training Epoch: 2/2, step 5439/7134 completed (loss: 0.33832108974456787, acc: 0.9212121367454529)
[2024-12-17 03:22:00,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:00,986][root][INFO] - Training Epoch: 2/2, step 5440/7134 completed (loss: 0.2162330150604248, acc: 0.949999988079071)
[2024-12-17 03:22:01,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:01,348][root][INFO] - Training Epoch: 2/2, step 5441/7134 completed (loss: 0.2275233119726181, acc: 0.9405405521392822)
[2024-12-17 03:22:01,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:01,718][root][INFO] - Training Epoch: 2/2, step 5442/7134 completed (loss: 0.1330433040857315, acc: 0.9642857313156128)
[2024-12-17 03:22:01,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:02,068][root][INFO] - Training Epoch: 2/2, step 5443/7134 completed (loss: 0.16030606627464294, acc: 0.9634146094322205)
[2024-12-17 03:22:02,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:02,444][root][INFO] - Training Epoch: 2/2, step 5444/7134 completed (loss: 0.15059463679790497, acc: 0.970588207244873)
[2024-12-17 03:22:02,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:02,813][root][INFO] - Training Epoch: 2/2, step 5445/7134 completed (loss: 0.2882356643676758, acc: 0.8970588445663452)
[2024-12-17 03:22:02,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:03,179][root][INFO] - Training Epoch: 2/2, step 5446/7134 completed (loss: 0.1556215137243271, acc: 0.9570552110671997)
[2024-12-17 03:22:03,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:03,555][root][INFO] - Training Epoch: 2/2, step 5447/7134 completed (loss: 0.2414446771144867, acc: 0.9383561611175537)
[2024-12-17 03:22:03,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:03,955][root][INFO] - Training Epoch: 2/2, step 5448/7134 completed (loss: 0.1961527168750763, acc: 0.9450549483299255)
[2024-12-17 03:22:04,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:04,319][root][INFO] - Training Epoch: 2/2, step 5449/7134 completed (loss: 0.22440487146377563, acc: 0.9590163826942444)
[2024-12-17 03:22:04,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:04,694][root][INFO] - Training Epoch: 2/2, step 5450/7134 completed (loss: 0.20222687721252441, acc: 0.9666666388511658)
[2024-12-17 03:22:04,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:05,073][root][INFO] - Training Epoch: 2/2, step 5451/7134 completed (loss: 0.05884615704417229, acc: 0.9940828680992126)
[2024-12-17 03:22:05,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:05,458][root][INFO] - Training Epoch: 2/2, step 5452/7134 completed (loss: 0.14185531437397003, acc: 0.9644970297813416)
[2024-12-17 03:22:05,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:05,831][root][INFO] - Training Epoch: 2/2, step 5453/7134 completed (loss: 0.22705478966236115, acc: 0.9555555582046509)
[2024-12-17 03:22:05,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:06,194][root][INFO] - Training Epoch: 2/2, step 5454/7134 completed (loss: 0.12847599387168884, acc: 0.9836956262588501)
[2024-12-17 03:22:06,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:06,569][root][INFO] - Training Epoch: 2/2, step 5455/7134 completed (loss: 0.22035565972328186, acc: 0.9572192430496216)
[2024-12-17 03:22:06,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:06,946][root][INFO] - Training Epoch: 2/2, step 5456/7134 completed (loss: 0.14758102595806122, acc: 0.9677419066429138)
[2024-12-17 03:22:07,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:07,332][root][INFO] - Training Epoch: 2/2, step 5457/7134 completed (loss: 0.1778137981891632, acc: 0.9425287246704102)
[2024-12-17 03:22:07,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:07,713][root][INFO] - Training Epoch: 2/2, step 5458/7134 completed (loss: 0.14260324835777283, acc: 0.9668508172035217)
[2024-12-17 03:22:07,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:08,082][root][INFO] - Training Epoch: 2/2, step 5459/7134 completed (loss: 0.039513252675533295, acc: 0.987730085849762)
[2024-12-17 03:22:08,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:08,431][root][INFO] - Training Epoch: 2/2, step 5460/7134 completed (loss: 0.06812214851379395, acc: 0.9881656765937805)
[2024-12-17 03:22:08,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:08,800][root][INFO] - Training Epoch: 2/2, step 5461/7134 completed (loss: 0.29290682077407837, acc: 0.9266055226325989)
[2024-12-17 03:22:08,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:09,147][root][INFO] - Training Epoch: 2/2, step 5462/7134 completed (loss: 0.08380787074565887, acc: 0.9754601120948792)
[2024-12-17 03:22:09,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:09,514][root][INFO] - Training Epoch: 2/2, step 5463/7134 completed (loss: 0.23746268451213837, acc: 0.9506173133850098)
[2024-12-17 03:22:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:09,884][root][INFO] - Training Epoch: 2/2, step 5464/7134 completed (loss: 0.24379420280456543, acc: 0.9508196711540222)
[2024-12-17 03:22:10,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:10,263][root][INFO] - Training Epoch: 2/2, step 5465/7134 completed (loss: 0.10453145205974579, acc: 0.9937499761581421)
[2024-12-17 03:22:10,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:10,645][root][INFO] - Training Epoch: 2/2, step 5466/7134 completed (loss: 0.1206469014286995, acc: 0.9701492786407471)
[2024-12-17 03:22:10,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:11,020][root][INFO] - Training Epoch: 2/2, step 5467/7134 completed (loss: 0.07231862843036652, acc: 0.9800994992256165)
[2024-12-17 03:22:11,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:11,391][root][INFO] - Training Epoch: 2/2, step 5468/7134 completed (loss: 0.1154107078909874, acc: 0.9685863852500916)
[2024-12-17 03:22:11,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:11,755][root][INFO] - Training Epoch: 2/2, step 5469/7134 completed (loss: 0.1712295562028885, acc: 0.9523809552192688)
[2024-12-17 03:22:11,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:12,129][root][INFO] - Training Epoch: 2/2, step 5470/7134 completed (loss: 0.042821455746889114, acc: 0.9950248599052429)
[2024-12-17 03:22:12,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:12,497][root][INFO] - Training Epoch: 2/2, step 5471/7134 completed (loss: 0.06832534819841385, acc: 0.9823529124259949)
[2024-12-17 03:22:12,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:12,882][root][INFO] - Training Epoch: 2/2, step 5472/7134 completed (loss: 0.14281389117240906, acc: 0.9720670580863953)
[2024-12-17 03:22:12,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:13,259][root][INFO] - Training Epoch: 2/2, step 5473/7134 completed (loss: 0.03829449042677879, acc: 0.9949495196342468)
[2024-12-17 03:22:13,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:13,631][root][INFO] - Training Epoch: 2/2, step 5474/7134 completed (loss: 0.12727046012878418, acc: 0.9757575988769531)
[2024-12-17 03:22:13,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:13,985][root][INFO] - Training Epoch: 2/2, step 5475/7134 completed (loss: 0.041467178612947464, acc: 0.9938271641731262)
[2024-12-17 03:22:14,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:14,334][root][INFO] - Training Epoch: 2/2, step 5476/7134 completed (loss: 0.024922018870711327, acc: 0.9935064911842346)
[2024-12-17 03:22:14,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:14,707][root][INFO] - Training Epoch: 2/2, step 5477/7134 completed (loss: 0.045457206666469574, acc: 0.9948979616165161)
[2024-12-17 03:22:14,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:15,095][root][INFO] - Training Epoch: 2/2, step 5478/7134 completed (loss: 0.17075228691101074, acc: 0.9555555582046509)
[2024-12-17 03:22:15,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:15,487][root][INFO] - Training Epoch: 2/2, step 5479/7134 completed (loss: 0.16249899566173553, acc: 0.9662162065505981)
[2024-12-17 03:22:15,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:15,871][root][INFO] - Training Epoch: 2/2, step 5480/7134 completed (loss: 0.20347639918327332, acc: 0.9345238208770752)
[2024-12-17 03:22:15,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:16,196][root][INFO] - Training Epoch: 2/2, step 5481/7134 completed (loss: 0.14189620316028595, acc: 0.9672130942344666)
[2024-12-17 03:22:16,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:16,791][root][INFO] - Training Epoch: 2/2, step 5482/7134 completed (loss: 0.3627433776855469, acc: 0.9175257682800293)
[2024-12-17 03:22:16,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:17,213][root][INFO] - Training Epoch: 2/2, step 5483/7134 completed (loss: 0.1757076382637024, acc: 0.9515151381492615)
[2024-12-17 03:22:17,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:17,577][root][INFO] - Training Epoch: 2/2, step 5484/7134 completed (loss: 0.19009357690811157, acc: 0.9444444179534912)
[2024-12-17 03:22:17,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:17,931][root][INFO] - Training Epoch: 2/2, step 5485/7134 completed (loss: 0.17434585094451904, acc: 0.9516128897666931)
[2024-12-17 03:22:18,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:18,298][root][INFO] - Training Epoch: 2/2, step 5486/7134 completed (loss: 0.23630954325199127, acc: 0.9242424368858337)
[2024-12-17 03:22:18,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:18,650][root][INFO] - Training Epoch: 2/2, step 5487/7134 completed (loss: 0.16430285573005676, acc: 0.9523809552192688)
[2024-12-17 03:22:18,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:19,030][root][INFO] - Training Epoch: 2/2, step 5488/7134 completed (loss: 0.27516916394233704, acc: 0.9341317415237427)
[2024-12-17 03:22:19,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:19,433][root][INFO] - Training Epoch: 2/2, step 5489/7134 completed (loss: 0.38595566153526306, acc: 0.8658536672592163)
[2024-12-17 03:22:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:19,812][root][INFO] - Training Epoch: 2/2, step 5490/7134 completed (loss: 0.1656114161014557, acc: 0.9595959782600403)
[2024-12-17 03:22:19,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:20,184][root][INFO] - Training Epoch: 2/2, step 5491/7134 completed (loss: 0.12462842464447021, acc: 0.9766082167625427)
[2024-12-17 03:22:20,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:20,559][root][INFO] - Training Epoch: 2/2, step 5492/7134 completed (loss: 0.18866358697414398, acc: 0.9477611780166626)
[2024-12-17 03:22:20,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:20,888][root][INFO] - Training Epoch: 2/2, step 5493/7134 completed (loss: 0.29431959986686707, acc: 0.9166666865348816)
[2024-12-17 03:22:20,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:21,262][root][INFO] - Training Epoch: 2/2, step 5494/7134 completed (loss: 0.12918201088905334, acc: 0.9685534834861755)
[2024-12-17 03:22:21,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:21,648][root][INFO] - Training Epoch: 2/2, step 5495/7134 completed (loss: 0.12182486802339554, acc: 0.969924807548523)
[2024-12-17 03:22:21,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:22,048][root][INFO] - Training Epoch: 2/2, step 5496/7134 completed (loss: 0.12387137860059738, acc: 0.9682539701461792)
[2024-12-17 03:22:22,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:22,382][root][INFO] - Training Epoch: 2/2, step 5497/7134 completed (loss: 0.21389077603816986, acc: 0.9470587968826294)
[2024-12-17 03:22:22,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:22,749][root][INFO] - Training Epoch: 2/2, step 5498/7134 completed (loss: 0.2603839635848999, acc: 0.9468085169792175)
[2024-12-17 03:22:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:23,141][root][INFO] - Training Epoch: 2/2, step 5499/7134 completed (loss: 0.22313499450683594, acc: 0.9279279112815857)
[2024-12-17 03:22:23,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:23,503][root][INFO] - Training Epoch: 2/2, step 5500/7134 completed (loss: 0.1266924887895584, acc: 0.9585492014884949)
[2024-12-17 03:22:23,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:23,889][root][INFO] - Training Epoch: 2/2, step 5501/7134 completed (loss: 0.15851633250713348, acc: 0.9595959782600403)
[2024-12-17 03:22:24,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:24,270][root][INFO] - Training Epoch: 2/2, step 5502/7134 completed (loss: 0.15347465872764587, acc: 0.9548022747039795)
[2024-12-17 03:22:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:24,634][root][INFO] - Training Epoch: 2/2, step 5503/7134 completed (loss: 0.3216594457626343, acc: 0.9384615421295166)
[2024-12-17 03:22:24,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:25,004][root][INFO] - Training Epoch: 2/2, step 5504/7134 completed (loss: 0.24257612228393555, acc: 0.9518072009086609)
[2024-12-17 03:22:25,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:25,383][root][INFO] - Training Epoch: 2/2, step 5505/7134 completed (loss: 0.29144027829170227, acc: 0.9090909361839294)
[2024-12-17 03:22:25,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:25,752][root][INFO] - Training Epoch: 2/2, step 5506/7134 completed (loss: 0.3060790002346039, acc: 0.9292929172515869)
[2024-12-17 03:22:25,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:26,120][root][INFO] - Training Epoch: 2/2, step 5507/7134 completed (loss: 0.15214167535305023, acc: 0.9532163739204407)
[2024-12-17 03:22:26,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:26,495][root][INFO] - Training Epoch: 2/2, step 5508/7134 completed (loss: 0.1499088853597641, acc: 0.9665071964263916)
[2024-12-17 03:22:26,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:26,869][root][INFO] - Training Epoch: 2/2, step 5509/7134 completed (loss: 0.22443413734436035, acc: 0.9620853066444397)
[2024-12-17 03:22:26,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:27,241][root][INFO] - Training Epoch: 2/2, step 5510/7134 completed (loss: 0.3198768198490143, acc: 0.9139785170555115)
[2024-12-17 03:22:27,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:27,615][root][INFO] - Training Epoch: 2/2, step 5511/7134 completed (loss: 0.20840126276016235, acc: 0.9563106894493103)
[2024-12-17 03:22:27,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:27,977][root][INFO] - Training Epoch: 2/2, step 5512/7134 completed (loss: 0.2643887400627136, acc: 0.9450549483299255)
[2024-12-17 03:22:28,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:28,342][root][INFO] - Training Epoch: 2/2, step 5513/7134 completed (loss: 0.2746676504611969, acc: 0.9053254723548889)
[2024-12-17 03:22:28,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:28,697][root][INFO] - Training Epoch: 2/2, step 5514/7134 completed (loss: 0.39891278743743896, acc: 0.8981481194496155)
[2024-12-17 03:22:28,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:29,055][root][INFO] - Training Epoch: 2/2, step 5515/7134 completed (loss: 0.2517871558666229, acc: 0.9285714030265808)
[2024-12-17 03:22:29,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:29,423][root][INFO] - Training Epoch: 2/2, step 5516/7134 completed (loss: 0.17969205975532532, acc: 0.9655172228813171)
[2024-12-17 03:22:29,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:29,799][root][INFO] - Training Epoch: 2/2, step 5517/7134 completed (loss: 0.15647757053375244, acc: 0.9664804339408875)
[2024-12-17 03:22:29,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:30,197][root][INFO] - Training Epoch: 2/2, step 5518/7134 completed (loss: 0.20153406262397766, acc: 0.9388889074325562)
[2024-12-17 03:22:30,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:30,558][root][INFO] - Training Epoch: 2/2, step 5519/7134 completed (loss: 0.12421033531427383, acc: 0.9567901492118835)
[2024-12-17 03:22:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:30,925][root][INFO] - Training Epoch: 2/2, step 5520/7134 completed (loss: 0.1323576271533966, acc: 0.9620853066444397)
[2024-12-17 03:22:31,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:31,294][root][INFO] - Training Epoch: 2/2, step 5521/7134 completed (loss: 0.19704189896583557, acc: 0.9424083828926086)
[2024-12-17 03:22:31,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:31,656][root][INFO] - Training Epoch: 2/2, step 5522/7134 completed (loss: 0.2864045798778534, acc: 0.9109947681427002)
[2024-12-17 03:22:31,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:32,025][root][INFO] - Training Epoch: 2/2, step 5523/7134 completed (loss: 0.20524781942367554, acc: 0.9340659379959106)
[2024-12-17 03:22:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:32,394][root][INFO] - Training Epoch: 2/2, step 5524/7134 completed (loss: 0.35862910747528076, acc: 0.9113923907279968)
[2024-12-17 03:22:32,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:32,756][root][INFO] - Training Epoch: 2/2, step 5525/7134 completed (loss: 0.1376585215330124, acc: 0.9634146094322205)
[2024-12-17 03:22:32,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:33,140][root][INFO] - Training Epoch: 2/2, step 5526/7134 completed (loss: 0.13671323657035828, acc: 0.9627329111099243)
[2024-12-17 03:22:33,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:33,504][root][INFO] - Training Epoch: 2/2, step 5527/7134 completed (loss: 0.18532346189022064, acc: 0.9650349617004395)
[2024-12-17 03:22:33,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:33,858][root][INFO] - Training Epoch: 2/2, step 5528/7134 completed (loss: 0.2205701619386673, acc: 0.9444444179534912)
[2024-12-17 03:22:33,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:34,239][root][INFO] - Training Epoch: 2/2, step 5529/7134 completed (loss: 0.12843860685825348, acc: 0.9727272987365723)
[2024-12-17 03:22:34,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:34,610][root][INFO] - Training Epoch: 2/2, step 5530/7134 completed (loss: 0.14800608158111572, acc: 0.9591836929321289)
[2024-12-17 03:22:34,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:34,997][root][INFO] - Training Epoch: 2/2, step 5531/7134 completed (loss: 0.14212022721767426, acc: 0.9578313231468201)
[2024-12-17 03:22:35,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:35,385][root][INFO] - Training Epoch: 2/2, step 5532/7134 completed (loss: 0.20748117566108704, acc: 0.9435028433799744)
[2024-12-17 03:22:35,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:35,767][root][INFO] - Training Epoch: 2/2, step 5533/7134 completed (loss: 0.04857969284057617, acc: 0.9944444298744202)
[2024-12-17 03:22:35,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:36,166][root][INFO] - Training Epoch: 2/2, step 5534/7134 completed (loss: 0.2597157955169678, acc: 0.915730357170105)
[2024-12-17 03:22:36,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:36,545][root][INFO] - Training Epoch: 2/2, step 5535/7134 completed (loss: 0.12117155641317368, acc: 0.9585492014884949)
[2024-12-17 03:22:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:36,928][root][INFO] - Training Epoch: 2/2, step 5536/7134 completed (loss: 0.16718079149723053, acc: 0.9398906826972961)
[2024-12-17 03:22:37,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:37,307][root][INFO] - Training Epoch: 2/2, step 5537/7134 completed (loss: 0.14031578600406647, acc: 0.9712643623352051)
[2024-12-17 03:22:37,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:37,672][root][INFO] - Training Epoch: 2/2, step 5538/7134 completed (loss: 0.12861843407154083, acc: 0.9790576100349426)
[2024-12-17 03:22:37,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:38,072][root][INFO] - Training Epoch: 2/2, step 5539/7134 completed (loss: 0.13520166277885437, acc: 0.9617486596107483)
[2024-12-17 03:22:38,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:38,433][root][INFO] - Training Epoch: 2/2, step 5540/7134 completed (loss: 0.20282016694545746, acc: 0.9638554453849792)
[2024-12-17 03:22:38,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:38,798][root][INFO] - Training Epoch: 2/2, step 5541/7134 completed (loss: 0.08500517159700394, acc: 0.9825581312179565)
[2024-12-17 03:22:38,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:39,184][root][INFO] - Training Epoch: 2/2, step 5542/7134 completed (loss: 0.037001948803663254, acc: 1.0)
[2024-12-17 03:22:39,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:39,567][root][INFO] - Training Epoch: 2/2, step 5543/7134 completed (loss: 0.10367525368928909, acc: 0.9839572310447693)
[2024-12-17 03:22:39,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:39,930][root][INFO] - Training Epoch: 2/2, step 5544/7134 completed (loss: 0.08133319765329361, acc: 0.9890710115432739)
[2024-12-17 03:22:40,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:40,305][root][INFO] - Training Epoch: 2/2, step 5545/7134 completed (loss: 0.1203470453619957, acc: 0.9821428656578064)
[2024-12-17 03:22:40,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:40,677][root][INFO] - Training Epoch: 2/2, step 5546/7134 completed (loss: 0.12134087085723877, acc: 0.970059871673584)
[2024-12-17 03:22:40,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:41,053][root][INFO] - Training Epoch: 2/2, step 5547/7134 completed (loss: 0.12603896856307983, acc: 0.9668508172035217)
[2024-12-17 03:22:41,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:41,411][root][INFO] - Training Epoch: 2/2, step 5548/7134 completed (loss: 0.09328757226467133, acc: 0.9823529124259949)
[2024-12-17 03:22:41,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:41,744][root][INFO] - Training Epoch: 2/2, step 5549/7134 completed (loss: 0.1399715542793274, acc: 0.9597315192222595)
[2024-12-17 03:22:41,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:42,095][root][INFO] - Training Epoch: 2/2, step 5550/7134 completed (loss: 0.09196597337722778, acc: 0.983146071434021)
[2024-12-17 03:22:42,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:42,462][root][INFO] - Training Epoch: 2/2, step 5551/7134 completed (loss: 0.2476380616426468, acc: 0.9419354796409607)
[2024-12-17 03:22:42,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:42,828][root][INFO] - Training Epoch: 2/2, step 5552/7134 completed (loss: 0.07469216734170914, acc: 0.9815950989723206)
[2024-12-17 03:22:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:43,175][root][INFO] - Training Epoch: 2/2, step 5553/7134 completed (loss: 0.17938463389873505, acc: 0.9526627063751221)
[2024-12-17 03:22:43,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:43,538][root][INFO] - Training Epoch: 2/2, step 5554/7134 completed (loss: 0.09991390258073807, acc: 0.9808917045593262)
[2024-12-17 03:22:43,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:43,892][root][INFO] - Training Epoch: 2/2, step 5555/7134 completed (loss: 0.18491490185260773, acc: 0.9642857313156128)
[2024-12-17 03:22:43,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:44,245][root][INFO] - Training Epoch: 2/2, step 5556/7134 completed (loss: 0.2525189518928528, acc: 0.9441340565681458)
[2024-12-17 03:22:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:44,633][root][INFO] - Training Epoch: 2/2, step 5557/7134 completed (loss: 0.17009830474853516, acc: 0.9627329111099243)
[2024-12-17 03:22:44,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:45,026][root][INFO] - Training Epoch: 2/2, step 5558/7134 completed (loss: 0.12083066254854202, acc: 0.9722222089767456)
[2024-12-17 03:22:45,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:45,389][root][INFO] - Training Epoch: 2/2, step 5559/7134 completed (loss: 0.21061019599437714, acc: 0.9608938694000244)
[2024-12-17 03:22:45,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:45,746][root][INFO] - Training Epoch: 2/2, step 5560/7134 completed (loss: 0.2770383358001709, acc: 0.9388889074325562)
[2024-12-17 03:22:45,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:46,147][root][INFO] - Training Epoch: 2/2, step 5561/7134 completed (loss: 0.22841617465019226, acc: 0.9672130942344666)
[2024-12-17 03:22:46,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:46,518][root][INFO] - Training Epoch: 2/2, step 5562/7134 completed (loss: 0.20198021829128265, acc: 0.9568345546722412)
[2024-12-17 03:22:46,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:46,867][root][INFO] - Training Epoch: 2/2, step 5563/7134 completed (loss: 0.07783462107181549, acc: 0.9722222089767456)
[2024-12-17 03:22:46,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:47,235][root][INFO] - Training Epoch: 2/2, step 5564/7134 completed (loss: 0.11992631107568741, acc: 0.96875)
[2024-12-17 03:22:47,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:47,622][root][INFO] - Training Epoch: 2/2, step 5565/7134 completed (loss: 0.054541561752557755, acc: 0.9866666793823242)
[2024-12-17 03:22:47,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:48,006][root][INFO] - Training Epoch: 2/2, step 5566/7134 completed (loss: 0.0590214766561985, acc: 0.989847719669342)
[2024-12-17 03:22:48,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:48,397][root][INFO] - Training Epoch: 2/2, step 5567/7134 completed (loss: 0.03718771040439606, acc: 0.9950248599052429)
[2024-12-17 03:22:48,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:48,806][root][INFO] - Training Epoch: 2/2, step 5568/7134 completed (loss: 0.04686488211154938, acc: 0.9945054650306702)
[2024-12-17 03:22:48,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:49,199][root][INFO] - Training Epoch: 2/2, step 5569/7134 completed (loss: 0.048610106110572815, acc: 0.9947916865348816)
[2024-12-17 03:22:49,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:49,570][root][INFO] - Training Epoch: 2/2, step 5570/7134 completed (loss: 0.05723731592297554, acc: 0.9836956262588501)
[2024-12-17 03:22:49,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:49,919][root][INFO] - Training Epoch: 2/2, step 5571/7134 completed (loss: 0.1413014680147171, acc: 0.9810126423835754)
[2024-12-17 03:22:50,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:50,271][root][INFO] - Training Epoch: 2/2, step 5572/7134 completed (loss: 0.09657193720340729, acc: 0.9815950989723206)
[2024-12-17 03:22:50,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:50,652][root][INFO] - Training Epoch: 2/2, step 5573/7134 completed (loss: 0.0926768034696579, acc: 0.9869281053543091)
[2024-12-17 03:22:50,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:51,008][root][INFO] - Training Epoch: 2/2, step 5574/7134 completed (loss: 0.06767257302999496, acc: 0.9791666865348816)
[2024-12-17 03:22:51,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:51,396][root][INFO] - Training Epoch: 2/2, step 5575/7134 completed (loss: 0.20975156128406525, acc: 0.95333331823349)
[2024-12-17 03:22:51,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:51,767][root][INFO] - Training Epoch: 2/2, step 5576/7134 completed (loss: 0.0650329440832138, acc: 0.9940476417541504)
[2024-12-17 03:22:51,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:52,143][root][INFO] - Training Epoch: 2/2, step 5577/7134 completed (loss: 0.29027360677719116, acc: 0.9111111164093018)
[2024-12-17 03:22:52,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:52,518][root][INFO] - Training Epoch: 2/2, step 5578/7134 completed (loss: 0.17765170335769653, acc: 0.9556962251663208)
[2024-12-17 03:22:52,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:52,898][root][INFO] - Training Epoch: 2/2, step 5579/7134 completed (loss: 0.12489336729049683, acc: 0.9509202241897583)
[2024-12-17 03:22:53,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:53,275][root][INFO] - Training Epoch: 2/2, step 5580/7134 completed (loss: 0.10580050945281982, acc: 0.9722222089767456)
[2024-12-17 03:22:53,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:53,685][root][INFO] - Training Epoch: 2/2, step 5581/7134 completed (loss: 0.10462786257266998, acc: 0.9818181991577148)
[2024-12-17 03:22:53,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:54,080][root][INFO] - Training Epoch: 2/2, step 5582/7134 completed (loss: 0.1270415186882019, acc: 0.9779005646705627)
[2024-12-17 03:22:54,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:54,466][root][INFO] - Training Epoch: 2/2, step 5583/7134 completed (loss: 0.10279471427202225, acc: 0.9748743772506714)
[2024-12-17 03:22:54,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:54,830][root][INFO] - Training Epoch: 2/2, step 5584/7134 completed (loss: 0.21723218262195587, acc: 0.9556962251663208)
[2024-12-17 03:22:54,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:55,213][root][INFO] - Training Epoch: 2/2, step 5585/7134 completed (loss: 0.18135087192058563, acc: 0.9560975432395935)
[2024-12-17 03:22:55,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:55,582][root][INFO] - Training Epoch: 2/2, step 5586/7134 completed (loss: 0.10634683072566986, acc: 0.9795918464660645)
[2024-12-17 03:22:55,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:55,968][root][INFO] - Training Epoch: 2/2, step 5587/7134 completed (loss: 0.10335750877857208, acc: 0.9657142758369446)
[2024-12-17 03:22:56,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:56,350][root][INFO] - Training Epoch: 2/2, step 5588/7134 completed (loss: 0.09742598235607147, acc: 0.9691358208656311)
[2024-12-17 03:22:56,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:56,714][root][INFO] - Training Epoch: 2/2, step 5589/7134 completed (loss: 0.16444134712219238, acc: 0.9627329111099243)
[2024-12-17 03:22:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:57,068][root][INFO] - Training Epoch: 2/2, step 5590/7134 completed (loss: 0.16714312136173248, acc: 0.9653179049491882)
[2024-12-17 03:22:57,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:57,416][root][INFO] - Training Epoch: 2/2, step 5591/7134 completed (loss: 0.05316019430756569, acc: 0.9884393215179443)
[2024-12-17 03:22:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:57,765][root][INFO] - Training Epoch: 2/2, step 5592/7134 completed (loss: 0.11905670166015625, acc: 0.9767441749572754)
[2024-12-17 03:22:57,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:58,127][root][INFO] - Training Epoch: 2/2, step 5593/7134 completed (loss: 0.11508870869874954, acc: 0.9728260636329651)
[2024-12-17 03:22:58,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:58,515][root][INFO] - Training Epoch: 2/2, step 5594/7134 completed (loss: 0.06763288378715515, acc: 0.9886363744735718)
[2024-12-17 03:22:58,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:58,884][root][INFO] - Training Epoch: 2/2, step 5595/7134 completed (loss: 0.11009965091943741, acc: 0.9659090638160706)
[2024-12-17 03:22:59,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:59,256][root][INFO] - Training Epoch: 2/2, step 5596/7134 completed (loss: 0.052055977284908295, acc: 0.976047933101654)
[2024-12-17 03:22:59,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:22:59,646][root][INFO] - Training Epoch: 2/2, step 5597/7134 completed (loss: 0.208976149559021, acc: 0.9638554453849792)
[2024-12-17 03:22:59,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:00,033][root][INFO] - Training Epoch: 2/2, step 5598/7134 completed (loss: 0.10575494170188904, acc: 0.9653179049491882)
[2024-12-17 03:23:00,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:00,422][root][INFO] - Training Epoch: 2/2, step 5599/7134 completed (loss: 0.20227575302124023, acc: 0.9591836929321289)
[2024-12-17 03:23:00,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:00,786][root][INFO] - Training Epoch: 2/2, step 5600/7134 completed (loss: 0.08983881026506424, acc: 0.9857142567634583)
[2024-12-17 03:23:00,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:01,141][root][INFO] - Training Epoch: 2/2, step 5601/7134 completed (loss: 0.16159428656101227, acc: 0.9618320465087891)
[2024-12-17 03:23:01,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:01,510][root][INFO] - Training Epoch: 2/2, step 5602/7134 completed (loss: 0.19673435389995575, acc: 0.9507042169570923)
[2024-12-17 03:23:01,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:01,865][root][INFO] - Training Epoch: 2/2, step 5603/7134 completed (loss: 0.14869287610054016, acc: 0.9508196711540222)
[2024-12-17 03:23:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:02,199][root][INFO] - Training Epoch: 2/2, step 5604/7134 completed (loss: 0.18292291462421417, acc: 0.9593495726585388)
[2024-12-17 03:23:02,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:02,552][root][INFO] - Training Epoch: 2/2, step 5605/7134 completed (loss: 0.18611757457256317, acc: 0.9448819160461426)
[2024-12-17 03:23:02,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:02,875][root][INFO] - Training Epoch: 2/2, step 5606/7134 completed (loss: 0.21227644383907318, acc: 0.9532710313796997)
[2024-12-17 03:23:02,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:03,226][root][INFO] - Training Epoch: 2/2, step 5607/7134 completed (loss: 0.05643845722079277, acc: 0.9784172773361206)
[2024-12-17 03:23:03,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:03,590][root][INFO] - Training Epoch: 2/2, step 5608/7134 completed (loss: 0.14606332778930664, acc: 0.9689922332763672)
[2024-12-17 03:23:03,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:03,953][root][INFO] - Training Epoch: 2/2, step 5609/7134 completed (loss: 0.09580705314874649, acc: 0.9833333492279053)
[2024-12-17 03:23:04,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:04,322][root][INFO] - Training Epoch: 2/2, step 5610/7134 completed (loss: 0.05239122733473778, acc: 0.9727272987365723)
[2024-12-17 03:23:04,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:04,704][root][INFO] - Training Epoch: 2/2, step 5611/7134 completed (loss: 0.16056056320667267, acc: 0.9552238583564758)
[2024-12-17 03:23:04,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:05,075][root][INFO] - Training Epoch: 2/2, step 5612/7134 completed (loss: 0.1471845954656601, acc: 0.9577465057373047)
[2024-12-17 03:23:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:05,464][root][INFO] - Training Epoch: 2/2, step 5613/7134 completed (loss: 0.20823168754577637, acc: 0.9285714030265808)
[2024-12-17 03:23:05,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:05,826][root][INFO] - Training Epoch: 2/2, step 5614/7134 completed (loss: 0.2196786105632782, acc: 0.9597315192222595)
[2024-12-17 03:23:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:06,160][root][INFO] - Training Epoch: 2/2, step 5615/7134 completed (loss: 0.13290148973464966, acc: 0.961904764175415)
[2024-12-17 03:23:06,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:06,486][root][INFO] - Training Epoch: 2/2, step 5616/7134 completed (loss: 0.13556480407714844, acc: 0.970370352268219)
[2024-12-17 03:23:06,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:06,854][root][INFO] - Training Epoch: 2/2, step 5617/7134 completed (loss: 0.10354728996753693, acc: 0.961240291595459)
[2024-12-17 03:23:06,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:07,242][root][INFO] - Training Epoch: 2/2, step 5618/7134 completed (loss: 0.1345949023962021, acc: 0.9485294222831726)
[2024-12-17 03:23:07,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:07,598][root][INFO] - Training Epoch: 2/2, step 5619/7134 completed (loss: 0.15849684178829193, acc: 0.9579831957817078)
[2024-12-17 03:23:07,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:07,953][root][INFO] - Training Epoch: 2/2, step 5620/7134 completed (loss: 0.13071544468402863, acc: 0.95652174949646)
[2024-12-17 03:23:08,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:08,327][root][INFO] - Training Epoch: 2/2, step 5621/7134 completed (loss: 0.10452570766210556, acc: 0.9677419066429138)
[2024-12-17 03:23:08,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:08,757][root][INFO] - Training Epoch: 2/2, step 5622/7134 completed (loss: 0.17701667547225952, acc: 0.9625668525695801)
[2024-12-17 03:23:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:09,101][root][INFO] - Training Epoch: 2/2, step 5623/7134 completed (loss: 0.1870177537202835, acc: 0.9375)
[2024-12-17 03:23:09,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:09,451][root][INFO] - Training Epoch: 2/2, step 5624/7134 completed (loss: 0.12045447528362274, acc: 0.9738562107086182)
[2024-12-17 03:23:09,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:09,881][root][INFO] - Training Epoch: 2/2, step 5625/7134 completed (loss: 0.0626077875494957, acc: 0.9901960492134094)
[2024-12-17 03:23:10,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:10,277][root][INFO] - Training Epoch: 2/2, step 5626/7134 completed (loss: 0.10547919571399689, acc: 0.9793103337287903)
[2024-12-17 03:23:10,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:10,671][root][INFO] - Training Epoch: 2/2, step 5627/7134 completed (loss: 0.2377530187368393, acc: 0.9166666865348816)
[2024-12-17 03:23:10,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:11,069][root][INFO] - Training Epoch: 2/2, step 5628/7134 completed (loss: 0.09236622601747513, acc: 0.9910714030265808)
[2024-12-17 03:23:11,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:11,454][root][INFO] - Training Epoch: 2/2, step 5629/7134 completed (loss: 0.1351812332868576, acc: 0.9672130942344666)
[2024-12-17 03:23:11,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:11,835][root][INFO] - Training Epoch: 2/2, step 5630/7134 completed (loss: 0.1966630220413208, acc: 0.9509803652763367)
[2024-12-17 03:23:11,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:12,236][root][INFO] - Training Epoch: 2/2, step 5631/7134 completed (loss: 0.0861826092004776, acc: 0.9837398529052734)
[2024-12-17 03:23:12,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:12,633][root][INFO] - Training Epoch: 2/2, step 5632/7134 completed (loss: 0.1846756935119629, acc: 0.9711538553237915)
[2024-12-17 03:23:12,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:13,087][root][INFO] - Training Epoch: 2/2, step 5633/7134 completed (loss: 0.056835584342479706, acc: 0.9821428656578064)
[2024-12-17 03:23:13,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:13,484][root][INFO] - Training Epoch: 2/2, step 5634/7134 completed (loss: 0.08403929322957993, acc: 0.9646017551422119)
[2024-12-17 03:23:13,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:13,893][root][INFO] - Training Epoch: 2/2, step 5635/7134 completed (loss: 0.09069700539112091, acc: 0.96875)
[2024-12-17 03:23:14,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:14,270][root][INFO] - Training Epoch: 2/2, step 5636/7134 completed (loss: 0.11943596601486206, acc: 0.9692307710647583)
[2024-12-17 03:23:14,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:14,690][root][INFO] - Training Epoch: 2/2, step 5637/7134 completed (loss: 0.08221963793039322, acc: 0.9848484992980957)
[2024-12-17 03:23:14,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:15,071][root][INFO] - Training Epoch: 2/2, step 5638/7134 completed (loss: 0.09724356234073639, acc: 0.9736841917037964)
[2024-12-17 03:23:15,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:15,459][root][INFO] - Training Epoch: 2/2, step 5639/7134 completed (loss: 0.11293276399374008, acc: 0.9675324559211731)
[2024-12-17 03:23:15,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:15,820][root][INFO] - Training Epoch: 2/2, step 5640/7134 completed (loss: 0.13514040410518646, acc: 0.9716312289237976)
[2024-12-17 03:23:15,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:16,172][root][INFO] - Training Epoch: 2/2, step 5641/7134 completed (loss: 0.21456938982009888, acc: 0.9550561904907227)
[2024-12-17 03:23:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:16,550][root][INFO] - Training Epoch: 2/2, step 5642/7134 completed (loss: 0.11936773359775543, acc: 0.9650349617004395)
[2024-12-17 03:23:16,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:16,924][root][INFO] - Training Epoch: 2/2, step 5643/7134 completed (loss: 0.19597619771957397, acc: 0.9368420839309692)
[2024-12-17 03:23:17,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:17,300][root][INFO] - Training Epoch: 2/2, step 5644/7134 completed (loss: 0.1713062822818756, acc: 0.9428571462631226)
[2024-12-17 03:23:17,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:17,656][root][INFO] - Training Epoch: 2/2, step 5645/7134 completed (loss: 0.08612820506095886, acc: 0.9722222089767456)
[2024-12-17 03:23:17,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:18,016][root][INFO] - Training Epoch: 2/2, step 5646/7134 completed (loss: 0.10336203128099442, acc: 0.9714285731315613)
[2024-12-17 03:23:18,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:18,426][root][INFO] - Training Epoch: 2/2, step 5647/7134 completed (loss: 0.23280589282512665, acc: 0.9513888955116272)
[2024-12-17 03:23:18,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:18,815][root][INFO] - Training Epoch: 2/2, step 5648/7134 completed (loss: 0.22938905656337738, acc: 0.9399999976158142)
[2024-12-17 03:23:18,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:19,206][root][INFO] - Training Epoch: 2/2, step 5649/7134 completed (loss: 0.21639244258403778, acc: 0.9527027010917664)
[2024-12-17 03:23:19,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:19,607][root][INFO] - Training Epoch: 2/2, step 5650/7134 completed (loss: 0.21498075127601624, acc: 0.9435483813285828)
[2024-12-17 03:23:19,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:19,986][root][INFO] - Training Epoch: 2/2, step 5651/7134 completed (loss: 0.10138434171676636, acc: 0.9591836929321289)
[2024-12-17 03:23:20,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:20,378][root][INFO] - Training Epoch: 2/2, step 5652/7134 completed (loss: 0.19048841297626495, acc: 0.9424460530281067)
[2024-12-17 03:23:20,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:20,754][root][INFO] - Training Epoch: 2/2, step 5653/7134 completed (loss: 0.1800052672624588, acc: 0.9350649118423462)
[2024-12-17 03:23:20,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:21,120][root][INFO] - Training Epoch: 2/2, step 5654/7134 completed (loss: 0.07508890330791473, acc: 0.9765625)
[2024-12-17 03:23:21,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:21,502][root][INFO] - Training Epoch: 2/2, step 5655/7134 completed (loss: 0.07432349026203156, acc: 0.9906542301177979)
[2024-12-17 03:23:21,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:21,891][root][INFO] - Training Epoch: 2/2, step 5656/7134 completed (loss: 0.1777019053697586, acc: 0.9344262480735779)
[2024-12-17 03:23:22,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:22,264][root][INFO] - Training Epoch: 2/2, step 5657/7134 completed (loss: 0.21620357036590576, acc: 0.9536423683166504)
[2024-12-17 03:23:22,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:22,642][root][INFO] - Training Epoch: 2/2, step 5658/7134 completed (loss: 0.14304041862487793, acc: 0.9738562107086182)
[2024-12-17 03:23:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:23,010][root][INFO] - Training Epoch: 2/2, step 5659/7134 completed (loss: 0.13549335300922394, acc: 0.9642857313156128)
[2024-12-17 03:23:23,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:23,393][root][INFO] - Training Epoch: 2/2, step 5660/7134 completed (loss: 0.2005608081817627, acc: 0.9609375)
[2024-12-17 03:23:23,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:23,773][root][INFO] - Training Epoch: 2/2, step 5661/7134 completed (loss: 0.11672969907522202, acc: 0.9747899174690247)
[2024-12-17 03:23:23,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:24,191][root][INFO] - Training Epoch: 2/2, step 5662/7134 completed (loss: 0.11693033576011658, acc: 0.971222996711731)
[2024-12-17 03:23:24,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:24,572][root][INFO] - Training Epoch: 2/2, step 5663/7134 completed (loss: 0.03840130195021629, acc: 1.0)
[2024-12-17 03:23:24,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:24,965][root][INFO] - Training Epoch: 2/2, step 5664/7134 completed (loss: 0.24480317533016205, acc: 0.9589040875434875)
[2024-12-17 03:23:25,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:25,351][root][INFO] - Training Epoch: 2/2, step 5665/7134 completed (loss: 0.06525683403015137, acc: 0.9863945841789246)
[2024-12-17 03:23:25,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:25,737][root][INFO] - Training Epoch: 2/2, step 5666/7134 completed (loss: 0.12245405465364456, acc: 0.9673202633857727)
[2024-12-17 03:23:25,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:26,169][root][INFO] - Training Epoch: 2/2, step 5667/7134 completed (loss: 0.20989154279232025, acc: 0.9593495726585388)
[2024-12-17 03:23:26,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:26,529][root][INFO] - Training Epoch: 2/2, step 5668/7134 completed (loss: 0.1985137164592743, acc: 0.9481481313705444)
[2024-12-17 03:23:26,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:26,913][root][INFO] - Training Epoch: 2/2, step 5669/7134 completed (loss: 0.13041788339614868, acc: 0.9681528806686401)
[2024-12-17 03:23:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:27,301][root][INFO] - Training Epoch: 2/2, step 5670/7134 completed (loss: 0.08833688497543335, acc: 0.9603174328804016)
[2024-12-17 03:23:27,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:27,695][root][INFO] - Training Epoch: 2/2, step 5671/7134 completed (loss: 0.1190570518374443, acc: 0.9719101190567017)
[2024-12-17 03:23:27,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:28,073][root][INFO] - Training Epoch: 2/2, step 5672/7134 completed (loss: 0.1531411111354828, acc: 0.9555555582046509)
[2024-12-17 03:23:28,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:28,424][root][INFO] - Training Epoch: 2/2, step 5673/7134 completed (loss: 0.14190903306007385, acc: 0.9794520735740662)
[2024-12-17 03:23:28,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:28,808][root][INFO] - Training Epoch: 2/2, step 5674/7134 completed (loss: 0.18741269409656525, acc: 0.9455782175064087)
[2024-12-17 03:23:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:29,217][root][INFO] - Training Epoch: 2/2, step 5675/7134 completed (loss: 0.23424169421195984, acc: 0.9466666579246521)
[2024-12-17 03:23:29,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:29,629][root][INFO] - Training Epoch: 2/2, step 5676/7134 completed (loss: 0.26737746596336365, acc: 0.9252873659133911)
[2024-12-17 03:23:29,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:30,004][root][INFO] - Training Epoch: 2/2, step 5677/7134 completed (loss: 0.31593087315559387, acc: 0.9285714030265808)
[2024-12-17 03:23:30,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:30,376][root][INFO] - Training Epoch: 2/2, step 5678/7134 completed (loss: 0.16110678017139435, acc: 0.9629629850387573)
[2024-12-17 03:23:30,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:30,777][root][INFO] - Training Epoch: 2/2, step 5679/7134 completed (loss: 0.40884360671043396, acc: 0.9177215099334717)
[2024-12-17 03:23:30,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:31,156][root][INFO] - Training Epoch: 2/2, step 5680/7134 completed (loss: 0.4077587127685547, acc: 0.885869562625885)
[2024-12-17 03:23:31,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:31,540][root][INFO] - Training Epoch: 2/2, step 5681/7134 completed (loss: 0.3219890594482422, acc: 0.903030276298523)
[2024-12-17 03:23:31,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:31,929][root][INFO] - Training Epoch: 2/2, step 5682/7134 completed (loss: 0.1562899351119995, acc: 0.9578313231468201)
[2024-12-17 03:23:32,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:32,344][root][INFO] - Training Epoch: 2/2, step 5683/7134 completed (loss: 0.24153123795986176, acc: 0.9555555582046509)
[2024-12-17 03:23:32,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:32,733][root][INFO] - Training Epoch: 2/2, step 5684/7134 completed (loss: 0.3691670596599579, acc: 0.9207317233085632)
[2024-12-17 03:23:32,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:33,119][root][INFO] - Training Epoch: 2/2, step 5685/7134 completed (loss: 0.30073100328445435, acc: 0.9212598204612732)
[2024-12-17 03:23:33,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:33,493][root][INFO] - Training Epoch: 2/2, step 5686/7134 completed (loss: 0.26238685846328735, acc: 0.9280575513839722)
[2024-12-17 03:23:33,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:33,891][root][INFO] - Training Epoch: 2/2, step 5687/7134 completed (loss: 0.2599620521068573, acc: 0.9696969985961914)
[2024-12-17 03:23:34,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:34,305][root][INFO] - Training Epoch: 2/2, step 5688/7134 completed (loss: 0.33338627219200134, acc: 0.9277777671813965)
[2024-12-17 03:23:34,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:34,690][root][INFO] - Training Epoch: 2/2, step 5689/7134 completed (loss: 0.19399230182170868, acc: 0.9695122241973877)
[2024-12-17 03:23:34,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:35,080][root][INFO] - Training Epoch: 2/2, step 5690/7134 completed (loss: 0.11177968233823776, acc: 0.969072163105011)
[2024-12-17 03:23:35,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:35,435][root][INFO] - Training Epoch: 2/2, step 5691/7134 completed (loss: 0.18687787652015686, acc: 0.9617486596107483)
[2024-12-17 03:23:35,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:35,817][root][INFO] - Training Epoch: 2/2, step 5692/7134 completed (loss: 0.1851211041212082, acc: 0.9714285731315613)
[2024-12-17 03:23:35,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:36,178][root][INFO] - Training Epoch: 2/2, step 5693/7134 completed (loss: 0.044751640409231186, acc: 0.9874213933944702)
[2024-12-17 03:23:36,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:36,582][root][INFO] - Training Epoch: 2/2, step 5694/7134 completed (loss: 0.08521479368209839, acc: 0.9883720874786377)
[2024-12-17 03:23:36,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:37,022][root][INFO] - Training Epoch: 2/2, step 5695/7134 completed (loss: 0.0854429304599762, acc: 0.9754601120948792)
[2024-12-17 03:23:37,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:37,419][root][INFO] - Training Epoch: 2/2, step 5696/7134 completed (loss: 0.12815633416175842, acc: 0.9702970385551453)
[2024-12-17 03:23:37,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:37,814][root][INFO] - Training Epoch: 2/2, step 5697/7134 completed (loss: 0.19432900846004486, acc: 0.9636363387107849)
[2024-12-17 03:23:37,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:38,160][root][INFO] - Training Epoch: 2/2, step 5698/7134 completed (loss: 0.09086582064628601, acc: 0.9772727489471436)
[2024-12-17 03:23:38,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:38,569][root][INFO] - Training Epoch: 2/2, step 5699/7134 completed (loss: 0.32469189167022705, acc: 0.9195402264595032)
[2024-12-17 03:23:38,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:38,954][root][INFO] - Training Epoch: 2/2, step 5700/7134 completed (loss: 0.16324003040790558, acc: 0.9554139971733093)
[2024-12-17 03:23:39,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:39,345][root][INFO] - Training Epoch: 2/2, step 5701/7134 completed (loss: 0.1798986941576004, acc: 0.9675675630569458)
[2024-12-17 03:23:39,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:39,761][root][INFO] - Training Epoch: 2/2, step 5702/7134 completed (loss: 0.10138820111751556, acc: 0.9825581312179565)
[2024-12-17 03:23:39,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:40,171][root][INFO] - Training Epoch: 2/2, step 5703/7134 completed (loss: 0.05558968707919121, acc: 0.9874213933944702)
[2024-12-17 03:23:40,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:40,533][root][INFO] - Training Epoch: 2/2, step 5704/7134 completed (loss: 0.15255309641361237, acc: 0.9470587968826294)
[2024-12-17 03:23:40,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:40,894][root][INFO] - Training Epoch: 2/2, step 5705/7134 completed (loss: 0.06053038313984871, acc: 0.970588207244873)
[2024-12-17 03:23:41,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:41,300][root][INFO] - Training Epoch: 2/2, step 5706/7134 completed (loss: 0.09481728076934814, acc: 0.9702970385551453)
[2024-12-17 03:23:41,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:41,688][root][INFO] - Training Epoch: 2/2, step 5707/7134 completed (loss: 0.1605759561061859, acc: 0.9760000109672546)
[2024-12-17 03:23:41,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:42,076][root][INFO] - Training Epoch: 2/2, step 5708/7134 completed (loss: 0.0538504496216774, acc: 0.9871794581413269)
[2024-12-17 03:23:42,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:42,450][root][INFO] - Training Epoch: 2/2, step 5709/7134 completed (loss: 0.22806954383850098, acc: 0.9627329111099243)
[2024-12-17 03:23:42,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:42,904][root][INFO] - Training Epoch: 2/2, step 5710/7134 completed (loss: 0.19932320713996887, acc: 0.9428571462631226)
[2024-12-17 03:23:43,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:43,315][root][INFO] - Training Epoch: 2/2, step 5711/7134 completed (loss: 0.1821756660938263, acc: 0.9569892287254333)
[2024-12-17 03:23:43,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:43,742][root][INFO] - Training Epoch: 2/2, step 5712/7134 completed (loss: 0.06941583752632141, acc: 0.9838709831237793)
[2024-12-17 03:23:43,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:44,136][root][INFO] - Training Epoch: 2/2, step 5713/7134 completed (loss: 0.10097591578960419, acc: 0.9775280952453613)
[2024-12-17 03:23:44,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:44,561][root][INFO] - Training Epoch: 2/2, step 5714/7134 completed (loss: 0.07826373726129532, acc: 0.9836956262588501)
[2024-12-17 03:23:44,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:44,973][root][INFO] - Training Epoch: 2/2, step 5715/7134 completed (loss: 0.40564513206481934, acc: 0.9485294222831726)
[2024-12-17 03:23:45,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:45,362][root][INFO] - Training Epoch: 2/2, step 5716/7134 completed (loss: 0.23811763525009155, acc: 0.9444444179534912)
[2024-12-17 03:23:45,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:45,720][root][INFO] - Training Epoch: 2/2, step 5717/7134 completed (loss: 0.2658612132072449, acc: 0.9415204524993896)
[2024-12-17 03:23:45,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:46,158][root][INFO] - Training Epoch: 2/2, step 5718/7134 completed (loss: 0.1653171330690384, acc: 0.9539473652839661)
[2024-12-17 03:23:46,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:46,544][root][INFO] - Training Epoch: 2/2, step 5719/7134 completed (loss: 0.1479933261871338, acc: 0.9470587968826294)
[2024-12-17 03:23:46,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:46,977][root][INFO] - Training Epoch: 2/2, step 5720/7134 completed (loss: 0.19935134053230286, acc: 0.942307710647583)
[2024-12-17 03:23:47,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:47,407][root][INFO] - Training Epoch: 2/2, step 5721/7134 completed (loss: 0.16678807139396667, acc: 0.9326424598693848)
[2024-12-17 03:23:47,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:47,830][root][INFO] - Training Epoch: 2/2, step 5722/7134 completed (loss: 0.07078229635953903, acc: 0.9818181991577148)
[2024-12-17 03:23:47,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:48,267][root][INFO] - Training Epoch: 2/2, step 5723/7134 completed (loss: 0.1281731277704239, acc: 0.9682539701461792)
[2024-12-17 03:23:48,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:48,695][root][INFO] - Training Epoch: 2/2, step 5724/7134 completed (loss: 0.1620623767375946, acc: 0.9575757384300232)
[2024-12-17 03:23:48,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:49,148][root][INFO] - Training Epoch: 2/2, step 5725/7134 completed (loss: 0.20481882989406586, acc: 0.954285740852356)
[2024-12-17 03:23:49,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:49,556][root][INFO] - Training Epoch: 2/2, step 5726/7134 completed (loss: 0.25349554419517517, acc: 0.946107804775238)
[2024-12-17 03:23:49,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:49,983][root][INFO] - Training Epoch: 2/2, step 5727/7134 completed (loss: 0.04415789619088173, acc: 0.9949748516082764)
[2024-12-17 03:23:50,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:50,369][root][INFO] - Training Epoch: 2/2, step 5728/7134 completed (loss: 0.026779118925333023, acc: 0.9926470518112183)
[2024-12-17 03:23:50,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:50,741][root][INFO] - Training Epoch: 2/2, step 5729/7134 completed (loss: 0.07139026373624802, acc: 0.9870129823684692)
[2024-12-17 03:23:50,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:51,178][root][INFO] - Training Epoch: 2/2, step 5730/7134 completed (loss: 0.11504077166318893, acc: 0.9777777791023254)
[2024-12-17 03:23:51,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:51,635][root][INFO] - Training Epoch: 2/2, step 5731/7134 completed (loss: 0.14727023243904114, acc: 0.9624999761581421)
[2024-12-17 03:23:51,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:52,052][root][INFO] - Training Epoch: 2/2, step 5732/7134 completed (loss: 0.7081920504570007, acc: 0.8072289228439331)
[2024-12-17 03:23:52,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:52,428][root][INFO] - Training Epoch: 2/2, step 5733/7134 completed (loss: 0.2527076005935669, acc: 0.9240506291389465)
[2024-12-17 03:23:52,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:52,810][root][INFO] - Training Epoch: 2/2, step 5734/7134 completed (loss: 0.1757381558418274, acc: 0.9523809552192688)
[2024-12-17 03:23:52,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:53,203][root][INFO] - Training Epoch: 2/2, step 5735/7134 completed (loss: 0.20917533338069916, acc: 0.9536423683166504)
[2024-12-17 03:23:53,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:53,626][root][INFO] - Training Epoch: 2/2, step 5736/7134 completed (loss: 0.18391118943691254, acc: 0.939226508140564)
[2024-12-17 03:23:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:54,020][root][INFO] - Training Epoch: 2/2, step 5737/7134 completed (loss: 0.08504238724708557, acc: 0.9824561476707458)
[2024-12-17 03:23:54,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:54,415][root][INFO] - Training Epoch: 2/2, step 5738/7134 completed (loss: 0.11908812820911407, acc: 0.9747474789619446)
[2024-12-17 03:23:54,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:54,798][root][INFO] - Training Epoch: 2/2, step 5739/7134 completed (loss: 0.18364840745925903, acc: 0.9583333134651184)
[2024-12-17 03:23:54,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:55,171][root][INFO] - Training Epoch: 2/2, step 5740/7134 completed (loss: 0.08691582828760147, acc: 0.9739583134651184)
[2024-12-17 03:23:55,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:55,550][root][INFO] - Training Epoch: 2/2, step 5741/7134 completed (loss: 0.1720246821641922, acc: 0.9488636255264282)
[2024-12-17 03:23:55,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:55,954][root][INFO] - Training Epoch: 2/2, step 5742/7134 completed (loss: 0.09454617649316788, acc: 0.983146071434021)
[2024-12-17 03:23:56,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:56,358][root][INFO] - Training Epoch: 2/2, step 5743/7134 completed (loss: 0.09931870549917221, acc: 0.984375)
[2024-12-17 03:23:56,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:56,746][root][INFO] - Training Epoch: 2/2, step 5744/7134 completed (loss: 0.053534310311079025, acc: 0.982300877571106)
[2024-12-17 03:23:56,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:57,214][root][INFO] - Training Epoch: 2/2, step 5745/7134 completed (loss: 0.197905033826828, acc: 0.9719101190567017)
[2024-12-17 03:23:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:57,616][root][INFO] - Training Epoch: 2/2, step 5746/7134 completed (loss: 0.13679049909114838, acc: 0.9691358208656311)
[2024-12-17 03:23:57,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:57,997][root][INFO] - Training Epoch: 2/2, step 5747/7134 completed (loss: 0.18767942488193512, acc: 0.9575757384300232)
[2024-12-17 03:23:58,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:58,408][root][INFO] - Training Epoch: 2/2, step 5748/7134 completed (loss: 0.07248193770647049, acc: 0.9842519760131836)
[2024-12-17 03:23:58,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:58,820][root][INFO] - Training Epoch: 2/2, step 5749/7134 completed (loss: 0.19754672050476074, acc: 0.9467455744743347)
[2024-12-17 03:23:58,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:59,225][root][INFO] - Training Epoch: 2/2, step 5750/7134 completed (loss: 0.15975064039230347, acc: 0.9608938694000244)
[2024-12-17 03:23:59,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:23:59,640][root][INFO] - Training Epoch: 2/2, step 5751/7134 completed (loss: 0.16201873123645782, acc: 0.9668874144554138)
[2024-12-17 03:23:59,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:00,040][root][INFO] - Training Epoch: 2/2, step 5752/7134 completed (loss: 0.574091911315918, acc: 0.8549618124961853)
[2024-12-17 03:24:00,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:00,403][root][INFO] - Training Epoch: 2/2, step 5753/7134 completed (loss: 0.2573004364967346, acc: 0.9328858852386475)
[2024-12-17 03:24:00,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:00,769][root][INFO] - Training Epoch: 2/2, step 5754/7134 completed (loss: 0.19783362746238708, acc: 0.977011501789093)
[2024-12-17 03:24:00,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:01,134][root][INFO] - Training Epoch: 2/2, step 5755/7134 completed (loss: 0.21392415463924408, acc: 0.948051929473877)
[2024-12-17 03:24:01,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:01,466][root][INFO] - Training Epoch: 2/2, step 5756/7134 completed (loss: 0.22950826585292816, acc: 0.9360465407371521)
[2024-12-17 03:24:01,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:01,847][root][INFO] - Training Epoch: 2/2, step 5757/7134 completed (loss: 0.299489825963974, acc: 0.932584285736084)
[2024-12-17 03:24:01,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:02,212][root][INFO] - Training Epoch: 2/2, step 5758/7134 completed (loss: 0.340285986661911, acc: 0.9135802388191223)
[2024-12-17 03:24:02,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:02,617][root][INFO] - Training Epoch: 2/2, step 5759/7134 completed (loss: 0.43809521198272705, acc: 0.9223300814628601)
[2024-12-17 03:24:02,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:03,072][root][INFO] - Training Epoch: 2/2, step 5760/7134 completed (loss: 0.22121702134609222, acc: 0.9415584206581116)
[2024-12-17 03:24:03,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:03,475][root][INFO] - Training Epoch: 2/2, step 5761/7134 completed (loss: 0.17469605803489685, acc: 0.9359999895095825)
[2024-12-17 03:24:03,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:03,863][root][INFO] - Training Epoch: 2/2, step 5762/7134 completed (loss: 0.15406477451324463, acc: 0.961240291595459)
[2024-12-17 03:24:03,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:04,235][root][INFO] - Training Epoch: 2/2, step 5763/7134 completed (loss: 0.13932251930236816, acc: 0.9562841653823853)
[2024-12-17 03:24:04,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:04,583][root][INFO] - Training Epoch: 2/2, step 5764/7134 completed (loss: 0.058249205350875854, acc: 0.9847328066825867)
[2024-12-17 03:24:04,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:04,931][root][INFO] - Training Epoch: 2/2, step 5765/7134 completed (loss: 0.20327535271644592, acc: 0.9496855139732361)
[2024-12-17 03:24:05,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:05,302][root][INFO] - Training Epoch: 2/2, step 5766/7134 completed (loss: 0.0911664292216301, acc: 0.9870967864990234)
[2024-12-17 03:24:05,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:05,729][root][INFO] - Training Epoch: 2/2, step 5767/7134 completed (loss: 0.07575023919343948, acc: 0.9751552939414978)
[2024-12-17 03:24:05,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:06,136][root][INFO] - Training Epoch: 2/2, step 5768/7134 completed (loss: 0.03769969195127487, acc: 1.0)
[2024-12-17 03:24:06,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:06,524][root][INFO] - Training Epoch: 2/2, step 5769/7134 completed (loss: 0.03863511607050896, acc: 0.9928571581840515)
[2024-12-17 03:24:06,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:06,909][root][INFO] - Training Epoch: 2/2, step 5770/7134 completed (loss: 0.06413383036851883, acc: 0.9891892075538635)
[2024-12-17 03:24:07,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:07,283][root][INFO] - Training Epoch: 2/2, step 5771/7134 completed (loss: 0.2490970939397812, acc: 0.9447852969169617)
[2024-12-17 03:24:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:07,693][root][INFO] - Training Epoch: 2/2, step 5772/7134 completed (loss: 0.08507172763347626, acc: 0.9750000238418579)
[2024-12-17 03:24:07,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:08,105][root][INFO] - Training Epoch: 2/2, step 5773/7134 completed (loss: 0.11836735159158707, acc: 0.9624060392379761)
[2024-12-17 03:24:08,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:08,529][root][INFO] - Training Epoch: 2/2, step 5774/7134 completed (loss: 0.0730152577161789, acc: 0.9814814925193787)
[2024-12-17 03:24:08,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:08,995][root][INFO] - Training Epoch: 2/2, step 5775/7134 completed (loss: 0.08459394425153732, acc: 0.9800000190734863)
[2024-12-17 03:24:09,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:09,406][root][INFO] - Training Epoch: 2/2, step 5776/7134 completed (loss: 0.19032132625579834, acc: 0.9438202381134033)
[2024-12-17 03:24:09,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:09,851][root][INFO] - Training Epoch: 2/2, step 5777/7134 completed (loss: 0.1802673637866974, acc: 0.9532710313796997)
[2024-12-17 03:24:09,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:10,272][root][INFO] - Training Epoch: 2/2, step 5778/7134 completed (loss: 0.4120263457298279, acc: 0.9024389982223511)
[2024-12-17 03:24:10,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:10,669][root][INFO] - Training Epoch: 2/2, step 5779/7134 completed (loss: 0.17272025346755981, acc: 0.970588207244873)
[2024-12-17 03:24:10,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:11,074][root][INFO] - Training Epoch: 2/2, step 5780/7134 completed (loss: 0.16933131217956543, acc: 0.9552238583564758)
[2024-12-17 03:24:11,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:11,492][root][INFO] - Training Epoch: 2/2, step 5781/7134 completed (loss: 0.2939280569553375, acc: 0.9364162087440491)
[2024-12-17 03:24:11,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:11,930][root][INFO] - Training Epoch: 2/2, step 5782/7134 completed (loss: 0.11845369637012482, acc: 0.9779005646705627)
[2024-12-17 03:24:12,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:12,317][root][INFO] - Training Epoch: 2/2, step 5783/7134 completed (loss: 0.14300818741321564, acc: 0.9653179049491882)
[2024-12-17 03:24:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:12,709][root][INFO] - Training Epoch: 2/2, step 5784/7134 completed (loss: 0.16559316217899323, acc: 0.9491525292396545)
[2024-12-17 03:24:12,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:13,107][root][INFO] - Training Epoch: 2/2, step 5785/7134 completed (loss: 0.16003631055355072, acc: 0.9621621370315552)
[2024-12-17 03:24:13,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:13,490][root][INFO] - Training Epoch: 2/2, step 5786/7134 completed (loss: 0.15726163983345032, acc: 0.9603174328804016)
[2024-12-17 03:24:13,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:13,887][root][INFO] - Training Epoch: 2/2, step 5787/7134 completed (loss: 0.12218443304300308, acc: 0.9790576100349426)
[2024-12-17 03:24:13,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:14,238][root][INFO] - Training Epoch: 2/2, step 5788/7134 completed (loss: 0.09365151077508926, acc: 0.9868420958518982)
[2024-12-17 03:24:14,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:14,649][root][INFO] - Training Epoch: 2/2, step 5789/7134 completed (loss: 0.11467993259429932, acc: 0.9646464586257935)
[2024-12-17 03:24:14,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:15,056][root][INFO] - Training Epoch: 2/2, step 5790/7134 completed (loss: 0.0888947993516922, acc: 0.988095223903656)
[2024-12-17 03:24:15,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:15,477][root][INFO] - Training Epoch: 2/2, step 5791/7134 completed (loss: 0.10751065611839294, acc: 0.9701492786407471)
[2024-12-17 03:24:15,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:15,909][root][INFO] - Training Epoch: 2/2, step 5792/7134 completed (loss: 0.3229321837425232, acc: 0.926174521446228)
[2024-12-17 03:24:16,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:16,282][root][INFO] - Training Epoch: 2/2, step 5793/7134 completed (loss: 0.20403273403644562, acc: 0.9509202241897583)
[2024-12-17 03:24:16,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:16,662][root][INFO] - Training Epoch: 2/2, step 5794/7134 completed (loss: 0.3843769133090973, acc: 0.9299362897872925)
[2024-12-17 03:24:16,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:17,067][root][INFO] - Training Epoch: 2/2, step 5795/7134 completed (loss: 0.3783726096153259, acc: 0.8947368264198303)
[2024-12-17 03:24:17,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:17,457][root][INFO] - Training Epoch: 2/2, step 5796/7134 completed (loss: 0.32539603114128113, acc: 0.9083969593048096)
[2024-12-17 03:24:17,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:17,828][root][INFO] - Training Epoch: 2/2, step 5797/7134 completed (loss: 0.19447338581085205, acc: 0.9395973086357117)
[2024-12-17 03:24:17,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:18,206][root][INFO] - Training Epoch: 2/2, step 5798/7134 completed (loss: 0.8104755282402039, acc: 0.8662790656089783)
[2024-12-17 03:24:18,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:18,582][root][INFO] - Training Epoch: 2/2, step 5799/7134 completed (loss: 0.1503579020500183, acc: 0.9527559280395508)
[2024-12-17 03:24:18,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:18,971][root][INFO] - Training Epoch: 2/2, step 5800/7134 completed (loss: 0.39463549852371216, acc: 0.9208633303642273)
[2024-12-17 03:24:19,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:19,342][root][INFO] - Training Epoch: 2/2, step 5801/7134 completed (loss: 0.25978395342826843, acc: 0.9197530746459961)
[2024-12-17 03:24:19,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:19,711][root][INFO] - Training Epoch: 2/2, step 5802/7134 completed (loss: 0.14554905891418457, acc: 0.970588207244873)
[2024-12-17 03:24:19,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:20,101][root][INFO] - Training Epoch: 2/2, step 5803/7134 completed (loss: 0.09321431815624237, acc: 0.982758641242981)
[2024-12-17 03:24:20,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:20,469][root][INFO] - Training Epoch: 2/2, step 5804/7134 completed (loss: 0.29681098461151123, acc: 0.9490445852279663)
[2024-12-17 03:24:20,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:20,861][root][INFO] - Training Epoch: 2/2, step 5805/7134 completed (loss: 0.2116508036851883, acc: 0.940397322177887)
[2024-12-17 03:24:20,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:21,286][root][INFO] - Training Epoch: 2/2, step 5806/7134 completed (loss: 0.15035636723041534, acc: 0.9636363387107849)
[2024-12-17 03:24:21,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:21,662][root][INFO] - Training Epoch: 2/2, step 5807/7134 completed (loss: 0.2954954504966736, acc: 0.9295774698257446)
[2024-12-17 03:24:21,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:22,047][root][INFO] - Training Epoch: 2/2, step 5808/7134 completed (loss: 0.07440454512834549, acc: 0.9810126423835754)
[2024-12-17 03:24:22,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:22,425][root][INFO] - Training Epoch: 2/2, step 5809/7134 completed (loss: 0.10669854283332825, acc: 0.970588207244873)
[2024-12-17 03:24:22,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:22,807][root][INFO] - Training Epoch: 2/2, step 5810/7134 completed (loss: 0.10319805145263672, acc: 0.9752066135406494)
[2024-12-17 03:24:22,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:23,197][root][INFO] - Training Epoch: 2/2, step 5811/7134 completed (loss: 0.20682941377162933, acc: 0.9560439586639404)
[2024-12-17 03:24:23,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:23,599][root][INFO] - Training Epoch: 2/2, step 5812/7134 completed (loss: 0.08078638464212418, acc: 0.9852941036224365)
[2024-12-17 03:24:23,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:24,039][root][INFO] - Training Epoch: 2/2, step 5813/7134 completed (loss: 0.07639853656291962, acc: 0.9918032884597778)
[2024-12-17 03:24:24,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:24,541][root][INFO] - Training Epoch: 2/2, step 5814/7134 completed (loss: 0.12667091190814972, acc: 0.984000027179718)
[2024-12-17 03:24:24,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:24,956][root][INFO] - Training Epoch: 2/2, step 5815/7134 completed (loss: 0.1456080973148346, acc: 0.9568965435028076)
[2024-12-17 03:24:25,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:25,373][root][INFO] - Training Epoch: 2/2, step 5816/7134 completed (loss: 0.03519207984209061, acc: 0.9946523904800415)
[2024-12-17 03:24:25,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:25,775][root][INFO] - Training Epoch: 2/2, step 5817/7134 completed (loss: 0.17038358747959137, acc: 0.9714285731315613)
[2024-12-17 03:24:25,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:26,179][root][INFO] - Training Epoch: 2/2, step 5818/7134 completed (loss: 0.07052654027938843, acc: 0.9803921580314636)
[2024-12-17 03:24:26,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:26,568][root][INFO] - Training Epoch: 2/2, step 5819/7134 completed (loss: 0.04490434005856514, acc: 0.9929577708244324)
[2024-12-17 03:24:26,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:26,917][root][INFO] - Training Epoch: 2/2, step 5820/7134 completed (loss: 0.11155347526073456, acc: 0.9752066135406494)
[2024-12-17 03:24:27,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:27,272][root][INFO] - Training Epoch: 2/2, step 5821/7134 completed (loss: 0.07321928441524506, acc: 0.9862068891525269)
[2024-12-17 03:24:27,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:27,659][root][INFO] - Training Epoch: 2/2, step 5822/7134 completed (loss: 0.0979057103395462, acc: 0.9731543660163879)
[2024-12-17 03:24:27,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:28,104][root][INFO] - Training Epoch: 2/2, step 5823/7134 completed (loss: 0.04628562927246094, acc: 0.9863945841789246)
[2024-12-17 03:24:28,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:28,497][root][INFO] - Training Epoch: 2/2, step 5824/7134 completed (loss: 0.060036104172468185, acc: 0.9878787994384766)
[2024-12-17 03:24:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:28,907][root][INFO] - Training Epoch: 2/2, step 5825/7134 completed (loss: 0.19363999366760254, acc: 0.9465649127960205)
[2024-12-17 03:24:29,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:29,292][root][INFO] - Training Epoch: 2/2, step 5826/7134 completed (loss: 0.10938955843448639, acc: 0.9767441749572754)
[2024-12-17 03:24:29,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:29,646][root][INFO] - Training Epoch: 2/2, step 5827/7134 completed (loss: 0.07278510183095932, acc: 0.9919354915618896)
[2024-12-17 03:24:29,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:30,003][root][INFO] - Training Epoch: 2/2, step 5828/7134 completed (loss: 0.08380786329507828, acc: 0.9803921580314636)
[2024-12-17 03:24:30,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:30,444][root][INFO] - Training Epoch: 2/2, step 5829/7134 completed (loss: 0.09323465079069138, acc: 0.9756097793579102)
[2024-12-17 03:24:30,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:30,870][root][INFO] - Training Epoch: 2/2, step 5830/7134 completed (loss: 0.07748118042945862, acc: 0.9919999837875366)
[2024-12-17 03:24:30,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:31,227][root][INFO] - Training Epoch: 2/2, step 5831/7134 completed (loss: 0.05662056431174278, acc: 0.9897959232330322)
[2024-12-17 03:24:31,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:31,607][root][INFO] - Training Epoch: 2/2, step 5832/7134 completed (loss: 0.20792868733406067, acc: 0.9465649127960205)
[2024-12-17 03:24:31,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:31,999][root][INFO] - Training Epoch: 2/2, step 5833/7134 completed (loss: 0.07619608938694, acc: 0.9849624037742615)
[2024-12-17 03:24:32,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:32,367][root][INFO] - Training Epoch: 2/2, step 5834/7134 completed (loss: 0.21283210813999176, acc: 0.9473684430122375)
[2024-12-17 03:24:32,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:32,738][root][INFO] - Training Epoch: 2/2, step 5835/7134 completed (loss: 0.11327493190765381, acc: 0.9800000190734863)
[2024-12-17 03:24:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:33,129][root][INFO] - Training Epoch: 2/2, step 5836/7134 completed (loss: 0.24019452929496765, acc: 0.9426751732826233)
[2024-12-17 03:24:33,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:33,512][root][INFO] - Training Epoch: 2/2, step 5837/7134 completed (loss: 0.4879906177520752, acc: 0.899328887462616)
[2024-12-17 03:24:33,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:33,900][root][INFO] - Training Epoch: 2/2, step 5838/7134 completed (loss: 0.21795383095741272, acc: 0.9640287756919861)
[2024-12-17 03:24:33,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:34,261][root][INFO] - Training Epoch: 2/2, step 5839/7134 completed (loss: 0.287485271692276, acc: 0.9130434989929199)
[2024-12-17 03:24:34,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:34,622][root][INFO] - Training Epoch: 2/2, step 5840/7134 completed (loss: 0.03133400157094002, acc: 0.9930070042610168)
[2024-12-17 03:24:34,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:35,002][root][INFO] - Training Epoch: 2/2, step 5841/7134 completed (loss: 0.2564717233181, acc: 0.9312499761581421)
[2024-12-17 03:24:35,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:35,326][root][INFO] - Training Epoch: 2/2, step 5842/7134 completed (loss: 0.10325804352760315, acc: 0.9752066135406494)
[2024-12-17 03:24:35,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:35,697][root][INFO] - Training Epoch: 2/2, step 5843/7134 completed (loss: 0.22462984919548035, acc: 0.9702380895614624)
[2024-12-17 03:24:35,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:36,094][root][INFO] - Training Epoch: 2/2, step 5844/7134 completed (loss: 0.10415203869342804, acc: 0.9759036302566528)
[2024-12-17 03:24:36,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:36,464][root][INFO] - Training Epoch: 2/2, step 5845/7134 completed (loss: 0.17993780970573425, acc: 0.9415584206581116)
[2024-12-17 03:24:36,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:36,900][root][INFO] - Training Epoch: 2/2, step 5846/7134 completed (loss: 0.14696882665157318, acc: 0.9642857313156128)
[2024-12-17 03:24:37,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:37,311][root][INFO] - Training Epoch: 2/2, step 5847/7134 completed (loss: 0.08184845745563507, acc: 0.9759036302566528)
[2024-12-17 03:24:37,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:37,713][root][INFO] - Training Epoch: 2/2, step 5848/7134 completed (loss: 0.0961742177605629, acc: 0.9797297120094299)
[2024-12-17 03:24:37,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:38,091][root][INFO] - Training Epoch: 2/2, step 5849/7134 completed (loss: 0.1734265685081482, acc: 0.948051929473877)
[2024-12-17 03:24:38,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:38,462][root][INFO] - Training Epoch: 2/2, step 5850/7134 completed (loss: 0.11846023797988892, acc: 0.9577465057373047)
[2024-12-17 03:24:38,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:38,834][root][INFO] - Training Epoch: 2/2, step 5851/7134 completed (loss: 0.2213069498538971, acc: 0.9383561611175537)
[2024-12-17 03:24:38,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:39,224][root][INFO] - Training Epoch: 2/2, step 5852/7134 completed (loss: 0.14019986987113953, acc: 0.9580419659614563)
[2024-12-17 03:24:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:39,616][root][INFO] - Training Epoch: 2/2, step 5853/7134 completed (loss: 0.17584306001663208, acc: 0.949438214302063)
[2024-12-17 03:24:39,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:40,006][root][INFO] - Training Epoch: 2/2, step 5854/7134 completed (loss: 0.16922444105148315, acc: 0.9538461565971375)
[2024-12-17 03:24:40,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:40,362][root][INFO] - Training Epoch: 2/2, step 5855/7134 completed (loss: 0.1451248824596405, acc: 0.9576271176338196)
[2024-12-17 03:24:40,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:40,704][root][INFO] - Training Epoch: 2/2, step 5856/7134 completed (loss: 0.18604305386543274, acc: 0.9507042169570923)
[2024-12-17 03:24:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:41,099][root][INFO] - Training Epoch: 2/2, step 5857/7134 completed (loss: 0.2012818455696106, acc: 0.9548872113227844)
[2024-12-17 03:24:41,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:41,453][root][INFO] - Training Epoch: 2/2, step 5858/7134 completed (loss: 0.12666916847229004, acc: 0.963302731513977)
[2024-12-17 03:24:41,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:41,838][root][INFO] - Training Epoch: 2/2, step 5859/7134 completed (loss: 0.11173424124717712, acc: 0.9741379022598267)
[2024-12-17 03:24:41,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:42,217][root][INFO] - Training Epoch: 2/2, step 5860/7134 completed (loss: 0.08773290365934372, acc: 0.9659090638160706)
[2024-12-17 03:24:42,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:42,593][root][INFO] - Training Epoch: 2/2, step 5861/7134 completed (loss: 0.15921775996685028, acc: 0.961904764175415)
[2024-12-17 03:24:42,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:42,976][root][INFO] - Training Epoch: 2/2, step 5862/7134 completed (loss: 0.17954254150390625, acc: 0.9322034120559692)
[2024-12-17 03:24:43,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:43,373][root][INFO] - Training Epoch: 2/2, step 5863/7134 completed (loss: 0.3426135182380676, acc: 0.9247311949729919)
[2024-12-17 03:24:43,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:43,761][root][INFO] - Training Epoch: 2/2, step 5864/7134 completed (loss: 0.2657330334186554, acc: 0.9298245906829834)
[2024-12-17 03:24:43,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:44,133][root][INFO] - Training Epoch: 2/2, step 5865/7134 completed (loss: 0.1829567402601242, acc: 0.9652777910232544)
[2024-12-17 03:24:44,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:44,493][root][INFO] - Training Epoch: 2/2, step 5866/7134 completed (loss: 0.09776317328214645, acc: 0.9780219793319702)
[2024-12-17 03:24:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:44,858][root][INFO] - Training Epoch: 2/2, step 5867/7134 completed (loss: 0.13226205110549927, acc: 0.9662162065505981)
[2024-12-17 03:24:44,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:45,242][root][INFO] - Training Epoch: 2/2, step 5868/7134 completed (loss: 0.2681954503059387, acc: 0.9411764740943909)
[2024-12-17 03:24:45,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:45,602][root][INFO] - Training Epoch: 2/2, step 5869/7134 completed (loss: 0.16119615733623505, acc: 0.940119743347168)
[2024-12-17 03:24:45,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:45,962][root][INFO] - Training Epoch: 2/2, step 5870/7134 completed (loss: 0.18181447684764862, acc: 0.9537037014961243)
[2024-12-17 03:24:46,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:46,324][root][INFO] - Training Epoch: 2/2, step 5871/7134 completed (loss: 0.09662187099456787, acc: 0.963302731513977)
[2024-12-17 03:24:46,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:46,674][root][INFO] - Training Epoch: 2/2, step 5872/7134 completed (loss: 0.18141664564609528, acc: 0.9440993666648865)
[2024-12-17 03:24:46,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:47,099][root][INFO] - Training Epoch: 2/2, step 5873/7134 completed (loss: 0.1701638102531433, acc: 0.9518716335296631)
[2024-12-17 03:24:47,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:47,424][root][INFO] - Training Epoch: 2/2, step 5874/7134 completed (loss: 0.0906578004360199, acc: 0.976190447807312)
[2024-12-17 03:24:47,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:47,904][root][INFO] - Training Epoch: 2/2, step 5875/7134 completed (loss: 0.2295406311750412, acc: 0.939393937587738)
[2024-12-17 03:24:48,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:48,287][root][INFO] - Training Epoch: 2/2, step 5876/7134 completed (loss: 0.05868371203541756, acc: 0.9887640476226807)
[2024-12-17 03:24:48,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:48,660][root][INFO] - Training Epoch: 2/2, step 5877/7134 completed (loss: 0.12254239618778229, acc: 0.9720670580863953)
[2024-12-17 03:24:48,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:49,025][root][INFO] - Training Epoch: 2/2, step 5878/7134 completed (loss: 0.16303610801696777, acc: 0.9636363387107849)
[2024-12-17 03:24:49,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:49,370][root][INFO] - Training Epoch: 2/2, step 5879/7134 completed (loss: 0.09540166705846786, acc: 0.9555555582046509)
[2024-12-17 03:24:49,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:49,774][root][INFO] - Training Epoch: 2/2, step 5880/7134 completed (loss: 0.118927001953125, acc: 0.9821428656578064)
[2024-12-17 03:24:49,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:50,135][root][INFO] - Training Epoch: 2/2, step 5881/7134 completed (loss: 0.05844566971063614, acc: 0.9829059839248657)
[2024-12-17 03:24:50,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:50,520][root][INFO] - Training Epoch: 2/2, step 5882/7134 completed (loss: 0.07550876587629318, acc: 0.970588207244873)
[2024-12-17 03:24:50,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:50,888][root][INFO] - Training Epoch: 2/2, step 5883/7134 completed (loss: 0.11792057752609253, acc: 0.9615384340286255)
[2024-12-17 03:24:51,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:51,260][root][INFO] - Training Epoch: 2/2, step 5884/7134 completed (loss: 0.24330660700798035, acc: 0.9365079402923584)
[2024-12-17 03:24:51,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:51,606][root][INFO] - Training Epoch: 2/2, step 5885/7134 completed (loss: 0.34755972027778625, acc: 0.9215686321258545)
[2024-12-17 03:24:51,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:51,985][root][INFO] - Training Epoch: 2/2, step 5886/7134 completed (loss: 0.07059159874916077, acc: 0.976190447807312)
[2024-12-17 03:24:52,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:52,348][root][INFO] - Training Epoch: 2/2, step 5887/7134 completed (loss: 0.04053274542093277, acc: 1.0)
[2024-12-17 03:24:52,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:52,726][root][INFO] - Training Epoch: 2/2, step 5888/7134 completed (loss: 0.24352845549583435, acc: 0.957446813583374)
[2024-12-17 03:24:52,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:53,105][root][INFO] - Training Epoch: 2/2, step 5889/7134 completed (loss: 0.1509908139705658, acc: 0.9615384340286255)
[2024-12-17 03:24:53,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:53,490][root][INFO] - Training Epoch: 2/2, step 5890/7134 completed (loss: 0.06525246053934097, acc: 0.9797297120094299)
[2024-12-17 03:24:53,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:53,863][root][INFO] - Training Epoch: 2/2, step 5891/7134 completed (loss: 0.2037152498960495, acc: 0.9642857313156128)
[2024-12-17 03:24:53,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:54,238][root][INFO] - Training Epoch: 2/2, step 5892/7134 completed (loss: 0.1407439410686493, acc: 0.9651162624359131)
[2024-12-17 03:24:54,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:54,626][root][INFO] - Training Epoch: 2/2, step 5893/7134 completed (loss: 0.07665982097387314, acc: 0.9754601120948792)
[2024-12-17 03:24:54,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:54,975][root][INFO] - Training Epoch: 2/2, step 5894/7134 completed (loss: 0.153716042637825, acc: 0.9729729890823364)
[2024-12-17 03:24:55,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:55,347][root][INFO] - Training Epoch: 2/2, step 5895/7134 completed (loss: 0.1344287395477295, acc: 0.9375)
[2024-12-17 03:24:55,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:55,720][root][INFO] - Training Epoch: 2/2, step 5896/7134 completed (loss: 0.08036456257104874, acc: 0.9748427867889404)
[2024-12-17 03:24:55,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:56,102][root][INFO] - Training Epoch: 2/2, step 5897/7134 completed (loss: 0.08310382813215256, acc: 0.9829545617103577)
[2024-12-17 03:24:56,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:56,478][root][INFO] - Training Epoch: 2/2, step 5898/7134 completed (loss: 0.17777881026268005, acc: 0.9732142686843872)
[2024-12-17 03:24:56,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:56,880][root][INFO] - Training Epoch: 2/2, step 5899/7134 completed (loss: 0.1289857178926468, acc: 0.9487179517745972)
[2024-12-17 03:24:57,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:57,255][root][INFO] - Training Epoch: 2/2, step 5900/7134 completed (loss: 0.08217816799879074, acc: 0.9753086566925049)
[2024-12-17 03:24:57,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:57,631][root][INFO] - Training Epoch: 2/2, step 5901/7134 completed (loss: 0.18145093321800232, acc: 0.969072163105011)
[2024-12-17 03:24:57,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:58,017][root][INFO] - Training Epoch: 2/2, step 5902/7134 completed (loss: 0.12862929701805115, acc: 0.9591836929321289)
[2024-12-17 03:24:58,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:58,378][root][INFO] - Training Epoch: 2/2, step 5903/7134 completed (loss: 0.11283200979232788, acc: 0.991150438785553)
[2024-12-17 03:24:58,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:58,769][root][INFO] - Training Epoch: 2/2, step 5904/7134 completed (loss: 0.18206901848316193, acc: 0.9577465057373047)
[2024-12-17 03:24:58,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:59,113][root][INFO] - Training Epoch: 2/2, step 5905/7134 completed (loss: 0.15176863968372345, acc: 0.9662162065505981)
[2024-12-17 03:24:59,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:59,496][root][INFO] - Training Epoch: 2/2, step 5906/7134 completed (loss: 0.13550113141536713, acc: 0.9673202633857727)
[2024-12-17 03:24:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:24:59,873][root][INFO] - Training Epoch: 2/2, step 5907/7134 completed (loss: 0.08669163286685944, acc: 0.9861111044883728)
[2024-12-17 03:24:59,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:00,268][root][INFO] - Training Epoch: 2/2, step 5908/7134 completed (loss: 0.1289673149585724, acc: 0.9610389471054077)
[2024-12-17 03:25:00,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:00,773][root][INFO] - Training Epoch: 2/2, step 5909/7134 completed (loss: 0.14660345017910004, acc: 0.956204354763031)
[2024-12-17 03:25:00,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:01,172][root][INFO] - Training Epoch: 2/2, step 5910/7134 completed (loss: 0.2910284698009491, acc: 0.9271523356437683)
[2024-12-17 03:25:01,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:01,544][root][INFO] - Training Epoch: 2/2, step 5911/7134 completed (loss: 0.21683193743228912, acc: 0.939130425453186)
[2024-12-17 03:25:01,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:01,901][root][INFO] - Training Epoch: 2/2, step 5912/7134 completed (loss: 0.08374888449907303, acc: 0.984375)
[2024-12-17 03:25:02,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:02,273][root][INFO] - Training Epoch: 2/2, step 5913/7134 completed (loss: 0.14184696972370148, acc: 0.9526627063751221)
[2024-12-17 03:25:02,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:02,648][root][INFO] - Training Epoch: 2/2, step 5914/7134 completed (loss: 0.13108007609844208, acc: 0.9714285731315613)
[2024-12-17 03:25:02,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:03,030][root][INFO] - Training Epoch: 2/2, step 5915/7134 completed (loss: 0.2501924932003021, acc: 0.9541984796524048)
[2024-12-17 03:25:03,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:03,416][root][INFO] - Training Epoch: 2/2, step 5916/7134 completed (loss: 0.203878253698349, acc: 0.9602649211883545)
[2024-12-17 03:25:03,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:03,783][root][INFO] - Training Epoch: 2/2, step 5917/7134 completed (loss: 0.08720337599515915, acc: 0.9760000109672546)
[2024-12-17 03:25:03,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:04,178][root][INFO] - Training Epoch: 2/2, step 5918/7134 completed (loss: 0.2972046732902527, acc: 0.9370629191398621)
[2024-12-17 03:25:04,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:04,546][root][INFO] - Training Epoch: 2/2, step 5919/7134 completed (loss: 0.06473604589700699, acc: 0.9925373196601868)
[2024-12-17 03:25:04,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:04,930][root][INFO] - Training Epoch: 2/2, step 5920/7134 completed (loss: 0.12665998935699463, acc: 0.9552238583564758)
[2024-12-17 03:25:05,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:05,316][root][INFO] - Training Epoch: 2/2, step 5921/7134 completed (loss: 0.14325198531150818, acc: 0.9568965435028076)
[2024-12-17 03:25:05,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:05,715][root][INFO] - Training Epoch: 2/2, step 5922/7134 completed (loss: 0.6235758066177368, acc: 0.8782051205635071)
[2024-12-17 03:25:05,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:06,092][root][INFO] - Training Epoch: 2/2, step 5923/7134 completed (loss: 0.25123584270477295, acc: 0.9556962251663208)
[2024-12-17 03:25:06,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:06,467][root][INFO] - Training Epoch: 2/2, step 5924/7134 completed (loss: 0.14647804200649261, acc: 0.9519230723381042)
[2024-12-17 03:25:06,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:06,810][root][INFO] - Training Epoch: 2/2, step 5925/7134 completed (loss: 0.4849388599395752, acc: 0.9111111164093018)
[2024-12-17 03:25:06,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:07,192][root][INFO] - Training Epoch: 2/2, step 5926/7134 completed (loss: 0.3449242115020752, acc: 0.9078947305679321)
[2024-12-17 03:25:07,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:07,572][root][INFO] - Training Epoch: 2/2, step 5927/7134 completed (loss: 0.33078500628471375, acc: 0.9196428656578064)
[2024-12-17 03:25:07,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:07,899][root][INFO] - Training Epoch: 2/2, step 5928/7134 completed (loss: 0.9042068719863892, acc: 0.8513513803482056)
[2024-12-17 03:25:08,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:08,286][root][INFO] - Training Epoch: 2/2, step 5929/7134 completed (loss: 0.2526217997074127, acc: 0.9354838728904724)
[2024-12-17 03:25:08,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:08,657][root][INFO] - Training Epoch: 2/2, step 5930/7134 completed (loss: 0.4757607877254486, acc: 0.9173553586006165)
[2024-12-17 03:25:08,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:09,037][root][INFO] - Training Epoch: 2/2, step 5931/7134 completed (loss: 0.21665990352630615, acc: 0.9572649598121643)
[2024-12-17 03:25:09,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:09,421][root][INFO] - Training Epoch: 2/2, step 5932/7134 completed (loss: 0.4967457056045532, acc: 0.8992805480957031)
[2024-12-17 03:25:09,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:09,789][root][INFO] - Training Epoch: 2/2, step 5933/7134 completed (loss: 0.4886719286441803, acc: 0.8970588445663452)
[2024-12-17 03:25:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:10,160][root][INFO] - Training Epoch: 2/2, step 5934/7134 completed (loss: 0.24199406802654266, acc: 0.9428571462631226)
[2024-12-17 03:25:10,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:10,530][root][INFO] - Training Epoch: 2/2, step 5935/7134 completed (loss: 0.10228341817855835, acc: 0.9672130942344666)
[2024-12-17 03:25:10,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:10,852][root][INFO] - Training Epoch: 2/2, step 5936/7134 completed (loss: 0.3993106186389923, acc: 0.9447852969169617)
[2024-12-17 03:25:10,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:11,224][root][INFO] - Training Epoch: 2/2, step 5937/7134 completed (loss: 0.16956110298633575, acc: 0.9647887349128723)
[2024-12-17 03:25:11,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:11,583][root][INFO] - Training Epoch: 2/2, step 5938/7134 completed (loss: 0.1791284680366516, acc: 0.9624060392379761)
[2024-12-17 03:25:11,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:11,952][root][INFO] - Training Epoch: 2/2, step 5939/7134 completed (loss: 0.8706533908843994, acc: 0.8362069129943848)
[2024-12-17 03:25:12,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:12,338][root][INFO] - Training Epoch: 2/2, step 5940/7134 completed (loss: 0.27547720074653625, acc: 0.9378882050514221)
[2024-12-17 03:25:12,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:12,700][root][INFO] - Training Epoch: 2/2, step 5941/7134 completed (loss: 0.30801716446876526, acc: 0.9047619104385376)
[2024-12-17 03:25:12,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:13,079][root][INFO] - Training Epoch: 2/2, step 5942/7134 completed (loss: 0.08911829441785812, acc: 0.9679999947547913)
[2024-12-17 03:25:13,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:13,456][root][INFO] - Training Epoch: 2/2, step 5943/7134 completed (loss: 0.09322059154510498, acc: 0.9815950989723206)
[2024-12-17 03:25:13,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:13,837][root][INFO] - Training Epoch: 2/2, step 5944/7134 completed (loss: 0.20604850351810455, acc: 0.9387755393981934)
[2024-12-17 03:25:13,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:14,233][root][INFO] - Training Epoch: 2/2, step 5945/7134 completed (loss: 0.08347124606370926, acc: 0.976331353187561)
[2024-12-17 03:25:14,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:14,590][root][INFO] - Training Epoch: 2/2, step 5946/7134 completed (loss: 0.13003060221672058, acc: 0.9652777910232544)
[2024-12-17 03:25:14,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:14,975][root][INFO] - Training Epoch: 2/2, step 5947/7134 completed (loss: 0.2287473976612091, acc: 0.932692289352417)
[2024-12-17 03:25:15,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:15,339][root][INFO] - Training Epoch: 2/2, step 5948/7134 completed (loss: 0.24094796180725098, acc: 0.9430894255638123)
[2024-12-17 03:25:15,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:15,730][root][INFO] - Training Epoch: 2/2, step 5949/7134 completed (loss: 0.09079664200544357, acc: 0.9666666388511658)
[2024-12-17 03:25:15,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:16,125][root][INFO] - Training Epoch: 2/2, step 5950/7134 completed (loss: 0.3744644820690155, acc: 0.9207921028137207)
[2024-12-17 03:25:16,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:16,504][root][INFO] - Training Epoch: 2/2, step 5951/7134 completed (loss: 0.28735724091529846, acc: 0.9285714030265808)
[2024-12-17 03:25:16,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:16,889][root][INFO] - Training Epoch: 2/2, step 5952/7134 completed (loss: 0.5343812704086304, acc: 0.9210526347160339)
[2024-12-17 03:25:16,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:17,259][root][INFO] - Training Epoch: 2/2, step 5953/7134 completed (loss: 0.20024223625659943, acc: 0.9245283007621765)
[2024-12-17 03:25:17,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:17,624][root][INFO] - Training Epoch: 2/2, step 5954/7134 completed (loss: 0.14692328870296478, acc: 0.9603960514068604)
[2024-12-17 03:25:17,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:17,996][root][INFO] - Training Epoch: 2/2, step 5955/7134 completed (loss: 0.2335672229528427, acc: 0.9629629850387573)
[2024-12-17 03:25:18,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:18,337][root][INFO] - Training Epoch: 2/2, step 5956/7134 completed (loss: 0.3520040512084961, acc: 0.9166666865348816)
[2024-12-17 03:25:18,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:18,729][root][INFO] - Training Epoch: 2/2, step 5957/7134 completed (loss: 0.13916340470314026, acc: 0.9695122241973877)
[2024-12-17 03:25:18,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:19,107][root][INFO] - Training Epoch: 2/2, step 5958/7134 completed (loss: 0.19724589586257935, acc: 0.9371428489685059)
[2024-12-17 03:25:19,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:19,472][root][INFO] - Training Epoch: 2/2, step 5959/7134 completed (loss: 0.17424127459526062, acc: 0.9627659320831299)
[2024-12-17 03:25:19,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:19,884][root][INFO] - Training Epoch: 2/2, step 5960/7134 completed (loss: 0.035993825644254684, acc: 0.9940476417541504)
[2024-12-17 03:25:20,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:20,282][root][INFO] - Training Epoch: 2/2, step 5961/7134 completed (loss: 0.24661768972873688, acc: 0.9259259104728699)
[2024-12-17 03:25:20,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:20,622][root][INFO] - Training Epoch: 2/2, step 5962/7134 completed (loss: 0.10646893084049225, acc: 0.9655172228813171)
[2024-12-17 03:25:20,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:20,981][root][INFO] - Training Epoch: 2/2, step 5963/7134 completed (loss: 0.0987657681107521, acc: 0.9885714054107666)
[2024-12-17 03:25:21,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:21,337][root][INFO] - Training Epoch: 2/2, step 5964/7134 completed (loss: 0.051885224878787994, acc: 0.9842519760131836)
[2024-12-17 03:25:21,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:21,712][root][INFO] - Training Epoch: 2/2, step 5965/7134 completed (loss: 0.12424182891845703, acc: 0.9743589758872986)
[2024-12-17 03:25:21,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:22,090][root][INFO] - Training Epoch: 2/2, step 5966/7134 completed (loss: 0.14610832929611206, acc: 0.9619565010070801)
[2024-12-17 03:25:22,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:22,426][root][INFO] - Training Epoch: 2/2, step 5967/7134 completed (loss: 0.1015511006116867, acc: 0.9791666865348816)
[2024-12-17 03:25:22,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:22,843][root][INFO] - Training Epoch: 2/2, step 5968/7134 completed (loss: 0.2057294100522995, acc: 0.9599999785423279)
[2024-12-17 03:25:22,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:23,227][root][INFO] - Training Epoch: 2/2, step 5969/7134 completed (loss: 0.1443324238061905, acc: 0.9612902998924255)
[2024-12-17 03:25:23,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:23,642][root][INFO] - Training Epoch: 2/2, step 5970/7134 completed (loss: 0.1521136462688446, acc: 0.96875)
[2024-12-17 03:25:23,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:24,023][root][INFO] - Training Epoch: 2/2, step 5971/7134 completed (loss: 0.07019699364900589, acc: 0.9789473414421082)
[2024-12-17 03:25:24,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:24,428][root][INFO] - Training Epoch: 2/2, step 5972/7134 completed (loss: 0.2653169631958008, acc: 0.9325153231620789)
[2024-12-17 03:25:24,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:24,921][root][INFO] - Training Epoch: 2/2, step 5973/7134 completed (loss: 0.2810799777507782, acc: 0.9485714435577393)
[2024-12-17 03:25:25,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:25,347][root][INFO] - Training Epoch: 2/2, step 5974/7134 completed (loss: 0.07309339195489883, acc: 0.9926470518112183)
[2024-12-17 03:25:25,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:25,738][root][INFO] - Training Epoch: 2/2, step 5975/7134 completed (loss: 0.10570546239614487, acc: 0.9695122241973877)
[2024-12-17 03:25:25,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:26,092][root][INFO] - Training Epoch: 2/2, step 5976/7134 completed (loss: 0.17037062346935272, acc: 0.9673202633857727)
[2024-12-17 03:25:26,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:26,491][root][INFO] - Training Epoch: 2/2, step 5977/7134 completed (loss: 0.1576545089483261, acc: 0.9649999737739563)
[2024-12-17 03:25:26,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:26,871][root][INFO] - Training Epoch: 2/2, step 5978/7134 completed (loss: 0.18548725545406342, acc: 0.9503105878829956)
[2024-12-17 03:25:27,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:27,254][root][INFO] - Training Epoch: 2/2, step 5979/7134 completed (loss: 0.22182315587997437, acc: 0.9473684430122375)
[2024-12-17 03:25:27,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:27,661][root][INFO] - Training Epoch: 2/2, step 5980/7134 completed (loss: 0.11428869515657425, acc: 0.967391312122345)
[2024-12-17 03:25:27,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:28,037][root][INFO] - Training Epoch: 2/2, step 5981/7134 completed (loss: 0.09365120530128479, acc: 0.989847719669342)
[2024-12-17 03:25:28,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:28,389][root][INFO] - Training Epoch: 2/2, step 5982/7134 completed (loss: 0.09722612053155899, acc: 0.9838709831237793)
[2024-12-17 03:25:28,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:28,756][root][INFO] - Training Epoch: 2/2, step 5983/7134 completed (loss: 0.200935497879982, acc: 0.9482758641242981)
[2024-12-17 03:25:28,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:29,117][root][INFO] - Training Epoch: 2/2, step 5984/7134 completed (loss: 0.16041041910648346, acc: 0.9696969985961914)
[2024-12-17 03:25:29,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:29,484][root][INFO] - Training Epoch: 2/2, step 5985/7134 completed (loss: 0.11257237941026688, acc: 0.9719101190567017)
[2024-12-17 03:25:29,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:29,874][root][INFO] - Training Epoch: 2/2, step 5986/7134 completed (loss: 0.20185083150863647, acc: 0.9682539701461792)
[2024-12-17 03:25:30,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:30,292][root][INFO] - Training Epoch: 2/2, step 5987/7134 completed (loss: 0.17930011451244354, acc: 0.9609755873680115)
[2024-12-17 03:25:30,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:30,706][root][INFO] - Training Epoch: 2/2, step 5988/7134 completed (loss: 0.13686932623386383, acc: 0.9666666388511658)
[2024-12-17 03:25:30,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:31,113][root][INFO] - Training Epoch: 2/2, step 5989/7134 completed (loss: 0.13446584343910217, acc: 0.9615384340286255)
[2024-12-17 03:25:31,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:31,538][root][INFO] - Training Epoch: 2/2, step 5990/7134 completed (loss: 0.16158337891101837, acc: 0.9613259434700012)
[2024-12-17 03:25:31,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:31,830][root][INFO] - Training Epoch: 2/2, step 5991/7134 completed (loss: 0.2386433631181717, acc: 0.9545454382896423)
[2024-12-17 03:25:31,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:32,204][root][INFO] - Training Epoch: 2/2, step 5992/7134 completed (loss: 0.09466598182916641, acc: 0.9744898080825806)
[2024-12-17 03:25:32,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:32,568][root][INFO] - Training Epoch: 2/2, step 5993/7134 completed (loss: 0.09759245067834854, acc: 0.9775280952453613)
[2024-12-17 03:25:32,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:32,947][root][INFO] - Training Epoch: 2/2, step 5994/7134 completed (loss: 0.08536551892757416, acc: 0.9586777091026306)
[2024-12-17 03:25:33,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:33,316][root][INFO] - Training Epoch: 2/2, step 5995/7134 completed (loss: 0.1323329508304596, acc: 0.9595375657081604)
[2024-12-17 03:25:33,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:33,727][root][INFO] - Training Epoch: 2/2, step 5996/7134 completed (loss: 0.1329086869955063, acc: 0.9599999785423279)
[2024-12-17 03:25:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:34,109][root][INFO] - Training Epoch: 2/2, step 5997/7134 completed (loss: 0.13358968496322632, acc: 0.9715909361839294)
[2024-12-17 03:25:34,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:34,527][root][INFO] - Training Epoch: 2/2, step 5998/7134 completed (loss: 0.10747721046209335, acc: 0.9576719403266907)
[2024-12-17 03:25:34,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:34,919][root][INFO] - Training Epoch: 2/2, step 5999/7134 completed (loss: 0.0566365122795105, acc: 0.9855072498321533)
[2024-12-17 03:25:35,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:35,242][root][INFO] - Training Epoch: 2/2, step 6000/7134 completed (loss: 0.07303454726934433, acc: 0.9718309640884399)
[2024-12-17 03:25:35,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:35,618][root][INFO] - Training Epoch: 2/2, step 6001/7134 completed (loss: 0.04184164106845856, acc: 0.9938650131225586)
[2024-12-17 03:25:35,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:36,031][root][INFO] - Training Epoch: 2/2, step 6002/7134 completed (loss: 0.1192626953125, acc: 0.9669421315193176)
[2024-12-17 03:25:36,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:36,424][root][INFO] - Training Epoch: 2/2, step 6003/7134 completed (loss: 0.18854163587093353, acc: 0.9350649118423462)
[2024-12-17 03:25:36,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:36,804][root][INFO] - Training Epoch: 2/2, step 6004/7134 completed (loss: 0.3791922330856323, acc: 0.913294792175293)
[2024-12-17 03:25:36,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:37,208][root][INFO] - Training Epoch: 2/2, step 6005/7134 completed (loss: 0.1876116842031479, acc: 0.9536423683166504)
[2024-12-17 03:25:37,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:37,615][root][INFO] - Training Epoch: 2/2, step 6006/7134 completed (loss: 0.23436130583286285, acc: 0.9359999895095825)
[2024-12-17 03:25:37,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:37,983][root][INFO] - Training Epoch: 2/2, step 6007/7134 completed (loss: 0.17501282691955566, acc: 0.9411764740943909)
[2024-12-17 03:25:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:38,354][root][INFO] - Training Epoch: 2/2, step 6008/7134 completed (loss: 0.20774707198143005, acc: 0.9440559148788452)
[2024-12-17 03:25:38,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:38,731][root][INFO] - Training Epoch: 2/2, step 6009/7134 completed (loss: 0.09754858911037445, acc: 0.9924812316894531)
[2024-12-17 03:25:38,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:39,137][root][INFO] - Training Epoch: 2/2, step 6010/7134 completed (loss: 0.21994322538375854, acc: 0.9240506291389465)
[2024-12-17 03:25:39,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:39,520][root][INFO] - Training Epoch: 2/2, step 6011/7134 completed (loss: 0.28767409920692444, acc: 0.9404761791229248)
[2024-12-17 03:25:39,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:39,921][root][INFO] - Training Epoch: 2/2, step 6012/7134 completed (loss: 0.1012294739484787, acc: 0.9696969985961914)
[2024-12-17 03:25:40,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:40,298][root][INFO] - Training Epoch: 2/2, step 6013/7134 completed (loss: 0.17627917230129242, acc: 0.966292142868042)
[2024-12-17 03:25:40,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:40,665][root][INFO] - Training Epoch: 2/2, step 6014/7134 completed (loss: 0.14959868788719177, acc: 0.960629940032959)
[2024-12-17 03:25:40,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:41,113][root][INFO] - Training Epoch: 2/2, step 6015/7134 completed (loss: 0.2014082372188568, acc: 0.9459459185600281)
[2024-12-17 03:25:41,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:41,495][root][INFO] - Training Epoch: 2/2, step 6016/7134 completed (loss: 0.09386180341243744, acc: 0.9864864945411682)
[2024-12-17 03:25:41,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:41,884][root][INFO] - Training Epoch: 2/2, step 6017/7134 completed (loss: 0.2855032682418823, acc: 0.9615384340286255)
[2024-12-17 03:25:42,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:42,323][root][INFO] - Training Epoch: 2/2, step 6018/7134 completed (loss: 0.1441156268119812, acc: 0.942307710647583)
[2024-12-17 03:25:42,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:42,683][root][INFO] - Training Epoch: 2/2, step 6019/7134 completed (loss: 0.18595477938652039, acc: 0.9444444179534912)
[2024-12-17 03:25:42,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:43,108][root][INFO] - Training Epoch: 2/2, step 6020/7134 completed (loss: 0.025428926572203636, acc: 1.0)
[2024-12-17 03:25:43,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:43,472][root][INFO] - Training Epoch: 2/2, step 6021/7134 completed (loss: 0.10465157777070999, acc: 0.9512194991111755)
[2024-12-17 03:25:43,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:43,817][root][INFO] - Training Epoch: 2/2, step 6022/7134 completed (loss: 0.2013130486011505, acc: 0.9342105388641357)
[2024-12-17 03:25:43,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:44,116][root][INFO] - Training Epoch: 2/2, step 6023/7134 completed (loss: 0.058059800416231155, acc: 0.9886363744735718)
[2024-12-17 03:25:44,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:44,471][root][INFO] - Training Epoch: 2/2, step 6024/7134 completed (loss: 0.023237356916069984, acc: 1.0)
[2024-12-17 03:25:44,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:44,819][root][INFO] - Training Epoch: 2/2, step 6025/7134 completed (loss: 0.12473983317613602, acc: 0.9590163826942444)
[2024-12-17 03:25:44,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:45,156][root][INFO] - Training Epoch: 2/2, step 6026/7134 completed (loss: 0.2978302538394928, acc: 0.9152542352676392)
[2024-12-17 03:25:45,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:45,438][root][INFO] - Training Epoch: 2/2, step 6027/7134 completed (loss: 0.0944817066192627, acc: 0.9775280952453613)
[2024-12-17 03:25:45,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:45,783][root][INFO] - Training Epoch: 2/2, step 6028/7134 completed (loss: 0.1118990033864975, acc: 0.9666666388511658)
[2024-12-17 03:25:45,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:46,138][root][INFO] - Training Epoch: 2/2, step 6029/7134 completed (loss: 0.16169561445713043, acc: 0.9577465057373047)
[2024-12-17 03:25:46,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:46,547][root][INFO] - Training Epoch: 2/2, step 6030/7134 completed (loss: 0.0664258673787117, acc: 1.0)
[2024-12-17 03:25:46,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:47,013][root][INFO] - Training Epoch: 2/2, step 6031/7134 completed (loss: 0.06440997868776321, acc: 0.9883720874786377)
[2024-12-17 03:25:47,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:47,394][root][INFO] - Training Epoch: 2/2, step 6032/7134 completed (loss: 0.04448462650179863, acc: 0.9900990128517151)
[2024-12-17 03:25:47,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:47,815][root][INFO] - Training Epoch: 2/2, step 6033/7134 completed (loss: 0.22560982406139374, acc: 0.9545454382896423)
[2024-12-17 03:25:47,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:48,221][root][INFO] - Training Epoch: 2/2, step 6034/7134 completed (loss: 0.34921756386756897, acc: 0.9104477763175964)
[2024-12-17 03:25:48,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:48,637][root][INFO] - Training Epoch: 2/2, step 6035/7134 completed (loss: 0.35752779245376587, acc: 0.9061033129692078)
[2024-12-17 03:25:48,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:49,038][root][INFO] - Training Epoch: 2/2, step 6036/7134 completed (loss: 0.3665185272693634, acc: 0.9269663095474243)
[2024-12-17 03:25:49,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:49,414][root][INFO] - Training Epoch: 2/2, step 6037/7134 completed (loss: 0.2623993754386902, acc: 0.9290780425071716)
[2024-12-17 03:25:49,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:49,843][root][INFO] - Training Epoch: 2/2, step 6038/7134 completed (loss: 0.21317578852176666, acc: 0.9313725233078003)
[2024-12-17 03:25:49,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:50,251][root][INFO] - Training Epoch: 2/2, step 6039/7134 completed (loss: 0.24369196593761444, acc: 0.9463414549827576)
[2024-12-17 03:25:50,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:50,638][root][INFO] - Training Epoch: 2/2, step 6040/7134 completed (loss: 0.15893608331680298, acc: 0.9603524208068848)
[2024-12-17 03:25:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:51,010][root][INFO] - Training Epoch: 2/2, step 6041/7134 completed (loss: 0.2758050858974457, acc: 0.9301075339317322)
[2024-12-17 03:25:51,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:51,390][root][INFO] - Training Epoch: 2/2, step 6042/7134 completed (loss: 0.09356053173542023, acc: 0.963302731513977)
[2024-12-17 03:25:51,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:51,779][root][INFO] - Training Epoch: 2/2, step 6043/7134 completed (loss: 0.17372344434261322, acc: 0.9516128897666931)
[2024-12-17 03:25:51,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:52,173][root][INFO] - Training Epoch: 2/2, step 6044/7134 completed (loss: 0.13247063755989075, acc: 0.9571428298950195)
[2024-12-17 03:25:52,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:52,539][root][INFO] - Training Epoch: 2/2, step 6045/7134 completed (loss: 0.21688660979270935, acc: 0.9330143332481384)
[2024-12-17 03:25:52,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:52,945][root][INFO] - Training Epoch: 2/2, step 6046/7134 completed (loss: 0.3240378797054291, acc: 0.8835616707801819)
[2024-12-17 03:25:53,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:53,369][root][INFO] - Training Epoch: 2/2, step 6047/7134 completed (loss: 0.4563387930393219, acc: 0.884353756904602)
[2024-12-17 03:25:53,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:53,775][root][INFO] - Training Epoch: 2/2, step 6048/7134 completed (loss: 0.3786894977092743, acc: 0.8943089246749878)
[2024-12-17 03:25:53,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:54,142][root][INFO] - Training Epoch: 2/2, step 6049/7134 completed (loss: 0.15816427767276764, acc: 0.9510489702224731)
[2024-12-17 03:25:54,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:54,507][root][INFO] - Training Epoch: 2/2, step 6050/7134 completed (loss: 0.304998517036438, acc: 0.9248554706573486)
[2024-12-17 03:25:54,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:54,896][root][INFO] - Training Epoch: 2/2, step 6051/7134 completed (loss: 0.4091053009033203, acc: 0.8863636255264282)
[2024-12-17 03:25:55,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:55,302][root][INFO] - Training Epoch: 2/2, step 6052/7134 completed (loss: 0.304136723279953, acc: 0.9133333563804626)
[2024-12-17 03:25:55,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:55,710][root][INFO] - Training Epoch: 2/2, step 6053/7134 completed (loss: 0.2855801582336426, acc: 0.9115044474601746)
[2024-12-17 03:25:55,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:56,077][root][INFO] - Training Epoch: 2/2, step 6054/7134 completed (loss: 0.16131731867790222, acc: 0.9533678889274597)
[2024-12-17 03:25:56,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:56,425][root][INFO] - Training Epoch: 2/2, step 6055/7134 completed (loss: 0.2267824411392212, acc: 0.9090909361839294)
[2024-12-17 03:25:56,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:56,820][root][INFO] - Training Epoch: 2/2, step 6056/7134 completed (loss: 0.29020631313323975, acc: 0.9099099040031433)
[2024-12-17 03:25:56,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:57,176][root][INFO] - Training Epoch: 2/2, step 6057/7134 completed (loss: 0.1548995077610016, acc: 0.948051929473877)
[2024-12-17 03:25:57,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:57,547][root][INFO] - Training Epoch: 2/2, step 6058/7134 completed (loss: 0.09418527036905289, acc: 0.9830508232116699)
[2024-12-17 03:25:57,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:57,893][root][INFO] - Training Epoch: 2/2, step 6059/7134 completed (loss: 0.08656413853168488, acc: 0.9726027250289917)
[2024-12-17 03:25:58,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:58,267][root][INFO] - Training Epoch: 2/2, step 6060/7134 completed (loss: 0.16871105134487152, acc: 0.9506173133850098)
[2024-12-17 03:25:58,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:58,651][root][INFO] - Training Epoch: 2/2, step 6061/7134 completed (loss: 0.3009190559387207, acc: 0.9295774698257446)
[2024-12-17 03:25:58,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:59,013][root][INFO] - Training Epoch: 2/2, step 6062/7134 completed (loss: 0.32646670937538147, acc: 0.9259259104728699)
[2024-12-17 03:25:59,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:59,368][root][INFO] - Training Epoch: 2/2, step 6063/7134 completed (loss: 0.27326810359954834, acc: 0.9237288236618042)
[2024-12-17 03:25:59,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:25:59,752][root][INFO] - Training Epoch: 2/2, step 6064/7134 completed (loss: 0.2309717983007431, acc: 0.9440993666648865)
[2024-12-17 03:25:59,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:00,140][root][INFO] - Training Epoch: 2/2, step 6065/7134 completed (loss: 0.23177342116832733, acc: 0.9441624283790588)
[2024-12-17 03:26:00,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:00,508][root][INFO] - Training Epoch: 2/2, step 6066/7134 completed (loss: 0.3226492702960968, acc: 0.9185185432434082)
[2024-12-17 03:26:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:00,886][root][INFO] - Training Epoch: 2/2, step 6067/7134 completed (loss: 0.38836345076560974, acc: 0.9013158082962036)
[2024-12-17 03:26:01,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:01,362][root][INFO] - Training Epoch: 2/2, step 6068/7134 completed (loss: 0.4590369462966919, acc: 0.8540540337562561)
[2024-12-17 03:26:01,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:01,742][root][INFO] - Training Epoch: 2/2, step 6069/7134 completed (loss: 0.3672467768192291, acc: 0.8705882430076599)
[2024-12-17 03:26:01,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:02,105][root][INFO] - Training Epoch: 2/2, step 6070/7134 completed (loss: 0.26794710755348206, acc: 0.9200000166893005)
[2024-12-17 03:26:02,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:02,446][root][INFO] - Training Epoch: 2/2, step 6071/7134 completed (loss: 0.35714009404182434, acc: 0.9053254723548889)
[2024-12-17 03:26:02,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:02,810][root][INFO] - Training Epoch: 2/2, step 6072/7134 completed (loss: 0.45464619994163513, acc: 0.8583333492279053)
[2024-12-17 03:26:02,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:03,192][root][INFO] - Training Epoch: 2/2, step 6073/7134 completed (loss: 0.2508479952812195, acc: 0.9235668778419495)
[2024-12-17 03:26:03,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:03,577][root][INFO] - Training Epoch: 2/2, step 6074/7134 completed (loss: 0.3626802861690521, acc: 0.9161290526390076)
[2024-12-17 03:26:03,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:03,962][root][INFO] - Training Epoch: 2/2, step 6075/7134 completed (loss: 0.2166069597005844, acc: 0.9368420839309692)
[2024-12-17 03:26:04,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:04,328][root][INFO] - Training Epoch: 2/2, step 6076/7134 completed (loss: 0.34879976511001587, acc: 0.8983957171440125)
[2024-12-17 03:26:04,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:04,696][root][INFO] - Training Epoch: 2/2, step 6077/7134 completed (loss: 0.2509593367576599, acc: 0.9526627063751221)
[2024-12-17 03:26:04,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:05,065][root][INFO] - Training Epoch: 2/2, step 6078/7134 completed (loss: 0.32091453671455383, acc: 0.9209039807319641)
[2024-12-17 03:26:05,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:05,465][root][INFO] - Training Epoch: 2/2, step 6079/7134 completed (loss: 0.17962756752967834, acc: 0.9545454382896423)
[2024-12-17 03:26:05,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:05,848][root][INFO] - Training Epoch: 2/2, step 6080/7134 completed (loss: 0.1528477519750595, acc: 0.959770143032074)
[2024-12-17 03:26:05,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:06,220][root][INFO] - Training Epoch: 2/2, step 6081/7134 completed (loss: 0.225075364112854, acc: 0.9527027010917664)
[2024-12-17 03:26:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:06,605][root][INFO] - Training Epoch: 2/2, step 6082/7134 completed (loss: 0.1355694979429245, acc: 0.9597315192222595)
[2024-12-17 03:26:06,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:06,994][root][INFO] - Training Epoch: 2/2, step 6083/7134 completed (loss: 0.11165709048509598, acc: 0.9740932583808899)
[2024-12-17 03:26:07,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:07,362][root][INFO] - Training Epoch: 2/2, step 6084/7134 completed (loss: 0.142271488904953, acc: 0.9800000190734863)
[2024-12-17 03:26:07,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:07,745][root][INFO] - Training Epoch: 2/2, step 6085/7134 completed (loss: 0.1976027935743332, acc: 0.9444444179534912)
[2024-12-17 03:26:07,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:08,140][root][INFO] - Training Epoch: 2/2, step 6086/7134 completed (loss: 0.047270696610212326, acc: 0.9890710115432739)
[2024-12-17 03:26:08,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:08,525][root][INFO] - Training Epoch: 2/2, step 6087/7134 completed (loss: 0.28884434700012207, acc: 0.9411764740943909)
[2024-12-17 03:26:08,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:08,891][root][INFO] - Training Epoch: 2/2, step 6088/7134 completed (loss: 0.2741081118583679, acc: 0.9513513445854187)
[2024-12-17 03:26:09,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:09,270][root][INFO] - Training Epoch: 2/2, step 6089/7134 completed (loss: 0.10547585785388947, acc: 0.977142870426178)
[2024-12-17 03:26:09,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:09,651][root][INFO] - Training Epoch: 2/2, step 6090/7134 completed (loss: 0.08662403374910355, acc: 0.9786096215248108)
[2024-12-17 03:26:09,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:10,011][root][INFO] - Training Epoch: 2/2, step 6091/7134 completed (loss: 0.1255531907081604, acc: 0.9745222926139832)
[2024-12-17 03:26:10,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:10,392][root][INFO] - Training Epoch: 2/2, step 6092/7134 completed (loss: 0.25525805354118347, acc: 0.9333333373069763)
[2024-12-17 03:26:10,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:10,758][root][INFO] - Training Epoch: 2/2, step 6093/7134 completed (loss: 0.16622723639011383, acc: 0.9552238583564758)
[2024-12-17 03:26:10,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:11,132][root][INFO] - Training Epoch: 2/2, step 6094/7134 completed (loss: 0.41630780696868896, acc: 0.9034090638160706)
[2024-12-17 03:26:11,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:11,463][root][INFO] - Training Epoch: 2/2, step 6095/7134 completed (loss: 0.1664944291114807, acc: 0.9447852969169617)
[2024-12-17 03:26:11,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:11,905][root][INFO] - Training Epoch: 2/2, step 6096/7134 completed (loss: 0.24856412410736084, acc: 0.9340101480484009)
[2024-12-17 03:26:12,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:12,271][root][INFO] - Training Epoch: 2/2, step 6097/7134 completed (loss: 0.21168462932109833, acc: 0.9254658222198486)
[2024-12-17 03:26:12,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:12,651][root][INFO] - Training Epoch: 2/2, step 6098/7134 completed (loss: 0.20870904624462128, acc: 0.9356725215911865)
[2024-12-17 03:26:12,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:13,036][root][INFO] - Training Epoch: 2/2, step 6099/7134 completed (loss: 0.15410852432250977, acc: 0.9455782175064087)
[2024-12-17 03:26:13,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:13,393][root][INFO] - Training Epoch: 2/2, step 6100/7134 completed (loss: 0.2957276701927185, acc: 0.9487179517745972)
[2024-12-17 03:26:13,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:13,766][root][INFO] - Training Epoch: 2/2, step 6101/7134 completed (loss: 0.1207883358001709, acc: 0.9583333134651184)
[2024-12-17 03:26:13,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:14,149][root][INFO] - Training Epoch: 2/2, step 6102/7134 completed (loss: 0.22217802703380585, acc: 0.953125)
[2024-12-17 03:26:14,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:14,482][root][INFO] - Training Epoch: 2/2, step 6103/7134 completed (loss: 0.12222030013799667, acc: 0.9727272987365723)
[2024-12-17 03:26:14,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:14,829][root][INFO] - Training Epoch: 2/2, step 6104/7134 completed (loss: 0.5251990556716919, acc: 0.8783783912658691)
[2024-12-17 03:26:14,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:15,180][root][INFO] - Training Epoch: 2/2, step 6105/7134 completed (loss: 0.5971039533615112, acc: 0.8787878751754761)
[2024-12-17 03:26:15,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:15,550][root][INFO] - Training Epoch: 2/2, step 6106/7134 completed (loss: 0.2448495626449585, acc: 0.960629940032959)
[2024-12-17 03:26:15,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:15,911][root][INFO] - Training Epoch: 2/2, step 6107/7134 completed (loss: 0.09840825945138931, acc: 0.9829059839248657)
[2024-12-17 03:26:16,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:16,264][root][INFO] - Training Epoch: 2/2, step 6108/7134 completed (loss: 0.26599591970443726, acc: 0.9256198406219482)
[2024-12-17 03:26:16,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:16,638][root][INFO] - Training Epoch: 2/2, step 6109/7134 completed (loss: 0.09332109242677689, acc: 0.9652174115180969)
[2024-12-17 03:26:16,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:17,052][root][INFO] - Training Epoch: 2/2, step 6110/7134 completed (loss: 0.37052640318870544, acc: 0.921875)
[2024-12-17 03:26:17,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:17,430][root][INFO] - Training Epoch: 2/2, step 6111/7134 completed (loss: 0.23839092254638672, acc: 0.95652174949646)
[2024-12-17 03:26:17,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:17,815][root][INFO] - Training Epoch: 2/2, step 6112/7134 completed (loss: 0.20528022944927216, acc: 0.9477124214172363)
[2024-12-17 03:26:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:18,190][root][INFO] - Training Epoch: 2/2, step 6113/7134 completed (loss: 0.34879302978515625, acc: 0.9512194991111755)
[2024-12-17 03:26:18,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:18,563][root][INFO] - Training Epoch: 2/2, step 6114/7134 completed (loss: 0.16477711498737335, acc: 0.9650349617004395)
[2024-12-17 03:26:18,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:18,908][root][INFO] - Training Epoch: 2/2, step 6115/7134 completed (loss: 0.18225498497486115, acc: 0.9520000219345093)
[2024-12-17 03:26:19,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:19,277][root][INFO] - Training Epoch: 2/2, step 6116/7134 completed (loss: 0.33878666162490845, acc: 0.9435483813285828)
[2024-12-17 03:26:19,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:19,663][root][INFO] - Training Epoch: 2/2, step 6117/7134 completed (loss: 0.20998220145702362, acc: 0.940119743347168)
[2024-12-17 03:26:19,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:20,035][root][INFO] - Training Epoch: 2/2, step 6118/7134 completed (loss: 0.0983773022890091, acc: 0.976190447807312)
[2024-12-17 03:26:20,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:20,414][root][INFO] - Training Epoch: 2/2, step 6119/7134 completed (loss: 0.13459910452365875, acc: 0.9621621370315552)
[2024-12-17 03:26:20,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:20,762][root][INFO] - Training Epoch: 2/2, step 6120/7134 completed (loss: 0.08603727072477341, acc: 0.9924242496490479)
[2024-12-17 03:26:20,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:21,127][root][INFO] - Training Epoch: 2/2, step 6121/7134 completed (loss: 0.23187299072742462, acc: 0.9448819160461426)
[2024-12-17 03:26:21,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:21,471][root][INFO] - Training Epoch: 2/2, step 6122/7134 completed (loss: 0.10141988098621368, acc: 0.9596773982048035)
[2024-12-17 03:26:21,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:21,852][root][INFO] - Training Epoch: 2/2, step 6123/7134 completed (loss: 0.168925479054451, acc: 0.9658119678497314)
[2024-12-17 03:26:21,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:22,208][root][INFO] - Training Epoch: 2/2, step 6124/7134 completed (loss: 0.13119269907474518, acc: 0.9663865566253662)
[2024-12-17 03:26:22,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:22,593][root][INFO] - Training Epoch: 2/2, step 6125/7134 completed (loss: 0.3210417628288269, acc: 0.9252336621284485)
[2024-12-17 03:26:22,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:22,967][root][INFO] - Training Epoch: 2/2, step 6126/7134 completed (loss: 0.20990432798862457, acc: 0.9668874144554138)
[2024-12-17 03:26:23,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:23,359][root][INFO] - Training Epoch: 2/2, step 6127/7134 completed (loss: 0.06727764755487442, acc: 0.9803921580314636)
[2024-12-17 03:26:23,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:23,711][root][INFO] - Training Epoch: 2/2, step 6128/7134 completed (loss: 0.15785232186317444, acc: 0.9579831957817078)
[2024-12-17 03:26:23,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:24,067][root][INFO] - Training Epoch: 2/2, step 6129/7134 completed (loss: 0.3185867965221405, acc: 0.9112426042556763)
[2024-12-17 03:26:24,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:24,420][root][INFO] - Training Epoch: 2/2, step 6130/7134 completed (loss: 0.3058829605579376, acc: 0.9402984976768494)
[2024-12-17 03:26:24,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:24,792][root][INFO] - Training Epoch: 2/2, step 6131/7134 completed (loss: 0.3026938736438751, acc: 0.9368932247161865)
[2024-12-17 03:26:24,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:25,120][root][INFO] - Training Epoch: 2/2, step 6132/7134 completed (loss: 0.1931753158569336, acc: 0.942307710647583)
[2024-12-17 03:26:25,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:25,501][root][INFO] - Training Epoch: 2/2, step 6133/7134 completed (loss: 0.2304585576057434, acc: 0.9375)
[2024-12-17 03:26:25,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:25,878][root][INFO] - Training Epoch: 2/2, step 6134/7134 completed (loss: 0.267257958650589, acc: 0.9364162087440491)
[2024-12-17 03:26:25,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:26,235][root][INFO] - Training Epoch: 2/2, step 6135/7134 completed (loss: 0.11166071146726608, acc: 0.9689922332763672)
[2024-12-17 03:26:26,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:26,594][root][INFO] - Training Epoch: 2/2, step 6136/7134 completed (loss: 0.21775110065937042, acc: 0.946107804775238)
[2024-12-17 03:26:26,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:26,965][root][INFO] - Training Epoch: 2/2, step 6137/7134 completed (loss: 0.19029715657234192, acc: 0.9740259647369385)
[2024-12-17 03:26:27,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:27,319][root][INFO] - Training Epoch: 2/2, step 6138/7134 completed (loss: 0.1913200169801712, acc: 0.9509202241897583)
[2024-12-17 03:26:27,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:27,667][root][INFO] - Training Epoch: 2/2, step 6139/7134 completed (loss: 0.36988919973373413, acc: 0.9047619104385376)
[2024-12-17 03:26:27,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:28,076][root][INFO] - Training Epoch: 2/2, step 6140/7134 completed (loss: 0.15984880924224854, acc: 0.9692307710647583)
[2024-12-17 03:26:28,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:28,438][root][INFO] - Training Epoch: 2/2, step 6141/7134 completed (loss: 0.40116432309150696, acc: 0.8840579986572266)
[2024-12-17 03:26:28,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:28,821][root][INFO] - Training Epoch: 2/2, step 6142/7134 completed (loss: 0.1462094932794571, acc: 0.9657142758369446)
[2024-12-17 03:26:28,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:29,189][root][INFO] - Training Epoch: 2/2, step 6143/7134 completed (loss: 0.2063598334789276, acc: 0.9575757384300232)
[2024-12-17 03:26:29,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:29,571][root][INFO] - Training Epoch: 2/2, step 6144/7134 completed (loss: 0.19711214303970337, acc: 0.9383561611175537)
[2024-12-17 03:26:29,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:29,953][root][INFO] - Training Epoch: 2/2, step 6145/7134 completed (loss: 0.29514390230178833, acc: 0.9453551769256592)
[2024-12-17 03:26:30,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:30,307][root][INFO] - Training Epoch: 2/2, step 6146/7134 completed (loss: 0.2820887863636017, acc: 0.9518072009086609)
[2024-12-17 03:26:30,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:30,686][root][INFO] - Training Epoch: 2/2, step 6147/7134 completed (loss: 0.11152777075767517, acc: 0.9842519760131836)
[2024-12-17 03:26:30,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:31,075][root][INFO] - Training Epoch: 2/2, step 6148/7134 completed (loss: 0.12635846436023712, acc: 0.9724137783050537)
[2024-12-17 03:26:31,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:31,442][root][INFO] - Training Epoch: 2/2, step 6149/7134 completed (loss: 0.2362125962972641, acc: 0.9602649211883545)
[2024-12-17 03:26:31,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:31,810][root][INFO] - Training Epoch: 2/2, step 6150/7134 completed (loss: 0.11543785780668259, acc: 0.9650349617004395)
[2024-12-17 03:26:31,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:32,127][root][INFO] - Training Epoch: 2/2, step 6151/7134 completed (loss: 0.10537058860063553, acc: 0.9808917045593262)
[2024-12-17 03:26:32,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:32,509][root][INFO] - Training Epoch: 2/2, step 6152/7134 completed (loss: 0.24358715116977692, acc: 0.9657142758369446)
[2024-12-17 03:26:32,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:32,881][root][INFO] - Training Epoch: 2/2, step 6153/7134 completed (loss: 0.10930363088846207, acc: 0.9814814925193787)
[2024-12-17 03:26:33,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:33,265][root][INFO] - Training Epoch: 2/2, step 6154/7134 completed (loss: 0.2109977900981903, acc: 0.9613259434700012)
[2024-12-17 03:26:33,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:33,622][root][INFO] - Training Epoch: 2/2, step 6155/7134 completed (loss: 0.17549386620521545, acc: 0.9467455744743347)
[2024-12-17 03:26:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:33,970][root][INFO] - Training Epoch: 2/2, step 6156/7134 completed (loss: 0.09861817955970764, acc: 0.9936708807945251)
[2024-12-17 03:26:34,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:34,347][root][INFO] - Training Epoch: 2/2, step 6157/7134 completed (loss: 0.15825605392456055, acc: 0.9746835231781006)
[2024-12-17 03:26:34,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:34,715][root][INFO] - Training Epoch: 2/2, step 6158/7134 completed (loss: 0.26091012358665466, acc: 0.9385964870452881)
[2024-12-17 03:26:34,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:35,098][root][INFO] - Training Epoch: 2/2, step 6159/7134 completed (loss: 0.16359810531139374, acc: 0.976190447807312)
[2024-12-17 03:26:35,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:35,477][root][INFO] - Training Epoch: 2/2, step 6160/7134 completed (loss: 0.33570510149002075, acc: 0.9044585824012756)
[2024-12-17 03:26:35,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:35,851][root][INFO] - Training Epoch: 2/2, step 6161/7134 completed (loss: 0.227054163813591, acc: 0.9527559280395508)
[2024-12-17 03:26:35,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:36,226][root][INFO] - Training Epoch: 2/2, step 6162/7134 completed (loss: 0.3430428206920624, acc: 0.9166666865348816)
[2024-12-17 03:26:36,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:36,591][root][INFO] - Training Epoch: 2/2, step 6163/7134 completed (loss: 0.4078480005264282, acc: 0.9147287011146545)
[2024-12-17 03:26:36,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:36,972][root][INFO] - Training Epoch: 2/2, step 6164/7134 completed (loss: 0.24995239078998566, acc: 0.9451219439506531)
[2024-12-17 03:26:37,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:37,335][root][INFO] - Training Epoch: 2/2, step 6165/7134 completed (loss: 0.24484799802303314, acc: 0.9465649127960205)
[2024-12-17 03:26:37,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:37,725][root][INFO] - Training Epoch: 2/2, step 6166/7134 completed (loss: 0.14487597346305847, acc: 0.970802903175354)
[2024-12-17 03:26:37,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:38,100][root][INFO] - Training Epoch: 2/2, step 6167/7134 completed (loss: 0.07326453924179077, acc: 0.9825581312179565)
[2024-12-17 03:26:38,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:38,481][root][INFO] - Training Epoch: 2/2, step 6168/7134 completed (loss: 0.10777941346168518, acc: 0.9838709831237793)
[2024-12-17 03:26:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:38,851][root][INFO] - Training Epoch: 2/2, step 6169/7134 completed (loss: 0.15328916907310486, acc: 0.9759036302566528)
[2024-12-17 03:26:38,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:39,218][root][INFO] - Training Epoch: 2/2, step 6170/7134 completed (loss: 0.1643531322479248, acc: 0.9568345546722412)
[2024-12-17 03:26:39,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:39,603][root][INFO] - Training Epoch: 2/2, step 6171/7134 completed (loss: 0.03902311250567436, acc: 0.9945054650306702)
[2024-12-17 03:26:39,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:39,978][root][INFO] - Training Epoch: 2/2, step 6172/7134 completed (loss: 0.17950451374053955, acc: 0.9453125)
[2024-12-17 03:26:40,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:40,357][root][INFO] - Training Epoch: 2/2, step 6173/7134 completed (loss: 0.13931450247764587, acc: 0.9551281929016113)
[2024-12-17 03:26:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:40,732][root][INFO] - Training Epoch: 2/2, step 6174/7134 completed (loss: 0.05778171494603157, acc: 0.9757575988769531)
[2024-12-17 03:26:40,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:41,111][root][INFO] - Training Epoch: 2/2, step 6175/7134 completed (loss: 0.1387912780046463, acc: 0.9629629850387573)
[2024-12-17 03:26:41,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:41,476][root][INFO] - Training Epoch: 2/2, step 6176/7134 completed (loss: 0.13938893377780914, acc: 0.9512194991111755)
[2024-12-17 03:26:41,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:41,839][root][INFO] - Training Epoch: 2/2, step 6177/7134 completed (loss: 0.0887080729007721, acc: 0.9780219793319702)
[2024-12-17 03:26:41,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:42,193][root][INFO] - Training Epoch: 2/2, step 6178/7134 completed (loss: 0.13890787959098816, acc: 0.9607843160629272)
[2024-12-17 03:26:42,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:42,553][root][INFO] - Training Epoch: 2/2, step 6179/7134 completed (loss: 0.2927688956260681, acc: 0.9333333373069763)
[2024-12-17 03:26:42,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:42,894][root][INFO] - Training Epoch: 2/2, step 6180/7134 completed (loss: 0.6494525074958801, acc: 0.8617021441459656)
[2024-12-17 03:26:42,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:43,238][root][INFO] - Training Epoch: 2/2, step 6181/7134 completed (loss: 0.6270397305488586, acc: 0.8611111044883728)
[2024-12-17 03:26:43,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:43,609][root][INFO] - Training Epoch: 2/2, step 6182/7134 completed (loss: 0.31395912170410156, acc: 0.930232584476471)
[2024-12-17 03:26:43,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:43,976][root][INFO] - Training Epoch: 2/2, step 6183/7134 completed (loss: 0.5945987105369568, acc: 0.8580247163772583)
[2024-12-17 03:26:44,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:44,304][root][INFO] - Training Epoch: 2/2, step 6184/7134 completed (loss: 0.5395483374595642, acc: 0.852173924446106)
[2024-12-17 03:26:44,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:44,702][root][INFO] - Training Epoch: 2/2, step 6185/7134 completed (loss: 0.2559199035167694, acc: 0.9193548560142517)
[2024-12-17 03:26:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:45,076][root][INFO] - Training Epoch: 2/2, step 6186/7134 completed (loss: 0.09437624365091324, acc: 0.9923664331436157)
[2024-12-17 03:26:45,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:45,463][root][INFO] - Training Epoch: 2/2, step 6187/7134 completed (loss: 0.22229117155075073, acc: 0.9532163739204407)
[2024-12-17 03:26:45,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:45,847][root][INFO] - Training Epoch: 2/2, step 6188/7134 completed (loss: 0.2026534229516983, acc: 0.9673202633857727)
[2024-12-17 03:26:45,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:46,219][root][INFO] - Training Epoch: 2/2, step 6189/7134 completed (loss: 0.3793671131134033, acc: 0.9230769276618958)
[2024-12-17 03:26:46,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:46,651][root][INFO] - Training Epoch: 2/2, step 6190/7134 completed (loss: 0.5948958992958069, acc: 0.9071428775787354)
[2024-12-17 03:26:46,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:47,030][root][INFO] - Training Epoch: 2/2, step 6191/7134 completed (loss: 0.2779657244682312, acc: 0.934959352016449)
[2024-12-17 03:26:47,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:47,409][root][INFO] - Training Epoch: 2/2, step 6192/7134 completed (loss: 0.16012921929359436, acc: 0.9560975432395935)
[2024-12-17 03:26:47,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:47,783][root][INFO] - Training Epoch: 2/2, step 6193/7134 completed (loss: 0.21428988873958588, acc: 0.939393937587738)
[2024-12-17 03:26:47,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:48,156][root][INFO] - Training Epoch: 2/2, step 6194/7134 completed (loss: 0.18677879869937897, acc: 0.9508196711540222)
[2024-12-17 03:26:48,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:48,554][root][INFO] - Training Epoch: 2/2, step 6195/7134 completed (loss: 0.2308250516653061, acc: 0.9245283007621765)
[2024-12-17 03:26:48,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:48,954][root][INFO] - Training Epoch: 2/2, step 6196/7134 completed (loss: 0.16714967787265778, acc: 0.9444444179534912)
[2024-12-17 03:26:49,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:49,333][root][INFO] - Training Epoch: 2/2, step 6197/7134 completed (loss: 0.21220900118350983, acc: 0.9375)
[2024-12-17 03:26:49,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:49,710][root][INFO] - Training Epoch: 2/2, step 6198/7134 completed (loss: 0.14991147816181183, acc: 0.9557521939277649)
[2024-12-17 03:26:49,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:50,113][root][INFO] - Training Epoch: 2/2, step 6199/7134 completed (loss: 0.1462828665971756, acc: 0.9629629850387573)
[2024-12-17 03:26:50,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:50,494][root][INFO] - Training Epoch: 2/2, step 6200/7134 completed (loss: 0.1279541254043579, acc: 0.9692307710647583)
[2024-12-17 03:26:50,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:50,874][root][INFO] - Training Epoch: 2/2, step 6201/7134 completed (loss: 0.10315979272127151, acc: 0.9712918400764465)
[2024-12-17 03:26:50,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:51,233][root][INFO] - Training Epoch: 2/2, step 6202/7134 completed (loss: 0.2739209532737732, acc: 0.9238095283508301)
[2024-12-17 03:26:51,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:51,574][root][INFO] - Training Epoch: 2/2, step 6203/7134 completed (loss: 0.1563432216644287, acc: 0.9593023061752319)
[2024-12-17 03:26:51,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:51,941][root][INFO] - Training Epoch: 2/2, step 6204/7134 completed (loss: 0.06065523251891136, acc: 0.9916666746139526)
[2024-12-17 03:26:52,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:52,357][root][INFO] - Training Epoch: 2/2, step 6205/7134 completed (loss: 0.12260567396879196, acc: 0.971222996711731)
[2024-12-17 03:26:52,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:52,703][root][INFO] - Training Epoch: 2/2, step 6206/7134 completed (loss: 0.12885479629039764, acc: 0.9751552939414978)
[2024-12-17 03:26:52,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:53,067][root][INFO] - Training Epoch: 2/2, step 6207/7134 completed (loss: 0.5084289312362671, acc: 0.8787878751754761)
[2024-12-17 03:26:53,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:53,426][root][INFO] - Training Epoch: 2/2, step 6208/7134 completed (loss: 0.13326048851013184, acc: 0.9635416865348816)
[2024-12-17 03:26:53,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:53,841][root][INFO] - Training Epoch: 2/2, step 6209/7134 completed (loss: 0.11760392785072327, acc: 0.9821428656578064)
[2024-12-17 03:26:53,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:54,248][root][INFO] - Training Epoch: 2/2, step 6210/7134 completed (loss: 0.16124610602855682, acc: 0.9572192430496216)
[2024-12-17 03:26:54,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:54,618][root][INFO] - Training Epoch: 2/2, step 6211/7134 completed (loss: 0.1613161414861679, acc: 0.939393937587738)
[2024-12-17 03:26:54,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:54,970][root][INFO] - Training Epoch: 2/2, step 6212/7134 completed (loss: 0.15903452038764954, acc: 0.9572649598121643)
[2024-12-17 03:26:55,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:55,312][root][INFO] - Training Epoch: 2/2, step 6213/7134 completed (loss: 0.12460961192846298, acc: 0.9545454382896423)
[2024-12-17 03:26:55,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:55,670][root][INFO] - Training Epoch: 2/2, step 6214/7134 completed (loss: 0.10885372012853622, acc: 0.9661017060279846)
[2024-12-17 03:26:55,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:56,054][root][INFO] - Training Epoch: 2/2, step 6215/7134 completed (loss: 0.16345907747745514, acc: 0.95652174949646)
[2024-12-17 03:26:56,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:56,401][root][INFO] - Training Epoch: 2/2, step 6216/7134 completed (loss: 0.09133903682231903, acc: 0.9795918464660645)
[2024-12-17 03:26:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:56,768][root][INFO] - Training Epoch: 2/2, step 6217/7134 completed (loss: 0.12037477642297745, acc: 0.9620253443717957)
[2024-12-17 03:26:56,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:57,165][root][INFO] - Training Epoch: 2/2, step 6218/7134 completed (loss: 0.13796019554138184, acc: 0.9677419066429138)
[2024-12-17 03:26:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:57,539][root][INFO] - Training Epoch: 2/2, step 6219/7134 completed (loss: 0.14276616275310516, acc: 0.9607843160629272)
[2024-12-17 03:26:57,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:57,838][root][INFO] - Training Epoch: 2/2, step 6220/7134 completed (loss: 0.302938312292099, acc: 0.9655172228813171)
[2024-12-17 03:26:57,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:58,211][root][INFO] - Training Epoch: 2/2, step 6221/7134 completed (loss: 0.06974183022975922, acc: 0.9776119589805603)
[2024-12-17 03:26:58,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:58,613][root][INFO] - Training Epoch: 2/2, step 6222/7134 completed (loss: 0.26726746559143066, acc: 0.9277108311653137)
[2024-12-17 03:26:58,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:59,001][root][INFO] - Training Epoch: 2/2, step 6223/7134 completed (loss: 0.2687807083129883, acc: 0.9427083134651184)
[2024-12-17 03:26:59,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:59,406][root][INFO] - Training Epoch: 2/2, step 6224/7134 completed (loss: 0.11508295685052872, acc: 0.9594594836235046)
[2024-12-17 03:26:59,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:26:59,808][root][INFO] - Training Epoch: 2/2, step 6225/7134 completed (loss: 0.1335320770740509, acc: 0.9664804339408875)
[2024-12-17 03:26:59,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:00,205][root][INFO] - Training Epoch: 2/2, step 6226/7134 completed (loss: 0.27608102560043335, acc: 0.9402173757553101)
[2024-12-17 03:27:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:00,574][root][INFO] - Training Epoch: 2/2, step 6227/7134 completed (loss: 0.12256290018558502, acc: 0.9750000238418579)
[2024-12-17 03:27:00,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:00,944][root][INFO] - Training Epoch: 2/2, step 6228/7134 completed (loss: 0.17077088356018066, acc: 0.9468085169792175)
[2024-12-17 03:27:01,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:01,347][root][INFO] - Training Epoch: 2/2, step 6229/7134 completed (loss: 0.3005288541316986, acc: 0.9317073225975037)
[2024-12-17 03:27:01,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:01,731][root][INFO] - Training Epoch: 2/2, step 6230/7134 completed (loss: 0.24912099540233612, acc: 0.9414893388748169)
[2024-12-17 03:27:01,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:02,082][root][INFO] - Training Epoch: 2/2, step 6231/7134 completed (loss: 0.10506080090999603, acc: 0.9649122953414917)
[2024-12-17 03:27:02,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:02,473][root][INFO] - Training Epoch: 2/2, step 6232/7134 completed (loss: 0.17062613368034363, acc: 0.9450549483299255)
[2024-12-17 03:27:02,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:02,846][root][INFO] - Training Epoch: 2/2, step 6233/7134 completed (loss: 0.10373104363679886, acc: 0.9712643623352051)
[2024-12-17 03:27:02,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:03,204][root][INFO] - Training Epoch: 2/2, step 6234/7134 completed (loss: 0.23450405895709991, acc: 0.9333333373069763)
[2024-12-17 03:27:03,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:03,563][root][INFO] - Training Epoch: 2/2, step 6235/7134 completed (loss: 0.0666632205247879, acc: 0.9940476417541504)
[2024-12-17 03:27:03,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:03,937][root][INFO] - Training Epoch: 2/2, step 6236/7134 completed (loss: 0.18053527176380157, acc: 0.9553072452545166)
[2024-12-17 03:27:04,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:04,307][root][INFO] - Training Epoch: 2/2, step 6237/7134 completed (loss: 0.28458020091056824, acc: 0.9265536665916443)
[2024-12-17 03:27:04,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:04,649][root][INFO] - Training Epoch: 2/2, step 6238/7134 completed (loss: 0.16497676074504852, acc: 0.9668874144554138)
[2024-12-17 03:27:04,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:05,020][root][INFO] - Training Epoch: 2/2, step 6239/7134 completed (loss: 0.1323821097612381, acc: 0.9585492014884949)
[2024-12-17 03:27:05,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:05,409][root][INFO] - Training Epoch: 2/2, step 6240/7134 completed (loss: 0.04293100908398628, acc: 0.9879518151283264)
[2024-12-17 03:27:05,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:05,829][root][INFO] - Training Epoch: 2/2, step 6241/7134 completed (loss: 0.07616695761680603, acc: 0.9866666793823242)
[2024-12-17 03:27:05,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:06,180][root][INFO] - Training Epoch: 2/2, step 6242/7134 completed (loss: 0.1258542388677597, acc: 0.9659863710403442)
[2024-12-17 03:27:06,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:06,544][root][INFO] - Training Epoch: 2/2, step 6243/7134 completed (loss: 0.1796623319387436, acc: 0.9530201554298401)
[2024-12-17 03:27:06,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:06,898][root][INFO] - Training Epoch: 2/2, step 6244/7134 completed (loss: 0.2187451869249344, acc: 0.9640718698501587)
[2024-12-17 03:27:06,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:07,253][root][INFO] - Training Epoch: 2/2, step 6245/7134 completed (loss: 0.1469946652650833, acc: 0.9467455744743347)
[2024-12-17 03:27:07,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:07,636][root][INFO] - Training Epoch: 2/2, step 6246/7134 completed (loss: 0.05259021744132042, acc: 0.9839572310447693)
[2024-12-17 03:27:07,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:07,998][root][INFO] - Training Epoch: 2/2, step 6247/7134 completed (loss: 0.10326407104730606, acc: 0.9728260636329651)
[2024-12-17 03:27:08,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:08,389][root][INFO] - Training Epoch: 2/2, step 6248/7134 completed (loss: 0.30291876196861267, acc: 0.9281437397003174)
[2024-12-17 03:27:08,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:08,760][root][INFO] - Training Epoch: 2/2, step 6249/7134 completed (loss: 0.023315278813242912, acc: 1.0)
[2024-12-17 03:27:08,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:09,190][root][INFO] - Training Epoch: 2/2, step 6250/7134 completed (loss: 0.025203341618180275, acc: 0.9927536249160767)
[2024-12-17 03:27:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:09,595][root][INFO] - Training Epoch: 2/2, step 6251/7134 completed (loss: 0.11372344940900803, acc: 0.9668874144554138)
[2024-12-17 03:27:09,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:09,995][root][INFO] - Training Epoch: 2/2, step 6252/7134 completed (loss: 0.04326692596077919, acc: 0.9857142567634583)
[2024-12-17 03:27:10,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:10,363][root][INFO] - Training Epoch: 2/2, step 6253/7134 completed (loss: 0.05838029459118843, acc: 0.9860140085220337)
[2024-12-17 03:27:10,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:10,757][root][INFO] - Training Epoch: 2/2, step 6254/7134 completed (loss: 0.08043746650218964, acc: 0.9776119589805603)
[2024-12-17 03:27:10,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:11,131][root][INFO] - Training Epoch: 2/2, step 6255/7134 completed (loss: 0.0932396650314331, acc: 0.9772727489471436)
[2024-12-17 03:27:11,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:11,500][root][INFO] - Training Epoch: 2/2, step 6256/7134 completed (loss: 0.06433439254760742, acc: 0.9830508232116699)
[2024-12-17 03:27:11,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:11,888][root][INFO] - Training Epoch: 2/2, step 6257/7134 completed (loss: 0.06416670978069305, acc: 0.9822485446929932)
[2024-12-17 03:27:12,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:12,276][root][INFO] - Training Epoch: 2/2, step 6258/7134 completed (loss: 0.05969657748937607, acc: 0.9800000190734863)
[2024-12-17 03:27:12,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:12,679][root][INFO] - Training Epoch: 2/2, step 6259/7134 completed (loss: 0.03246499225497246, acc: 0.9937888383865356)
[2024-12-17 03:27:12,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:13,060][root][INFO] - Training Epoch: 2/2, step 6260/7134 completed (loss: 0.07672258466482162, acc: 0.987261176109314)
[2024-12-17 03:27:13,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:13,479][root][INFO] - Training Epoch: 2/2, step 6261/7134 completed (loss: 0.10117747634649277, acc: 0.9751552939414978)
[2024-12-17 03:27:13,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:13,844][root][INFO] - Training Epoch: 2/2, step 6262/7134 completed (loss: 0.03265911713242531, acc: 0.9876543283462524)
[2024-12-17 03:27:13,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:14,223][root][INFO] - Training Epoch: 2/2, step 6263/7134 completed (loss: 0.021114647388458252, acc: 1.0)
[2024-12-17 03:27:14,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:14,604][root][INFO] - Training Epoch: 2/2, step 6264/7134 completed (loss: 0.03132221847772598, acc: 0.9863013625144958)
[2024-12-17 03:27:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:15,003][root][INFO] - Training Epoch: 2/2, step 6265/7134 completed (loss: 0.06180379539728165, acc: 0.9815950989723206)
[2024-12-17 03:27:15,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:15,371][root][INFO] - Training Epoch: 2/2, step 6266/7134 completed (loss: 0.027985412627458572, acc: 1.0)
[2024-12-17 03:27:15,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:15,796][root][INFO] - Training Epoch: 2/2, step 6267/7134 completed (loss: 0.07394570857286453, acc: 0.9802631735801697)
[2024-12-17 03:27:15,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:16,180][root][INFO] - Training Epoch: 2/2, step 6268/7134 completed (loss: 0.056653715670108795, acc: 0.9875776171684265)
[2024-12-17 03:27:16,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:16,579][root][INFO] - Training Epoch: 2/2, step 6269/7134 completed (loss: 0.03283819556236267, acc: 0.9910714030265808)
[2024-12-17 03:27:16,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:16,970][root][INFO] - Training Epoch: 2/2, step 6270/7134 completed (loss: 0.047483157366514206, acc: 0.9868420958518982)
[2024-12-17 03:27:17,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:17,348][root][INFO] - Training Epoch: 2/2, step 6271/7134 completed (loss: 0.09206121414899826, acc: 0.9829545617103577)
[2024-12-17 03:27:17,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:17,731][root][INFO] - Training Epoch: 2/2, step 6272/7134 completed (loss: 0.02009074203670025, acc: 0.9938650131225586)
[2024-12-17 03:27:17,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:18,115][root][INFO] - Training Epoch: 2/2, step 6273/7134 completed (loss: 0.03019716404378414, acc: 0.9940828680992126)
[2024-12-17 03:27:18,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:18,482][root][INFO] - Training Epoch: 2/2, step 6274/7134 completed (loss: 0.021927431225776672, acc: 1.0)
[2024-12-17 03:27:18,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:18,845][root][INFO] - Training Epoch: 2/2, step 6275/7134 completed (loss: 0.06680219620466232, acc: 0.9865771532058716)
[2024-12-17 03:27:18,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:19,212][root][INFO] - Training Epoch: 2/2, step 6276/7134 completed (loss: 0.09015421569347382, acc: 0.9593495726585388)
[2024-12-17 03:27:19,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:19,577][root][INFO] - Training Epoch: 2/2, step 6277/7134 completed (loss: 0.24205487966537476, acc: 0.9528301954269409)
[2024-12-17 03:27:19,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:19,952][root][INFO] - Training Epoch: 2/2, step 6278/7134 completed (loss: 0.06447983533143997, acc: 0.9632353186607361)
[2024-12-17 03:27:20,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:20,332][root][INFO] - Training Epoch: 2/2, step 6279/7134 completed (loss: 0.09356299042701721, acc: 0.9769230484962463)
[2024-12-17 03:27:20,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:20,742][root][INFO] - Training Epoch: 2/2, step 6280/7134 completed (loss: 0.11488797515630722, acc: 0.9776119589805603)
[2024-12-17 03:27:20,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:21,137][root][INFO] - Training Epoch: 2/2, step 6281/7134 completed (loss: 0.041555874049663544, acc: 0.9926470518112183)
[2024-12-17 03:27:21,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:21,539][root][INFO] - Training Epoch: 2/2, step 6282/7134 completed (loss: 0.08090341091156006, acc: 0.9583333134651184)
[2024-12-17 03:27:21,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:21,949][root][INFO] - Training Epoch: 2/2, step 6283/7134 completed (loss: 0.07473532855510712, acc: 0.991304337978363)
[2024-12-17 03:27:22,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:22,342][root][INFO] - Training Epoch: 2/2, step 6284/7134 completed (loss: 0.27418968081474304, acc: 0.9090909361839294)
[2024-12-17 03:27:22,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:22,748][root][INFO] - Training Epoch: 2/2, step 6285/7134 completed (loss: 0.28054335713386536, acc: 0.9052631855010986)
[2024-12-17 03:27:22,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:23,114][root][INFO] - Training Epoch: 2/2, step 6286/7134 completed (loss: 0.03217459097504616, acc: 0.9930555820465088)
[2024-12-17 03:27:23,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:23,473][root][INFO] - Training Epoch: 2/2, step 6287/7134 completed (loss: 0.06133477762341499, acc: 0.9696969985961914)
[2024-12-17 03:27:23,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:23,868][root][INFO] - Training Epoch: 2/2, step 6288/7134 completed (loss: 0.054243165999650955, acc: 0.9858155846595764)
[2024-12-17 03:27:23,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:24,264][root][INFO] - Training Epoch: 2/2, step 6289/7134 completed (loss: 0.04209137335419655, acc: 0.9848484992980957)
[2024-12-17 03:27:24,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:24,645][root][INFO] - Training Epoch: 2/2, step 6290/7134 completed (loss: 0.11273875832557678, acc: 0.9776119589805603)
[2024-12-17 03:27:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:25,011][root][INFO] - Training Epoch: 2/2, step 6291/7134 completed (loss: 0.028636664152145386, acc: 0.9924242496490479)
[2024-12-17 03:27:25,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:25,400][root][INFO] - Training Epoch: 2/2, step 6292/7134 completed (loss: 0.163878932595253, acc: 0.9553571343421936)
[2024-12-17 03:27:25,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:25,796][root][INFO] - Training Epoch: 2/2, step 6293/7134 completed (loss: 0.16164104640483856, acc: 0.9636363387107849)
[2024-12-17 03:27:25,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:26,201][root][INFO] - Training Epoch: 2/2, step 6294/7134 completed (loss: 0.20915088057518005, acc: 0.9473684430122375)
[2024-12-17 03:27:26,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:26,575][root][INFO] - Training Epoch: 2/2, step 6295/7134 completed (loss: 0.08337125182151794, acc: 0.9848484992980957)
[2024-12-17 03:27:26,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:26,896][root][INFO] - Training Epoch: 2/2, step 6296/7134 completed (loss: 0.22513918578624725, acc: 0.9424460530281067)
[2024-12-17 03:27:26,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:27,255][root][INFO] - Training Epoch: 2/2, step 6297/7134 completed (loss: 0.13953639566898346, acc: 0.9624060392379761)
[2024-12-17 03:27:27,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:27,620][root][INFO] - Training Epoch: 2/2, step 6298/7134 completed (loss: 0.1759537160396576, acc: 0.9583333134651184)
[2024-12-17 03:27:27,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:28,010][root][INFO] - Training Epoch: 2/2, step 6299/7134 completed (loss: 0.26026269793510437, acc: 0.9473684430122375)
[2024-12-17 03:27:28,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:28,384][root][INFO] - Training Epoch: 2/2, step 6300/7134 completed (loss: 0.15395605564117432, acc: 0.9605262875556946)
[2024-12-17 03:27:28,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:28,765][root][INFO] - Training Epoch: 2/2, step 6301/7134 completed (loss: 0.03655533492565155, acc: 0.9907407164573669)
[2024-12-17 03:27:28,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:29,115][root][INFO] - Training Epoch: 2/2, step 6302/7134 completed (loss: 0.06730791926383972, acc: 0.9720670580863953)
[2024-12-17 03:27:29,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:29,501][root][INFO] - Training Epoch: 2/2, step 6303/7134 completed (loss: 0.03671760857105255, acc: 0.9820627570152283)
[2024-12-17 03:27:29,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:29,883][root][INFO] - Training Epoch: 2/2, step 6304/7134 completed (loss: 0.03212878108024597, acc: 0.9886363744735718)
[2024-12-17 03:27:30,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:30,282][root][INFO] - Training Epoch: 2/2, step 6305/7134 completed (loss: 0.11647529900074005, acc: 0.9726027250289917)
[2024-12-17 03:27:30,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:30,688][root][INFO] - Training Epoch: 2/2, step 6306/7134 completed (loss: 0.07615585625171661, acc: 0.971563994884491)
[2024-12-17 03:27:30,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:31,071][root][INFO] - Training Epoch: 2/2, step 6307/7134 completed (loss: 0.09888141602277756, acc: 0.9770992398262024)
[2024-12-17 03:27:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:31,458][root][INFO] - Training Epoch: 2/2, step 6308/7134 completed (loss: 0.08559645712375641, acc: 0.984455943107605)
[2024-12-17 03:27:31,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:31,863][root][INFO] - Training Epoch: 2/2, step 6309/7134 completed (loss: 0.07106932997703552, acc: 0.9704142212867737)
[2024-12-17 03:27:32,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:32,269][root][INFO] - Training Epoch: 2/2, step 6310/7134 completed (loss: 0.1388181895017624, acc: 0.9561403393745422)
[2024-12-17 03:27:32,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:32,649][root][INFO] - Training Epoch: 2/2, step 6311/7134 completed (loss: 0.1072075366973877, acc: 0.9583333134651184)
[2024-12-17 03:27:32,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:33,071][root][INFO] - Training Epoch: 2/2, step 6312/7134 completed (loss: 0.1058795377612114, acc: 0.9617834687232971)
[2024-12-17 03:27:33,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:33,437][root][INFO] - Training Epoch: 2/2, step 6313/7134 completed (loss: 0.03568679466843605, acc: 0.9837837815284729)
[2024-12-17 03:27:33,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:33,781][root][INFO] - Training Epoch: 2/2, step 6314/7134 completed (loss: 0.06455245614051819, acc: 0.9892473220825195)
[2024-12-17 03:27:33,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:34,135][root][INFO] - Training Epoch: 2/2, step 6315/7134 completed (loss: 0.21488937735557556, acc: 0.9597315192222595)
[2024-12-17 03:27:34,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:34,531][root][INFO] - Training Epoch: 2/2, step 6316/7134 completed (loss: 0.061839841306209564, acc: 0.9931034445762634)
[2024-12-17 03:27:34,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:34,948][root][INFO] - Training Epoch: 2/2, step 6317/7134 completed (loss: 0.05589916184544563, acc: 0.9932432174682617)
[2024-12-17 03:27:35,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:35,319][root][INFO] - Training Epoch: 2/2, step 6318/7134 completed (loss: 0.06832434982061386, acc: 0.9736841917037964)
[2024-12-17 03:27:35,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:35,722][root][INFO] - Training Epoch: 2/2, step 6319/7134 completed (loss: 0.060644347220659256, acc: 0.9777777791023254)
[2024-12-17 03:27:35,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:36,106][root][INFO] - Training Epoch: 2/2, step 6320/7134 completed (loss: 0.06734436750411987, acc: 0.9864864945411682)
[2024-12-17 03:27:36,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:36,469][root][INFO] - Training Epoch: 2/2, step 6321/7134 completed (loss: 0.04066798463463783, acc: 0.9809523820877075)
[2024-12-17 03:27:36,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:36,860][root][INFO] - Training Epoch: 2/2, step 6322/7134 completed (loss: 0.07700949907302856, acc: 0.9745222926139832)
[2024-12-17 03:27:36,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:37,246][root][INFO] - Training Epoch: 2/2, step 6323/7134 completed (loss: 0.10325239598751068, acc: 0.981249988079071)
[2024-12-17 03:27:37,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:37,609][root][INFO] - Training Epoch: 2/2, step 6324/7134 completed (loss: 0.2047913819551468, acc: 0.9726775884628296)
[2024-12-17 03:27:37,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:37,970][root][INFO] - Training Epoch: 2/2, step 6325/7134 completed (loss: 0.07554885745048523, acc: 0.9919354915618896)
[2024-12-17 03:27:38,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:38,340][root][INFO] - Training Epoch: 2/2, step 6326/7134 completed (loss: 0.1603805273771286, acc: 0.9371069073677063)
[2024-12-17 03:27:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:38,703][root][INFO] - Training Epoch: 2/2, step 6327/7134 completed (loss: 0.055250681936740875, acc: 0.9890109896659851)
[2024-12-17 03:27:38,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:39,087][root][INFO] - Training Epoch: 2/2, step 6328/7134 completed (loss: 0.2112727165222168, acc: 0.95652174949646)
[2024-12-17 03:27:39,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:39,456][root][INFO] - Training Epoch: 2/2, step 6329/7134 completed (loss: 0.08302852511405945, acc: 0.9743589758872986)
[2024-12-17 03:27:39,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:39,829][root][INFO] - Training Epoch: 2/2, step 6330/7134 completed (loss: 0.058336686342954636, acc: 0.9811320900917053)
[2024-12-17 03:27:39,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:40,207][root][INFO] - Training Epoch: 2/2, step 6331/7134 completed (loss: 0.021761372685432434, acc: 1.0)
[2024-12-17 03:27:40,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:40,579][root][INFO] - Training Epoch: 2/2, step 6332/7134 completed (loss: 0.2181728184223175, acc: 0.936170220375061)
[2024-12-17 03:27:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:40,923][root][INFO] - Training Epoch: 2/2, step 6333/7134 completed (loss: 0.10895492136478424, acc: 0.9655172228813171)
[2024-12-17 03:27:41,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:41,255][root][INFO] - Training Epoch: 2/2, step 6334/7134 completed (loss: 0.06300804764032364, acc: 0.9852941036224365)
[2024-12-17 03:27:41,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:41,610][root][INFO] - Training Epoch: 2/2, step 6335/7134 completed (loss: 0.025818418711423874, acc: 0.993630588054657)
[2024-12-17 03:27:41,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:41,965][root][INFO] - Training Epoch: 2/2, step 6336/7134 completed (loss: 0.1691703498363495, acc: 0.9561403393745422)
[2024-12-17 03:27:42,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:42,357][root][INFO] - Training Epoch: 2/2, step 6337/7134 completed (loss: 0.019097942858934402, acc: 0.9930070042610168)
[2024-12-17 03:27:42,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:42,743][root][INFO] - Training Epoch: 2/2, step 6338/7134 completed (loss: 0.07109108567237854, acc: 0.9937106966972351)
[2024-12-17 03:27:42,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:43,126][root][INFO] - Training Epoch: 2/2, step 6339/7134 completed (loss: 0.05598999932408333, acc: 0.9803921580314636)
[2024-12-17 03:27:43,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:43,515][root][INFO] - Training Epoch: 2/2, step 6340/7134 completed (loss: 0.04897502437233925, acc: 0.9754601120948792)
[2024-12-17 03:27:43,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:43,894][root][INFO] - Training Epoch: 2/2, step 6341/7134 completed (loss: 0.08691780269145966, acc: 0.9685039520263672)
[2024-12-17 03:27:44,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:44,287][root][INFO] - Training Epoch: 2/2, step 6342/7134 completed (loss: 0.1342202126979828, acc: 0.9710982441902161)
[2024-12-17 03:27:44,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:44,665][root][INFO] - Training Epoch: 2/2, step 6343/7134 completed (loss: 0.13602229952812195, acc: 0.9726027250289917)
[2024-12-17 03:27:44,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:45,064][root][INFO] - Training Epoch: 2/2, step 6344/7134 completed (loss: 0.1103614792227745, acc: 0.9613259434700012)
[2024-12-17 03:27:45,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:45,443][root][INFO] - Training Epoch: 2/2, step 6345/7134 completed (loss: 0.0668049305677414, acc: 0.989130437374115)
[2024-12-17 03:27:45,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:45,819][root][INFO] - Training Epoch: 2/2, step 6346/7134 completed (loss: 0.24605172872543335, acc: 0.9360465407371521)
[2024-12-17 03:27:45,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:46,156][root][INFO] - Training Epoch: 2/2, step 6347/7134 completed (loss: 0.16499334573745728, acc: 0.9579831957817078)
[2024-12-17 03:27:46,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:46,541][root][INFO] - Training Epoch: 2/2, step 6348/7134 completed (loss: 0.10936760902404785, acc: 0.9722222089767456)
[2024-12-17 03:27:46,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:46,924][root][INFO] - Training Epoch: 2/2, step 6349/7134 completed (loss: 0.08782917261123657, acc: 0.9772727489471436)
[2024-12-17 03:27:47,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:47,304][root][INFO] - Training Epoch: 2/2, step 6350/7134 completed (loss: 0.16462621092796326, acc: 0.9523809552192688)
[2024-12-17 03:27:47,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:47,679][root][INFO] - Training Epoch: 2/2, step 6351/7134 completed (loss: 0.19103537499904633, acc: 0.9221556782722473)
[2024-12-17 03:27:47,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:48,062][root][INFO] - Training Epoch: 2/2, step 6352/7134 completed (loss: 0.324532687664032, acc: 0.8959537744522095)
[2024-12-17 03:27:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:48,425][root][INFO] - Training Epoch: 2/2, step 6353/7134 completed (loss: 0.17324542999267578, acc: 0.9570552110671997)
[2024-12-17 03:27:48,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:48,789][root][INFO] - Training Epoch: 2/2, step 6354/7134 completed (loss: 0.08456002920866013, acc: 0.9712643623352051)
[2024-12-17 03:27:48,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:49,130][root][INFO] - Training Epoch: 2/2, step 6355/7134 completed (loss: 0.05309994891285896, acc: 0.9866666793823242)
[2024-12-17 03:27:49,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:49,499][root][INFO] - Training Epoch: 2/2, step 6356/7134 completed (loss: 0.11074553430080414, acc: 0.9617834687232971)
[2024-12-17 03:27:49,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:49,907][root][INFO] - Training Epoch: 2/2, step 6357/7134 completed (loss: 0.11065562069416046, acc: 0.9757575988769531)
[2024-12-17 03:27:50,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:50,374][root][INFO] - Training Epoch: 2/2, step 6358/7134 completed (loss: 0.12726259231567383, acc: 0.9649122953414917)
[2024-12-17 03:27:50,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:50,765][root][INFO] - Training Epoch: 2/2, step 6359/7134 completed (loss: 0.1498994380235672, acc: 0.9776536226272583)
[2024-12-17 03:27:50,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:51,121][root][INFO] - Training Epoch: 2/2, step 6360/7134 completed (loss: 0.06509601324796677, acc: 0.9863945841789246)
[2024-12-17 03:27:51,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:51,509][root][INFO] - Training Epoch: 2/2, step 6361/7134 completed (loss: 0.1706238090991974, acc: 0.9424460530281067)
[2024-12-17 03:27:51,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:51,888][root][INFO] - Training Epoch: 2/2, step 6362/7134 completed (loss: 0.08196060359477997, acc: 0.9806451797485352)
[2024-12-17 03:27:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:52,276][root][INFO] - Training Epoch: 2/2, step 6363/7134 completed (loss: 0.1570216864347458, acc: 0.9644970297813416)
[2024-12-17 03:27:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:52,656][root][INFO] - Training Epoch: 2/2, step 6364/7134 completed (loss: 0.11435361951589584, acc: 0.9617834687232971)
[2024-12-17 03:27:52,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:53,023][root][INFO] - Training Epoch: 2/2, step 6365/7134 completed (loss: 0.06426508724689484, acc: 0.9830508232116699)
[2024-12-17 03:27:53,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:53,388][root][INFO] - Training Epoch: 2/2, step 6366/7134 completed (loss: 0.2281779944896698, acc: 0.9585798978805542)
[2024-12-17 03:27:53,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:53,801][root][INFO] - Training Epoch: 2/2, step 6367/7134 completed (loss: 0.09818059951066971, acc: 0.9767441749572754)
[2024-12-17 03:27:53,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:54,160][root][INFO] - Training Epoch: 2/2, step 6368/7134 completed (loss: 0.16394084692001343, acc: 0.9638554453849792)
[2024-12-17 03:27:54,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:54,536][root][INFO] - Training Epoch: 2/2, step 6369/7134 completed (loss: 0.1514691710472107, acc: 0.9702380895614624)
[2024-12-17 03:27:54,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:54,918][root][INFO] - Training Epoch: 2/2, step 6370/7134 completed (loss: 0.35520830750465393, acc: 0.9127907156944275)
[2024-12-17 03:27:55,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:55,285][root][INFO] - Training Epoch: 2/2, step 6371/7134 completed (loss: 0.3155655264854431, acc: 0.9215686321258545)
[2024-12-17 03:27:55,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:55,647][root][INFO] - Training Epoch: 2/2, step 6372/7134 completed (loss: 0.22191108763217926, acc: 0.931034505367279)
[2024-12-17 03:27:55,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:55,991][root][INFO] - Training Epoch: 2/2, step 6373/7134 completed (loss: 0.14192967116832733, acc: 0.9677419066429138)
[2024-12-17 03:27:56,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:56,376][root][INFO] - Training Epoch: 2/2, step 6374/7134 completed (loss: 0.09878989309072495, acc: 0.9747899174690247)
[2024-12-17 03:27:56,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:56,766][root][INFO] - Training Epoch: 2/2, step 6375/7134 completed (loss: 0.1548987478017807, acc: 0.9668508172035217)
[2024-12-17 03:27:56,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:57,090][root][INFO] - Training Epoch: 2/2, step 6376/7134 completed (loss: 0.09807261824607849, acc: 0.9756097793579102)
[2024-12-17 03:27:57,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:57,445][root][INFO] - Training Epoch: 2/2, step 6377/7134 completed (loss: 0.19289281964302063, acc: 0.9520000219345093)
[2024-12-17 03:27:57,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:57,830][root][INFO] - Training Epoch: 2/2, step 6378/7134 completed (loss: 0.2445223033428192, acc: 0.9488372206687927)
[2024-12-17 03:27:57,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:58,211][root][INFO] - Training Epoch: 2/2, step 6379/7134 completed (loss: 0.17592667043209076, acc: 0.9789473414421082)
[2024-12-17 03:27:58,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:58,603][root][INFO] - Training Epoch: 2/2, step 6380/7134 completed (loss: 0.19514301419258118, acc: 0.96875)
[2024-12-17 03:27:58,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:58,962][root][INFO] - Training Epoch: 2/2, step 6381/7134 completed (loss: 0.05722948536276817, acc: 0.9797297120094299)
[2024-12-17 03:27:59,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:59,332][root][INFO] - Training Epoch: 2/2, step 6382/7134 completed (loss: 0.060796450823545456, acc: 0.9725274443626404)
[2024-12-17 03:27:59,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:27:59,669][root][INFO] - Training Epoch: 2/2, step 6383/7134 completed (loss: 0.2624238431453705, acc: 0.9595375657081604)
[2024-12-17 03:27:59,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:00,055][root][INFO] - Training Epoch: 2/2, step 6384/7134 completed (loss: 0.10137336701154709, acc: 0.9746835231781006)
[2024-12-17 03:28:00,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:00,414][root][INFO] - Training Epoch: 2/2, step 6385/7134 completed (loss: 0.18998658657073975, acc: 0.9609755873680115)
[2024-12-17 03:28:00,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:00,794][root][INFO] - Training Epoch: 2/2, step 6386/7134 completed (loss: 0.1325957328081131, acc: 0.9731183052062988)
[2024-12-17 03:28:00,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:01,158][root][INFO] - Training Epoch: 2/2, step 6387/7134 completed (loss: 0.09875521808862686, acc: 0.9757575988769531)
[2024-12-17 03:28:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:01,526][root][INFO] - Training Epoch: 2/2, step 6388/7134 completed (loss: 0.1617065817117691, acc: 0.9620253443717957)
[2024-12-17 03:28:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:01,906][root][INFO] - Training Epoch: 2/2, step 6389/7134 completed (loss: 0.19132183492183685, acc: 0.9375)
[2024-12-17 03:28:02,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:02,301][root][INFO] - Training Epoch: 2/2, step 6390/7134 completed (loss: 0.08913030475378036, acc: 0.9869565367698669)
[2024-12-17 03:28:02,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:02,691][root][INFO] - Training Epoch: 2/2, step 6391/7134 completed (loss: 0.20220734179019928, acc: 0.9593023061752319)
[2024-12-17 03:28:02,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:03,079][root][INFO] - Training Epoch: 2/2, step 6392/7134 completed (loss: 0.27985507249832153, acc: 0.947826087474823)
[2024-12-17 03:28:03,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:03,478][root][INFO] - Training Epoch: 2/2, step 6393/7134 completed (loss: 0.10663548856973648, acc: 0.9675925970077515)
[2024-12-17 03:28:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:03,855][root][INFO] - Training Epoch: 2/2, step 6394/7134 completed (loss: 0.20454280078411102, acc: 0.9722222089767456)
[2024-12-17 03:28:03,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:04,247][root][INFO] - Training Epoch: 2/2, step 6395/7134 completed (loss: 0.11765348166227341, acc: 0.9653465151786804)
[2024-12-17 03:28:04,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:04,626][root][INFO] - Training Epoch: 2/2, step 6396/7134 completed (loss: 0.163486048579216, acc: 0.9665071964263916)
[2024-12-17 03:28:04,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:05,022][root][INFO] - Training Epoch: 2/2, step 6397/7134 completed (loss: 0.08908284455537796, acc: 0.9751243591308594)
[2024-12-17 03:28:05,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:05,379][root][INFO] - Training Epoch: 2/2, step 6398/7134 completed (loss: 0.08577436208724976, acc: 0.9793103337287903)
[2024-12-17 03:28:05,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:05,742][root][INFO] - Training Epoch: 2/2, step 6399/7134 completed (loss: 0.2031012922525406, acc: 0.9606741666793823)
[2024-12-17 03:28:05,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:06,104][root][INFO] - Training Epoch: 2/2, step 6400/7134 completed (loss: 0.08361335098743439, acc: 0.9819276928901672)
[2024-12-17 03:28:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:06,491][root][INFO] - Training Epoch: 2/2, step 6401/7134 completed (loss: 0.08415698260068893, acc: 0.9809523820877075)
[2024-12-17 03:28:06,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:06,862][root][INFO] - Training Epoch: 2/2, step 6402/7134 completed (loss: 0.20869329571723938, acc: 0.9545454382896423)
[2024-12-17 03:28:06,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:07,214][root][INFO] - Training Epoch: 2/2, step 6403/7134 completed (loss: 0.03731454163789749, acc: 0.9896373152732849)
[2024-12-17 03:28:07,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:07,578][root][INFO] - Training Epoch: 2/2, step 6404/7134 completed (loss: 0.06460481882095337, acc: 0.976331353187561)
[2024-12-17 03:28:07,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:07,997][root][INFO] - Training Epoch: 2/2, step 6405/7134 completed (loss: 0.10324447602033615, acc: 0.9711538553237915)
[2024-12-17 03:28:08,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:08,387][root][INFO] - Training Epoch: 2/2, step 6406/7134 completed (loss: 0.16846992075443268, acc: 0.9399999976158142)
[2024-12-17 03:28:08,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:08,784][root][INFO] - Training Epoch: 2/2, step 6407/7134 completed (loss: 0.0731649100780487, acc: 0.9888888597488403)
[2024-12-17 03:28:08,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:09,152][root][INFO] - Training Epoch: 2/2, step 6408/7134 completed (loss: 0.1841113269329071, acc: 0.942307710647583)
[2024-12-17 03:28:09,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:09,566][root][INFO] - Training Epoch: 2/2, step 6409/7134 completed (loss: 0.11759892851114273, acc: 0.9878048896789551)
[2024-12-17 03:28:09,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:09,936][root][INFO] - Training Epoch: 2/2, step 6410/7134 completed (loss: 0.21232512593269348, acc: 0.9333333373069763)
[2024-12-17 03:28:10,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:10,282][root][INFO] - Training Epoch: 2/2, step 6411/7134 completed (loss: 0.18970909714698792, acc: 0.9534883499145508)
[2024-12-17 03:28:10,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:10,637][root][INFO] - Training Epoch: 2/2, step 6412/7134 completed (loss: 0.035218801349401474, acc: 0.9935483932495117)
[2024-12-17 03:28:10,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:11,010][root][INFO] - Training Epoch: 2/2, step 6413/7134 completed (loss: 0.23686257004737854, acc: 0.9463087320327759)
[2024-12-17 03:28:11,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:11,382][root][INFO] - Training Epoch: 2/2, step 6414/7134 completed (loss: 0.09030081331729889, acc: 0.9539473652839661)
[2024-12-17 03:28:11,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:11,775][root][INFO] - Training Epoch: 2/2, step 6415/7134 completed (loss: 0.08100809156894684, acc: 0.9829545617103577)
[2024-12-17 03:28:11,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:12,186][root][INFO] - Training Epoch: 2/2, step 6416/7134 completed (loss: 0.22521662712097168, acc: 0.9637681245803833)
[2024-12-17 03:28:12,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:12,546][root][INFO] - Training Epoch: 2/2, step 6417/7134 completed (loss: 0.3000600039958954, acc: 0.9379844665527344)
[2024-12-17 03:28:12,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:12,914][root][INFO] - Training Epoch: 2/2, step 6418/7134 completed (loss: 0.3894687592983246, acc: 0.899328887462616)
[2024-12-17 03:28:13,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:13,291][root][INFO] - Training Epoch: 2/2, step 6419/7134 completed (loss: 0.29781851172447205, acc: 0.9285714030265808)
[2024-12-17 03:28:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:13,666][root][INFO] - Training Epoch: 2/2, step 6420/7134 completed (loss: 0.24334996938705444, acc: 0.9556962251663208)
[2024-12-17 03:28:13,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:14,031][root][INFO] - Training Epoch: 2/2, step 6421/7134 completed (loss: 0.2432519793510437, acc: 0.9397590160369873)
[2024-12-17 03:28:14,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:14,405][root][INFO] - Training Epoch: 2/2, step 6422/7134 completed (loss: 0.2130340039730072, acc: 0.9608938694000244)
[2024-12-17 03:28:14,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:14,851][root][INFO] - Training Epoch: 2/2, step 6423/7134 completed (loss: 0.20068565011024475, acc: 0.9679487347602844)
[2024-12-17 03:28:14,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:15,268][root][INFO] - Training Epoch: 2/2, step 6424/7134 completed (loss: 0.19026368856430054, acc: 0.9414893388748169)
[2024-12-17 03:28:15,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:15,683][root][INFO] - Training Epoch: 2/2, step 6425/7134 completed (loss: 0.08896578848361969, acc: 0.9553072452545166)
[2024-12-17 03:28:15,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:16,049][root][INFO] - Training Epoch: 2/2, step 6426/7134 completed (loss: 0.1772632598876953, acc: 0.9497206807136536)
[2024-12-17 03:28:16,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:16,435][root][INFO] - Training Epoch: 2/2, step 6427/7134 completed (loss: 0.15885087847709656, acc: 0.9426751732826233)
[2024-12-17 03:28:16,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:16,811][root][INFO] - Training Epoch: 2/2, step 6428/7134 completed (loss: 0.11773573607206345, acc: 0.9617834687232971)
[2024-12-17 03:28:16,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:17,176][root][INFO] - Training Epoch: 2/2, step 6429/7134 completed (loss: 0.0836024060845375, acc: 0.9806451797485352)
[2024-12-17 03:28:17,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:17,566][root][INFO] - Training Epoch: 2/2, step 6430/7134 completed (loss: 0.211910679936409, acc: 0.9624999761581421)
[2024-12-17 03:28:17,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:17,970][root][INFO] - Training Epoch: 2/2, step 6431/7134 completed (loss: 0.24154497683048248, acc: 0.9405405521392822)
[2024-12-17 03:28:18,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:18,375][root][INFO] - Training Epoch: 2/2, step 6432/7134 completed (loss: 0.8915651440620422, acc: 0.8193548321723938)
[2024-12-17 03:28:18,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:18,753][root][INFO] - Training Epoch: 2/2, step 6433/7134 completed (loss: 0.38994309306144714, acc: 0.9204545617103577)
[2024-12-17 03:28:18,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:19,117][root][INFO] - Training Epoch: 2/2, step 6434/7134 completed (loss: 0.07593380659818649, acc: 0.9826589822769165)
[2024-12-17 03:28:19,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:19,489][root][INFO] - Training Epoch: 2/2, step 6435/7134 completed (loss: 0.1102362722158432, acc: 0.9637681245803833)
[2024-12-17 03:28:19,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:19,856][root][INFO] - Training Epoch: 2/2, step 6436/7134 completed (loss: 0.13559143245220184, acc: 0.9731543660163879)
[2024-12-17 03:28:19,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:20,220][root][INFO] - Training Epoch: 2/2, step 6437/7134 completed (loss: 0.3015619218349457, acc: 0.9539473652839661)
[2024-12-17 03:28:20,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:20,593][root][INFO] - Training Epoch: 2/2, step 6438/7134 completed (loss: 0.3168143928050995, acc: 0.9320388436317444)
[2024-12-17 03:28:20,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:20,979][root][INFO] - Training Epoch: 2/2, step 6439/7134 completed (loss: 0.1349649429321289, acc: 0.95652174949646)
[2024-12-17 03:28:21,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:21,379][root][INFO] - Training Epoch: 2/2, step 6440/7134 completed (loss: 0.1745046228170395, acc: 0.9567307829856873)
[2024-12-17 03:28:21,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:21,741][root][INFO] - Training Epoch: 2/2, step 6441/7134 completed (loss: 0.09778103977441788, acc: 0.9811320900917053)
[2024-12-17 03:28:21,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:22,110][root][INFO] - Training Epoch: 2/2, step 6442/7134 completed (loss: 0.08205036073923111, acc: 0.9854369163513184)
[2024-12-17 03:28:22,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:22,476][root][INFO] - Training Epoch: 2/2, step 6443/7134 completed (loss: 0.08127854019403458, acc: 0.9901960492134094)
[2024-12-17 03:28:22,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:22,844][root][INFO] - Training Epoch: 2/2, step 6444/7134 completed (loss: 0.1853771060705185, acc: 0.9611111283302307)
[2024-12-17 03:28:22,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:23,218][root][INFO] - Training Epoch: 2/2, step 6445/7134 completed (loss: 0.25050827860832214, acc: 0.9458128213882446)
[2024-12-17 03:28:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:23,587][root][INFO] - Training Epoch: 2/2, step 6446/7134 completed (loss: 0.06909125298261642, acc: 0.9754902124404907)
[2024-12-17 03:28:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:23,970][root][INFO] - Training Epoch: 2/2, step 6447/7134 completed (loss: 0.14845937490463257, acc: 0.96875)
[2024-12-17 03:28:24,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:24,342][root][INFO] - Training Epoch: 2/2, step 6448/7134 completed (loss: 0.4050987958908081, acc: 0.9225806593894958)
[2024-12-17 03:28:24,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:24,713][root][INFO] - Training Epoch: 2/2, step 6449/7134 completed (loss: 0.1268799602985382, acc: 0.9637305736541748)
[2024-12-17 03:28:24,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:25,110][root][INFO] - Training Epoch: 2/2, step 6450/7134 completed (loss: 0.12084569782018661, acc: 0.9826589822769165)
[2024-12-17 03:28:25,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:25,526][root][INFO] - Training Epoch: 2/2, step 6451/7134 completed (loss: 0.21081200242042542, acc: 0.9495798349380493)
[2024-12-17 03:28:25,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:25,891][root][INFO] - Training Epoch: 2/2, step 6452/7134 completed (loss: 0.09846340119838715, acc: 0.9795918464660645)
[2024-12-17 03:28:26,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:26,309][root][INFO] - Training Epoch: 2/2, step 6453/7134 completed (loss: 0.10430475324392319, acc: 0.9631901979446411)
[2024-12-17 03:28:26,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:26,697][root][INFO] - Training Epoch: 2/2, step 6454/7134 completed (loss: 0.152730330824852, acc: 0.9562841653823853)
[2024-12-17 03:28:26,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:27,070][root][INFO] - Training Epoch: 2/2, step 6455/7134 completed (loss: 0.2655491530895233, acc: 0.9266666769981384)
[2024-12-17 03:28:27,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:27,463][root][INFO] - Training Epoch: 2/2, step 6456/7134 completed (loss: 0.28072530031204224, acc: 0.946107804775238)
[2024-12-17 03:28:27,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:27,863][root][INFO] - Training Epoch: 2/2, step 6457/7134 completed (loss: 0.06678485125303268, acc: 0.9816513657569885)
[2024-12-17 03:28:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:28,244][root][INFO] - Training Epoch: 2/2, step 6458/7134 completed (loss: 0.05310988053679466, acc: 0.9864864945411682)
[2024-12-17 03:28:28,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:28,598][root][INFO] - Training Epoch: 2/2, step 6459/7134 completed (loss: 0.026602119207382202, acc: 1.0)
[2024-12-17 03:28:28,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:29,005][root][INFO] - Training Epoch: 2/2, step 6460/7134 completed (loss: 0.08338162302970886, acc: 0.9846938848495483)
[2024-12-17 03:28:29,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:29,364][root][INFO] - Training Epoch: 2/2, step 6461/7134 completed (loss: 0.044254790991544724, acc: 0.9884393215179443)
[2024-12-17 03:28:29,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:29,726][root][INFO] - Training Epoch: 2/2, step 6462/7134 completed (loss: 0.07789863646030426, acc: 0.9840425252914429)
[2024-12-17 03:28:29,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:30,104][root][INFO] - Training Epoch: 2/2, step 6463/7134 completed (loss: 0.14250999689102173, acc: 0.9660193920135498)
[2024-12-17 03:28:30,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:30,452][root][INFO] - Training Epoch: 2/2, step 6464/7134 completed (loss: 0.11411906778812408, acc: 0.9776536226272583)
[2024-12-17 03:28:30,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:30,866][root][INFO] - Training Epoch: 2/2, step 6465/7134 completed (loss: 0.045406486839056015, acc: 0.9890710115432739)
[2024-12-17 03:28:31,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:31,286][root][INFO] - Training Epoch: 2/2, step 6466/7134 completed (loss: 0.19295324385166168, acc: 0.9417989253997803)
[2024-12-17 03:28:31,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:31,673][root][INFO] - Training Epoch: 2/2, step 6467/7134 completed (loss: 0.3416939079761505, acc: 0.9397590160369873)
[2024-12-17 03:28:31,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:32,041][root][INFO] - Training Epoch: 2/2, step 6468/7134 completed (loss: 0.1128353700041771, acc: 0.9852941036224365)
[2024-12-17 03:28:32,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:32,433][root][INFO] - Training Epoch: 2/2, step 6469/7134 completed (loss: 0.2329014092683792, acc: 0.9485981464385986)
[2024-12-17 03:28:32,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:32,783][root][INFO] - Training Epoch: 2/2, step 6470/7134 completed (loss: 0.20601439476013184, acc: 0.9313725233078003)
[2024-12-17 03:28:32,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:33,150][root][INFO] - Training Epoch: 2/2, step 6471/7134 completed (loss: 0.08553454279899597, acc: 0.9856114983558655)
[2024-12-17 03:28:33,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:33,567][root][INFO] - Training Epoch: 2/2, step 6472/7134 completed (loss: 0.20427633821964264, acc: 0.9599999785423279)
[2024-12-17 03:28:33,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:33,962][root][INFO] - Training Epoch: 2/2, step 6473/7134 completed (loss: 0.05850055068731308, acc: 0.9833333492279053)
[2024-12-17 03:28:34,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:34,306][root][INFO] - Training Epoch: 2/2, step 6474/7134 completed (loss: 0.14748159050941467, acc: 0.9569892287254333)
[2024-12-17 03:28:34,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:34,661][root][INFO] - Training Epoch: 2/2, step 6475/7134 completed (loss: 0.13806408643722534, acc: 0.949999988079071)
[2024-12-17 03:28:34,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:35,013][root][INFO] - Training Epoch: 2/2, step 6476/7134 completed (loss: 0.10092618316411972, acc: 0.9666666388511658)
[2024-12-17 03:28:35,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:35,363][root][INFO] - Training Epoch: 2/2, step 6477/7134 completed (loss: 0.1449706256389618, acc: 0.9739130139350891)
[2024-12-17 03:28:35,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:35,733][root][INFO] - Training Epoch: 2/2, step 6478/7134 completed (loss: 0.12293962389230728, acc: 0.9492753744125366)
[2024-12-17 03:28:35,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:36,115][root][INFO] - Training Epoch: 2/2, step 6479/7134 completed (loss: 0.1032102108001709, acc: 0.9664429426193237)
[2024-12-17 03:28:36,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:36,506][root][INFO] - Training Epoch: 2/2, step 6480/7134 completed (loss: 0.12129989266395569, acc: 0.9714285731315613)
[2024-12-17 03:28:36,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:36,866][root][INFO] - Training Epoch: 2/2, step 6481/7134 completed (loss: 0.06561083346605301, acc: 0.9785714149475098)
[2024-12-17 03:28:36,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:37,233][root][INFO] - Training Epoch: 2/2, step 6482/7134 completed (loss: 0.0695684403181076, acc: 0.9800000190734863)
[2024-12-17 03:28:37,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:37,594][root][INFO] - Training Epoch: 2/2, step 6483/7134 completed (loss: 0.327917218208313, acc: 0.9513888955116272)
[2024-12-17 03:28:37,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:37,956][root][INFO] - Training Epoch: 2/2, step 6484/7134 completed (loss: 0.2100970447063446, acc: 0.9649122953414917)
[2024-12-17 03:28:38,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:38,334][root][INFO] - Training Epoch: 2/2, step 6485/7134 completed (loss: 0.05145427957177162, acc: 0.9915966391563416)
[2024-12-17 03:28:38,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:38,697][root][INFO] - Training Epoch: 2/2, step 6486/7134 completed (loss: 0.4260483384132385, acc: 0.8985507488250732)
[2024-12-17 03:28:38,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:39,029][root][INFO] - Training Epoch: 2/2, step 6487/7134 completed (loss: 0.3303246796131134, acc: 0.8897058963775635)
[2024-12-17 03:28:39,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:39,380][root][INFO] - Training Epoch: 2/2, step 6488/7134 completed (loss: 0.1865435391664505, acc: 0.9469696879386902)
[2024-12-17 03:28:39,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:39,785][root][INFO] - Training Epoch: 2/2, step 6489/7134 completed (loss: 0.3530915081501007, acc: 0.94017094373703)
[2024-12-17 03:28:39,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:40,152][root][INFO] - Training Epoch: 2/2, step 6490/7134 completed (loss: 0.4411381483078003, acc: 0.888059675693512)
[2024-12-17 03:28:40,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:40,559][root][INFO] - Training Epoch: 2/2, step 6491/7134 completed (loss: 0.2352295219898224, acc: 0.9350649118423462)
[2024-12-17 03:28:40,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:40,928][root][INFO] - Training Epoch: 2/2, step 6492/7134 completed (loss: 0.10492256283760071, acc: 0.9741935729980469)
[2024-12-17 03:28:41,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:41,303][root][INFO] - Training Epoch: 2/2, step 6493/7134 completed (loss: 0.19297586381435394, acc: 0.9523809552192688)
[2024-12-17 03:28:41,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:41,645][root][INFO] - Training Epoch: 2/2, step 6494/7134 completed (loss: 0.27130404114723206, acc: 0.9380530714988708)
[2024-12-17 03:28:41,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:42,006][root][INFO] - Training Epoch: 2/2, step 6495/7134 completed (loss: 0.26093462109565735, acc: 0.9382715821266174)
[2024-12-17 03:28:42,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:42,391][root][INFO] - Training Epoch: 2/2, step 6496/7134 completed (loss: 0.24750301241874695, acc: 0.9306358098983765)
[2024-12-17 03:28:42,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:42,750][root][INFO] - Training Epoch: 2/2, step 6497/7134 completed (loss: 0.27027779817581177, acc: 0.9375)
[2024-12-17 03:28:42,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:43,155][root][INFO] - Training Epoch: 2/2, step 6498/7134 completed (loss: 0.1928556114435196, acc: 0.9588235020637512)
[2024-12-17 03:28:43,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:43,527][root][INFO] - Training Epoch: 2/2, step 6499/7134 completed (loss: 0.25095146894454956, acc: 0.9202127456665039)
[2024-12-17 03:28:43,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:43,927][root][INFO] - Training Epoch: 2/2, step 6500/7134 completed (loss: 0.4004060626029968, acc: 0.9137930870056152)
[2024-12-17 03:28:44,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:44,317][root][INFO] - Training Epoch: 2/2, step 6501/7134 completed (loss: 0.49661019444465637, acc: 0.8814433217048645)
[2024-12-17 03:28:44,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:44,730][root][INFO] - Training Epoch: 2/2, step 6502/7134 completed (loss: 0.21327024698257446, acc: 0.9444444179534912)
[2024-12-17 03:28:44,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:45,112][root][INFO] - Training Epoch: 2/2, step 6503/7134 completed (loss: 0.2419317066669464, acc: 0.95652174949646)
[2024-12-17 03:28:45,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:45,485][root][INFO] - Training Epoch: 2/2, step 6504/7134 completed (loss: 0.22929494082927704, acc: 0.931506872177124)
[2024-12-17 03:28:45,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:45,854][root][INFO] - Training Epoch: 2/2, step 6505/7134 completed (loss: 0.24708862602710724, acc: 0.95333331823349)
[2024-12-17 03:28:45,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:46,264][root][INFO] - Training Epoch: 2/2, step 6506/7134 completed (loss: 0.2652858793735504, acc: 0.938144326210022)
[2024-12-17 03:28:46,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:46,659][root][INFO] - Training Epoch: 2/2, step 6507/7134 completed (loss: 0.24089990556240082, acc: 0.9263803958892822)
[2024-12-17 03:28:46,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:47,043][root][INFO] - Training Epoch: 2/2, step 6508/7134 completed (loss: 0.1344512403011322, acc: 0.9611111283302307)
[2024-12-17 03:28:47,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:47,451][root][INFO] - Training Epoch: 2/2, step 6509/7134 completed (loss: 0.11796114593744278, acc: 0.9742268323898315)
[2024-12-17 03:28:47,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:47,852][root][INFO] - Training Epoch: 2/2, step 6510/7134 completed (loss: 0.15034228563308716, acc: 0.9611650705337524)
[2024-12-17 03:28:47,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:48,250][root][INFO] - Training Epoch: 2/2, step 6511/7134 completed (loss: 0.15007944405078888, acc: 0.9552238583564758)
[2024-12-17 03:28:48,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:48,660][root][INFO] - Training Epoch: 2/2, step 6512/7134 completed (loss: 0.17430007457733154, acc: 0.9636363387107849)
[2024-12-17 03:28:48,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:49,054][root][INFO] - Training Epoch: 2/2, step 6513/7134 completed (loss: 0.09434536099433899, acc: 0.9629629850387573)
[2024-12-17 03:28:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:49,416][root][INFO] - Training Epoch: 2/2, step 6514/7134 completed (loss: 0.3001127243041992, acc: 0.9444444179534912)
[2024-12-17 03:28:49,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:49,851][root][INFO] - Training Epoch: 2/2, step 6515/7134 completed (loss: 0.09634508192539215, acc: 0.9725274443626404)
[2024-12-17 03:28:49,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:50,274][root][INFO] - Training Epoch: 2/2, step 6516/7134 completed (loss: 0.16777272522449493, acc: 0.9588235020637512)
[2024-12-17 03:28:50,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:50,722][root][INFO] - Training Epoch: 2/2, step 6517/7134 completed (loss: 0.0839323028922081, acc: 0.9813664555549622)
[2024-12-17 03:28:50,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:51,248][root][INFO] - Training Epoch: 2/2, step 6518/7134 completed (loss: 0.053851231932640076, acc: 0.9820359349250793)
[2024-12-17 03:28:51,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:51,659][root][INFO] - Training Epoch: 2/2, step 6519/7134 completed (loss: 0.12226217240095139, acc: 0.9842519760131836)
[2024-12-17 03:28:51,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:52,037][root][INFO] - Training Epoch: 2/2, step 6520/7134 completed (loss: 0.05891440063714981, acc: 0.9935064911842346)
[2024-12-17 03:28:52,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:52,415][root][INFO] - Training Epoch: 2/2, step 6521/7134 completed (loss: 0.056938037276268005, acc: 0.9891892075538635)
[2024-12-17 03:28:52,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:52,833][root][INFO] - Training Epoch: 2/2, step 6522/7134 completed (loss: 0.11140706390142441, acc: 0.9738562107086182)
[2024-12-17 03:28:52,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:53,258][root][INFO] - Training Epoch: 2/2, step 6523/7134 completed (loss: 0.3964270353317261, acc: 0.9375)
[2024-12-17 03:28:53,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:53,654][root][INFO] - Training Epoch: 2/2, step 6524/7134 completed (loss: 0.19082076847553253, acc: 0.9668508172035217)
[2024-12-17 03:28:53,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:54,066][root][INFO] - Training Epoch: 2/2, step 6525/7134 completed (loss: 0.07290446758270264, acc: 0.9917355179786682)
[2024-12-17 03:28:54,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:54,526][root][INFO] - Training Epoch: 2/2, step 6526/7134 completed (loss: 0.1550745964050293, acc: 0.9593908786773682)
[2024-12-17 03:28:54,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:54,932][root][INFO] - Training Epoch: 2/2, step 6527/7134 completed (loss: 0.21706709265708923, acc: 0.9430379867553711)
[2024-12-17 03:28:55,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:55,302][root][INFO] - Training Epoch: 2/2, step 6528/7134 completed (loss: 0.24863766133785248, acc: 0.9492753744125366)
[2024-12-17 03:28:55,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:55,687][root][INFO] - Training Epoch: 2/2, step 6529/7134 completed (loss: 0.263473778963089, acc: 0.9389312863349915)
[2024-12-17 03:28:55,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:56,068][root][INFO] - Training Epoch: 2/2, step 6530/7134 completed (loss: 0.13189710676670074, acc: 0.9779005646705627)
[2024-12-17 03:28:56,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:56,474][root][INFO] - Training Epoch: 2/2, step 6531/7134 completed (loss: 0.1485138237476349, acc: 0.9390243887901306)
[2024-12-17 03:28:56,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:56,853][root][INFO] - Training Epoch: 2/2, step 6532/7134 completed (loss: 0.2888294756412506, acc: 0.9505494236946106)
[2024-12-17 03:28:56,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:57,262][root][INFO] - Training Epoch: 2/2, step 6533/7134 completed (loss: 0.044857896864414215, acc: 0.9870129823684692)
[2024-12-17 03:28:57,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:57,619][root][INFO] - Training Epoch: 2/2, step 6534/7134 completed (loss: 0.24945282936096191, acc: 0.9537572264671326)
[2024-12-17 03:28:57,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:58,023][root][INFO] - Training Epoch: 2/2, step 6535/7134 completed (loss: 0.08574438095092773, acc: 0.9811320900917053)
[2024-12-17 03:28:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:58,419][root][INFO] - Training Epoch: 2/2, step 6536/7134 completed (loss: 0.05386063829064369, acc: 0.9739130139350891)
[2024-12-17 03:28:58,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:58,745][root][INFO] - Training Epoch: 2/2, step 6537/7134 completed (loss: 0.12152452021837234, acc: 0.9642857313156128)
[2024-12-17 03:28:58,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:59,130][root][INFO] - Training Epoch: 2/2, step 6538/7134 completed (loss: 0.20598992705345154, acc: 0.9383561611175537)
[2024-12-17 03:28:59,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:59,478][root][INFO] - Training Epoch: 2/2, step 6539/7134 completed (loss: 0.03781004622578621, acc: 0.9870129823684692)
[2024-12-17 03:28:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:28:59,872][root][INFO] - Training Epoch: 2/2, step 6540/7134 completed (loss: 0.6980239748954773, acc: 0.875)
[2024-12-17 03:29:00,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:00,289][root][INFO] - Training Epoch: 2/2, step 6541/7134 completed (loss: 0.10662661492824554, acc: 0.9558011293411255)
[2024-12-17 03:29:00,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:00,688][root][INFO] - Training Epoch: 2/2, step 6542/7134 completed (loss: 0.1632770597934723, acc: 0.9571428298950195)
[2024-12-17 03:29:00,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:01,063][root][INFO] - Training Epoch: 2/2, step 6543/7134 completed (loss: 0.08177070319652557, acc: 0.9912280440330505)
[2024-12-17 03:29:01,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:01,448][root][INFO] - Training Epoch: 2/2, step 6544/7134 completed (loss: 0.16409623622894287, acc: 0.9369369149208069)
[2024-12-17 03:29:01,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:01,808][root][INFO] - Training Epoch: 2/2, step 6545/7134 completed (loss: 0.03916888311505318, acc: 0.9917355179786682)
[2024-12-17 03:29:01,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:02,153][root][INFO] - Training Epoch: 2/2, step 6546/7134 completed (loss: 0.12850435078144073, acc: 0.97826087474823)
[2024-12-17 03:29:02,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:02,531][root][INFO] - Training Epoch: 2/2, step 6547/7134 completed (loss: 0.26147139072418213, acc: 0.9492753744125366)
[2024-12-17 03:29:02,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:02,882][root][INFO] - Training Epoch: 2/2, step 6548/7134 completed (loss: 0.12034908682107925, acc: 0.961904764175415)
[2024-12-17 03:29:03,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:03,300][root][INFO] - Training Epoch: 2/2, step 6549/7134 completed (loss: 0.3654606342315674, acc: 0.9236640930175781)
[2024-12-17 03:29:03,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:03,678][root][INFO] - Training Epoch: 2/2, step 6550/7134 completed (loss: 0.23052074015140533, acc: 0.9554139971733093)
[2024-12-17 03:29:03,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:04,068][root][INFO] - Training Epoch: 2/2, step 6551/7134 completed (loss: 0.15421193838119507, acc: 0.9543147087097168)
[2024-12-17 03:29:04,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:04,442][root][INFO] - Training Epoch: 2/2, step 6552/7134 completed (loss: 0.2556043565273285, acc: 0.9383260011672974)
[2024-12-17 03:29:04,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:04,837][root][INFO] - Training Epoch: 2/2, step 6553/7134 completed (loss: 0.21450820565223694, acc: 0.9292929172515869)
[2024-12-17 03:29:04,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:05,236][root][INFO] - Training Epoch: 2/2, step 6554/7134 completed (loss: 0.15437184274196625, acc: 0.9672897458076477)
[2024-12-17 03:29:05,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:05,628][root][INFO] - Training Epoch: 2/2, step 6555/7134 completed (loss: 0.2192302942276001, acc: 0.943965494632721)
[2024-12-17 03:29:05,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:05,991][root][INFO] - Training Epoch: 2/2, step 6556/7134 completed (loss: 0.20851178467273712, acc: 0.9683257937431335)
[2024-12-17 03:29:06,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:06,361][root][INFO] - Training Epoch: 2/2, step 6557/7134 completed (loss: 0.21566125750541687, acc: 0.9414414167404175)
[2024-12-17 03:29:06,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:06,747][root][INFO] - Training Epoch: 2/2, step 6558/7134 completed (loss: 0.20210814476013184, acc: 0.9626168012619019)
[2024-12-17 03:29:06,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:07,181][root][INFO] - Training Epoch: 2/2, step 6559/7134 completed (loss: 0.22526589035987854, acc: 0.9518072009086609)
[2024-12-17 03:29:07,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:07,645][root][INFO] - Training Epoch: 2/2, step 6560/7134 completed (loss: 0.10556060075759888, acc: 0.963350772857666)
[2024-12-17 03:29:07,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:08,026][root][INFO] - Training Epoch: 2/2, step 6561/7134 completed (loss: 0.09263118356466293, acc: 0.9738219976425171)
[2024-12-17 03:29:08,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:08,416][root][INFO] - Training Epoch: 2/2, step 6562/7134 completed (loss: 0.09290974587202072, acc: 0.9811320900917053)
[2024-12-17 03:29:08,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:08,830][root][INFO] - Training Epoch: 2/2, step 6563/7134 completed (loss: 0.13271096348762512, acc: 0.9646464586257935)
[2024-12-17 03:29:08,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:09,207][root][INFO] - Training Epoch: 2/2, step 6564/7134 completed (loss: 0.13864244520664215, acc: 0.9759036302566528)
[2024-12-17 03:29:09,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:09,595][root][INFO] - Training Epoch: 2/2, step 6565/7134 completed (loss: 0.25649505853652954, acc: 0.9414414167404175)
[2024-12-17 03:29:09,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:10,068][root][INFO] - Training Epoch: 2/2, step 6566/7134 completed (loss: 0.1343940943479538, acc: 0.9596773982048035)
[2024-12-17 03:29:10,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:10,565][root][INFO] - Training Epoch: 2/2, step 6567/7134 completed (loss: 0.1402936577796936, acc: 0.9599999785423279)
[2024-12-17 03:29:10,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:10,956][root][INFO] - Training Epoch: 2/2, step 6568/7134 completed (loss: 0.13324622809886932, acc: 0.9560439586639404)
[2024-12-17 03:29:11,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:11,340][root][INFO] - Training Epoch: 2/2, step 6569/7134 completed (loss: 0.12998376786708832, acc: 0.9796954393386841)
[2024-12-17 03:29:11,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:11,752][root][INFO] - Training Epoch: 2/2, step 6570/7134 completed (loss: 0.11538585275411606, acc: 0.9753694534301758)
[2024-12-17 03:29:11,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:12,149][root][INFO] - Training Epoch: 2/2, step 6571/7134 completed (loss: 0.05247291922569275, acc: 0.9939393997192383)
[2024-12-17 03:29:12,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:12,559][root][INFO] - Training Epoch: 2/2, step 6572/7134 completed (loss: 0.12168928980827332, acc: 0.9658536314964294)
[2024-12-17 03:29:12,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:12,967][root][INFO] - Training Epoch: 2/2, step 6573/7134 completed (loss: 0.07538743317127228, acc: 0.9805825352668762)
[2024-12-17 03:29:13,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:13,349][root][INFO] - Training Epoch: 2/2, step 6574/7134 completed (loss: 0.0695999413728714, acc: 0.9784482717514038)
[2024-12-17 03:29:13,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:13,738][root][INFO] - Training Epoch: 2/2, step 6575/7134 completed (loss: 0.15479129552841187, acc: 0.9624413251876831)
[2024-12-17 03:29:13,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:14,137][root][INFO] - Training Epoch: 2/2, step 6576/7134 completed (loss: 0.10346054285764694, acc: 0.9678899049758911)
[2024-12-17 03:29:14,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:14,558][root][INFO] - Training Epoch: 2/2, step 6577/7134 completed (loss: 0.1349942684173584, acc: 0.9636363387107849)
[2024-12-17 03:29:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:15,107][root][INFO] - Training Epoch: 2/2, step 6578/7134 completed (loss: 0.1208808645606041, acc: 0.9590163826942444)
[2024-12-17 03:29:15,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:15,504][root][INFO] - Training Epoch: 2/2, step 6579/7134 completed (loss: 0.22808364033699036, acc: 0.9624060392379761)
[2024-12-17 03:29:15,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:15,911][root][INFO] - Training Epoch: 2/2, step 6580/7134 completed (loss: 0.15631340444087982, acc: 0.9578947424888611)
[2024-12-17 03:29:16,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:16,299][root][INFO] - Training Epoch: 2/2, step 6581/7134 completed (loss: 0.20291244983673096, acc: 0.9513513445854187)
[2024-12-17 03:29:16,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:16,663][root][INFO] - Training Epoch: 2/2, step 6582/7134 completed (loss: 0.25855469703674316, acc: 0.9276315569877625)
[2024-12-17 03:29:16,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:17,049][root][INFO] - Training Epoch: 2/2, step 6583/7134 completed (loss: 0.1678117960691452, acc: 0.9547738432884216)
[2024-12-17 03:29:17,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:17,438][root][INFO] - Training Epoch: 2/2, step 6584/7134 completed (loss: 0.17252235114574432, acc: 0.9516128897666931)
[2024-12-17 03:29:17,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:17,809][root][INFO] - Training Epoch: 2/2, step 6585/7134 completed (loss: 0.18649201095104218, acc: 0.9594594836235046)
[2024-12-17 03:29:17,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:18,221][root][INFO] - Training Epoch: 2/2, step 6586/7134 completed (loss: 0.22590427100658417, acc: 0.9631901979446411)
[2024-12-17 03:29:18,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:18,593][root][INFO] - Training Epoch: 2/2, step 6587/7134 completed (loss: 0.2401258945465088, acc: 0.9639175534248352)
[2024-12-17 03:29:18,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:19,000][root][INFO] - Training Epoch: 2/2, step 6588/7134 completed (loss: 0.1466168761253357, acc: 0.9593023061752319)
[2024-12-17 03:29:19,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:19,405][root][INFO] - Training Epoch: 2/2, step 6589/7134 completed (loss: 0.1911962628364563, acc: 0.9192546606063843)
[2024-12-17 03:29:19,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:19,859][root][INFO] - Training Epoch: 2/2, step 6590/7134 completed (loss: 0.22342468798160553, acc: 0.957446813583374)
[2024-12-17 03:29:19,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:20,272][root][INFO] - Training Epoch: 2/2, step 6591/7134 completed (loss: 0.17020662128925323, acc: 0.9532163739204407)
[2024-12-17 03:29:20,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:20,669][root][INFO] - Training Epoch: 2/2, step 6592/7134 completed (loss: 0.18384487926959991, acc: 0.9458128213882446)
[2024-12-17 03:29:20,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:21,071][root][INFO] - Training Epoch: 2/2, step 6593/7134 completed (loss: 0.1193968802690506, acc: 0.9733333587646484)
[2024-12-17 03:29:21,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:21,457][root][INFO] - Training Epoch: 2/2, step 6594/7134 completed (loss: 0.11213687062263489, acc: 0.9655172228813171)
[2024-12-17 03:29:21,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:21,825][root][INFO] - Training Epoch: 2/2, step 6595/7134 completed (loss: 0.13295094668865204, acc: 0.9691358208656311)
[2024-12-17 03:29:21,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:22,184][root][INFO] - Training Epoch: 2/2, step 6596/7134 completed (loss: 0.198306605219841, acc: 0.9337349534034729)
[2024-12-17 03:29:22,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:22,575][root][INFO] - Training Epoch: 2/2, step 6597/7134 completed (loss: 0.13807174563407898, acc: 0.9581151604652405)
[2024-12-17 03:29:22,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:22,957][root][INFO] - Training Epoch: 2/2, step 6598/7134 completed (loss: 0.21725472807884216, acc: 0.9453551769256592)
[2024-12-17 03:29:23,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:23,418][root][INFO] - Training Epoch: 2/2, step 6599/7134 completed (loss: 0.13221228122711182, acc: 0.9609755873680115)
[2024-12-17 03:29:23,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:23,855][root][INFO] - Training Epoch: 2/2, step 6600/7134 completed (loss: 0.23673102259635925, acc: 0.9382022619247437)
[2024-12-17 03:29:23,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:24,240][root][INFO] - Training Epoch: 2/2, step 6601/7134 completed (loss: 0.24073421955108643, acc: 0.9411764740943909)
[2024-12-17 03:29:24,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:24,668][root][INFO] - Training Epoch: 2/2, step 6602/7134 completed (loss: 0.15251648426055908, acc: 0.9554455280303955)
[2024-12-17 03:29:24,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:25,095][root][INFO] - Training Epoch: 2/2, step 6603/7134 completed (loss: 0.1399928629398346, acc: 0.9748427867889404)
[2024-12-17 03:29:25,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:25,491][root][INFO] - Training Epoch: 2/2, step 6604/7134 completed (loss: 0.25531765818595886, acc: 0.9247311949729919)
[2024-12-17 03:29:25,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:25,888][root][INFO] - Training Epoch: 2/2, step 6605/7134 completed (loss: 0.30075201392173767, acc: 0.9086021780967712)
[2024-12-17 03:29:26,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:26,322][root][INFO] - Training Epoch: 2/2, step 6606/7134 completed (loss: 0.1211514100432396, acc: 0.9664804339408875)
[2024-12-17 03:29:26,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:26,735][root][INFO] - Training Epoch: 2/2, step 6607/7134 completed (loss: 0.2589564025402069, acc: 0.9612902998924255)
[2024-12-17 03:29:26,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:27,178][root][INFO] - Training Epoch: 2/2, step 6608/7134 completed (loss: 0.07939339429140091, acc: 0.9794520735740662)
[2024-12-17 03:29:27,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:27,589][root][INFO] - Training Epoch: 2/2, step 6609/7134 completed (loss: 0.2000875473022461, acc: 0.9433962106704712)
[2024-12-17 03:29:27,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:27,982][root][INFO] - Training Epoch: 2/2, step 6610/7134 completed (loss: 0.24251015484333038, acc: 0.9272727370262146)
[2024-12-17 03:29:28,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:28,411][root][INFO] - Training Epoch: 2/2, step 6611/7134 completed (loss: 0.19786310195922852, acc: 0.9383561611175537)
[2024-12-17 03:29:28,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:28,871][root][INFO] - Training Epoch: 2/2, step 6612/7134 completed (loss: 0.3590709865093231, acc: 0.9025641083717346)
[2024-12-17 03:29:29,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:29,289][root][INFO] - Training Epoch: 2/2, step 6613/7134 completed (loss: 0.16852794587612152, acc: 0.9463087320327759)
[2024-12-17 03:29:29,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:29,690][root][INFO] - Training Epoch: 2/2, step 6614/7134 completed (loss: 0.19063842296600342, acc: 0.9780219793319702)
[2024-12-17 03:29:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:30,069][root][INFO] - Training Epoch: 2/2, step 6615/7134 completed (loss: 0.2067340761423111, acc: 0.9459459185600281)
[2024-12-17 03:29:30,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:30,507][root][INFO] - Training Epoch: 2/2, step 6616/7134 completed (loss: 0.14505645632743835, acc: 0.9636363387107849)
[2024-12-17 03:29:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:30,927][root][INFO] - Training Epoch: 2/2, step 6617/7134 completed (loss: 0.11734157055616379, acc: 0.970370352268219)
[2024-12-17 03:29:31,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:31,302][root][INFO] - Training Epoch: 2/2, step 6618/7134 completed (loss: 0.03778596594929695, acc: 0.9927536249160767)
[2024-12-17 03:29:31,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:31,720][root][INFO] - Training Epoch: 2/2, step 6619/7134 completed (loss: 0.11417367309331894, acc: 0.9661017060279846)
[2024-12-17 03:29:31,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:32,110][root][INFO] - Training Epoch: 2/2, step 6620/7134 completed (loss: 0.21263648569583893, acc: 0.9375)
[2024-12-17 03:29:32,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:32,504][root][INFO] - Training Epoch: 2/2, step 6621/7134 completed (loss: 0.12278921157121658, acc: 0.9599999785423279)
[2024-12-17 03:29:32,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:32,905][root][INFO] - Training Epoch: 2/2, step 6622/7134 completed (loss: 0.1020224392414093, acc: 0.9679487347602844)
[2024-12-17 03:29:33,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:33,276][root][INFO] - Training Epoch: 2/2, step 6623/7134 completed (loss: 0.17784419655799866, acc: 0.9640718698501587)
[2024-12-17 03:29:33,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:33,671][root][INFO] - Training Epoch: 2/2, step 6624/7134 completed (loss: 0.06593667715787888, acc: 0.993630588054657)
[2024-12-17 03:29:33,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:34,079][root][INFO] - Training Epoch: 2/2, step 6625/7134 completed (loss: 0.09423892945051193, acc: 0.9735099077224731)
[2024-12-17 03:29:34,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:34,580][root][INFO] - Training Epoch: 2/2, step 6626/7134 completed (loss: 0.19442938268184662, acc: 0.9371428489685059)
[2024-12-17 03:29:34,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:35,001][root][INFO] - Training Epoch: 2/2, step 6627/7134 completed (loss: 0.11549684405326843, acc: 0.9731183052062988)
[2024-12-17 03:29:35,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:35,375][root][INFO] - Training Epoch: 2/2, step 6628/7134 completed (loss: 0.14302372932434082, acc: 0.9642857313156128)
[2024-12-17 03:29:35,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:35,777][root][INFO] - Training Epoch: 2/2, step 6629/7134 completed (loss: 0.20983800292015076, acc: 0.9624999761581421)
[2024-12-17 03:29:35,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:36,194][root][INFO] - Training Epoch: 2/2, step 6630/7134 completed (loss: 0.11739393323659897, acc: 0.9791666865348816)
[2024-12-17 03:29:36,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:36,567][root][INFO] - Training Epoch: 2/2, step 6631/7134 completed (loss: 0.10456615686416626, acc: 0.9689440727233887)
[2024-12-17 03:29:36,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:37,019][root][INFO] - Training Epoch: 2/2, step 6632/7134 completed (loss: 0.06208985298871994, acc: 0.989847719669342)
[2024-12-17 03:29:37,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:37,405][root][INFO] - Training Epoch: 2/2, step 6633/7134 completed (loss: 0.11211969703435898, acc: 0.9835164546966553)
[2024-12-17 03:29:37,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:37,780][root][INFO] - Training Epoch: 2/2, step 6634/7134 completed (loss: 0.12095442414283752, acc: 0.9774436354637146)
[2024-12-17 03:29:37,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:38,135][root][INFO] - Training Epoch: 2/2, step 6635/7134 completed (loss: 0.3427666425704956, acc: 0.9200000166893005)
[2024-12-17 03:29:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:38,511][root][INFO] - Training Epoch: 2/2, step 6636/7134 completed (loss: 0.2089085876941681, acc: 0.9414634108543396)
[2024-12-17 03:29:38,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:38,883][root][INFO] - Training Epoch: 2/2, step 6637/7134 completed (loss: 0.18550345301628113, acc: 0.9437500238418579)
[2024-12-17 03:29:38,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:39,263][root][INFO] - Training Epoch: 2/2, step 6638/7134 completed (loss: 0.14186857640743256, acc: 0.9615384340286255)
[2024-12-17 03:29:39,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:39,654][root][INFO] - Training Epoch: 2/2, step 6639/7134 completed (loss: 0.3529787063598633, acc: 0.946107804775238)
[2024-12-17 03:29:39,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:40,059][root][INFO] - Training Epoch: 2/2, step 6640/7134 completed (loss: 0.1310555636882782, acc: 0.9745222926139832)
[2024-12-17 03:29:40,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:40,447][root][INFO] - Training Epoch: 2/2, step 6641/7134 completed (loss: 0.3736170530319214, acc: 0.9115044474601746)
[2024-12-17 03:29:40,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:40,842][root][INFO] - Training Epoch: 2/2, step 6642/7134 completed (loss: 0.1711188107728958, acc: 0.9638554453849792)
[2024-12-17 03:29:40,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:41,224][root][INFO] - Training Epoch: 2/2, step 6643/7134 completed (loss: 0.18341782689094543, acc: 0.9516128897666931)
[2024-12-17 03:29:41,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:41,599][root][INFO] - Training Epoch: 2/2, step 6644/7134 completed (loss: 0.16691873967647552, acc: 0.954356849193573)
[2024-12-17 03:29:41,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:41,966][root][INFO] - Training Epoch: 2/2, step 6645/7134 completed (loss: 0.11568596214056015, acc: 0.9629629850387573)
[2024-12-17 03:29:42,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:42,347][root][INFO] - Training Epoch: 2/2, step 6646/7134 completed (loss: 0.19856911897659302, acc: 0.943231463432312)
[2024-12-17 03:29:42,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:42,719][root][INFO] - Training Epoch: 2/2, step 6647/7134 completed (loss: 0.07894688844680786, acc: 0.9764705896377563)
[2024-12-17 03:29:42,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:43,104][root][INFO] - Training Epoch: 2/2, step 6648/7134 completed (loss: 0.1489233374595642, acc: 0.9612902998924255)
[2024-12-17 03:29:43,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:43,491][root][INFO] - Training Epoch: 2/2, step 6649/7134 completed (loss: 0.2215888649225235, acc: 0.9516907930374146)
[2024-12-17 03:29:43,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:43,882][root][INFO] - Training Epoch: 2/2, step 6650/7134 completed (loss: 0.1329917311668396, acc: 0.9545454382896423)
[2024-12-17 03:29:43,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:44,271][root][INFO] - Training Epoch: 2/2, step 6651/7134 completed (loss: 0.18730686604976654, acc: 0.9488636255264282)
[2024-12-17 03:29:44,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:44,654][root][INFO] - Training Epoch: 2/2, step 6652/7134 completed (loss: 0.316628634929657, acc: 0.9166666865348816)
[2024-12-17 03:29:44,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:45,065][root][INFO] - Training Epoch: 2/2, step 6653/7134 completed (loss: 0.3405834138393402, acc: 0.8863636255264282)
[2024-12-17 03:29:45,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:45,436][root][INFO] - Training Epoch: 2/2, step 6654/7134 completed (loss: 0.3008806109428406, acc: 0.9367088675498962)
[2024-12-17 03:29:45,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:45,812][root][INFO] - Training Epoch: 2/2, step 6655/7134 completed (loss: 0.20143607258796692, acc: 0.9523809552192688)
[2024-12-17 03:29:45,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:46,180][root][INFO] - Training Epoch: 2/2, step 6656/7134 completed (loss: 0.1930808275938034, acc: 0.9315789341926575)
[2024-12-17 03:29:46,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:46,558][root][INFO] - Training Epoch: 2/2, step 6657/7134 completed (loss: 0.24856522679328918, acc: 0.9308510422706604)
[2024-12-17 03:29:46,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:46,934][root][INFO] - Training Epoch: 2/2, step 6658/7134 completed (loss: 0.1325325071811676, acc: 0.9543147087097168)
[2024-12-17 03:29:47,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:47,351][root][INFO] - Training Epoch: 2/2, step 6659/7134 completed (loss: 0.20325128734111786, acc: 0.9508196711540222)
[2024-12-17 03:29:47,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:47,745][root][INFO] - Training Epoch: 2/2, step 6660/7134 completed (loss: 0.10720045119524002, acc: 0.9672130942344666)
[2024-12-17 03:29:47,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:48,126][root][INFO] - Training Epoch: 2/2, step 6661/7134 completed (loss: 0.17723597586154938, acc: 0.9452736377716064)
[2024-12-17 03:29:48,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:48,497][root][INFO] - Training Epoch: 2/2, step 6662/7134 completed (loss: 0.2875008285045624, acc: 0.9280575513839722)
[2024-12-17 03:29:48,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:48,933][root][INFO] - Training Epoch: 2/2, step 6663/7134 completed (loss: 0.14754606783390045, acc: 0.9567099809646606)
[2024-12-17 03:29:49,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:49,353][root][INFO] - Training Epoch: 2/2, step 6664/7134 completed (loss: 0.23115786910057068, acc: 0.949999988079071)
[2024-12-17 03:29:49,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:49,732][root][INFO] - Training Epoch: 2/2, step 6665/7134 completed (loss: 0.20534776151180267, acc: 0.9245283007621765)
[2024-12-17 03:29:49,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:50,177][root][INFO] - Training Epoch: 2/2, step 6666/7134 completed (loss: 0.1138700321316719, acc: 0.9757575988769531)
[2024-12-17 03:29:50,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:50,581][root][INFO] - Training Epoch: 2/2, step 6667/7134 completed (loss: 0.23320627212524414, acc: 0.918367326259613)
[2024-12-17 03:29:50,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:50,999][root][INFO] - Training Epoch: 2/2, step 6668/7134 completed (loss: 0.08220688253641129, acc: 0.9781022071838379)
[2024-12-17 03:29:51,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:51,384][root][INFO] - Training Epoch: 2/2, step 6669/7134 completed (loss: 0.07429324835538864, acc: 0.9722222089767456)
[2024-12-17 03:29:51,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:51,752][root][INFO] - Training Epoch: 2/2, step 6670/7134 completed (loss: 0.12021636962890625, acc: 0.971222996711731)
[2024-12-17 03:29:51,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:52,143][root][INFO] - Training Epoch: 2/2, step 6671/7134 completed (loss: 0.1281299889087677, acc: 0.9634146094322205)
[2024-12-17 03:29:52,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:52,538][root][INFO] - Training Epoch: 2/2, step 6672/7134 completed (loss: 0.077540323138237, acc: 0.9760000109672546)
[2024-12-17 03:29:52,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:52,921][root][INFO] - Training Epoch: 2/2, step 6673/7134 completed (loss: 0.055061426013708115, acc: 0.9748427867889404)
[2024-12-17 03:29:53,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:53,290][root][INFO] - Training Epoch: 2/2, step 6674/7134 completed (loss: 0.06068120896816254, acc: 0.9830508232116699)
[2024-12-17 03:29:53,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:53,691][root][INFO] - Training Epoch: 2/2, step 6675/7134 completed (loss: 0.12846440076828003, acc: 0.9607843160629272)
[2024-12-17 03:29:53,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:54,086][root][INFO] - Training Epoch: 2/2, step 6676/7134 completed (loss: 0.059947241097688675, acc: 0.9800000190734863)
[2024-12-17 03:29:54,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:54,505][root][INFO] - Training Epoch: 2/2, step 6677/7134 completed (loss: 0.11157877743244171, acc: 0.9770992398262024)
[2024-12-17 03:29:54,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:54,923][root][INFO] - Training Epoch: 2/2, step 6678/7134 completed (loss: 0.07240014523267746, acc: 0.9851852059364319)
[2024-12-17 03:29:55,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:55,336][root][INFO] - Training Epoch: 2/2, step 6679/7134 completed (loss: 0.06900124996900558, acc: 0.982300877571106)
[2024-12-17 03:29:55,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:55,732][root][INFO] - Training Epoch: 2/2, step 6680/7134 completed (loss: 0.058641813695430756, acc: 0.9885057210922241)
[2024-12-17 03:29:55,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:56,139][root][INFO] - Training Epoch: 2/2, step 6681/7134 completed (loss: 0.023450840264558792, acc: 0.9921875)
[2024-12-17 03:29:56,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:56,521][root][INFO] - Training Epoch: 2/2, step 6682/7134 completed (loss: 0.21452894806861877, acc: 0.9514563083648682)
[2024-12-17 03:29:56,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:56,889][root][INFO] - Training Epoch: 2/2, step 6683/7134 completed (loss: 0.1573963165283203, acc: 0.9655172228813171)
[2024-12-17 03:29:56,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:57,264][root][INFO] - Training Epoch: 2/2, step 6684/7134 completed (loss: 0.1874169409275055, acc: 0.960629940032959)
[2024-12-17 03:29:57,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:57,644][root][INFO] - Training Epoch: 2/2, step 6685/7134 completed (loss: 0.14808109402656555, acc: 0.9520000219345093)
[2024-12-17 03:29:57,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:58,010][root][INFO] - Training Epoch: 2/2, step 6686/7134 completed (loss: 0.21243460476398468, acc: 0.9568965435028076)
[2024-12-17 03:29:58,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:58,386][root][INFO] - Training Epoch: 2/2, step 6687/7134 completed (loss: 0.17674975097179413, acc: 0.9767441749572754)
[2024-12-17 03:29:58,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:58,800][root][INFO] - Training Epoch: 2/2, step 6688/7134 completed (loss: 0.32656121253967285, acc: 0.9064748287200928)
[2024-12-17 03:29:58,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:59,181][root][INFO] - Training Epoch: 2/2, step 6689/7134 completed (loss: 0.2355266660451889, acc: 0.9444444179534912)
[2024-12-17 03:29:59,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:59,539][root][INFO] - Training Epoch: 2/2, step 6690/7134 completed (loss: 0.3384269177913666, acc: 0.9019607901573181)
[2024-12-17 03:29:59,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:29:59,936][root][INFO] - Training Epoch: 2/2, step 6691/7134 completed (loss: 0.1438085436820984, acc: 0.9652777910232544)
[2024-12-17 03:30:00,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:00,318][root][INFO] - Training Epoch: 2/2, step 6692/7134 completed (loss: 0.28479135036468506, acc: 0.9252336621284485)
[2024-12-17 03:30:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:00,730][root][INFO] - Training Epoch: 2/2, step 6693/7134 completed (loss: 0.21448636054992676, acc: 0.9407407641410828)
[2024-12-17 03:30:00,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:01,139][root][INFO] - Training Epoch: 2/2, step 6694/7134 completed (loss: 0.11728350073099136, acc: 0.9735099077224731)
[2024-12-17 03:30:01,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:01,551][root][INFO] - Training Epoch: 2/2, step 6695/7134 completed (loss: 0.17325632274150848, acc: 0.9602272510528564)
[2024-12-17 03:30:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:01,987][root][INFO] - Training Epoch: 2/2, step 6696/7134 completed (loss: 0.23678292334079742, acc: 0.9375)
[2024-12-17 03:30:02,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:02,423][root][INFO] - Training Epoch: 2/2, step 6697/7134 completed (loss: 0.3542407751083374, acc: 0.9071428775787354)
[2024-12-17 03:30:02,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:02,827][root][INFO] - Training Epoch: 2/2, step 6698/7134 completed (loss: 0.10661458969116211, acc: 0.9664429426193237)
[2024-12-17 03:30:02,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:03,269][root][INFO] - Training Epoch: 2/2, step 6699/7134 completed (loss: 0.1979190856218338, acc: 0.9523809552192688)
[2024-12-17 03:30:03,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:03,682][root][INFO] - Training Epoch: 2/2, step 6700/7134 completed (loss: 0.34975072741508484, acc: 0.8962963223457336)
[2024-12-17 03:30:03,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:04,075][root][INFO] - Training Epoch: 2/2, step 6701/7134 completed (loss: 0.44446897506713867, acc: 0.8805969953536987)
[2024-12-17 03:30:04,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:04,475][root][INFO] - Training Epoch: 2/2, step 6702/7134 completed (loss: 0.22957274317741394, acc: 0.939130425453186)
[2024-12-17 03:30:04,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:04,835][root][INFO] - Training Epoch: 2/2, step 6703/7134 completed (loss: 0.2559012770652771, acc: 0.95652174949646)
[2024-12-17 03:30:04,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:05,211][root][INFO] - Training Epoch: 2/2, step 6704/7134 completed (loss: 0.31500381231307983, acc: 0.9137930870056152)
[2024-12-17 03:30:05,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:05,607][root][INFO] - Training Epoch: 2/2, step 6705/7134 completed (loss: 0.15202973783016205, acc: 0.9479768872261047)
[2024-12-17 03:30:05,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:06,058][root][INFO] - Training Epoch: 2/2, step 6706/7134 completed (loss: 0.1579165756702423, acc: 0.9545454382896423)
[2024-12-17 03:30:06,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:06,445][root][INFO] - Training Epoch: 2/2, step 6707/7134 completed (loss: 0.12186899036169052, acc: 0.9743589758872986)
[2024-12-17 03:30:06,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:06,830][root][INFO] - Training Epoch: 2/2, step 6708/7134 completed (loss: 0.2321823686361313, acc: 0.9160305261611938)
[2024-12-17 03:30:06,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:07,215][root][INFO] - Training Epoch: 2/2, step 6709/7134 completed (loss: 0.18346142768859863, acc: 0.957317054271698)
[2024-12-17 03:30:07,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:07,633][root][INFO] - Training Epoch: 2/2, step 6710/7134 completed (loss: 0.2388543337583542, acc: 0.9548872113227844)
[2024-12-17 03:30:07,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:08,038][root][INFO] - Training Epoch: 2/2, step 6711/7134 completed (loss: 0.10372591763734818, acc: 0.9810126423835754)
[2024-12-17 03:30:08,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:08,432][root][INFO] - Training Epoch: 2/2, step 6712/7134 completed (loss: 0.2983413338661194, acc: 0.9103448390960693)
[2024-12-17 03:30:08,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:08,888][root][INFO] - Training Epoch: 2/2, step 6713/7134 completed (loss: 0.4030129015445709, acc: 0.9141104221343994)
[2024-12-17 03:30:08,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:09,292][root][INFO] - Training Epoch: 2/2, step 6714/7134 completed (loss: 0.2898704707622528, acc: 0.9306358098983765)
[2024-12-17 03:30:09,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:09,684][root][INFO] - Training Epoch: 2/2, step 6715/7134 completed (loss: 0.35368022322654724, acc: 0.9189189076423645)
[2024-12-17 03:30:09,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:10,061][root][INFO] - Training Epoch: 2/2, step 6716/7134 completed (loss: 0.17342022061347961, acc: 0.9520547986030579)
[2024-12-17 03:30:10,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:10,423][root][INFO] - Training Epoch: 2/2, step 6717/7134 completed (loss: 0.13535214960575104, acc: 0.9594594836235046)
[2024-12-17 03:30:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:10,784][root][INFO] - Training Epoch: 2/2, step 6718/7134 completed (loss: 0.18149083852767944, acc: 0.9724137783050537)
[2024-12-17 03:30:10,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:11,175][root][INFO] - Training Epoch: 2/2, step 6719/7134 completed (loss: 0.14218637347221375, acc: 0.9731543660163879)
[2024-12-17 03:30:11,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:11,613][root][INFO] - Training Epoch: 2/2, step 6720/7134 completed (loss: 0.255718469619751, acc: 0.9252873659133911)
[2024-12-17 03:30:11,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:11,986][root][INFO] - Training Epoch: 2/2, step 6721/7134 completed (loss: 0.29474207758903503, acc: 0.9426751732826233)
[2024-12-17 03:30:12,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:12,346][root][INFO] - Training Epoch: 2/2, step 6722/7134 completed (loss: 0.27596473693847656, acc: 0.9300699234008789)
[2024-12-17 03:30:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:12,741][root][INFO] - Training Epoch: 2/2, step 6723/7134 completed (loss: 0.12777340412139893, acc: 0.9836065769195557)
[2024-12-17 03:30:12,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:13,129][root][INFO] - Training Epoch: 2/2, step 6724/7134 completed (loss: 0.2533464729785919, acc: 0.9622641801834106)
[2024-12-17 03:30:13,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:13,493][root][INFO] - Training Epoch: 2/2, step 6725/7134 completed (loss: 0.213633731007576, acc: 0.9407894611358643)
[2024-12-17 03:30:13,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:13,892][root][INFO] - Training Epoch: 2/2, step 6726/7134 completed (loss: 0.33231982588768005, acc: 0.942148745059967)
[2024-12-17 03:30:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:14,268][root][INFO] - Training Epoch: 2/2, step 6727/7134 completed (loss: 0.2615773677825928, acc: 0.9208633303642273)
[2024-12-17 03:30:14,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:14,668][root][INFO] - Training Epoch: 2/2, step 6728/7134 completed (loss: 0.2818048894405365, acc: 0.9161290526390076)
[2024-12-17 03:30:14,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:15,048][root][INFO] - Training Epoch: 2/2, step 6729/7134 completed (loss: 0.08438480645418167, acc: 0.9746835231781006)
[2024-12-17 03:30:15,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:15,431][root][INFO] - Training Epoch: 2/2, step 6730/7134 completed (loss: 0.25853344798088074, acc: 0.9367815852165222)
[2024-12-17 03:30:15,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:15,827][root][INFO] - Training Epoch: 2/2, step 6731/7134 completed (loss: 0.1665937751531601, acc: 0.9638554453849792)
[2024-12-17 03:30:15,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:16,201][root][INFO] - Training Epoch: 2/2, step 6732/7134 completed (loss: 0.1566016674041748, acc: 0.942307710647583)
[2024-12-17 03:30:16,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:16,627][root][INFO] - Training Epoch: 2/2, step 6733/7134 completed (loss: 0.13967907428741455, acc: 0.9640287756919861)
[2024-12-17 03:30:16,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:17,008][root][INFO] - Training Epoch: 2/2, step 6734/7134 completed (loss: 0.26792192459106445, acc: 0.9300699234008789)
[2024-12-17 03:30:17,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:17,387][root][INFO] - Training Epoch: 2/2, step 6735/7134 completed (loss: 0.20658911764621735, acc: 0.9358974099159241)
[2024-12-17 03:30:17,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:17,814][root][INFO] - Training Epoch: 2/2, step 6736/7134 completed (loss: 0.19081634283065796, acc: 0.949999988079071)
[2024-12-17 03:30:17,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:18,223][root][INFO] - Training Epoch: 2/2, step 6737/7134 completed (loss: 0.3016725480556488, acc: 0.9139072895050049)
[2024-12-17 03:30:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:18,604][root][INFO] - Training Epoch: 2/2, step 6738/7134 completed (loss: 0.18616318702697754, acc: 0.9558823704719543)
[2024-12-17 03:30:18,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:18,947][root][INFO] - Training Epoch: 2/2, step 6739/7134 completed (loss: 0.1266598105430603, acc: 0.9642857313156128)
[2024-12-17 03:30:19,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:19,339][root][INFO] - Training Epoch: 2/2, step 6740/7134 completed (loss: 0.19977082312107086, acc: 0.9324324131011963)
[2024-12-17 03:30:19,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:19,732][root][INFO] - Training Epoch: 2/2, step 6741/7134 completed (loss: 0.06438851356506348, acc: 0.9759036302566528)
[2024-12-17 03:30:19,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:20,143][root][INFO] - Training Epoch: 2/2, step 6742/7134 completed (loss: 0.04912680387496948, acc: 0.9882352948188782)
[2024-12-17 03:30:20,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:20,548][root][INFO] - Training Epoch: 2/2, step 6743/7134 completed (loss: 0.057143621146678925, acc: 0.9774011373519897)
[2024-12-17 03:30:20,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:20,948][root][INFO] - Training Epoch: 2/2, step 6744/7134 completed (loss: 0.12694214284420013, acc: 0.9594594836235046)
[2024-12-17 03:30:21,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:21,342][root][INFO] - Training Epoch: 2/2, step 6745/7134 completed (loss: 0.05309005081653595, acc: 0.9825581312179565)
[2024-12-17 03:30:21,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:21,677][root][INFO] - Training Epoch: 2/2, step 6746/7134 completed (loss: 0.04802009463310242, acc: 0.9776119589805603)
[2024-12-17 03:30:21,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:22,047][root][INFO] - Training Epoch: 2/2, step 6747/7134 completed (loss: 0.0850713774561882, acc: 0.9738219976425171)
[2024-12-17 03:30:22,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:22,429][root][INFO] - Training Epoch: 2/2, step 6748/7134 completed (loss: 0.11814948916435242, acc: 0.9803921580314636)
[2024-12-17 03:30:22,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:22,856][root][INFO] - Training Epoch: 2/2, step 6749/7134 completed (loss: 0.13514462113380432, acc: 0.9599999785423279)
[2024-12-17 03:30:23,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:23,265][root][INFO] - Training Epoch: 2/2, step 6750/7134 completed (loss: 0.15724711120128632, acc: 0.9653465151786804)
[2024-12-17 03:30:23,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:23,687][root][INFO] - Training Epoch: 2/2, step 6751/7134 completed (loss: 0.08646468818187714, acc: 0.9751243591308594)
[2024-12-17 03:30:23,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:24,070][root][INFO] - Training Epoch: 2/2, step 6752/7134 completed (loss: 0.11717453598976135, acc: 0.9693251252174377)
[2024-12-17 03:30:24,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:24,450][root][INFO] - Training Epoch: 2/2, step 6753/7134 completed (loss: 0.056373231112957, acc: 0.9848484992980957)
[2024-12-17 03:30:24,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:24,861][root][INFO] - Training Epoch: 2/2, step 6754/7134 completed (loss: 0.08088185638189316, acc: 0.9738219976425171)
[2024-12-17 03:30:24,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:25,295][root][INFO] - Training Epoch: 2/2, step 6755/7134 completed (loss: 0.2001694142818451, acc: 0.9581151604652405)
[2024-12-17 03:30:25,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:25,681][root][INFO] - Training Epoch: 2/2, step 6756/7134 completed (loss: 0.07499129325151443, acc: 0.983146071434021)
[2024-12-17 03:30:25,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:26,056][root][INFO] - Training Epoch: 2/2, step 6757/7134 completed (loss: 0.05448799580335617, acc: 0.9870967864990234)
[2024-12-17 03:30:26,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:26,469][root][INFO] - Training Epoch: 2/2, step 6758/7134 completed (loss: 0.06097479909658432, acc: 0.9896373152732849)
[2024-12-17 03:30:26,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:26,858][root][INFO] - Training Epoch: 2/2, step 6759/7134 completed (loss: 0.058310896158218384, acc: 0.9821428656578064)
[2024-12-17 03:30:26,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:27,264][root][INFO] - Training Epoch: 2/2, step 6760/7134 completed (loss: 0.21309952437877655, acc: 0.9627659320831299)
[2024-12-17 03:30:27,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:27,644][root][INFO] - Training Epoch: 2/2, step 6761/7134 completed (loss: 0.14352978765964508, acc: 0.9714285731315613)
[2024-12-17 03:30:27,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:28,027][root][INFO] - Training Epoch: 2/2, step 6762/7134 completed (loss: 0.04968605563044548, acc: 0.9800000190734863)
[2024-12-17 03:30:28,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:28,474][root][INFO] - Training Epoch: 2/2, step 6763/7134 completed (loss: 0.05375240370631218, acc: 0.9839572310447693)
[2024-12-17 03:30:28,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:28,850][root][INFO] - Training Epoch: 2/2, step 6764/7134 completed (loss: 0.0766371563076973, acc: 0.9764705896377563)
[2024-12-17 03:30:28,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:29,248][root][INFO] - Training Epoch: 2/2, step 6765/7134 completed (loss: 0.052377212792634964, acc: 0.9890109896659851)
[2024-12-17 03:30:29,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:29,631][root][INFO] - Training Epoch: 2/2, step 6766/7134 completed (loss: 0.09482409805059433, acc: 0.9885714054107666)
[2024-12-17 03:30:29,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:29,969][root][INFO] - Training Epoch: 2/2, step 6767/7134 completed (loss: 0.19673611223697662, acc: 0.9553571343421936)
[2024-12-17 03:30:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:30,366][root][INFO] - Training Epoch: 2/2, step 6768/7134 completed (loss: 0.043018680065870285, acc: 0.9920634627342224)
[2024-12-17 03:30:30,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:30,725][root][INFO] - Training Epoch: 2/2, step 6769/7134 completed (loss: 0.1908409297466278, acc: 0.9615384340286255)
[2024-12-17 03:30:30,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:31,104][root][INFO] - Training Epoch: 2/2, step 6770/7134 completed (loss: 0.11661847680807114, acc: 0.9736841917037964)
[2024-12-17 03:30:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:31,470][root][INFO] - Training Epoch: 2/2, step 6771/7134 completed (loss: 0.0452708974480629, acc: 0.9941520690917969)
[2024-12-17 03:30:31,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:31,854][root][INFO] - Training Epoch: 2/2, step 6772/7134 completed (loss: 0.2648410499095917, acc: 0.9580419659614563)
[2024-12-17 03:30:31,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:32,205][root][INFO] - Training Epoch: 2/2, step 6773/7134 completed (loss: 0.10726539045572281, acc: 0.9753086566925049)
[2024-12-17 03:30:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:32,580][root][INFO] - Training Epoch: 2/2, step 6774/7134 completed (loss: 0.23122656345367432, acc: 0.9467455744743347)
[2024-12-17 03:30:32,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:33,012][root][INFO] - Training Epoch: 2/2, step 6775/7134 completed (loss: 0.08725528419017792, acc: 0.9793103337287903)
[2024-12-17 03:30:33,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:33,392][root][INFO] - Training Epoch: 2/2, step 6776/7134 completed (loss: 0.09394237399101257, acc: 0.9679999947547913)
[2024-12-17 03:30:33,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:33,782][root][INFO] - Training Epoch: 2/2, step 6777/7134 completed (loss: 0.14243070781230927, acc: 0.9828571677207947)
[2024-12-17 03:30:33,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:34,221][root][INFO] - Training Epoch: 2/2, step 6778/7134 completed (loss: 0.0798974335193634, acc: 0.9829545617103577)
[2024-12-17 03:30:34,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:34,609][root][INFO] - Training Epoch: 2/2, step 6779/7134 completed (loss: 0.07544735819101334, acc: 0.9821428656578064)
[2024-12-17 03:30:34,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:34,985][root][INFO] - Training Epoch: 2/2, step 6780/7134 completed (loss: 0.05081084743142128, acc: 0.9940119981765747)
[2024-12-17 03:30:35,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:35,371][root][INFO] - Training Epoch: 2/2, step 6781/7134 completed (loss: 0.05013442039489746, acc: 0.9824561476707458)
[2024-12-17 03:30:35,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:35,763][root][INFO] - Training Epoch: 2/2, step 6782/7134 completed (loss: 0.04722271114587784, acc: 0.9870967864990234)
[2024-12-17 03:30:35,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:36,132][root][INFO] - Training Epoch: 2/2, step 6783/7134 completed (loss: 0.10070997476577759, acc: 0.9793103337287903)
[2024-12-17 03:30:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:36,536][root][INFO] - Training Epoch: 2/2, step 6784/7134 completed (loss: 0.032589610666036606, acc: 1.0)
[2024-12-17 03:30:36,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:36,954][root][INFO] - Training Epoch: 2/2, step 6785/7134 completed (loss: 0.07675626873970032, acc: 0.9738562107086182)
[2024-12-17 03:30:37,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:37,358][root][INFO] - Training Epoch: 2/2, step 6786/7134 completed (loss: 0.06285620480775833, acc: 0.9830508232116699)
[2024-12-17 03:30:37,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:37,811][root][INFO] - Training Epoch: 2/2, step 6787/7134 completed (loss: 0.07871011644601822, acc: 0.9781420826911926)
[2024-12-17 03:30:37,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:38,201][root][INFO] - Training Epoch: 2/2, step 6788/7134 completed (loss: 0.10016501694917679, acc: 0.971222996711731)
[2024-12-17 03:30:38,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:38,570][root][INFO] - Training Epoch: 2/2, step 6789/7134 completed (loss: 0.051848363131284714, acc: 0.978723406791687)
[2024-12-17 03:30:38,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:38,950][root][INFO] - Training Epoch: 2/2, step 6790/7134 completed (loss: 0.2011232227087021, acc: 0.9545454382896423)
[2024-12-17 03:30:39,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:39,315][root][INFO] - Training Epoch: 2/2, step 6791/7134 completed (loss: 0.08905664086341858, acc: 0.9679487347602844)
[2024-12-17 03:30:39,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:39,711][root][INFO] - Training Epoch: 2/2, step 6792/7134 completed (loss: 0.03762407973408699, acc: 0.9925373196601868)
[2024-12-17 03:30:39,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:40,137][root][INFO] - Training Epoch: 2/2, step 6793/7134 completed (loss: 0.10790657252073288, acc: 0.9736841917037964)
[2024-12-17 03:30:40,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:40,542][root][INFO] - Training Epoch: 2/2, step 6794/7134 completed (loss: 0.07382330298423767, acc: 0.9795918464660645)
[2024-12-17 03:30:40,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:40,974][root][INFO] - Training Epoch: 2/2, step 6795/7134 completed (loss: 0.05123322084546089, acc: 0.9885714054107666)
[2024-12-17 03:30:41,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:41,408][root][INFO] - Training Epoch: 2/2, step 6796/7134 completed (loss: 0.01735568791627884, acc: 1.0)
[2024-12-17 03:30:41,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:41,884][root][INFO] - Training Epoch: 2/2, step 6797/7134 completed (loss: 0.19373950362205505, acc: 0.957317054271698)
[2024-12-17 03:30:41,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:42,284][root][INFO] - Training Epoch: 2/2, step 6798/7134 completed (loss: 0.13206931948661804, acc: 0.9578313231468201)
[2024-12-17 03:30:42,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:42,697][root][INFO] - Training Epoch: 2/2, step 6799/7134 completed (loss: 0.10481677949428558, acc: 0.970059871673584)
[2024-12-17 03:30:42,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:43,091][root][INFO] - Training Epoch: 2/2, step 6800/7134 completed (loss: 0.12935495376586914, acc: 0.9556962251663208)
[2024-12-17 03:30:43,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:43,494][root][INFO] - Training Epoch: 2/2, step 6801/7134 completed (loss: 0.09005128592252731, acc: 0.9568345546722412)
[2024-12-17 03:30:43,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:43,911][root][INFO] - Training Epoch: 2/2, step 6802/7134 completed (loss: 0.06801352649927139, acc: 0.9860140085220337)
[2024-12-17 03:30:44,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:44,318][root][INFO] - Training Epoch: 2/2, step 6803/7134 completed (loss: 0.10159559547901154, acc: 0.9666666388511658)
[2024-12-17 03:30:44,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:44,708][root][INFO] - Training Epoch: 2/2, step 6804/7134 completed (loss: 0.16987496614456177, acc: 0.9731543660163879)
[2024-12-17 03:30:44,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:45,084][root][INFO] - Training Epoch: 2/2, step 6805/7134 completed (loss: 0.1939842849969864, acc: 0.970370352268219)
[2024-12-17 03:30:45,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:45,494][root][INFO] - Training Epoch: 2/2, step 6806/7134 completed (loss: 0.09224110841751099, acc: 0.9775280952453613)
[2024-12-17 03:30:45,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:45,898][root][INFO] - Training Epoch: 2/2, step 6807/7134 completed (loss: 0.0665917843580246, acc: 0.9750000238418579)
[2024-12-17 03:30:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:46,260][root][INFO] - Training Epoch: 2/2, step 6808/7134 completed (loss: 0.10735547542572021, acc: 0.9664429426193237)
[2024-12-17 03:30:46,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:46,629][root][INFO] - Training Epoch: 2/2, step 6809/7134 completed (loss: 0.13456545770168304, acc: 0.9743589758872986)
[2024-12-17 03:30:46,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:47,008][root][INFO] - Training Epoch: 2/2, step 6810/7134 completed (loss: 0.07696805149316788, acc: 0.9659090638160706)
[2024-12-17 03:30:47,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:47,409][root][INFO] - Training Epoch: 2/2, step 6811/7134 completed (loss: 0.08838378638029099, acc: 0.9709302186965942)
[2024-12-17 03:30:47,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:47,830][root][INFO] - Training Epoch: 2/2, step 6812/7134 completed (loss: 0.09006933122873306, acc: 0.9925925731658936)
[2024-12-17 03:30:47,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:48,205][root][INFO] - Training Epoch: 2/2, step 6813/7134 completed (loss: 0.05497719720005989, acc: 0.9937499761581421)
[2024-12-17 03:30:48,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:48,578][root][INFO] - Training Epoch: 2/2, step 6814/7134 completed (loss: 0.029366176575422287, acc: 0.9942857027053833)
[2024-12-17 03:30:48,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:48,964][root][INFO] - Training Epoch: 2/2, step 6815/7134 completed (loss: 0.04820338264107704, acc: 0.9941176176071167)
[2024-12-17 03:30:49,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:49,382][root][INFO] - Training Epoch: 2/2, step 6816/7134 completed (loss: 0.06304781138896942, acc: 0.9861111044883728)
[2024-12-17 03:30:49,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:49,776][root][INFO] - Training Epoch: 2/2, step 6817/7134 completed (loss: 0.17815352976322174, acc: 0.9577465057373047)
[2024-12-17 03:30:49,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:50,169][root][INFO] - Training Epoch: 2/2, step 6818/7134 completed (loss: 0.05834187567234039, acc: 0.9795918464660645)
[2024-12-17 03:30:50,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:50,555][root][INFO] - Training Epoch: 2/2, step 6819/7134 completed (loss: 0.09058023989200592, acc: 0.9635036587715149)
[2024-12-17 03:30:50,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:50,953][root][INFO] - Training Epoch: 2/2, step 6820/7134 completed (loss: 0.10447388142347336, acc: 0.970802903175354)
[2024-12-17 03:30:51,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:51,319][root][INFO] - Training Epoch: 2/2, step 6821/7134 completed (loss: 0.02105061709880829, acc: 1.0)
[2024-12-17 03:30:51,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:51,735][root][INFO] - Training Epoch: 2/2, step 6822/7134 completed (loss: 0.2912939488887787, acc: 0.9224806427955627)
[2024-12-17 03:30:51,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:52,110][root][INFO] - Training Epoch: 2/2, step 6823/7134 completed (loss: 0.10889109969139099, acc: 0.9698795080184937)
[2024-12-17 03:30:52,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:52,501][root][INFO] - Training Epoch: 2/2, step 6824/7134 completed (loss: 0.34382912516593933, acc: 0.8861788511276245)
[2024-12-17 03:30:52,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:52,899][root][INFO] - Training Epoch: 2/2, step 6825/7134 completed (loss: 0.15844140946865082, acc: 0.9462365508079529)
[2024-12-17 03:30:53,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:53,329][root][INFO] - Training Epoch: 2/2, step 6826/7134 completed (loss: 0.2540971636772156, acc: 0.9275362491607666)
[2024-12-17 03:30:53,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:53,720][root][INFO] - Training Epoch: 2/2, step 6827/7134 completed (loss: 0.35635408759117126, acc: 0.921875)
[2024-12-17 03:30:53,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:54,101][root][INFO] - Training Epoch: 2/2, step 6828/7134 completed (loss: 0.28879231214523315, acc: 0.9366196990013123)
[2024-12-17 03:30:54,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:54,503][root][INFO] - Training Epoch: 2/2, step 6829/7134 completed (loss: 0.24366506934165955, acc: 0.9289940595626831)
[2024-12-17 03:30:54,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:54,909][root][INFO] - Training Epoch: 2/2, step 6830/7134 completed (loss: 0.19016426801681519, acc: 0.9662162065505981)
[2024-12-17 03:30:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:55,370][root][INFO] - Training Epoch: 2/2, step 6831/7134 completed (loss: 0.19549213349819183, acc: 0.9497206807136536)
[2024-12-17 03:30:55,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:55,747][root][INFO] - Training Epoch: 2/2, step 6832/7134 completed (loss: 0.24107766151428223, acc: 0.9236111044883728)
[2024-12-17 03:30:55,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:56,110][root][INFO] - Training Epoch: 2/2, step 6833/7134 completed (loss: 0.17231148481369019, acc: 0.9363057613372803)
[2024-12-17 03:30:56,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:56,450][root][INFO] - Training Epoch: 2/2, step 6834/7134 completed (loss: 0.2195310890674591, acc: 0.9463087320327759)
[2024-12-17 03:30:56,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:56,793][root][INFO] - Training Epoch: 2/2, step 6835/7134 completed (loss: 0.16090501844882965, acc: 0.9803921580314636)
[2024-12-17 03:30:56,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:57,173][root][INFO] - Training Epoch: 2/2, step 6836/7134 completed (loss: 0.1285475194454193, acc: 0.971563994884491)
[2024-12-17 03:30:57,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:57,572][root][INFO] - Training Epoch: 2/2, step 6837/7134 completed (loss: 0.12331762164831161, acc: 0.9696969985961914)
[2024-12-17 03:30:57,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:57,951][root][INFO] - Training Epoch: 2/2, step 6838/7134 completed (loss: 0.31390634179115295, acc: 0.9216867685317993)
[2024-12-17 03:30:58,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:58,278][root][INFO] - Training Epoch: 2/2, step 6839/7134 completed (loss: 0.34842196106910706, acc: 0.9466666579246521)
[2024-12-17 03:30:58,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:58,648][root][INFO] - Training Epoch: 2/2, step 6840/7134 completed (loss: 0.26365041732788086, acc: 0.9235668778419495)
[2024-12-17 03:30:58,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:59,036][root][INFO] - Training Epoch: 2/2, step 6841/7134 completed (loss: 0.17610248923301697, acc: 0.957317054271698)
[2024-12-17 03:30:59,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:59,432][root][INFO] - Training Epoch: 2/2, step 6842/7134 completed (loss: 0.16392335295677185, acc: 0.9615384340286255)
[2024-12-17 03:30:59,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:30:59,796][root][INFO] - Training Epoch: 2/2, step 6843/7134 completed (loss: 0.16595368087291718, acc: 0.9585492014884949)
[2024-12-17 03:30:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:00,166][root][INFO] - Training Epoch: 2/2, step 6844/7134 completed (loss: 0.2772592008113861, acc: 0.9127516746520996)
[2024-12-17 03:31:00,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:00,585][root][INFO] - Training Epoch: 2/2, step 6845/7134 completed (loss: 0.1269330084323883, acc: 0.9538461565971375)
[2024-12-17 03:31:00,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:01,006][root][INFO] - Training Epoch: 2/2, step 6846/7134 completed (loss: 0.22149363160133362, acc: 0.9382715821266174)
[2024-12-17 03:31:01,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:01,395][root][INFO] - Training Epoch: 2/2, step 6847/7134 completed (loss: 0.18533113598823547, acc: 0.9437500238418579)
[2024-12-17 03:31:01,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:01,778][root][INFO] - Training Epoch: 2/2, step 6848/7134 completed (loss: 0.19291608035564423, acc: 0.9550561904907227)
[2024-12-17 03:31:01,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:02,155][root][INFO] - Training Epoch: 2/2, step 6849/7134 completed (loss: 0.1337856501340866, acc: 0.9714285731315613)
[2024-12-17 03:31:02,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:02,547][root][INFO] - Training Epoch: 2/2, step 6850/7134 completed (loss: 0.3840043842792511, acc: 0.9428571462631226)
[2024-12-17 03:31:02,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:03,002][root][INFO] - Training Epoch: 2/2, step 6851/7134 completed (loss: 0.19148895144462585, acc: 0.9723756909370422)
[2024-12-17 03:31:03,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:03,381][root][INFO] - Training Epoch: 2/2, step 6852/7134 completed (loss: 0.18453505635261536, acc: 0.9714285731315613)
[2024-12-17 03:31:03,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:03,767][root][INFO] - Training Epoch: 2/2, step 6853/7134 completed (loss: 0.15790140628814697, acc: 0.9537572264671326)
[2024-12-17 03:31:03,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:04,136][root][INFO] - Training Epoch: 2/2, step 6854/7134 completed (loss: 0.1283038705587387, acc: 0.9661017060279846)
[2024-12-17 03:31:04,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:04,519][root][INFO] - Training Epoch: 2/2, step 6855/7134 completed (loss: 0.07687502354383469, acc: 0.9813084006309509)
[2024-12-17 03:31:04,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:04,888][root][INFO] - Training Epoch: 2/2, step 6856/7134 completed (loss: 0.016081511974334717, acc: 0.9939758777618408)
[2024-12-17 03:31:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:05,304][root][INFO] - Training Epoch: 2/2, step 6857/7134 completed (loss: 0.04276319965720177, acc: 0.9940476417541504)
[2024-12-17 03:31:05,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:05,722][root][INFO] - Training Epoch: 2/2, step 6858/7134 completed (loss: 0.0525033064186573, acc: 0.9848484992980957)
[2024-12-17 03:31:05,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:06,137][root][INFO] - Training Epoch: 2/2, step 6859/7134 completed (loss: 0.03849758580327034, acc: 0.9887640476226807)
[2024-12-17 03:31:06,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:06,590][root][INFO] - Training Epoch: 2/2, step 6860/7134 completed (loss: 0.07905852049589157, acc: 0.9793103337287903)
[2024-12-17 03:31:06,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:06,983][root][INFO] - Training Epoch: 2/2, step 6861/7134 completed (loss: 0.055510424077510834, acc: 0.9860140085220337)
[2024-12-17 03:31:07,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:07,379][root][INFO] - Training Epoch: 2/2, step 6862/7134 completed (loss: 0.12392685562372208, acc: 0.9696969985961914)
[2024-12-17 03:31:07,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:07,863][root][INFO] - Training Epoch: 2/2, step 6863/7134 completed (loss: 0.05316724255681038, acc: 0.9882352948188782)
[2024-12-17 03:31:07,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:08,270][root][INFO] - Training Epoch: 2/2, step 6864/7134 completed (loss: 0.06520024687051773, acc: 0.9716312289237976)
[2024-12-17 03:31:08,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:08,671][root][INFO] - Training Epoch: 2/2, step 6865/7134 completed (loss: 0.17077447474002838, acc: 0.9593495726585388)
[2024-12-17 03:31:08,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:09,117][root][INFO] - Training Epoch: 2/2, step 6866/7134 completed (loss: 0.047531284391880035, acc: 0.9803921580314636)
[2024-12-17 03:31:09,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:09,502][root][INFO] - Training Epoch: 2/2, step 6867/7134 completed (loss: 0.020601071417331696, acc: 0.9924812316894531)
[2024-12-17 03:31:09,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:09,881][root][INFO] - Training Epoch: 2/2, step 6868/7134 completed (loss: 0.02174399234354496, acc: 1.0)
[2024-12-17 03:31:10,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:10,302][root][INFO] - Training Epoch: 2/2, step 6869/7134 completed (loss: 0.021165212616324425, acc: 1.0)
[2024-12-17 03:31:10,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:10,745][root][INFO] - Training Epoch: 2/2, step 6870/7134 completed (loss: 0.10462573915719986, acc: 0.9810126423835754)
[2024-12-17 03:31:10,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:11,132][root][INFO] - Training Epoch: 2/2, step 6871/7134 completed (loss: 0.03137833625078201, acc: 1.0)
[2024-12-17 03:31:11,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:11,524][root][INFO] - Training Epoch: 2/2, step 6872/7134 completed (loss: 0.09515500068664551, acc: 0.9829545617103577)
[2024-12-17 03:31:11,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:11,909][root][INFO] - Training Epoch: 2/2, step 6873/7134 completed (loss: 0.07714289426803589, acc: 0.9882352948188782)
[2024-12-17 03:31:12,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:12,304][root][INFO] - Training Epoch: 2/2, step 6874/7134 completed (loss: 0.05735819414258003, acc: 0.96875)
[2024-12-17 03:31:12,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:12,682][root][INFO] - Training Epoch: 2/2, step 6875/7134 completed (loss: 0.15497717261314392, acc: 0.9597315192222595)
[2024-12-17 03:31:12,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:13,007][root][INFO] - Training Epoch: 2/2, step 6876/7134 completed (loss: 0.06439971923828125, acc: 0.9847328066825867)
[2024-12-17 03:31:13,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:13,380][root][INFO] - Training Epoch: 2/2, step 6877/7134 completed (loss: 0.06844231486320496, acc: 0.9823529124259949)
[2024-12-17 03:31:13,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:13,791][root][INFO] - Training Epoch: 2/2, step 6878/7134 completed (loss: 0.1673736423254013, acc: 0.9738562107086182)
[2024-12-17 03:31:13,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:14,198][root][INFO] - Training Epoch: 2/2, step 6879/7134 completed (loss: 0.11610084027051926, acc: 0.9655172228813171)
[2024-12-17 03:31:14,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:14,593][root][INFO] - Training Epoch: 2/2, step 6880/7134 completed (loss: 0.08614671975374222, acc: 0.9746192693710327)
[2024-12-17 03:31:14,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:14,966][root][INFO] - Training Epoch: 2/2, step 6881/7134 completed (loss: 0.17215627431869507, acc: 0.957446813583374)
[2024-12-17 03:31:15,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:15,357][root][INFO] - Training Epoch: 2/2, step 6882/7134 completed (loss: 0.26677098870277405, acc: 0.922535240650177)
[2024-12-17 03:31:15,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:15,777][root][INFO] - Training Epoch: 2/2, step 6883/7134 completed (loss: 0.1353839635848999, acc: 0.970588207244873)
[2024-12-17 03:31:15,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:16,202][root][INFO] - Training Epoch: 2/2, step 6884/7134 completed (loss: 0.19669534265995026, acc: 0.9602272510528564)
[2024-12-17 03:31:16,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:16,555][root][INFO] - Training Epoch: 2/2, step 6885/7134 completed (loss: 0.06551884114742279, acc: 0.9906542301177979)
[2024-12-17 03:31:16,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:16,928][root][INFO] - Training Epoch: 2/2, step 6886/7134 completed (loss: 0.1180802658200264, acc: 0.9729729890823364)
[2024-12-17 03:31:17,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:17,297][root][INFO] - Training Epoch: 2/2, step 6887/7134 completed (loss: 0.12634214758872986, acc: 0.95652174949646)
[2024-12-17 03:31:17,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:17,697][root][INFO] - Training Epoch: 2/2, step 6888/7134 completed (loss: 0.1195698156952858, acc: 0.9599999785423279)
[2024-12-17 03:31:17,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:18,106][root][INFO] - Training Epoch: 2/2, step 6889/7134 completed (loss: 0.07153580337762833, acc: 0.9803921580314636)
[2024-12-17 03:31:18,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:18,492][root][INFO] - Training Epoch: 2/2, step 6890/7134 completed (loss: 0.14736585319042206, acc: 0.9569892287254333)
[2024-12-17 03:31:18,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:18,891][root][INFO] - Training Epoch: 2/2, step 6891/7134 completed (loss: 0.06726416200399399, acc: 0.9876543283462524)
[2024-12-17 03:31:19,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:19,313][root][INFO] - Training Epoch: 2/2, step 6892/7134 completed (loss: 0.1301393061876297, acc: 0.9677419066429138)
[2024-12-17 03:31:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:19,740][root][INFO] - Training Epoch: 2/2, step 6893/7134 completed (loss: 0.20922425389289856, acc: 0.9519230723381042)
[2024-12-17 03:31:19,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:20,153][root][INFO] - Training Epoch: 2/2, step 6894/7134 completed (loss: 0.16017787158489227, acc: 0.9739583134651184)
[2024-12-17 03:31:20,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:20,534][root][INFO] - Training Epoch: 2/2, step 6895/7134 completed (loss: 0.19280558824539185, acc: 0.9704433679580688)
[2024-12-17 03:31:20,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:20,937][root][INFO] - Training Epoch: 2/2, step 6896/7134 completed (loss: 0.21177908778190613, acc: 0.9364162087440491)
[2024-12-17 03:31:21,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:21,322][root][INFO] - Training Epoch: 2/2, step 6897/7134 completed (loss: 0.08886595815420151, acc: 0.9900990128517151)
[2024-12-17 03:31:21,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:21,734][root][INFO] - Training Epoch: 2/2, step 6898/7134 completed (loss: 0.09848325699567795, acc: 0.9710982441902161)
[2024-12-17 03:31:21,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:22,130][root][INFO] - Training Epoch: 2/2, step 6899/7134 completed (loss: 0.1385400891304016, acc: 0.9734042286872864)
[2024-12-17 03:31:22,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:22,508][root][INFO] - Training Epoch: 2/2, step 6900/7134 completed (loss: 0.27628669142723083, acc: 0.9479768872261047)
[2024-12-17 03:31:22,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:22,903][root][INFO] - Training Epoch: 2/2, step 6901/7134 completed (loss: 0.23041372001171112, acc: 0.9513513445854187)
[2024-12-17 03:31:23,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:23,332][root][INFO] - Training Epoch: 2/2, step 6902/7134 completed (loss: 0.024284442886710167, acc: 0.9943820238113403)
[2024-12-17 03:31:23,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:23,733][root][INFO] - Training Epoch: 2/2, step 6903/7134 completed (loss: 0.0958612933754921, acc: 0.9804878234863281)
[2024-12-17 03:31:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:24,153][root][INFO] - Training Epoch: 2/2, step 6904/7134 completed (loss: 0.09019382297992706, acc: 0.9792746305465698)
[2024-12-17 03:31:24,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:24,562][root][INFO] - Training Epoch: 2/2, step 6905/7134 completed (loss: 0.09304746985435486, acc: 0.96517413854599)
[2024-12-17 03:31:24,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:24,947][root][INFO] - Training Epoch: 2/2, step 6906/7134 completed (loss: 0.17286793887615204, acc: 0.970588207244873)
[2024-12-17 03:31:25,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:25,388][root][INFO] - Training Epoch: 2/2, step 6907/7134 completed (loss: 0.10018747299909592, acc: 0.984455943107605)
[2024-12-17 03:31:25,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:25,782][root][INFO] - Training Epoch: 2/2, step 6908/7134 completed (loss: 0.1583780199289322, acc: 0.9666666388511658)
[2024-12-17 03:31:25,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:26,193][root][INFO] - Training Epoch: 2/2, step 6909/7134 completed (loss: 0.1440407633781433, acc: 0.9562841653823853)
[2024-12-17 03:31:26,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:26,584][root][INFO] - Training Epoch: 2/2, step 6910/7134 completed (loss: 0.11839771270751953, acc: 0.9791666865348816)
[2024-12-17 03:31:26,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:26,949][root][INFO] - Training Epoch: 2/2, step 6911/7134 completed (loss: 0.3664954900741577, acc: 0.9337016344070435)
[2024-12-17 03:31:27,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:27,345][root][INFO] - Training Epoch: 2/2, step 6912/7134 completed (loss: 0.14755824208259583, acc: 0.9804878234863281)
[2024-12-17 03:31:27,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:27,794][root][INFO] - Training Epoch: 2/2, step 6913/7134 completed (loss: 0.12286733835935593, acc: 0.9758453965187073)
[2024-12-17 03:31:27,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:28,204][root][INFO] - Training Epoch: 2/2, step 6914/7134 completed (loss: 0.2638278901576996, acc: 0.9346405267715454)
[2024-12-17 03:31:28,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:28,617][root][INFO] - Training Epoch: 2/2, step 6915/7134 completed (loss: 0.13438880443572998, acc: 0.9729729890823364)
[2024-12-17 03:31:28,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:29,013][root][INFO] - Training Epoch: 2/2, step 6916/7134 completed (loss: 0.19475363194942474, acc: 0.9560975432395935)
[2024-12-17 03:31:29,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:29,424][root][INFO] - Training Epoch: 2/2, step 6917/7134 completed (loss: 0.18030384182929993, acc: 0.9432989954948425)
[2024-12-17 03:31:29,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:29,842][root][INFO] - Training Epoch: 2/2, step 6918/7134 completed (loss: 0.11848070472478867, acc: 0.969072163105011)
[2024-12-17 03:31:29,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:30,246][root][INFO] - Training Epoch: 2/2, step 6919/7134 completed (loss: 0.23427988588809967, acc: 0.9492385983467102)
[2024-12-17 03:31:30,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:30,658][root][INFO] - Training Epoch: 2/2, step 6920/7134 completed (loss: 0.06649685651063919, acc: 0.9820359349250793)
[2024-12-17 03:31:30,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,060][root][INFO] - Training Epoch: 2/2, step 6921/7134 completed (loss: 0.16482967138290405, acc: 0.9607843160629272)
[2024-12-17 03:31:31,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,455][root][INFO] - Training Epoch: 2/2, step 6922/7134 completed (loss: 0.18583180010318756, acc: 0.9615384340286255)
[2024-12-17 03:31:31,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:31,835][root][INFO] - Training Epoch: 2/2, step 6923/7134 completed (loss: 0.14796720445156097, acc: 0.9649122953414917)
[2024-12-17 03:31:31,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:32,273][root][INFO] - Training Epoch: 2/2, step 6924/7134 completed (loss: 0.12817788124084473, acc: 0.9696969985961914)
[2024-12-17 03:31:32,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:32,679][root][INFO] - Training Epoch: 2/2, step 6925/7134 completed (loss: 0.11070225387811661, acc: 0.9647058844566345)
[2024-12-17 03:31:32,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:33,071][root][INFO] - Training Epoch: 2/2, step 6926/7134 completed (loss: 0.2010338008403778, acc: 0.9523809552192688)
[2024-12-17 03:31:33,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:33,500][root][INFO] - Training Epoch: 2/2, step 6927/7134 completed (loss: 0.17417030036449432, acc: 0.9603960514068604)
[2024-12-17 03:31:33,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:33,944][root][INFO] - Training Epoch: 2/2, step 6928/7134 completed (loss: 0.21960537135601044, acc: 0.9453125)
[2024-12-17 03:31:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:34,367][root][INFO] - Training Epoch: 2/2, step 6929/7134 completed (loss: 0.06339512765407562, acc: 0.9829545617103577)
[2024-12-17 03:31:34,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:34,756][root][INFO] - Training Epoch: 2/2, step 6930/7134 completed (loss: 0.1599641889333725, acc: 0.96875)
[2024-12-17 03:31:34,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:35,177][root][INFO] - Training Epoch: 2/2, step 6931/7134 completed (loss: 0.1418537199497223, acc: 0.9629629850387573)
[2024-12-17 03:31:35,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:35,653][root][INFO] - Training Epoch: 2/2, step 6932/7134 completed (loss: 0.23379966616630554, acc: 0.9341317415237427)
[2024-12-17 03:31:35,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:36,064][root][INFO] - Training Epoch: 2/2, step 6933/7134 completed (loss: 0.3185581862926483, acc: 0.9221556782722473)
[2024-12-17 03:31:36,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:36,491][root][INFO] - Training Epoch: 2/2, step 6934/7134 completed (loss: 0.16721192002296448, acc: 0.9743589758872986)
[2024-12-17 03:31:36,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:36,884][root][INFO] - Training Epoch: 2/2, step 6935/7134 completed (loss: 0.15915951132774353, acc: 0.9680851101875305)
[2024-12-17 03:31:36,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:37,270][root][INFO] - Training Epoch: 2/2, step 6936/7134 completed (loss: 0.11471495777368546, acc: 0.9731183052062988)
[2024-12-17 03:31:37,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:37,691][root][INFO] - Training Epoch: 2/2, step 6937/7134 completed (loss: 0.2610478103160858, acc: 0.9520547986030579)
[2024-12-17 03:31:37,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,109][root][INFO] - Training Epoch: 2/2, step 6938/7134 completed (loss: 0.3910730183124542, acc: 0.9080459475517273)
[2024-12-17 03:31:38,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,531][root][INFO] - Training Epoch: 2/2, step 6939/7134 completed (loss: 0.21946370601654053, acc: 0.9345238208770752)
[2024-12-17 03:31:38,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:38,922][root][INFO] - Training Epoch: 2/2, step 6940/7134 completed (loss: 0.3841742277145386, acc: 0.9172413945198059)
[2024-12-17 03:31:39,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:39,324][root][INFO] - Training Epoch: 2/2, step 6941/7134 completed (loss: 0.08940277993679047, acc: 0.9779411554336548)
[2024-12-17 03:31:39,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:39,672][root][INFO] - Training Epoch: 2/2, step 6942/7134 completed (loss: 0.20444831252098083, acc: 0.9554139971733093)
[2024-12-17 03:31:39,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:40,119][root][INFO] - Training Epoch: 2/2, step 6943/7134 completed (loss: 0.19448639452457428, acc: 0.9380530714988708)
[2024-12-17 03:31:40,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:40,560][root][INFO] - Training Epoch: 2/2, step 6944/7134 completed (loss: 0.15724356472492218, acc: 0.9655172228813171)
[2024-12-17 03:31:40,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:40,976][root][INFO] - Training Epoch: 2/2, step 6945/7134 completed (loss: 0.23270690441131592, acc: 0.9765625)
[2024-12-17 03:31:41,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:41,445][root][INFO] - Training Epoch: 2/2, step 6946/7134 completed (loss: 0.25500932335853577, acc: 0.9139785170555115)
[2024-12-17 03:31:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:41,870][root][INFO] - Training Epoch: 2/2, step 6947/7134 completed (loss: 0.1738685816526413, acc: 0.9646017551422119)
[2024-12-17 03:31:41,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:42,266][root][INFO] - Training Epoch: 2/2, step 6948/7134 completed (loss: 0.23640543222427368, acc: 0.9357143044471741)
[2024-12-17 03:31:42,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:42,700][root][INFO] - Training Epoch: 2/2, step 6949/7134 completed (loss: 0.16304776072502136, acc: 0.947826087474823)
[2024-12-17 03:31:42,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:43,122][root][INFO] - Training Epoch: 2/2, step 6950/7134 completed (loss: 0.0960133820772171, acc: 0.9746835231781006)
[2024-12-17 03:31:43,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:43,499][root][INFO] - Training Epoch: 2/2, step 6951/7134 completed (loss: 0.19743256270885468, acc: 0.9305555820465088)
[2024-12-17 03:31:43,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:43,884][root][INFO] - Training Epoch: 2/2, step 6952/7134 completed (loss: 0.29319918155670166, acc: 0.9047619104385376)
[2024-12-17 03:31:43,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:44,262][root][INFO] - Training Epoch: 2/2, step 6953/7134 completed (loss: 0.13296359777450562, acc: 0.9548872113227844)
[2024-12-17 03:31:44,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:44,664][root][INFO] - Training Epoch: 2/2, step 6954/7134 completed (loss: 0.2539680302143097, acc: 0.9655172228813171)
[2024-12-17 03:31:44,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:45,049][root][INFO] - Training Epoch: 2/2, step 6955/7134 completed (loss: 0.08790651708841324, acc: 0.9750000238418579)
[2024-12-17 03:31:45,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:45,460][root][INFO] - Training Epoch: 2/2, step 6956/7134 completed (loss: 0.12431022524833679, acc: 0.956204354763031)
[2024-12-17 03:31:45,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:45,882][root][INFO] - Training Epoch: 2/2, step 6957/7134 completed (loss: 0.11980196088552475, acc: 0.9679999947547913)
[2024-12-17 03:31:45,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:46,357][root][INFO] - Training Epoch: 2/2, step 6958/7134 completed (loss: 0.23825779557228088, acc: 0.9572649598121643)
[2024-12-17 03:31:46,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:46,775][root][INFO] - Training Epoch: 2/2, step 6959/7134 completed (loss: 0.43849289417266846, acc: 0.8899082541465759)
[2024-12-17 03:31:46,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:47,179][root][INFO] - Training Epoch: 2/2, step 6960/7134 completed (loss: 0.18385069072246552, acc: 0.9513888955116272)
[2024-12-17 03:31:47,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:47,586][root][INFO] - Training Epoch: 2/2, step 6961/7134 completed (loss: 0.09299139678478241, acc: 0.9572649598121643)
[2024-12-17 03:31:47,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:47,992][root][INFO] - Training Epoch: 2/2, step 6962/7134 completed (loss: 0.12033441662788391, acc: 0.9710144996643066)
[2024-12-17 03:31:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:48,397][root][INFO] - Training Epoch: 2/2, step 6963/7134 completed (loss: 0.11694134771823883, acc: 0.9602649211883545)
[2024-12-17 03:31:48,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:48,774][root][INFO] - Training Epoch: 2/2, step 6964/7134 completed (loss: 0.02685059979557991, acc: 0.9924242496490479)
[2024-12-17 03:31:48,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:49,216][root][INFO] - Training Epoch: 2/2, step 6965/7134 completed (loss: 0.04442479833960533, acc: 0.9856114983558655)
[2024-12-17 03:31:49,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:49,674][root][INFO] - Training Epoch: 2/2, step 6966/7134 completed (loss: 0.0689798891544342, acc: 0.9714285731315613)
[2024-12-17 03:31:49,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:50,078][root][INFO] - Training Epoch: 2/2, step 6967/7134 completed (loss: 0.06859265267848969, acc: 0.9863945841789246)
[2024-12-17 03:31:50,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:50,489][root][INFO] - Training Epoch: 2/2, step 6968/7134 completed (loss: 0.08779897540807724, acc: 0.9731543660163879)
[2024-12-17 03:31:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:50,956][root][INFO] - Training Epoch: 2/2, step 6969/7134 completed (loss: 0.24667783081531525, acc: 0.9435483813285828)
[2024-12-17 03:31:51,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:51,387][root][INFO] - Training Epoch: 2/2, step 6970/7134 completed (loss: 0.3086245357990265, acc: 0.9396551847457886)
[2024-12-17 03:31:51,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:51,791][root][INFO] - Training Epoch: 2/2, step 6971/7134 completed (loss: 0.18522801995277405, acc: 0.9583333134651184)
[2024-12-17 03:31:51,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:52,261][root][INFO] - Training Epoch: 2/2, step 6972/7134 completed (loss: 0.1718263030052185, acc: 0.961240291595459)
[2024-12-17 03:31:52,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:52,694][root][INFO] - Training Epoch: 2/2, step 6973/7134 completed (loss: 0.19959449768066406, acc: 0.9568965435028076)
[2024-12-17 03:31:52,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:53,113][root][INFO] - Training Epoch: 2/2, step 6974/7134 completed (loss: 0.25321587920188904, acc: 0.9477124214172363)
[2024-12-17 03:31:53,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:53,550][root][INFO] - Training Epoch: 2/2, step 6975/7134 completed (loss: 0.15888342261314392, acc: 0.9658119678497314)
[2024-12-17 03:31:53,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:53,983][root][INFO] - Training Epoch: 2/2, step 6976/7134 completed (loss: 0.17499254643917084, acc: 0.9642857313156128)
[2024-12-17 03:31:54,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:54,418][root][INFO] - Training Epoch: 2/2, step 6977/7134 completed (loss: 0.1922224462032318, acc: 0.9541984796524048)
[2024-12-17 03:31:54,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:54,918][root][INFO] - Training Epoch: 2/2, step 6978/7134 completed (loss: 0.10514654219150543, acc: 0.9746835231781006)
[2024-12-17 03:31:55,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:55,386][root][INFO] - Training Epoch: 2/2, step 6979/7134 completed (loss: 0.15635864436626434, acc: 0.9602649211883545)
[2024-12-17 03:31:55,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:55,828][root][INFO] - Training Epoch: 2/2, step 6980/7134 completed (loss: 0.4799862802028656, acc: 0.8983050584793091)
[2024-12-17 03:31:55,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:56,277][root][INFO] - Training Epoch: 2/2, step 6981/7134 completed (loss: 0.2666208744049072, acc: 0.938144326210022)
[2024-12-17 03:31:56,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:56,681][root][INFO] - Training Epoch: 2/2, step 6982/7134 completed (loss: 0.3265751600265503, acc: 0.9424083828926086)
[2024-12-17 03:31:56,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,058][root][INFO] - Training Epoch: 2/2, step 6983/7134 completed (loss: 0.5356326699256897, acc: 0.8717948794364929)
[2024-12-17 03:31:57,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,456][root][INFO] - Training Epoch: 2/2, step 6984/7134 completed (loss: 0.2766668498516083, acc: 0.934883713722229)
[2024-12-17 03:31:57,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:57,893][root][INFO] - Training Epoch: 2/2, step 6985/7134 completed (loss: 0.4544958472251892, acc: 0.8884119987487793)
[2024-12-17 03:31:58,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:58,357][root][INFO] - Training Epoch: 2/2, step 6986/7134 completed (loss: 0.21565136313438416, acc: 0.9320987462997437)
[2024-12-17 03:31:58,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:58,755][root][INFO] - Training Epoch: 2/2, step 6987/7134 completed (loss: 0.18227103352546692, acc: 0.9545454382896423)
[2024-12-17 03:31:58,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:59,110][root][INFO] - Training Epoch: 2/2, step 6988/7134 completed (loss: 0.1545161008834839, acc: 0.9685039520263672)
[2024-12-17 03:31:59,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:59,474][root][INFO] - Training Epoch: 2/2, step 6989/7134 completed (loss: 0.3043857216835022, acc: 0.8918918967247009)
[2024-12-17 03:31:59,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:31:59,913][root][INFO] - Training Epoch: 2/2, step 6990/7134 completed (loss: 0.05868039280176163, acc: 0.9907407164573669)
[2024-12-17 03:32:00,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:00,330][root][INFO] - Training Epoch: 2/2, step 6991/7134 completed (loss: 0.40445563197135925, acc: 0.9306930899620056)
[2024-12-17 03:32:00,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:00,733][root][INFO] - Training Epoch: 2/2, step 6992/7134 completed (loss: 0.16607701778411865, acc: 0.9459459185600281)
[2024-12-17 03:32:00,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:01,192][root][INFO] - Training Epoch: 2/2, step 6993/7134 completed (loss: 0.26467499136924744, acc: 0.9235668778419495)
[2024-12-17 03:32:01,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:01,599][root][INFO] - Training Epoch: 2/2, step 6994/7134 completed (loss: 0.3695657253265381, acc: 0.9333333373069763)
[2024-12-17 03:32:01,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:02,002][root][INFO] - Training Epoch: 2/2, step 6995/7134 completed (loss: 0.17150981724262238, acc: 0.9534883499145508)
[2024-12-17 03:32:02,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:02,378][root][INFO] - Training Epoch: 2/2, step 6996/7134 completed (loss: 0.08174362033605576, acc: 0.9863013625144958)
[2024-12-17 03:32:02,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:02,742][root][INFO] - Training Epoch: 2/2, step 6997/7134 completed (loss: 0.09827563911676407, acc: 0.9677419066429138)
[2024-12-17 03:32:02,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,200][root][INFO] - Training Epoch: 2/2, step 6998/7134 completed (loss: 0.3810468316078186, acc: 0.9157894849777222)
[2024-12-17 03:32:03,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,595][root][INFO] - Training Epoch: 2/2, step 6999/7134 completed (loss: 0.09551828354597092, acc: 0.9774011373519897)
[2024-12-17 03:32:03,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:03,992][root][INFO] - Training Epoch: 2/2, step 7000/7134 completed (loss: 0.13203613460063934, acc: 0.9545454382896423)
[2024-12-17 03:32:04,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:04,411][root][INFO] - Training Epoch: 2/2, step 7001/7134 completed (loss: 0.40333256125450134, acc: 0.9610389471054077)
[2024-12-17 03:32:04,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:04,798][root][INFO] - Training Epoch: 2/2, step 7002/7134 completed (loss: 0.12482272833585739, acc: 0.9831932783126831)
[2024-12-17 03:32:04,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:05,195][root][INFO] - Training Epoch: 2/2, step 7003/7134 completed (loss: 0.06694060564041138, acc: 0.9896373152732849)
[2024-12-17 03:32:05,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:05,652][root][INFO] - Training Epoch: 2/2, step 7004/7134 completed (loss: 0.15125125646591187, acc: 0.9756097793579102)
[2024-12-17 03:32:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:06,051][root][INFO] - Training Epoch: 2/2, step 7005/7134 completed (loss: 0.1774974912405014, acc: 0.9638554453849792)
[2024-12-17 03:32:06,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:06,458][root][INFO] - Training Epoch: 2/2, step 7006/7134 completed (loss: 0.0965903028845787, acc: 0.9627329111099243)
[2024-12-17 03:32:06,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:06,855][root][INFO] - Training Epoch: 2/2, step 7007/7134 completed (loss: 0.1190166249871254, acc: 0.9612902998924255)
[2024-12-17 03:32:06,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:07,259][root][INFO] - Training Epoch: 2/2, step 7008/7134 completed (loss: 0.07987776398658752, acc: 0.9779005646705627)
[2024-12-17 03:32:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:07,660][root][INFO] - Training Epoch: 2/2, step 7009/7134 completed (loss: 0.14636781811714172, acc: 0.9635416865348816)
[2024-12-17 03:32:07,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,061][root][INFO] - Training Epoch: 2/2, step 7010/7134 completed (loss: 0.0729028731584549, acc: 0.9677419066429138)
[2024-12-17 03:32:08,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,486][root][INFO] - Training Epoch: 2/2, step 7011/7134 completed (loss: 0.20351974666118622, acc: 0.9476439952850342)
[2024-12-17 03:32:08,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:08,906][root][INFO] - Training Epoch: 2/2, step 7012/7134 completed (loss: 0.03413534536957741, acc: 1.0)
[2024-12-17 03:32:09,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:09,315][root][INFO] - Training Epoch: 2/2, step 7013/7134 completed (loss: 0.05028018355369568, acc: 0.993630588054657)
[2024-12-17 03:32:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:09,732][root][INFO] - Training Epoch: 2/2, step 7014/7134 completed (loss: 0.15765716135501862, acc: 0.9797297120094299)
[2024-12-17 03:32:09,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:10,153][root][INFO] - Training Epoch: 2/2, step 7015/7134 completed (loss: 0.10743818432092667, acc: 0.9701492786407471)
[2024-12-17 03:32:10,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:10,557][root][INFO] - Training Epoch: 2/2, step 7016/7134 completed (loss: 0.17509368062019348, acc: 0.9679487347602844)
[2024-12-17 03:32:10,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:10,929][root][INFO] - Training Epoch: 2/2, step 7017/7134 completed (loss: 0.30688977241516113, acc: 0.9292035102844238)
[2024-12-17 03:32:11,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:11,351][root][INFO] - Training Epoch: 2/2, step 7018/7134 completed (loss: 0.26908183097839355, acc: 0.9444444179534912)
[2024-12-17 03:32:11,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:11,743][root][INFO] - Training Epoch: 2/2, step 7019/7134 completed (loss: 0.44729849696159363, acc: 0.9240506291389465)
[2024-12-17 03:32:11,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:12,157][root][INFO] - Training Epoch: 2/2, step 7020/7134 completed (loss: 0.0808110386133194, acc: 0.9759036302566528)
[2024-12-17 03:32:12,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:12,605][root][INFO] - Training Epoch: 2/2, step 7021/7134 completed (loss: 0.1517598181962967, acc: 0.9481481313705444)
[2024-12-17 03:32:12,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,009][root][INFO] - Training Epoch: 2/2, step 7022/7134 completed (loss: 0.4281361401081085, acc: 0.8472222089767456)
[2024-12-17 03:32:13,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,391][root][INFO] - Training Epoch: 2/2, step 7023/7134 completed (loss: 0.31508052349090576, acc: 0.9156626462936401)
[2024-12-17 03:32:13,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:13,744][root][INFO] - Training Epoch: 2/2, step 7024/7134 completed (loss: 0.16682714223861694, acc: 0.9420289993286133)
[2024-12-17 03:32:13,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:14,119][root][INFO] - Training Epoch: 2/2, step 7025/7134 completed (loss: 0.34309491515159607, acc: 0.9238095283508301)
[2024-12-17 03:32:14,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:14,473][root][INFO] - Training Epoch: 2/2, step 7026/7134 completed (loss: 0.36562079191207886, acc: 0.9375)
[2024-12-17 03:32:14,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:14,840][root][INFO] - Training Epoch: 2/2, step 7027/7134 completed (loss: 0.21995973587036133, acc: 0.9436619877815247)
[2024-12-17 03:32:14,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:15,187][root][INFO] - Training Epoch: 2/2, step 7028/7134 completed (loss: 0.0947120189666748, acc: 0.9670329689979553)
[2024-12-17 03:32:15,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:15,578][root][INFO] - Training Epoch: 2/2, step 7029/7134 completed (loss: 0.14217305183410645, acc: 0.9550561904907227)
[2024-12-17 03:32:15,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:15,949][root][INFO] - Training Epoch: 2/2, step 7030/7134 completed (loss: 0.3473505675792694, acc: 0.9130434989929199)
[2024-12-17 03:32:16,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:16,347][root][INFO] - Training Epoch: 2/2, step 7031/7134 completed (loss: 0.4205121695995331, acc: 0.8888888955116272)
[2024-12-17 03:32:16,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:16,755][root][INFO] - Training Epoch: 2/2, step 7032/7134 completed (loss: 0.2299562245607376, acc: 0.9411764740943909)
[2024-12-17 03:32:16,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:17,195][root][INFO] - Training Epoch: 2/2, step 7033/7134 completed (loss: 0.36240050196647644, acc: 0.9012345671653748)
[2024-12-17 03:32:17,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:17,597][root][INFO] - Training Epoch: 2/2, step 7034/7134 completed (loss: 0.43384769558906555, acc: 0.90625)
[2024-12-17 03:32:17,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:17,996][root][INFO] - Training Epoch: 2/2, step 7035/7134 completed (loss: 0.3745136857032776, acc: 0.920634925365448)
[2024-12-17 03:32:18,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:18,415][root][INFO] - Training Epoch: 2/2, step 7036/7134 completed (loss: 0.3320969343185425, acc: 0.8571428656578064)
[2024-12-17 03:32:18,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:18,861][root][INFO] - Training Epoch: 2/2, step 7037/7134 completed (loss: 0.1897723227739334, acc: 0.9701492786407471)
[2024-12-17 03:32:19,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:19,282][root][INFO] - Training Epoch: 2/2, step 7038/7134 completed (loss: 0.6460848450660706, acc: 0.8607594966888428)
[2024-12-17 03:32:19,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:19,710][root][INFO] - Training Epoch: 2/2, step 7039/7134 completed (loss: 0.19611237943172455, acc: 0.9555555582046509)
[2024-12-17 03:32:19,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:20,048][root][INFO] - Training Epoch: 2/2, step 7040/7134 completed (loss: 0.41336381435394287, acc: 0.8799999952316284)
[2024-12-17 03:32:20,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:20,478][root][INFO] - Training Epoch: 2/2, step 7041/7134 completed (loss: 0.4239124357700348, acc: 0.875)
[2024-12-17 03:32:20,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:20,875][root][INFO] - Training Epoch: 2/2, step 7042/7134 completed (loss: 0.3724677860736847, acc: 0.9014084339141846)
[2024-12-17 03:32:21,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:21,283][root][INFO] - Training Epoch: 2/2, step 7043/7134 completed (loss: 0.3675135672092438, acc: 0.9333333373069763)
[2024-12-17 03:32:21,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:21,673][root][INFO] - Training Epoch: 2/2, step 7044/7134 completed (loss: 0.29557961225509644, acc: 0.9014084339141846)
[2024-12-17 03:32:21,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:22,077][root][INFO] - Training Epoch: 2/2, step 7045/7134 completed (loss: 0.17610405385494232, acc: 0.9586206674575806)
[2024-12-17 03:32:22,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:22,472][root][INFO] - Training Epoch: 2/2, step 7046/7134 completed (loss: 0.22402794659137726, acc: 0.9520958065986633)
[2024-12-17 03:32:22,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:22,896][root][INFO] - Training Epoch: 2/2, step 7047/7134 completed (loss: 0.18528525531291962, acc: 0.9624413251876831)
[2024-12-17 03:32:23,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:23,308][root][INFO] - Training Epoch: 2/2, step 7048/7134 completed (loss: 0.027892811223864555, acc: 1.0)
[2024-12-17 03:32:23,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:23,740][root][INFO] - Training Epoch: 2/2, step 7049/7134 completed (loss: 0.1774996668100357, acc: 0.9595375657081604)
[2024-12-17 03:32:23,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:24,183][root][INFO] - Training Epoch: 2/2, step 7050/7134 completed (loss: 0.0907164141535759, acc: 0.9828571677207947)
[2024-12-17 03:32:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:24,594][root][INFO] - Training Epoch: 2/2, step 7051/7134 completed (loss: 0.08606788516044617, acc: 0.9836956262588501)
[2024-12-17 03:32:24,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:24,991][root][INFO] - Training Epoch: 2/2, step 7052/7134 completed (loss: 0.10914944857358932, acc: 0.9768785834312439)
[2024-12-17 03:32:25,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:25,400][root][INFO] - Training Epoch: 2/2, step 7053/7134 completed (loss: 0.06430784612894058, acc: 0.9890710115432739)
[2024-12-17 03:32:25,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:25,801][root][INFO] - Training Epoch: 2/2, step 7054/7134 completed (loss: 0.2156122326850891, acc: 0.9612902998924255)
[2024-12-17 03:32:25,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:26,188][root][INFO] - Training Epoch: 2/2, step 7055/7134 completed (loss: 0.17996150255203247, acc: 0.9450549483299255)
[2024-12-17 03:32:26,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:26,601][root][INFO] - Training Epoch: 2/2, step 7056/7134 completed (loss: 0.10448154807090759, acc: 0.9722222089767456)
[2024-12-17 03:32:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:27,019][root][INFO] - Training Epoch: 2/2, step 7057/7134 completed (loss: 0.5609844326972961, acc: 0.90055251121521)
[2024-12-17 03:32:27,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:27,426][root][INFO] - Training Epoch: 2/2, step 7058/7134 completed (loss: 0.2483895719051361, acc: 0.9457364082336426)
[2024-12-17 03:32:27,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:27,830][root][INFO] - Training Epoch: 2/2, step 7059/7134 completed (loss: 0.11359955370426178, acc: 0.9807692170143127)
[2024-12-17 03:32:27,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:28,237][root][INFO] - Training Epoch: 2/2, step 7060/7134 completed (loss: 0.21684439480304718, acc: 0.9577465057373047)
[2024-12-17 03:32:28,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:28,631][root][INFO] - Training Epoch: 2/2, step 7061/7134 completed (loss: 0.21214012801647186, acc: 0.9408602118492126)
[2024-12-17 03:32:28,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:29,007][root][INFO] - Training Epoch: 2/2, step 7062/7134 completed (loss: 0.28817853331565857, acc: 0.9237288236618042)
[2024-12-17 03:32:29,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:29,386][root][INFO] - Training Epoch: 2/2, step 7063/7134 completed (loss: 0.300304114818573, acc: 0.9459459185600281)
[2024-12-17 03:32:29,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:29,776][root][INFO] - Training Epoch: 2/2, step 7064/7134 completed (loss: 0.09750299900770187, acc: 0.9819276928901672)
[2024-12-17 03:32:29,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:30,169][root][INFO] - Training Epoch: 2/2, step 7065/7134 completed (loss: 0.036791734397411346, acc: 0.9898989796638489)
[2024-12-17 03:32:30,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:30,637][root][INFO] - Training Epoch: 2/2, step 7066/7134 completed (loss: 0.09227462857961655, acc: 0.9842932224273682)
[2024-12-17 03:32:30,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:31,092][root][INFO] - Training Epoch: 2/2, step 7067/7134 completed (loss: 0.09788846969604492, acc: 0.9735449552536011)
[2024-12-17 03:32:31,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:31,472][root][INFO] - Training Epoch: 2/2, step 7068/7134 completed (loss: 0.05155915394425392, acc: 0.995121955871582)
[2024-12-17 03:32:31,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:31,854][root][INFO] - Training Epoch: 2/2, step 7069/7134 completed (loss: 0.09393788129091263, acc: 0.9826839566230774)
[2024-12-17 03:32:31,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:32,263][root][INFO] - Training Epoch: 2/2, step 7070/7134 completed (loss: 0.075266994535923, acc: 0.9768785834312439)
[2024-12-17 03:32:32,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:32,674][root][INFO] - Training Epoch: 2/2, step 7071/7134 completed (loss: 0.13149824738502502, acc: 0.9663865566253662)
[2024-12-17 03:32:32,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:33,091][root][INFO] - Training Epoch: 2/2, step 7072/7134 completed (loss: 0.10771916061639786, acc: 0.9696969985961914)
[2024-12-17 03:32:33,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:33,507][root][INFO] - Training Epoch: 2/2, step 7073/7134 completed (loss: 0.11497204005718231, acc: 0.9748743772506714)
[2024-12-17 03:32:33,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:33,901][root][INFO] - Training Epoch: 2/2, step 7074/7134 completed (loss: 0.4385078251361847, acc: 0.8861788511276245)
[2024-12-17 03:32:34,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:34,270][root][INFO] - Training Epoch: 2/2, step 7075/7134 completed (loss: 0.26389801502227783, acc: 0.9363057613372803)
[2024-12-17 03:32:34,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:34,662][root][INFO] - Training Epoch: 2/2, step 7076/7134 completed (loss: 0.4156399071216583, acc: 0.8932584524154663)
[2024-12-17 03:32:34,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,064][root][INFO] - Training Epoch: 2/2, step 7077/7134 completed (loss: 0.21653062105178833, acc: 0.9383561611175537)
[2024-12-17 03:32:35,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,502][root][INFO] - Training Epoch: 2/2, step 7078/7134 completed (loss: 0.1316312700510025, acc: 0.9793103337287903)
[2024-12-17 03:32:35,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:35,910][root][INFO] - Training Epoch: 2/2, step 7079/7134 completed (loss: 0.11989761888980865, acc: 0.9736841917037964)
[2024-12-17 03:32:36,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:36,338][root][INFO] - Training Epoch: 2/2, step 7080/7134 completed (loss: 0.1937141865491867, acc: 0.9455782175064087)
[2024-12-17 03:32:36,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:36,739][root][INFO] - Training Epoch: 2/2, step 7081/7134 completed (loss: 0.07619421929121017, acc: 0.9768785834312439)
[2024-12-17 03:32:36,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,150][root][INFO] - Training Epoch: 2/2, step 7082/7134 completed (loss: 0.2501743733882904, acc: 0.9473684430122375)
[2024-12-17 03:32:37,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,553][root][INFO] - Training Epoch: 2/2, step 7083/7134 completed (loss: 0.07173128426074982, acc: 0.9716312289237976)
[2024-12-17 03:32:37,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:37,958][root][INFO] - Training Epoch: 2/2, step 7084/7134 completed (loss: 0.1649075448513031, acc: 0.9425287246704102)
[2024-12-17 03:32:38,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:38,353][root][INFO] - Training Epoch: 2/2, step 7085/7134 completed (loss: 0.2206670641899109, acc: 0.9466666579246521)
[2024-12-17 03:32:38,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:38,746][root][INFO] - Training Epoch: 2/2, step 7086/7134 completed (loss: 0.1295318901538849, acc: 0.9677419066429138)
[2024-12-17 03:32:38,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,119][root][INFO] - Training Epoch: 2/2, step 7087/7134 completed (loss: 0.20501860976219177, acc: 0.9534883499145508)
[2024-12-17 03:32:39,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,498][root][INFO] - Training Epoch: 2/2, step 7088/7134 completed (loss: 0.2143789678812027, acc: 0.957446813583374)
[2024-12-17 03:32:39,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:39,866][root][INFO] - Training Epoch: 2/2, step 7089/7134 completed (loss: 0.2727499008178711, acc: 0.9290322661399841)
[2024-12-17 03:32:39,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:40,270][root][INFO] - Training Epoch: 2/2, step 7090/7134 completed (loss: 0.17390941083431244, acc: 0.9583333134651184)
[2024-12-17 03:32:40,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:40,656][root][INFO] - Training Epoch: 2/2, step 7091/7134 completed (loss: 0.07277064025402069, acc: 0.9818181991577148)
[2024-12-17 03:32:40,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:41,048][root][INFO] - Training Epoch: 2/2, step 7092/7134 completed (loss: 0.17616187036037445, acc: 0.9548872113227844)
[2024-12-17 03:32:41,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:41,422][root][INFO] - Training Epoch: 2/2, step 7093/7134 completed (loss: 0.19681937992572784, acc: 0.94017094373703)
[2024-12-17 03:32:41,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:41,792][root][INFO] - Training Epoch: 2/2, step 7094/7134 completed (loss: 0.09896254539489746, acc: 0.96875)
[2024-12-17 03:32:41,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,184][root][INFO] - Training Epoch: 2/2, step 7095/7134 completed (loss: 0.16751767694950104, acc: 0.9661017060279846)
[2024-12-17 03:32:42,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,551][root][INFO] - Training Epoch: 2/2, step 7096/7134 completed (loss: 0.10688558965921402, acc: 0.9507042169570923)
[2024-12-17 03:32:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:42,986][root][INFO] - Training Epoch: 2/2, step 7097/7134 completed (loss: 0.2605452835559845, acc: 0.9358974099159241)
[2024-12-17 03:32:43,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:43,411][root][INFO] - Training Epoch: 2/2, step 7098/7134 completed (loss: 0.09141766279935837, acc: 0.9720279574394226)
[2024-12-17 03:32:43,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:43,796][root][INFO] - Training Epoch: 2/2, step 7099/7134 completed (loss: 0.2533106803894043, acc: 0.9275362491607666)
[2024-12-17 03:32:43,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:44,206][root][INFO] - Training Epoch: 2/2, step 7100/7134 completed (loss: 0.20315290987491608, acc: 0.940119743347168)
[2024-12-17 03:32:44,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:44,566][root][INFO] - Training Epoch: 2/2, step 7101/7134 completed (loss: 0.14979715645313263, acc: 0.9640287756919861)
[2024-12-17 03:32:44,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:44,950][root][INFO] - Training Epoch: 2/2, step 7102/7134 completed (loss: 0.17784203588962555, acc: 0.9576271176338196)
[2024-12-17 03:32:45,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:45,378][root][INFO] - Training Epoch: 2/2, step 7103/7134 completed (loss: 0.0922088772058487, acc: 0.984375)
[2024-12-17 03:32:45,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:45,794][root][INFO] - Training Epoch: 2/2, step 7104/7134 completed (loss: 0.08397874981164932, acc: 0.9649122953414917)
[2024-12-17 03:32:45,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:46,208][root][INFO] - Training Epoch: 2/2, step 7105/7134 completed (loss: 0.07000228762626648, acc: 0.9930555820465088)
[2024-12-17 03:32:46,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:46,637][root][INFO] - Training Epoch: 2/2, step 7106/7134 completed (loss: 0.0690535306930542, acc: 0.9777777791023254)
[2024-12-17 03:32:46,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,073][root][INFO] - Training Epoch: 2/2, step 7107/7134 completed (loss: 0.10280913859605789, acc: 0.9689440727233887)
[2024-12-17 03:32:47,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,519][root][INFO] - Training Epoch: 2/2, step 7108/7134 completed (loss: 0.2427700310945511, acc: 0.9416058659553528)
[2024-12-17 03:32:47,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:47,872][root][INFO] - Training Epoch: 2/2, step 7109/7134 completed (loss: 0.17102648317813873, acc: 0.9481481313705444)
[2024-12-17 03:32:47,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:48,263][root][INFO] - Training Epoch: 2/2, step 7110/7134 completed (loss: 0.054587218910455704, acc: 0.9849624037742615)
[2024-12-17 03:32:48,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:48,656][root][INFO] - Training Epoch: 2/2, step 7111/7134 completed (loss: 0.16514387726783752, acc: 0.9537037014961243)
[2024-12-17 03:32:48,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:49,057][root][INFO] - Training Epoch: 2/2, step 7112/7134 completed (loss: 0.11786002665758133, acc: 0.9729729890823364)
[2024-12-17 03:32:49,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:49,494][root][INFO] - Training Epoch: 2/2, step 7113/7134 completed (loss: 0.19077105820178986, acc: 0.9426751732826233)
[2024-12-17 03:32:49,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:49,889][root][INFO] - Training Epoch: 2/2, step 7114/7134 completed (loss: 0.17373616993427277, acc: 0.963302731513977)
[2024-12-17 03:32:49,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:50,272][root][INFO] - Training Epoch: 2/2, step 7115/7134 completed (loss: 0.18830372393131256, acc: 0.9465649127960205)
[2024-12-17 03:32:50,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:50,648][root][INFO] - Training Epoch: 2/2, step 7116/7134 completed (loss: 0.31455332040786743, acc: 0.9338235259056091)
[2024-12-17 03:32:50,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:50,988][root][INFO] - Training Epoch: 2/2, step 7117/7134 completed (loss: 0.2265980988740921, acc: 0.9370078444480896)
[2024-12-17 03:32:51,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:51,372][root][INFO] - Training Epoch: 2/2, step 7118/7134 completed (loss: 0.23337005078792572, acc: 0.9428571462631226)
[2024-12-17 03:32:51,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:51,771][root][INFO] - Training Epoch: 2/2, step 7119/7134 completed (loss: 0.1550530195236206, acc: 0.9586206674575806)
[2024-12-17 03:32:51,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:52,140][root][INFO] - Training Epoch: 2/2, step 7120/7134 completed (loss: 0.1357859969139099, acc: 0.9611650705337524)
[2024-12-17 03:32:52,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:52,518][root][INFO] - Training Epoch: 2/2, step 7121/7134 completed (loss: 0.05575103312730789, acc: 0.9923076629638672)
[2024-12-17 03:32:52,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:52,897][root][INFO] - Training Epoch: 2/2, step 7122/7134 completed (loss: 0.15661358833312988, acc: 0.9677419066429138)
[2024-12-17 03:32:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:53,288][root][INFO] - Training Epoch: 2/2, step 7123/7134 completed (loss: 0.06075141578912735, acc: 0.9898989796638489)
[2024-12-17 03:32:53,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:53,735][root][INFO] - Training Epoch: 2/2, step 7124/7134 completed (loss: 0.18648023903369904, acc: 0.9672130942344666)
[2024-12-17 03:32:53,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:54,129][root][INFO] - Training Epoch: 2/2, step 7125/7134 completed (loss: 0.09382954984903336, acc: 0.9847328066825867)
[2024-12-17 03:32:54,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:54,535][root][INFO] - Training Epoch: 2/2, step 7126/7134 completed (loss: 0.34127551317214966, acc: 0.9270073175430298)
[2024-12-17 03:32:54,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:54,936][root][INFO] - Training Epoch: 2/2, step 7127/7134 completed (loss: 0.19801189005374908, acc: 0.9629629850387573)
[2024-12-17 03:32:55,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:55,365][root][INFO] - Training Epoch: 2/2, step 7128/7134 completed (loss: 0.1473555564880371, acc: 0.965753436088562)
[2024-12-17 03:32:55,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:55,766][root][INFO] - Training Epoch: 2/2, step 7129/7134 completed (loss: 0.4883536696434021, acc: 0.8759689927101135)
[2024-12-17 03:32:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:57,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:57,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:57,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:58,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:58,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:58,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:59,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:32:59,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:00,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:00,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:01,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:02,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:02,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:02,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:03,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:03,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:04,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:05,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:05,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:05,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:06,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:06,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:06,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:07,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:08,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:08,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:09,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:09,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:09,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:10,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:11,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:11,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:11,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:12,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:12,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:13,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:14,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:14,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:14,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:15,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:15,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:15,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:16,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:17,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:17,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:18,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:18,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:18,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:19,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:19,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:19,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:20,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:21,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:21,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:22,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:22,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:22,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:23,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:23,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:23,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:24,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:24,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:25,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:25,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:25,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:26,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:26,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:26,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:27,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:27,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:28,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:28,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:29,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:29,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:29,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:30,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:30,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:31,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:31,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:32,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:32,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:32,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:33,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:33,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:33,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:34,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:34,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:34,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:35,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:35,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:36,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:36,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:36,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:37,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:37,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:38,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:38,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:39,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:39,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:40,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:41,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:41,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:41,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:42,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:42,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:42,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:43,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:43,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:44,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:45,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:45,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:45,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:46,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:46,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:47,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:47,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:47,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:48,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:48,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:48,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:49,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:49,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:50,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:50,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:50,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:51,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:51,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:52,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:53,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:54,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:54,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:56,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:56,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:56,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:57,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:57,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:58,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:59,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:33:59,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:00,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:00,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:00,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:01,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:01,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:02,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:02,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:02,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:03,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:03,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:03,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:04,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:04,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:05,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:05,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:05,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:06,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:07,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:07,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:07,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:08,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:08,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:08,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:09,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:09,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:09,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:10,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:11,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:12,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:12,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:12,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:13,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:13,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:14,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:14,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:14,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:15,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:16,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:16,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:17,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:18,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:18,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:19,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:19,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:19,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:20,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:20,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:20,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:21,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:22,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:23,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:23,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:24,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:24,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:24,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:25,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:25,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:26,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:26,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:27,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:28,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:28,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:29,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:29,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:29,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:30,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:30,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:30,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:31,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:31,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:31,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:32,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:33,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:33,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:34,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:34,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:34,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:35,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:35,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:36,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:36,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:36,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:37,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:37,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:37,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:38,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:38,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:39,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:39,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:40,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:41,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:41,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:42,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:42,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:42,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:43,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:43,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:45,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:45,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:45,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:46,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:46,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:47,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:47,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:48,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:49,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:49,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:50,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:51,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:51,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:51,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:52,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:52,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:52,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:53,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:53,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:54,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:55,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:55,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:55,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:56,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:56,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:57,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:57,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:57,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:58,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:58,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:58,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:59,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:59,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:34:59,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:00,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:00,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:01,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:01,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:02,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:02,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:03,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:03,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:04,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:04,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:05,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:05,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:06,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:06,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:06,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:07,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:07,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:08,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:09,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:10,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:10,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:11,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:12,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:13,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:13,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:13,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:14,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:14,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:14,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:15,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:15,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:15,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:16,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:16,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:16,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:17,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:18,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:18,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:18,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:19,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:19,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:19,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:20,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:21,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:21,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:21,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:22,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:22,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:22,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:23,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:23,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:24,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:25,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:25,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:26,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:26,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:26,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:27,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:27,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:27,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:28,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:28,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:29,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:30,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:30,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:30,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:31,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:31,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:32,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:32,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:32,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:33,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:33,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:34,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:34,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:34,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:35,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:35,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:35,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:36,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:37,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:37,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:37,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:38,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:38,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:38,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:39,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:39,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:40,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:42,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:42,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:43,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:43,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:43,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:44,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:44,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:44,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:45,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:46,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:46,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:46,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:47,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:47,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:48,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:48,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:48,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:49,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:50,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:51,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:51,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:52,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:52,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:52,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:53,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:53,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:54,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:54,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:54,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:55,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:55,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:55,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:56,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:56,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:57,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:57,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:57,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:58,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:58,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:58,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:59,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:35:59,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:00,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:00,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:01,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:01,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:01,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:02,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:02,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:02,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:03,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:04,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:04,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:04,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:05,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:05,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:05,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:06,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:06,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:06,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:07,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:08,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:08,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:08,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:09,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:09,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:10,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:10,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:10,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:11,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:11,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:11,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:12,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:13,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:13,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:13,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:14,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:15,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:15,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:16,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:16,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:17,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:17,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:17,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:18,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:18,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:18,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:19,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:19,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:20,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:20,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:21,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:21,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:22,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:22,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:23,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:23,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:23,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:24,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:24,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:24,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:25,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:25,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:26,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:26,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:26,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:27,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:27,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:28,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:29,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:29,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:30,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:30,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:30,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:31,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:31,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:31,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:32,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:32,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:32,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:33,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:33,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:33,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:34,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:34,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:34,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:35,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:35,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:35,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:36,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:36,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:36,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:37,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:38,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:38,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:39,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:39,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:39,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:40,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:40,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:40,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:41,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:41,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:41,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:42,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:42,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:43,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:43,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:43,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:44,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:45,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:45,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:45,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:46,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:46,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:47,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:47,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:47,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:48,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:48,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:49,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:49,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:50,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:50,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:50,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:51,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:51,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:51,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:52,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:52,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:53,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:53,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:53,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:54,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:55,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:55,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:56,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:56,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:56,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:57,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:57,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:57,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:59,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:59,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:36:59,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:00,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:00,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:01,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:01,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:01,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:02,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:02,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:03,298][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(1.2781, device='cuda:0') eval_epoch_loss=tensor(0.2454, device='cuda:0') eval_epoch_acc=tensor(0.9425, device='cuda:0')
[2024-12-17 03:37:03,300][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-12-17 03:37:03,300][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-12-17 03:37:03,564][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_7130_loss_0.2453521341085434/model.pt
[2024-12-17 03:37:03,567][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/librispeech-100_wavlm_llama32_1b_linear_peft directory
[2024-12-17 03:37:03,568][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 0.2453521341085434
[2024-12-17 03:37:03,568][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.9425398707389832
[2024-12-17 03:37:03,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,045][root][INFO] - Training Epoch: 2/2, step 7130/7134 completed (loss: 0.7582220435142517, acc: 0.8533333539962769)
[2024-12-17 03:37:04,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,494][root][INFO] - Training Epoch: 2/2, step 7131/7134 completed (loss: 0.21754677593708038, acc: 0.9528301954269409)
[2024-12-17 03:37:04,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:04,893][root][INFO] - Training Epoch: 2/2, step 7132/7134 completed (loss: 0.10082370042800903, acc: 0.970588207244873)
[2024-12-17 03:37:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-12-17 03:37:05,315][root][INFO] - Training Epoch: 2/2, step 7133/7134 completed (loss: 0.1269017457962036, acc: 0.9774436354637146)
[2024-12-17 03:37:05,850][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=1.4459, train_epoch_loss=0.3687, epoch time 3682.2139873169363s
[2024-12-17 03:37:05,851][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-12-17 03:37:05,851][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 21 GB
[2024-12-17 03:37:05,851][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-12-17 03:37:05,851][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 0
[2024-12-17 03:37:05,851][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 8 GB
[2024-12-17 03:37:05,856][root][INFO] - Key: avg_train_prep, Value: 26.883066177368164
[2024-12-17 03:37:05,859][root][INFO] - Key: avg_train_loss, Value: 2.163041114807129
[2024-12-17 03:37:05,859][root][INFO] - Key: avg_train_acc, Value: 0.6110798120498657
[2024-12-17 03:37:05,859][root][INFO] - Key: avg_eval_prep, Value: 25.908418655395508
[2024-12-17 03:37:05,860][root][INFO] - Key: avg_eval_loss, Value: 2.1047136783599854
[2024-12-17 03:37:05,860][root][INFO] - Key: avg_eval_acc, Value: 0.6214379668235779
[2024-12-17 03:37:05,860][root][INFO] - Key: avg_epoch_time, Value: 3696.762399589643
[2024-12-17 03:37:05,860][root][INFO] - Key: avg_checkpoint_time, Value: 0.26718928338959813
