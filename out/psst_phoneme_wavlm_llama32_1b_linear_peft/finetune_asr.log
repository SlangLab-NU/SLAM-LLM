[2024-11-13 02:49:05,903][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-13 02:49:05,903][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-13 02:49:05,903][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-13 02:49:05,903][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-13_02-49-05.txt', 'log_interval': 5}
[2024-11-13 02:49:26,025][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-13 02:49:31,393][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-13 02:49:31,395][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-13 02:49:31,398][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-13 02:49:31,399][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-13 02:49:35,761][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 02:49:35,763][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-13 02:49:35,763][slam_llm.models.slam_model][INFO] - setup peft...
[2024-11-13 02:49:36,030][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 02:49:36,032][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-13 02:49:36,133][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-13 02:49:36,133][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-13 02:49:36,134][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-13 02:49:36,138][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-11-13 02:49:38,060][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-13 02:49:38,573][root][INFO] - --> Training Set Length = 2298
[2024-11-13 02:49:38,578][root][INFO] - --> Validation Set Length = 341
[2024-11-13 02:49:38,579][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 02:49:38,579][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 02:49:40,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:41,277][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-13 02:49:41,817][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.668733596801758, acc: 0.0)
[2024-11-13 02:49:41,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:42,117][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.454545021057129, acc: 0.0)
[2024-11-13 02:49:42,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:42,363][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 7.9719133377075195, acc: 0.0)
[2024-11-13 02:49:42,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:42,641][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 8.105181694030762, acc: 0.0)
[2024-11-13 02:49:42,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:43,022][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 6.935710906982422, acc: 0.054054055362939835)
[2024-11-13 02:49:43,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:43,297][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 7.550785064697266, acc: 0.0)
[2024-11-13 02:49:43,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:43,576][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 8.534565925598145, acc: 0.020408162847161293)
[2024-11-13 02:49:43,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:43,847][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 8.191487312316895, acc: 0.0)
[2024-11-13 02:49:43,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:44,130][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.745497703552246, acc: 0.0)
[2024-11-13 02:49:44,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:44,462][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.625200271606445, acc: 0.0)
[2024-11-13 02:49:44,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:44,739][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.46161937713623, acc: 0.0)
[2024-11-13 02:49:44,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:45,019][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.068220138549805, acc: 0.0)
[2024-11-13 02:49:45,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:45,298][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.878807067871094, acc: 0.0)
[2024-11-13 02:49:45,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:45,573][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 7.0040283203125, acc: 0.021739130839705467)
[2024-11-13 02:49:45,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:45,907][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.601143836975098, acc: 0.0)
[2024-11-13 02:49:46,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:46,160][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.5243096351623535, acc: 0.08163265138864517)
[2024-11-13 02:49:46,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:46,444][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.681644439697266, acc: 0.0)
[2024-11-13 02:49:46,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:46,696][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.23445987701416, acc: 0.0)
[2024-11-13 02:49:46,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:46,951][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.501181602478027, acc: 0.1388888955116272)
[2024-11-13 02:49:47,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:47,229][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.594762802124023, acc: 0.05263157933950424)
[2024-11-13 02:49:47,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:47,508][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.121969223022461, acc: 0.03846153989434242)
[2024-11-13 02:49:47,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:47,765][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.38892126083374, acc: 0.0)
[2024-11-13 02:49:47,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:48,009][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.442540168762207, acc: 0.03999999910593033)
[2024-11-13 02:49:48,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:48,263][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.887929916381836, acc: 0.0476190485060215)
[2024-11-13 02:49:48,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:48,512][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.885890007019043, acc: 0.0)
[2024-11-13 02:49:48,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:48,798][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.223604202270508, acc: 0.03773584961891174)
[2024-11-13 02:49:48,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:49,063][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.78192138671875, acc: 0.08219178020954132)
[2024-11-13 02:49:49,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:50,428][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.2111430168151855, acc: 0.25691699981689453)
[2024-11-13 02:49:50,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:50,705][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.970505237579346, acc: 0.04651162773370743)
[2024-11-13 02:49:50,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:50,992][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.468252182006836, acc: 0.1204819306731224)
[2024-11-13 02:49:51,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:51,307][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.288740158081055, acc: 0.1111111119389534)
[2024-11-13 02:49:51,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:51,573][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 7.611308574676514, acc: 0.0357142873108387)
[2024-11-13 02:49:51,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:51,858][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.359655380249023, acc: 0.0)
[2024-11-13 02:49:51,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:52,109][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.974135875701904, acc: 0.0)
[2024-11-13 02:49:52,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:52,413][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.052766799926758, acc: 0.15126051008701324)
[2024-11-13 02:49:52,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:52,712][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.252723693847656, acc: 0.1803278625011444)
[2024-11-13 02:49:52,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:53,009][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.320371150970459, acc: 0.1587301641702652)
[2024-11-13 02:49:53,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:53,245][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.235169410705566, acc: 0.033898305147886276)
[2024-11-13 02:49:53,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:53,546][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 5.164863109588623, acc: 0.2068965584039688)
[2024-11-13 02:49:53,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:53,800][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 8.051466941833496, acc: 0.0)
[2024-11-13 02:49:53,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:54,206][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 6.591322898864746, acc: 0.03846153989434242)
[2024-11-13 02:49:54,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:54,641][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.076723575592041, acc: 0.2567567527294159)
[2024-11-13 02:49:54,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:55,004][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.343128204345703, acc: 0.1538461595773697)
[2024-11-13 02:49:55,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:55,442][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.415618419647217, acc: 0.17171716690063477)
[2024-11-13 02:49:55,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:55,868][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.647577285766602, acc: 0.23711340129375458)
[2024-11-13 02:49:55,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:56,259][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.073023319244385, acc: 0.16911764442920685)
[2024-11-13 02:49:56,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:56,518][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.703132152557373, acc: 0.0)
[2024-11-13 02:49:56,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:56,769][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.616334915161133, acc: 0.0)
[2024-11-13 02:49:56,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:57,026][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 6.714832305908203, acc: 0.0357142873108387)
[2024-11-13 02:49:57,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:57,344][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.026357173919678, acc: 0.02777777798473835)
[2024-11-13 02:49:57,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:57,642][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.185353755950928, acc: 0.21052631735801697)
[2024-11-13 02:49:57,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:57,930][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.2705769538879395, acc: 0.1746031790971756)
[2024-11-13 02:49:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:58,207][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.231087684631348, acc: 0.14084507524967194)
[2024-11-13 02:49:58,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:58,748][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.522497653961182, acc: 0.25333333015441895)
[2024-11-13 02:49:58,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:59,110][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.424733638763428, acc: 0.054054055362939835)
[2024-11-13 02:49:59,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 02:49:59,395][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 6.827517986297607, acc: 0.0)
[2024-11-13 04:54:08,195][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 0, 'resume_epoch': 1, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True}
[2024-11-13 04:54:08,197][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': 'NO_SHARD', 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-11-13 04:54:08,197][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-11-13 04:54:08,197][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-11-13_04-54-07.txt', 'log_interval': 5}
[2024-11-13 04:54:33,599][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-11-13 04:54:39,106][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-13 04:54:39,108][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-11-13 04:54:39,110][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-11-13 04:54:39,111][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-11-13 04:54:48,471][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 04:54:48,474][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-11-13 04:54:48,474][slam_llm.models.slam_model][INFO] - setup peft...
[2024-11-13 04:54:48,795][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-11-13 04:54:48,797][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-11-13 04:54:48,916][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-11-13 04:54:48,916][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-11-13 04:54:48,916][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-11-13 04:54:48,921][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-11-13 04:54:51,138][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-11-13 04:54:55,309][root][INFO] - --> Training Set Length = 2298
[2024-11-13 04:54:55,324][root][INFO] - --> Validation Set Length = 341
[2024-11-13 04:54:55,324][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 04:54:55,325][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-11-13 04:54:58,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:01,124][numexpr.utils][INFO] - Note: NumExpr detected 28 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 8.
[2024-11-13 04:55:03,682][root][INFO] - Training Epoch: 1/10, step 0/574 completed (loss: 8.668733596801758, acc: 0.0)
[2024-11-13 04:55:03,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:04,115][root][INFO] - Training Epoch: 1/10, step 1/574 completed (loss: 8.454545021057129, acc: 0.0)
[2024-11-13 04:55:04,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:04,532][root][INFO] - Training Epoch: 1/10, step 2/574 completed (loss: 7.9719133377075195, acc: 0.0)
[2024-11-13 04:55:04,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:04,946][root][INFO] - Training Epoch: 1/10, step 3/574 completed (loss: 8.105181694030762, acc: 0.0)
[2024-11-13 04:55:05,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:05,531][root][INFO] - Training Epoch: 1/10, step 4/574 completed (loss: 6.935710906982422, acc: 0.054054055362939835)
[2024-11-13 04:55:05,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:05,847][root][INFO] - Training Epoch: 1/10, step 5/574 completed (loss: 7.550785064697266, acc: 0.0)
[2024-11-13 04:55:05,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:06,230][root][INFO] - Training Epoch: 1/10, step 6/574 completed (loss: 8.534565925598145, acc: 0.020408162847161293)
[2024-11-13 04:55:06,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:06,616][root][INFO] - Training Epoch: 1/10, step 7/574 completed (loss: 8.191487312316895, acc: 0.0)
[2024-11-13 04:55:06,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:07,046][root][INFO] - Training Epoch: 1/10, step 8/574 completed (loss: 9.745497703552246, acc: 0.0)
[2024-11-13 04:55:07,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:07,414][root][INFO] - Training Epoch: 1/10, step 9/574 completed (loss: 7.625200271606445, acc: 0.0)
[2024-11-13 04:55:07,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:07,863][root][INFO] - Training Epoch: 1/10, step 10/574 completed (loss: 8.46161937713623, acc: 0.0)
[2024-11-13 04:55:08,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:08,235][root][INFO] - Training Epoch: 1/10, step 11/574 completed (loss: 7.068220138549805, acc: 0.0)
[2024-11-13 04:55:08,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:08,581][root][INFO] - Training Epoch: 1/10, step 12/574 completed (loss: 7.878807067871094, acc: 0.0)
[2024-11-13 04:55:08,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:08,952][root][INFO] - Training Epoch: 1/10, step 13/574 completed (loss: 7.0040283203125, acc: 0.021739130839705467)
[2024-11-13 04:55:09,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:09,344][root][INFO] - Training Epoch: 1/10, step 14/574 completed (loss: 7.601143836975098, acc: 0.0)
[2024-11-13 04:55:09,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:09,728][root][INFO] - Training Epoch: 1/10, step 15/574 completed (loss: 6.5243096351623535, acc: 0.08163265138864517)
[2024-11-13 04:55:09,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:10,084][root][INFO] - Training Epoch: 1/10, step 16/574 completed (loss: 9.681644439697266, acc: 0.0)
[2024-11-13 04:55:10,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:10,438][root][INFO] - Training Epoch: 1/10, step 17/574 completed (loss: 8.23445987701416, acc: 0.0)
[2024-11-13 04:55:10,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:10,771][root][INFO] - Training Epoch: 1/10, step 18/574 completed (loss: 6.501181602478027, acc: 0.1388888955116272)
[2024-11-13 04:55:10,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:11,116][root][INFO] - Training Epoch: 1/10, step 19/574 completed (loss: 8.594762802124023, acc: 0.05263157933950424)
[2024-11-13 04:55:11,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:11,492][root][INFO] - Training Epoch: 1/10, step 20/574 completed (loss: 8.121969223022461, acc: 0.03846153989434242)
[2024-11-13 04:55:11,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:11,847][root][INFO] - Training Epoch: 1/10, step 21/574 completed (loss: 7.38892126083374, acc: 0.0)
[2024-11-13 04:55:11,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:12,239][root][INFO] - Training Epoch: 1/10, step 22/574 completed (loss: 7.442540168762207, acc: 0.03999999910593033)
[2024-11-13 04:55:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:12,681][root][INFO] - Training Epoch: 1/10, step 23/574 completed (loss: 8.887929916381836, acc: 0.0476190485060215)
[2024-11-13 04:55:12,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:13,036][root][INFO] - Training Epoch: 1/10, step 24/574 completed (loss: 8.885890007019043, acc: 0.0)
[2024-11-13 04:55:13,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:13,550][root][INFO] - Training Epoch: 1/10, step 25/574 completed (loss: 6.223604202270508, acc: 0.03773584961891174)
[2024-11-13 04:55:13,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:13,988][root][INFO] - Training Epoch: 1/10, step 26/574 completed (loss: 5.78192138671875, acc: 0.08219178020954132)
[2024-11-13 04:55:14,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:15,586][root][INFO] - Training Epoch: 1/10, step 27/574 completed (loss: 4.2111430168151855, acc: 0.25691699981689453)
[2024-11-13 04:55:15,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:16,017][root][INFO] - Training Epoch: 1/10, step 28/574 completed (loss: 6.970348358154297, acc: 0.04651162773370743)
[2024-11-13 04:55:16,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:16,450][root][INFO] - Training Epoch: 1/10, step 29/574 completed (loss: 5.4677958488464355, acc: 0.1204819306731224)
[2024-11-13 04:55:16,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:16,845][root][INFO] - Training Epoch: 1/10, step 30/574 completed (loss: 5.28890323638916, acc: 0.1111111119389534)
[2024-11-13 04:55:16,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:17,261][root][INFO] - Training Epoch: 1/10, step 31/574 completed (loss: 7.611556529998779, acc: 0.0357142873108387)
[2024-11-13 04:55:17,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:17,675][root][INFO] - Training Epoch: 1/10, step 32/574 completed (loss: 7.358923435211182, acc: 0.0)
[2024-11-13 04:55:17,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:18,114][root][INFO] - Training Epoch: 1/10, step 33/574 completed (loss: 7.974462032318115, acc: 0.0)
[2024-11-13 04:55:18,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:18,517][root][INFO] - Training Epoch: 1/10, step 34/574 completed (loss: 5.0530781745910645, acc: 0.15126051008701324)
[2024-11-13 04:55:18,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:18,969][root][INFO] - Training Epoch: 1/10, step 35/574 completed (loss: 5.252770900726318, acc: 0.1803278625011444)
[2024-11-13 04:55:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:19,391][root][INFO] - Training Epoch: 1/10, step 36/574 completed (loss: 5.319570064544678, acc: 0.1587301641702652)
[2024-11-13 04:55:19,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:19,768][root][INFO] - Training Epoch: 1/10, step 37/574 completed (loss: 6.234495639801025, acc: 0.033898305147886276)
[2024-11-13 04:55:19,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:20,221][root][INFO] - Training Epoch: 1/10, step 38/574 completed (loss: 5.164780616760254, acc: 0.2068965584039688)
[2024-11-13 04:55:20,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:20,567][root][INFO] - Training Epoch: 1/10, step 39/574 completed (loss: 8.05106258392334, acc: 0.0)
[2024-11-13 04:55:20,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:20,930][root][INFO] - Training Epoch: 1/10, step 40/574 completed (loss: 6.59037971496582, acc: 0.03846153989434242)
[2024-11-13 04:55:21,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:21,406][root][INFO] - Training Epoch: 1/10, step 41/574 completed (loss: 5.0768513679504395, acc: 0.2567567527294159)
[2024-11-13 04:55:21,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:21,805][root][INFO] - Training Epoch: 1/10, step 42/574 completed (loss: 5.343320369720459, acc: 0.1538461595773697)
[2024-11-13 04:55:21,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:22,310][root][INFO] - Training Epoch: 1/10, step 43/574 completed (loss: 5.416161060333252, acc: 0.17171716690063477)
[2024-11-13 04:55:22,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:22,762][root][INFO] - Training Epoch: 1/10, step 44/574 completed (loss: 4.646631240844727, acc: 0.23711340129375458)
[2024-11-13 04:55:22,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:23,191][root][INFO] - Training Epoch: 1/10, step 45/574 completed (loss: 5.072206497192383, acc: 0.16911764442920685)
[2024-11-13 04:55:23,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:23,531][root][INFO] - Training Epoch: 1/10, step 46/574 completed (loss: 7.702559947967529, acc: 0.0)
[2024-11-13 04:55:23,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:23,872][root][INFO] - Training Epoch: 1/10, step 47/574 completed (loss: 6.617359161376953, acc: 0.0)
[2024-11-13 04:55:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:24,323][root][INFO] - Training Epoch: 1/10, step 48/574 completed (loss: 6.715455055236816, acc: 0.0357142873108387)
[2024-11-13 04:55:24,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:24,698][root][INFO] - Training Epoch: 1/10, step 49/574 completed (loss: 6.026689529418945, acc: 0.02777777798473835)
[2024-11-13 04:55:24,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:25,169][root][INFO] - Training Epoch: 1/10, step 50/574 completed (loss: 5.184969902038574, acc: 0.21052631735801697)
[2024-11-13 04:55:25,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:25,555][root][INFO] - Training Epoch: 1/10, step 51/574 completed (loss: 5.271467685699463, acc: 0.1746031790971756)
[2024-11-13 04:55:25,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:25,898][root][INFO] - Training Epoch: 1/10, step 52/574 completed (loss: 5.230622291564941, acc: 0.14084507524967194)
[2024-11-13 04:55:26,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:26,403][root][INFO] - Training Epoch: 1/10, step 53/574 completed (loss: 4.523012638092041, acc: 0.25333333015441895)
[2024-11-13 04:55:26,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:26,849][root][INFO] - Training Epoch: 1/10, step 54/574 completed (loss: 6.425832271575928, acc: 0.054054055362939835)
[2024-11-13 04:55:26,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:27,189][root][INFO] - Training Epoch: 1/10, step 55/574 completed (loss: 6.828917503356934, acc: 0.0)
[2024-11-13 04:55:28,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:30,496][root][INFO] - Training Epoch: 1/10, step 56/574 completed (loss: 3.0649030208587646, acc: 0.4300341308116913)
[2024-11-13 04:55:31,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:31,941][root][INFO] - Training Epoch: 1/10, step 57/574 completed (loss: 3.646818161010742, acc: 0.29193899035453796)
[2024-11-13 04:55:32,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:32,728][root][INFO] - Training Epoch: 1/10, step 58/574 completed (loss: 3.9419960975646973, acc: 0.27272728085517883)
[2024-11-13 04:55:32,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:33,369][root][INFO] - Training Epoch: 1/10, step 59/574 completed (loss: 4.283234119415283, acc: 0.1764705926179886)
[2024-11-13 04:55:33,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:33,962][root][INFO] - Training Epoch: 1/10, step 60/574 completed (loss: 4.017107963562012, acc: 0.21739129722118378)
[2024-11-13 04:55:34,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:34,439][root][INFO] - Training Epoch: 1/10, step 61/574 completed (loss: 4.2783050537109375, acc: 0.26249998807907104)
[2024-11-13 04:55:34,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:34,781][root][INFO] - Training Epoch: 1/10, step 62/574 completed (loss: 5.4131879806518555, acc: 0.05882352963089943)
[2024-11-13 04:55:34,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:35,072][root][INFO] - Training Epoch: 1/10, step 63/574 completed (loss: 5.593912124633789, acc: 0.1111111119389534)
[2024-11-13 04:55:35,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:35,472][root][INFO] - Training Epoch: 1/10, step 64/574 completed (loss: 3.874513864517212, acc: 0.3125)
[2024-11-13 04:55:35,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:35,836][root][INFO] - Training Epoch: 1/10, step 65/574 completed (loss: 4.978899002075195, acc: 0.17241379618644714)
[2024-11-13 04:55:35,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:36,173][root][INFO] - Training Epoch: 1/10, step 66/574 completed (loss: 4.472108364105225, acc: 0.2142857164144516)
[2024-11-13 04:55:36,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:36,484][root][INFO] - Training Epoch: 1/10, step 67/574 completed (loss: 4.91353702545166, acc: 0.10000000149011612)
[2024-11-13 04:55:36,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:36,877][root][INFO] - Training Epoch: 1/10, step 68/574 completed (loss: 5.915406703948975, acc: 0.07999999821186066)
[2024-11-13 04:55:37,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:37,282][root][INFO] - Training Epoch: 1/10, step 69/574 completed (loss: 5.555822849273682, acc: 0.1111111119389534)
[2024-11-13 04:55:37,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:37,718][root][INFO] - Training Epoch: 1/10, step 70/574 completed (loss: 5.726879596710205, acc: 0.03030303120613098)
[2024-11-13 04:55:37,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:38,136][root][INFO] - Training Epoch: 1/10, step 71/574 completed (loss: 4.0568623542785645, acc: 0.2647058963775635)
[2024-11-13 04:55:38,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:38,588][root][INFO] - Training Epoch: 1/10, step 72/574 completed (loss: 3.7779765129089355, acc: 0.2460317462682724)
[2024-11-13 04:55:38,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:38,973][root][INFO] - Training Epoch: 1/10, step 73/574 completed (loss: 4.088982582092285, acc: 0.23589743673801422)
[2024-11-13 04:55:39,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:39,317][root][INFO] - Training Epoch: 1/10, step 74/574 completed (loss: 4.901524066925049, acc: 0.11224489659070969)
[2024-11-13 04:55:39,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:39,670][root][INFO] - Training Epoch: 1/10, step 75/574 completed (loss: 4.496652126312256, acc: 0.11940298229455948)
[2024-11-13 04:55:39,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:40,103][root][INFO] - Training Epoch: 1/10, step 76/574 completed (loss: 3.7743520736694336, acc: 0.2737226188182831)
[2024-11-13 04:55:40,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:40,438][root][INFO] - Training Epoch: 1/10, step 77/574 completed (loss: 5.973977088928223, acc: 0.0)
[2024-11-13 04:55:40,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:40,777][root][INFO] - Training Epoch: 1/10, step 78/574 completed (loss: 5.431652069091797, acc: 0.0833333358168602)
[2024-11-13 04:55:40,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:41,112][root][INFO] - Training Epoch: 1/10, step 79/574 completed (loss: 4.760403633117676, acc: 0.06060606241226196)
[2024-11-13 04:55:41,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:41,416][root][INFO] - Training Epoch: 1/10, step 80/574 completed (loss: 4.847584247589111, acc: 0.1538461595773697)
[2024-11-13 04:55:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:41,807][root][INFO] - Training Epoch: 1/10, step 81/574 completed (loss: 4.6602630615234375, acc: 0.13461539149284363)
[2024-11-13 04:55:41,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:42,184][root][INFO] - Training Epoch: 1/10, step 82/574 completed (loss: 4.7421135902404785, acc: 0.13461539149284363)
[2024-11-13 04:55:42,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:42,602][root][INFO] - Training Epoch: 1/10, step 83/574 completed (loss: 4.225368499755859, acc: 0.125)
[2024-11-13 04:55:42,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:43,019][root][INFO] - Training Epoch: 1/10, step 84/574 completed (loss: 4.591995716094971, acc: 0.17391304671764374)
[2024-11-13 04:55:43,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:43,432][root][INFO] - Training Epoch: 1/10, step 85/574 completed (loss: 4.322249412536621, acc: 0.14000000059604645)
[2024-11-13 04:55:43,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:43,771][root][INFO] - Training Epoch: 1/10, step 86/574 completed (loss: 5.33396577835083, acc: 0.1304347813129425)
[2024-11-13 04:55:43,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:44,328][root][INFO] - Training Epoch: 1/10, step 87/574 completed (loss: 4.311328887939453, acc: 0.23999999463558197)
[2024-11-13 04:55:44,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:44,710][root][INFO] - Training Epoch: 1/10, step 88/574 completed (loss: 3.6243746280670166, acc: 0.28155338764190674)
[2024-11-13 04:55:45,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:45,950][root][INFO] - Training Epoch: 1/10, step 89/574 completed (loss: 3.5049402713775635, acc: 0.3543689250946045)
[2024-11-13 04:55:46,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:46,838][root][INFO] - Training Epoch: 1/10, step 90/574 completed (loss: 3.704845428466797, acc: 0.25806450843811035)
[2024-11-13 04:55:47,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:47,658][root][INFO] - Training Epoch: 1/10, step 91/574 completed (loss: 3.2694990634918213, acc: 0.3534482717514038)
[2024-11-13 04:55:47,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:48,526][root][INFO] - Training Epoch: 1/10, step 92/574 completed (loss: 3.521510124206543, acc: 0.2947368323802948)
[2024-11-13 04:55:48,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:49,570][root][INFO] - Training Epoch: 1/10, step 93/574 completed (loss: 3.63423228263855, acc: 0.21782177686691284)
[2024-11-13 04:55:49,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:49,941][root][INFO] - Training Epoch: 1/10, step 94/574 completed (loss: 3.7183432579040527, acc: 0.20967741310596466)
[2024-11-13 04:55:50,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:50,314][root][INFO] - Training Epoch: 1/10, step 95/574 completed (loss: 3.9854178428649902, acc: 0.23188406229019165)
[2024-11-13 04:55:50,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:50,709][root][INFO] - Training Epoch: 1/10, step 96/574 completed (loss: 4.081142425537109, acc: 0.15126051008701324)
[2024-11-13 04:55:50,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:51,151][root][INFO] - Training Epoch: 1/10, step 97/574 completed (loss: 3.8785042762756348, acc: 0.18269230425357819)
[2024-11-13 04:55:51,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:51,573][root][INFO] - Training Epoch: 1/10, step 98/574 completed (loss: 3.818186044692993, acc: 0.22627736628055573)
[2024-11-13 04:55:51,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:51,998][root][INFO] - Training Epoch: 1/10, step 99/574 completed (loss: 4.4317097663879395, acc: 0.16417910158634186)
[2024-11-13 04:55:52,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:52,361][root][INFO] - Training Epoch: 1/10, step 100/574 completed (loss: 4.7756571769714355, acc: 0.10000000149011612)
[2024-11-13 04:55:52,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:52,716][root][INFO] - Training Epoch: 1/10, step 101/574 completed (loss: 3.82045578956604, acc: 0.22727273404598236)
[2024-11-13 04:55:52,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:53,039][root][INFO] - Training Epoch: 1/10, step 102/574 completed (loss: 3.3205580711364746, acc: 0.17391304671764374)
[2024-11-13 04:55:53,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:53,433][root][INFO] - Training Epoch: 1/10, step 103/574 completed (loss: 3.4278151988983154, acc: 0.25)
[2024-11-13 04:55:53,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:53,872][root][INFO] - Training Epoch: 1/10, step 104/574 completed (loss: 3.949591636657715, acc: 0.17241379618644714)
[2024-11-13 04:55:53,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:54,231][root][INFO] - Training Epoch: 1/10, step 105/574 completed (loss: 3.692065477371216, acc: 0.1860465109348297)
[2024-11-13 04:55:54,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:54,610][root][INFO] - Training Epoch: 1/10, step 106/574 completed (loss: 3.4342401027679443, acc: 0.23999999463558197)
[2024-11-13 04:55:54,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:54,959][root][INFO] - Training Epoch: 1/10, step 107/574 completed (loss: 3.809183120727539, acc: 0.1764705926179886)
[2024-11-13 04:55:55,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:55,276][root][INFO] - Training Epoch: 1/10, step 108/574 completed (loss: 3.7347772121429443, acc: 0.19230769574642181)
[2024-11-13 04:55:55,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:55,555][root][INFO] - Training Epoch: 1/10, step 109/574 completed (loss: 3.755067825317383, acc: 0.2142857164144516)
[2024-11-13 04:55:55,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:56,013][root][INFO] - Training Epoch: 1/10, step 110/574 completed (loss: 3.9389493465423584, acc: 0.2153846174478531)
[2024-11-13 04:55:56,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:56,488][root][INFO] - Training Epoch: 1/10, step 111/574 completed (loss: 3.584625244140625, acc: 0.19298245012760162)
[2024-11-13 04:55:56,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:56,926][root][INFO] - Training Epoch: 1/10, step 112/574 completed (loss: 3.395939350128174, acc: 0.2631579041481018)
[2024-11-13 04:55:57,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:57,367][root][INFO] - Training Epoch: 1/10, step 113/574 completed (loss: 3.801130533218384, acc: 0.28205129504203796)
[2024-11-13 04:55:57,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:57,769][root][INFO] - Training Epoch: 1/10, step 114/574 completed (loss: 3.3905794620513916, acc: 0.30612245202064514)
[2024-11-13 04:55:57,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:58,132][root][INFO] - Training Epoch: 1/10, step 115/574 completed (loss: 3.503054618835449, acc: 0.1818181872367859)
[2024-11-13 04:55:58,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:58,499][root][INFO] - Training Epoch: 1/10, step 116/574 completed (loss: 3.131588935852051, acc: 0.2698412835597992)
[2024-11-13 04:55:58,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:58,848][root][INFO] - Training Epoch: 1/10, step 117/574 completed (loss: 3.2616305351257324, acc: 0.26829269528388977)
[2024-11-13 04:55:58,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:55:59,197][root][INFO] - Training Epoch: 1/10, step 118/574 completed (loss: 3.232473373413086, acc: 0.4193548262119293)
[2024-11-13 04:55:59,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:00,140][root][INFO] - Training Epoch: 1/10, step 119/574 completed (loss: 3.0716230869293213, acc: 0.33840304613113403)
[2024-11-13 04:56:00,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:00,471][root][INFO] - Training Epoch: 1/10, step 120/574 completed (loss: 3.1214523315429688, acc: 0.3199999928474426)
[2024-11-13 04:56:00,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:00,882][root][INFO] - Training Epoch: 1/10, step 121/574 completed (loss: 3.372087240219116, acc: 0.3076923191547394)
[2024-11-13 04:56:00,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:01,134][root][INFO] - Training Epoch: 1/10, step 122/574 completed (loss: 3.7611687183380127, acc: 0.2083333283662796)
[2024-11-13 04:56:01,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:01,478][root][INFO] - Training Epoch: 1/10, step 123/574 completed (loss: 2.9438836574554443, acc: 0.3684210479259491)
[2024-11-13 04:56:01,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:01,852][root][INFO] - Training Epoch: 1/10, step 124/574 completed (loss: 3.356484889984131, acc: 0.21472392976284027)
[2024-11-13 04:56:01,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:02,218][root][INFO] - Training Epoch: 1/10, step 125/574 completed (loss: 2.6218061447143555, acc: 0.4166666567325592)
[2024-11-13 04:56:02,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:02,624][root][INFO] - Training Epoch: 1/10, step 126/574 completed (loss: 3.0444552898406982, acc: 0.23333333432674408)
[2024-11-13 04:56:02,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:03,064][root][INFO] - Training Epoch: 1/10, step 127/574 completed (loss: 3.0457348823547363, acc: 0.25)
[2024-11-13 04:56:03,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:03,493][root][INFO] - Training Epoch: 1/10, step 128/574 completed (loss: 3.246462821960449, acc: 0.2974359095096588)
[2024-11-13 04:56:03,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:03,927][root][INFO] - Training Epoch: 1/10, step 129/574 completed (loss: 2.6547441482543945, acc: 0.375)
[2024-11-13 04:56:04,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:04,258][root][INFO] - Training Epoch: 1/10, step 130/574 completed (loss: 3.5704309940338135, acc: 0.19230769574642181)
[2024-11-13 04:56:04,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:04,593][root][INFO] - Training Epoch: 1/10, step 131/574 completed (loss: 2.783121109008789, acc: 0.3478260934352875)
[2024-11-13 04:56:04,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:04,976][root][INFO] - Training Epoch: 1/10, step 132/574 completed (loss: 3.605687141418457, acc: 0.21875)
[2024-11-13 04:56:05,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:05,349][root][INFO] - Training Epoch: 1/10, step 133/574 completed (loss: 2.742973804473877, acc: 0.3478260934352875)
[2024-11-13 04:56:05,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:05,741][root][INFO] - Training Epoch: 1/10, step 134/574 completed (loss: 2.8567206859588623, acc: 0.22857142984867096)
[2024-11-13 04:56:05,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:06,014][root][INFO] - Training Epoch: 1/10, step 135/574 completed (loss: 2.8415400981903076, acc: 0.26923078298568726)
[2024-11-13 04:56:06,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:06,315][root][INFO] - Training Epoch: 1/10, step 136/574 completed (loss: 3.410074234008789, acc: 0.190476194024086)
[2024-11-13 04:56:06,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:06,637][root][INFO] - Training Epoch: 1/10, step 137/574 completed (loss: 2.4292080402374268, acc: 0.4333333373069763)
[2024-11-13 04:56:06,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:06,970][root][INFO] - Training Epoch: 1/10, step 138/574 completed (loss: 2.5506811141967773, acc: 0.3913043439388275)
[2024-11-13 04:56:07,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:07,327][root][INFO] - Training Epoch: 1/10, step 139/574 completed (loss: 3.75177264213562, acc: 0.2857142984867096)
[2024-11-13 04:56:07,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:07,641][root][INFO] - Training Epoch: 1/10, step 140/574 completed (loss: 3.2332651615142822, acc: 0.38461539149284363)
[2024-11-13 04:56:07,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:07,955][root][INFO] - Training Epoch: 1/10, step 141/574 completed (loss: 3.4766178131103516, acc: 0.16129031777381897)
[2024-11-13 04:56:08,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:08,281][root][INFO] - Training Epoch: 1/10, step 142/574 completed (loss: 3.0426409244537354, acc: 0.2432432472705841)
[2024-11-13 04:56:09,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:09,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:10,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:10,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:10,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:11,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:11,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:12,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:12,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:13,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:13,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:14,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:14,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:15,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:15,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:15,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:16,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:16,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:17,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:17,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:18,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:18,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:18,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:19,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:19,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:20,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:20,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:20,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:21,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:21,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:22,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:22,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:22,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:23,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:23,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:23,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:24,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:24,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:25,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:25,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:25,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:26,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:26,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:27,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:27,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:27,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:28,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:28,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:29,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:29,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:29,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:30,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:30,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:30,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:31,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:31,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:32,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:32,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:33,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:33,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:33,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:34,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:34,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:35,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:35,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:36,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:36,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:36,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:37,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:37,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:37,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:38,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:38,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:39,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:39,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:39,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:40,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:40,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:40,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:41,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:42,539][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(20.0574, device='cuda:0') eval_epoch_loss=tensor(2.9986, device='cuda:0') eval_epoch_acc=tensor(0.2864, device='cuda:0')
[2024-11-13 04:56:42,541][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 04:56:42,541][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 04:56:42,984][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_143_loss_2.9985973834991455/model.pt
[2024-11-13 04:56:42,988][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 04:56:42,989][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.9985973834991455
[2024-11-13 04:56:42,989][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.28641706705093384
[2024-11-13 04:56:43,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:43,597][root][INFO] - Training Epoch: 1/10, step 143/574 completed (loss: 2.5181915760040283, acc: 0.42105263471603394)
[2024-11-13 04:56:43,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:43,994][root][INFO] - Training Epoch: 1/10, step 144/574 completed (loss: 2.4339568614959717, acc: 0.44029849767684937)
[2024-11-13 04:56:44,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:44,364][root][INFO] - Training Epoch: 1/10, step 145/574 completed (loss: 2.8820812702178955, acc: 0.27551019191741943)
[2024-11-13 04:56:44,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:44,936][root][INFO] - Training Epoch: 1/10, step 146/574 completed (loss: 2.678459644317627, acc: 0.3191489279270172)
[2024-11-13 04:56:45,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:45,288][root][INFO] - Training Epoch: 1/10, step 147/574 completed (loss: 2.6029467582702637, acc: 0.4000000059604645)
[2024-11-13 04:56:45,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:45,712][root][INFO] - Training Epoch: 1/10, step 148/574 completed (loss: 3.3754405975341797, acc: 0.1785714328289032)
[2024-11-13 04:56:45,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:46,080][root][INFO] - Training Epoch: 1/10, step 149/574 completed (loss: 2.5528812408447266, acc: 0.3913043439388275)
[2024-11-13 04:56:46,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:46,468][root][INFO] - Training Epoch: 1/10, step 150/574 completed (loss: 3.1211893558502197, acc: 0.24137930572032928)
[2024-11-13 04:56:46,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:46,850][root][INFO] - Training Epoch: 1/10, step 151/574 completed (loss: 2.825049638748169, acc: 0.32608696818351746)
[2024-11-13 04:56:46,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:47,145][root][INFO] - Training Epoch: 1/10, step 152/574 completed (loss: 2.507251739501953, acc: 0.33898305892944336)
[2024-11-13 04:56:47,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:47,573][root][INFO] - Training Epoch: 1/10, step 153/574 completed (loss: 3.1671738624572754, acc: 0.2631579041481018)
[2024-11-13 04:56:47,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:48,003][root][INFO] - Training Epoch: 1/10, step 154/574 completed (loss: 2.874358654022217, acc: 0.3378378450870514)
[2024-11-13 04:56:48,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:48,347][root][INFO] - Training Epoch: 1/10, step 155/574 completed (loss: 2.6206953525543213, acc: 0.4285714328289032)
[2024-11-13 04:56:48,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:48,641][root][INFO] - Training Epoch: 1/10, step 156/574 completed (loss: 2.2476985454559326, acc: 0.3913043439388275)
[2024-11-13 04:56:48,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:48,963][root][INFO] - Training Epoch: 1/10, step 157/574 completed (loss: 2.6296706199645996, acc: 0.31578946113586426)
[2024-11-13 04:56:49,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:50,702][root][INFO] - Training Epoch: 1/10, step 158/574 completed (loss: 3.002927541732788, acc: 0.3513513505458832)
[2024-11-13 04:56:50,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:51,120][root][INFO] - Training Epoch: 1/10, step 159/574 completed (loss: 3.0606017112731934, acc: 0.31481480598449707)
[2024-11-13 04:56:51,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:51,590][root][INFO] - Training Epoch: 1/10, step 160/574 completed (loss: 3.0262749195098877, acc: 0.3372093141078949)
[2024-11-13 04:56:51,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:52,206][root][INFO] - Training Epoch: 1/10, step 161/574 completed (loss: 2.6206607818603516, acc: 0.38823530077934265)
[2024-11-13 04:56:52,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:52,761][root][INFO] - Training Epoch: 1/10, step 162/574 completed (loss: 2.9792160987854004, acc: 0.30337077379226685)
[2024-11-13 04:56:52,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:53,087][root][INFO] - Training Epoch: 1/10, step 163/574 completed (loss: 2.657504081726074, acc: 0.3636363744735718)
[2024-11-13 04:56:53,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:53,418][root][INFO] - Training Epoch: 1/10, step 164/574 completed (loss: 2.8574724197387695, acc: 0.2857142984867096)
[2024-11-13 04:56:53,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:53,733][root][INFO] - Training Epoch: 1/10, step 165/574 completed (loss: 3.1864123344421387, acc: 0.2068965584039688)
[2024-11-13 04:56:53,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:54,064][root][INFO] - Training Epoch: 1/10, step 166/574 completed (loss: 1.9527095556259155, acc: 0.5102040767669678)
[2024-11-13 04:56:54,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:54,371][root][INFO] - Training Epoch: 1/10, step 167/574 completed (loss: 2.401609182357788, acc: 0.3400000035762787)
[2024-11-13 04:56:54,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:54,813][root][INFO] - Training Epoch: 1/10, step 168/574 completed (loss: 2.4264814853668213, acc: 0.375)
[2024-11-13 04:56:54,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:55,132][root][INFO] - Training Epoch: 1/10, step 169/574 completed (loss: 2.541316509246826, acc: 0.343137264251709)
[2024-11-13 04:56:55,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:56,215][root][INFO] - Training Epoch: 1/10, step 170/574 completed (loss: 3.022820472717285, acc: 0.3493150770664215)
[2024-11-13 04:56:56,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:56,506][root][INFO] - Training Epoch: 1/10, step 171/574 completed (loss: 2.2605068683624268, acc: 0.4166666567325592)
[2024-11-13 04:56:56,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:56,774][root][INFO] - Training Epoch: 1/10, step 172/574 completed (loss: 2.996171712875366, acc: 0.25925925374031067)
[2024-11-13 04:56:56,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:57,050][root][INFO] - Training Epoch: 1/10, step 173/574 completed (loss: 2.659970760345459, acc: 0.3214285671710968)
[2024-11-13 04:56:57,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:57,694][root][INFO] - Training Epoch: 1/10, step 174/574 completed (loss: 2.2482426166534424, acc: 0.4690265357494354)
[2024-11-13 04:56:57,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:57,977][root][INFO] - Training Epoch: 1/10, step 175/574 completed (loss: 2.6850428581237793, acc: 0.28985506296157837)
[2024-11-13 04:56:58,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:58,358][root][INFO] - Training Epoch: 1/10, step 176/574 completed (loss: 2.870027780532837, acc: 0.27272728085517883)
[2024-11-13 04:56:58,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:56:59,340][root][INFO] - Training Epoch: 1/10, step 177/574 completed (loss: 2.8829987049102783, acc: 0.3358778655529022)
[2024-11-13 04:56:59,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:00,023][root][INFO] - Training Epoch: 1/10, step 178/574 completed (loss: 2.956526041030884, acc: 0.22962963581085205)
[2024-11-13 04:57:00,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:00,348][root][INFO] - Training Epoch: 1/10, step 179/574 completed (loss: 2.677372455596924, acc: 0.2950819730758667)
[2024-11-13 04:57:00,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:00,703][root][INFO] - Training Epoch: 1/10, step 180/574 completed (loss: 2.3146049976348877, acc: 0.2916666567325592)
[2024-11-13 04:57:00,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:01,058][root][INFO] - Training Epoch: 1/10, step 181/574 completed (loss: 2.4371652603149414, acc: 0.4000000059604645)
[2024-11-13 04:57:01,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:01,429][root][INFO] - Training Epoch: 1/10, step 182/574 completed (loss: 2.887709379196167, acc: 0.3214285671710968)
[2024-11-13 04:57:01,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:01,814][root][INFO] - Training Epoch: 1/10, step 183/574 completed (loss: 2.914120674133301, acc: 0.25609755516052246)
[2024-11-13 04:57:01,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:02,166][root][INFO] - Training Epoch: 1/10, step 184/574 completed (loss: 2.9161441326141357, acc: 0.29909366369247437)
[2024-11-13 04:57:02,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:02,500][root][INFO] - Training Epoch: 1/10, step 185/574 completed (loss: 2.923354387283325, acc: 0.24495677649974823)
[2024-11-13 04:57:02,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:02,988][root][INFO] - Training Epoch: 1/10, step 186/574 completed (loss: 3.0109338760375977, acc: 0.2718749940395355)
[2024-11-13 04:57:03,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:03,560][root][INFO] - Training Epoch: 1/10, step 187/574 completed (loss: 2.6936681270599365, acc: 0.3058161437511444)
[2024-11-13 04:57:03,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:03,983][root][INFO] - Training Epoch: 1/10, step 188/574 completed (loss: 2.684065341949463, acc: 0.33451956510543823)
[2024-11-13 04:57:04,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:04,306][root][INFO] - Training Epoch: 1/10, step 189/574 completed (loss: 3.330186128616333, acc: 0.2800000011920929)
[2024-11-13 04:57:04,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:04,904][root][INFO] - Training Epoch: 1/10, step 190/574 completed (loss: 2.70878005027771, acc: 0.3488371968269348)
[2024-11-13 04:57:05,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:05,760][root][INFO] - Training Epoch: 1/10, step 191/574 completed (loss: 2.6454901695251465, acc: 0.3650793731212616)
[2024-11-13 04:57:06,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:06,739][root][INFO] - Training Epoch: 1/10, step 192/574 completed (loss: 2.5421905517578125, acc: 0.3712121248245239)
[2024-11-13 04:57:06,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:07,521][root][INFO] - Training Epoch: 1/10, step 193/574 completed (loss: 2.200962543487549, acc: 0.4588235318660736)
[2024-11-13 04:57:07,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:08,676][root][INFO] - Training Epoch: 1/10, step 194/574 completed (loss: 2.2755415439605713, acc: 0.43209877610206604)
[2024-11-13 04:57:08,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:09,673][root][INFO] - Training Epoch: 1/10, step 195/574 completed (loss: 2.3285133838653564, acc: 0.35483869910240173)
[2024-11-13 04:57:09,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:10,003][root][INFO] - Training Epoch: 1/10, step 196/574 completed (loss: 2.368015766143799, acc: 0.3928571343421936)
[2024-11-13 04:57:10,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:10,315][root][INFO] - Training Epoch: 1/10, step 197/574 completed (loss: 2.9563450813293457, acc: 0.25)
[2024-11-13 04:57:10,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:10,699][root][INFO] - Training Epoch: 1/10, step 198/574 completed (loss: 3.0613536834716797, acc: 0.2647058963775635)
[2024-11-13 04:57:10,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:11,067][root][INFO] - Training Epoch: 1/10, step 199/574 completed (loss: 2.5577592849731445, acc: 0.36764705181121826)
[2024-11-13 04:57:11,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:11,446][root][INFO] - Training Epoch: 1/10, step 200/574 completed (loss: 2.760091781616211, acc: 0.31355932354927063)
[2024-11-13 04:57:11,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:11,824][root][INFO] - Training Epoch: 1/10, step 201/574 completed (loss: 2.710282564163208, acc: 0.36567163467407227)
[2024-11-13 04:57:11,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:12,260][root][INFO] - Training Epoch: 1/10, step 202/574 completed (loss: 2.9206161499023438, acc: 0.28155338764190674)
[2024-11-13 04:57:12,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:12,621][root][INFO] - Training Epoch: 1/10, step 203/574 completed (loss: 2.663421154022217, acc: 0.380952388048172)
[2024-11-13 04:57:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:12,985][root][INFO] - Training Epoch: 1/10, step 204/574 completed (loss: 2.599959135055542, acc: 0.34065935015678406)
[2024-11-13 04:57:13,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:13,348][root][INFO] - Training Epoch: 1/10, step 205/574 completed (loss: 2.7341864109039307, acc: 0.3094170391559601)
[2024-11-13 04:57:13,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:13,766][root][INFO] - Training Epoch: 1/10, step 206/574 completed (loss: 2.550387144088745, acc: 0.3818897604942322)
[2024-11-13 04:57:13,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:14,119][root][INFO] - Training Epoch: 1/10, step 207/574 completed (loss: 2.656972646713257, acc: 0.3405172526836395)
[2024-11-13 04:57:14,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:14,543][root][INFO] - Training Epoch: 1/10, step 208/574 completed (loss: 2.4224929809570312, acc: 0.4202898442745209)
[2024-11-13 04:57:14,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:15,021][root][INFO] - Training Epoch: 1/10, step 209/574 completed (loss: 2.7086029052734375, acc: 0.30739298462867737)
[2024-11-13 04:57:15,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:15,376][root][INFO] - Training Epoch: 1/10, step 210/574 completed (loss: 2.8425960540771484, acc: 0.25)
[2024-11-13 04:57:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:15,728][root][INFO] - Training Epoch: 1/10, step 211/574 completed (loss: 2.8178391456604004, acc: 0.3913043439388275)
[2024-11-13 04:57:15,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:16,091][root][INFO] - Training Epoch: 1/10, step 212/574 completed (loss: 2.8349571228027344, acc: 0.25)
[2024-11-13 04:57:16,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:16,487][root][INFO] - Training Epoch: 1/10, step 213/574 completed (loss: 2.407480239868164, acc: 0.3617021143436432)
[2024-11-13 04:57:16,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:17,245][root][INFO] - Training Epoch: 1/10, step 214/574 completed (loss: 2.5326244831085205, acc: 0.33076924085617065)
[2024-11-13 04:57:17,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:17,603][root][INFO] - Training Epoch: 1/10, step 215/574 completed (loss: 2.4014625549316406, acc: 0.3243243098258972)
[2024-11-13 04:57:17,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:17,947][root][INFO] - Training Epoch: 1/10, step 216/574 completed (loss: 2.5912187099456787, acc: 0.3488371968269348)
[2024-11-13 04:57:18,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:18,512][root][INFO] - Training Epoch: 1/10, step 217/574 completed (loss: 2.4214212894439697, acc: 0.36936935782432556)
[2024-11-13 04:57:18,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:18,982][root][INFO] - Training Epoch: 1/10, step 218/574 completed (loss: 2.4359192848205566, acc: 0.35555556416511536)
[2024-11-13 04:57:19,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:19,313][root][INFO] - Training Epoch: 1/10, step 219/574 completed (loss: 2.0936083793640137, acc: 0.39393940567970276)
[2024-11-13 04:57:19,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:19,652][root][INFO] - Training Epoch: 1/10, step 220/574 completed (loss: 1.9625228643417358, acc: 0.48148149251937866)
[2024-11-13 04:57:19,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:20,044][root][INFO] - Training Epoch: 1/10, step 221/574 completed (loss: 1.9826158285140991, acc: 0.4000000059604645)
[2024-11-13 04:57:20,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:20,460][root][INFO] - Training Epoch: 1/10, step 222/574 completed (loss: 2.5146098136901855, acc: 0.3461538553237915)
[2024-11-13 04:57:20,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:21,268][root][INFO] - Training Epoch: 1/10, step 223/574 completed (loss: 2.2745254039764404, acc: 0.40760868787765503)
[2024-11-13 04:57:21,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:21,826][root][INFO] - Training Epoch: 1/10, step 224/574 completed (loss: 2.5526037216186523, acc: 0.34090909361839294)
[2024-11-13 04:57:21,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:22,300][root][INFO] - Training Epoch: 1/10, step 225/574 completed (loss: 2.6451127529144287, acc: 0.28723403811454773)
[2024-11-13 04:57:22,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:22,664][root][INFO] - Training Epoch: 1/10, step 226/574 completed (loss: 2.7678005695343018, acc: 0.30188679695129395)
[2024-11-13 04:57:22,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:23,009][root][INFO] - Training Epoch: 1/10, step 227/574 completed (loss: 2.3894269466400146, acc: 0.4333333373069763)
[2024-11-13 04:57:23,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:23,376][root][INFO] - Training Epoch: 1/10, step 228/574 completed (loss: 2.0083532333374023, acc: 0.39534884691238403)
[2024-11-13 04:57:23,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:23,757][root][INFO] - Training Epoch: 1/10, step 229/574 completed (loss: 2.245814323425293, acc: 0.4333333373069763)
[2024-11-13 04:57:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:24,194][root][INFO] - Training Epoch: 1/10, step 230/574 completed (loss: 2.9123544692993164, acc: 0.2526315748691559)
[2024-11-13 04:57:24,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:24,530][root][INFO] - Training Epoch: 1/10, step 231/574 completed (loss: 2.3780767917633057, acc: 0.3888888955116272)
[2024-11-13 04:57:24,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:24,993][root][INFO] - Training Epoch: 1/10, step 232/574 completed (loss: 2.121957540512085, acc: 0.4611110985279083)
[2024-11-13 04:57:25,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:25,504][root][INFO] - Training Epoch: 1/10, step 233/574 completed (loss: 2.1888375282287598, acc: 0.4587155878543854)
[2024-11-13 04:57:25,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:25,993][root][INFO] - Training Epoch: 1/10, step 234/574 completed (loss: 2.1629018783569336, acc: 0.4076923131942749)
[2024-11-13 04:57:26,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:26,370][root][INFO] - Training Epoch: 1/10, step 235/574 completed (loss: 2.168274402618408, acc: 0.3684210479259491)
[2024-11-13 04:57:26,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:26,797][root][INFO] - Training Epoch: 1/10, step 236/574 completed (loss: 2.037966251373291, acc: 0.375)
[2024-11-13 04:57:26,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:27,211][root][INFO] - Training Epoch: 1/10, step 237/574 completed (loss: 2.6267688274383545, acc: 0.22727273404598236)
[2024-11-13 04:57:27,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:27,574][root][INFO] - Training Epoch: 1/10, step 238/574 completed (loss: 1.913293719291687, acc: 0.40740740299224854)
[2024-11-13 04:57:27,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:27,946][root][INFO] - Training Epoch: 1/10, step 239/574 completed (loss: 2.1251800060272217, acc: 0.48571428656578064)
[2024-11-13 04:57:28,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:28,389][root][INFO] - Training Epoch: 1/10, step 240/574 completed (loss: 1.9893791675567627, acc: 0.40909090638160706)
[2024-11-13 04:57:28,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:28,788][root][INFO] - Training Epoch: 1/10, step 241/574 completed (loss: 2.206275224685669, acc: 0.40909090638160706)
[2024-11-13 04:57:28,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:29,433][root][INFO] - Training Epoch: 1/10, step 242/574 completed (loss: 2.3585050106048584, acc: 0.35483869910240173)
[2024-11-13 04:57:29,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:30,031][root][INFO] - Training Epoch: 1/10, step 243/574 completed (loss: 2.1787397861480713, acc: 0.40909090638160706)
[2024-11-13 04:57:30,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:30,423][root][INFO] - Training Epoch: 1/10, step 244/574 completed (loss: 2.019186019897461, acc: 0.4285714328289032)
[2024-11-13 04:57:30,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:30,872][root][INFO] - Training Epoch: 1/10, step 245/574 completed (loss: 2.4514272212982178, acc: 0.3076923191547394)
[2024-11-13 04:57:30,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:31,225][root][INFO] - Training Epoch: 1/10, step 246/574 completed (loss: 2.852586269378662, acc: 0.25806450843811035)
[2024-11-13 04:57:31,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:31,561][root][INFO] - Training Epoch: 1/10, step 247/574 completed (loss: 1.9316736459732056, acc: 0.3499999940395355)
[2024-11-13 04:57:31,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:31,956][root][INFO] - Training Epoch: 1/10, step 248/574 completed (loss: 2.544297218322754, acc: 0.4324324429035187)
[2024-11-13 04:57:32,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:32,230][root][INFO] - Training Epoch: 1/10, step 249/574 completed (loss: 2.3199942111968994, acc: 0.29729729890823364)
[2024-11-13 04:57:32,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:32,552][root][INFO] - Training Epoch: 1/10, step 250/574 completed (loss: 2.5441911220550537, acc: 0.29729729890823364)
[2024-11-13 04:57:32,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:32,942][root][INFO] - Training Epoch: 1/10, step 251/574 completed (loss: 2.562962293624878, acc: 0.3529411852359772)
[2024-11-13 04:57:33,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:33,378][root][INFO] - Training Epoch: 1/10, step 252/574 completed (loss: 1.6449854373931885, acc: 0.5609756112098694)
[2024-11-13 04:57:33,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:33,721][root][INFO] - Training Epoch: 1/10, step 253/574 completed (loss: 1.6929491758346558, acc: 0.5600000023841858)
[2024-11-13 04:57:33,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:34,137][root][INFO] - Training Epoch: 1/10, step 254/574 completed (loss: 1.4555976390838623, acc: 0.6000000238418579)
[2024-11-13 04:57:34,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:34,539][root][INFO] - Training Epoch: 1/10, step 255/574 completed (loss: 2.3140902519226074, acc: 0.32258063554763794)
[2024-11-13 04:57:34,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:34,946][root][INFO] - Training Epoch: 1/10, step 256/574 completed (loss: 2.5962328910827637, acc: 0.31578946113586426)
[2024-11-13 04:57:35,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:35,302][root][INFO] - Training Epoch: 1/10, step 257/574 completed (loss: 2.6123430728912354, acc: 0.30000001192092896)
[2024-11-13 04:57:35,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:35,657][root][INFO] - Training Epoch: 1/10, step 258/574 completed (loss: 2.2934651374816895, acc: 0.3684210479259491)
[2024-11-13 04:57:35,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:36,242][root][INFO] - Training Epoch: 1/10, step 259/574 completed (loss: 2.335991382598877, acc: 0.3962264060974121)
[2024-11-13 04:57:36,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:36,842][root][INFO] - Training Epoch: 1/10, step 260/574 completed (loss: 2.374976396560669, acc: 0.375)
[2024-11-13 04:57:36,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:37,163][root][INFO] - Training Epoch: 1/10, step 261/574 completed (loss: 2.1574363708496094, acc: 0.4166666567325592)
[2024-11-13 04:57:37,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:37,528][root][INFO] - Training Epoch: 1/10, step 262/574 completed (loss: 2.3842432498931885, acc: 0.4516128897666931)
[2024-11-13 04:57:37,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:37,904][root][INFO] - Training Epoch: 1/10, step 263/574 completed (loss: 2.704496145248413, acc: 0.3466666638851166)
[2024-11-13 04:57:38,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:38,237][root][INFO] - Training Epoch: 1/10, step 264/574 completed (loss: 2.513204336166382, acc: 0.375)
[2024-11-13 04:57:38,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:39,183][root][INFO] - Training Epoch: 1/10, step 265/574 completed (loss: 2.8037078380584717, acc: 0.29600000381469727)
[2024-11-13 04:57:39,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:39,548][root][INFO] - Training Epoch: 1/10, step 266/574 completed (loss: 2.376905918121338, acc: 0.449438214302063)
[2024-11-13 04:57:39,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:39,930][root][INFO] - Training Epoch: 1/10, step 267/574 completed (loss: 2.6195242404937744, acc: 0.3378378450870514)
[2024-11-13 04:57:40,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:40,399][root][INFO] - Training Epoch: 1/10, step 268/574 completed (loss: 2.0213136672973633, acc: 0.48275861144065857)
[2024-11-13 04:57:40,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:40,722][root][INFO] - Training Epoch: 1/10, step 269/574 completed (loss: 2.2576489448547363, acc: 0.40909090638160706)
[2024-11-13 04:57:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:41,053][root][INFO] - Training Epoch: 1/10, step 270/574 completed (loss: 1.7892016172409058, acc: 0.5)
[2024-11-13 04:57:41,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:41,393][root][INFO] - Training Epoch: 1/10, step 271/574 completed (loss: 1.7382903099060059, acc: 0.5625)
[2024-11-13 04:57:41,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:41,719][root][INFO] - Training Epoch: 1/10, step 272/574 completed (loss: 2.052194833755493, acc: 0.46666666865348816)
[2024-11-13 04:57:41,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:42,154][root][INFO] - Training Epoch: 1/10, step 273/574 completed (loss: 2.508450984954834, acc: 0.38333332538604736)
[2024-11-13 04:57:42,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:42,521][root][INFO] - Training Epoch: 1/10, step 274/574 completed (loss: 2.128666639328003, acc: 0.4375)
[2024-11-13 04:57:42,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:42,836][root][INFO] - Training Epoch: 1/10, step 275/574 completed (loss: 1.6403374671936035, acc: 0.5333333611488342)
[2024-11-13 04:57:42,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:43,120][root][INFO] - Training Epoch: 1/10, step 276/574 completed (loss: 2.01930832862854, acc: 0.4482758641242981)
[2024-11-13 04:57:43,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:43,382][root][INFO] - Training Epoch: 1/10, step 277/574 completed (loss: 1.9484378099441528, acc: 0.4000000059604645)
[2024-11-13 04:57:43,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:43,643][root][INFO] - Training Epoch: 1/10, step 278/574 completed (loss: 2.5558042526245117, acc: 0.3191489279270172)
[2024-11-13 04:57:43,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:43,915][root][INFO] - Training Epoch: 1/10, step 279/574 completed (loss: 2.2756757736206055, acc: 0.375)
[2024-11-13 04:57:44,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:44,231][root][INFO] - Training Epoch: 1/10, step 280/574 completed (loss: 2.022073984146118, acc: 0.40909090638160706)
[2024-11-13 04:57:44,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:44,675][root][INFO] - Training Epoch: 1/10, step 281/574 completed (loss: 2.5965540409088135, acc: 0.3614457845687866)
[2024-11-13 04:57:44,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:45,013][root][INFO] - Training Epoch: 1/10, step 282/574 completed (loss: 2.4906442165374756, acc: 0.34259259700775146)
[2024-11-13 04:57:45,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:45,245][root][INFO] - Training Epoch: 1/10, step 283/574 completed (loss: 2.528071165084839, acc: 0.21052631735801697)
[2024-11-13 04:57:45,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:45,602][root][INFO] - Training Epoch: 1/10, step 284/574 completed (loss: 2.520540952682495, acc: 0.1764705926179886)
[2024-11-13 04:57:45,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:45,933][root][INFO] - Training Epoch: 1/10, step 285/574 completed (loss: 2.371626377105713, acc: 0.30000001192092896)
[2024-11-13 04:57:46,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:46,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:47,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:47,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:47,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:48,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:48,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:48,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:49,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:49,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:49,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:50,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:50,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:51,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:51,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:52,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:52,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:52,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:53,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:53,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:54,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:54,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:54,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:55,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:55,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:55,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:56,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:56,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:56,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:57,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:57,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:57,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:58,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:58,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:59,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:59,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:59,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:57:59,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:00,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:00,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:01,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:01,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:01,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:02,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:02,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:02,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:03,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:03,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:03,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:04,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:04,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:04,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:05,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:05,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:06,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:06,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:06,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:07,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:07,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:08,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:08,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:08,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:09,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:09,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:10,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:10,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:10,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:11,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:11,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:11,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:12,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:12,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:12,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:13,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:13,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:13,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:14,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:14,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:15,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:15,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:15,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:16,466][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(10.6523, device='cuda:0') eval_epoch_loss=tensor(2.3658, device='cuda:0') eval_epoch_acc=tensor(0.4000, device='cuda:0')
[2024-11-13 04:58:16,467][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 04:58:16,467][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 04:58:16,741][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_286_loss_2.3657748699188232/model.pt
[2024-11-13 04:58:16,745][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 04:58:16,746][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 2.3657748699188232
[2024-11-13 04:58:16,746][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.4000460207462311
[2024-11-13 04:58:16,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:17,069][root][INFO] - Training Epoch: 1/10, step 286/574 completed (loss: 2.4341018199920654, acc: 0.3359375)
[2024-11-13 04:58:17,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:17,404][root][INFO] - Training Epoch: 1/10, step 287/574 completed (loss: 2.6384687423706055, acc: 0.2879999876022339)
[2024-11-13 04:58:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:17,727][root][INFO] - Training Epoch: 1/10, step 288/574 completed (loss: 2.29734206199646, acc: 0.4175824224948883)
[2024-11-13 04:58:17,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:18,053][root][INFO] - Training Epoch: 1/10, step 289/574 completed (loss: 2.6788980960845947, acc: 0.2732919156551361)
[2024-11-13 04:58:18,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:18,442][root][INFO] - Training Epoch: 1/10, step 290/574 completed (loss: 2.7100114822387695, acc: 0.2989690601825714)
[2024-11-13 04:58:18,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:18,792][root][INFO] - Training Epoch: 1/10, step 291/574 completed (loss: 1.6761345863342285, acc: 0.5909090638160706)
[2024-11-13 04:58:18,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:19,093][root][INFO] - Training Epoch: 1/10, step 292/574 completed (loss: 2.432424545288086, acc: 0.3571428656578064)
[2024-11-13 04:58:19,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:19,457][root][INFO] - Training Epoch: 1/10, step 293/574 completed (loss: 2.027949571609497, acc: 0.4655172526836395)
[2024-11-13 04:58:19,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:19,946][root][INFO] - Training Epoch: 1/10, step 294/574 completed (loss: 1.801153540611267, acc: 0.581818163394928)
[2024-11-13 04:58:20,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:20,509][root][INFO] - Training Epoch: 1/10, step 295/574 completed (loss: 2.0511491298675537, acc: 0.47422680258750916)
[2024-11-13 04:58:20,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:20,844][root][INFO] - Training Epoch: 1/10, step 296/574 completed (loss: 2.449373722076416, acc: 0.4137931168079376)
[2024-11-13 04:58:20,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:21,189][root][INFO] - Training Epoch: 1/10, step 297/574 completed (loss: 2.102074146270752, acc: 0.5185185074806213)
[2024-11-13 04:58:21,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:21,527][root][INFO] - Training Epoch: 1/10, step 298/574 completed (loss: 2.2946219444274902, acc: 0.42105263471603394)
[2024-11-13 04:58:21,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:21,885][root][INFO] - Training Epoch: 1/10, step 299/574 completed (loss: 2.460498094558716, acc: 0.3928571343421936)
[2024-11-13 04:58:21,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:22,222][root][INFO] - Training Epoch: 1/10, step 300/574 completed (loss: 2.3280258178710938, acc: 0.375)
[2024-11-13 04:58:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:22,540][root][INFO] - Training Epoch: 1/10, step 301/574 completed (loss: 2.6024088859558105, acc: 0.3396226465702057)
[2024-11-13 04:58:22,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:22,865][root][INFO] - Training Epoch: 1/10, step 302/574 completed (loss: 1.5726269483566284, acc: 0.5660377144813538)
[2024-11-13 04:58:22,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:23,225][root][INFO] - Training Epoch: 1/10, step 303/574 completed (loss: 1.8405522108078003, acc: 0.5882353186607361)
[2024-11-13 04:58:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:23,549][root][INFO] - Training Epoch: 1/10, step 304/574 completed (loss: 2.6332690715789795, acc: 0.3125)
[2024-11-13 04:58:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:23,889][root][INFO] - Training Epoch: 1/10, step 305/574 completed (loss: 1.8902580738067627, acc: 0.5409836173057556)
[2024-11-13 04:58:23,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:24,178][root][INFO] - Training Epoch: 1/10, step 306/574 completed (loss: 1.456652283668518, acc: 0.5666666626930237)
[2024-11-13 04:58:24,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:24,480][root][INFO] - Training Epoch: 1/10, step 307/574 completed (loss: 1.1462839841842651, acc: 0.7368420958518982)
[2024-11-13 04:58:24,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:24,772][root][INFO] - Training Epoch: 1/10, step 308/574 completed (loss: 2.5697734355926514, acc: 0.3478260934352875)
[2024-11-13 04:58:24,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:25,203][root][INFO] - Training Epoch: 1/10, step 309/574 completed (loss: 2.2501161098480225, acc: 0.4305555522441864)
[2024-11-13 04:58:25,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:25,518][root][INFO] - Training Epoch: 1/10, step 310/574 completed (loss: 2.233656644821167, acc: 0.3855421543121338)
[2024-11-13 04:58:25,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:25,777][root][INFO] - Training Epoch: 1/10, step 311/574 completed (loss: 2.6559994220733643, acc: 0.3205128312110901)
[2024-11-13 04:58:25,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:26,112][root][INFO] - Training Epoch: 1/10, step 312/574 completed (loss: 2.6947028636932373, acc: 0.3163265287876129)
[2024-11-13 04:58:26,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:26,393][root][INFO] - Training Epoch: 1/10, step 313/574 completed (loss: 0.8629618287086487, acc: 0.875)
[2024-11-13 04:58:26,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:26,666][root][INFO] - Training Epoch: 1/10, step 314/574 completed (loss: 1.9710516929626465, acc: 0.4583333432674408)
[2024-11-13 04:58:26,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:26,983][root][INFO] - Training Epoch: 1/10, step 315/574 completed (loss: 2.007333755493164, acc: 0.4193548262119293)
[2024-11-13 04:58:27,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:27,322][root][INFO] - Training Epoch: 1/10, step 316/574 completed (loss: 2.377664566040039, acc: 0.32258063554763794)
[2024-11-13 04:58:27,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:27,681][root][INFO] - Training Epoch: 1/10, step 317/574 completed (loss: 1.987239956855774, acc: 0.46268656849861145)
[2024-11-13 04:58:27,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:28,074][root][INFO] - Training Epoch: 1/10, step 318/574 completed (loss: 1.8477095365524292, acc: 0.5)
[2024-11-13 04:58:28,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:28,430][root][INFO] - Training Epoch: 1/10, step 319/574 completed (loss: 2.770336389541626, acc: 0.24444444477558136)
[2024-11-13 04:58:28,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:28,789][root][INFO] - Training Epoch: 1/10, step 320/574 completed (loss: 2.131528377532959, acc: 0.3709677457809448)
[2024-11-13 04:58:28,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:29,091][root][INFO] - Training Epoch: 1/10, step 321/574 completed (loss: 1.5951827764511108, acc: 0.6399999856948853)
[2024-11-13 04:58:29,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:29,468][root][INFO] - Training Epoch: 1/10, step 322/574 completed (loss: 3.1271603107452393, acc: 0.25925925374031067)
[2024-11-13 04:58:29,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:29,788][root][INFO] - Training Epoch: 1/10, step 323/574 completed (loss: 3.7391605377197266, acc: 0.05714285746216774)
[2024-11-13 04:58:29,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:30,139][root][INFO] - Training Epoch: 1/10, step 324/574 completed (loss: 2.802771806716919, acc: 0.12820513546466827)
[2024-11-13 04:58:30,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:30,464][root][INFO] - Training Epoch: 1/10, step 325/574 completed (loss: 2.777095079421997, acc: 0.3414634168148041)
[2024-11-13 04:58:30,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:30,786][root][INFO] - Training Epoch: 1/10, step 326/574 completed (loss: 2.403581142425537, acc: 0.3947368562221527)
[2024-11-13 04:58:30,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:31,094][root][INFO] - Training Epoch: 1/10, step 327/574 completed (loss: 1.6613715887069702, acc: 0.42105263471603394)
[2024-11-13 04:58:31,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:31,417][root][INFO] - Training Epoch: 1/10, step 328/574 completed (loss: 1.7986491918563843, acc: 0.3928571343421936)
[2024-11-13 04:58:31,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:31,726][root][INFO] - Training Epoch: 1/10, step 329/574 completed (loss: 2.3906641006469727, acc: 0.3333333432674408)
[2024-11-13 04:58:31,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:32,024][root][INFO] - Training Epoch: 1/10, step 330/574 completed (loss: 1.5132107734680176, acc: 0.5625)
[2024-11-13 04:58:32,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:32,388][root][INFO] - Training Epoch: 1/10, step 331/574 completed (loss: 2.365652084350586, acc: 0.3709677457809448)
[2024-11-13 04:58:32,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:32,826][root][INFO] - Training Epoch: 1/10, step 332/574 completed (loss: 2.018235683441162, acc: 0.4385964870452881)
[2024-11-13 04:58:32,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:33,072][root][INFO] - Training Epoch: 1/10, step 333/574 completed (loss: 2.704690933227539, acc: 0.25)
[2024-11-13 04:58:33,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:33,339][root][INFO] - Training Epoch: 1/10, step 334/574 completed (loss: 1.9678785800933838, acc: 0.5666666626930237)
[2024-11-13 04:58:33,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:33,580][root][INFO] - Training Epoch: 1/10, step 335/574 completed (loss: 2.107936143875122, acc: 0.4736842215061188)
[2024-11-13 04:58:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:33,925][root][INFO] - Training Epoch: 1/10, step 336/574 completed (loss: 2.399268388748169, acc: 0.3400000035762787)
[2024-11-13 04:58:34,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:34,296][root][INFO] - Training Epoch: 1/10, step 337/574 completed (loss: 2.4920127391815186, acc: 0.3333333432674408)
[2024-11-13 04:58:34,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:34,706][root][INFO] - Training Epoch: 1/10, step 338/574 completed (loss: 2.6195180416107178, acc: 0.3297872245311737)
[2024-11-13 04:58:34,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:35,077][root][INFO] - Training Epoch: 1/10, step 339/574 completed (loss: 2.625147581100464, acc: 0.3855421543121338)
[2024-11-13 04:58:35,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:35,482][root][INFO] - Training Epoch: 1/10, step 340/574 completed (loss: 1.8424551486968994, acc: 0.6086956262588501)
[2024-11-13 04:58:35,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:35,819][root][INFO] - Training Epoch: 1/10, step 341/574 completed (loss: 2.651111602783203, acc: 0.3333333432674408)
[2024-11-13 04:58:35,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:36,205][root][INFO] - Training Epoch: 1/10, step 342/574 completed (loss: 2.786953926086426, acc: 0.3253012001514435)
[2024-11-13 04:58:36,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:36,577][root][INFO] - Training Epoch: 1/10, step 343/574 completed (loss: 2.195976972579956, acc: 0.4528301954269409)
[2024-11-13 04:58:36,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:36,949][root][INFO] - Training Epoch: 1/10, step 344/574 completed (loss: 2.578165292739868, acc: 0.3037974536418915)
[2024-11-13 04:58:37,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:37,297][root][INFO] - Training Epoch: 1/10, step 345/574 completed (loss: 2.3487627506256104, acc: 0.3529411852359772)
[2024-11-13 04:58:37,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:37,709][root][INFO] - Training Epoch: 1/10, step 346/574 completed (loss: 2.828456163406372, acc: 0.2985074520111084)
[2024-11-13 04:58:37,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:38,036][root][INFO] - Training Epoch: 1/10, step 347/574 completed (loss: 1.8428575992584229, acc: 0.6000000238418579)
[2024-11-13 04:58:38,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:38,338][root][INFO] - Training Epoch: 1/10, step 348/574 completed (loss: 1.7213128805160522, acc: 0.5199999809265137)
[2024-11-13 04:58:38,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:38,765][root][INFO] - Training Epoch: 1/10, step 349/574 completed (loss: 1.7473089694976807, acc: 0.5833333134651184)
[2024-11-13 04:58:38,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:39,060][root][INFO] - Training Epoch: 1/10, step 350/574 completed (loss: 2.2777702808380127, acc: 0.41860464215278625)
[2024-11-13 04:58:39,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:39,364][root][INFO] - Training Epoch: 1/10, step 351/574 completed (loss: 2.224893093109131, acc: 0.38461539149284363)
[2024-11-13 04:58:39,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:39,778][root][INFO] - Training Epoch: 1/10, step 352/574 completed (loss: 2.311689853668213, acc: 0.42222222685813904)
[2024-11-13 04:58:39,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:40,079][root][INFO] - Training Epoch: 1/10, step 353/574 completed (loss: 1.3748985528945923, acc: 0.52173912525177)
[2024-11-13 04:58:40,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:40,342][root][INFO] - Training Epoch: 1/10, step 354/574 completed (loss: 2.8053064346313477, acc: 0.3076923191547394)
[2024-11-13 04:58:40,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:40,721][root][INFO] - Training Epoch: 1/10, step 355/574 completed (loss: 2.740710973739624, acc: 0.3076923191547394)
[2024-11-13 04:58:40,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:41,256][root][INFO] - Training Epoch: 1/10, step 356/574 completed (loss: 2.3136487007141113, acc: 0.35652172565460205)
[2024-11-13 04:58:41,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:41,656][root][INFO] - Training Epoch: 1/10, step 357/574 completed (loss: 2.4303576946258545, acc: 0.30434781312942505)
[2024-11-13 04:58:41,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:42,088][root][INFO] - Training Epoch: 1/10, step 358/574 completed (loss: 2.5242772102355957, acc: 0.3265306055545807)
[2024-11-13 04:58:42,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:42,443][root][INFO] - Training Epoch: 1/10, step 359/574 completed (loss: 0.8173120021820068, acc: 0.8333333134651184)
[2024-11-13 04:58:42,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:42,704][root][INFO] - Training Epoch: 1/10, step 360/574 completed (loss: 1.85341215133667, acc: 0.4615384638309479)
[2024-11-13 04:58:42,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:42,959][root][INFO] - Training Epoch: 1/10, step 361/574 completed (loss: 2.484633445739746, acc: 0.3658536672592163)
[2024-11-13 04:58:43,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:43,306][root][INFO] - Training Epoch: 1/10, step 362/574 completed (loss: 2.149320363998413, acc: 0.46666666865348816)
[2024-11-13 04:58:43,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:43,630][root][INFO] - Training Epoch: 1/10, step 363/574 completed (loss: 2.5101735591888428, acc: 0.3684210479259491)
[2024-11-13 04:58:43,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:43,895][root][INFO] - Training Epoch: 1/10, step 364/574 completed (loss: 2.43146014213562, acc: 0.4146341383457184)
[2024-11-13 04:58:43,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:44,155][root][INFO] - Training Epoch: 1/10, step 365/574 completed (loss: 2.4331929683685303, acc: 0.39393940567970276)
[2024-11-13 04:58:44,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:44,387][root][INFO] - Training Epoch: 1/10, step 366/574 completed (loss: 1.1338303089141846, acc: 0.6666666865348816)
[2024-11-13 04:58:44,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:44,639][root][INFO] - Training Epoch: 1/10, step 367/574 completed (loss: 0.9898753762245178, acc: 0.739130437374115)
[2024-11-13 04:58:44,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:44,923][root][INFO] - Training Epoch: 1/10, step 368/574 completed (loss: 1.6723659038543701, acc: 0.4642857015132904)
[2024-11-13 04:58:45,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:45,193][root][INFO] - Training Epoch: 1/10, step 369/574 completed (loss: 1.9862464666366577, acc: 0.46875)
[2024-11-13 04:58:45,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:45,862][root][INFO] - Training Epoch: 1/10, step 370/574 completed (loss: 2.314086437225342, acc: 0.43030303716659546)
[2024-11-13 04:58:46,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:46,790][root][INFO] - Training Epoch: 1/10, step 371/574 completed (loss: 1.8058277368545532, acc: 0.5943396091461182)
[2024-11-13 04:58:46,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:47,146][root][INFO] - Training Epoch: 1/10, step 372/574 completed (loss: 2.1515088081359863, acc: 0.4555555582046509)
[2024-11-13 04:58:47,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:47,496][root][INFO] - Training Epoch: 1/10, step 373/574 completed (loss: 2.199241876602173, acc: 0.4642857015132904)
[2024-11-13 04:58:47,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:47,861][root][INFO] - Training Epoch: 1/10, step 374/574 completed (loss: 1.3645626306533813, acc: 0.6571428775787354)
[2024-11-13 04:58:47,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:48,202][root][INFO] - Training Epoch: 1/10, step 375/574 completed (loss: 0.967216968536377, acc: 0.7599999904632568)
[2024-11-13 04:58:48,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:48,499][root][INFO] - Training Epoch: 1/10, step 376/574 completed (loss: 1.094468355178833, acc: 0.6521739363670349)
[2024-11-13 04:58:48,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:48,813][root][INFO] - Training Epoch: 1/10, step 377/574 completed (loss: 2.696241617202759, acc: 0.25)
[2024-11-13 04:58:48,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:49,173][root][INFO] - Training Epoch: 1/10, step 378/574 completed (loss: 2.135755777359009, acc: 0.4421052634716034)
[2024-11-13 04:58:49,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:49,756][root][INFO] - Training Epoch: 1/10, step 379/574 completed (loss: 2.0914900302886963, acc: 0.443113774061203)
[2024-11-13 04:58:49,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:50,176][root][INFO] - Training Epoch: 1/10, step 380/574 completed (loss: 1.9731252193450928, acc: 0.4887218177318573)
[2024-11-13 04:58:50,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:51,466][root][INFO] - Training Epoch: 1/10, step 381/574 completed (loss: 2.0207161903381348, acc: 0.45989304780960083)
[2024-11-13 04:58:51,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:52,026][root][INFO] - Training Epoch: 1/10, step 382/574 completed (loss: 1.7711154222488403, acc: 0.5495495200157166)
[2024-11-13 04:58:52,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:52,345][root][INFO] - Training Epoch: 1/10, step 383/574 completed (loss: 1.6518644094467163, acc: 0.5357142686843872)
[2024-11-13 04:58:52,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:52,647][root][INFO] - Training Epoch: 1/10, step 384/574 completed (loss: 1.272680401802063, acc: 0.6428571343421936)
[2024-11-13 04:58:52,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:52,975][root][INFO] - Training Epoch: 1/10, step 385/574 completed (loss: 2.022005796432495, acc: 0.375)
[2024-11-13 04:58:53,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:53,352][root][INFO] - Training Epoch: 1/10, step 386/574 completed (loss: 2.15559458732605, acc: 0.4166666567325592)
[2024-11-13 04:58:53,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:53,659][root][INFO] - Training Epoch: 1/10, step 387/574 completed (loss: 2.0413601398468018, acc: 0.42105263471603394)
[2024-11-13 04:58:53,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:53,978][root][INFO] - Training Epoch: 1/10, step 388/574 completed (loss: 1.7043023109436035, acc: 0.5454545617103577)
[2024-11-13 04:58:54,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:54,336][root][INFO] - Training Epoch: 1/10, step 389/574 completed (loss: 2.1625330448150635, acc: 0.44999998807907104)
[2024-11-13 04:58:54,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:54,672][root][INFO] - Training Epoch: 1/10, step 390/574 completed (loss: 2.0614805221557617, acc: 0.4761904776096344)
[2024-11-13 04:58:54,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:55,036][root][INFO] - Training Epoch: 1/10, step 391/574 completed (loss: 2.6113743782043457, acc: 0.3333333432674408)
[2024-11-13 04:58:55,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:55,377][root][INFO] - Training Epoch: 1/10, step 392/574 completed (loss: 2.5829076766967773, acc: 0.3980582654476166)
[2024-11-13 04:58:55,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:55,924][root][INFO] - Training Epoch: 1/10, step 393/574 completed (loss: 2.152120590209961, acc: 0.44117647409439087)
[2024-11-13 04:58:56,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:56,338][root][INFO] - Training Epoch: 1/10, step 394/574 completed (loss: 2.4939584732055664, acc: 0.3866666555404663)
[2024-11-13 04:58:56,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:56,750][root][INFO] - Training Epoch: 1/10, step 395/574 completed (loss: 2.398607015609741, acc: 0.4027777910232544)
[2024-11-13 04:58:56,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:57,192][root][INFO] - Training Epoch: 1/10, step 396/574 completed (loss: 2.3106491565704346, acc: 0.4883720874786377)
[2024-11-13 04:58:57,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:57,490][root][INFO] - Training Epoch: 1/10, step 397/574 completed (loss: 1.5204731225967407, acc: 0.6666666865348816)
[2024-11-13 04:58:57,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:57,780][root][INFO] - Training Epoch: 1/10, step 398/574 completed (loss: 1.918660044670105, acc: 0.44186046719551086)
[2024-11-13 04:58:57,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:58,102][root][INFO] - Training Epoch: 1/10, step 399/574 completed (loss: 2.1239523887634277, acc: 0.4000000059604645)
[2024-11-13 04:58:58,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:58,651][root][INFO] - Training Epoch: 1/10, step 400/574 completed (loss: 2.2129852771759033, acc: 0.4264705777168274)
[2024-11-13 04:58:58,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:59,041][root][INFO] - Training Epoch: 1/10, step 401/574 completed (loss: 2.2061076164245605, acc: 0.4266666769981384)
[2024-11-13 04:58:59,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:59,440][root][INFO] - Training Epoch: 1/10, step 402/574 completed (loss: 1.6636147499084473, acc: 0.6363636255264282)
[2024-11-13 04:58:59,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:58:59,759][root][INFO] - Training Epoch: 1/10, step 403/574 completed (loss: 2.0182342529296875, acc: 0.5151515007019043)
[2024-11-13 04:58:59,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:00,156][root][INFO] - Training Epoch: 1/10, step 404/574 completed (loss: 1.6704678535461426, acc: 0.4838709533214569)
[2024-11-13 04:59:00,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:00,472][root][INFO] - Training Epoch: 1/10, step 405/574 completed (loss: 2.1743266582489014, acc: 0.5185185074806213)
[2024-11-13 04:59:00,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:00,772][root][INFO] - Training Epoch: 1/10, step 406/574 completed (loss: 1.1659153699874878, acc: 0.7599999904632568)
[2024-11-13 04:59:00,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:01,180][root][INFO] - Training Epoch: 1/10, step 407/574 completed (loss: 1.2625781297683716, acc: 0.6388888955116272)
[2024-11-13 04:59:01,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:01,525][root][INFO] - Training Epoch: 1/10, step 408/574 completed (loss: 1.3558710813522339, acc: 0.5925925970077515)
[2024-11-13 04:59:01,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:01,857][root][INFO] - Training Epoch: 1/10, step 409/574 completed (loss: 1.560535192489624, acc: 0.6153846383094788)
[2024-11-13 04:59:01,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:02,189][root][INFO] - Training Epoch: 1/10, step 410/574 completed (loss: 1.7387806177139282, acc: 0.5517241358757019)
[2024-11-13 04:59:02,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:02,503][root][INFO] - Training Epoch: 1/10, step 411/574 completed (loss: 1.284596562385559, acc: 0.6428571343421936)
[2024-11-13 04:59:02,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:02,876][root][INFO] - Training Epoch: 1/10, step 412/574 completed (loss: 1.2917253971099854, acc: 0.6666666865348816)
[2024-11-13 04:59:02,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:03,208][root][INFO] - Training Epoch: 1/10, step 413/574 completed (loss: 1.7631398439407349, acc: 0.4848484992980957)
[2024-11-13 04:59:03,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:03,477][root][INFO] - Training Epoch: 1/10, step 414/574 completed (loss: 1.7989482879638672, acc: 0.40909090638160706)
[2024-11-13 04:59:03,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:03,828][root][INFO] - Training Epoch: 1/10, step 415/574 completed (loss: 2.3233327865600586, acc: 0.47058823704719543)
[2024-11-13 04:59:03,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:04,138][root][INFO] - Training Epoch: 1/10, step 416/574 completed (loss: 2.060443878173828, acc: 0.5)
[2024-11-13 04:59:04,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:04,437][root][INFO] - Training Epoch: 1/10, step 417/574 completed (loss: 1.8471698760986328, acc: 0.5)
[2024-11-13 04:59:04,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:04,729][root][INFO] - Training Epoch: 1/10, step 418/574 completed (loss: 2.0554327964782715, acc: 0.5)
[2024-11-13 04:59:04,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:05,070][root][INFO] - Training Epoch: 1/10, step 419/574 completed (loss: 3.067418098449707, acc: 0.30000001192092896)
[2024-11-13 04:59:05,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:05,368][root][INFO] - Training Epoch: 1/10, step 420/574 completed (loss: 0.9453644752502441, acc: 0.8095238208770752)
[2024-11-13 04:59:05,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:05,638][root][INFO] - Training Epoch: 1/10, step 421/574 completed (loss: 2.219651699066162, acc: 0.4000000059604645)
[2024-11-13 04:59:05,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:05,943][root][INFO] - Training Epoch: 1/10, step 422/574 completed (loss: 2.0602831840515137, acc: 0.4375)
[2024-11-13 04:59:06,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:06,269][root][INFO] - Training Epoch: 1/10, step 423/574 completed (loss: 2.022717237472534, acc: 0.4166666567325592)
[2024-11-13 04:59:06,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:06,635][root][INFO] - Training Epoch: 1/10, step 424/574 completed (loss: 1.9091438055038452, acc: 0.4444444477558136)
[2024-11-13 04:59:06,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:06,955][root][INFO] - Training Epoch: 1/10, step 425/574 completed (loss: 1.6116658449172974, acc: 0.5454545617103577)
[2024-11-13 04:59:07,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:07,271][root][INFO] - Training Epoch: 1/10, step 426/574 completed (loss: 1.3659887313842773, acc: 0.739130437374115)
[2024-11-13 04:59:07,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:07,594][root][INFO] - Training Epoch: 1/10, step 427/574 completed (loss: 1.564418911933899, acc: 0.5945945978164673)
[2024-11-13 04:59:07,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:07,931][root][INFO] - Training Epoch: 1/10, step 428/574 completed (loss: 1.357271671295166, acc: 0.7407407164573669)
[2024-11-13 04:59:08,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:09,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:09,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:09,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:10,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:10,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:10,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:11,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:11,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:11,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:12,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:12,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:12,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:13,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:13,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:14,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:14,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:14,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:15,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:15,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:15,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:15,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:16,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:16,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:16,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:17,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:17,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:18,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:18,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:18,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:19,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:19,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:20,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:20,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:20,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:21,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:21,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:21,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:22,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:22,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:22,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:23,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:23,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:23,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:24,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:24,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:24,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:25,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:25,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:25,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:25,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:26,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:26,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:26,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:27,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:27,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:27,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:28,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:28,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:28,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:29,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:29,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:30,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:30,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:31,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:31,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:31,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:32,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:32,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:33,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:33,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:33,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:34,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:34,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:34,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:35,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:35,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:36,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:36,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:36,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:37,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:37,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:38,201][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(11.4487, device='cuda:0') eval_epoch_loss=tensor(2.4379, device='cuda:0') eval_epoch_acc=tensor(0.3847, device='cuda:0')
[2024-11-13 04:59:38,202][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 04:59:38,203][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 04:59:38,568][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_429_loss_2.4378790855407715/model.pt
[2024-11-13 04:59:38,573][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 04:59:38,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:38,918][root][INFO] - Training Epoch: 1/10, step 429/574 completed (loss: 2.1406290531158447, acc: 0.43478259444236755)
[2024-11-13 04:59:39,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:39,263][root][INFO] - Training Epoch: 1/10, step 430/574 completed (loss: 1.1508504152297974, acc: 0.7037037014961243)
[2024-11-13 04:59:39,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:39,606][root][INFO] - Training Epoch: 1/10, step 431/574 completed (loss: 1.3250508308410645, acc: 0.6666666865348816)
[2024-11-13 04:59:39,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:39,917][root][INFO] - Training Epoch: 1/10, step 432/574 completed (loss: 2.0143938064575195, acc: 0.43478259444236755)
[2024-11-13 04:59:40,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:40,268][root][INFO] - Training Epoch: 1/10, step 433/574 completed (loss: 1.6152491569519043, acc: 0.6388888955116272)
[2024-11-13 04:59:40,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:40,564][root][INFO] - Training Epoch: 1/10, step 434/574 completed (loss: 0.8007684946060181, acc: 0.800000011920929)
[2024-11-13 04:59:40,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:40,887][root][INFO] - Training Epoch: 1/10, step 435/574 completed (loss: 1.701322317123413, acc: 0.4545454680919647)
[2024-11-13 04:59:40,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:41,213][root][INFO] - Training Epoch: 1/10, step 436/574 completed (loss: 1.6474251747131348, acc: 0.4722222089767456)
[2024-11-13 04:59:41,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:41,612][root][INFO] - Training Epoch: 1/10, step 437/574 completed (loss: 1.848193645477295, acc: 0.5454545617103577)
[2024-11-13 04:59:41,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:41,921][root][INFO] - Training Epoch: 1/10, step 438/574 completed (loss: 0.6982128024101257, acc: 0.761904776096344)
[2024-11-13 04:59:42,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:42,262][root][INFO] - Training Epoch: 1/10, step 439/574 completed (loss: 2.3652098178863525, acc: 0.4615384638309479)
[2024-11-13 04:59:42,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:42,765][root][INFO] - Training Epoch: 1/10, step 440/574 completed (loss: 2.136232376098633, acc: 0.42424243688583374)
[2024-11-13 04:59:43,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:43,532][root][INFO] - Training Epoch: 1/10, step 441/574 completed (loss: 2.8230412006378174, acc: 0.29600000381469727)
[2024-11-13 04:59:43,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:43,959][root][INFO] - Training Epoch: 1/10, step 442/574 completed (loss: 2.571406602859497, acc: 0.33870968222618103)
[2024-11-13 04:59:44,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:44,641][root][INFO] - Training Epoch: 1/10, step 443/574 completed (loss: 2.4355626106262207, acc: 0.34825870394706726)
[2024-11-13 04:59:44,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:44,982][root][INFO] - Training Epoch: 1/10, step 444/574 completed (loss: 2.4410619735717773, acc: 0.3962264060974121)
[2024-11-13 04:59:45,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:45,427][root][INFO] - Training Epoch: 1/10, step 445/574 completed (loss: 1.64661705493927, acc: 0.5681818127632141)
[2024-11-13 04:59:45,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:45,756][root][INFO] - Training Epoch: 1/10, step 446/574 completed (loss: 2.234685182571411, acc: 0.52173912525177)
[2024-11-13 04:59:45,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:46,058][root][INFO] - Training Epoch: 1/10, step 447/574 completed (loss: 1.9398545026779175, acc: 0.5)
[2024-11-13 04:59:46,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:46,398][root][INFO] - Training Epoch: 1/10, step 448/574 completed (loss: 1.615204095840454, acc: 0.5357142686843872)
[2024-11-13 04:59:46,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:46,743][root][INFO] - Training Epoch: 1/10, step 449/574 completed (loss: 2.697808265686035, acc: 0.3731343150138855)
[2024-11-13 04:59:46,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:47,081][root][INFO] - Training Epoch: 1/10, step 450/574 completed (loss: 2.1720008850097656, acc: 0.4722222089767456)
[2024-11-13 04:59:47,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:47,394][root][INFO] - Training Epoch: 1/10, step 451/574 completed (loss: 2.5217130184173584, acc: 0.3913043439388275)
[2024-11-13 04:59:47,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:47,759][root][INFO] - Training Epoch: 1/10, step 452/574 completed (loss: 2.5959813594818115, acc: 0.29487180709838867)
[2024-11-13 04:59:47,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:48,097][root][INFO] - Training Epoch: 1/10, step 453/574 completed (loss: 2.58302640914917, acc: 0.42105263471603394)
[2024-11-13 04:59:48,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:48,421][root][INFO] - Training Epoch: 1/10, step 454/574 completed (loss: 1.9412903785705566, acc: 0.5306122303009033)
[2024-11-13 04:59:48,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:48,769][root][INFO] - Training Epoch: 1/10, step 455/574 completed (loss: 1.7628546953201294, acc: 0.5757575631141663)
[2024-11-13 04:59:48,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:49,028][root][INFO] - Training Epoch: 1/10, step 456/574 completed (loss: 2.3312594890594482, acc: 0.2989690601825714)
[2024-11-13 04:59:49,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:49,459][root][INFO] - Training Epoch: 1/10, step 457/574 completed (loss: 2.224465847015381, acc: 0.4000000059604645)
[2024-11-13 04:59:49,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:49,884][root][INFO] - Training Epoch: 1/10, step 458/574 completed (loss: 2.287337303161621, acc: 0.36627906560897827)
[2024-11-13 04:59:49,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:50,210][root][INFO] - Training Epoch: 1/10, step 459/574 completed (loss: 2.5624916553497314, acc: 0.375)
[2024-11-13 04:59:50,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:50,551][root][INFO] - Training Epoch: 1/10, step 460/574 completed (loss: 2.286167621612549, acc: 0.37037035822868347)
[2024-11-13 04:59:50,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:50,932][root][INFO] - Training Epoch: 1/10, step 461/574 completed (loss: 1.7589176893234253, acc: 0.4722222089767456)
[2024-11-13 04:59:51,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:51,266][root][INFO] - Training Epoch: 1/10, step 462/574 completed (loss: 1.7746319770812988, acc: 0.59375)
[2024-11-13 04:59:51,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:51,603][root][INFO] - Training Epoch: 1/10, step 463/574 completed (loss: 1.9433561563491821, acc: 0.4615384638309479)
[2024-11-13 04:59:51,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:51,878][root][INFO] - Training Epoch: 1/10, step 464/574 completed (loss: 2.1256725788116455, acc: 0.45652174949645996)
[2024-11-13 04:59:51,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:52,181][root][INFO] - Training Epoch: 1/10, step 465/574 completed (loss: 2.4238393306732178, acc: 0.190476194024086)
[2024-11-13 04:59:52,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:52,583][root][INFO] - Training Epoch: 1/10, step 466/574 completed (loss: 2.5175979137420654, acc: 0.3012048304080963)
[2024-11-13 04:59:52,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:52,968][root][INFO] - Training Epoch: 1/10, step 467/574 completed (loss: 2.237745761871338, acc: 0.37837839126586914)
[2024-11-13 04:59:53,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:53,312][root][INFO] - Training Epoch: 1/10, step 468/574 completed (loss: 2.2779769897460938, acc: 0.4660194218158722)
[2024-11-13 04:59:53,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:53,641][root][INFO] - Training Epoch: 1/10, step 469/574 completed (loss: 2.063811779022217, acc: 0.42276424169540405)
[2024-11-13 04:59:53,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:53,954][root][INFO] - Training Epoch: 1/10, step 470/574 completed (loss: 1.8643304109573364, acc: 0.5833333134651184)
[2024-11-13 04:59:54,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:54,299][root][INFO] - Training Epoch: 1/10, step 471/574 completed (loss: 2.6651217937469482, acc: 0.3571428656578064)
[2024-11-13 04:59:54,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:54,746][root][INFO] - Training Epoch: 1/10, step 472/574 completed (loss: 2.335437297821045, acc: 0.343137264251709)
[2024-11-13 04:59:54,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:55,149][root][INFO] - Training Epoch: 1/10, step 473/574 completed (loss: 2.528721809387207, acc: 0.331877738237381)
[2024-11-13 04:59:55,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:55,522][root][INFO] - Training Epoch: 1/10, step 474/574 completed (loss: 2.336411714553833, acc: 0.3541666567325592)
[2024-11-13 04:59:55,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:55,893][root][INFO] - Training Epoch: 1/10, step 475/574 completed (loss: 2.3784782886505127, acc: 0.3619631826877594)
[2024-11-13 04:59:55,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:56,225][root][INFO] - Training Epoch: 1/10, step 476/574 completed (loss: 2.5023274421691895, acc: 0.3525179922580719)
[2024-11-13 04:59:56,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:56,606][root][INFO] - Training Epoch: 1/10, step 477/574 completed (loss: 2.4258079528808594, acc: 0.36180904507637024)
[2024-11-13 04:59:56,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:56,945][root][INFO] - Training Epoch: 1/10, step 478/574 completed (loss: 1.779611349105835, acc: 0.5555555820465088)
[2024-11-13 04:59:57,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:57,285][root][INFO] - Training Epoch: 1/10, step 479/574 completed (loss: 1.710673451423645, acc: 0.5757575631141663)
[2024-11-13 04:59:57,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:57,608][root][INFO] - Training Epoch: 1/10, step 480/574 completed (loss: 1.7617789506912231, acc: 0.40740740299224854)
[2024-11-13 04:59:57,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:57,927][root][INFO] - Training Epoch: 1/10, step 481/574 completed (loss: 1.9334163665771484, acc: 0.4000000059604645)
[2024-11-13 04:59:58,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:58,274][root][INFO] - Training Epoch: 1/10, step 482/574 completed (loss: 1.0407772064208984, acc: 0.699999988079071)
[2024-11-13 04:59:58,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:58,676][root][INFO] - Training Epoch: 1/10, step 483/574 completed (loss: 1.8798978328704834, acc: 0.48275861144065857)
[2024-11-13 04:59:58,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:58,997][root][INFO] - Training Epoch: 1/10, step 484/574 completed (loss: 1.5544902086257935, acc: 0.6129032373428345)
[2024-11-13 04:59:59,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:59,398][root][INFO] - Training Epoch: 1/10, step 485/574 completed (loss: 1.10057532787323, acc: 0.7368420958518982)
[2024-11-13 04:59:59,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 04:59:59,766][root][INFO] - Training Epoch: 1/10, step 486/574 completed (loss: 2.3089678287506104, acc: 0.40740740299224854)
[2024-11-13 04:59:59,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:00,072][root][INFO] - Training Epoch: 1/10, step 487/574 completed (loss: 2.2334256172180176, acc: 0.4285714328289032)
[2024-11-13 05:00:00,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:00,351][root][INFO] - Training Epoch: 1/10, step 488/574 completed (loss: 1.6474475860595703, acc: 0.4545454680919647)
[2024-11-13 05:00:00,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:00,746][root][INFO] - Training Epoch: 1/10, step 489/574 completed (loss: 2.05877947807312, acc: 0.4153846204280853)
[2024-11-13 05:00:00,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:01,103][root][INFO] - Training Epoch: 1/10, step 490/574 completed (loss: 1.32920241355896, acc: 0.6666666865348816)
[2024-11-13 05:00:01,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:01,498][root][INFO] - Training Epoch: 1/10, step 491/574 completed (loss: 1.5518574714660645, acc: 0.6551724076271057)
[2024-11-13 05:00:01,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:01,896][root][INFO] - Training Epoch: 1/10, step 492/574 completed (loss: 2.246971607208252, acc: 0.3921568691730499)
[2024-11-13 05:00:02,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:02,276][root][INFO] - Training Epoch: 1/10, step 493/574 completed (loss: 1.7598955631256104, acc: 0.517241358757019)
[2024-11-13 05:00:02,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:02,612][root][INFO] - Training Epoch: 1/10, step 494/574 completed (loss: 0.8823537230491638, acc: 0.7368420958518982)
[2024-11-13 05:00:02,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:02,980][root][INFO] - Training Epoch: 1/10, step 495/574 completed (loss: 3.407147169113159, acc: 0.21052631735801697)
[2024-11-13 05:00:03,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:03,311][root][INFO] - Training Epoch: 1/10, step 496/574 completed (loss: 2.2376089096069336, acc: 0.4196428656578064)
[2024-11-13 05:00:03,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:03,703][root][INFO] - Training Epoch: 1/10, step 497/574 completed (loss: 2.1057045459747314, acc: 0.40449437499046326)
[2024-11-13 05:00:03,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:04,009][root][INFO] - Training Epoch: 1/10, step 498/574 completed (loss: 2.426812171936035, acc: 0.33707866072654724)
[2024-11-13 05:00:04,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:04,328][root][INFO] - Training Epoch: 1/10, step 499/574 completed (loss: 2.5328588485717773, acc: 0.3404255211353302)
[2024-11-13 05:00:04,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:04,670][root][INFO] - Training Epoch: 1/10, step 500/574 completed (loss: 2.514545202255249, acc: 0.3695652186870575)
[2024-11-13 05:00:04,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:05,042][root][INFO] - Training Epoch: 1/10, step 501/574 completed (loss: 0.9058086276054382, acc: 0.8399999737739563)
[2024-11-13 05:00:05,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:05,391][root][INFO] - Training Epoch: 1/10, step 502/574 completed (loss: 1.3827887773513794, acc: 0.692307710647583)
[2024-11-13 05:00:05,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:05,717][root][INFO] - Training Epoch: 1/10, step 503/574 completed (loss: 1.0803533792495728, acc: 0.7407407164573669)
[2024-11-13 05:00:05,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:06,033][root][INFO] - Training Epoch: 1/10, step 504/574 completed (loss: 1.8651670217514038, acc: 0.5555555820465088)
[2024-11-13 05:00:06,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:06,348][root][INFO] - Training Epoch: 1/10, step 505/574 completed (loss: 1.8341268301010132, acc: 0.5094339847564697)
[2024-11-13 05:00:06,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:06,656][root][INFO] - Training Epoch: 1/10, step 506/574 completed (loss: 1.6349204778671265, acc: 0.517241358757019)
[2024-11-13 05:00:06,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:07,313][root][INFO] - Training Epoch: 1/10, step 507/574 completed (loss: 2.1552202701568604, acc: 0.4324324429035187)
[2024-11-13 05:00:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:07,787][root][INFO] - Training Epoch: 1/10, step 508/574 completed (loss: 2.1761066913604736, acc: 0.43661972880363464)
[2024-11-13 05:00:07,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:08,081][root][INFO] - Training Epoch: 1/10, step 509/574 completed (loss: 0.5441405773162842, acc: 0.8999999761581421)
[2024-11-13 05:00:08,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:08,393][root][INFO] - Training Epoch: 1/10, step 510/574 completed (loss: 0.9151926636695862, acc: 0.800000011920929)
[2024-11-13 05:00:08,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:08,750][root][INFO] - Training Epoch: 1/10, step 511/574 completed (loss: 1.3756872415542603, acc: 0.692307710647583)
[2024-11-13 05:00:10,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:11,558][root][INFO] - Training Epoch: 1/10, step 512/574 completed (loss: 2.2620067596435547, acc: 0.44999998807907104)
[2024-11-13 05:00:11,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:12,352][root][INFO] - Training Epoch: 1/10, step 513/574 completed (loss: 2.2935805320739746, acc: 0.4444444477558136)
[2024-11-13 05:00:12,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:12,729][root][INFO] - Training Epoch: 1/10, step 514/574 completed (loss: 1.8736008405685425, acc: 0.5357142686843872)
[2024-11-13 05:00:12,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:13,080][root][INFO] - Training Epoch: 1/10, step 515/574 completed (loss: 1.8167725801467896, acc: 0.6000000238418579)
[2024-11-13 05:00:13,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:13,846][root][INFO] - Training Epoch: 1/10, step 516/574 completed (loss: 2.0000643730163574, acc: 0.5277777910232544)
[2024-11-13 05:00:13,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:14,192][root][INFO] - Training Epoch: 1/10, step 517/574 completed (loss: 0.6016323566436768, acc: 0.7692307829856873)
[2024-11-13 05:00:14,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:14,520][root][INFO] - Training Epoch: 1/10, step 518/574 completed (loss: 2.187016725540161, acc: 0.4838709533214569)
[2024-11-13 05:00:14,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:14,803][root][INFO] - Training Epoch: 1/10, step 519/574 completed (loss: 2.3848583698272705, acc: 0.5)
[2024-11-13 05:00:14,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:15,199][root][INFO] - Training Epoch: 1/10, step 520/574 completed (loss: 2.3810670375823975, acc: 0.4444444477558136)
[2024-11-13 05:00:15,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:16,315][root][INFO] - Training Epoch: 1/10, step 521/574 completed (loss: 2.280019998550415, acc: 0.41101694107055664)
[2024-11-13 05:00:16,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:16,687][root][INFO] - Training Epoch: 1/10, step 522/574 completed (loss: 2.3148744106292725, acc: 0.4253731369972229)
[2024-11-13 05:00:16,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:17,101][root][INFO] - Training Epoch: 1/10, step 523/574 completed (loss: 2.3526999950408936, acc: 0.36496350169181824)
[2024-11-13 05:00:17,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:17,723][root][INFO] - Training Epoch: 1/10, step 524/574 completed (loss: 2.1315088272094727, acc: 0.4399999976158142)
[2024-11-13 05:00:17,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:18,066][root][INFO] - Training Epoch: 1/10, step 525/574 completed (loss: 2.3911240100860596, acc: 0.31481480598449707)
[2024-11-13 05:00:18,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:18,475][root][INFO] - Training Epoch: 1/10, step 526/574 completed (loss: 2.054293155670166, acc: 0.4423076808452606)
[2024-11-13 05:00:18,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:18,808][root][INFO] - Training Epoch: 1/10, step 527/574 completed (loss: 2.492103338241577, acc: 0.2380952388048172)
[2024-11-13 05:00:18,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:19,181][root][INFO] - Training Epoch: 1/10, step 528/574 completed (loss: 2.9598824977874756, acc: 0.21311475336551666)
[2024-11-13 05:00:19,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:19,527][root][INFO] - Training Epoch: 1/10, step 529/574 completed (loss: 2.0512571334838867, acc: 0.49152541160583496)
[2024-11-13 05:00:19,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:19,856][root][INFO] - Training Epoch: 1/10, step 530/574 completed (loss: 2.599635124206543, acc: 0.3255814015865326)
[2024-11-13 05:00:19,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:20,214][root][INFO] - Training Epoch: 1/10, step 531/574 completed (loss: 2.334465265274048, acc: 0.4318181872367859)
[2024-11-13 05:00:20,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:20,577][root][INFO] - Training Epoch: 1/10, step 532/574 completed (loss: 2.5102932453155518, acc: 0.30188679695129395)
[2024-11-13 05:00:20,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:21,009][root][INFO] - Training Epoch: 1/10, step 533/574 completed (loss: 2.1390912532806396, acc: 0.5454545617103577)
[2024-11-13 05:00:21,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:21,384][root][INFO] - Training Epoch: 1/10, step 534/574 completed (loss: 1.6337999105453491, acc: 0.6399999856948853)
[2024-11-13 05:00:21,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:21,790][root][INFO] - Training Epoch: 1/10, step 535/574 completed (loss: 1.972879409790039, acc: 0.5)
[2024-11-13 05:00:21,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:22,132][root][INFO] - Training Epoch: 1/10, step 536/574 completed (loss: 1.4850128889083862, acc: 0.5)
[2024-11-13 05:00:22,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:22,553][root][INFO] - Training Epoch: 1/10, step 537/574 completed (loss: 2.0305607318878174, acc: 0.4769230782985687)
[2024-11-13 05:00:22,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:22,922][root][INFO] - Training Epoch: 1/10, step 538/574 completed (loss: 1.955400824546814, acc: 0.46875)
[2024-11-13 05:00:23,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:23,377][root][INFO] - Training Epoch: 1/10, step 539/574 completed (loss: 1.3376394510269165, acc: 0.625)
[2024-11-13 05:00:23,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:23,787][root][INFO] - Training Epoch: 1/10, step 540/574 completed (loss: 2.071131706237793, acc: 0.39393940567970276)
[2024-11-13 05:00:23,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:24,148][root][INFO] - Training Epoch: 1/10, step 541/574 completed (loss: 0.684744119644165, acc: 0.75)
[2024-11-13 05:00:24,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:24,489][root][INFO] - Training Epoch: 1/10, step 542/574 completed (loss: 1.345779299736023, acc: 0.6451612710952759)
[2024-11-13 05:00:24,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:24,827][root][INFO] - Training Epoch: 1/10, step 543/574 completed (loss: 0.7457420229911804, acc: 0.8695651888847351)
[2024-11-13 05:00:24,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:25,167][root][INFO] - Training Epoch: 1/10, step 544/574 completed (loss: 2.2212018966674805, acc: 0.36666667461395264)
[2024-11-13 05:00:25,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:25,502][root][INFO] - Training Epoch: 1/10, step 545/574 completed (loss: 1.9032469987869263, acc: 0.39024388790130615)
[2024-11-13 05:00:25,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:25,858][root][INFO] - Training Epoch: 1/10, step 546/574 completed (loss: 1.2280975580215454, acc: 0.6571428775787354)
[2024-11-13 05:00:26,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:26,220][root][INFO] - Training Epoch: 1/10, step 547/574 completed (loss: 1.745690941810608, acc: 0.5526315569877625)
[2024-11-13 05:00:26,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:26,489][root][INFO] - Training Epoch: 1/10, step 548/574 completed (loss: 1.8623987436294556, acc: 0.4838709533214569)
[2024-11-13 05:00:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:26,766][root][INFO] - Training Epoch: 1/10, step 549/574 completed (loss: 0.8034346699714661, acc: 0.8399999737739563)
[2024-11-13 05:00:26,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:27,079][root][INFO] - Training Epoch: 1/10, step 550/574 completed (loss: 1.572472095489502, acc: 0.5454545617103577)
[2024-11-13 05:00:27,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:27,383][root][INFO] - Training Epoch: 1/10, step 551/574 completed (loss: 1.4462215900421143, acc: 0.625)
[2024-11-13 05:00:27,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:27,662][root][INFO] - Training Epoch: 1/10, step 552/574 completed (loss: 1.6752192974090576, acc: 0.5142857432365417)
[2024-11-13 05:00:27,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:27,950][root][INFO] - Training Epoch: 1/10, step 553/574 completed (loss: 2.5462186336517334, acc: 0.32116788625717163)
[2024-11-13 05:00:28,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:28,343][root][INFO] - Training Epoch: 1/10, step 554/574 completed (loss: 2.1589109897613525, acc: 0.43448275327682495)
[2024-11-13 05:00:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:28,744][root][INFO] - Training Epoch: 1/10, step 555/574 completed (loss: 2.821277379989624, acc: 0.24285714328289032)
[2024-11-13 05:00:28,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:29,113][root][INFO] - Training Epoch: 1/10, step 556/574 completed (loss: 2.870061159133911, acc: 0.23178808391094208)
[2024-11-13 05:00:29,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:29,467][root][INFO] - Training Epoch: 1/10, step 557/574 completed (loss: 2.35713791847229, acc: 0.41025641560554504)
[2024-11-13 05:00:29,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:29,801][root][INFO] - Training Epoch: 1/10, step 558/574 completed (loss: 0.8095223903656006, acc: 0.800000011920929)
[2024-11-13 05:00:29,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:30,165][root][INFO] - Training Epoch: 1/10, step 559/574 completed (loss: 1.6192874908447266, acc: 0.5769230723381042)
[2024-11-13 05:00:30,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:30,531][root][INFO] - Training Epoch: 1/10, step 560/574 completed (loss: 1.1337190866470337, acc: 0.6538461446762085)
[2024-11-13 05:00:30,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:30,899][root][INFO] - Training Epoch: 1/10, step 561/574 completed (loss: 1.8849670886993408, acc: 0.4615384638309479)
[2024-11-13 05:00:31,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:31,283][root][INFO] - Training Epoch: 1/10, step 562/574 completed (loss: 1.9756217002868652, acc: 0.5333333611488342)
[2024-11-13 05:00:31,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:31,621][root][INFO] - Training Epoch: 1/10, step 563/574 completed (loss: 2.2566077709198, acc: 0.350649356842041)
[2024-11-13 05:00:31,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:32,023][root][INFO] - Training Epoch: 1/10, step 564/574 completed (loss: 2.132633924484253, acc: 0.4166666567325592)
[2024-11-13 05:00:32,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:32,383][root][INFO] - Training Epoch: 1/10, step 565/574 completed (loss: 2.4562642574310303, acc: 0.37931033968925476)
[2024-11-13 05:00:32,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:32,735][root][INFO] - Training Epoch: 1/10, step 566/574 completed (loss: 2.224315881729126, acc: 0.380952388048172)
[2024-11-13 05:00:32,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:33,049][root][INFO] - Training Epoch: 1/10, step 567/574 completed (loss: 1.792169451713562, acc: 0.42105263471603394)
[2024-11-13 05:00:33,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:33,400][root][INFO] - Training Epoch: 1/10, step 568/574 completed (loss: 1.8891098499298096, acc: 0.5185185074806213)
[2024-11-13 05:00:33,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:33,822][root][INFO] - Training Epoch: 1/10, step 569/574 completed (loss: 2.302849531173706, acc: 0.34224599599838257)
[2024-11-13 05:00:33,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:34,162][root][INFO] - Training Epoch: 1/10, step 570/574 completed (loss: 1.7334548234939575, acc: 0.5483871102333069)
[2024-11-13 05:00:34,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:34,566][root][INFO] - Training Epoch: 1/10, step 571/574 completed (loss: 2.2555737495422363, acc: 0.4188034236431122)
[2024-11-13 05:00:35,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:35,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:36,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:36,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:36,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:37,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:37,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:37,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:38,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:38,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:39,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:39,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:39,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:40,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:40,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:40,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:41,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:41,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:41,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:42,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:42,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:42,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:43,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:43,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:44,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:44,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:44,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:45,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:45,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:46,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:46,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:46,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:47,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:47,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:48,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:48,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:49,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:49,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:49,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:49,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:50,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:50,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:50,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:51,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:51,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:51,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:52,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:52,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:53,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:53,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:53,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:54,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:54,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:54,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:55,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:55,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:55,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:56,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:57,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:57,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:58,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:58,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:58,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:59,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:59,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:00:59,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:00,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:00,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:00,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:01,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:01,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:01,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:02,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:02,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:03,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:03,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:03,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:04,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:04,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:04,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:05,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:05,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:06,293][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.2766, device='cuda:0') eval_epoch_loss=tensor(1.9847, device='cuda:0') eval_epoch_acc=tensor(0.4674, device='cuda:0')
[2024-11-13 05:01:06,295][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:01:06,296][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:01:06,684][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_1_step_572_loss_1.9846633672714233/model.pt
[2024-11-13 05:01:06,687][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:01:06,688][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 1 is 1.9846633672714233
[2024-11-13 05:01:06,688][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 1 is 0.46737411618232727
[2024-11-13 05:01:06,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:07,050][root][INFO] - Training Epoch: 1/10, step 572/574 completed (loss: 2.5107460021972656, acc: 0.3469387888908386)
[2024-11-13 05:01:07,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:07,434][root][INFO] - Training Epoch: 1/10, step 573/574 completed (loss: 2.3928208351135254, acc: 0.3207547068595886)
[2024-11-13 05:01:08,144][slam_llm.utils.train_utils][INFO] - Epoch 1: train_perplexity=18.0370, train_epoch_loss=2.8924, epoch time 372.8093614988029s
[2024-11-13 05:01:08,144][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-13 05:01:08,144][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-13 05:01:08,145][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-13 05:01:08,145][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 3
[2024-11-13 05:01:08,145][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:01:08,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:09,293][root][INFO] - Training Epoch: 2/10, step 0/574 completed (loss: 1.7023859024047852, acc: 0.48148149251937866)
[2024-11-13 05:01:09,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:09,643][root][INFO] - Training Epoch: 2/10, step 1/574 completed (loss: 2.198152780532837, acc: 0.4000000059604645)
[2024-11-13 05:01:09,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:09,986][root][INFO] - Training Epoch: 2/10, step 2/574 completed (loss: 2.761223077774048, acc: 0.3513513505458832)
[2024-11-13 05:01:10,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:10,325][root][INFO] - Training Epoch: 2/10, step 3/574 completed (loss: 2.452009677886963, acc: 0.2368421107530594)
[2024-11-13 05:01:10,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:10,654][root][INFO] - Training Epoch: 2/10, step 4/574 completed (loss: 1.9785975217819214, acc: 0.45945945382118225)
[2024-11-13 05:01:10,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:11,018][root][INFO] - Training Epoch: 2/10, step 5/574 completed (loss: 2.0531985759735107, acc: 0.3571428656578064)
[2024-11-13 05:01:11,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:11,340][root][INFO] - Training Epoch: 2/10, step 6/574 completed (loss: 2.3175647258758545, acc: 0.40816327929496765)
[2024-11-13 05:01:11,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:11,680][root][INFO] - Training Epoch: 2/10, step 7/574 completed (loss: 2.0444095134735107, acc: 0.36666667461395264)
[2024-11-13 05:01:11,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:12,043][root][INFO] - Training Epoch: 2/10, step 8/574 completed (loss: 0.4478679895401001, acc: 0.9090909361839294)
[2024-11-13 05:01:12,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:12,329][root][INFO] - Training Epoch: 2/10, step 9/574 completed (loss: 0.8296628594398499, acc: 0.7692307829856873)
[2024-11-13 05:01:12,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:12,671][root][INFO] - Training Epoch: 2/10, step 10/574 completed (loss: 1.407455325126648, acc: 0.5555555820465088)
[2024-11-13 05:01:12,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:13,078][root][INFO] - Training Epoch: 2/10, step 11/574 completed (loss: 2.112361431121826, acc: 0.38461539149284363)
[2024-11-13 05:01:13,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:13,418][root][INFO] - Training Epoch: 2/10, step 12/574 completed (loss: 1.8220643997192383, acc: 0.4848484992980957)
[2024-11-13 05:01:13,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:13,850][root][INFO] - Training Epoch: 2/10, step 13/574 completed (loss: 1.9548306465148926, acc: 0.43478259444236755)
[2024-11-13 05:01:13,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:14,223][root][INFO] - Training Epoch: 2/10, step 14/574 completed (loss: 2.304502248764038, acc: 0.4117647111415863)
[2024-11-13 05:01:14,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:14,511][root][INFO] - Training Epoch: 2/10, step 15/574 completed (loss: 1.8348770141601562, acc: 0.40816327929496765)
[2024-11-13 05:01:14,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:14,817][root][INFO] - Training Epoch: 2/10, step 16/574 completed (loss: 1.0470420122146606, acc: 0.7894737124443054)
[2024-11-13 05:01:14,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:15,111][root][INFO] - Training Epoch: 2/10, step 17/574 completed (loss: 2.202833890914917, acc: 0.375)
[2024-11-13 05:01:15,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:15,469][root][INFO] - Training Epoch: 2/10, step 18/574 completed (loss: 2.4283971786499023, acc: 0.3055555522441864)
[2024-11-13 05:01:15,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:15,838][root][INFO] - Training Epoch: 2/10, step 19/574 completed (loss: 1.9717612266540527, acc: 0.42105263471603394)
[2024-11-13 05:01:15,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:16,150][root][INFO] - Training Epoch: 2/10, step 20/574 completed (loss: 1.8964896202087402, acc: 0.5769230723381042)
[2024-11-13 05:01:16,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:16,459][root][INFO] - Training Epoch: 2/10, step 21/574 completed (loss: 2.067819833755493, acc: 0.4482758641242981)
[2024-11-13 05:01:16,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:16,770][root][INFO] - Training Epoch: 2/10, step 22/574 completed (loss: 1.8107513189315796, acc: 0.4399999976158142)
[2024-11-13 05:01:16,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:17,094][root][INFO] - Training Epoch: 2/10, step 23/574 completed (loss: 0.965427041053772, acc: 0.7142857313156128)
[2024-11-13 05:01:17,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:17,369][root][INFO] - Training Epoch: 2/10, step 24/574 completed (loss: 2.096924304962158, acc: 0.375)
[2024-11-13 05:01:17,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:17,710][root][INFO] - Training Epoch: 2/10, step 25/574 completed (loss: 2.7156591415405273, acc: 0.2641509473323822)
[2024-11-13 05:01:17,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:18,060][root][INFO] - Training Epoch: 2/10, step 26/574 completed (loss: 2.4448821544647217, acc: 0.3835616409778595)
[2024-11-13 05:01:18,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:19,518][root][INFO] - Training Epoch: 2/10, step 27/574 completed (loss: 2.522937059402466, acc: 0.3280632495880127)
[2024-11-13 05:01:19,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:19,886][root][INFO] - Training Epoch: 2/10, step 28/574 completed (loss: 2.2818307876586914, acc: 0.3720930218696594)
[2024-11-13 05:01:19,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:20,281][root][INFO] - Training Epoch: 2/10, step 29/574 completed (loss: 2.2765417098999023, acc: 0.33734938502311707)
[2024-11-13 05:01:20,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:20,697][root][INFO] - Training Epoch: 2/10, step 30/574 completed (loss: 2.314302682876587, acc: 0.395061731338501)
[2024-11-13 05:01:20,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:21,090][root][INFO] - Training Epoch: 2/10, step 31/574 completed (loss: 2.5038204193115234, acc: 0.4285714328289032)
[2024-11-13 05:01:21,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:21,432][root][INFO] - Training Epoch: 2/10, step 32/574 completed (loss: 1.734851360321045, acc: 0.5185185074806213)
[2024-11-13 05:01:21,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:21,761][root][INFO] - Training Epoch: 2/10, step 33/574 completed (loss: 1.6229668855667114, acc: 0.52173912525177)
[2024-11-13 05:01:21,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:22,092][root][INFO] - Training Epoch: 2/10, step 34/574 completed (loss: 2.2057855129241943, acc: 0.40336135029792786)
[2024-11-13 05:01:22,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:22,365][root][INFO] - Training Epoch: 2/10, step 35/574 completed (loss: 1.913688063621521, acc: 0.4754098355770111)
[2024-11-13 05:01:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:22,712][root][INFO] - Training Epoch: 2/10, step 36/574 completed (loss: 2.0836141109466553, acc: 0.3650793731212616)
[2024-11-13 05:01:22,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:23,027][root][INFO] - Training Epoch: 2/10, step 37/574 completed (loss: 2.3425261974334717, acc: 0.4067796468734741)
[2024-11-13 05:01:23,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:23,346][root][INFO] - Training Epoch: 2/10, step 38/574 completed (loss: 1.6453802585601807, acc: 0.49425286054611206)
[2024-11-13 05:01:23,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:23,646][root][INFO] - Training Epoch: 2/10, step 39/574 completed (loss: 1.1324368715286255, acc: 0.7142857313156128)
[2024-11-13 05:01:23,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:23,909][root][INFO] - Training Epoch: 2/10, step 40/574 completed (loss: 2.3200995922088623, acc: 0.38461539149284363)
[2024-11-13 05:01:24,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:24,247][root][INFO] - Training Epoch: 2/10, step 41/574 completed (loss: 2.8394980430603027, acc: 0.2567567527294159)
[2024-11-13 05:01:24,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:24,585][root][INFO] - Training Epoch: 2/10, step 42/574 completed (loss: 2.2308030128479004, acc: 0.4307692348957062)
[2024-11-13 05:01:24,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:25,005][root][INFO] - Training Epoch: 2/10, step 43/574 completed (loss: 2.492884397506714, acc: 0.3232323229312897)
[2024-11-13 05:01:25,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:25,417][root][INFO] - Training Epoch: 2/10, step 44/574 completed (loss: 2.151151657104492, acc: 0.42268040776252747)
[2024-11-13 05:01:25,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:25,817][root][INFO] - Training Epoch: 2/10, step 45/574 completed (loss: 2.2912607192993164, acc: 0.4264705777168274)
[2024-11-13 05:01:25,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:26,156][root][INFO] - Training Epoch: 2/10, step 46/574 completed (loss: 0.9987008571624756, acc: 0.7692307829856873)
[2024-11-13 05:01:26,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:26,473][root][INFO] - Training Epoch: 2/10, step 47/574 completed (loss: 0.9482306838035583, acc: 0.7777777910232544)
[2024-11-13 05:01:26,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:26,767][root][INFO] - Training Epoch: 2/10, step 48/574 completed (loss: 1.4066718816757202, acc: 0.6071428656578064)
[2024-11-13 05:01:26,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:27,131][root][INFO] - Training Epoch: 2/10, step 49/574 completed (loss: 1.265472173690796, acc: 0.6666666865348816)
[2024-11-13 05:01:27,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:27,487][root][INFO] - Training Epoch: 2/10, step 50/574 completed (loss: 1.746702790260315, acc: 0.6140350699424744)
[2024-11-13 05:01:27,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:27,819][root][INFO] - Training Epoch: 2/10, step 51/574 completed (loss: 1.7214759588241577, acc: 0.5555555820465088)
[2024-11-13 05:01:27,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:28,171][root][INFO] - Training Epoch: 2/10, step 52/574 completed (loss: 2.1973342895507812, acc: 0.4225352108478546)
[2024-11-13 05:01:28,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:28,630][root][INFO] - Training Epoch: 2/10, step 53/574 completed (loss: 2.52717661857605, acc: 0.4399999976158142)
[2024-11-13 05:01:28,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:28,941][root][INFO] - Training Epoch: 2/10, step 54/574 completed (loss: 1.350800633430481, acc: 0.6486486196517944)
[2024-11-13 05:01:29,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:29,288][root][INFO] - Training Epoch: 2/10, step 55/574 completed (loss: 0.7438623905181885, acc: 0.807692289352417)
[2024-11-13 05:01:30,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:32,366][root][INFO] - Training Epoch: 2/10, step 56/574 completed (loss: 2.039968729019165, acc: 0.4948805570602417)
[2024-11-13 05:01:32,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:33,787][root][INFO] - Training Epoch: 2/10, step 57/574 completed (loss: 2.4890859127044678, acc: 0.379084974527359)
[2024-11-13 05:01:33,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:34,408][root][INFO] - Training Epoch: 2/10, step 58/574 completed (loss: 2.117436170578003, acc: 0.4545454680919647)
[2024-11-13 05:01:34,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:34,978][root][INFO] - Training Epoch: 2/10, step 59/574 completed (loss: 2.4073662757873535, acc: 0.3602941036224365)
[2024-11-13 05:01:35,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:35,554][root][INFO] - Training Epoch: 2/10, step 60/574 completed (loss: 2.4624407291412354, acc: 0.3188405930995941)
[2024-11-13 05:01:35,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:36,029][root][INFO] - Training Epoch: 2/10, step 61/574 completed (loss: 1.8177690505981445, acc: 0.550000011920929)
[2024-11-13 05:01:36,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:36,407][root][INFO] - Training Epoch: 2/10, step 62/574 completed (loss: 1.5025595426559448, acc: 0.5588235259056091)
[2024-11-13 05:01:36,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:36,845][root][INFO] - Training Epoch: 2/10, step 63/574 completed (loss: 2.0045042037963867, acc: 0.3888888955116272)
[2024-11-13 05:01:36,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:37,243][root][INFO] - Training Epoch: 2/10, step 64/574 completed (loss: 1.8788172006607056, acc: 0.515625)
[2024-11-13 05:01:37,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:37,588][root][INFO] - Training Epoch: 2/10, step 65/574 completed (loss: 0.9191226959228516, acc: 0.7586206793785095)
[2024-11-13 05:01:37,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:37,997][root][INFO] - Training Epoch: 2/10, step 66/574 completed (loss: 2.426701068878174, acc: 0.4107142984867096)
[2024-11-13 05:01:38,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:38,402][root][INFO] - Training Epoch: 2/10, step 67/574 completed (loss: 2.250925302505493, acc: 0.4333333373069763)
[2024-11-13 05:01:38,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:38,782][root][INFO] - Training Epoch: 2/10, step 68/574 completed (loss: 1.0242223739624023, acc: 0.6800000071525574)
[2024-11-13 05:01:38,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:39,150][root][INFO] - Training Epoch: 2/10, step 69/574 completed (loss: 1.3496463298797607, acc: 0.7222222089767456)
[2024-11-13 05:01:39,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:39,461][root][INFO] - Training Epoch: 2/10, step 70/574 completed (loss: 1.520291805267334, acc: 0.6060606241226196)
[2024-11-13 05:01:39,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:39,769][root][INFO] - Training Epoch: 2/10, step 71/574 completed (loss: 2.2487401962280273, acc: 0.44117647409439087)
[2024-11-13 05:01:39,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:40,091][root][INFO] - Training Epoch: 2/10, step 72/574 completed (loss: 2.1098837852478027, acc: 0.4523809552192688)
[2024-11-13 05:01:40,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:40,465][root][INFO] - Training Epoch: 2/10, step 73/574 completed (loss: 2.385310173034668, acc: 0.34358975291252136)
[2024-11-13 05:01:40,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:40,763][root][INFO] - Training Epoch: 2/10, step 74/574 completed (loss: 2.1545896530151367, acc: 0.44897958636283875)
[2024-11-13 05:01:40,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:41,030][root][INFO] - Training Epoch: 2/10, step 75/574 completed (loss: 2.5803062915802, acc: 0.2985074520111084)
[2024-11-13 05:01:41,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:41,411][root][INFO] - Training Epoch: 2/10, step 76/574 completed (loss: 2.322608232498169, acc: 0.3832116723060608)
[2024-11-13 05:01:41,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:41,705][root][INFO] - Training Epoch: 2/10, step 77/574 completed (loss: 0.5866521596908569, acc: 0.8095238208770752)
[2024-11-13 05:01:41,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:41,991][root][INFO] - Training Epoch: 2/10, step 78/574 completed (loss: 0.6555071473121643, acc: 0.875)
[2024-11-13 05:01:42,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:42,292][root][INFO] - Training Epoch: 2/10, step 79/574 completed (loss: 1.2735928297042847, acc: 0.6060606241226196)
[2024-11-13 05:01:42,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:42,584][root][INFO] - Training Epoch: 2/10, step 80/574 completed (loss: 1.140893578529358, acc: 0.6538461446762085)
[2024-11-13 05:01:42,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:42,904][root][INFO] - Training Epoch: 2/10, step 81/574 completed (loss: 1.9828709363937378, acc: 0.4615384638309479)
[2024-11-13 05:01:42,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:43,152][root][INFO] - Training Epoch: 2/10, step 82/574 completed (loss: 2.396730661392212, acc: 0.42307692766189575)
[2024-11-13 05:01:43,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:43,534][root][INFO] - Training Epoch: 2/10, step 83/574 completed (loss: 1.7779799699783325, acc: 0.4375)
[2024-11-13 05:01:43,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:43,888][root][INFO] - Training Epoch: 2/10, step 84/574 completed (loss: 2.2446467876434326, acc: 0.4637681245803833)
[2024-11-13 05:01:43,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:44,194][root][INFO] - Training Epoch: 2/10, step 85/574 completed (loss: 1.6115885972976685, acc: 0.5400000214576721)
[2024-11-13 05:01:44,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:44,556][root][INFO] - Training Epoch: 2/10, step 86/574 completed (loss: 2.0213634967803955, acc: 0.5652173757553101)
[2024-11-13 05:01:44,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:45,027][root][INFO] - Training Epoch: 2/10, step 87/574 completed (loss: 2.6164989471435547, acc: 0.3400000035762787)
[2024-11-13 05:01:45,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:45,376][root][INFO] - Training Epoch: 2/10, step 88/574 completed (loss: 1.9362766742706299, acc: 0.5048543810844421)
[2024-11-13 05:01:45,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:46,525][root][INFO] - Training Epoch: 2/10, step 89/574 completed (loss: 1.9699177742004395, acc: 0.5145630836486816)
[2024-11-13 05:01:46,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:47,393][root][INFO] - Training Epoch: 2/10, step 90/574 completed (loss: 2.1324751377105713, acc: 0.4032258093357086)
[2024-11-13 05:01:47,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:48,202][root][INFO] - Training Epoch: 2/10, step 91/574 completed (loss: 1.8906080722808838, acc: 0.5344827771186829)
[2024-11-13 05:01:48,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:48,945][root][INFO] - Training Epoch: 2/10, step 92/574 completed (loss: 1.6082887649536133, acc: 0.5368421077728271)
[2024-11-13 05:01:49,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:49,935][root][INFO] - Training Epoch: 2/10, step 93/574 completed (loss: 2.4237630367279053, acc: 0.3663366436958313)
[2024-11-13 05:01:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:50,247][root][INFO] - Training Epoch: 2/10, step 94/574 completed (loss: 2.4274353981018066, acc: 0.35483869910240173)
[2024-11-13 05:01:50,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:50,602][root][INFO] - Training Epoch: 2/10, step 95/574 completed (loss: 2.5305638313293457, acc: 0.3188405930995941)
[2024-11-13 05:01:50,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:51,019][root][INFO] - Training Epoch: 2/10, step 96/574 completed (loss: 2.6619529724121094, acc: 0.2689075767993927)
[2024-11-13 05:01:51,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:51,389][root][INFO] - Training Epoch: 2/10, step 97/574 completed (loss: 2.6756770610809326, acc: 0.25)
[2024-11-13 05:01:51,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:51,781][root][INFO] - Training Epoch: 2/10, step 98/574 completed (loss: 2.550483465194702, acc: 0.37226277589797974)
[2024-11-13 05:01:51,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:52,108][root][INFO] - Training Epoch: 2/10, step 99/574 completed (loss: 2.5174286365509033, acc: 0.3731343150138855)
[2024-11-13 05:01:52,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:52,391][root][INFO] - Training Epoch: 2/10, step 100/574 completed (loss: 1.4906796216964722, acc: 0.699999988079071)
[2024-11-13 05:01:52,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:52,648][root][INFO] - Training Epoch: 2/10, step 101/574 completed (loss: 1.0070428848266602, acc: 0.7272727489471436)
[2024-11-13 05:01:52,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:52,889][root][INFO] - Training Epoch: 2/10, step 102/574 completed (loss: 1.147355318069458, acc: 0.5652173757553101)
[2024-11-13 05:01:52,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:53,111][root][INFO] - Training Epoch: 2/10, step 103/574 completed (loss: 1.8498663902282715, acc: 0.40909090638160706)
[2024-11-13 05:01:53,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:53,383][root][INFO] - Training Epoch: 2/10, step 104/574 completed (loss: 2.091768264770508, acc: 0.4482758641242981)
[2024-11-13 05:01:53,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:53,681][root][INFO] - Training Epoch: 2/10, step 105/574 completed (loss: 1.9297477006912231, acc: 0.4883720874786377)
[2024-11-13 05:01:53,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:54,023][root][INFO] - Training Epoch: 2/10, step 106/574 completed (loss: 1.3775769472122192, acc: 0.6399999856948853)
[2024-11-13 05:01:54,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:54,347][root][INFO] - Training Epoch: 2/10, step 107/574 completed (loss: 0.5901420712471008, acc: 0.7647058963775635)
[2024-11-13 05:01:54,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:54,664][root][INFO] - Training Epoch: 2/10, step 108/574 completed (loss: 0.5256766080856323, acc: 0.8461538553237915)
[2024-11-13 05:01:54,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:54,946][root][INFO] - Training Epoch: 2/10, step 109/574 completed (loss: 1.7454694509506226, acc: 0.5)
[2024-11-13 05:01:55,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:55,269][root][INFO] - Training Epoch: 2/10, step 110/574 completed (loss: 2.042297124862671, acc: 0.4769230782985687)
[2024-11-13 05:01:55,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:55,686][root][INFO] - Training Epoch: 2/10, step 111/574 completed (loss: 2.0135858058929443, acc: 0.4912280738353729)
[2024-11-13 05:01:55,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:56,033][root][INFO] - Training Epoch: 2/10, step 112/574 completed (loss: 1.944965124130249, acc: 0.42105263471603394)
[2024-11-13 05:01:56,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:56,426][root][INFO] - Training Epoch: 2/10, step 113/574 completed (loss: 2.148587942123413, acc: 0.43589743971824646)
[2024-11-13 05:01:56,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:56,811][root][INFO] - Training Epoch: 2/10, step 114/574 completed (loss: 1.6147258281707764, acc: 0.6938775777816772)
[2024-11-13 05:01:56,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:57,153][root][INFO] - Training Epoch: 2/10, step 115/574 completed (loss: 0.6122086048126221, acc: 0.8181818127632141)
[2024-11-13 05:01:57,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:57,480][root][INFO] - Training Epoch: 2/10, step 116/574 completed (loss: 2.165335178375244, acc: 0.4444444477558136)
[2024-11-13 05:01:57,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:57,792][root][INFO] - Training Epoch: 2/10, step 117/574 completed (loss: 2.276566743850708, acc: 0.46341463923454285)
[2024-11-13 05:01:57,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:58,142][root][INFO] - Training Epoch: 2/10, step 118/574 completed (loss: 1.8343993425369263, acc: 0.5645161271095276)
[2024-11-13 05:01:58,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:59,025][root][INFO] - Training Epoch: 2/10, step 119/574 completed (loss: 2.1785202026367188, acc: 0.4220532178878784)
[2024-11-13 05:01:59,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:59,331][root][INFO] - Training Epoch: 2/10, step 120/574 completed (loss: 1.7788989543914795, acc: 0.4933333396911621)
[2024-11-13 05:01:59,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:01:59,739][root][INFO] - Training Epoch: 2/10, step 121/574 completed (loss: 1.6139929294586182, acc: 0.5961538553237915)
[2024-11-13 05:01:59,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:00,064][root][INFO] - Training Epoch: 2/10, step 122/574 completed (loss: 0.9022502899169922, acc: 0.8333333134651184)
[2024-11-13 05:02:00,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:00,391][root][INFO] - Training Epoch: 2/10, step 123/574 completed (loss: 1.7333937883377075, acc: 0.5263158082962036)
[2024-11-13 05:02:00,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:00,757][root][INFO] - Training Epoch: 2/10, step 124/574 completed (loss: 2.2609024047851562, acc: 0.3742331266403198)
[2024-11-13 05:02:00,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:01,125][root][INFO] - Training Epoch: 2/10, step 125/574 completed (loss: 1.9076834917068481, acc: 0.4930555522441864)
[2024-11-13 05:02:01,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:01,484][root][INFO] - Training Epoch: 2/10, step 126/574 completed (loss: 2.4210386276245117, acc: 0.3166666626930237)
[2024-11-13 05:02:01,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:01,825][root][INFO] - Training Epoch: 2/10, step 127/574 completed (loss: 2.433091640472412, acc: 0.3214285671710968)
[2024-11-13 05:02:01,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:02,167][root][INFO] - Training Epoch: 2/10, step 128/574 completed (loss: 2.1885852813720703, acc: 0.40512821078300476)
[2024-11-13 05:02:02,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:02,596][root][INFO] - Training Epoch: 2/10, step 129/574 completed (loss: 1.9886596202850342, acc: 0.4852941036224365)
[2024-11-13 05:02:02,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:02,943][root][INFO] - Training Epoch: 2/10, step 130/574 completed (loss: 1.130431890487671, acc: 0.6538461446762085)
[2024-11-13 05:02:03,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:03,240][root][INFO] - Training Epoch: 2/10, step 131/574 completed (loss: 0.9189947247505188, acc: 0.739130437374115)
[2024-11-13 05:02:03,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:03,503][root][INFO] - Training Epoch: 2/10, step 132/574 completed (loss: 1.6783568859100342, acc: 0.4375)
[2024-11-13 05:02:03,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:03,753][root][INFO] - Training Epoch: 2/10, step 133/574 completed (loss: 1.9069371223449707, acc: 0.52173912525177)
[2024-11-13 05:02:03,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:04,017][root][INFO] - Training Epoch: 2/10, step 134/574 completed (loss: 1.4391487836837769, acc: 0.6285714507102966)
[2024-11-13 05:02:04,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:04,355][root][INFO] - Training Epoch: 2/10, step 135/574 completed (loss: 1.373351812362671, acc: 0.5769230723381042)
[2024-11-13 05:02:04,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:04,646][root][INFO] - Training Epoch: 2/10, step 136/574 completed (loss: 2.1976070404052734, acc: 0.3333333432674408)
[2024-11-13 05:02:04,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:04,894][root][INFO] - Training Epoch: 2/10, step 137/574 completed (loss: 1.4456719160079956, acc: 0.5333333611488342)
[2024-11-13 05:02:04,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:05,137][root][INFO] - Training Epoch: 2/10, step 138/574 completed (loss: 1.6726412773132324, acc: 0.52173912525177)
[2024-11-13 05:02:05,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:05,385][root][INFO] - Training Epoch: 2/10, step 139/574 completed (loss: 2.3789045810699463, acc: 0.523809552192688)
[2024-11-13 05:02:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:05,697][root][INFO] - Training Epoch: 2/10, step 140/574 completed (loss: 2.1671946048736572, acc: 0.42307692766189575)
[2024-11-13 05:02:06,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:06,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:07,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:07,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:07,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:08,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:08,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:09,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:09,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:09,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:10,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:10,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:10,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:11,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:11,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:12,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:12,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:12,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:13,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:13,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:13,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:14,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:15,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:15,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:16,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:16,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:16,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:17,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:17,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:17,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:18,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:18,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:19,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:19,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:20,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:20,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:20,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:21,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:21,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:21,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:22,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:22,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:22,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:23,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:23,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:24,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:25,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:25,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:25,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:26,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:26,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:26,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:27,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:27,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:27,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:28,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:28,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:29,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:29,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:30,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:30,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:30,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:30,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:31,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:31,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:32,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:32,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:33,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:33,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:33,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:34,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:34,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:34,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:35,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:35,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:35,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:36,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:36,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:36,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:37,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:38,046][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(7.2970, device='cuda:0') eval_epoch_loss=tensor(1.9875, device='cuda:0') eval_epoch_acc=tensor(0.4596, device='cuda:0')
[2024-11-13 05:02:38,049][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:02:38,050][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:02:38,386][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_141_loss_1.9874569177627563/model.pt
[2024-11-13 05:02:38,393][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:02:38,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:38,721][root][INFO] - Training Epoch: 2/10, step 141/574 completed (loss: 2.6867642402648926, acc: 0.29032257199287415)
[2024-11-13 05:02:38,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:39,049][root][INFO] - Training Epoch: 2/10, step 142/574 completed (loss: 2.3135504722595215, acc: 0.4324324429035187)
[2024-11-13 05:02:39,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:39,605][root][INFO] - Training Epoch: 2/10, step 143/574 completed (loss: 2.180288553237915, acc: 0.3684210479259491)
[2024-11-13 05:02:39,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:39,990][root][INFO] - Training Epoch: 2/10, step 144/574 completed (loss: 1.9053176641464233, acc: 0.4776119291782379)
[2024-11-13 05:02:40,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:40,404][root][INFO] - Training Epoch: 2/10, step 145/574 completed (loss: 2.38535213470459, acc: 0.3163265287876129)
[2024-11-13 05:02:40,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:40,871][root][INFO] - Training Epoch: 2/10, step 146/574 completed (loss: 2.1401114463806152, acc: 0.3723404109477997)
[2024-11-13 05:02:41,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:41,295][root][INFO] - Training Epoch: 2/10, step 147/574 completed (loss: 1.8734006881713867, acc: 0.5285714268684387)
[2024-11-13 05:02:41,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:41,650][root][INFO] - Training Epoch: 2/10, step 148/574 completed (loss: 2.2343711853027344, acc: 0.4642857015132904)
[2024-11-13 05:02:41,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:41,997][root][INFO] - Training Epoch: 2/10, step 149/574 completed (loss: 1.6764813661575317, acc: 0.52173912525177)
[2024-11-13 05:02:42,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:42,305][root][INFO] - Training Epoch: 2/10, step 150/574 completed (loss: 1.9959882497787476, acc: 0.4137931168079376)
[2024-11-13 05:02:42,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:42,621][root][INFO] - Training Epoch: 2/10, step 151/574 completed (loss: 2.203676700592041, acc: 0.5)
[2024-11-13 05:02:42,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:42,942][root][INFO] - Training Epoch: 2/10, step 152/574 completed (loss: 2.02431321144104, acc: 0.4576271176338196)
[2024-11-13 05:02:43,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:43,265][root][INFO] - Training Epoch: 2/10, step 153/574 completed (loss: 2.533419609069824, acc: 0.3684210479259491)
[2024-11-13 05:02:43,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:43,610][root][INFO] - Training Epoch: 2/10, step 154/574 completed (loss: 1.971343755722046, acc: 0.5)
[2024-11-13 05:02:43,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:43,968][root][INFO] - Training Epoch: 2/10, step 155/574 completed (loss: 1.6638023853302002, acc: 0.6071428656578064)
[2024-11-13 05:02:44,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:44,307][root][INFO] - Training Epoch: 2/10, step 156/574 completed (loss: 1.5004761219024658, acc: 0.5652173757553101)
[2024-11-13 05:02:44,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:44,699][root][INFO] - Training Epoch: 2/10, step 157/574 completed (loss: 2.343501091003418, acc: 0.3684210479259491)
[2024-11-13 05:02:45,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:46,480][root][INFO] - Training Epoch: 2/10, step 158/574 completed (loss: 1.8045520782470703, acc: 0.5135135054588318)
[2024-11-13 05:02:46,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:46,868][root][INFO] - Training Epoch: 2/10, step 159/574 completed (loss: 2.248065233230591, acc: 0.48148149251937866)
[2024-11-13 05:02:47,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:47,296][root][INFO] - Training Epoch: 2/10, step 160/574 completed (loss: 2.0728306770324707, acc: 0.43023255467414856)
[2024-11-13 05:02:47,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:47,900][root][INFO] - Training Epoch: 2/10, step 161/574 completed (loss: 1.8791680335998535, acc: 0.47058823704719543)
[2024-11-13 05:02:48,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:48,458][root][INFO] - Training Epoch: 2/10, step 162/574 completed (loss: 2.167069911956787, acc: 0.449438214302063)
[2024-11-13 05:02:48,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:48,731][root][INFO] - Training Epoch: 2/10, step 163/574 completed (loss: 1.945295810699463, acc: 0.47727271914482117)
[2024-11-13 05:02:48,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:49,042][root][INFO] - Training Epoch: 2/10, step 164/574 completed (loss: 1.6477872133255005, acc: 0.523809552192688)
[2024-11-13 05:02:49,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:49,392][root][INFO] - Training Epoch: 2/10, step 165/574 completed (loss: 1.911037802696228, acc: 0.48275861144065857)
[2024-11-13 05:02:49,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:49,824][root][INFO] - Training Epoch: 2/10, step 166/574 completed (loss: 1.58069908618927, acc: 0.5510203838348389)
[2024-11-13 05:02:49,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:50,154][root][INFO] - Training Epoch: 2/10, step 167/574 completed (loss: 1.9885623455047607, acc: 0.41999998688697815)
[2024-11-13 05:02:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:50,629][root][INFO] - Training Epoch: 2/10, step 168/574 completed (loss: 1.8833999633789062, acc: 0.5138888955116272)
[2024-11-13 05:02:50,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:51,043][root][INFO] - Training Epoch: 2/10, step 169/574 completed (loss: 2.1172962188720703, acc: 0.46078431606292725)
[2024-11-13 05:02:51,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:52,185][root][INFO] - Training Epoch: 2/10, step 170/574 completed (loss: 2.474604845046997, acc: 0.4109589159488678)
[2024-11-13 05:02:52,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:52,476][root][INFO] - Training Epoch: 2/10, step 171/574 completed (loss: 1.1686698198318481, acc: 0.6666666865348816)
[2024-11-13 05:02:52,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:52,811][root][INFO] - Training Epoch: 2/10, step 172/574 completed (loss: 1.0683754682540894, acc: 0.7407407164573669)
[2024-11-13 05:02:52,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:53,127][root][INFO] - Training Epoch: 2/10, step 173/574 completed (loss: 1.6057859659194946, acc: 0.5714285969734192)
[2024-11-13 05:02:53,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:53,684][root][INFO] - Training Epoch: 2/10, step 174/574 completed (loss: 1.9646660089492798, acc: 0.4955752193927765)
[2024-11-13 05:02:53,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:54,069][root][INFO] - Training Epoch: 2/10, step 175/574 completed (loss: 2.0196285247802734, acc: 0.4202898442745209)
[2024-11-13 05:02:54,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:54,412][root][INFO] - Training Epoch: 2/10, step 176/574 completed (loss: 2.031564235687256, acc: 0.39772728085517883)
[2024-11-13 05:02:54,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:55,482][root][INFO] - Training Epoch: 2/10, step 177/574 completed (loss: 2.4650285243988037, acc: 0.3435114622116089)
[2024-11-13 05:02:55,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:56,169][root][INFO] - Training Epoch: 2/10, step 178/574 completed (loss: 2.2924768924713135, acc: 0.3777777850627899)
[2024-11-13 05:02:56,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:56,474][root][INFO] - Training Epoch: 2/10, step 179/574 completed (loss: 1.646676778793335, acc: 0.5409836173057556)
[2024-11-13 05:02:56,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:56,748][root][INFO] - Training Epoch: 2/10, step 180/574 completed (loss: 0.6943523287773132, acc: 0.75)
[2024-11-13 05:02:56,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:57,062][root][INFO] - Training Epoch: 2/10, step 181/574 completed (loss: 1.3794233798980713, acc: 0.6000000238418579)
[2024-11-13 05:02:57,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:57,442][root][INFO] - Training Epoch: 2/10, step 182/574 completed (loss: 1.1901229619979858, acc: 0.6785714030265808)
[2024-11-13 05:02:57,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:57,834][root][INFO] - Training Epoch: 2/10, step 183/574 completed (loss: 2.2020950317382812, acc: 0.40243902802467346)
[2024-11-13 05:02:57,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:58,277][root][INFO] - Training Epoch: 2/10, step 184/574 completed (loss: 2.416316270828247, acc: 0.36253777146339417)
[2024-11-13 05:02:58,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:58,702][root][INFO] - Training Epoch: 2/10, step 185/574 completed (loss: 2.4898571968078613, acc: 0.33141210675239563)
[2024-11-13 05:02:58,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:59,208][root][INFO] - Training Epoch: 2/10, step 186/574 completed (loss: 2.522651195526123, acc: 0.37812501192092896)
[2024-11-13 05:02:59,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:02:59,739][root][INFO] - Training Epoch: 2/10, step 187/574 completed (loss: 2.272773027420044, acc: 0.3808630406856537)
[2024-11-13 05:02:59,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:00,212][root][INFO] - Training Epoch: 2/10, step 188/574 completed (loss: 2.262097120285034, acc: 0.3701067566871643)
[2024-11-13 05:03:00,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:00,525][root][INFO] - Training Epoch: 2/10, step 189/574 completed (loss: 2.397416830062866, acc: 0.5199999809265137)
[2024-11-13 05:03:00,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:01,173][root][INFO] - Training Epoch: 2/10, step 190/574 completed (loss: 2.3224658966064453, acc: 0.41860464215278625)
[2024-11-13 05:03:01,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:02,025][root][INFO] - Training Epoch: 2/10, step 191/574 completed (loss: 2.0821571350097656, acc: 0.5158730149269104)
[2024-11-13 05:03:02,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:03,031][root][INFO] - Training Epoch: 2/10, step 192/574 completed (loss: 2.131214141845703, acc: 0.46212121844291687)
[2024-11-13 05:03:03,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:03,791][root][INFO] - Training Epoch: 2/10, step 193/574 completed (loss: 1.8643656969070435, acc: 0.5411764979362488)
[2024-11-13 05:03:04,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:05,134][root][INFO] - Training Epoch: 2/10, step 194/574 completed (loss: 1.8144632577896118, acc: 0.5308641791343689)
[2024-11-13 05:03:05,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:06,109][root][INFO] - Training Epoch: 2/10, step 195/574 completed (loss: 1.5174494981765747, acc: 0.5645161271095276)
[2024-11-13 05:03:06,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:06,479][root][INFO] - Training Epoch: 2/10, step 196/574 completed (loss: 0.7566646933555603, acc: 0.75)
[2024-11-13 05:03:06,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:06,821][root][INFO] - Training Epoch: 2/10, step 197/574 completed (loss: 2.050663709640503, acc: 0.574999988079071)
[2024-11-13 05:03:06,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:07,135][root][INFO] - Training Epoch: 2/10, step 198/574 completed (loss: 2.1595842838287354, acc: 0.4264705777168274)
[2024-11-13 05:03:07,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:07,537][root][INFO] - Training Epoch: 2/10, step 199/574 completed (loss: 2.1100876331329346, acc: 0.44117647409439087)
[2024-11-13 05:03:07,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:07,892][root][INFO] - Training Epoch: 2/10, step 200/574 completed (loss: 2.374190330505371, acc: 0.3644067943096161)
[2024-11-13 05:03:07,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:08,222][root][INFO] - Training Epoch: 2/10, step 201/574 completed (loss: 2.36556077003479, acc: 0.4253731369972229)
[2024-11-13 05:03:08,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:08,581][root][INFO] - Training Epoch: 2/10, step 202/574 completed (loss: 2.264186143875122, acc: 0.3689320385456085)
[2024-11-13 05:03:08,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:08,935][root][INFO] - Training Epoch: 2/10, step 203/574 completed (loss: 1.9906047582626343, acc: 0.4761904776096344)
[2024-11-13 05:03:09,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:09,238][root][INFO] - Training Epoch: 2/10, step 204/574 completed (loss: 2.0343456268310547, acc: 0.4285714328289032)
[2024-11-13 05:03:09,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:09,569][root][INFO] - Training Epoch: 2/10, step 205/574 completed (loss: 2.246314287185669, acc: 0.4260089695453644)
[2024-11-13 05:03:09,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:09,985][root][INFO] - Training Epoch: 2/10, step 206/574 completed (loss: 2.098907470703125, acc: 0.4881889820098877)
[2024-11-13 05:03:10,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:10,327][root][INFO] - Training Epoch: 2/10, step 207/574 completed (loss: 2.1239452362060547, acc: 0.40086206793785095)
[2024-11-13 05:03:10,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:10,698][root][INFO] - Training Epoch: 2/10, step 208/574 completed (loss: 2.0531766414642334, acc: 0.46014493703842163)
[2024-11-13 05:03:10,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:11,070][root][INFO] - Training Epoch: 2/10, step 209/574 completed (loss: 2.31205153465271, acc: 0.3501945436000824)
[2024-11-13 05:03:11,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:11,447][root][INFO] - Training Epoch: 2/10, step 210/574 completed (loss: 2.3984601497650146, acc: 0.4021739065647125)
[2024-11-13 05:03:11,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:11,793][root][INFO] - Training Epoch: 2/10, step 211/574 completed (loss: 1.4465649127960205, acc: 0.5652173757553101)
[2024-11-13 05:03:11,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:12,139][root][INFO] - Training Epoch: 2/10, step 212/574 completed (loss: 1.7275980710983276, acc: 0.6071428656578064)
[2024-11-13 05:03:12,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:12,533][root][INFO] - Training Epoch: 2/10, step 213/574 completed (loss: 1.4371471405029297, acc: 0.5744680762290955)
[2024-11-13 05:03:12,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:13,288][root][INFO] - Training Epoch: 2/10, step 214/574 completed (loss: 1.8701176643371582, acc: 0.5153846144676208)
[2024-11-13 05:03:13,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:13,665][root][INFO] - Training Epoch: 2/10, step 215/574 completed (loss: 1.7468878030776978, acc: 0.5540540814399719)
[2024-11-13 05:03:13,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:13,988][root][INFO] - Training Epoch: 2/10, step 216/574 completed (loss: 1.7248826026916504, acc: 0.5348837375640869)
[2024-11-13 05:03:14,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:14,666][root][INFO] - Training Epoch: 2/10, step 217/574 completed (loss: 1.8326783180236816, acc: 0.522522509098053)
[2024-11-13 05:03:14,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:15,063][root][INFO] - Training Epoch: 2/10, step 218/574 completed (loss: 1.7204276323318481, acc: 0.5222222208976746)
[2024-11-13 05:03:15,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:15,426][root][INFO] - Training Epoch: 2/10, step 219/574 completed (loss: 0.8158814311027527, acc: 0.7272727489471436)
[2024-11-13 05:03:15,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:15,773][root][INFO] - Training Epoch: 2/10, step 220/574 completed (loss: 0.328875333070755, acc: 0.9259259104728699)
[2024-11-13 05:03:15,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:16,079][root][INFO] - Training Epoch: 2/10, step 221/574 completed (loss: 0.8651207089424133, acc: 0.7200000286102295)
[2024-11-13 05:03:16,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:16,412][root][INFO] - Training Epoch: 2/10, step 222/574 completed (loss: 2.070086717605591, acc: 0.48076921701431274)
[2024-11-13 05:03:16,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:17,376][root][INFO] - Training Epoch: 2/10, step 223/574 completed (loss: 1.777989387512207, acc: 0.5163043737411499)
[2024-11-13 05:03:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:17,931][root][INFO] - Training Epoch: 2/10, step 224/574 completed (loss: 1.9858943223953247, acc: 0.4431818127632141)
[2024-11-13 05:03:18,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:18,380][root][INFO] - Training Epoch: 2/10, step 225/574 completed (loss: 2.175105571746826, acc: 0.41489362716674805)
[2024-11-13 05:03:18,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:18,801][root][INFO] - Training Epoch: 2/10, step 226/574 completed (loss: 1.6021251678466797, acc: 0.5471698045730591)
[2024-11-13 05:03:18,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:19,155][root][INFO] - Training Epoch: 2/10, step 227/574 completed (loss: 1.9166775941848755, acc: 0.5)
[2024-11-13 05:03:19,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:19,488][root][INFO] - Training Epoch: 2/10, step 228/574 completed (loss: 1.470665693283081, acc: 0.6279069781303406)
[2024-11-13 05:03:19,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:19,836][root][INFO] - Training Epoch: 2/10, step 229/574 completed (loss: 1.3703765869140625, acc: 0.6333333253860474)
[2024-11-13 05:03:19,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:20,212][root][INFO] - Training Epoch: 2/10, step 230/574 completed (loss: 2.4206159114837646, acc: 0.4000000059604645)
[2024-11-13 05:03:20,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:20,496][root][INFO] - Training Epoch: 2/10, step 231/574 completed (loss: 1.883577585220337, acc: 0.4888888895511627)
[2024-11-13 05:03:20,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:20,931][root][INFO] - Training Epoch: 2/10, step 232/574 completed (loss: 1.7437793016433716, acc: 0.550000011920929)
[2024-11-13 05:03:21,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:21,426][root][INFO] - Training Epoch: 2/10, step 233/574 completed (loss: 1.87568998336792, acc: 0.536697268486023)
[2024-11-13 05:03:21,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:21,891][root][INFO] - Training Epoch: 2/10, step 234/574 completed (loss: 1.735316276550293, acc: 0.5461538434028625)
[2024-11-13 05:03:21,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:22,183][root][INFO] - Training Epoch: 2/10, step 235/574 completed (loss: 1.4673799276351929, acc: 0.6315789222717285)
[2024-11-13 05:03:22,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:22,494][root][INFO] - Training Epoch: 2/10, step 236/574 completed (loss: 1.3405224084854126, acc: 0.6666666865348816)
[2024-11-13 05:03:22,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:22,813][root][INFO] - Training Epoch: 2/10, step 237/574 completed (loss: 2.9146111011505127, acc: 0.3181818127632141)
[2024-11-13 05:03:22,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:23,193][root][INFO] - Training Epoch: 2/10, step 238/574 completed (loss: 1.6607377529144287, acc: 0.5555555820465088)
[2024-11-13 05:03:23,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:23,498][root][INFO] - Training Epoch: 2/10, step 239/574 completed (loss: 1.581061840057373, acc: 0.6285714507102966)
[2024-11-13 05:03:23,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:23,894][root][INFO] - Training Epoch: 2/10, step 240/574 completed (loss: 1.5919036865234375, acc: 0.5909090638160706)
[2024-11-13 05:03:23,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:24,254][root][INFO] - Training Epoch: 2/10, step 241/574 completed (loss: 1.834140419960022, acc: 0.5227272510528564)
[2024-11-13 05:03:24,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:24,845][root][INFO] - Training Epoch: 2/10, step 242/574 completed (loss: 2.0128238201141357, acc: 0.4193548262119293)
[2024-11-13 05:03:25,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:25,448][root][INFO] - Training Epoch: 2/10, step 243/574 completed (loss: 1.4208165407180786, acc: 0.6136363744735718)
[2024-11-13 05:03:25,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:25,762][root][INFO] - Training Epoch: 2/10, step 244/574 completed (loss: 0.5547491908073425, acc: 0.9047619104385376)
[2024-11-13 05:03:25,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:26,109][root][INFO] - Training Epoch: 2/10, step 245/574 completed (loss: 1.2956892251968384, acc: 0.6538461446762085)
[2024-11-13 05:03:26,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:26,492][root][INFO] - Training Epoch: 2/10, step 246/574 completed (loss: 1.1861850023269653, acc: 0.774193525314331)
[2024-11-13 05:03:26,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:26,822][root][INFO] - Training Epoch: 2/10, step 247/574 completed (loss: 0.8155931234359741, acc: 0.6000000238418579)
[2024-11-13 05:03:26,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:27,183][root][INFO] - Training Epoch: 2/10, step 248/574 completed (loss: 1.350973129272461, acc: 0.5405405163764954)
[2024-11-13 05:03:27,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:27,581][root][INFO] - Training Epoch: 2/10, step 249/574 completed (loss: 1.5233221054077148, acc: 0.5405405163764954)
[2024-11-13 05:03:27,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:27,939][root][INFO] - Training Epoch: 2/10, step 250/574 completed (loss: 1.3934991359710693, acc: 0.6756756901741028)
[2024-11-13 05:03:28,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:28,272][root][INFO] - Training Epoch: 2/10, step 251/574 completed (loss: 1.9461545944213867, acc: 0.529411792755127)
[2024-11-13 05:03:28,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:28,650][root][INFO] - Training Epoch: 2/10, step 252/574 completed (loss: 0.6585772633552551, acc: 0.8536585569381714)
[2024-11-13 05:03:28,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:28,992][root][INFO] - Training Epoch: 2/10, step 253/574 completed (loss: 0.47232890129089355, acc: 0.8799999952316284)
[2024-11-13 05:03:29,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:29,298][root][INFO] - Training Epoch: 2/10, step 254/574 completed (loss: 0.2661791145801544, acc: 0.8799999952316284)
[2024-11-13 05:03:29,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:29,599][root][INFO] - Training Epoch: 2/10, step 255/574 completed (loss: 0.5479915738105774, acc: 0.8387096524238586)
[2024-11-13 05:03:29,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:29,980][root][INFO] - Training Epoch: 2/10, step 256/574 completed (loss: 1.6194266080856323, acc: 0.5263158082962036)
[2024-11-13 05:03:30,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:30,353][root][INFO] - Training Epoch: 2/10, step 257/574 completed (loss: 1.893009901046753, acc: 0.5285714268684387)
[2024-11-13 05:03:30,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:30,703][root][INFO] - Training Epoch: 2/10, step 258/574 completed (loss: 1.4901149272918701, acc: 0.5921052694320679)
[2024-11-13 05:03:30,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:31,325][root][INFO] - Training Epoch: 2/10, step 259/574 completed (loss: 1.9108651876449585, acc: 0.4150943458080292)
[2024-11-13 05:03:31,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:31,978][root][INFO] - Training Epoch: 2/10, step 260/574 completed (loss: 1.8857874870300293, acc: 0.5166666507720947)
[2024-11-13 05:03:32,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:32,320][root][INFO] - Training Epoch: 2/10, step 261/574 completed (loss: 1.3111311197280884, acc: 0.6666666865348816)
[2024-11-13 05:03:32,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:32,735][root][INFO] - Training Epoch: 2/10, step 262/574 completed (loss: 1.8243342638015747, acc: 0.5161290168762207)
[2024-11-13 05:03:32,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:33,057][root][INFO] - Training Epoch: 2/10, step 263/574 completed (loss: 2.8446826934814453, acc: 0.3199999928474426)
[2024-11-13 05:03:33,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:33,381][root][INFO] - Training Epoch: 2/10, step 264/574 completed (loss: 2.165998935699463, acc: 0.4583333432674408)
[2024-11-13 05:03:33,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:34,338][root][INFO] - Training Epoch: 2/10, step 265/574 completed (loss: 2.446848154067993, acc: 0.36000001430511475)
[2024-11-13 05:03:34,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:34,662][root][INFO] - Training Epoch: 2/10, step 266/574 completed (loss: 2.085364580154419, acc: 0.449438214302063)
[2024-11-13 05:03:34,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:35,012][root][INFO] - Training Epoch: 2/10, step 267/574 completed (loss: 2.2353057861328125, acc: 0.45945945382118225)
[2024-11-13 05:03:35,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:35,491][root][INFO] - Training Epoch: 2/10, step 268/574 completed (loss: 1.4695379734039307, acc: 0.6034482717514038)
[2024-11-13 05:03:35,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:35,818][root][INFO] - Training Epoch: 2/10, step 269/574 completed (loss: 1.2387298345565796, acc: 0.7272727489471436)
[2024-11-13 05:03:35,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:36,171][root][INFO] - Training Epoch: 2/10, step 270/574 completed (loss: 0.9611513018608093, acc: 0.6363636255264282)
[2024-11-13 05:03:36,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:36,494][root][INFO] - Training Epoch: 2/10, step 271/574 completed (loss: 0.8282724022865295, acc: 0.75)
[2024-11-13 05:03:36,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:36,814][root][INFO] - Training Epoch: 2/10, step 272/574 completed (loss: 1.1291497945785522, acc: 0.699999988079071)
[2024-11-13 05:03:36,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:37,235][root][INFO] - Training Epoch: 2/10, step 273/574 completed (loss: 1.8944703340530396, acc: 0.46666666865348816)
[2024-11-13 05:03:37,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:37,561][root][INFO] - Training Epoch: 2/10, step 274/574 completed (loss: 1.2097688913345337, acc: 0.65625)
[2024-11-13 05:03:37,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:37,910][root][INFO] - Training Epoch: 2/10, step 275/574 completed (loss: 0.8695305585861206, acc: 0.7666666507720947)
[2024-11-13 05:03:37,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:38,239][root][INFO] - Training Epoch: 2/10, step 276/574 completed (loss: 1.4249978065490723, acc: 0.7586206793785095)
[2024-11-13 05:03:38,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:38,548][root][INFO] - Training Epoch: 2/10, step 277/574 completed (loss: 0.9429118633270264, acc: 0.7200000286102295)
[2024-11-13 05:03:38,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:38,888][root][INFO] - Training Epoch: 2/10, step 278/574 completed (loss: 2.1068570613861084, acc: 0.44680851697921753)
[2024-11-13 05:03:38,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:39,279][root][INFO] - Training Epoch: 2/10, step 279/574 completed (loss: 1.5870203971862793, acc: 0.5833333134651184)
[2024-11-13 05:03:39,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:39,638][root][INFO] - Training Epoch: 2/10, step 280/574 completed (loss: 1.4567561149597168, acc: 0.6590909361839294)
[2024-11-13 05:03:39,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:40,101][root][INFO] - Training Epoch: 2/10, step 281/574 completed (loss: 2.104560375213623, acc: 0.4819277226924896)
[2024-11-13 05:03:40,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:40,464][root][INFO] - Training Epoch: 2/10, step 282/574 completed (loss: 2.0870981216430664, acc: 0.45370370149612427)
[2024-11-13 05:03:40,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:40,753][root][INFO] - Training Epoch: 2/10, step 283/574 completed (loss: 1.962821125984192, acc: 0.42105263471603394)
[2024-11-13 05:03:41,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:42,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:42,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:42,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:43,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:43,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:43,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:43,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:44,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:44,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:45,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:45,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:45,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:46,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:46,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:47,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:47,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:47,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:47,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:48,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:48,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:48,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:49,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:49,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:50,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:50,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:50,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:51,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:51,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:51,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:52,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:52,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:53,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:53,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:53,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:54,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:54,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:55,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:55,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:55,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:56,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:56,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:57,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:57,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:57,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:58,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:58,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:59,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:59,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:03:59,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:00,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:00,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:00,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:01,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:01,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:02,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:02,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:02,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:03,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:03,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:03,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:04,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:04,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:04,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:05,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:05,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:06,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:06,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:06,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:07,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:07,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:07,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:08,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:08,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:08,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:09,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:09,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:09,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:10,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:10,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:11,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:11,754][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(5.4740, device='cuda:0') eval_epoch_loss=tensor(1.7000, device='cuda:0') eval_epoch_acc=tensor(0.5552, device='cuda:0')
[2024-11-13 05:04:11,756][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:04:11,756][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:04:12,066][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_284_loss_1.7000032663345337/model.pt
[2024-11-13 05:04:12,072][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:04:12,072][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.7000032663345337
[2024-11-13 05:04:12,073][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.5552484393119812
[2024-11-13 05:04:12,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:12,468][root][INFO] - Training Epoch: 2/10, step 284/574 completed (loss: 1.708928108215332, acc: 0.44117647409439087)
[2024-11-13 05:04:12,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:12,804][root][INFO] - Training Epoch: 2/10, step 285/574 completed (loss: 1.7401632070541382, acc: 0.5)
[2024-11-13 05:04:12,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:13,158][root][INFO] - Training Epoch: 2/10, step 286/574 completed (loss: 2.0098392963409424, acc: 0.40625)
[2024-11-13 05:04:13,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:13,597][root][INFO] - Training Epoch: 2/10, step 287/574 completed (loss: 2.302933931350708, acc: 0.36800000071525574)
[2024-11-13 05:04:13,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:14,019][root][INFO] - Training Epoch: 2/10, step 288/574 completed (loss: 1.807399868965149, acc: 0.5604395866394043)
[2024-11-13 05:04:14,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:14,393][root][INFO] - Training Epoch: 2/10, step 289/574 completed (loss: 2.264439344406128, acc: 0.3913043439388275)
[2024-11-13 05:04:14,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:14,771][root][INFO] - Training Epoch: 2/10, step 290/574 completed (loss: 2.437822103500366, acc: 0.37628865242004395)
[2024-11-13 05:04:14,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:15,094][root][INFO] - Training Epoch: 2/10, step 291/574 completed (loss: 0.5354490876197815, acc: 0.7727272510528564)
[2024-11-13 05:04:15,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:15,461][root][INFO] - Training Epoch: 2/10, step 292/574 completed (loss: 1.8527612686157227, acc: 0.5)
[2024-11-13 05:04:15,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:15,881][root][INFO] - Training Epoch: 2/10, step 293/574 completed (loss: 1.4524165391921997, acc: 0.6206896305084229)
[2024-11-13 05:04:16,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:16,375][root][INFO] - Training Epoch: 2/10, step 294/574 completed (loss: 1.3234272003173828, acc: 0.6909090876579285)
[2024-11-13 05:04:16,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:16,929][root][INFO] - Training Epoch: 2/10, step 295/574 completed (loss: 1.7696104049682617, acc: 0.5463917255401611)
[2024-11-13 05:04:17,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:17,255][root][INFO] - Training Epoch: 2/10, step 296/574 completed (loss: 2.071979284286499, acc: 0.4655172526836395)
[2024-11-13 05:04:17,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:17,596][root][INFO] - Training Epoch: 2/10, step 297/574 completed (loss: 1.4302011728286743, acc: 0.7407407164573669)
[2024-11-13 05:04:17,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:17,931][root][INFO] - Training Epoch: 2/10, step 298/574 completed (loss: 1.7998522520065308, acc: 0.5526315569877625)
[2024-11-13 05:04:18,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:18,217][root][INFO] - Training Epoch: 2/10, step 299/574 completed (loss: 1.6519453525543213, acc: 0.6071428656578064)
[2024-11-13 05:04:18,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:18,571][root][INFO] - Training Epoch: 2/10, step 300/574 completed (loss: 1.4357733726501465, acc: 0.59375)
[2024-11-13 05:04:18,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:18,921][root][INFO] - Training Epoch: 2/10, step 301/574 completed (loss: 1.8899866342544556, acc: 0.5660377144813538)
[2024-11-13 05:04:19,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:19,227][root][INFO] - Training Epoch: 2/10, step 302/574 completed (loss: 0.8521271347999573, acc: 0.7547169923782349)
[2024-11-13 05:04:19,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:19,572][root][INFO] - Training Epoch: 2/10, step 303/574 completed (loss: 1.0716519355773926, acc: 0.7647058963775635)
[2024-11-13 05:04:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:19,869][root][INFO] - Training Epoch: 2/10, step 304/574 completed (loss: 2.0430235862731934, acc: 0.40625)
[2024-11-13 05:04:19,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:20,219][root][INFO] - Training Epoch: 2/10, step 305/574 completed (loss: 1.2380980253219604, acc: 0.6721311211585999)
[2024-11-13 05:04:20,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:20,618][root][INFO] - Training Epoch: 2/10, step 306/574 completed (loss: 0.6717784404754639, acc: 0.8999999761581421)
[2024-11-13 05:04:20,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:20,946][root][INFO] - Training Epoch: 2/10, step 307/574 completed (loss: 0.16972145438194275, acc: 0.9473684430122375)
[2024-11-13 05:04:21,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:21,269][root][INFO] - Training Epoch: 2/10, step 308/574 completed (loss: 1.8952395915985107, acc: 0.5362318754196167)
[2024-11-13 05:04:21,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:21,751][root][INFO] - Training Epoch: 2/10, step 309/574 completed (loss: 1.6861939430236816, acc: 0.5833333134651184)
[2024-11-13 05:04:21,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:22,107][root][INFO] - Training Epoch: 2/10, step 310/574 completed (loss: 1.4551101922988892, acc: 0.5783132314682007)
[2024-11-13 05:04:22,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:22,506][root][INFO] - Training Epoch: 2/10, step 311/574 completed (loss: 1.98277747631073, acc: 0.4615384638309479)
[2024-11-13 05:04:22,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:22,919][root][INFO] - Training Epoch: 2/10, step 312/574 completed (loss: 2.092177629470825, acc: 0.44897958636283875)
[2024-11-13 05:04:23,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:23,296][root][INFO] - Training Epoch: 2/10, step 313/574 completed (loss: 0.2636057734489441, acc: 0.9583333134651184)
[2024-11-13 05:04:23,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:23,616][root][INFO] - Training Epoch: 2/10, step 314/574 completed (loss: 0.9139449596405029, acc: 0.7916666865348816)
[2024-11-13 05:04:23,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:23,994][root][INFO] - Training Epoch: 2/10, step 315/574 completed (loss: 0.9262082576751709, acc: 0.7419354915618896)
[2024-11-13 05:04:24,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:24,316][root][INFO] - Training Epoch: 2/10, step 316/574 completed (loss: 1.0517003536224365, acc: 0.7096773982048035)
[2024-11-13 05:04:24,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:24,729][root][INFO] - Training Epoch: 2/10, step 317/574 completed (loss: 1.3471912145614624, acc: 0.641791045665741)
[2024-11-13 05:04:24,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:25,129][root][INFO] - Training Epoch: 2/10, step 318/574 completed (loss: 1.2814666032791138, acc: 0.625)
[2024-11-13 05:04:25,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:25,464][root][INFO] - Training Epoch: 2/10, step 319/574 completed (loss: 1.632666826248169, acc: 0.4888888895511627)
[2024-11-13 05:04:25,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:25,782][root][INFO] - Training Epoch: 2/10, step 320/574 completed (loss: 1.3206545114517212, acc: 0.6612903475761414)
[2024-11-13 05:04:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:26,122][root][INFO] - Training Epoch: 2/10, step 321/574 completed (loss: 0.736125111579895, acc: 0.7599999904632568)
[2024-11-13 05:04:26,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:26,428][root][INFO] - Training Epoch: 2/10, step 322/574 completed (loss: 2.5211782455444336, acc: 0.29629629850387573)
[2024-11-13 05:04:26,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:26,787][root][INFO] - Training Epoch: 2/10, step 323/574 completed (loss: 3.072352409362793, acc: 0.20000000298023224)
[2024-11-13 05:04:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:27,162][root][INFO] - Training Epoch: 2/10, step 324/574 completed (loss: 2.376757860183716, acc: 0.28205129504203796)
[2024-11-13 05:04:27,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:27,493][root][INFO] - Training Epoch: 2/10, step 325/574 completed (loss: 2.695971727371216, acc: 0.3414634168148041)
[2024-11-13 05:04:27,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:27,794][root][INFO] - Training Epoch: 2/10, step 326/574 completed (loss: 2.1338939666748047, acc: 0.4736842215061188)
[2024-11-13 05:04:27,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:28,102][root][INFO] - Training Epoch: 2/10, step 327/574 completed (loss: 1.2949614524841309, acc: 0.5789473652839661)
[2024-11-13 05:04:28,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:28,447][root][INFO] - Training Epoch: 2/10, step 328/574 completed (loss: 0.6424914002418518, acc: 0.8214285969734192)
[2024-11-13 05:04:28,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:28,775][root][INFO] - Training Epoch: 2/10, step 329/574 completed (loss: 1.5398979187011719, acc: 0.5555555820465088)
[2024-11-13 05:04:28,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:29,080][root][INFO] - Training Epoch: 2/10, step 330/574 completed (loss: 0.605732262134552, acc: 0.9375)
[2024-11-13 05:04:29,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:29,471][root][INFO] - Training Epoch: 2/10, step 331/574 completed (loss: 1.7633291482925415, acc: 0.5322580933570862)
[2024-11-13 05:04:29,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:29,879][root][INFO] - Training Epoch: 2/10, step 332/574 completed (loss: 1.3988062143325806, acc: 0.5964912176132202)
[2024-11-13 05:04:29,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:30,197][root][INFO] - Training Epoch: 2/10, step 333/574 completed (loss: 1.8460490703582764, acc: 0.5)
[2024-11-13 05:04:30,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:30,536][root][INFO] - Training Epoch: 2/10, step 334/574 completed (loss: 0.9903832077980042, acc: 0.6333333253860474)
[2024-11-13 05:04:30,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:30,882][root][INFO] - Training Epoch: 2/10, step 335/574 completed (loss: 1.6436171531677246, acc: 0.42105263471603394)
[2024-11-13 05:04:30,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:31,238][root][INFO] - Training Epoch: 2/10, step 336/574 completed (loss: 1.8734116554260254, acc: 0.46000000834465027)
[2024-11-13 05:04:31,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:31,590][root][INFO] - Training Epoch: 2/10, step 337/574 completed (loss: 2.1142826080322266, acc: 0.4597701132297516)
[2024-11-13 05:04:31,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:31,975][root][INFO] - Training Epoch: 2/10, step 338/574 completed (loss: 2.4193196296691895, acc: 0.38297873735427856)
[2024-11-13 05:04:32,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:32,306][root][INFO] - Training Epoch: 2/10, step 339/574 completed (loss: 2.2580971717834473, acc: 0.42168673872947693)
[2024-11-13 05:04:32,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:32,606][root][INFO] - Training Epoch: 2/10, step 340/574 completed (loss: 0.9306266903877258, acc: 0.739130437374115)
[2024-11-13 05:04:32,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:32,943][root][INFO] - Training Epoch: 2/10, step 341/574 completed (loss: 1.5287901163101196, acc: 0.6410256624221802)
[2024-11-13 05:04:33,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:33,300][root][INFO] - Training Epoch: 2/10, step 342/574 completed (loss: 2.2365176677703857, acc: 0.46987950801849365)
[2024-11-13 05:04:33,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:33,688][root][INFO] - Training Epoch: 2/10, step 343/574 completed (loss: 1.4821362495422363, acc: 0.5471698045730591)
[2024-11-13 05:04:33,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:34,053][root][INFO] - Training Epoch: 2/10, step 344/574 completed (loss: 1.6132718324661255, acc: 0.5696202516555786)
[2024-11-13 05:04:34,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:34,344][root][INFO] - Training Epoch: 2/10, step 345/574 completed (loss: 1.370435118675232, acc: 0.6078431606292725)
[2024-11-13 05:04:34,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:34,652][root][INFO] - Training Epoch: 2/10, step 346/574 completed (loss: 2.1854796409606934, acc: 0.447761207818985)
[2024-11-13 05:04:34,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:35,003][root][INFO] - Training Epoch: 2/10, step 347/574 completed (loss: 0.4899898171424866, acc: 0.8999999761581421)
[2024-11-13 05:04:35,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:35,382][root][INFO] - Training Epoch: 2/10, step 348/574 completed (loss: 0.9913123846054077, acc: 0.800000011920929)
[2024-11-13 05:04:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:35,800][root][INFO] - Training Epoch: 2/10, step 349/574 completed (loss: 1.1392202377319336, acc: 0.6666666865348816)
[2024-11-13 05:04:35,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:36,093][root][INFO] - Training Epoch: 2/10, step 350/574 completed (loss: 1.634117841720581, acc: 0.5813953280448914)
[2024-11-13 05:04:36,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:36,423][root][INFO] - Training Epoch: 2/10, step 351/574 completed (loss: 1.6250824928283691, acc: 0.5384615659713745)
[2024-11-13 05:04:36,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:36,855][root][INFO] - Training Epoch: 2/10, step 352/574 completed (loss: 1.9630627632141113, acc: 0.4444444477558136)
[2024-11-13 05:04:36,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:37,188][root][INFO] - Training Epoch: 2/10, step 353/574 completed (loss: 0.48203733563423157, acc: 0.782608687877655)
[2024-11-13 05:04:37,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:37,535][root][INFO] - Training Epoch: 2/10, step 354/574 completed (loss: 2.382923126220703, acc: 0.4615384638309479)
[2024-11-13 05:04:37,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:37,875][root][INFO] - Training Epoch: 2/10, step 355/574 completed (loss: 2.213610887527466, acc: 0.4175824224948883)
[2024-11-13 05:04:38,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:38,390][root][INFO] - Training Epoch: 2/10, step 356/574 completed (loss: 1.7588951587677002, acc: 0.5043478012084961)
[2024-11-13 05:04:38,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:38,724][root][INFO] - Training Epoch: 2/10, step 357/574 completed (loss: 1.8716685771942139, acc: 0.43478259444236755)
[2024-11-13 05:04:38,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:39,005][root][INFO] - Training Epoch: 2/10, step 358/574 completed (loss: 1.9531645774841309, acc: 0.44897958636283875)
[2024-11-13 05:04:39,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:39,289][root][INFO] - Training Epoch: 2/10, step 359/574 completed (loss: 0.25940990447998047, acc: 0.9583333134651184)
[2024-11-13 05:04:39,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:39,611][root][INFO] - Training Epoch: 2/10, step 360/574 completed (loss: 0.8903881907463074, acc: 0.807692289352417)
[2024-11-13 05:04:39,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:39,913][root][INFO] - Training Epoch: 2/10, step 361/574 completed (loss: 1.4887856245040894, acc: 0.5609756112098694)
[2024-11-13 05:04:40,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:40,301][root][INFO] - Training Epoch: 2/10, step 362/574 completed (loss: 1.453805923461914, acc: 0.6000000238418579)
[2024-11-13 05:04:40,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:40,615][root][INFO] - Training Epoch: 2/10, step 363/574 completed (loss: 1.847128987312317, acc: 0.46052631735801697)
[2024-11-13 05:04:40,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:41,000][root][INFO] - Training Epoch: 2/10, step 364/574 completed (loss: 1.3546578884124756, acc: 0.6097561120986938)
[2024-11-13 05:04:41,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:41,307][root][INFO] - Training Epoch: 2/10, step 365/574 completed (loss: 1.2775051593780518, acc: 0.6363636255264282)
[2024-11-13 05:04:41,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:41,625][root][INFO] - Training Epoch: 2/10, step 366/574 completed (loss: 0.33290591835975647, acc: 0.9166666865348816)
[2024-11-13 05:04:41,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:41,954][root][INFO] - Training Epoch: 2/10, step 367/574 completed (loss: 0.24753984808921814, acc: 0.9130434989929199)
[2024-11-13 05:04:42,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:42,405][root][INFO] - Training Epoch: 2/10, step 368/574 completed (loss: 0.646065354347229, acc: 0.8214285969734192)
[2024-11-13 05:04:42,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:42,720][root][INFO] - Training Epoch: 2/10, step 369/574 completed (loss: 1.230562686920166, acc: 0.65625)
[2024-11-13 05:04:42,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:43,361][root][INFO] - Training Epoch: 2/10, step 370/574 completed (loss: 1.9445985555648804, acc: 0.5030303001403809)
[2024-11-13 05:04:43,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:44,390][root][INFO] - Training Epoch: 2/10, step 371/574 completed (loss: 1.3070735931396484, acc: 0.6698113083839417)
[2024-11-13 05:04:44,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:44,711][root][INFO] - Training Epoch: 2/10, step 372/574 completed (loss: 1.3813515901565552, acc: 0.5666666626930237)
[2024-11-13 05:04:44,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:45,020][root][INFO] - Training Epoch: 2/10, step 373/574 completed (loss: 1.08962881565094, acc: 0.7142857313156128)
[2024-11-13 05:04:45,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:45,384][root][INFO] - Training Epoch: 2/10, step 374/574 completed (loss: 0.6670293807983398, acc: 0.8285714387893677)
[2024-11-13 05:04:45,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:45,695][root][INFO] - Training Epoch: 2/10, step 375/574 completed (loss: 0.2351057082414627, acc: 0.9599999785423279)
[2024-11-13 05:04:45,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:45,987][root][INFO] - Training Epoch: 2/10, step 376/574 completed (loss: 0.26325279474258423, acc: 0.9130434989929199)
[2024-11-13 05:04:46,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:46,321][root][INFO] - Training Epoch: 2/10, step 377/574 completed (loss: 1.7785524129867554, acc: 0.5833333134651184)
[2024-11-13 05:04:46,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:46,755][root][INFO] - Training Epoch: 2/10, step 378/574 completed (loss: 1.3035317659378052, acc: 0.7368420958518982)
[2024-11-13 05:04:46,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:47,358][root][INFO] - Training Epoch: 2/10, step 379/574 completed (loss: 1.6421984434127808, acc: 0.628742516040802)
[2024-11-13 05:04:47,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:47,793][root][INFO] - Training Epoch: 2/10, step 380/574 completed (loss: 1.453050136566162, acc: 0.5939849615097046)
[2024-11-13 05:04:48,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:49,073][root][INFO] - Training Epoch: 2/10, step 381/574 completed (loss: 1.4219615459442139, acc: 0.614973247051239)
[2024-11-13 05:04:49,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:49,638][root][INFO] - Training Epoch: 2/10, step 382/574 completed (loss: 0.913328230381012, acc: 0.7567567825317383)
[2024-11-13 05:04:49,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:50,017][root][INFO] - Training Epoch: 2/10, step 383/574 completed (loss: 0.7452751398086548, acc: 0.7857142686843872)
[2024-11-13 05:04:50,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:50,368][root][INFO] - Training Epoch: 2/10, step 384/574 completed (loss: 0.3724917769432068, acc: 0.8928571343421936)
[2024-11-13 05:04:50,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:50,709][root][INFO] - Training Epoch: 2/10, step 385/574 completed (loss: 0.9913405179977417, acc: 0.8125)
[2024-11-13 05:04:50,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:51,036][root][INFO] - Training Epoch: 2/10, step 386/574 completed (loss: 1.1257317066192627, acc: 0.6944444179534912)
[2024-11-13 05:04:51,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:51,357][root][INFO] - Training Epoch: 2/10, step 387/574 completed (loss: 0.5640272498130798, acc: 0.7631579041481018)
[2024-11-13 05:04:51,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:51,659][root][INFO] - Training Epoch: 2/10, step 388/574 completed (loss: 0.40191009640693665, acc: 0.8636363744735718)
[2024-11-13 05:04:51,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:51,962][root][INFO] - Training Epoch: 2/10, step 389/574 completed (loss: 0.6395596861839294, acc: 0.8999999761581421)
[2024-11-13 05:04:52,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:52,257][root][INFO] - Training Epoch: 2/10, step 390/574 completed (loss: 0.886455237865448, acc: 0.8571428656578064)
[2024-11-13 05:04:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:52,565][root][INFO] - Training Epoch: 2/10, step 391/574 completed (loss: 2.256382465362549, acc: 0.48148149251937866)
[2024-11-13 05:04:52,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:52,853][root][INFO] - Training Epoch: 2/10, step 392/574 completed (loss: 2.023035764694214, acc: 0.49514561891555786)
[2024-11-13 05:04:52,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:53,390][root][INFO] - Training Epoch: 2/10, step 393/574 completed (loss: 1.7286759614944458, acc: 0.5808823704719543)
[2024-11-13 05:04:53,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:53,771][root][INFO] - Training Epoch: 2/10, step 394/574 completed (loss: 2.0619778633117676, acc: 0.4866666793823242)
[2024-11-13 05:04:53,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:54,130][root][INFO] - Training Epoch: 2/10, step 395/574 completed (loss: 1.7317187786102295, acc: 0.5902777910232544)
[2024-11-13 05:04:54,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:54,404][root][INFO] - Training Epoch: 2/10, step 396/574 completed (loss: 1.2758582830429077, acc: 0.6744186282157898)
[2024-11-13 05:04:54,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:54,701][root][INFO] - Training Epoch: 2/10, step 397/574 completed (loss: 0.5232345461845398, acc: 0.7916666865348816)
[2024-11-13 05:04:54,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:54,994][root][INFO] - Training Epoch: 2/10, step 398/574 completed (loss: 1.1015255451202393, acc: 0.6279069781303406)
[2024-11-13 05:04:55,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:55,331][root][INFO] - Training Epoch: 2/10, step 399/574 completed (loss: 0.9784159660339355, acc: 0.7599999904632568)
[2024-11-13 05:04:55,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:55,868][root][INFO] - Training Epoch: 2/10, step 400/574 completed (loss: 1.5417366027832031, acc: 0.5735294222831726)
[2024-11-13 05:04:55,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:56,125][root][INFO] - Training Epoch: 2/10, step 401/574 completed (loss: 1.4367339611053467, acc: 0.653333306312561)
[2024-11-13 05:04:56,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:56,357][root][INFO] - Training Epoch: 2/10, step 402/574 completed (loss: 1.2252200841903687, acc: 0.6666666865348816)
[2024-11-13 05:04:56,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:56,607][root][INFO] - Training Epoch: 2/10, step 403/574 completed (loss: 1.093928575515747, acc: 0.7272727489471436)
[2024-11-13 05:04:56,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:56,934][root][INFO] - Training Epoch: 2/10, step 404/574 completed (loss: 1.1279191970825195, acc: 0.6774193644523621)
[2024-11-13 05:04:57,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:57,222][root][INFO] - Training Epoch: 2/10, step 405/574 completed (loss: 1.0580044984817505, acc: 0.7407407164573669)
[2024-11-13 05:04:57,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:57,560][root][INFO] - Training Epoch: 2/10, step 406/574 completed (loss: 0.43468746542930603, acc: 0.9200000166893005)
[2024-11-13 05:04:57,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:57,921][root][INFO] - Training Epoch: 2/10, step 407/574 completed (loss: 0.5828670859336853, acc: 0.8055555820465088)
[2024-11-13 05:04:58,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:58,297][root][INFO] - Training Epoch: 2/10, step 408/574 completed (loss: 0.5329858064651489, acc: 0.8888888955116272)
[2024-11-13 05:04:58,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:58,653][root][INFO] - Training Epoch: 2/10, step 409/574 completed (loss: 0.5441877841949463, acc: 0.7692307829856873)
[2024-11-13 05:04:58,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:58,942][root][INFO] - Training Epoch: 2/10, step 410/574 completed (loss: 0.8214539885520935, acc: 0.7413793206214905)
[2024-11-13 05:04:59,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:59,279][root][INFO] - Training Epoch: 2/10, step 411/574 completed (loss: 0.410350501537323, acc: 0.8571428656578064)
[2024-11-13 05:04:59,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:59,598][root][INFO] - Training Epoch: 2/10, step 412/574 completed (loss: 0.8992054462432861, acc: 0.800000011920929)
[2024-11-13 05:04:59,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:04:59,878][root][INFO] - Training Epoch: 2/10, step 413/574 completed (loss: 0.927885115146637, acc: 0.7878788113594055)
[2024-11-13 05:04:59,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:00,197][root][INFO] - Training Epoch: 2/10, step 414/574 completed (loss: 0.5355882048606873, acc: 0.8181818127632141)
[2024-11-13 05:05:00,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:00,547][root][INFO] - Training Epoch: 2/10, step 415/574 completed (loss: 1.5424792766571045, acc: 0.6078431606292725)
[2024-11-13 05:05:00,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:00,918][root][INFO] - Training Epoch: 2/10, step 416/574 completed (loss: 1.0816905498504639, acc: 0.6538461446762085)
[2024-11-13 05:05:01,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:01,256][root][INFO] - Training Epoch: 2/10, step 417/574 completed (loss: 0.9143780469894409, acc: 0.7222222089767456)
[2024-11-13 05:05:01,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:01,596][root][INFO] - Training Epoch: 2/10, step 418/574 completed (loss: 1.0879456996917725, acc: 0.7250000238418579)
[2024-11-13 05:05:01,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:01,898][root][INFO] - Training Epoch: 2/10, step 419/574 completed (loss: 1.5606029033660889, acc: 0.6499999761581421)
[2024-11-13 05:05:01,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:02,253][root][INFO] - Training Epoch: 2/10, step 420/574 completed (loss: 0.376004695892334, acc: 0.9047619104385376)
[2024-11-13 05:05:02,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:02,605][root][INFO] - Training Epoch: 2/10, step 421/574 completed (loss: 1.0379148721694946, acc: 0.7333333492279053)
[2024-11-13 05:05:02,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:02,940][root][INFO] - Training Epoch: 2/10, step 422/574 completed (loss: 1.313474416732788, acc: 0.71875)
[2024-11-13 05:05:03,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:03,287][root][INFO] - Training Epoch: 2/10, step 423/574 completed (loss: 1.2544119358062744, acc: 0.5833333134651184)
[2024-11-13 05:05:03,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:03,668][root][INFO] - Training Epoch: 2/10, step 424/574 completed (loss: 0.6899157166481018, acc: 0.7407407164573669)
[2024-11-13 05:05:03,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:04,063][root][INFO] - Training Epoch: 2/10, step 425/574 completed (loss: 0.7279398441314697, acc: 0.8181818127632141)
[2024-11-13 05:05:04,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:04,390][root][INFO] - Training Epoch: 2/10, step 426/574 completed (loss: 0.6028108596801758, acc: 0.8260869383811951)
[2024-11-13 05:05:05,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:05,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:05,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:06,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:06,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:07,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:07,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:07,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:08,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:08,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:08,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:09,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:09,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:09,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:10,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:10,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:11,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:11,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:11,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:12,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:12,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:12,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:13,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:13,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:13,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:14,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:14,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:14,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:15,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:15,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:15,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:16,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:16,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:16,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:17,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:17,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:17,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:18,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:18,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:18,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:19,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:19,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:20,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:20,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:20,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:21,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:21,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:21,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:22,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:22,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:22,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:23,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:23,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:24,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:24,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:25,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:25,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:25,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:25,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:26,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:27,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:27,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:27,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:28,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:28,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:28,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:29,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:29,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:30,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:30,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:30,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:31,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:31,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:31,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:32,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:32,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:32,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:33,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:33,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:34,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:34,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:35,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:35,815][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(4.2963, device='cuda:0') eval_epoch_loss=tensor(1.4578, device='cuda:0') eval_epoch_acc=tensor(0.6097, device='cuda:0')
[2024-11-13 05:05:35,817][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:05:35,817][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:05:36,236][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_427_loss_1.4577502012252808/model.pt
[2024-11-13 05:05:36,241][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:05:36,242][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.4577502012252808
[2024-11-13 05:05:36,242][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6096674799919128
[2024-11-13 05:05:36,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:36,628][root][INFO] - Training Epoch: 2/10, step 427/574 completed (loss: 0.8093535304069519, acc: 0.7567567825317383)
[2024-11-13 05:05:36,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:36,977][root][INFO] - Training Epoch: 2/10, step 428/574 completed (loss: 0.504496693611145, acc: 0.8888888955116272)
[2024-11-13 05:05:37,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:37,307][root][INFO] - Training Epoch: 2/10, step 429/574 completed (loss: 0.8270477056503296, acc: 0.782608687877655)
[2024-11-13 05:05:37,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:37,593][root][INFO] - Training Epoch: 2/10, step 430/574 completed (loss: 0.20587758719921112, acc: 0.9629629850387573)
[2024-11-13 05:05:37,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:37,872][root][INFO] - Training Epoch: 2/10, step 431/574 completed (loss: 0.2348545789718628, acc: 0.9629629850387573)
[2024-11-13 05:05:37,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:38,208][root][INFO] - Training Epoch: 2/10, step 432/574 completed (loss: 0.7198859453201294, acc: 0.739130437374115)
[2024-11-13 05:05:38,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:38,571][root][INFO] - Training Epoch: 2/10, step 433/574 completed (loss: 1.0301817655563354, acc: 0.7222222089767456)
[2024-11-13 05:05:38,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:38,893][root][INFO] - Training Epoch: 2/10, step 434/574 completed (loss: 0.24075597524642944, acc: 0.9200000166893005)
[2024-11-13 05:05:38,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:39,231][root][INFO] - Training Epoch: 2/10, step 435/574 completed (loss: 0.8207478523254395, acc: 0.8181818127632141)
[2024-11-13 05:05:39,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:39,576][root][INFO] - Training Epoch: 2/10, step 436/574 completed (loss: 1.0259852409362793, acc: 0.7222222089767456)
[2024-11-13 05:05:39,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:39,973][root][INFO] - Training Epoch: 2/10, step 437/574 completed (loss: 1.2052308320999146, acc: 0.75)
[2024-11-13 05:05:40,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:40,300][root][INFO] - Training Epoch: 2/10, step 438/574 completed (loss: 0.3394745886325836, acc: 0.8571428656578064)
[2024-11-13 05:05:40,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:40,655][root][INFO] - Training Epoch: 2/10, step 439/574 completed (loss: 1.5613824129104614, acc: 0.6153846383094788)
[2024-11-13 05:05:40,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:41,168][root][INFO] - Training Epoch: 2/10, step 440/574 completed (loss: 1.7136279344558716, acc: 0.5454545617103577)
[2024-11-13 05:05:41,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:41,931][root][INFO] - Training Epoch: 2/10, step 441/574 completed (loss: 2.1112704277038574, acc: 0.42399999499320984)
[2024-11-13 05:05:42,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:42,350][root][INFO] - Training Epoch: 2/10, step 442/574 completed (loss: 1.9401867389678955, acc: 0.5161290168762207)
[2024-11-13 05:05:42,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:43,051][root][INFO] - Training Epoch: 2/10, step 443/574 completed (loss: 1.8360707759857178, acc: 0.49751242995262146)
[2024-11-13 05:05:43,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:43,378][root][INFO] - Training Epoch: 2/10, step 444/574 completed (loss: 1.709510087966919, acc: 0.6037735939025879)
[2024-11-13 05:05:43,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:43,822][root][INFO] - Training Epoch: 2/10, step 445/574 completed (loss: 0.8730165958404541, acc: 0.7727272510528564)
[2024-11-13 05:05:43,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:44,151][root][INFO] - Training Epoch: 2/10, step 446/574 completed (loss: 1.450728416442871, acc: 0.6086956262588501)
[2024-11-13 05:05:44,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:44,439][root][INFO] - Training Epoch: 2/10, step 447/574 completed (loss: 1.3449375629425049, acc: 0.6538461446762085)
[2024-11-13 05:05:44,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:44,782][root][INFO] - Training Epoch: 2/10, step 448/574 completed (loss: 0.7052848935127258, acc: 0.8928571343421936)
[2024-11-13 05:05:44,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:45,130][root][INFO] - Training Epoch: 2/10, step 449/574 completed (loss: 1.2018386125564575, acc: 0.611940324306488)
[2024-11-13 05:05:45,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:45,520][root][INFO] - Training Epoch: 2/10, step 450/574 completed (loss: 0.7905101776123047, acc: 0.75)
[2024-11-13 05:05:45,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:45,907][root][INFO] - Training Epoch: 2/10, step 451/574 completed (loss: 1.086870789527893, acc: 0.717391312122345)
[2024-11-13 05:05:46,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:46,251][root][INFO] - Training Epoch: 2/10, step 452/574 completed (loss: 1.2746399641036987, acc: 0.692307710647583)
[2024-11-13 05:05:46,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:46,588][root][INFO] - Training Epoch: 2/10, step 453/574 completed (loss: 1.3653370141983032, acc: 0.5921052694320679)
[2024-11-13 05:05:46,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:47,041][root][INFO] - Training Epoch: 2/10, step 454/574 completed (loss: 1.0687562227249146, acc: 0.7142857313156128)
[2024-11-13 05:05:47,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:47,456][root][INFO] - Training Epoch: 2/10, step 455/574 completed (loss: 1.4026538133621216, acc: 0.6969696879386902)
[2024-11-13 05:05:47,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:47,876][root][INFO] - Training Epoch: 2/10, step 456/574 completed (loss: 1.7595840692520142, acc: 0.5154638886451721)
[2024-11-13 05:05:47,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:48,222][root][INFO] - Training Epoch: 2/10, step 457/574 completed (loss: 1.0809364318847656, acc: 0.6714285612106323)
[2024-11-13 05:05:48,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:48,595][root][INFO] - Training Epoch: 2/10, step 458/574 completed (loss: 1.6449142694473267, acc: 0.5523256063461304)
[2024-11-13 05:05:48,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:48,970][root][INFO] - Training Epoch: 2/10, step 459/574 completed (loss: 1.3070955276489258, acc: 0.6071428656578064)
[2024-11-13 05:05:49,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:49,311][root][INFO] - Training Epoch: 2/10, step 460/574 completed (loss: 1.3032488822937012, acc: 0.6913580298423767)
[2024-11-13 05:05:49,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:49,616][root][INFO] - Training Epoch: 2/10, step 461/574 completed (loss: 1.1886940002441406, acc: 0.6944444179534912)
[2024-11-13 05:05:49,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:49,950][root][INFO] - Training Epoch: 2/10, step 462/574 completed (loss: 0.7754611968994141, acc: 0.71875)
[2024-11-13 05:05:50,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:50,259][root][INFO] - Training Epoch: 2/10, step 463/574 completed (loss: 0.6908854842185974, acc: 0.8461538553237915)
[2024-11-13 05:05:50,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:50,568][root][INFO] - Training Epoch: 2/10, step 464/574 completed (loss: 1.1286616325378418, acc: 0.6739130616188049)
[2024-11-13 05:05:50,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:50,915][root][INFO] - Training Epoch: 2/10, step 465/574 completed (loss: 1.0143400430679321, acc: 0.726190447807312)
[2024-11-13 05:05:51,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:51,323][root][INFO] - Training Epoch: 2/10, step 466/574 completed (loss: 1.6676794290542603, acc: 0.4939759075641632)
[2024-11-13 05:05:51,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:51,682][root][INFO] - Training Epoch: 2/10, step 467/574 completed (loss: 1.4239482879638672, acc: 0.5855855941772461)
[2024-11-13 05:05:51,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:52,069][root][INFO] - Training Epoch: 2/10, step 468/574 completed (loss: 1.5783815383911133, acc: 0.5728155374526978)
[2024-11-13 05:05:52,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:52,435][root][INFO] - Training Epoch: 2/10, step 469/574 completed (loss: 1.3442648649215698, acc: 0.642276406288147)
[2024-11-13 05:05:52,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:52,739][root][INFO] - Training Epoch: 2/10, step 470/574 completed (loss: 0.816609799861908, acc: 0.7083333134651184)
[2024-11-13 05:05:52,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:53,128][root][INFO] - Training Epoch: 2/10, step 471/574 completed (loss: 1.4379472732543945, acc: 0.6785714030265808)
[2024-11-13 05:05:53,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:53,553][root][INFO] - Training Epoch: 2/10, step 472/574 completed (loss: 1.727666974067688, acc: 0.5098039507865906)
[2024-11-13 05:05:53,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:54,004][root][INFO] - Training Epoch: 2/10, step 473/574 completed (loss: 1.8424924612045288, acc: 0.5240174531936646)
[2024-11-13 05:05:54,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:54,335][root][INFO] - Training Epoch: 2/10, step 474/574 completed (loss: 1.598915934562683, acc: 0.5520833134651184)
[2024-11-13 05:05:54,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:54,708][root][INFO] - Training Epoch: 2/10, step 475/574 completed (loss: 1.3311680555343628, acc: 0.6687116622924805)
[2024-11-13 05:05:54,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:55,054][root][INFO] - Training Epoch: 2/10, step 476/574 completed (loss: 1.3526058197021484, acc: 0.6187050342559814)
[2024-11-13 05:05:55,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:55,398][root][INFO] - Training Epoch: 2/10, step 477/574 completed (loss: 1.6320313215255737, acc: 0.5628140568733215)
[2024-11-13 05:05:55,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:55,716][root][INFO] - Training Epoch: 2/10, step 478/574 completed (loss: 1.2734849452972412, acc: 0.6666666865348816)
[2024-11-13 05:05:55,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:56,040][root][INFO] - Training Epoch: 2/10, step 479/574 completed (loss: 1.227489709854126, acc: 0.6666666865348816)
[2024-11-13 05:05:56,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:56,411][root][INFO] - Training Epoch: 2/10, step 480/574 completed (loss: 0.9754641652107239, acc: 0.7037037014961243)
[2024-11-13 05:05:56,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:56,749][root][INFO] - Training Epoch: 2/10, step 481/574 completed (loss: 1.083724856376648, acc: 0.699999988079071)
[2024-11-13 05:05:56,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:57,061][root][INFO] - Training Epoch: 2/10, step 482/574 completed (loss: 1.018702745437622, acc: 0.75)
[2024-11-13 05:05:57,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:57,429][root][INFO] - Training Epoch: 2/10, step 483/574 completed (loss: 1.3824657201766968, acc: 0.6379310488700867)
[2024-11-13 05:05:57,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:57,750][root][INFO] - Training Epoch: 2/10, step 484/574 completed (loss: 0.4658014178276062, acc: 0.8709677457809448)
[2024-11-13 05:05:57,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:58,060][root][INFO] - Training Epoch: 2/10, step 485/574 completed (loss: 0.7390738725662231, acc: 0.7894737124443054)
[2024-11-13 05:05:58,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:58,400][root][INFO] - Training Epoch: 2/10, step 486/574 completed (loss: 1.828154444694519, acc: 0.5185185074806213)
[2024-11-13 05:05:58,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:58,741][root][INFO] - Training Epoch: 2/10, step 487/574 completed (loss: 1.3494091033935547, acc: 0.6190476417541504)
[2024-11-13 05:05:58,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:59,068][root][INFO] - Training Epoch: 2/10, step 488/574 completed (loss: 1.055031657218933, acc: 0.5909090638160706)
[2024-11-13 05:05:59,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:59,461][root][INFO] - Training Epoch: 2/10, step 489/574 completed (loss: 1.5803163051605225, acc: 0.5538461804389954)
[2024-11-13 05:05:59,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:05:59,834][root][INFO] - Training Epoch: 2/10, step 490/574 completed (loss: 0.8095940947532654, acc: 0.7666666507720947)
[2024-11-13 05:05:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:00,178][root][INFO] - Training Epoch: 2/10, step 491/574 completed (loss: 0.9951018691062927, acc: 0.7241379022598267)
[2024-11-13 05:06:00,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:00,588][root][INFO] - Training Epoch: 2/10, step 492/574 completed (loss: 1.0355833768844604, acc: 0.6666666865348816)
[2024-11-13 05:06:00,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:00,983][root][INFO] - Training Epoch: 2/10, step 493/574 completed (loss: 0.963582456111908, acc: 0.7586206793785095)
[2024-11-13 05:06:01,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:01,323][root][INFO] - Training Epoch: 2/10, step 494/574 completed (loss: 0.5440224409103394, acc: 0.8947368264198303)
[2024-11-13 05:06:01,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:01,681][root][INFO] - Training Epoch: 2/10, step 495/574 completed (loss: 2.3596291542053223, acc: 0.4736842215061188)
[2024-11-13 05:06:01,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:02,048][root][INFO] - Training Epoch: 2/10, step 496/574 completed (loss: 1.5384910106658936, acc: 0.6160714030265808)
[2024-11-13 05:06:02,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:02,429][root][INFO] - Training Epoch: 2/10, step 497/574 completed (loss: 1.1157991886138916, acc: 0.7303370833396912)
[2024-11-13 05:06:02,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:02,824][root][INFO] - Training Epoch: 2/10, step 498/574 completed (loss: 1.4493963718414307, acc: 0.5617977380752563)
[2024-11-13 05:06:02,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:03,213][root][INFO] - Training Epoch: 2/10, step 499/574 completed (loss: 1.890771508216858, acc: 0.4822694957256317)
[2024-11-13 05:06:03,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:03,584][root][INFO] - Training Epoch: 2/10, step 500/574 completed (loss: 1.67635977268219, acc: 0.554347813129425)
[2024-11-13 05:06:03,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:03,992][root][INFO] - Training Epoch: 2/10, step 501/574 completed (loss: 0.14408685266971588, acc: 1.0)
[2024-11-13 05:06:04,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:04,272][root][INFO] - Training Epoch: 2/10, step 502/574 completed (loss: 0.529273271560669, acc: 0.8846153616905212)
[2024-11-13 05:06:04,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:04,659][root][INFO] - Training Epoch: 2/10, step 503/574 completed (loss: 0.39568859338760376, acc: 0.8888888955116272)
[2024-11-13 05:06:04,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:05,003][root][INFO] - Training Epoch: 2/10, step 504/574 completed (loss: 0.9117947816848755, acc: 0.6666666865348816)
[2024-11-13 05:06:05,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:05,321][root][INFO] - Training Epoch: 2/10, step 505/574 completed (loss: 1.0398032665252686, acc: 0.7924528121948242)
[2024-11-13 05:06:05,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:05,613][root][INFO] - Training Epoch: 2/10, step 506/574 completed (loss: 0.9512320756912231, acc: 0.7931034564971924)
[2024-11-13 05:06:05,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:06,223][root][INFO] - Training Epoch: 2/10, step 507/574 completed (loss: 1.803239345550537, acc: 0.5135135054588318)
[2024-11-13 05:06:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:06,664][root][INFO] - Training Epoch: 2/10, step 508/574 completed (loss: 1.3013681173324585, acc: 0.6760563254356384)
[2024-11-13 05:06:06,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:06,969][root][INFO] - Training Epoch: 2/10, step 509/574 completed (loss: 0.32433947920799255, acc: 0.800000011920929)
[2024-11-13 05:06:07,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:07,259][root][INFO] - Training Epoch: 2/10, step 510/574 completed (loss: 0.27375009655952454, acc: 0.9333333373069763)
[2024-11-13 05:06:07,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:07,644][root][INFO] - Training Epoch: 2/10, step 511/574 completed (loss: 0.7801755666732788, acc: 0.8461538553237915)
[2024-11-13 05:06:09,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:10,366][root][INFO] - Training Epoch: 2/10, step 512/574 completed (loss: 1.905677318572998, acc: 0.4928571283817291)
[2024-11-13 05:06:10,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:11,249][root][INFO] - Training Epoch: 2/10, step 513/574 completed (loss: 1.4550663232803345, acc: 0.6269841194152832)
[2024-11-13 05:06:11,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:11,565][root][INFO] - Training Epoch: 2/10, step 514/574 completed (loss: 1.0967353582382202, acc: 0.75)
[2024-11-13 05:06:11,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:11,913][root][INFO] - Training Epoch: 2/10, step 515/574 completed (loss: 0.7406578660011292, acc: 0.75)
[2024-11-13 05:06:12,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:12,660][root][INFO] - Training Epoch: 2/10, step 516/574 completed (loss: 1.123010277748108, acc: 0.7083333134651184)
[2024-11-13 05:06:12,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:13,090][root][INFO] - Training Epoch: 2/10, step 517/574 completed (loss: 0.10462865233421326, acc: 1.0)
[2024-11-13 05:06:13,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:13,491][root][INFO] - Training Epoch: 2/10, step 518/574 completed (loss: 0.9741414189338684, acc: 0.6774193644523621)
[2024-11-13 05:06:13,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:13,913][root][INFO] - Training Epoch: 2/10, step 519/574 completed (loss: 1.3592793941497803, acc: 0.6499999761581421)
[2024-11-13 05:06:14,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:14,298][root][INFO] - Training Epoch: 2/10, step 520/574 completed (loss: 1.561888575553894, acc: 0.5925925970077515)
[2024-11-13 05:06:14,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:15,478][root][INFO] - Training Epoch: 2/10, step 521/574 completed (loss: 1.7185969352722168, acc: 0.49152541160583496)
[2024-11-13 05:06:15,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:15,825][root][INFO] - Training Epoch: 2/10, step 522/574 completed (loss: 1.2100533246994019, acc: 0.6641790866851807)
[2024-11-13 05:06:15,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:16,235][root][INFO] - Training Epoch: 2/10, step 523/574 completed (loss: 1.3421639204025269, acc: 0.5839415788650513)
[2024-11-13 05:06:16,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:16,827][root][INFO] - Training Epoch: 2/10, step 524/574 completed (loss: 1.4065579175949097, acc: 0.6050000190734863)
[2024-11-13 05:06:16,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:17,206][root][INFO] - Training Epoch: 2/10, step 525/574 completed (loss: 0.5228722095489502, acc: 0.9444444179534912)
[2024-11-13 05:06:17,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:17,530][root][INFO] - Training Epoch: 2/10, step 526/574 completed (loss: 0.6621372699737549, acc: 0.7884615659713745)
[2024-11-13 05:06:17,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:17,816][root][INFO] - Training Epoch: 2/10, step 527/574 completed (loss: 0.8217369318008423, acc: 0.6666666865348816)
[2024-11-13 05:06:17,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:18,134][root][INFO] - Training Epoch: 2/10, step 528/574 completed (loss: 2.612144708633423, acc: 0.32786884903907776)
[2024-11-13 05:06:18,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:18,419][root][INFO] - Training Epoch: 2/10, step 529/574 completed (loss: 0.8206494450569153, acc: 0.8135592937469482)
[2024-11-13 05:06:18,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:18,733][root][INFO] - Training Epoch: 2/10, step 530/574 completed (loss: 2.1082253456115723, acc: 0.41860464215278625)
[2024-11-13 05:06:18,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:19,030][root][INFO] - Training Epoch: 2/10, step 531/574 completed (loss: 1.930306315422058, acc: 0.5227272510528564)
[2024-11-13 05:06:19,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:19,368][root][INFO] - Training Epoch: 2/10, step 532/574 completed (loss: 2.1163318157196045, acc: 0.4528301954269409)
[2024-11-13 05:06:19,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:19,689][root][INFO] - Training Epoch: 2/10, step 533/574 completed (loss: 1.3855671882629395, acc: 0.6590909361839294)
[2024-11-13 05:06:19,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:20,004][root][INFO] - Training Epoch: 2/10, step 534/574 completed (loss: 1.102632761001587, acc: 0.7200000286102295)
[2024-11-13 05:06:20,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:20,293][root][INFO] - Training Epoch: 2/10, step 535/574 completed (loss: 0.8338330388069153, acc: 0.800000011920929)
[2024-11-13 05:06:20,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:20,568][root][INFO] - Training Epoch: 2/10, step 536/574 completed (loss: 0.6224485039710999, acc: 0.8181818127632141)
[2024-11-13 05:06:20,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:20,953][root][INFO] - Training Epoch: 2/10, step 537/574 completed (loss: 1.1677800416946411, acc: 0.692307710647583)
[2024-11-13 05:06:21,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:21,385][root][INFO] - Training Epoch: 2/10, step 538/574 completed (loss: 1.0281097888946533, acc: 0.734375)
[2024-11-13 05:06:21,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:21,827][root][INFO] - Training Epoch: 2/10, step 539/574 completed (loss: 0.9621192812919617, acc: 0.71875)
[2024-11-13 05:06:21,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:22,165][root][INFO] - Training Epoch: 2/10, step 540/574 completed (loss: 1.3046269416809082, acc: 0.6969696879386902)
[2024-11-13 05:06:22,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:22,470][root][INFO] - Training Epoch: 2/10, step 541/574 completed (loss: 0.6223596334457397, acc: 0.6875)
[2024-11-13 05:06:22,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:22,781][root][INFO] - Training Epoch: 2/10, step 542/574 completed (loss: 0.24506185948848724, acc: 0.9677419066429138)
[2024-11-13 05:06:22,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:23,097][root][INFO] - Training Epoch: 2/10, step 543/574 completed (loss: 0.39043915271759033, acc: 0.8695651888847351)
[2024-11-13 05:06:23,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:23,357][root][INFO] - Training Epoch: 2/10, step 544/574 completed (loss: 1.2200483083724976, acc: 0.5666666626930237)
[2024-11-13 05:06:23,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:23,743][root][INFO] - Training Epoch: 2/10, step 545/574 completed (loss: 0.5274922847747803, acc: 0.8780487775802612)
[2024-11-13 05:06:23,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:24,087][root][INFO] - Training Epoch: 2/10, step 546/574 completed (loss: 0.5521180033683777, acc: 0.800000011920929)
[2024-11-13 05:06:24,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:24,425][root][INFO] - Training Epoch: 2/10, step 547/574 completed (loss: 0.741013765335083, acc: 0.8157894611358643)
[2024-11-13 05:06:24,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:24,763][root][INFO] - Training Epoch: 2/10, step 548/574 completed (loss: 0.6301062107086182, acc: 0.8064516186714172)
[2024-11-13 05:06:24,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:25,093][root][INFO] - Training Epoch: 2/10, step 549/574 completed (loss: 0.2436186969280243, acc: 0.9599999785423279)
[2024-11-13 05:06:25,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:25,395][root][INFO] - Training Epoch: 2/10, step 550/574 completed (loss: 0.6580876111984253, acc: 0.7878788113594055)
[2024-11-13 05:06:25,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:25,732][root][INFO] - Training Epoch: 2/10, step 551/574 completed (loss: 0.6125550866127014, acc: 0.8500000238418579)
[2024-11-13 05:06:25,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:26,042][root][INFO] - Training Epoch: 2/10, step 552/574 completed (loss: 0.45802590250968933, acc: 0.8857142925262451)
[2024-11-13 05:06:26,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:26,385][root][INFO] - Training Epoch: 2/10, step 553/574 completed (loss: 1.2823318243026733, acc: 0.6350364685058594)
[2024-11-13 05:06:26,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:26,778][root][INFO] - Training Epoch: 2/10, step 554/574 completed (loss: 1.076649785041809, acc: 0.7034482955932617)
[2024-11-13 05:06:26,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:27,150][root][INFO] - Training Epoch: 2/10, step 555/574 completed (loss: 1.4144937992095947, acc: 0.6499999761581421)
[2024-11-13 05:06:27,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:27,470][root][INFO] - Training Epoch: 2/10, step 556/574 completed (loss: 1.236402988433838, acc: 0.6688741445541382)
[2024-11-13 05:06:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:27,833][root][INFO] - Training Epoch: 2/10, step 557/574 completed (loss: 0.9436453580856323, acc: 0.7008547186851501)
[2024-11-13 05:06:27,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:28,195][root][INFO] - Training Epoch: 2/10, step 558/574 completed (loss: 0.27669233083724976, acc: 0.9200000166893005)
[2024-11-13 05:06:28,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:28,523][root][INFO] - Training Epoch: 2/10, step 559/574 completed (loss: 0.9440972805023193, acc: 0.7307692170143127)
[2024-11-13 05:06:28,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:28,930][root][INFO] - Training Epoch: 2/10, step 560/574 completed (loss: 0.24396660923957825, acc: 0.9230769276618958)
[2024-11-13 05:06:29,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:29,284][root][INFO] - Training Epoch: 2/10, step 561/574 completed (loss: 1.0362337827682495, acc: 0.7435897588729858)
[2024-11-13 05:06:29,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:29,626][root][INFO] - Training Epoch: 2/10, step 562/574 completed (loss: 1.0509918928146362, acc: 0.6888889074325562)
[2024-11-13 05:06:29,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:30,022][root][INFO] - Training Epoch: 2/10, step 563/574 completed (loss: 1.0822397470474243, acc: 0.7142857313156128)
[2024-11-13 05:06:30,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:30,395][root][INFO] - Training Epoch: 2/10, step 564/574 completed (loss: 0.9905958771705627, acc: 0.7291666865348816)
[2024-11-13 05:06:30,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:30,777][root][INFO] - Training Epoch: 2/10, step 565/574 completed (loss: 0.7620102167129517, acc: 0.8103448152542114)
[2024-11-13 05:06:30,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:31,180][root][INFO] - Training Epoch: 2/10, step 566/574 completed (loss: 1.0439001321792603, acc: 0.7142857313156128)
[2024-11-13 05:06:31,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:31,497][root][INFO] - Training Epoch: 2/10, step 567/574 completed (loss: 0.7965909838676453, acc: 0.6842105388641357)
[2024-11-13 05:06:31,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:31,807][root][INFO] - Training Epoch: 2/10, step 568/574 completed (loss: 0.4584823250770569, acc: 0.8518518805503845)
[2024-11-13 05:06:31,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:32,186][root][INFO] - Training Epoch: 2/10, step 569/574 completed (loss: 1.232179045677185, acc: 0.6470588445663452)
[2024-11-13 05:06:33,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:33,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:34,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:34,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:34,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:35,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:35,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:35,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:36,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:36,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:37,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:37,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:37,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:38,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:38,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:38,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:38,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:39,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:39,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:40,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:40,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:40,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:41,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:41,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:41,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:42,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:42,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:43,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:43,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:43,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:44,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:44,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:44,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:45,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:45,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:45,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:46,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:46,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:47,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:47,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:48,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:48,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:48,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:49,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:49,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:49,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:50,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:50,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:50,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:51,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:51,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:51,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:52,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:52,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:52,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:53,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:53,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:53,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:54,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:54,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:55,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:55,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:55,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:56,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:56,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:57,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:57,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:58,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:58,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:58,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:59,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:59,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:06:59,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:00,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:00,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:00,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:01,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:01,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:01,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:02,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:02,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:02,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:03,538][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(3.4803, device='cuda:0') eval_epoch_loss=tensor(1.2471, device='cuda:0') eval_epoch_acc=tensor(0.6730, device='cuda:0')
[2024-11-13 05:07:03,539][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:07:03,539][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:07:03,868][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_2_step_570_loss_1.2471081018447876/model.pt
[2024-11-13 05:07:03,874][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:07:03,874][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 2 is 1.2471081018447876
[2024-11-13 05:07:03,875][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 2 is 0.6729527115821838
[2024-11-13 05:07:03,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:04,268][root][INFO] - Training Epoch: 2/10, step 570/574 completed (loss: 0.9711116552352905, acc: 0.7419354915618896)
[2024-11-13 05:07:04,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:04,605][root][INFO] - Training Epoch: 2/10, step 571/574 completed (loss: 1.025949239730835, acc: 0.7435897588729858)
[2024-11-13 05:07:04,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:04,920][root][INFO] - Training Epoch: 2/10, step 572/574 completed (loss: 1.3215901851654053, acc: 0.6326530575752258)
[2024-11-13 05:07:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:05,244][root][INFO] - Training Epoch: 2/10, step 573/574 completed (loss: 1.483177661895752, acc: 0.5849056839942932)
[2024-11-13 05:07:05,754][slam_llm.utils.train_utils][INFO] - Epoch 2: train_perplexity=4.5694, train_epoch_loss=1.5194, epoch time 357.6083206422627s
[2024-11-13 05:07:05,754][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 12 GB
[2024-11-13 05:07:05,754][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-13 05:07:05,755][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 12 GB
[2024-11-13 05:07:05,755][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 6
[2024-11-13 05:07:05,755][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:07:06,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:06,758][root][INFO] - Training Epoch: 3/10, step 0/574 completed (loss: 1.2550413608551025, acc: 0.6296296119689941)
[2024-11-13 05:07:06,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:07,081][root][INFO] - Training Epoch: 3/10, step 1/574 completed (loss: 1.0866285562515259, acc: 0.6800000071525574)
[2024-11-13 05:07:07,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:07,411][root][INFO] - Training Epoch: 3/10, step 2/574 completed (loss: 1.648098349571228, acc: 0.5675675868988037)
[2024-11-13 05:07:07,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:07,777][root][INFO] - Training Epoch: 3/10, step 3/574 completed (loss: 1.0582493543624878, acc: 0.7105262875556946)
[2024-11-13 05:07:07,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:08,086][root][INFO] - Training Epoch: 3/10, step 4/574 completed (loss: 0.8772355318069458, acc: 0.7027027010917664)
[2024-11-13 05:07:08,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:08,471][root][INFO] - Training Epoch: 3/10, step 5/574 completed (loss: 0.8338680863380432, acc: 0.7857142686843872)
[2024-11-13 05:07:08,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:08,835][root][INFO] - Training Epoch: 3/10, step 6/574 completed (loss: 1.3380354642868042, acc: 0.6734693646430969)
[2024-11-13 05:07:08,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:09,164][root][INFO] - Training Epoch: 3/10, step 7/574 completed (loss: 0.7217881083488464, acc: 0.8333333134651184)
[2024-11-13 05:07:09,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:09,520][root][INFO] - Training Epoch: 3/10, step 8/574 completed (loss: 0.2651970088481903, acc: 0.9090909361839294)
[2024-11-13 05:07:09,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:09,887][root][INFO] - Training Epoch: 3/10, step 9/574 completed (loss: 0.24521119892597198, acc: 0.8846153616905212)
[2024-11-13 05:07:09,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:10,221][root][INFO] - Training Epoch: 3/10, step 10/574 completed (loss: 0.3372610807418823, acc: 0.8888888955116272)
[2024-11-13 05:07:10,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:10,597][root][INFO] - Training Epoch: 3/10, step 11/574 completed (loss: 1.5966260433197021, acc: 0.6410256624221802)
[2024-11-13 05:07:10,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:10,929][root][INFO] - Training Epoch: 3/10, step 12/574 completed (loss: 0.9000879526138306, acc: 0.7575757503509521)
[2024-11-13 05:07:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:11,326][root][INFO] - Training Epoch: 3/10, step 13/574 completed (loss: 1.0683175325393677, acc: 0.695652186870575)
[2024-11-13 05:07:11,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:11,691][root][INFO] - Training Epoch: 3/10, step 14/574 completed (loss: 1.185840368270874, acc: 0.6470588445663452)
[2024-11-13 05:07:11,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:12,062][root][INFO] - Training Epoch: 3/10, step 15/574 completed (loss: 1.0657894611358643, acc: 0.8163265585899353)
[2024-11-13 05:07:12,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:12,414][root][INFO] - Training Epoch: 3/10, step 16/574 completed (loss: 0.5175361633300781, acc: 0.8947368264198303)
[2024-11-13 05:07:12,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:12,752][root][INFO] - Training Epoch: 3/10, step 17/574 completed (loss: 1.0770468711853027, acc: 0.6666666865348816)
[2024-11-13 05:07:12,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:13,097][root][INFO] - Training Epoch: 3/10, step 18/574 completed (loss: 1.3138281106948853, acc: 0.6388888955116272)
[2024-11-13 05:07:13,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:13,493][root][INFO] - Training Epoch: 3/10, step 19/574 completed (loss: 0.6820745468139648, acc: 0.7894737124443054)
[2024-11-13 05:07:13,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:13,842][root][INFO] - Training Epoch: 3/10, step 20/574 completed (loss: 0.8990986943244934, acc: 0.7692307829856873)
[2024-11-13 05:07:13,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:14,160][root][INFO] - Training Epoch: 3/10, step 21/574 completed (loss: 0.9410851001739502, acc: 0.7241379022598267)
[2024-11-13 05:07:14,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:14,441][root][INFO] - Training Epoch: 3/10, step 22/574 completed (loss: 0.9976089596748352, acc: 0.6399999856948853)
[2024-11-13 05:07:14,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:14,811][root][INFO] - Training Epoch: 3/10, step 23/574 completed (loss: 0.7561297416687012, acc: 0.9047619104385376)
[2024-11-13 05:07:14,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:15,212][root][INFO] - Training Epoch: 3/10, step 24/574 completed (loss: 0.4627053141593933, acc: 0.875)
[2024-11-13 05:07:15,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:15,564][root][INFO] - Training Epoch: 3/10, step 25/574 completed (loss: 1.567969799041748, acc: 0.6415094137191772)
[2024-11-13 05:07:15,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:15,925][root][INFO] - Training Epoch: 3/10, step 26/574 completed (loss: 1.4685893058776855, acc: 0.6164383292198181)
[2024-11-13 05:07:16,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:17,287][root][INFO] - Training Epoch: 3/10, step 27/574 completed (loss: 1.8888733386993408, acc: 0.47826087474823)
[2024-11-13 05:07:17,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:17,629][root][INFO] - Training Epoch: 3/10, step 28/574 completed (loss: 1.0409495830535889, acc: 0.6744186282157898)
[2024-11-13 05:07:17,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:17,960][root][INFO] - Training Epoch: 3/10, step 29/574 completed (loss: 1.0234439373016357, acc: 0.6867470145225525)
[2024-11-13 05:07:18,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:18,388][root][INFO] - Training Epoch: 3/10, step 30/574 completed (loss: 1.3823407888412476, acc: 0.6296296119689941)
[2024-11-13 05:07:18,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:18,784][root][INFO] - Training Epoch: 3/10, step 31/574 completed (loss: 1.398611068725586, acc: 0.6071428656578064)
[2024-11-13 05:07:18,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:19,146][root][INFO] - Training Epoch: 3/10, step 32/574 completed (loss: 0.5772573351860046, acc: 0.8148148059844971)
[2024-11-13 05:07:19,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:19,498][root][INFO] - Training Epoch: 3/10, step 33/574 completed (loss: 0.31774455308914185, acc: 0.95652174949646)
[2024-11-13 05:07:19,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:19,866][root][INFO] - Training Epoch: 3/10, step 34/574 completed (loss: 1.0454225540161133, acc: 0.7226890921592712)
[2024-11-13 05:07:19,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:20,162][root][INFO] - Training Epoch: 3/10, step 35/574 completed (loss: 0.8269967436790466, acc: 0.7704917788505554)
[2024-11-13 05:07:20,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:20,481][root][INFO] - Training Epoch: 3/10, step 36/574 completed (loss: 1.027772307395935, acc: 0.6984127163887024)
[2024-11-13 05:07:20,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:20,810][root][INFO] - Training Epoch: 3/10, step 37/574 completed (loss: 1.0669100284576416, acc: 0.7796609997749329)
[2024-11-13 05:07:20,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:21,230][root][INFO] - Training Epoch: 3/10, step 38/574 completed (loss: 0.6092074513435364, acc: 0.8275862336158752)
[2024-11-13 05:07:21,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:21,581][root][INFO] - Training Epoch: 3/10, step 39/574 completed (loss: 0.5594779849052429, acc: 0.9047619104385376)
[2024-11-13 05:07:21,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:21,954][root][INFO] - Training Epoch: 3/10, step 40/574 completed (loss: 1.2660161256790161, acc: 0.7307692170143127)
[2024-11-13 05:07:22,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:22,362][root][INFO] - Training Epoch: 3/10, step 41/574 completed (loss: 1.2253774404525757, acc: 0.6756756901741028)
[2024-11-13 05:07:22,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:22,729][root][INFO] - Training Epoch: 3/10, step 42/574 completed (loss: 1.505316972732544, acc: 0.5076923370361328)
[2024-11-13 05:07:22,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:23,149][root][INFO] - Training Epoch: 3/10, step 43/574 completed (loss: 1.2313940525054932, acc: 0.6666666865348816)
[2024-11-13 05:07:23,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:23,563][root][INFO] - Training Epoch: 3/10, step 44/574 completed (loss: 1.1471396684646606, acc: 0.6907216310501099)
[2024-11-13 05:07:23,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:23,961][root][INFO] - Training Epoch: 3/10, step 45/574 completed (loss: 1.27401864528656, acc: 0.6397058963775635)
[2024-11-13 05:07:24,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:24,363][root][INFO] - Training Epoch: 3/10, step 46/574 completed (loss: 0.4263100028038025, acc: 0.8846153616905212)
[2024-11-13 05:07:24,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:24,720][root][INFO] - Training Epoch: 3/10, step 47/574 completed (loss: 0.4381082057952881, acc: 0.9259259104728699)
[2024-11-13 05:07:24,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:25,090][root][INFO] - Training Epoch: 3/10, step 48/574 completed (loss: 0.4558778703212738, acc: 0.8928571343421936)
[2024-11-13 05:07:25,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:25,502][root][INFO] - Training Epoch: 3/10, step 49/574 completed (loss: 0.30846351385116577, acc: 0.9444444179534912)
[2024-11-13 05:07:25,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:25,927][root][INFO] - Training Epoch: 3/10, step 50/574 completed (loss: 1.0708155632019043, acc: 0.6666666865348816)
[2024-11-13 05:07:26,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:26,304][root][INFO] - Training Epoch: 3/10, step 51/574 completed (loss: 1.2524466514587402, acc: 0.6507936716079712)
[2024-11-13 05:07:26,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:26,651][root][INFO] - Training Epoch: 3/10, step 52/574 completed (loss: 1.764518141746521, acc: 0.5352112650871277)
[2024-11-13 05:07:26,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:27,125][root][INFO] - Training Epoch: 3/10, step 53/574 completed (loss: 1.916571021080017, acc: 0.4333333373069763)
[2024-11-13 05:07:27,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:27,472][root][INFO] - Training Epoch: 3/10, step 54/574 completed (loss: 1.0119943618774414, acc: 0.7027027010917664)
[2024-11-13 05:07:27,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:27,762][root][INFO] - Training Epoch: 3/10, step 55/574 completed (loss: 0.2212790697813034, acc: 0.9230769276618958)
[2024-11-13 05:07:29,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:30,917][root][INFO] - Training Epoch: 3/10, step 56/574 completed (loss: 1.671679973602295, acc: 0.5597269535064697)
[2024-11-13 05:07:31,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:32,251][root][INFO] - Training Epoch: 3/10, step 57/574 completed (loss: 1.9000740051269531, acc: 0.5228758454322815)
[2024-11-13 05:07:32,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:32,875][root][INFO] - Training Epoch: 3/10, step 58/574 completed (loss: 1.4157050848007202, acc: 0.6306818127632141)
[2024-11-13 05:07:33,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:33,447][root][INFO] - Training Epoch: 3/10, step 59/574 completed (loss: 1.3996379375457764, acc: 0.6176470518112183)
[2024-11-13 05:07:33,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:34,032][root][INFO] - Training Epoch: 3/10, step 60/574 completed (loss: 1.4328017234802246, acc: 0.5724637508392334)
[2024-11-13 05:07:34,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:34,438][root][INFO] - Training Epoch: 3/10, step 61/574 completed (loss: 1.3417670726776123, acc: 0.637499988079071)
[2024-11-13 05:07:34,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:34,748][root][INFO] - Training Epoch: 3/10, step 62/574 completed (loss: 0.774060845375061, acc: 0.7647058963775635)
[2024-11-13 05:07:34,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:35,113][root][INFO] - Training Epoch: 3/10, step 63/574 completed (loss: 0.5465060472488403, acc: 0.8333333134651184)
[2024-11-13 05:07:35,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:35,502][root][INFO] - Training Epoch: 3/10, step 64/574 completed (loss: 0.7321784496307373, acc: 0.796875)
[2024-11-13 05:07:35,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:35,856][root][INFO] - Training Epoch: 3/10, step 65/574 completed (loss: 0.4384159445762634, acc: 0.8275862336158752)
[2024-11-13 05:07:35,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:36,216][root][INFO] - Training Epoch: 3/10, step 66/574 completed (loss: 1.283590316772461, acc: 0.6964285969734192)
[2024-11-13 05:07:36,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:36,570][root][INFO] - Training Epoch: 3/10, step 67/574 completed (loss: 0.8692257404327393, acc: 0.7833333611488342)
[2024-11-13 05:07:36,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:36,949][root][INFO] - Training Epoch: 3/10, step 68/574 completed (loss: 0.2230488359928131, acc: 0.9599999785423279)
[2024-11-13 05:07:37,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:37,296][root][INFO] - Training Epoch: 3/10, step 69/574 completed (loss: 1.0828583240509033, acc: 0.7777777910232544)
[2024-11-13 05:07:37,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:37,630][root][INFO] - Training Epoch: 3/10, step 70/574 completed (loss: 1.554800033569336, acc: 0.6363636255264282)
[2024-11-13 05:07:37,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:37,892][root][INFO] - Training Epoch: 3/10, step 71/574 completed (loss: 1.3978708982467651, acc: 0.6029411554336548)
[2024-11-13 05:07:37,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:38,264][root][INFO] - Training Epoch: 3/10, step 72/574 completed (loss: 1.3110685348510742, acc: 0.6111111044883728)
[2024-11-13 05:07:38,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:38,660][root][INFO] - Training Epoch: 3/10, step 73/574 completed (loss: 1.8534456491470337, acc: 0.482051283121109)
[2024-11-13 05:07:38,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:38,995][root][INFO] - Training Epoch: 3/10, step 74/574 completed (loss: 1.4886358976364136, acc: 0.6122449040412903)
[2024-11-13 05:07:39,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:39,370][root][INFO] - Training Epoch: 3/10, step 75/574 completed (loss: 1.6907258033752441, acc: 0.5298507213592529)
[2024-11-13 05:07:39,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:39,781][root][INFO] - Training Epoch: 3/10, step 76/574 completed (loss: 1.8187586069107056, acc: 0.49635037779808044)
[2024-11-13 05:07:39,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:40,128][root][INFO] - Training Epoch: 3/10, step 77/574 completed (loss: 0.2584872245788574, acc: 0.9047619104385376)
[2024-11-13 05:07:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:40,429][root][INFO] - Training Epoch: 3/10, step 78/574 completed (loss: 0.4366006553173065, acc: 0.9166666865348816)
[2024-11-13 05:07:40,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:40,735][root][INFO] - Training Epoch: 3/10, step 79/574 completed (loss: 0.613987386226654, acc: 0.8484848737716675)
[2024-11-13 05:07:40,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:41,109][root][INFO] - Training Epoch: 3/10, step 80/574 completed (loss: 0.3612135052680969, acc: 0.9615384340286255)
[2024-11-13 05:07:41,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:41,483][root][INFO] - Training Epoch: 3/10, step 81/574 completed (loss: 1.319913625717163, acc: 0.6153846383094788)
[2024-11-13 05:07:41,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:41,843][root][INFO] - Training Epoch: 3/10, step 82/574 completed (loss: 1.468292474746704, acc: 0.6538461446762085)
[2024-11-13 05:07:41,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:42,143][root][INFO] - Training Epoch: 3/10, step 83/574 completed (loss: 0.6274703145027161, acc: 0.84375)
[2024-11-13 05:07:42,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:42,521][root][INFO] - Training Epoch: 3/10, step 84/574 completed (loss: 0.8784540295600891, acc: 0.7681159377098083)
[2024-11-13 05:07:42,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:42,884][root][INFO] - Training Epoch: 3/10, step 85/574 completed (loss: 0.9388049244880676, acc: 0.7200000286102295)
[2024-11-13 05:07:42,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:43,243][root][INFO] - Training Epoch: 3/10, step 86/574 completed (loss: 0.5924433469772339, acc: 0.695652186870575)
[2024-11-13 05:07:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:43,695][root][INFO] - Training Epoch: 3/10, step 87/574 completed (loss: 1.6325328350067139, acc: 0.47999998927116394)
[2024-11-13 05:07:43,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:44,067][root][INFO] - Training Epoch: 3/10, step 88/574 completed (loss: 1.3763439655303955, acc: 0.6601941585540771)
[2024-11-13 05:07:44,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:45,212][root][INFO] - Training Epoch: 3/10, step 89/574 completed (loss: 1.3041974306106567, acc: 0.6747573018074036)
[2024-11-13 05:07:45,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:46,059][root][INFO] - Training Epoch: 3/10, step 90/574 completed (loss: 1.5771772861480713, acc: 0.5645161271095276)
[2024-11-13 05:07:46,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:46,866][root][INFO] - Training Epoch: 3/10, step 91/574 completed (loss: 1.3367043733596802, acc: 0.6637930870056152)
[2024-11-13 05:07:47,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:47,608][root][INFO] - Training Epoch: 3/10, step 92/574 completed (loss: 1.2118772268295288, acc: 0.6315789222717285)
[2024-11-13 05:07:47,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:48,598][root][INFO] - Training Epoch: 3/10, step 93/574 completed (loss: 1.8579834699630737, acc: 0.4653465449810028)
[2024-11-13 05:07:48,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:48,903][root][INFO] - Training Epoch: 3/10, step 94/574 completed (loss: 1.6512645483016968, acc: 0.5483871102333069)
[2024-11-13 05:07:48,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:49,273][root][INFO] - Training Epoch: 3/10, step 95/574 completed (loss: 1.355470895767212, acc: 0.5507246255874634)
[2024-11-13 05:07:49,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:49,638][root][INFO] - Training Epoch: 3/10, step 96/574 completed (loss: 1.955512523651123, acc: 0.4453781545162201)
[2024-11-13 05:07:49,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:50,023][root][INFO] - Training Epoch: 3/10, step 97/574 completed (loss: 1.8572337627410889, acc: 0.4615384638309479)
[2024-11-13 05:07:50,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:50,432][root][INFO] - Training Epoch: 3/10, step 98/574 completed (loss: 1.899096131324768, acc: 0.43065693974494934)
[2024-11-13 05:07:50,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:50,823][root][INFO] - Training Epoch: 3/10, step 99/574 completed (loss: 1.9155412912368774, acc: 0.43283581733703613)
[2024-11-13 05:07:50,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:51,201][root][INFO] - Training Epoch: 3/10, step 100/574 completed (loss: 0.7957105040550232, acc: 0.75)
[2024-11-13 05:07:51,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:51,540][root][INFO] - Training Epoch: 3/10, step 101/574 completed (loss: 0.1768413931131363, acc: 0.9545454382896423)
[2024-11-13 05:07:51,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:51,833][root][INFO] - Training Epoch: 3/10, step 102/574 completed (loss: 0.19932861626148224, acc: 0.95652174949646)
[2024-11-13 05:07:51,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:52,212][root][INFO] - Training Epoch: 3/10, step 103/574 completed (loss: 0.4390162527561188, acc: 0.9090909361839294)
[2024-11-13 05:07:52,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:52,587][root][INFO] - Training Epoch: 3/10, step 104/574 completed (loss: 0.8679935336112976, acc: 0.7758620977401733)
[2024-11-13 05:07:52,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:52,901][root][INFO] - Training Epoch: 3/10, step 105/574 completed (loss: 0.7528583407402039, acc: 0.7674418687820435)
[2024-11-13 05:07:52,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:53,201][root][INFO] - Training Epoch: 3/10, step 106/574 completed (loss: 0.708446204662323, acc: 0.800000011920929)
[2024-11-13 05:07:53,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:53,513][root][INFO] - Training Epoch: 3/10, step 107/574 completed (loss: 0.17878372967243195, acc: 0.9411764740943909)
[2024-11-13 05:07:53,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:53,906][root][INFO] - Training Epoch: 3/10, step 108/574 completed (loss: 0.11553143709897995, acc: 0.9615384340286255)
[2024-11-13 05:07:54,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:54,226][root][INFO] - Training Epoch: 3/10, step 109/574 completed (loss: 0.5135533213615417, acc: 0.8333333134651184)
[2024-11-13 05:07:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:54,570][root][INFO] - Training Epoch: 3/10, step 110/574 completed (loss: 0.6720066070556641, acc: 0.8461538553237915)
[2024-11-13 05:07:54,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:55,002][root][INFO] - Training Epoch: 3/10, step 111/574 completed (loss: 1.076507329940796, acc: 0.719298243522644)
[2024-11-13 05:07:55,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:55,402][root][INFO] - Training Epoch: 3/10, step 112/574 completed (loss: 1.2216938734054565, acc: 0.6666666865348816)
[2024-11-13 05:07:55,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:55,802][root][INFO] - Training Epoch: 3/10, step 113/574 completed (loss: 0.8474690318107605, acc: 0.7948718070983887)
[2024-11-13 05:07:55,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:56,179][root][INFO] - Training Epoch: 3/10, step 114/574 completed (loss: 0.5125832557678223, acc: 0.8367347121238708)
[2024-11-13 05:07:56,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:56,563][root][INFO] - Training Epoch: 3/10, step 115/574 completed (loss: 0.21820107102394104, acc: 0.9545454382896423)
[2024-11-13 05:07:56,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:57,002][root][INFO] - Training Epoch: 3/10, step 116/574 completed (loss: 1.22031831741333, acc: 0.6984127163887024)
[2024-11-13 05:07:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:57,357][root][INFO] - Training Epoch: 3/10, step 117/574 completed (loss: 1.274269700050354, acc: 0.642276406288147)
[2024-11-13 05:07:57,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:57,760][root][INFO] - Training Epoch: 3/10, step 118/574 completed (loss: 1.1606849431991577, acc: 0.6935483813285828)
[2024-11-13 05:07:58,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:58,693][root][INFO] - Training Epoch: 3/10, step 119/574 completed (loss: 1.5988880395889282, acc: 0.5931559205055237)
[2024-11-13 05:07:58,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:59,079][root][INFO] - Training Epoch: 3/10, step 120/574 completed (loss: 0.8312872052192688, acc: 0.7599999904632568)
[2024-11-13 05:07:59,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:59,480][root][INFO] - Training Epoch: 3/10, step 121/574 completed (loss: 1.0131056308746338, acc: 0.7307692170143127)
[2024-11-13 05:07:59,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:07:59,780][root][INFO] - Training Epoch: 3/10, step 122/574 completed (loss: 0.43337884545326233, acc: 0.7916666865348816)
[2024-11-13 05:07:59,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:00,084][root][INFO] - Training Epoch: 3/10, step 123/574 completed (loss: 0.8294218182563782, acc: 0.7894737124443054)
[2024-11-13 05:08:00,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:00,473][root][INFO] - Training Epoch: 3/10, step 124/574 completed (loss: 1.5734820365905762, acc: 0.5766870975494385)
[2024-11-13 05:08:00,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:00,882][root][INFO] - Training Epoch: 3/10, step 125/574 completed (loss: 1.6962964534759521, acc: 0.5625)
[2024-11-13 05:08:00,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:01,289][root][INFO] - Training Epoch: 3/10, step 126/574 completed (loss: 1.6714707612991333, acc: 0.5166666507720947)
[2024-11-13 05:08:01,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:01,675][root][INFO] - Training Epoch: 3/10, step 127/574 completed (loss: 1.7677702903747559, acc: 0.5178571343421936)
[2024-11-13 05:08:01,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:02,037][root][INFO] - Training Epoch: 3/10, step 128/574 completed (loss: 1.384088397026062, acc: 0.6307692527770996)
[2024-11-13 05:08:02,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:02,443][root][INFO] - Training Epoch: 3/10, step 129/574 completed (loss: 1.4794410467147827, acc: 0.5882353186607361)
[2024-11-13 05:08:02,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:02,801][root][INFO] - Training Epoch: 3/10, step 130/574 completed (loss: 0.734573483467102, acc: 0.7307692170143127)
[2024-11-13 05:08:02,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:03,160][root][INFO] - Training Epoch: 3/10, step 131/574 completed (loss: 0.43413829803466797, acc: 0.8695651888847351)
[2024-11-13 05:08:03,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:03,520][root][INFO] - Training Epoch: 3/10, step 132/574 completed (loss: 1.182401180267334, acc: 0.625)
[2024-11-13 05:08:03,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:03,909][root][INFO] - Training Epoch: 3/10, step 133/574 completed (loss: 1.4915071725845337, acc: 0.5652173757553101)
[2024-11-13 05:08:04,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:04,284][root][INFO] - Training Epoch: 3/10, step 134/574 completed (loss: 0.9601171016693115, acc: 0.7142857313156128)
[2024-11-13 05:08:04,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:04,602][root][INFO] - Training Epoch: 3/10, step 135/574 completed (loss: 0.7698990702629089, acc: 0.7692307829856873)
[2024-11-13 05:08:04,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:04,924][root][INFO] - Training Epoch: 3/10, step 136/574 completed (loss: 1.22447669506073, acc: 0.6666666865348816)
[2024-11-13 05:08:05,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:05,273][root][INFO] - Training Epoch: 3/10, step 137/574 completed (loss: 1.196381688117981, acc: 0.6333333253860474)
[2024-11-13 05:08:05,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:05,659][root][INFO] - Training Epoch: 3/10, step 138/574 completed (loss: 1.2941007614135742, acc: 0.6521739363670349)
[2024-11-13 05:08:06,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:07,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:07,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:07,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:08,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:08,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:08,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:09,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:09,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:10,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:10,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:10,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:11,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:11,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:11,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:12,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:12,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:12,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:13,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:13,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:13,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:14,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:14,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:14,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:15,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:15,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:15,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:16,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:16,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:16,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:17,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:17,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:17,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:18,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:18,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:18,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:19,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:19,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:19,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:20,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:20,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:21,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:21,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:21,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:22,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:22,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:23,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:23,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:23,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:23,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:24,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:24,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:24,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:25,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:25,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:26,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:26,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:26,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:27,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:27,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:28,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:28,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:29,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:29,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:29,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:30,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:30,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:30,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:31,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:31,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:32,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:32,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:33,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:33,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:33,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:34,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:34,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:35,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:35,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:35,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:36,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:36,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:36,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:37,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:37,725][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.7425, device='cuda:0') eval_epoch_loss=tensor(1.0089, device='cuda:0') eval_epoch_acc=tensor(0.7193, device='cuda:0')
[2024-11-13 05:08:37,726][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:08:37,727][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:08:38,109][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_3_step_139_loss_1.008852243423462/model.pt
[2024-11-13 05:08:38,114][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:08:38,114][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 1.008852243423462
[2024-11-13 05:08:38,115][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7193449139595032
[2024-11-13 05:08:38,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:38,442][root][INFO] - Training Epoch: 3/10, step 139/574 completed (loss: 1.260197639465332, acc: 0.6666666865348816)
[2024-11-13 05:08:38,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:38,743][root][INFO] - Training Epoch: 3/10, step 140/574 completed (loss: 1.570211410522461, acc: 0.5)
[2024-11-13 05:08:38,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:39,035][root][INFO] - Training Epoch: 3/10, step 141/574 completed (loss: 1.596954345703125, acc: 0.5483871102333069)
[2024-11-13 05:08:39,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:39,339][root][INFO] - Training Epoch: 3/10, step 142/574 completed (loss: 1.3240299224853516, acc: 0.5945945978164673)
[2024-11-13 05:08:39,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:39,872][root][INFO] - Training Epoch: 3/10, step 143/574 completed (loss: 1.4090434312820435, acc: 0.5877193212509155)
[2024-11-13 05:08:39,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:40,186][root][INFO] - Training Epoch: 3/10, step 144/574 completed (loss: 1.1794779300689697, acc: 0.6791045069694519)
[2024-11-13 05:08:40,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:40,536][root][INFO] - Training Epoch: 3/10, step 145/574 completed (loss: 1.3327056169509888, acc: 0.6122449040412903)
[2024-11-13 05:08:40,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:40,975][root][INFO] - Training Epoch: 3/10, step 146/574 completed (loss: 1.5832509994506836, acc: 0.521276593208313)
[2024-11-13 05:08:41,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:41,283][root][INFO] - Training Epoch: 3/10, step 147/574 completed (loss: 1.326418399810791, acc: 0.6571428775787354)
[2024-11-13 05:08:41,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:41,651][root][INFO] - Training Epoch: 3/10, step 148/574 completed (loss: 1.6229093074798584, acc: 0.5357142686843872)
[2024-11-13 05:08:41,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:41,985][root][INFO] - Training Epoch: 3/10, step 149/574 completed (loss: 0.8028002977371216, acc: 0.695652186870575)
[2024-11-13 05:08:42,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:42,276][root][INFO] - Training Epoch: 3/10, step 150/574 completed (loss: 1.0717887878417969, acc: 0.6896551847457886)
[2024-11-13 05:08:42,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:42,615][root][INFO] - Training Epoch: 3/10, step 151/574 completed (loss: 1.7099770307540894, acc: 0.5869565010070801)
[2024-11-13 05:08:42,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:42,961][root][INFO] - Training Epoch: 3/10, step 152/574 completed (loss: 1.1775158643722534, acc: 0.6779661178588867)
[2024-11-13 05:08:43,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:43,277][root][INFO] - Training Epoch: 3/10, step 153/574 completed (loss: 1.6866393089294434, acc: 0.5614035129547119)
[2024-11-13 05:08:43,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:43,558][root][INFO] - Training Epoch: 3/10, step 154/574 completed (loss: 1.0522807836532593, acc: 0.7432432174682617)
[2024-11-13 05:08:43,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:43,940][root][INFO] - Training Epoch: 3/10, step 155/574 completed (loss: 0.7904546856880188, acc: 0.8214285969734192)
[2024-11-13 05:08:44,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:44,281][root][INFO] - Training Epoch: 3/10, step 156/574 completed (loss: 0.7372413873672485, acc: 0.782608687877655)
[2024-11-13 05:08:44,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:44,671][root][INFO] - Training Epoch: 3/10, step 157/574 completed (loss: 1.913193702697754, acc: 0.42105263471603394)
[2024-11-13 05:08:45,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:46,400][root][INFO] - Training Epoch: 3/10, step 158/574 completed (loss: 1.204297661781311, acc: 0.6891891956329346)
[2024-11-13 05:08:46,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:46,692][root][INFO] - Training Epoch: 3/10, step 159/574 completed (loss: 1.7121232748031616, acc: 0.5370370149612427)
[2024-11-13 05:08:46,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:47,078][root][INFO] - Training Epoch: 3/10, step 160/574 completed (loss: 1.5824930667877197, acc: 0.5)
[2024-11-13 05:08:47,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:47,690][root][INFO] - Training Epoch: 3/10, step 161/574 completed (loss: 1.6092476844787598, acc: 0.48235294222831726)
[2024-11-13 05:08:47,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:48,255][root][INFO] - Training Epoch: 3/10, step 162/574 completed (loss: 1.5978319644927979, acc: 0.5730336904525757)
[2024-11-13 05:08:48,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:48,567][root][INFO] - Training Epoch: 3/10, step 163/574 completed (loss: 0.763430655002594, acc: 0.8181818127632141)
[2024-11-13 05:08:48,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:48,862][root][INFO] - Training Epoch: 3/10, step 164/574 completed (loss: 0.6228964924812317, acc: 0.8095238208770752)
[2024-11-13 05:08:48,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:49,169][root][INFO] - Training Epoch: 3/10, step 165/574 completed (loss: 1.1148462295532227, acc: 0.7586206793785095)
[2024-11-13 05:08:49,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:49,470][root][INFO] - Training Epoch: 3/10, step 166/574 completed (loss: 0.5956656336784363, acc: 0.8163265585899353)
[2024-11-13 05:08:49,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:49,836][root][INFO] - Training Epoch: 3/10, step 167/574 completed (loss: 0.7765410542488098, acc: 0.7400000095367432)
[2024-11-13 05:08:49,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:50,237][root][INFO] - Training Epoch: 3/10, step 168/574 completed (loss: 1.087948203086853, acc: 0.6805555820465088)
[2024-11-13 05:08:50,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:50,550][root][INFO] - Training Epoch: 3/10, step 169/574 completed (loss: 1.5716701745986938, acc: 0.6078431606292725)
[2024-11-13 05:08:50,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:51,680][root][INFO] - Training Epoch: 3/10, step 170/574 completed (loss: 1.678576946258545, acc: 0.6095890402793884)
[2024-11-13 05:08:51,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:51,993][root][INFO] - Training Epoch: 3/10, step 171/574 completed (loss: 0.6300848126411438, acc: 0.875)
[2024-11-13 05:08:52,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:52,312][root][INFO] - Training Epoch: 3/10, step 172/574 completed (loss: 0.7875827550888062, acc: 0.7037037014961243)
[2024-11-13 05:08:52,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:52,642][root][INFO] - Training Epoch: 3/10, step 173/574 completed (loss: 1.1093790531158447, acc: 0.75)
[2024-11-13 05:08:52,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:53,193][root][INFO] - Training Epoch: 3/10, step 174/574 completed (loss: 1.4063477516174316, acc: 0.6283186078071594)
[2024-11-13 05:08:53,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:53,505][root][INFO] - Training Epoch: 3/10, step 175/574 completed (loss: 1.1497191190719604, acc: 0.695652186870575)
[2024-11-13 05:08:53,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:53,854][root][INFO] - Training Epoch: 3/10, step 176/574 completed (loss: 0.865490734577179, acc: 0.75)
[2024-11-13 05:08:54,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:54,897][root][INFO] - Training Epoch: 3/10, step 177/574 completed (loss: 1.5793697834014893, acc: 0.5648854970932007)
[2024-11-13 05:08:55,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:55,566][root][INFO] - Training Epoch: 3/10, step 178/574 completed (loss: 1.4387370347976685, acc: 0.5703703761100769)
[2024-11-13 05:08:55,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:55,922][root][INFO] - Training Epoch: 3/10, step 179/574 completed (loss: 0.8716591596603394, acc: 0.7049180269241333)
[2024-11-13 05:08:56,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:56,255][root][INFO] - Training Epoch: 3/10, step 180/574 completed (loss: 0.10685619711875916, acc: 1.0)
[2024-11-13 05:08:56,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:56,553][root][INFO] - Training Epoch: 3/10, step 181/574 completed (loss: 0.4605581760406494, acc: 0.8799999952316284)
[2024-11-13 05:08:56,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:56,843][root][INFO] - Training Epoch: 3/10, step 182/574 completed (loss: 0.338577002286911, acc: 0.9285714030265808)
[2024-11-13 05:08:56,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:57,214][root][INFO] - Training Epoch: 3/10, step 183/574 completed (loss: 0.8298989534378052, acc: 0.7682926654815674)
[2024-11-13 05:08:57,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:57,595][root][INFO] - Training Epoch: 3/10, step 184/574 completed (loss: 1.1331218481063843, acc: 0.6888217329978943)
[2024-11-13 05:08:57,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:57,931][root][INFO] - Training Epoch: 3/10, step 185/574 completed (loss: 1.2433819770812988, acc: 0.6426513195037842)
[2024-11-13 05:08:58,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:58,407][root][INFO] - Training Epoch: 3/10, step 186/574 completed (loss: 1.3919525146484375, acc: 0.6156250238418579)
[2024-11-13 05:08:58,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:58,932][root][INFO] - Training Epoch: 3/10, step 187/574 completed (loss: 1.2023309469223022, acc: 0.6697936058044434)
[2024-11-13 05:08:59,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:59,352][root][INFO] - Training Epoch: 3/10, step 188/574 completed (loss: 1.1197059154510498, acc: 0.6654804348945618)
[2024-11-13 05:08:59,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:08:59,660][root][INFO] - Training Epoch: 3/10, step 189/574 completed (loss: 0.954699695110321, acc: 0.800000011920929)
[2024-11-13 05:08:59,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:00,215][root][INFO] - Training Epoch: 3/10, step 190/574 completed (loss: 1.5780121088027954, acc: 0.569767415523529)
[2024-11-13 05:09:00,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:01,026][root][INFO] - Training Epoch: 3/10, step 191/574 completed (loss: 1.8136765956878662, acc: 0.5158730149269104)
[2024-11-13 05:09:01,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:02,066][root][INFO] - Training Epoch: 3/10, step 192/574 completed (loss: 1.5543535947799683, acc: 0.5303030014038086)
[2024-11-13 05:09:02,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:02,813][root][INFO] - Training Epoch: 3/10, step 193/574 completed (loss: 1.021189570426941, acc: 0.6941176652908325)
[2024-11-13 05:09:03,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:03,922][root][INFO] - Training Epoch: 3/10, step 194/574 completed (loss: 1.4168771505355835, acc: 0.604938268661499)
[2024-11-13 05:09:04,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:04,900][root][INFO] - Training Epoch: 3/10, step 195/574 completed (loss: 0.9955421686172485, acc: 0.7096773982048035)
[2024-11-13 05:09:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:05,248][root][INFO] - Training Epoch: 3/10, step 196/574 completed (loss: 0.26512497663497925, acc: 0.8928571343421936)
[2024-11-13 05:09:05,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:05,546][root][INFO] - Training Epoch: 3/10, step 197/574 completed (loss: 1.2564702033996582, acc: 0.6499999761581421)
[2024-11-13 05:09:05,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:05,836][root][INFO] - Training Epoch: 3/10, step 198/574 completed (loss: 1.119718313217163, acc: 0.6323529481887817)
[2024-11-13 05:09:05,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:06,152][root][INFO] - Training Epoch: 3/10, step 199/574 completed (loss: 1.2369048595428467, acc: 0.654411792755127)
[2024-11-13 05:09:06,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:06,536][root][INFO] - Training Epoch: 3/10, step 200/574 completed (loss: 1.1299101114273071, acc: 0.694915235042572)
[2024-11-13 05:09:06,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:06,931][root][INFO] - Training Epoch: 3/10, step 201/574 completed (loss: 1.2408396005630493, acc: 0.6567164063453674)
[2024-11-13 05:09:07,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:07,321][root][INFO] - Training Epoch: 3/10, step 202/574 completed (loss: 1.2482880353927612, acc: 0.6407766938209534)
[2024-11-13 05:09:07,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:07,700][root][INFO] - Training Epoch: 3/10, step 203/574 completed (loss: 1.3376433849334717, acc: 0.6349206566810608)
[2024-11-13 05:09:07,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:08,087][root][INFO] - Training Epoch: 3/10, step 204/574 completed (loss: 0.7518527507781982, acc: 0.8021978139877319)
[2024-11-13 05:09:08,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:08,484][root][INFO] - Training Epoch: 3/10, step 205/574 completed (loss: 0.974181056022644, acc: 0.726457417011261)
[2024-11-13 05:09:08,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:08,914][root][INFO] - Training Epoch: 3/10, step 206/574 completed (loss: 1.083827257156372, acc: 0.7047244310379028)
[2024-11-13 05:09:09,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:09,261][root][INFO] - Training Epoch: 3/10, step 207/574 completed (loss: 0.9233335256576538, acc: 0.7241379022598267)
[2024-11-13 05:09:09,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:09,673][root][INFO] - Training Epoch: 3/10, step 208/574 completed (loss: 0.8635138869285583, acc: 0.7898550629615784)
[2024-11-13 05:09:09,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:10,050][root][INFO] - Training Epoch: 3/10, step 209/574 completed (loss: 1.0208914279937744, acc: 0.731517493724823)
[2024-11-13 05:09:10,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:10,378][root][INFO] - Training Epoch: 3/10, step 210/574 completed (loss: 1.1252564191818237, acc: 0.695652186870575)
[2024-11-13 05:09:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:10,706][root][INFO] - Training Epoch: 3/10, step 211/574 completed (loss: 0.2733551561832428, acc: 0.8695651888847351)
[2024-11-13 05:09:10,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:11,022][root][INFO] - Training Epoch: 3/10, step 212/574 completed (loss: 0.46112754940986633, acc: 0.8214285969734192)
[2024-11-13 05:09:11,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:11,374][root][INFO] - Training Epoch: 3/10, step 213/574 completed (loss: 0.3633612096309662, acc: 0.8723404407501221)
[2024-11-13 05:09:11,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:12,097][root][INFO] - Training Epoch: 3/10, step 214/574 completed (loss: 0.4549855887889862, acc: 0.892307698726654)
[2024-11-13 05:09:12,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:12,432][root][INFO] - Training Epoch: 3/10, step 215/574 completed (loss: 0.5529399514198303, acc: 0.7972972989082336)
[2024-11-13 05:09:12,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:12,861][root][INFO] - Training Epoch: 3/10, step 216/574 completed (loss: 0.3872000575065613, acc: 0.9069767594337463)
[2024-11-13 05:09:13,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:13,398][root][INFO] - Training Epoch: 3/10, step 217/574 completed (loss: 0.6056528091430664, acc: 0.8288288116455078)
[2024-11-13 05:09:13,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:13,821][root][INFO] - Training Epoch: 3/10, step 218/574 completed (loss: 0.40273725986480713, acc: 0.8777777552604675)
[2024-11-13 05:09:13,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:14,132][root][INFO] - Training Epoch: 3/10, step 219/574 completed (loss: 0.4303181767463684, acc: 0.8787878751754761)
[2024-11-13 05:09:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:14,428][root][INFO] - Training Epoch: 3/10, step 220/574 completed (loss: 0.23139320313930511, acc: 0.9629629850387573)
[2024-11-13 05:09:14,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:14,742][root][INFO] - Training Epoch: 3/10, step 221/574 completed (loss: 0.34959059953689575, acc: 0.8799999952316284)
[2024-11-13 05:09:14,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:15,098][root][INFO] - Training Epoch: 3/10, step 222/574 completed (loss: 1.2357585430145264, acc: 0.6346153616905212)
[2024-11-13 05:09:15,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:15,924][root][INFO] - Training Epoch: 3/10, step 223/574 completed (loss: 0.8262444138526917, acc: 0.75)
[2024-11-13 05:09:16,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:16,465][root][INFO] - Training Epoch: 3/10, step 224/574 completed (loss: 0.9040506482124329, acc: 0.7613636255264282)
[2024-11-13 05:09:16,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:16,902][root][INFO] - Training Epoch: 3/10, step 225/574 completed (loss: 1.1591647863388062, acc: 0.6595744490623474)
[2024-11-13 05:09:16,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:17,270][root][INFO] - Training Epoch: 3/10, step 226/574 completed (loss: 0.9704201221466064, acc: 0.7169811129570007)
[2024-11-13 05:09:17,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:17,610][root][INFO] - Training Epoch: 3/10, step 227/574 completed (loss: 0.727982759475708, acc: 0.7833333611488342)
[2024-11-13 05:09:17,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:17,918][root][INFO] - Training Epoch: 3/10, step 228/574 completed (loss: 0.520025372505188, acc: 0.8837209343910217)
[2024-11-13 05:09:17,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:18,265][root][INFO] - Training Epoch: 3/10, step 229/574 completed (loss: 1.3220584392547607, acc: 0.6333333253860474)
[2024-11-13 05:09:18,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:18,650][root][INFO] - Training Epoch: 3/10, step 230/574 completed (loss: 2.3525161743164062, acc: 0.378947377204895)
[2024-11-13 05:09:18,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:18,990][root][INFO] - Training Epoch: 3/10, step 231/574 completed (loss: 1.574305534362793, acc: 0.5888888835906982)
[2024-11-13 05:09:19,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:19,417][root][INFO] - Training Epoch: 3/10, step 232/574 completed (loss: 1.5437432527542114, acc: 0.5833333134651184)
[2024-11-13 05:09:19,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:19,902][root][INFO] - Training Epoch: 3/10, step 233/574 completed (loss: 1.7288793325424194, acc: 0.5458715558052063)
[2024-11-13 05:09:20,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:20,370][root][INFO] - Training Epoch: 3/10, step 234/574 completed (loss: 1.5160664319992065, acc: 0.5692307949066162)
[2024-11-13 05:09:20,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:20,719][root][INFO] - Training Epoch: 3/10, step 235/574 completed (loss: 0.6518846154212952, acc: 0.8421052694320679)
[2024-11-13 05:09:20,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:21,076][root][INFO] - Training Epoch: 3/10, step 236/574 completed (loss: 0.8696239590644836, acc: 0.7916666865348816)
[2024-11-13 05:09:21,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:21,395][root][INFO] - Training Epoch: 3/10, step 237/574 completed (loss: 2.242729425430298, acc: 0.5454545617103577)
[2024-11-13 05:09:21,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:21,803][root][INFO] - Training Epoch: 3/10, step 238/574 completed (loss: 1.0825684070587158, acc: 0.7407407164573669)
[2024-11-13 05:09:21,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:22,208][root][INFO] - Training Epoch: 3/10, step 239/574 completed (loss: 0.9340925812721252, acc: 0.7142857313156128)
[2024-11-13 05:09:22,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:22,588][root][INFO] - Training Epoch: 3/10, step 240/574 completed (loss: 1.1532988548278809, acc: 0.6363636255264282)
[2024-11-13 05:09:22,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:22,958][root][INFO] - Training Epoch: 3/10, step 241/574 completed (loss: 1.1952624320983887, acc: 0.6136363744735718)
[2024-11-13 05:09:23,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:23,579][root][INFO] - Training Epoch: 3/10, step 242/574 completed (loss: 1.6731183528900146, acc: 0.5161290168762207)
[2024-11-13 05:09:23,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:24,109][root][INFO] - Training Epoch: 3/10, step 243/574 completed (loss: 1.3264274597167969, acc: 0.6363636255264282)
[2024-11-13 05:09:24,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:24,414][root][INFO] - Training Epoch: 3/10, step 244/574 completed (loss: 0.21229912340641022, acc: 0.9523809552192688)
[2024-11-13 05:09:24,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:24,696][root][INFO] - Training Epoch: 3/10, step 245/574 completed (loss: 0.5463775992393494, acc: 0.807692289352417)
[2024-11-13 05:09:24,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:25,065][root][INFO] - Training Epoch: 3/10, step 246/574 completed (loss: 0.7017983198165894, acc: 0.8387096524238586)
[2024-11-13 05:09:25,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:25,399][root][INFO] - Training Epoch: 3/10, step 247/574 completed (loss: 0.5978840589523315, acc: 0.800000011920929)
[2024-11-13 05:09:25,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:25,757][root][INFO] - Training Epoch: 3/10, step 248/574 completed (loss: 0.8012592792510986, acc: 0.7567567825317383)
[2024-11-13 05:09:25,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:26,127][root][INFO] - Training Epoch: 3/10, step 249/574 completed (loss: 0.7824985980987549, acc: 0.6756756901741028)
[2024-11-13 05:09:26,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:26,484][root][INFO] - Training Epoch: 3/10, step 250/574 completed (loss: 0.6901405453681946, acc: 0.837837815284729)
[2024-11-13 05:09:26,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:26,853][root][INFO] - Training Epoch: 3/10, step 251/574 completed (loss: 0.5757524371147156, acc: 0.8235294222831726)
[2024-11-13 05:09:26,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:27,214][root][INFO] - Training Epoch: 3/10, step 252/574 completed (loss: 0.24246685206890106, acc: 0.9512194991111755)
[2024-11-13 05:09:27,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:27,569][root][INFO] - Training Epoch: 3/10, step 253/574 completed (loss: 0.23970440030097961, acc: 0.9599999785423279)
[2024-11-13 05:09:27,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:27,879][root][INFO] - Training Epoch: 3/10, step 254/574 completed (loss: 0.0828770324587822, acc: 1.0)
[2024-11-13 05:09:27,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:28,205][root][INFO] - Training Epoch: 3/10, step 255/574 completed (loss: 0.2629890739917755, acc: 0.9354838728904724)
[2024-11-13 05:09:28,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:28,575][root][INFO] - Training Epoch: 3/10, step 256/574 completed (loss: 0.4605976641178131, acc: 0.9122806787490845)
[2024-11-13 05:09:28,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:28,873][root][INFO] - Training Epoch: 3/10, step 257/574 completed (loss: 0.4513145983219147, acc: 0.8571428656578064)
[2024-11-13 05:09:28,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:29,260][root][INFO] - Training Epoch: 3/10, step 258/574 completed (loss: 0.6648405194282532, acc: 0.8552631735801697)
[2024-11-13 05:09:29,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:29,871][root][INFO] - Training Epoch: 3/10, step 259/574 completed (loss: 1.0444175004959106, acc: 0.7452830076217651)
[2024-11-13 05:09:30,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:30,479][root][INFO] - Training Epoch: 3/10, step 260/574 completed (loss: 0.9043437838554382, acc: 0.7333333492279053)
[2024-11-13 05:09:30,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:30,812][root][INFO] - Training Epoch: 3/10, step 261/574 completed (loss: 0.32218727469444275, acc: 0.8888888955116272)
[2024-11-13 05:09:30,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:31,144][root][INFO] - Training Epoch: 3/10, step 262/574 completed (loss: 0.8259475827217102, acc: 0.8387096524238586)
[2024-11-13 05:09:31,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:31,549][root][INFO] - Training Epoch: 3/10, step 263/574 completed (loss: 1.7155916690826416, acc: 0.5600000023841858)
[2024-11-13 05:09:31,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:31,899][root][INFO] - Training Epoch: 3/10, step 264/574 completed (loss: 1.1284576654434204, acc: 0.6875)
[2024-11-13 05:09:32,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:32,784][root][INFO] - Training Epoch: 3/10, step 265/574 completed (loss: 1.5995683670043945, acc: 0.5680000185966492)
[2024-11-13 05:09:32,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:33,156][root][INFO] - Training Epoch: 3/10, step 266/574 completed (loss: 1.4050889015197754, acc: 0.5955055952072144)
[2024-11-13 05:09:33,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:33,525][root][INFO] - Training Epoch: 3/10, step 267/574 completed (loss: 1.3606210947036743, acc: 0.6216216087341309)
[2024-11-13 05:09:33,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:33,990][root][INFO] - Training Epoch: 3/10, step 268/574 completed (loss: 0.9499806761741638, acc: 0.7068965435028076)
[2024-11-13 05:09:34,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:34,364][root][INFO] - Training Epoch: 3/10, step 269/574 completed (loss: 0.1984102874994278, acc: 0.9545454382896423)
[2024-11-13 05:09:34,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:34,768][root][INFO] - Training Epoch: 3/10, step 270/574 completed (loss: 0.3304422199726105, acc: 0.9090909361839294)
[2024-11-13 05:09:34,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:35,128][root][INFO] - Training Epoch: 3/10, step 271/574 completed (loss: 0.4290050268173218, acc: 0.875)
[2024-11-13 05:09:35,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:35,477][root][INFO] - Training Epoch: 3/10, step 272/574 completed (loss: 0.3407198488712311, acc: 0.8666666746139526)
[2024-11-13 05:09:35,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:35,840][root][INFO] - Training Epoch: 3/10, step 273/574 completed (loss: 0.9273532032966614, acc: 0.75)
[2024-11-13 05:09:35,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:36,148][root][INFO] - Training Epoch: 3/10, step 274/574 completed (loss: 0.3117848038673401, acc: 0.90625)
[2024-11-13 05:09:36,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:36,484][root][INFO] - Training Epoch: 3/10, step 275/574 completed (loss: 0.3862742781639099, acc: 0.8666666746139526)
[2024-11-13 05:09:36,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:36,811][root][INFO] - Training Epoch: 3/10, step 276/574 completed (loss: 0.575113832950592, acc: 0.8965517282485962)
[2024-11-13 05:09:36,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:37,174][root][INFO] - Training Epoch: 3/10, step 277/574 completed (loss: 0.4581466317176819, acc: 0.8799999952316284)
[2024-11-13 05:09:37,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:37,511][root][INFO] - Training Epoch: 3/10, step 278/574 completed (loss: 1.339040756225586, acc: 0.6170212626457214)
[2024-11-13 05:09:37,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:37,847][root][INFO] - Training Epoch: 3/10, step 279/574 completed (loss: 0.6302391886711121, acc: 0.8125)
[2024-11-13 05:09:37,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:38,218][root][INFO] - Training Epoch: 3/10, step 280/574 completed (loss: 0.2864539325237274, acc: 0.9090909361839294)
[2024-11-13 05:09:38,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:38,648][root][INFO] - Training Epoch: 3/10, step 281/574 completed (loss: 1.2084053754806519, acc: 0.6626505851745605)
[2024-11-13 05:09:39,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:39,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:39,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:40,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:40,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:41,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:41,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:41,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:42,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:42,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:42,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:43,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:43,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:43,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:44,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:44,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:44,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:45,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:45,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:46,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:46,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:46,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:47,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:47,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:47,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:47,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:48,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:48,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:49,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:49,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:49,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:50,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:50,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:50,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:51,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:51,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:52,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:52,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:52,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:53,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:53,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:53,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:54,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:54,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:54,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:55,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:55,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:55,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:56,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:56,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:56,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:57,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:57,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:57,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:58,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:58,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:58,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:59,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:09:59,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:00,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:00,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:00,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:01,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:01,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:01,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:01,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:02,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:02,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:03,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:03,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:03,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:04,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:04,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:05,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:05,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:06,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:06,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:06,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:07,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:07,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:07,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:08,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:09,055][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3928, device='cuda:0') eval_epoch_loss=tensor(0.8724, device='cuda:0') eval_epoch_acc=tensor(0.7636, device='cuda:0')
[2024-11-13 05:10:09,056][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:10:09,057][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:10:09,341][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_3_step_282_loss_0.8724489212036133/model.pt
[2024-11-13 05:10:09,348][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:10:09,349][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 3 is 0.8724489212036133
[2024-11-13 05:10:09,349][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 3 is 0.7636153697967529
[2024-11-13 05:10:09,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:09,814][root][INFO] - Training Epoch: 3/10, step 282/574 completed (loss: 1.2690593004226685, acc: 0.6388888955116272)
[2024-11-13 05:10:09,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:10,136][root][INFO] - Training Epoch: 3/10, step 283/574 completed (loss: 0.8408894538879395, acc: 0.7105262875556946)
[2024-11-13 05:10:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:10,450][root][INFO] - Training Epoch: 3/10, step 284/574 completed (loss: 0.929224967956543, acc: 0.7352941036224365)
[2024-11-13 05:10:10,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:10,822][root][INFO] - Training Epoch: 3/10, step 285/574 completed (loss: 0.6214061379432678, acc: 0.8500000238418579)
[2024-11-13 05:10:10,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:11,201][root][INFO] - Training Epoch: 3/10, step 286/574 completed (loss: 0.7404757142066956, acc: 0.7890625)
[2024-11-13 05:10:11,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:11,639][root][INFO] - Training Epoch: 3/10, step 287/574 completed (loss: 1.0165640115737915, acc: 0.7279999852180481)
[2024-11-13 05:10:11,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:11,980][root][INFO] - Training Epoch: 3/10, step 288/574 completed (loss: 0.8090018630027771, acc: 0.7802197933197021)
[2024-11-13 05:10:12,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:12,297][root][INFO] - Training Epoch: 3/10, step 289/574 completed (loss: 1.0017001628875732, acc: 0.7639751434326172)
[2024-11-13 05:10:12,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:12,635][root][INFO] - Training Epoch: 3/10, step 290/574 completed (loss: 1.1550673246383667, acc: 0.6907216310501099)
[2024-11-13 05:10:12,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:13,017][root][INFO] - Training Epoch: 3/10, step 291/574 completed (loss: 0.14655306935310364, acc: 0.9545454382896423)
[2024-11-13 05:10:13,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:13,331][root][INFO] - Training Epoch: 3/10, step 292/574 completed (loss: 0.9714736938476562, acc: 0.7142857313156128)
[2024-11-13 05:10:13,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:13,675][root][INFO] - Training Epoch: 3/10, step 293/574 completed (loss: 0.6600931882858276, acc: 0.7931034564971924)
[2024-11-13 05:10:13,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:14,153][root][INFO] - Training Epoch: 3/10, step 294/574 completed (loss: 0.7230958938598633, acc: 0.7454545497894287)
[2024-11-13 05:10:14,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:14,739][root][INFO] - Training Epoch: 3/10, step 295/574 completed (loss: 1.076072096824646, acc: 0.7061855792999268)
[2024-11-13 05:10:14,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:15,082][root][INFO] - Training Epoch: 3/10, step 296/574 completed (loss: 1.0319697856903076, acc: 0.6896551847457886)
[2024-11-13 05:10:15,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:15,406][root][INFO] - Training Epoch: 3/10, step 297/574 completed (loss: 0.4488644003868103, acc: 0.8518518805503845)
[2024-11-13 05:10:15,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:15,763][root][INFO] - Training Epoch: 3/10, step 298/574 completed (loss: 0.8586819171905518, acc: 0.6842105388641357)
[2024-11-13 05:10:15,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:16,100][root][INFO] - Training Epoch: 3/10, step 299/574 completed (loss: 0.5055459141731262, acc: 0.8571428656578064)
[2024-11-13 05:10:16,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:16,387][root][INFO] - Training Epoch: 3/10, step 300/574 completed (loss: 0.13640831410884857, acc: 0.96875)
[2024-11-13 05:10:16,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:16,747][root][INFO] - Training Epoch: 3/10, step 301/574 completed (loss: 0.5782537460327148, acc: 0.849056601524353)
[2024-11-13 05:10:16,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:17,104][root][INFO] - Training Epoch: 3/10, step 302/574 completed (loss: 0.07513163983821869, acc: 1.0)
[2024-11-13 05:10:17,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:17,416][root][INFO] - Training Epoch: 3/10, step 303/574 completed (loss: 0.32710039615631104, acc: 0.9117646813392639)
[2024-11-13 05:10:17,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:17,728][root][INFO] - Training Epoch: 3/10, step 304/574 completed (loss: 0.5950193405151367, acc: 0.8125)
[2024-11-13 05:10:17,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:18,086][root][INFO] - Training Epoch: 3/10, step 305/574 completed (loss: 0.5557276606559753, acc: 0.8032786846160889)
[2024-11-13 05:10:18,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:18,436][root][INFO] - Training Epoch: 3/10, step 306/574 completed (loss: 0.25867292284965515, acc: 0.9666666388511658)
[2024-11-13 05:10:18,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:18,758][root][INFO] - Training Epoch: 3/10, step 307/574 completed (loss: 0.05269559472799301, acc: 1.0)
[2024-11-13 05:10:18,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:19,088][root][INFO] - Training Epoch: 3/10, step 308/574 completed (loss: 0.5402248501777649, acc: 0.8550724387168884)
[2024-11-13 05:10:19,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:19,507][root][INFO] - Training Epoch: 3/10, step 309/574 completed (loss: 0.7564231157302856, acc: 0.75)
[2024-11-13 05:10:19,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:19,862][root][INFO] - Training Epoch: 3/10, step 310/574 completed (loss: 0.4646058678627014, acc: 0.8795180916786194)
[2024-11-13 05:10:19,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:20,208][root][INFO] - Training Epoch: 3/10, step 311/574 completed (loss: 1.004777431488037, acc: 0.692307710647583)
[2024-11-13 05:10:20,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:20,564][root][INFO] - Training Epoch: 3/10, step 312/574 completed (loss: 0.6896077990531921, acc: 0.8367347121238708)
[2024-11-13 05:10:20,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:20,857][root][INFO] - Training Epoch: 3/10, step 313/574 completed (loss: 0.03693140670657158, acc: 1.0)
[2024-11-13 05:10:20,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:21,228][root][INFO] - Training Epoch: 3/10, step 314/574 completed (loss: 0.40462711453437805, acc: 0.9166666865348816)
[2024-11-13 05:10:21,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:21,530][root][INFO] - Training Epoch: 3/10, step 315/574 completed (loss: 0.3054337203502655, acc: 0.9354838728904724)
[2024-11-13 05:10:21,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:21,863][root][INFO] - Training Epoch: 3/10, step 316/574 completed (loss: 0.5294361710548401, acc: 0.8709677457809448)
[2024-11-13 05:10:21,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:22,223][root][INFO] - Training Epoch: 3/10, step 317/574 completed (loss: 0.5416133403778076, acc: 0.8358209133148193)
[2024-11-13 05:10:22,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:22,538][root][INFO] - Training Epoch: 3/10, step 318/574 completed (loss: 0.34831300377845764, acc: 0.9038461446762085)
[2024-11-13 05:10:22,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:22,846][root][INFO] - Training Epoch: 3/10, step 319/574 completed (loss: 0.39463546872138977, acc: 0.9111111164093018)
[2024-11-13 05:10:22,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:23,161][root][INFO] - Training Epoch: 3/10, step 320/574 completed (loss: 0.3489818871021271, acc: 0.8870967626571655)
[2024-11-13 05:10:23,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:23,489][root][INFO] - Training Epoch: 3/10, step 321/574 completed (loss: 0.11197818070650101, acc: 0.9599999785423279)
[2024-11-13 05:10:23,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:23,820][root][INFO] - Training Epoch: 3/10, step 322/574 completed (loss: 1.1772233247756958, acc: 0.5925925970077515)
[2024-11-13 05:10:23,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:24,124][root][INFO] - Training Epoch: 3/10, step 323/574 completed (loss: 2.047286033630371, acc: 0.34285715222358704)
[2024-11-13 05:10:24,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:24,428][root][INFO] - Training Epoch: 3/10, step 324/574 completed (loss: 1.7397598028182983, acc: 0.4615384638309479)
[2024-11-13 05:10:24,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:24,778][root][INFO] - Training Epoch: 3/10, step 325/574 completed (loss: 2.0368824005126953, acc: 0.4878048896789551)
[2024-11-13 05:10:24,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:25,154][root][INFO] - Training Epoch: 3/10, step 326/574 completed (loss: 1.7809667587280273, acc: 0.5)
[2024-11-13 05:10:25,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:25,525][root][INFO] - Training Epoch: 3/10, step 327/574 completed (loss: 0.540194571018219, acc: 0.7894737124443054)
[2024-11-13 05:10:25,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:25,857][root][INFO] - Training Epoch: 3/10, step 328/574 completed (loss: 0.09554112702608109, acc: 1.0)
[2024-11-13 05:10:26,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:26,292][root][INFO] - Training Epoch: 3/10, step 329/574 completed (loss: 0.49367326498031616, acc: 0.8888888955116272)
[2024-11-13 05:10:26,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:26,663][root][INFO] - Training Epoch: 3/10, step 330/574 completed (loss: 0.15006694197654724, acc: 0.96875)
[2024-11-13 05:10:26,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:27,010][root][INFO] - Training Epoch: 3/10, step 331/574 completed (loss: 0.5936729907989502, acc: 0.8225806355476379)
[2024-11-13 05:10:27,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:27,403][root][INFO] - Training Epoch: 3/10, step 332/574 completed (loss: 0.35062941908836365, acc: 0.9122806787490845)
[2024-11-13 05:10:27,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:27,749][root][INFO] - Training Epoch: 3/10, step 333/574 completed (loss: 0.8272042870521545, acc: 0.75)
[2024-11-13 05:10:27,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:28,089][root][INFO] - Training Epoch: 3/10, step 334/574 completed (loss: 0.2991614043712616, acc: 0.8666666746139526)
[2024-11-13 05:10:28,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:28,461][root][INFO] - Training Epoch: 3/10, step 335/574 completed (loss: 0.8339402675628662, acc: 0.7368420958518982)
[2024-11-13 05:10:28,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:28,881][root][INFO] - Training Epoch: 3/10, step 336/574 completed (loss: 1.3950097560882568, acc: 0.6399999856948853)
[2024-11-13 05:10:29,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:29,261][root][INFO] - Training Epoch: 3/10, step 337/574 completed (loss: 1.6385774612426758, acc: 0.5517241358757019)
[2024-11-13 05:10:29,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:29,657][root][INFO] - Training Epoch: 3/10, step 338/574 completed (loss: 1.6728384494781494, acc: 0.5531914830207825)
[2024-11-13 05:10:29,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:30,062][root][INFO] - Training Epoch: 3/10, step 339/574 completed (loss: 1.7701265811920166, acc: 0.5903614163398743)
[2024-11-13 05:10:30,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:30,412][root][INFO] - Training Epoch: 3/10, step 340/574 completed (loss: 0.3064854145050049, acc: 0.8695651888847351)
[2024-11-13 05:10:30,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:30,789][root][INFO] - Training Epoch: 3/10, step 341/574 completed (loss: 0.9114616513252258, acc: 0.7692307829856873)
[2024-11-13 05:10:30,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:31,156][root][INFO] - Training Epoch: 3/10, step 342/574 completed (loss: 1.073011040687561, acc: 0.759036123752594)
[2024-11-13 05:10:31,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:31,579][root][INFO] - Training Epoch: 3/10, step 343/574 completed (loss: 0.8861209750175476, acc: 0.7547169923782349)
[2024-11-13 05:10:31,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:31,917][root][INFO] - Training Epoch: 3/10, step 344/574 completed (loss: 0.5669007897377014, acc: 0.8481012582778931)
[2024-11-13 05:10:31,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:32,242][root][INFO] - Training Epoch: 3/10, step 345/574 completed (loss: 0.42175331711769104, acc: 0.8823529481887817)
[2024-11-13 05:10:32,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:32,561][root][INFO] - Training Epoch: 3/10, step 346/574 completed (loss: 1.0744866132736206, acc: 0.7014925479888916)
[2024-11-13 05:10:32,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:32,896][root][INFO] - Training Epoch: 3/10, step 347/574 completed (loss: 0.23590520024299622, acc: 0.949999988079071)
[2024-11-13 05:10:33,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:33,258][root][INFO] - Training Epoch: 3/10, step 348/574 completed (loss: 0.31443366408348083, acc: 0.8399999737739563)
[2024-11-13 05:10:33,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:33,691][root][INFO] - Training Epoch: 3/10, step 349/574 completed (loss: 0.8484362959861755, acc: 0.8055555820465088)
[2024-11-13 05:10:33,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:34,014][root][INFO] - Training Epoch: 3/10, step 350/574 completed (loss: 1.1859149932861328, acc: 0.5581395626068115)
[2024-11-13 05:10:34,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:34,342][root][INFO] - Training Epoch: 3/10, step 351/574 completed (loss: 0.7073297500610352, acc: 0.7692307829856873)
[2024-11-13 05:10:34,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:34,707][root][INFO] - Training Epoch: 3/10, step 352/574 completed (loss: 1.3086068630218506, acc: 0.5111111402511597)
[2024-11-13 05:10:34,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:35,013][root][INFO] - Training Epoch: 3/10, step 353/574 completed (loss: 0.17236609756946564, acc: 0.95652174949646)
[2024-11-13 05:10:35,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:35,392][root][INFO] - Training Epoch: 3/10, step 354/574 completed (loss: 1.109197735786438, acc: 0.692307710647583)
[2024-11-13 05:10:35,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:35,750][root][INFO] - Training Epoch: 3/10, step 355/574 completed (loss: 1.418468952178955, acc: 0.6373626589775085)
[2024-11-13 05:10:35,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:36,270][root][INFO] - Training Epoch: 3/10, step 356/574 completed (loss: 1.1502208709716797, acc: 0.6695652008056641)
[2024-11-13 05:10:36,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:36,659][root][INFO] - Training Epoch: 3/10, step 357/574 completed (loss: 0.9674498438835144, acc: 0.717391312122345)
[2024-11-13 05:10:36,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:37,033][root][INFO] - Training Epoch: 3/10, step 358/574 completed (loss: 1.020016074180603, acc: 0.7142857313156128)
[2024-11-13 05:10:37,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:37,365][root][INFO] - Training Epoch: 3/10, step 359/574 completed (loss: 0.021174075081944466, acc: 1.0)
[2024-11-13 05:10:37,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:37,694][root][INFO] - Training Epoch: 3/10, step 360/574 completed (loss: 0.30156853795051575, acc: 0.8846153616905212)
[2024-11-13 05:10:37,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:38,047][root][INFO] - Training Epoch: 3/10, step 361/574 completed (loss: 0.5901433825492859, acc: 0.8536585569381714)
[2024-11-13 05:10:38,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:38,378][root][INFO] - Training Epoch: 3/10, step 362/574 completed (loss: 0.8209758996963501, acc: 0.7777777910232544)
[2024-11-13 05:10:38,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:38,702][root][INFO] - Training Epoch: 3/10, step 363/574 completed (loss: 0.4949382543563843, acc: 0.8157894611358643)
[2024-11-13 05:10:38,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:39,051][root][INFO] - Training Epoch: 3/10, step 364/574 completed (loss: 0.3891841173171997, acc: 0.8780487775802612)
[2024-11-13 05:10:39,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:39,377][root][INFO] - Training Epoch: 3/10, step 365/574 completed (loss: 0.3190399408340454, acc: 0.9090909361839294)
[2024-11-13 05:10:39,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:39,695][root][INFO] - Training Epoch: 3/10, step 366/574 completed (loss: 0.04269292950630188, acc: 1.0)
[2024-11-13 05:10:39,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:40,035][root][INFO] - Training Epoch: 3/10, step 367/574 completed (loss: 0.23134370148181915, acc: 0.95652174949646)
[2024-11-13 05:10:40,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:40,396][root][INFO] - Training Epoch: 3/10, step 368/574 completed (loss: 0.0870630070567131, acc: 1.0)
[2024-11-13 05:10:40,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:40,700][root][INFO] - Training Epoch: 3/10, step 369/574 completed (loss: 0.46066567301750183, acc: 0.875)
[2024-11-13 05:10:40,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:41,323][root][INFO] - Training Epoch: 3/10, step 370/574 completed (loss: 1.036210298538208, acc: 0.739393949508667)
[2024-11-13 05:10:41,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:42,236][root][INFO] - Training Epoch: 3/10, step 371/574 completed (loss: 0.6330471634864807, acc: 0.8113207817077637)
[2024-11-13 05:10:42,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:42,576][root][INFO] - Training Epoch: 3/10, step 372/574 completed (loss: 0.6103799343109131, acc: 0.8444444537162781)
[2024-11-13 05:10:42,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:42,867][root][INFO] - Training Epoch: 3/10, step 373/574 completed (loss: 0.36516883969306946, acc: 0.9107142686843872)
[2024-11-13 05:10:42,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:43,171][root][INFO] - Training Epoch: 3/10, step 374/574 completed (loss: 0.4869345426559448, acc: 0.8285714387893677)
[2024-11-13 05:10:43,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:43,468][root][INFO] - Training Epoch: 3/10, step 375/574 completed (loss: 0.049778830260038376, acc: 1.0)
[2024-11-13 05:10:43,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:43,760][root][INFO] - Training Epoch: 3/10, step 376/574 completed (loss: 0.07168158143758774, acc: 1.0)
[2024-11-13 05:10:43,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:44,047][root][INFO] - Training Epoch: 3/10, step 377/574 completed (loss: 0.45561400055885315, acc: 0.8125)
[2024-11-13 05:10:44,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:44,359][root][INFO] - Training Epoch: 3/10, step 378/574 completed (loss: 0.15294604003429413, acc: 0.9894737005233765)
[2024-11-13 05:10:44,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:44,985][root][INFO] - Training Epoch: 3/10, step 379/574 completed (loss: 0.5249173641204834, acc: 0.886227548122406)
[2024-11-13 05:10:45,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:45,414][root][INFO] - Training Epoch: 3/10, step 380/574 completed (loss: 0.5363214612007141, acc: 0.8496240377426147)
[2024-11-13 05:10:45,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:46,711][root][INFO] - Training Epoch: 3/10, step 381/574 completed (loss: 0.7908617258071899, acc: 0.7860962748527527)
[2024-11-13 05:10:46,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:47,331][root][INFO] - Training Epoch: 3/10, step 382/574 completed (loss: 0.30554109811782837, acc: 0.8828828930854797)
[2024-11-13 05:10:47,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:47,683][root][INFO] - Training Epoch: 3/10, step 383/574 completed (loss: 0.34817999601364136, acc: 0.8928571343421936)
[2024-11-13 05:10:47,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:48,007][root][INFO] - Training Epoch: 3/10, step 384/574 completed (loss: 0.07083272933959961, acc: 1.0)
[2024-11-13 05:10:48,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:48,313][root][INFO] - Training Epoch: 3/10, step 385/574 completed (loss: 0.2622579336166382, acc: 0.9375)
[2024-11-13 05:10:48,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:48,679][root][INFO] - Training Epoch: 3/10, step 386/574 completed (loss: 0.06735868006944656, acc: 1.0)
[2024-11-13 05:10:48,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:49,024][root][INFO] - Training Epoch: 3/10, step 387/574 completed (loss: 0.12311102449893951, acc: 0.9736841917037964)
[2024-11-13 05:10:49,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:49,341][root][INFO] - Training Epoch: 3/10, step 388/574 completed (loss: 0.01771446503698826, acc: 1.0)
[2024-11-13 05:10:49,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:49,645][root][INFO] - Training Epoch: 3/10, step 389/574 completed (loss: 0.20733924210071564, acc: 0.949999988079071)
[2024-11-13 05:10:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:50,034][root][INFO] - Training Epoch: 3/10, step 390/574 completed (loss: 0.6324678063392639, acc: 0.8571428656578064)
[2024-11-13 05:10:50,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:50,372][root][INFO] - Training Epoch: 3/10, step 391/574 completed (loss: 1.4150892496109009, acc: 0.6481481194496155)
[2024-11-13 05:10:50,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:50,804][root][INFO] - Training Epoch: 3/10, step 392/574 completed (loss: 1.6196740865707397, acc: 0.582524299621582)
[2024-11-13 05:10:50,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:51,325][root][INFO] - Training Epoch: 3/10, step 393/574 completed (loss: 1.352524757385254, acc: 0.6764705777168274)
[2024-11-13 05:10:51,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:51,764][root][INFO] - Training Epoch: 3/10, step 394/574 completed (loss: 1.558538556098938, acc: 0.5933333039283752)
[2024-11-13 05:10:51,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:52,160][root][INFO] - Training Epoch: 3/10, step 395/574 completed (loss: 1.0262748003005981, acc: 0.7013888955116272)
[2024-11-13 05:10:52,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:52,505][root][INFO] - Training Epoch: 3/10, step 396/574 completed (loss: 0.7386259436607361, acc: 0.8139534592628479)
[2024-11-13 05:10:52,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:52,864][root][INFO] - Training Epoch: 3/10, step 397/574 completed (loss: 0.21908830106258392, acc: 0.875)
[2024-11-13 05:10:52,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:53,193][root][INFO] - Training Epoch: 3/10, step 398/574 completed (loss: 0.4761989116668701, acc: 0.8372092843055725)
[2024-11-13 05:10:53,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:53,531][root][INFO] - Training Epoch: 3/10, step 399/574 completed (loss: 0.5174517631530762, acc: 0.800000011920929)
[2024-11-13 05:10:53,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:54,153][root][INFO] - Training Epoch: 3/10, step 400/574 completed (loss: 0.5324417352676392, acc: 0.8529411554336548)
[2024-11-13 05:10:54,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:54,531][root][INFO] - Training Epoch: 3/10, step 401/574 completed (loss: 0.6501106023788452, acc: 0.8399999737739563)
[2024-11-13 05:10:54,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:54,884][root][INFO] - Training Epoch: 3/10, step 402/574 completed (loss: 0.7756028175354004, acc: 0.7575757503509521)
[2024-11-13 05:10:54,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:55,207][root][INFO] - Training Epoch: 3/10, step 403/574 completed (loss: 0.5602784752845764, acc: 0.8181818127632141)
[2024-11-13 05:10:55,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:55,551][root][INFO] - Training Epoch: 3/10, step 404/574 completed (loss: 0.30045193433761597, acc: 0.9032257795333862)
[2024-11-13 05:10:55,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:55,914][root][INFO] - Training Epoch: 3/10, step 405/574 completed (loss: 0.42903658747673035, acc: 0.8888888955116272)
[2024-11-13 05:10:56,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:56,276][root][INFO] - Training Epoch: 3/10, step 406/574 completed (loss: 0.18602637946605682, acc: 0.9599999785423279)
[2024-11-13 05:10:56,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:56,608][root][INFO] - Training Epoch: 3/10, step 407/574 completed (loss: 0.22734445333480835, acc: 0.9166666865348816)
[2024-11-13 05:10:56,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:56,988][root][INFO] - Training Epoch: 3/10, step 408/574 completed (loss: 0.36398589611053467, acc: 0.9259259104728699)
[2024-11-13 05:10:57,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:57,320][root][INFO] - Training Epoch: 3/10, step 409/574 completed (loss: 0.11351507157087326, acc: 1.0)
[2024-11-13 05:10:57,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:57,647][root][INFO] - Training Epoch: 3/10, step 410/574 completed (loss: 0.2716178894042969, acc: 0.8965517282485962)
[2024-11-13 05:10:57,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:57,956][root][INFO] - Training Epoch: 3/10, step 411/574 completed (loss: 0.18061970174312592, acc: 0.9642857313156128)
[2024-11-13 05:10:58,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:58,259][root][INFO] - Training Epoch: 3/10, step 412/574 completed (loss: 0.6755257844924927, acc: 0.800000011920929)
[2024-11-13 05:10:58,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:58,570][root][INFO] - Training Epoch: 3/10, step 413/574 completed (loss: 0.40195292234420776, acc: 0.9090909361839294)
[2024-11-13 05:10:58,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:58,875][root][INFO] - Training Epoch: 3/10, step 414/574 completed (loss: 0.16137751936912537, acc: 0.9545454382896423)
[2024-11-13 05:10:58,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:59,269][root][INFO] - Training Epoch: 3/10, step 415/574 completed (loss: 0.6616377830505371, acc: 0.7647058963775635)
[2024-11-13 05:10:59,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:59,600][root][INFO] - Training Epoch: 3/10, step 416/574 completed (loss: 0.24118193984031677, acc: 0.9230769276618958)
[2024-11-13 05:10:59,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:10:59,975][root][INFO] - Training Epoch: 3/10, step 417/574 completed (loss: 0.47475725412368774, acc: 0.8333333134651184)
[2024-11-13 05:11:00,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:00,379][root][INFO] - Training Epoch: 3/10, step 418/574 completed (loss: 0.49990314245224, acc: 0.8500000238418579)
[2024-11-13 05:11:00,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:00,743][root][INFO] - Training Epoch: 3/10, step 419/574 completed (loss: 0.5128737092018127, acc: 0.949999988079071)
[2024-11-13 05:11:00,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:01,126][root][INFO] - Training Epoch: 3/10, step 420/574 completed (loss: 0.13938339054584503, acc: 0.9523809552192688)
[2024-11-13 05:11:01,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:01,501][root][INFO] - Training Epoch: 3/10, step 421/574 completed (loss: 0.4575445353984833, acc: 0.8666666746139526)
[2024-11-13 05:11:01,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:01,866][root][INFO] - Training Epoch: 3/10, step 422/574 completed (loss: 0.5679602026939392, acc: 0.875)
[2024-11-13 05:11:01,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:02,230][root][INFO] - Training Epoch: 3/10, step 423/574 completed (loss: 0.5739583969116211, acc: 0.8888888955116272)
[2024-11-13 05:11:02,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:02,597][root][INFO] - Training Epoch: 3/10, step 424/574 completed (loss: 0.47996723651885986, acc: 0.8888888955116272)
[2024-11-13 05:11:03,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:03,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:04,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:04,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:04,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:05,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:05,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:06,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:06,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:06,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:07,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:07,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:08,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:08,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:08,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:09,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:09,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:10,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:10,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:10,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:11,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:11,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:11,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:12,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:12,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:13,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:13,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:13,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:14,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:14,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:14,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:15,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:15,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:16,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:16,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:16,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:17,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:17,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:17,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:18,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:18,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:19,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:19,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:19,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:20,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:20,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:20,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:21,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:21,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:21,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:21,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:22,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:23,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:23,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:23,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:24,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:24,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:24,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:25,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:25,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:25,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:26,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:26,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:27,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:27,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:27,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:28,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:28,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:28,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:29,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:29,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:30,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:30,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:30,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:31,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:31,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:31,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:32,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:32,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:32,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:33,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:33,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:33,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:34,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:35,023][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4651, device='cuda:0') eval_epoch_loss=tensor(0.9022, device='cuda:0') eval_epoch_acc=tensor(0.7497, device='cuda:0')
[2024-11-13 05:11:35,026][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:11:35,026][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:11:35,334][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_3_step_425_loss_0.902228057384491/model.pt
[2024-11-13 05:11:35,340][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:11:35,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:35,830][root][INFO] - Training Epoch: 3/10, step 425/574 completed (loss: 0.2738594710826874, acc: 0.939393937587738)
[2024-11-13 05:11:35,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:36,172][root][INFO] - Training Epoch: 3/10, step 426/574 completed (loss: 0.1991630643606186, acc: 0.95652174949646)
[2024-11-13 05:11:36,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:36,519][root][INFO] - Training Epoch: 3/10, step 427/574 completed (loss: 0.2786582410335541, acc: 0.9189189076423645)
[2024-11-13 05:11:36,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:36,858][root][INFO] - Training Epoch: 3/10, step 428/574 completed (loss: 0.10779575258493423, acc: 1.0)
[2024-11-13 05:11:36,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:37,176][root][INFO] - Training Epoch: 3/10, step 429/574 completed (loss: 0.2808845043182373, acc: 0.9130434989929199)
[2024-11-13 05:11:37,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:37,522][root][INFO] - Training Epoch: 3/10, step 430/574 completed (loss: 0.11759834736585617, acc: 0.9629629850387573)
[2024-11-13 05:11:37,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:37,865][root][INFO] - Training Epoch: 3/10, step 431/574 completed (loss: 0.04241716116666794, acc: 1.0)
[2024-11-13 05:11:37,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:38,208][root][INFO] - Training Epoch: 3/10, step 432/574 completed (loss: 0.1206476241350174, acc: 1.0)
[2024-11-13 05:11:38,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:38,601][root][INFO] - Training Epoch: 3/10, step 433/574 completed (loss: 0.2613965570926666, acc: 0.9166666865348816)
[2024-11-13 05:11:38,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:38,952][root][INFO] - Training Epoch: 3/10, step 434/574 completed (loss: 0.011838004924356937, acc: 1.0)
[2024-11-13 05:11:39,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:39,283][root][INFO] - Training Epoch: 3/10, step 435/574 completed (loss: 0.04685411602258682, acc: 1.0)
[2024-11-13 05:11:39,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:39,575][root][INFO] - Training Epoch: 3/10, step 436/574 completed (loss: 0.3783155679702759, acc: 0.8611111044883728)
[2024-11-13 05:11:39,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:39,923][root][INFO] - Training Epoch: 3/10, step 437/574 completed (loss: 0.26807960867881775, acc: 0.9545454382896423)
[2024-11-13 05:11:40,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:40,247][root][INFO] - Training Epoch: 3/10, step 438/574 completed (loss: 0.04295334592461586, acc: 1.0)
[2024-11-13 05:11:40,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:40,563][root][INFO] - Training Epoch: 3/10, step 439/574 completed (loss: 0.6399885416030884, acc: 0.8205128312110901)
[2024-11-13 05:11:40,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:41,094][root][INFO] - Training Epoch: 3/10, step 440/574 completed (loss: 0.8847727179527283, acc: 0.8181818127632141)
[2024-11-13 05:11:41,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:41,848][root][INFO] - Training Epoch: 3/10, step 441/574 completed (loss: 1.0260474681854248, acc: 0.7039999961853027)
[2024-11-13 05:11:41,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:42,255][root][INFO] - Training Epoch: 3/10, step 442/574 completed (loss: 1.1756224632263184, acc: 0.6935483813285828)
[2024-11-13 05:11:42,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:42,909][root][INFO] - Training Epoch: 3/10, step 443/574 completed (loss: 1.0194120407104492, acc: 0.7164179086685181)
[2024-11-13 05:11:42,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:43,239][root][INFO] - Training Epoch: 3/10, step 444/574 completed (loss: 0.6749218702316284, acc: 0.7547169923782349)
[2024-11-13 05:11:43,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:43,678][root][INFO] - Training Epoch: 3/10, step 445/574 completed (loss: 0.38682472705841064, acc: 0.8863636255264282)
[2024-11-13 05:11:43,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:44,002][root][INFO] - Training Epoch: 3/10, step 446/574 completed (loss: 0.8020859360694885, acc: 0.8260869383811951)
[2024-11-13 05:11:44,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:44,329][root][INFO] - Training Epoch: 3/10, step 447/574 completed (loss: 0.7362332940101624, acc: 0.807692289352417)
[2024-11-13 05:11:44,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:44,611][root][INFO] - Training Epoch: 3/10, step 448/574 completed (loss: 0.20171579718589783, acc: 0.9642857313156128)
[2024-11-13 05:11:44,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:44,916][root][INFO] - Training Epoch: 3/10, step 449/574 completed (loss: 0.4572329819202423, acc: 0.8656716346740723)
[2024-11-13 05:11:45,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:45,305][root][INFO] - Training Epoch: 3/10, step 450/574 completed (loss: 0.28900158405303955, acc: 0.9305555820465088)
[2024-11-13 05:11:45,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:45,699][root][INFO] - Training Epoch: 3/10, step 451/574 completed (loss: 0.31279221177101135, acc: 0.9021739363670349)
[2024-11-13 05:11:45,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:46,035][root][INFO] - Training Epoch: 3/10, step 452/574 completed (loss: 0.5726915597915649, acc: 0.8333333134651184)
[2024-11-13 05:11:46,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:46,430][root][INFO] - Training Epoch: 3/10, step 453/574 completed (loss: 0.6692025661468506, acc: 0.8421052694320679)
[2024-11-13 05:11:46,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:46,800][root][INFO] - Training Epoch: 3/10, step 454/574 completed (loss: 0.6086931228637695, acc: 0.8367347121238708)
[2024-11-13 05:11:46,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:47,136][root][INFO] - Training Epoch: 3/10, step 455/574 completed (loss: 0.4828972816467285, acc: 0.8787878751754761)
[2024-11-13 05:11:47,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:47,431][root][INFO] - Training Epoch: 3/10, step 456/574 completed (loss: 1.0029319524765015, acc: 0.7422680258750916)
[2024-11-13 05:11:47,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:47,806][root][INFO] - Training Epoch: 3/10, step 457/574 completed (loss: 0.5957698225975037, acc: 0.8142856955528259)
[2024-11-13 05:11:47,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:48,228][root][INFO] - Training Epoch: 3/10, step 458/574 completed (loss: 1.1340454816818237, acc: 0.7034883499145508)
[2024-11-13 05:11:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:48,614][root][INFO] - Training Epoch: 3/10, step 459/574 completed (loss: 0.4033428728580475, acc: 0.9107142686843872)
[2024-11-13 05:11:48,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:48,966][root][INFO] - Training Epoch: 3/10, step 460/574 completed (loss: 0.8139644861221313, acc: 0.8024691343307495)
[2024-11-13 05:11:49,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:49,279][root][INFO] - Training Epoch: 3/10, step 461/574 completed (loss: 0.8657853603363037, acc: 0.75)
[2024-11-13 05:11:49,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:49,613][root][INFO] - Training Epoch: 3/10, step 462/574 completed (loss: 0.17954964935779572, acc: 1.0)
[2024-11-13 05:11:49,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:49,945][root][INFO] - Training Epoch: 3/10, step 463/574 completed (loss: 0.4391184449195862, acc: 0.8461538553237915)
[2024-11-13 05:11:50,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:50,334][root][INFO] - Training Epoch: 3/10, step 464/574 completed (loss: 0.5217078328132629, acc: 0.8478260636329651)
[2024-11-13 05:11:50,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:50,674][root][INFO] - Training Epoch: 3/10, step 465/574 completed (loss: 0.5305678844451904, acc: 0.8690476417541504)
[2024-11-13 05:11:50,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:50,988][root][INFO] - Training Epoch: 3/10, step 466/574 completed (loss: 0.9945351481437683, acc: 0.7349397540092468)
[2024-11-13 05:11:51,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:51,324][root][INFO] - Training Epoch: 3/10, step 467/574 completed (loss: 0.6234651207923889, acc: 0.8288288116455078)
[2024-11-13 05:11:51,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:51,650][root][INFO] - Training Epoch: 3/10, step 468/574 completed (loss: 1.1438699960708618, acc: 0.6990291476249695)
[2024-11-13 05:11:51,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:51,974][root][INFO] - Training Epoch: 3/10, step 469/574 completed (loss: 0.8442201018333435, acc: 0.772357702255249)
[2024-11-13 05:11:52,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:52,286][root][INFO] - Training Epoch: 3/10, step 470/574 completed (loss: 0.31038984656333923, acc: 0.8333333134651184)
[2024-11-13 05:11:52,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:52,570][root][INFO] - Training Epoch: 3/10, step 471/574 completed (loss: 0.8045927882194519, acc: 0.7142857313156128)
[2024-11-13 05:11:52,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:52,977][root][INFO] - Training Epoch: 3/10, step 472/574 completed (loss: 0.8892738223075867, acc: 0.7156862616539001)
[2024-11-13 05:11:53,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:53,336][root][INFO] - Training Epoch: 3/10, step 473/574 completed (loss: 1.2240535020828247, acc: 0.6724891066551208)
[2024-11-13 05:11:53,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:53,672][root][INFO] - Training Epoch: 3/10, step 474/574 completed (loss: 0.9008644223213196, acc: 0.71875)
[2024-11-13 05:11:53,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:53,964][root][INFO] - Training Epoch: 3/10, step 475/574 completed (loss: 0.7157351970672607, acc: 0.8159509301185608)
[2024-11-13 05:11:54,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:54,285][root][INFO] - Training Epoch: 3/10, step 476/574 completed (loss: 0.852087676525116, acc: 0.7410072088241577)
[2024-11-13 05:11:54,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:54,632][root][INFO] - Training Epoch: 3/10, step 477/574 completed (loss: 1.067164659500122, acc: 0.713567852973938)
[2024-11-13 05:11:54,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:54,912][root][INFO] - Training Epoch: 3/10, step 478/574 completed (loss: 0.8242193460464478, acc: 0.8055555820465088)
[2024-11-13 05:11:54,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:55,182][root][INFO] - Training Epoch: 3/10, step 479/574 completed (loss: 0.5226865410804749, acc: 0.8181818127632141)
[2024-11-13 05:11:55,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:55,540][root][INFO] - Training Epoch: 3/10, step 480/574 completed (loss: 0.615549623966217, acc: 0.7777777910232544)
[2024-11-13 05:11:55,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:55,962][root][INFO] - Training Epoch: 3/10, step 481/574 completed (loss: 0.4309769570827484, acc: 0.949999988079071)
[2024-11-13 05:11:56,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:56,309][root][INFO] - Training Epoch: 3/10, step 482/574 completed (loss: 0.6894959211349487, acc: 0.800000011920929)
[2024-11-13 05:11:56,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:56,740][root][INFO] - Training Epoch: 3/10, step 483/574 completed (loss: 0.905198335647583, acc: 0.7413793206214905)
[2024-11-13 05:11:56,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:57,088][root][INFO] - Training Epoch: 3/10, step 484/574 completed (loss: 0.27920886874198914, acc: 0.9354838728904724)
[2024-11-13 05:11:57,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:57,484][root][INFO] - Training Epoch: 3/10, step 485/574 completed (loss: 0.35578370094299316, acc: 0.9473684430122375)
[2024-11-13 05:11:57,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:57,816][root][INFO] - Training Epoch: 3/10, step 486/574 completed (loss: 0.9477161169052124, acc: 0.7777777910232544)
[2024-11-13 05:11:57,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:58,130][root][INFO] - Training Epoch: 3/10, step 487/574 completed (loss: 0.5755605697631836, acc: 0.8095238208770752)
[2024-11-13 05:11:58,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:58,449][root][INFO] - Training Epoch: 3/10, step 488/574 completed (loss: 0.4063014090061188, acc: 0.9090909361839294)
[2024-11-13 05:11:58,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:58,802][root][INFO] - Training Epoch: 3/10, step 489/574 completed (loss: 1.1157578229904175, acc: 0.7230769395828247)
[2024-11-13 05:11:58,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:59,134][root][INFO] - Training Epoch: 3/10, step 490/574 completed (loss: 0.22997763752937317, acc: 0.9333333373069763)
[2024-11-13 05:11:59,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:59,466][root][INFO] - Training Epoch: 3/10, step 491/574 completed (loss: 0.4878007173538208, acc: 0.8275862336158752)
[2024-11-13 05:11:59,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:11:59,783][root][INFO] - Training Epoch: 3/10, step 492/574 completed (loss: 0.548529326915741, acc: 0.7647058963775635)
[2024-11-13 05:11:59,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:00,094][root][INFO] - Training Epoch: 3/10, step 493/574 completed (loss: 0.6302921175956726, acc: 0.8275862336158752)
[2024-11-13 05:12:00,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:00,372][root][INFO] - Training Epoch: 3/10, step 494/574 completed (loss: 0.36662164330482483, acc: 0.8947368264198303)
[2024-11-13 05:12:00,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:00,671][root][INFO] - Training Epoch: 3/10, step 495/574 completed (loss: 1.0865590572357178, acc: 0.7368420958518982)
[2024-11-13 05:12:00,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:01,090][root][INFO] - Training Epoch: 3/10, step 496/574 completed (loss: 1.0510923862457275, acc: 0.7410714030265808)
[2024-11-13 05:12:01,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:01,452][root][INFO] - Training Epoch: 3/10, step 497/574 completed (loss: 0.7077335119247437, acc: 0.8089887499809265)
[2024-11-13 05:12:01,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:01,784][root][INFO] - Training Epoch: 3/10, step 498/574 completed (loss: 0.9481461048126221, acc: 0.7415730357170105)
[2024-11-13 05:12:01,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:02,106][root][INFO] - Training Epoch: 3/10, step 499/574 completed (loss: 1.526032567024231, acc: 0.567375898361206)
[2024-11-13 05:12:02,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:02,444][root][INFO] - Training Epoch: 3/10, step 500/574 completed (loss: 1.268267035484314, acc: 0.6195651888847351)
[2024-11-13 05:12:02,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:02,759][root][INFO] - Training Epoch: 3/10, step 501/574 completed (loss: 0.09477806091308594, acc: 0.9599999785423279)
[2024-11-13 05:12:02,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:03,006][root][INFO] - Training Epoch: 3/10, step 502/574 completed (loss: 0.14272190630435944, acc: 0.9615384340286255)
[2024-11-13 05:12:03,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:03,289][root][INFO] - Training Epoch: 3/10, step 503/574 completed (loss: 0.30184823274612427, acc: 0.9259259104728699)
[2024-11-13 05:12:03,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:03,654][root][INFO] - Training Epoch: 3/10, step 504/574 completed (loss: 0.44040626287460327, acc: 0.8148148059844971)
[2024-11-13 05:12:03,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:04,014][root][INFO] - Training Epoch: 3/10, step 505/574 completed (loss: 0.4695894420146942, acc: 0.8679245114326477)
[2024-11-13 05:12:04,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:04,384][root][INFO] - Training Epoch: 3/10, step 506/574 completed (loss: 0.6681005954742432, acc: 0.8620689511299133)
[2024-11-13 05:12:04,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:04,998][root][INFO] - Training Epoch: 3/10, step 507/574 completed (loss: 1.3360062837600708, acc: 0.5945945978164673)
[2024-11-13 05:12:05,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:05,450][root][INFO] - Training Epoch: 3/10, step 508/574 completed (loss: 0.7662092447280884, acc: 0.8028169274330139)
[2024-11-13 05:12:05,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:05,822][root][INFO] - Training Epoch: 3/10, step 509/574 completed (loss: 0.2047458440065384, acc: 0.949999988079071)
[2024-11-13 05:12:05,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:06,146][root][INFO] - Training Epoch: 3/10, step 510/574 completed (loss: 0.12963825464248657, acc: 0.9666666388511658)
[2024-11-13 05:12:06,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:06,476][root][INFO] - Training Epoch: 3/10, step 511/574 completed (loss: 0.5513749718666077, acc: 0.8846153616905212)
[2024-11-13 05:12:08,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:09,321][root][INFO] - Training Epoch: 3/10, step 512/574 completed (loss: 1.333470344543457, acc: 0.6499999761581421)
[2024-11-13 05:12:09,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:10,196][root][INFO] - Training Epoch: 3/10, step 513/574 completed (loss: 0.5829869508743286, acc: 0.8492063283920288)
[2024-11-13 05:12:10,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:10,489][root][INFO] - Training Epoch: 3/10, step 514/574 completed (loss: 0.6544857025146484, acc: 0.7857142686843872)
[2024-11-13 05:12:10,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:10,804][root][INFO] - Training Epoch: 3/10, step 515/574 completed (loss: 0.2265901416540146, acc: 0.8999999761581421)
[2024-11-13 05:12:10,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:11,494][root][INFO] - Training Epoch: 3/10, step 516/574 completed (loss: 0.7851155996322632, acc: 0.8055555820465088)
[2024-11-13 05:12:11,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:11,783][root][INFO] - Training Epoch: 3/10, step 517/574 completed (loss: 0.022250991314649582, acc: 1.0)
[2024-11-13 05:12:11,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:12,108][root][INFO] - Training Epoch: 3/10, step 518/574 completed (loss: 0.5498685240745544, acc: 0.8709677457809448)
[2024-11-13 05:12:12,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:12,419][root][INFO] - Training Epoch: 3/10, step 519/574 completed (loss: 0.30803996324539185, acc: 0.8999999761581421)
[2024-11-13 05:12:12,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:12,733][root][INFO] - Training Epoch: 3/10, step 520/574 completed (loss: 0.5365819931030273, acc: 0.8888888955116272)
[2024-11-13 05:12:13,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:13,897][root][INFO] - Training Epoch: 3/10, step 521/574 completed (loss: 0.9868183732032776, acc: 0.7161017060279846)
[2024-11-13 05:12:13,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:14,250][root][INFO] - Training Epoch: 3/10, step 522/574 completed (loss: 0.6279439330101013, acc: 0.7985074520111084)
[2024-11-13 05:12:14,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:14,625][root][INFO] - Training Epoch: 3/10, step 523/574 completed (loss: 0.6349895000457764, acc: 0.8175182342529297)
[2024-11-13 05:12:14,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:15,201][root][INFO] - Training Epoch: 3/10, step 524/574 completed (loss: 0.8549923896789551, acc: 0.7699999809265137)
[2024-11-13 05:12:15,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:15,543][root][INFO] - Training Epoch: 3/10, step 525/574 completed (loss: 0.1250695437192917, acc: 0.9629629850387573)
[2024-11-13 05:12:15,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:15,860][root][INFO] - Training Epoch: 3/10, step 526/574 completed (loss: 0.3343052566051483, acc: 0.9230769276618958)
[2024-11-13 05:12:15,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:16,200][root][INFO] - Training Epoch: 3/10, step 527/574 completed (loss: 0.23872148990631104, acc: 0.9047619104385376)
[2024-11-13 05:12:16,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:16,582][root][INFO] - Training Epoch: 3/10, step 528/574 completed (loss: 1.9609545469284058, acc: 0.44262295961380005)
[2024-11-13 05:12:16,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:16,879][root][INFO] - Training Epoch: 3/10, step 529/574 completed (loss: 0.6628949642181396, acc: 0.8135592937469482)
[2024-11-13 05:12:16,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:17,160][root][INFO] - Training Epoch: 3/10, step 530/574 completed (loss: 1.7146141529083252, acc: 0.5813953280448914)
[2024-11-13 05:12:17,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:17,421][root][INFO] - Training Epoch: 3/10, step 531/574 completed (loss: 1.201674222946167, acc: 0.7272727489471436)
[2024-11-13 05:12:17,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:17,723][root][INFO] - Training Epoch: 3/10, step 532/574 completed (loss: 1.299495816230774, acc: 0.698113203048706)
[2024-11-13 05:12:17,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:18,027][root][INFO] - Training Epoch: 3/10, step 533/574 completed (loss: 0.88162761926651, acc: 0.7954545617103577)
[2024-11-13 05:12:18,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:18,367][root][INFO] - Training Epoch: 3/10, step 534/574 completed (loss: 0.6113284826278687, acc: 0.7599999904632568)
[2024-11-13 05:12:18,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:18,682][root][INFO] - Training Epoch: 3/10, step 535/574 completed (loss: 0.7295087575912476, acc: 0.8500000238418579)
[2024-11-13 05:12:18,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:18,977][root][INFO] - Training Epoch: 3/10, step 536/574 completed (loss: 0.22183941304683685, acc: 0.9545454382896423)
[2024-11-13 05:12:19,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:19,401][root][INFO] - Training Epoch: 3/10, step 537/574 completed (loss: 0.7348491549491882, acc: 0.8307692408561707)
[2024-11-13 05:12:19,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:19,706][root][INFO] - Training Epoch: 3/10, step 538/574 completed (loss: 0.7338745594024658, acc: 0.734375)
[2024-11-13 05:12:19,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:20,137][root][INFO] - Training Epoch: 3/10, step 539/574 completed (loss: 0.604560375213623, acc: 0.84375)
[2024-11-13 05:12:20,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:20,510][root][INFO] - Training Epoch: 3/10, step 540/574 completed (loss: 0.8889973163604736, acc: 0.7575757503509521)
[2024-11-13 05:12:20,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:20,851][root][INFO] - Training Epoch: 3/10, step 541/574 completed (loss: 0.2669561505317688, acc: 0.875)
[2024-11-13 05:12:20,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:21,145][root][INFO] - Training Epoch: 3/10, step 542/574 completed (loss: 0.0896475613117218, acc: 1.0)
[2024-11-13 05:12:21,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:21,499][root][INFO] - Training Epoch: 3/10, step 543/574 completed (loss: 0.030990250408649445, acc: 1.0)
[2024-11-13 05:12:21,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:21,816][root][INFO] - Training Epoch: 3/10, step 544/574 completed (loss: 0.5034225583076477, acc: 0.8666666746139526)
[2024-11-13 05:12:21,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:22,112][root][INFO] - Training Epoch: 3/10, step 545/574 completed (loss: 0.14879515767097473, acc: 0.9756097793579102)
[2024-11-13 05:12:22,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:22,366][root][INFO] - Training Epoch: 3/10, step 546/574 completed (loss: 0.1167365089058876, acc: 1.0)
[2024-11-13 05:12:22,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:22,605][root][INFO] - Training Epoch: 3/10, step 547/574 completed (loss: 0.13930881023406982, acc: 0.9736841917037964)
[2024-11-13 05:12:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:22,845][root][INFO] - Training Epoch: 3/10, step 548/574 completed (loss: 0.1552475094795227, acc: 0.9677419066429138)
[2024-11-13 05:12:22,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:23,076][root][INFO] - Training Epoch: 3/10, step 549/574 completed (loss: 0.061674222350120544, acc: 1.0)
[2024-11-13 05:12:23,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:23,365][root][INFO] - Training Epoch: 3/10, step 550/574 completed (loss: 0.5659035444259644, acc: 0.8181818127632141)
[2024-11-13 05:12:23,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:23,681][root][INFO] - Training Epoch: 3/10, step 551/574 completed (loss: 0.3287533223628998, acc: 0.8500000238418579)
[2024-11-13 05:12:23,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:24,017][root][INFO] - Training Epoch: 3/10, step 552/574 completed (loss: 0.27389028668403625, acc: 0.8999999761581421)
[2024-11-13 05:12:24,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:24,353][root][INFO] - Training Epoch: 3/10, step 553/574 completed (loss: 0.7176814079284668, acc: 0.8321167826652527)
[2024-11-13 05:12:24,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:24,684][root][INFO] - Training Epoch: 3/10, step 554/574 completed (loss: 0.5055186152458191, acc: 0.8482758402824402)
[2024-11-13 05:12:24,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:25,037][root][INFO] - Training Epoch: 3/10, step 555/574 completed (loss: 0.716995358467102, acc: 0.8214285969734192)
[2024-11-13 05:12:25,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:25,323][root][INFO] - Training Epoch: 3/10, step 556/574 completed (loss: 0.6925159096717834, acc: 0.7947019934654236)
[2024-11-13 05:12:25,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:25,570][root][INFO] - Training Epoch: 3/10, step 557/574 completed (loss: 0.3223450481891632, acc: 0.9059829115867615)
[2024-11-13 05:12:25,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:25,855][root][INFO] - Training Epoch: 3/10, step 558/574 completed (loss: 0.18868540227413177, acc: 0.9200000166893005)
[2024-11-13 05:12:25,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:26,190][root][INFO] - Training Epoch: 3/10, step 559/574 completed (loss: 0.31641334295272827, acc: 0.8846153616905212)
[2024-11-13 05:12:26,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:26,515][root][INFO] - Training Epoch: 3/10, step 560/574 completed (loss: 0.11654649674892426, acc: 0.9615384340286255)
[2024-11-13 05:12:26,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:26,804][root][INFO] - Training Epoch: 3/10, step 561/574 completed (loss: 0.4494396150112152, acc: 0.8717948794364929)
[2024-11-13 05:12:26,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:27,129][root][INFO] - Training Epoch: 3/10, step 562/574 completed (loss: 0.7026787996292114, acc: 0.8111110925674438)
[2024-11-13 05:12:27,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:27,479][root][INFO] - Training Epoch: 3/10, step 563/574 completed (loss: 0.5563458800315857, acc: 0.8571428656578064)
[2024-11-13 05:12:27,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:27,818][root][INFO] - Training Epoch: 3/10, step 564/574 completed (loss: 0.42361804842948914, acc: 0.875)
[2024-11-13 05:12:27,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:28,152][root][INFO] - Training Epoch: 3/10, step 565/574 completed (loss: 0.5494822263717651, acc: 0.8620689511299133)
[2024-11-13 05:12:28,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:28,476][root][INFO] - Training Epoch: 3/10, step 566/574 completed (loss: 0.5845248103141785, acc: 0.8928571343421936)
[2024-11-13 05:12:28,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:28,824][root][INFO] - Training Epoch: 3/10, step 567/574 completed (loss: 0.08047996461391449, acc: 1.0)
[2024-11-13 05:12:29,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:30,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:30,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:31,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:31,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:31,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:32,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:32,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:32,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:33,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:34,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:34,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:34,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:35,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:35,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:36,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:36,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:36,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:37,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:37,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:37,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:38,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:38,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:38,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:39,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:39,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:39,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:40,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:40,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:40,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:41,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:41,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:42,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:42,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:42,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:43,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:43,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:44,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:44,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:44,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:45,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:45,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:46,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:46,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:46,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:47,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:48,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:48,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:48,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:49,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:49,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:50,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:50,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:50,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:51,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:51,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:52,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:52,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:52,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:53,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:53,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:53,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:54,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:54,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:55,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:55,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:55,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:56,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:56,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:56,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:57,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:57,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:57,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:58,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:58,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:58,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:59,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:59,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:12:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:00,641][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4716, device='cuda:0') eval_epoch_loss=tensor(0.9049, device='cuda:0') eval_epoch_acc=tensor(0.7598, device='cuda:0')
[2024-11-13 05:13:00,642][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:13:00,643][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:13:00,904][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_3_step_568_loss_0.9048633575439453/model.pt
[2024-11-13 05:13:00,917][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:13:01,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:01,288][root][INFO] - Training Epoch: 3/10, step 568/574 completed (loss: 0.08676937222480774, acc: 0.9259259104728699)
[2024-11-13 05:13:01,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:01,664][root][INFO] - Training Epoch: 3/10, step 569/574 completed (loss: 0.6027526259422302, acc: 0.8074866533279419)
[2024-11-13 05:13:01,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:02,019][root][INFO] - Training Epoch: 3/10, step 570/574 completed (loss: 0.2653909921646118, acc: 0.9193548560142517)
[2024-11-13 05:13:02,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:02,367][root][INFO] - Training Epoch: 3/10, step 571/574 completed (loss: 0.6968346238136292, acc: 0.8632478713989258)
[2024-11-13 05:13:02,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:02,629][root][INFO] - Training Epoch: 3/10, step 572/574 completed (loss: 0.9284738302230835, acc: 0.7295918464660645)
[2024-11-13 05:13:02,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:02,929][root][INFO] - Training Epoch: 3/10, step 573/574 completed (loss: 0.9843313097953796, acc: 0.6918238997459412)
[2024-11-13 05:13:03,389][slam_llm.utils.train_utils][INFO] - Epoch 3: train_perplexity=2.2450, train_epoch_loss=0.8087, epoch time 357.6324014980346s
[2024-11-13 05:13:03,390][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:13:03,390][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 16 GB
[2024-11-13 05:13:03,390][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:13:03,390][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 9
[2024-11-13 05:13:03,391][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:13:04,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:04,444][root][INFO] - Training Epoch: 4/10, step 0/574 completed (loss: 0.321931391954422, acc: 0.8888888955116272)
[2024-11-13 05:13:04,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:04,764][root][INFO] - Training Epoch: 4/10, step 1/574 completed (loss: 0.3328319787979126, acc: 0.8799999952316284)
[2024-11-13 05:13:04,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:05,097][root][INFO] - Training Epoch: 4/10, step 2/574 completed (loss: 1.0637370347976685, acc: 0.7027027010917664)
[2024-11-13 05:13:05,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:05,437][root][INFO] - Training Epoch: 4/10, step 3/574 completed (loss: 0.5584384799003601, acc: 0.8947368264198303)
[2024-11-13 05:13:05,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:05,765][root][INFO] - Training Epoch: 4/10, step 4/574 completed (loss: 0.47908085584640503, acc: 0.8648648858070374)
[2024-11-13 05:13:05,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:06,079][root][INFO] - Training Epoch: 4/10, step 5/574 completed (loss: 0.34764665365219116, acc: 0.9642857313156128)
[2024-11-13 05:13:06,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:06,410][root][INFO] - Training Epoch: 4/10, step 6/574 completed (loss: 1.2823600769042969, acc: 0.6734693646430969)
[2024-11-13 05:13:06,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:06,722][root][INFO] - Training Epoch: 4/10, step 7/574 completed (loss: 0.6105457544326782, acc: 0.8666666746139526)
[2024-11-13 05:13:06,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:07,059][root][INFO] - Training Epoch: 4/10, step 8/574 completed (loss: 0.16941267251968384, acc: 0.9090909361839294)
[2024-11-13 05:13:07,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:07,409][root][INFO] - Training Epoch: 4/10, step 9/574 completed (loss: 0.03236984461545944, acc: 1.0)
[2024-11-13 05:13:07,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:07,777][root][INFO] - Training Epoch: 4/10, step 10/574 completed (loss: 0.25793883204460144, acc: 0.9259259104728699)
[2024-11-13 05:13:07,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:08,189][root][INFO] - Training Epoch: 4/10, step 11/574 completed (loss: 0.48931488394737244, acc: 0.7948718070983887)
[2024-11-13 05:13:08,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:08,557][root][INFO] - Training Epoch: 4/10, step 12/574 completed (loss: 0.21521799266338348, acc: 0.939393937587738)
[2024-11-13 05:13:08,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:08,914][root][INFO] - Training Epoch: 4/10, step 13/574 completed (loss: 0.5101099014282227, acc: 0.804347813129425)
[2024-11-13 05:13:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:09,228][root][INFO] - Training Epoch: 4/10, step 14/574 completed (loss: 0.3231927156448364, acc: 0.9215686321258545)
[2024-11-13 05:13:09,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:09,623][root][INFO] - Training Epoch: 4/10, step 15/574 completed (loss: 0.828386127948761, acc: 0.8163265585899353)
[2024-11-13 05:13:09,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:10,006][root][INFO] - Training Epoch: 4/10, step 16/574 completed (loss: 0.14175236225128174, acc: 0.9473684430122375)
[2024-11-13 05:13:10,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:10,368][root][INFO] - Training Epoch: 4/10, step 17/574 completed (loss: 0.702441930770874, acc: 0.7916666865348816)
[2024-11-13 05:13:10,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:10,733][root][INFO] - Training Epoch: 4/10, step 18/574 completed (loss: 1.1237252950668335, acc: 0.6944444179534912)
[2024-11-13 05:13:10,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:11,145][root][INFO] - Training Epoch: 4/10, step 19/574 completed (loss: 0.33376649022102356, acc: 0.8947368264198303)
[2024-11-13 05:13:11,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:11,506][root][INFO] - Training Epoch: 4/10, step 20/574 completed (loss: 0.2890293598175049, acc: 0.8846153616905212)
[2024-11-13 05:13:11,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:11,891][root][INFO] - Training Epoch: 4/10, step 21/574 completed (loss: 0.3144598603248596, acc: 0.931034505367279)
[2024-11-13 05:13:12,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:12,294][root][INFO] - Training Epoch: 4/10, step 22/574 completed (loss: 0.42801764607429504, acc: 0.8399999737739563)
[2024-11-13 05:13:12,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:12,655][root][INFO] - Training Epoch: 4/10, step 23/574 completed (loss: 0.46217799186706543, acc: 0.8095238208770752)
[2024-11-13 05:13:12,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:13,015][root][INFO] - Training Epoch: 4/10, step 24/574 completed (loss: 0.3696514070034027, acc: 0.875)
[2024-11-13 05:13:13,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:13,400][root][INFO] - Training Epoch: 4/10, step 25/574 completed (loss: 1.0943880081176758, acc: 0.7547169923782349)
[2024-11-13 05:13:13,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:13,738][root][INFO] - Training Epoch: 4/10, step 26/574 completed (loss: 0.9228188395500183, acc: 0.7534246444702148)
[2024-11-13 05:13:14,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:15,088][root][INFO] - Training Epoch: 4/10, step 27/574 completed (loss: 1.3808594942092896, acc: 0.6324110627174377)
[2024-11-13 05:13:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:15,418][root][INFO] - Training Epoch: 4/10, step 28/574 completed (loss: 0.5952262878417969, acc: 0.8139534592628479)
[2024-11-13 05:13:15,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:15,840][root][INFO] - Training Epoch: 4/10, step 29/574 completed (loss: 0.8036803007125854, acc: 0.7831325531005859)
[2024-11-13 05:13:15,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:16,237][root][INFO] - Training Epoch: 4/10, step 30/574 completed (loss: 0.9106278419494629, acc: 0.7654321193695068)
[2024-11-13 05:13:16,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:16,707][root][INFO] - Training Epoch: 4/10, step 31/574 completed (loss: 0.4057847559452057, acc: 0.8571428656578064)
[2024-11-13 05:13:16,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:17,068][root][INFO] - Training Epoch: 4/10, step 32/574 completed (loss: 0.3262609839439392, acc: 0.9259259104728699)
[2024-11-13 05:13:17,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:17,407][root][INFO] - Training Epoch: 4/10, step 33/574 completed (loss: 0.04354356229305267, acc: 1.0)
[2024-11-13 05:13:17,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:17,756][root][INFO] - Training Epoch: 4/10, step 34/574 completed (loss: 0.6144907474517822, acc: 0.8403361439704895)
[2024-11-13 05:13:17,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:18,074][root][INFO] - Training Epoch: 4/10, step 35/574 completed (loss: 0.40707674622535706, acc: 0.8852459192276001)
[2024-11-13 05:13:18,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:18,428][root][INFO] - Training Epoch: 4/10, step 36/574 completed (loss: 0.7117774486541748, acc: 0.7460317611694336)
[2024-11-13 05:13:18,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:18,763][root][INFO] - Training Epoch: 4/10, step 37/574 completed (loss: 0.7780821323394775, acc: 0.7966101765632629)
[2024-11-13 05:13:18,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:19,120][root][INFO] - Training Epoch: 4/10, step 38/574 completed (loss: 0.4416097402572632, acc: 0.8275862336158752)
[2024-11-13 05:13:19,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:19,482][root][INFO] - Training Epoch: 4/10, step 39/574 completed (loss: 0.3400476574897766, acc: 0.9047619104385376)
[2024-11-13 05:13:19,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:19,800][root][INFO] - Training Epoch: 4/10, step 40/574 completed (loss: 0.47084373235702515, acc: 0.8846153616905212)
[2024-11-13 05:13:19,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:20,231][root][INFO] - Training Epoch: 4/10, step 41/574 completed (loss: 0.6272370219230652, acc: 0.7567567825317383)
[2024-11-13 05:13:20,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:20,580][root][INFO] - Training Epoch: 4/10, step 42/574 completed (loss: 1.2565758228302002, acc: 0.692307710647583)
[2024-11-13 05:13:20,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:21,057][root][INFO] - Training Epoch: 4/10, step 43/574 completed (loss: 0.8360366821289062, acc: 0.7373737096786499)
[2024-11-13 05:13:21,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:21,491][root][INFO] - Training Epoch: 4/10, step 44/574 completed (loss: 0.6065109968185425, acc: 0.7731958627700806)
[2024-11-13 05:13:21,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:21,897][root][INFO] - Training Epoch: 4/10, step 45/574 completed (loss: 0.6293328404426575, acc: 0.8161764740943909)
[2024-11-13 05:13:21,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:22,205][root][INFO] - Training Epoch: 4/10, step 46/574 completed (loss: 0.32017263770103455, acc: 0.8846153616905212)
[2024-11-13 05:13:22,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:22,536][root][INFO] - Training Epoch: 4/10, step 47/574 completed (loss: 0.22272609174251556, acc: 0.9629629850387573)
[2024-11-13 05:13:22,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:22,880][root][INFO] - Training Epoch: 4/10, step 48/574 completed (loss: 0.24044887721538544, acc: 0.9642857313156128)
[2024-11-13 05:13:22,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:23,261][root][INFO] - Training Epoch: 4/10, step 49/574 completed (loss: 0.10155907273292542, acc: 1.0)
[2024-11-13 05:13:23,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:23,680][root][INFO] - Training Epoch: 4/10, step 50/574 completed (loss: 0.7370119690895081, acc: 0.8070175647735596)
[2024-11-13 05:13:23,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:24,046][root][INFO] - Training Epoch: 4/10, step 51/574 completed (loss: 0.89259272813797, acc: 0.7936508059501648)
[2024-11-13 05:13:24,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:24,422][root][INFO] - Training Epoch: 4/10, step 52/574 completed (loss: 1.133547306060791, acc: 0.6478873491287231)
[2024-11-13 05:13:24,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:24,863][root][INFO] - Training Epoch: 4/10, step 53/574 completed (loss: 1.5908098220825195, acc: 0.5266666412353516)
[2024-11-13 05:13:24,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:25,173][root][INFO] - Training Epoch: 4/10, step 54/574 completed (loss: 0.8160883188247681, acc: 0.7837837934494019)
[2024-11-13 05:13:25,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:25,478][root][INFO] - Training Epoch: 4/10, step 55/574 completed (loss: 0.11775325238704681, acc: 0.9615384340286255)
[2024-11-13 05:13:26,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:28,473][root][INFO] - Training Epoch: 4/10, step 56/574 completed (loss: 1.3471742868423462, acc: 0.6279863715171814)
[2024-11-13 05:13:28,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:29,782][root][INFO] - Training Epoch: 4/10, step 57/574 completed (loss: 1.4209414720535278, acc: 0.5925925970077515)
[2024-11-13 05:13:29,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:30,422][root][INFO] - Training Epoch: 4/10, step 58/574 completed (loss: 1.0021480321884155, acc: 0.7443181872367859)
[2024-11-13 05:13:30,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:30,990][root][INFO] - Training Epoch: 4/10, step 59/574 completed (loss: 0.7291274666786194, acc: 0.7647058963775635)
[2024-11-13 05:13:31,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:31,569][root][INFO] - Training Epoch: 4/10, step 60/574 completed (loss: 1.0157506465911865, acc: 0.7028985619544983)
[2024-11-13 05:13:31,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:32,025][root][INFO] - Training Epoch: 4/10, step 61/574 completed (loss: 0.8479412794113159, acc: 0.75)
[2024-11-13 05:13:32,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:32,415][root][INFO] - Training Epoch: 4/10, step 62/574 completed (loss: 0.41948843002319336, acc: 0.8529411554336548)
[2024-11-13 05:13:32,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:32,760][root][INFO] - Training Epoch: 4/10, step 63/574 completed (loss: 0.32891425490379333, acc: 0.8888888955116272)
[2024-11-13 05:13:32,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:33,108][root][INFO] - Training Epoch: 4/10, step 64/574 completed (loss: 0.26826411485671997, acc: 0.90625)
[2024-11-13 05:13:33,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:33,410][root][INFO] - Training Epoch: 4/10, step 65/574 completed (loss: 0.23607295751571655, acc: 0.931034505367279)
[2024-11-13 05:13:33,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:33,734][root][INFO] - Training Epoch: 4/10, step 66/574 completed (loss: 0.7330771088600159, acc: 0.8214285969734192)
[2024-11-13 05:13:33,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:34,128][root][INFO] - Training Epoch: 4/10, step 67/574 completed (loss: 0.503114640712738, acc: 0.8333333134651184)
[2024-11-13 05:13:34,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:34,494][root][INFO] - Training Epoch: 4/10, step 68/574 completed (loss: 0.029189538210630417, acc: 1.0)
[2024-11-13 05:13:34,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:34,835][root][INFO] - Training Epoch: 4/10, step 69/574 completed (loss: 0.5152029991149902, acc: 0.8333333134651184)
[2024-11-13 05:13:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:35,112][root][INFO] - Training Epoch: 4/10, step 70/574 completed (loss: 0.9097798466682434, acc: 0.8181818127632141)
[2024-11-13 05:13:35,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:35,516][root][INFO] - Training Epoch: 4/10, step 71/574 completed (loss: 1.11350679397583, acc: 0.625)
[2024-11-13 05:13:35,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:35,855][root][INFO] - Training Epoch: 4/10, step 72/574 completed (loss: 0.9823696613311768, acc: 0.7460317611694336)
[2024-11-13 05:13:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:36,211][root][INFO] - Training Epoch: 4/10, step 73/574 completed (loss: 1.609979510307312, acc: 0.5846154093742371)
[2024-11-13 05:13:36,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:36,520][root][INFO] - Training Epoch: 4/10, step 74/574 completed (loss: 1.125815987586975, acc: 0.6938775777816772)
[2024-11-13 05:13:36,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:36,892][root][INFO] - Training Epoch: 4/10, step 75/574 completed (loss: 1.2208937406539917, acc: 0.6492537260055542)
[2024-11-13 05:13:37,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:37,311][root][INFO] - Training Epoch: 4/10, step 76/574 completed (loss: 1.4979605674743652, acc: 0.5802919864654541)
[2024-11-13 05:13:37,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:37,670][root][INFO] - Training Epoch: 4/10, step 77/574 completed (loss: 0.018001407384872437, acc: 1.0)
[2024-11-13 05:13:37,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:38,017][root][INFO] - Training Epoch: 4/10, step 78/574 completed (loss: 0.17580030858516693, acc: 0.9166666865348816)
[2024-11-13 05:13:38,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:38,354][root][INFO] - Training Epoch: 4/10, step 79/574 completed (loss: 0.4293023645877838, acc: 0.8787878751754761)
[2024-11-13 05:13:38,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:38,676][root][INFO] - Training Epoch: 4/10, step 80/574 completed (loss: 0.3388718068599701, acc: 0.8846153616905212)
[2024-11-13 05:13:38,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:38,984][root][INFO] - Training Epoch: 4/10, step 81/574 completed (loss: 0.7175266742706299, acc: 0.7692307829856873)
[2024-11-13 05:13:39,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:39,323][root][INFO] - Training Epoch: 4/10, step 82/574 completed (loss: 0.9719128012657166, acc: 0.7692307829856873)
[2024-11-13 05:13:39,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:39,707][root][INFO] - Training Epoch: 4/10, step 83/574 completed (loss: 0.38488394021987915, acc: 0.875)
[2024-11-13 05:13:39,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:40,057][root][INFO] - Training Epoch: 4/10, step 84/574 completed (loss: 0.4296526312828064, acc: 0.8840579986572266)
[2024-11-13 05:13:40,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:40,385][root][INFO] - Training Epoch: 4/10, step 85/574 completed (loss: 0.6336329579353333, acc: 0.7799999713897705)
[2024-11-13 05:13:40,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:40,698][root][INFO] - Training Epoch: 4/10, step 86/574 completed (loss: 0.3335784077644348, acc: 0.8695651888847351)
[2024-11-13 05:13:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:41,165][root][INFO] - Training Epoch: 4/10, step 87/574 completed (loss: 1.109012246131897, acc: 0.7200000286102295)
[2024-11-13 05:13:41,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:41,516][root][INFO] - Training Epoch: 4/10, step 88/574 completed (loss: 1.1917142868041992, acc: 0.6796116232872009)
[2024-11-13 05:13:41,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:42,643][root][INFO] - Training Epoch: 4/10, step 89/574 completed (loss: 1.0879442691802979, acc: 0.7038834691047668)
[2024-11-13 05:13:42,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:43,462][root][INFO] - Training Epoch: 4/10, step 90/574 completed (loss: 1.213786244392395, acc: 0.6881720423698425)
[2024-11-13 05:13:43,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:44,282][root][INFO] - Training Epoch: 4/10, step 91/574 completed (loss: 1.071635127067566, acc: 0.7370689511299133)
[2024-11-13 05:13:44,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:45,025][root][INFO] - Training Epoch: 4/10, step 92/574 completed (loss: 0.9538306593894958, acc: 0.6947368383407593)
[2024-11-13 05:13:45,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:46,023][root][INFO] - Training Epoch: 4/10, step 93/574 completed (loss: 1.5175018310546875, acc: 0.5643564462661743)
[2024-11-13 05:13:46,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:46,295][root][INFO] - Training Epoch: 4/10, step 94/574 completed (loss: 1.0754714012145996, acc: 0.6935483813285828)
[2024-11-13 05:13:46,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:46,646][root][INFO] - Training Epoch: 4/10, step 95/574 completed (loss: 1.036581039428711, acc: 0.6811594367027283)
[2024-11-13 05:13:46,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:46,989][root][INFO] - Training Epoch: 4/10, step 96/574 completed (loss: 1.4494593143463135, acc: 0.5630252361297607)
[2024-11-13 05:13:47,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:47,354][root][INFO] - Training Epoch: 4/10, step 97/574 completed (loss: 1.4761226177215576, acc: 0.5288461446762085)
[2024-11-13 05:13:47,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:47,742][root][INFO] - Training Epoch: 4/10, step 98/574 completed (loss: 1.4928016662597656, acc: 0.5620437860488892)
[2024-11-13 05:13:47,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:48,124][root][INFO] - Training Epoch: 4/10, step 99/574 completed (loss: 1.4284623861312866, acc: 0.5223880410194397)
[2024-11-13 05:13:48,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:48,508][root][INFO] - Training Epoch: 4/10, step 100/574 completed (loss: 0.5244196653366089, acc: 0.8500000238418579)
[2024-11-13 05:13:48,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:48,882][root][INFO] - Training Epoch: 4/10, step 101/574 completed (loss: 0.03836939483880997, acc: 1.0)
[2024-11-13 05:13:48,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:49,242][root][INFO] - Training Epoch: 4/10, step 102/574 completed (loss: 0.03893416002392769, acc: 1.0)
[2024-11-13 05:13:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:49,616][root][INFO] - Training Epoch: 4/10, step 103/574 completed (loss: 0.13890340924263, acc: 0.9772727489471436)
[2024-11-13 05:13:49,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:49,986][root][INFO] - Training Epoch: 4/10, step 104/574 completed (loss: 0.5525413751602173, acc: 0.8103448152542114)
[2024-11-13 05:13:50,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:50,311][root][INFO] - Training Epoch: 4/10, step 105/574 completed (loss: 0.35774028301239014, acc: 0.930232584476471)
[2024-11-13 05:13:50,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:50,687][root][INFO] - Training Epoch: 4/10, step 106/574 completed (loss: 0.39012694358825684, acc: 0.8799999952316284)
[2024-11-13 05:13:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:51,022][root][INFO] - Training Epoch: 4/10, step 107/574 completed (loss: 0.04907868057489395, acc: 1.0)
[2024-11-13 05:13:51,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:51,361][root][INFO] - Training Epoch: 4/10, step 108/574 completed (loss: 0.016192864626646042, acc: 1.0)
[2024-11-13 05:13:51,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:51,677][root][INFO] - Training Epoch: 4/10, step 109/574 completed (loss: 0.29891568422317505, acc: 0.9523809552192688)
[2024-11-13 05:13:51,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:52,062][root][INFO] - Training Epoch: 4/10, step 110/574 completed (loss: 0.3116013705730438, acc: 0.9384615421295166)
[2024-11-13 05:13:52,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:52,483][root][INFO] - Training Epoch: 4/10, step 111/574 completed (loss: 0.5788817405700684, acc: 0.8421052694320679)
[2024-11-13 05:13:52,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:52,850][root][INFO] - Training Epoch: 4/10, step 112/574 completed (loss: 0.9112403988838196, acc: 0.7368420958518982)
[2024-11-13 05:13:52,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:53,207][root][INFO] - Training Epoch: 4/10, step 113/574 completed (loss: 0.5050257444381714, acc: 0.8717948794364929)
[2024-11-13 05:13:53,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:53,584][root][INFO] - Training Epoch: 4/10, step 114/574 completed (loss: 0.47213461995124817, acc: 0.8163265585899353)
[2024-11-13 05:13:53,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:53,900][root][INFO] - Training Epoch: 4/10, step 115/574 completed (loss: 0.05049419030547142, acc: 1.0)
[2024-11-13 05:13:53,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:54,221][root][INFO] - Training Epoch: 4/10, step 116/574 completed (loss: 0.7432530522346497, acc: 0.7460317611694336)
[2024-11-13 05:13:54,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:54,596][root][INFO] - Training Epoch: 4/10, step 117/574 completed (loss: 0.6549260020256042, acc: 0.8373983502388)
[2024-11-13 05:13:54,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:54,965][root][INFO] - Training Epoch: 4/10, step 118/574 completed (loss: 0.285770982503891, acc: 0.8870967626571655)
[2024-11-13 05:13:55,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:55,865][root][INFO] - Training Epoch: 4/10, step 119/574 completed (loss: 0.9847893714904785, acc: 0.7376425862312317)
[2024-11-13 05:13:55,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:56,185][root][INFO] - Training Epoch: 4/10, step 120/574 completed (loss: 0.3962893486022949, acc: 0.8666666746139526)
[2024-11-13 05:13:56,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:56,596][root][INFO] - Training Epoch: 4/10, step 121/574 completed (loss: 0.49115216732025146, acc: 0.8461538553237915)
[2024-11-13 05:13:56,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:56,892][root][INFO] - Training Epoch: 4/10, step 122/574 completed (loss: 0.1256789118051529, acc: 0.9583333134651184)
[2024-11-13 05:13:56,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:57,193][root][INFO] - Training Epoch: 4/10, step 123/574 completed (loss: 0.20214201509952545, acc: 0.9473684430122375)
[2024-11-13 05:13:57,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:57,518][root][INFO] - Training Epoch: 4/10, step 124/574 completed (loss: 1.2726185321807861, acc: 0.6380367875099182)
[2024-11-13 05:13:57,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:57,880][root][INFO] - Training Epoch: 4/10, step 125/574 completed (loss: 1.3351551294326782, acc: 0.6319444179534912)
[2024-11-13 05:13:57,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:58,225][root][INFO] - Training Epoch: 4/10, step 126/574 completed (loss: 1.3090341091156006, acc: 0.625)
[2024-11-13 05:13:58,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:58,578][root][INFO] - Training Epoch: 4/10, step 127/574 completed (loss: 1.3334654569625854, acc: 0.636904776096344)
[2024-11-13 05:13:58,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:58,924][root][INFO] - Training Epoch: 4/10, step 128/574 completed (loss: 1.0477324724197388, acc: 0.6871795058250427)
[2024-11-13 05:13:59,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:59,392][root][INFO] - Training Epoch: 4/10, step 129/574 completed (loss: 1.0676870346069336, acc: 0.7058823704719543)
[2024-11-13 05:13:59,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:13:59,730][root][INFO] - Training Epoch: 4/10, step 130/574 completed (loss: 0.6534408330917358, acc: 0.7692307829856873)
[2024-11-13 05:13:59,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:00,110][root][INFO] - Training Epoch: 4/10, step 131/574 completed (loss: 0.19214126467704773, acc: 0.95652174949646)
[2024-11-13 05:14:00,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:00,508][root][INFO] - Training Epoch: 4/10, step 132/574 completed (loss: 0.5039297938346863, acc: 0.875)
[2024-11-13 05:14:00,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:00,909][root][INFO] - Training Epoch: 4/10, step 133/574 completed (loss: 0.733943521976471, acc: 0.782608687877655)
[2024-11-13 05:14:01,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:01,255][root][INFO] - Training Epoch: 4/10, step 134/574 completed (loss: 0.673656165599823, acc: 0.7714285850524902)
[2024-11-13 05:14:01,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:01,603][root][INFO] - Training Epoch: 4/10, step 135/574 completed (loss: 0.5250944495201111, acc: 0.807692289352417)
[2024-11-13 05:14:01,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:01,953][root][INFO] - Training Epoch: 4/10, step 136/574 completed (loss: 0.5909727215766907, acc: 0.8571428656578064)
[2024-11-13 05:14:02,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:03,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:03,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:03,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:04,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:04,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:04,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:05,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:05,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:05,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:06,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:06,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:07,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:07,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:08,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:08,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:08,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:09,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:09,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:09,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:10,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:10,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:10,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:11,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:11,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:11,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:12,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:13,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:13,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:14,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:14,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:14,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:15,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:15,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:15,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:16,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:16,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:17,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:17,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:17,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:18,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:18,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:19,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:19,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:19,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:19,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:20,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:20,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:21,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:21,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:21,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:22,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:22,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:22,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:23,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:23,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:23,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:24,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:24,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:25,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:25,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:26,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:26,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:26,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:27,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:27,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:28,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:28,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:28,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:29,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:29,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:29,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:30,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:30,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:30,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:31,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:31,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:31,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:32,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:32,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:33,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:33,773][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.1505, device='cuda:0') eval_epoch_loss=tensor(0.7657, device='cuda:0') eval_epoch_acc=tensor(0.7883, device='cuda:0')
[2024-11-13 05:14:33,775][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:14:33,775][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:14:34,133][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_4_step_137_loss_0.7657225131988525/model.pt
[2024-11-13 05:14:34,144][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:14:34,146][slam_llm.utils.train_utils][INFO] - best eval loss on epoch 4 is 0.7657225131988525
[2024-11-13 05:14:34,147][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.788254976272583
[2024-11-13 05:14:34,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:34,558][root][INFO] - Training Epoch: 4/10, step 137/574 completed (loss: 0.9233629703521729, acc: 0.7333333492279053)
[2024-11-13 05:14:34,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:34,889][root][INFO] - Training Epoch: 4/10, step 138/574 completed (loss: 0.4751585125923157, acc: 0.8260869383811951)
[2024-11-13 05:14:35,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:35,256][root][INFO] - Training Epoch: 4/10, step 139/574 completed (loss: 0.14592353999614716, acc: 0.9523809552192688)
[2024-11-13 05:14:35,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:35,612][root][INFO] - Training Epoch: 4/10, step 140/574 completed (loss: 0.5735172033309937, acc: 0.7692307829856873)
[2024-11-13 05:14:35,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:35,883][root][INFO] - Training Epoch: 4/10, step 141/574 completed (loss: 0.777424693107605, acc: 0.8064516186714172)
[2024-11-13 05:14:35,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:36,213][root][INFO] - Training Epoch: 4/10, step 142/574 completed (loss: 0.5641953945159912, acc: 0.7837837934494019)
[2024-11-13 05:14:36,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:36,736][root][INFO] - Training Epoch: 4/10, step 143/574 completed (loss: 0.959580659866333, acc: 0.6842105388641357)
[2024-11-13 05:14:36,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:37,072][root][INFO] - Training Epoch: 4/10, step 144/574 completed (loss: 0.9108548164367676, acc: 0.7313432693481445)
[2024-11-13 05:14:37,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:37,418][root][INFO] - Training Epoch: 4/10, step 145/574 completed (loss: 0.7457000613212585, acc: 0.7653061151504517)
[2024-11-13 05:14:37,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:37,844][root][INFO] - Training Epoch: 4/10, step 146/574 completed (loss: 1.1704896688461304, acc: 0.6382978558540344)
[2024-11-13 05:14:37,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:38,160][root][INFO] - Training Epoch: 4/10, step 147/574 completed (loss: 0.7903595566749573, acc: 0.7857142686843872)
[2024-11-13 05:14:38,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:38,462][root][INFO] - Training Epoch: 4/10, step 148/574 completed (loss: 0.9642205834388733, acc: 0.6428571343421936)
[2024-11-13 05:14:38,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:38,734][root][INFO] - Training Epoch: 4/10, step 149/574 completed (loss: 0.5826964378356934, acc: 0.739130437374115)
[2024-11-13 05:14:38,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:39,044][root][INFO] - Training Epoch: 4/10, step 150/574 completed (loss: 0.5968729853630066, acc: 0.7931034564971924)
[2024-11-13 05:14:39,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:39,351][root][INFO] - Training Epoch: 4/10, step 151/574 completed (loss: 1.0222386121749878, acc: 0.717391312122345)
[2024-11-13 05:14:39,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:39,682][root][INFO] - Training Epoch: 4/10, step 152/574 completed (loss: 0.7744759321212769, acc: 0.8135592937469482)
[2024-11-13 05:14:39,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:40,061][root][INFO] - Training Epoch: 4/10, step 153/574 completed (loss: 1.0538513660430908, acc: 0.6315789222717285)
[2024-11-13 05:14:40,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:40,405][root][INFO] - Training Epoch: 4/10, step 154/574 completed (loss: 0.7222949266433716, acc: 0.7702702879905701)
[2024-11-13 05:14:40,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:40,705][root][INFO] - Training Epoch: 4/10, step 155/574 completed (loss: 0.21400071680545807, acc: 0.9285714030265808)
[2024-11-13 05:14:40,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:41,094][root][INFO] - Training Epoch: 4/10, step 156/574 completed (loss: 0.19473309814929962, acc: 0.95652174949646)
[2024-11-13 05:14:41,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:41,492][root][INFO] - Training Epoch: 4/10, step 157/574 completed (loss: 1.4439128637313843, acc: 0.5263158082962036)
[2024-11-13 05:14:42,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:43,282][root][INFO] - Training Epoch: 4/10, step 158/574 completed (loss: 1.0040514469146729, acc: 0.7027027010917664)
[2024-11-13 05:14:43,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:43,570][root][INFO] - Training Epoch: 4/10, step 159/574 completed (loss: 1.4659684896469116, acc: 0.5555555820465088)
[2024-11-13 05:14:43,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:43,956][root][INFO] - Training Epoch: 4/10, step 160/574 completed (loss: 1.1116909980773926, acc: 0.6627907156944275)
[2024-11-13 05:14:44,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:44,552][root][INFO] - Training Epoch: 4/10, step 161/574 completed (loss: 1.2180500030517578, acc: 0.6352941393852234)
[2024-11-13 05:14:44,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:45,104][root][INFO] - Training Epoch: 4/10, step 162/574 completed (loss: 1.4136135578155518, acc: 0.6292135119438171)
[2024-11-13 05:14:45,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:45,409][root][INFO] - Training Epoch: 4/10, step 163/574 completed (loss: 0.4439311921596527, acc: 0.9090909361839294)
[2024-11-13 05:14:45,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:45,682][root][INFO] - Training Epoch: 4/10, step 164/574 completed (loss: 0.2859152555465698, acc: 0.8571428656578064)
[2024-11-13 05:14:45,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:45,991][root][INFO] - Training Epoch: 4/10, step 165/574 completed (loss: 0.8780469298362732, acc: 0.7586206793785095)
[2024-11-13 05:14:46,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:46,414][root][INFO] - Training Epoch: 4/10, step 166/574 completed (loss: 0.24261198937892914, acc: 0.8979591727256775)
[2024-11-13 05:14:46,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:46,719][root][INFO] - Training Epoch: 4/10, step 167/574 completed (loss: 0.3495420217514038, acc: 0.8600000143051147)
[2024-11-13 05:14:46,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:47,148][root][INFO] - Training Epoch: 4/10, step 168/574 completed (loss: 0.6155520677566528, acc: 0.8472222089767456)
[2024-11-13 05:14:47,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:47,500][root][INFO] - Training Epoch: 4/10, step 169/574 completed (loss: 1.0592372417449951, acc: 0.7156862616539001)
[2024-11-13 05:14:47,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:48,541][root][INFO] - Training Epoch: 4/10, step 170/574 completed (loss: 1.1452412605285645, acc: 0.7191780805587769)
[2024-11-13 05:14:48,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:48,856][root][INFO] - Training Epoch: 4/10, step 171/574 completed (loss: 0.18226470053195953, acc: 0.9583333134651184)
[2024-11-13 05:14:48,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:49,225][root][INFO] - Training Epoch: 4/10, step 172/574 completed (loss: 0.5719084739685059, acc: 0.7777777910232544)
[2024-11-13 05:14:49,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:49,609][root][INFO] - Training Epoch: 4/10, step 173/574 completed (loss: 0.4814448356628418, acc: 0.8571428656578064)
[2024-11-13 05:14:49,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:50,149][root][INFO] - Training Epoch: 4/10, step 174/574 completed (loss: 1.0564475059509277, acc: 0.7433628439903259)
[2024-11-13 05:14:50,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:50,521][root][INFO] - Training Epoch: 4/10, step 175/574 completed (loss: 0.9285395741462708, acc: 0.7246376872062683)
[2024-11-13 05:14:50,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:50,881][root][INFO] - Training Epoch: 4/10, step 176/574 completed (loss: 0.5980820059776306, acc: 0.8068181872367859)
[2024-11-13 05:14:51,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:52,009][root][INFO] - Training Epoch: 4/10, step 177/574 completed (loss: 1.2973086833953857, acc: 0.6183205842971802)
[2024-11-13 05:14:52,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:52,684][root][INFO] - Training Epoch: 4/10, step 178/574 completed (loss: 1.1102828979492188, acc: 0.6962962746620178)
[2024-11-13 05:14:52,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:52,992][root][INFO] - Training Epoch: 4/10, step 179/574 completed (loss: 0.5526521801948547, acc: 0.7704917788505554)
[2024-11-13 05:14:53,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:53,382][root][INFO] - Training Epoch: 4/10, step 180/574 completed (loss: 0.0941014364361763, acc: 0.9583333134651184)
[2024-11-13 05:14:53,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:53,691][root][INFO] - Training Epoch: 4/10, step 181/574 completed (loss: 0.18539172410964966, acc: 0.9599999785423279)
[2024-11-13 05:14:53,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:54,081][root][INFO] - Training Epoch: 4/10, step 182/574 completed (loss: 0.12299003452062607, acc: 0.9642857313156128)
[2024-11-13 05:14:54,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:54,441][root][INFO] - Training Epoch: 4/10, step 183/574 completed (loss: 0.38922953605651855, acc: 0.8536585569381714)
[2024-11-13 05:14:54,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:54,776][root][INFO] - Training Epoch: 4/10, step 184/574 completed (loss: 0.7299394607543945, acc: 0.8187311291694641)
[2024-11-13 05:14:54,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:55,093][root][INFO] - Training Epoch: 4/10, step 185/574 completed (loss: 0.9117018580436707, acc: 0.7521613836288452)
[2024-11-13 05:14:55,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:55,595][root][INFO] - Training Epoch: 4/10, step 186/574 completed (loss: 0.9063817858695984, acc: 0.731249988079071)
[2024-11-13 05:14:55,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:56,127][root][INFO] - Training Epoch: 4/10, step 187/574 completed (loss: 0.9042200446128845, acc: 0.7692307829856873)
[2024-11-13 05:14:56,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:56,544][root][INFO] - Training Epoch: 4/10, step 188/574 completed (loss: 0.9161831140518188, acc: 0.754448413848877)
[2024-11-13 05:14:56,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:56,885][root][INFO] - Training Epoch: 4/10, step 189/574 completed (loss: 0.3163411021232605, acc: 0.8799999952316284)
[2024-11-13 05:14:57,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:57,458][root][INFO] - Training Epoch: 4/10, step 190/574 completed (loss: 1.0658661127090454, acc: 0.6627907156944275)
[2024-11-13 05:14:57,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:58,344][root][INFO] - Training Epoch: 4/10, step 191/574 completed (loss: 1.263039231300354, acc: 0.60317462682724)
[2024-11-13 05:14:58,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:14:59,306][root][INFO] - Training Epoch: 4/10, step 192/574 completed (loss: 1.2068575620651245, acc: 0.6363636255264282)
[2024-11-13 05:14:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:00,278][root][INFO] - Training Epoch: 4/10, step 193/574 completed (loss: 0.6583957672119141, acc: 0.800000011920929)
[2024-11-13 05:15:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:01,510][root][INFO] - Training Epoch: 4/10, step 194/574 completed (loss: 1.076322317123413, acc: 0.6604938507080078)
[2024-11-13 05:15:01,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:02,475][root][INFO] - Training Epoch: 4/10, step 195/574 completed (loss: 0.42511430382728577, acc: 0.8225806355476379)
[2024-11-13 05:15:02,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:02,758][root][INFO] - Training Epoch: 4/10, step 196/574 completed (loss: 0.19204141199588776, acc: 0.9642857313156128)
[2024-11-13 05:15:02,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:03,057][root][INFO] - Training Epoch: 4/10, step 197/574 completed (loss: 0.707381010055542, acc: 0.800000011920929)
[2024-11-13 05:15:03,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:03,466][root][INFO] - Training Epoch: 4/10, step 198/574 completed (loss: 0.8539093136787415, acc: 0.7352941036224365)
[2024-11-13 05:15:03,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:03,831][root][INFO] - Training Epoch: 4/10, step 199/574 completed (loss: 1.0044841766357422, acc: 0.7279411554336548)
[2024-11-13 05:15:03,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:04,163][root][INFO] - Training Epoch: 4/10, step 200/574 completed (loss: 0.8023108243942261, acc: 0.7796609997749329)
[2024-11-13 05:15:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:04,496][root][INFO] - Training Epoch: 4/10, step 201/574 completed (loss: 1.0232505798339844, acc: 0.7686567306518555)
[2024-11-13 05:15:04,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:04,886][root][INFO] - Training Epoch: 4/10, step 202/574 completed (loss: 0.9165818095207214, acc: 0.6990291476249695)
[2024-11-13 05:15:04,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:05,181][root][INFO] - Training Epoch: 4/10, step 203/574 completed (loss: 0.9559639692306519, acc: 0.7301587462425232)
[2024-11-13 05:15:05,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:05,476][root][INFO] - Training Epoch: 4/10, step 204/574 completed (loss: 0.4397130608558655, acc: 0.8791208863258362)
[2024-11-13 05:15:05,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:05,793][root][INFO] - Training Epoch: 4/10, step 205/574 completed (loss: 0.5188697576522827, acc: 0.8385650515556335)
[2024-11-13 05:15:05,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:06,205][root][INFO] - Training Epoch: 4/10, step 206/574 completed (loss: 0.7230427861213684, acc: 0.8110235929489136)
[2024-11-13 05:15:06,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:06,499][root][INFO] - Training Epoch: 4/10, step 207/574 completed (loss: 0.6139468550682068, acc: 0.8448275923728943)
[2024-11-13 05:15:06,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:06,853][root][INFO] - Training Epoch: 4/10, step 208/574 completed (loss: 0.6522876620292664, acc: 0.8152173757553101)
[2024-11-13 05:15:06,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:07,229][root][INFO] - Training Epoch: 4/10, step 209/574 completed (loss: 0.7135125994682312, acc: 0.7976653575897217)
[2024-11-13 05:15:07,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:07,627][root][INFO] - Training Epoch: 4/10, step 210/574 completed (loss: 0.6759965419769287, acc: 0.8369565010070801)
[2024-11-13 05:15:07,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:07,959][root][INFO] - Training Epoch: 4/10, step 211/574 completed (loss: 0.23708058893680573, acc: 0.95652174949646)
[2024-11-13 05:15:08,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:08,317][root][INFO] - Training Epoch: 4/10, step 212/574 completed (loss: 0.18441930413246155, acc: 0.9642857313156128)
[2024-11-13 05:15:08,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:08,676][root][INFO] - Training Epoch: 4/10, step 213/574 completed (loss: 0.1311863362789154, acc: 0.957446813583374)
[2024-11-13 05:15:08,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:09,522][root][INFO] - Training Epoch: 4/10, step 214/574 completed (loss: 0.3406326472759247, acc: 0.9230769276618958)
[2024-11-13 05:15:09,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:09,896][root][INFO] - Training Epoch: 4/10, step 215/574 completed (loss: 0.20565664768218994, acc: 0.9324324131011963)
[2024-11-13 05:15:10,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:10,245][root][INFO] - Training Epoch: 4/10, step 216/574 completed (loss: 0.19798043370246887, acc: 0.930232584476471)
[2024-11-13 05:15:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:10,793][root][INFO] - Training Epoch: 4/10, step 217/574 completed (loss: 0.3454117178916931, acc: 0.8918918967247009)
[2024-11-13 05:15:10,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:11,200][root][INFO] - Training Epoch: 4/10, step 218/574 completed (loss: 0.23456695675849915, acc: 0.9222221970558167)
[2024-11-13 05:15:11,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:11,596][root][INFO] - Training Epoch: 4/10, step 219/574 completed (loss: 0.18254444003105164, acc: 0.9696969985961914)
[2024-11-13 05:15:11,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:11,923][root][INFO] - Training Epoch: 4/10, step 220/574 completed (loss: 0.08803674578666687, acc: 0.9629629850387573)
[2024-11-13 05:15:12,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:12,231][root][INFO] - Training Epoch: 4/10, step 221/574 completed (loss: 0.0976518988609314, acc: 0.9599999785423279)
[2024-11-13 05:15:12,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:12,542][root][INFO] - Training Epoch: 4/10, step 222/574 completed (loss: 0.7665380239486694, acc: 0.7692307829856873)
[2024-11-13 05:15:12,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:13,351][root][INFO] - Training Epoch: 4/10, step 223/574 completed (loss: 0.5033992528915405, acc: 0.842391312122345)
[2024-11-13 05:15:13,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:13,899][root][INFO] - Training Epoch: 4/10, step 224/574 completed (loss: 0.6881465315818787, acc: 0.8181818127632141)
[2024-11-13 05:15:14,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:14,343][root][INFO] - Training Epoch: 4/10, step 225/574 completed (loss: 0.7661987543106079, acc: 0.7765957713127136)
[2024-11-13 05:15:14,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:14,754][root][INFO] - Training Epoch: 4/10, step 226/574 completed (loss: 0.7298969030380249, acc: 0.7358490824699402)
[2024-11-13 05:15:14,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:15,140][root][INFO] - Training Epoch: 4/10, step 227/574 completed (loss: 0.43904682993888855, acc: 0.8666666746139526)
[2024-11-13 05:15:15,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:15,537][root][INFO] - Training Epoch: 4/10, step 228/574 completed (loss: 0.33132240176200867, acc: 0.930232584476471)
[2024-11-13 05:15:15,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:15,875][root][INFO] - Training Epoch: 4/10, step 229/574 completed (loss: 0.9673235416412354, acc: 0.699999988079071)
[2024-11-13 05:15:16,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:16,283][root][INFO] - Training Epoch: 4/10, step 230/574 completed (loss: 2.0414974689483643, acc: 0.5157894492149353)
[2024-11-13 05:15:16,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:16,600][root][INFO] - Training Epoch: 4/10, step 231/574 completed (loss: 1.307761311531067, acc: 0.6222222447395325)
[2024-11-13 05:15:16,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:17,030][root][INFO] - Training Epoch: 4/10, step 232/574 completed (loss: 1.3937283754348755, acc: 0.6222222447395325)
[2024-11-13 05:15:17,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:17,530][root][INFO] - Training Epoch: 4/10, step 233/574 completed (loss: 1.7119436264038086, acc: 0.5412843823432922)
[2024-11-13 05:15:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:18,028][root][INFO] - Training Epoch: 4/10, step 234/574 completed (loss: 1.3529655933380127, acc: 0.6538461446762085)
[2024-11-13 05:15:18,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:18,397][root][INFO] - Training Epoch: 4/10, step 235/574 completed (loss: 0.247092604637146, acc: 0.8947368264198303)
[2024-11-13 05:15:18,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:18,800][root][INFO] - Training Epoch: 4/10, step 236/574 completed (loss: 0.31668344140052795, acc: 0.8333333134651184)
[2024-11-13 05:15:18,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:19,152][root][INFO] - Training Epoch: 4/10, step 237/574 completed (loss: 1.0044171810150146, acc: 0.7272727489471436)
[2024-11-13 05:15:19,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:19,508][root][INFO] - Training Epoch: 4/10, step 238/574 completed (loss: 0.7793436646461487, acc: 0.7777777910232544)
[2024-11-13 05:15:19,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:19,842][root][INFO] - Training Epoch: 4/10, step 239/574 completed (loss: 0.5172861814498901, acc: 0.7714285850524902)
[2024-11-13 05:15:19,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:20,190][root][INFO] - Training Epoch: 4/10, step 240/574 completed (loss: 0.9730433821678162, acc: 0.75)
[2024-11-13 05:15:20,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:20,530][root][INFO] - Training Epoch: 4/10, step 241/574 completed (loss: 0.8824748992919922, acc: 0.75)
[2024-11-13 05:15:20,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:21,149][root][INFO] - Training Epoch: 4/10, step 242/574 completed (loss: 1.346309781074524, acc: 0.6290322542190552)
[2024-11-13 05:15:21,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:21,697][root][INFO] - Training Epoch: 4/10, step 243/574 completed (loss: 1.190645694732666, acc: 0.7045454382896423)
[2024-11-13 05:15:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:22,064][root][INFO] - Training Epoch: 4/10, step 244/574 completed (loss: 0.014979977160692215, acc: 1.0)
[2024-11-13 05:15:22,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:22,448][root][INFO] - Training Epoch: 4/10, step 245/574 completed (loss: 0.24908903241157532, acc: 0.9230769276618958)
[2024-11-13 05:15:22,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:22,785][root][INFO] - Training Epoch: 4/10, step 246/574 completed (loss: 0.3014232814311981, acc: 0.9032257795333862)
[2024-11-13 05:15:22,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:23,114][root][INFO] - Training Epoch: 4/10, step 247/574 completed (loss: 0.27386462688446045, acc: 0.8999999761581421)
[2024-11-13 05:15:23,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:23,521][root][INFO] - Training Epoch: 4/10, step 248/574 completed (loss: 0.539652407169342, acc: 0.8918918967247009)
[2024-11-13 05:15:23,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:23,905][root][INFO] - Training Epoch: 4/10, step 249/574 completed (loss: 0.6097497940063477, acc: 0.837837815284729)
[2024-11-13 05:15:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:24,277][root][INFO] - Training Epoch: 4/10, step 250/574 completed (loss: 0.162880077958107, acc: 0.9459459185600281)
[2024-11-13 05:15:24,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:24,636][root][INFO] - Training Epoch: 4/10, step 251/574 completed (loss: 0.3573629558086395, acc: 0.8970588445663452)
[2024-11-13 05:15:24,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:24,963][root][INFO] - Training Epoch: 4/10, step 252/574 completed (loss: 0.16735346615314484, acc: 0.9268292784690857)
[2024-11-13 05:15:25,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:25,260][root][INFO] - Training Epoch: 4/10, step 253/574 completed (loss: 0.021559439599514008, acc: 1.0)
[2024-11-13 05:15:25,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:25,543][root][INFO] - Training Epoch: 4/10, step 254/574 completed (loss: 0.022800343111157417, acc: 1.0)
[2024-11-13 05:15:25,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:25,827][root][INFO] - Training Epoch: 4/10, step 255/574 completed (loss: 0.11159756779670715, acc: 0.9677419066429138)
[2024-11-13 05:15:25,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:26,128][root][INFO] - Training Epoch: 4/10, step 256/574 completed (loss: 0.29878342151641846, acc: 0.9473684430122375)
[2024-11-13 05:15:26,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:26,452][root][INFO] - Training Epoch: 4/10, step 257/574 completed (loss: 0.1601572483778, acc: 0.9571428298950195)
[2024-11-13 05:15:26,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:26,761][root][INFO] - Training Epoch: 4/10, step 258/574 completed (loss: 0.2909230589866638, acc: 0.9342105388641357)
[2024-11-13 05:15:26,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:27,321][root][INFO] - Training Epoch: 4/10, step 259/574 completed (loss: 0.5921719670295715, acc: 0.8584905862808228)
[2024-11-13 05:15:27,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:27,901][root][INFO] - Training Epoch: 4/10, step 260/574 completed (loss: 0.5511736273765564, acc: 0.7916666865348816)
[2024-11-13 05:15:27,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:28,198][root][INFO] - Training Epoch: 4/10, step 261/574 completed (loss: 0.151009202003479, acc: 0.9166666865348816)
[2024-11-13 05:15:28,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:28,499][root][INFO] - Training Epoch: 4/10, step 262/574 completed (loss: 0.5106536149978638, acc: 0.9032257795333862)
[2024-11-13 05:15:28,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:28,846][root][INFO] - Training Epoch: 4/10, step 263/574 completed (loss: 1.2878655195236206, acc: 0.653333306312561)
[2024-11-13 05:15:28,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:29,183][root][INFO] - Training Epoch: 4/10, step 264/574 completed (loss: 0.6412182450294495, acc: 0.7916666865348816)
[2024-11-13 05:15:29,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:30,094][root][INFO] - Training Epoch: 4/10, step 265/574 completed (loss: 1.262742280960083, acc: 0.6399999856948853)
[2024-11-13 05:15:30,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:30,414][root][INFO] - Training Epoch: 4/10, step 266/574 completed (loss: 1.2155781984329224, acc: 0.6741573214530945)
[2024-11-13 05:15:30,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:30,762][root][INFO] - Training Epoch: 4/10, step 267/574 completed (loss: 0.8592893481254578, acc: 0.6891891956329346)
[2024-11-13 05:15:30,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:31,205][root][INFO] - Training Epoch: 4/10, step 268/574 completed (loss: 0.7192325592041016, acc: 0.8103448152542114)
[2024-11-13 05:15:31,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:31,495][root][INFO] - Training Epoch: 4/10, step 269/574 completed (loss: 0.0779910758137703, acc: 1.0)
[2024-11-13 05:15:31,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:31,800][root][INFO] - Training Epoch: 4/10, step 270/574 completed (loss: 0.03778089955449104, acc: 1.0)
[2024-11-13 05:15:31,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:32,102][root][INFO] - Training Epoch: 4/10, step 271/574 completed (loss: 0.19227908551692963, acc: 0.90625)
[2024-11-13 05:15:32,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:32,428][root][INFO] - Training Epoch: 4/10, step 272/574 completed (loss: 0.21792788803577423, acc: 0.9666666388511658)
[2024-11-13 05:15:32,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:32,781][root][INFO] - Training Epoch: 4/10, step 273/574 completed (loss: 0.46995922923088074, acc: 0.8666666746139526)
[2024-11-13 05:15:32,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:33,072][root][INFO] - Training Epoch: 4/10, step 274/574 completed (loss: 0.2412429004907608, acc: 0.9375)
[2024-11-13 05:15:33,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:33,386][root][INFO] - Training Epoch: 4/10, step 275/574 completed (loss: 0.21933665871620178, acc: 0.9333333373069763)
[2024-11-13 05:15:33,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:33,695][root][INFO] - Training Epoch: 4/10, step 276/574 completed (loss: 0.49812179803848267, acc: 0.8965517282485962)
[2024-11-13 05:15:33,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:33,994][root][INFO] - Training Epoch: 4/10, step 277/574 completed (loss: 0.21311277151107788, acc: 0.9599999785423279)
[2024-11-13 05:15:34,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:34,293][root][INFO] - Training Epoch: 4/10, step 278/574 completed (loss: 0.6965515613555908, acc: 0.8297872543334961)
[2024-11-13 05:15:34,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:34,602][root][INFO] - Training Epoch: 4/10, step 279/574 completed (loss: 0.49774375557899475, acc: 0.8541666865348816)
[2024-11-13 05:15:35,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:35,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:36,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:36,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:36,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:37,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:37,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:37,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:38,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:38,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:39,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:39,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:39,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:40,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:40,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:40,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:41,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:41,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:42,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:42,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:42,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:43,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:43,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:43,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:44,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:44,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:45,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:45,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:45,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:46,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:46,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:47,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:47,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:47,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:48,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:48,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:48,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:49,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:49,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:49,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:50,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:50,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:50,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:51,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:51,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:52,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:52,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:52,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:53,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:53,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:54,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:54,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:54,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:55,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:55,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:55,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:56,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:56,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:56,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:57,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:57,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:58,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:58,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:59,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:59,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:15:59,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:00,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:00,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:00,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:01,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:01,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:01,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:02,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:02,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:02,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:03,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:03,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:03,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:04,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:04,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:04,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:05,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:05,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:06,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:06,910][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2068, device='cuda:0') eval_epoch_loss=tensor(0.7916, device='cuda:0') eval_epoch_acc=tensor(0.7951, device='cuda:0')
[2024-11-13 05:16:06,911][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:16:06,912][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:16:07,161][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_4_step_280_loss_0.7915551066398621/model.pt
[2024-11-13 05:16:07,164][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:16:07,165][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 4 is 0.7950742840766907
[2024-11-13 05:16:07,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:07,590][root][INFO] - Training Epoch: 4/10, step 280/574 completed (loss: 0.147184357047081, acc: 0.9545454382896423)
[2024-11-13 05:16:07,717][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:08,014][root][INFO] - Training Epoch: 4/10, step 281/574 completed (loss: 0.987075686454773, acc: 0.7228915691375732)
[2024-11-13 05:16:08,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:08,379][root][INFO] - Training Epoch: 4/10, step 282/574 completed (loss: 0.927662193775177, acc: 0.7129629850387573)
[2024-11-13 05:16:08,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:08,737][root][INFO] - Training Epoch: 4/10, step 283/574 completed (loss: 0.15753847360610962, acc: 0.9736841917037964)
[2024-11-13 05:16:08,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:09,038][root][INFO] - Training Epoch: 4/10, step 284/574 completed (loss: 0.3552756607532501, acc: 0.9117646813392639)
[2024-11-13 05:16:09,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:09,348][root][INFO] - Training Epoch: 4/10, step 285/574 completed (loss: 0.2692723274230957, acc: 0.8999999761581421)
[2024-11-13 05:16:09,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:09,654][root][INFO] - Training Epoch: 4/10, step 286/574 completed (loss: 0.6492844223976135, acc: 0.8203125)
[2024-11-13 05:16:09,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:09,979][root][INFO] - Training Epoch: 4/10, step 287/574 completed (loss: 0.7183717489242554, acc: 0.7839999794960022)
[2024-11-13 05:16:10,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:10,279][root][INFO] - Training Epoch: 4/10, step 288/574 completed (loss: 0.6825594902038574, acc: 0.8131868243217468)
[2024-11-13 05:16:10,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:10,583][root][INFO] - Training Epoch: 4/10, step 289/574 completed (loss: 0.5816227793693542, acc: 0.8447204828262329)
[2024-11-13 05:16:10,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:10,916][root][INFO] - Training Epoch: 4/10, step 290/574 completed (loss: 0.871774435043335, acc: 0.7835051417350769)
[2024-11-13 05:16:10,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:11,213][root][INFO] - Training Epoch: 4/10, step 291/574 completed (loss: 0.09881944209337234, acc: 0.9545454382896423)
[2024-11-13 05:16:11,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:11,525][root][INFO] - Training Epoch: 4/10, step 292/574 completed (loss: 0.43347734212875366, acc: 0.8809523582458496)
[2024-11-13 05:16:11,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:11,836][root][INFO] - Training Epoch: 4/10, step 293/574 completed (loss: 0.2161751240491867, acc: 0.931034505367279)
[2024-11-13 05:16:11,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:12,288][root][INFO] - Training Epoch: 4/10, step 294/574 completed (loss: 0.36981236934661865, acc: 0.8909090757369995)
[2024-11-13 05:16:12,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:12,832][root][INFO] - Training Epoch: 4/10, step 295/574 completed (loss: 0.8981344699859619, acc: 0.7577319741249084)
[2024-11-13 05:16:12,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:13,167][root][INFO] - Training Epoch: 4/10, step 296/574 completed (loss: 0.6861898899078369, acc: 0.7758620977401733)
[2024-11-13 05:16:13,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:13,515][root][INFO] - Training Epoch: 4/10, step 297/574 completed (loss: 0.2071020007133484, acc: 0.9259259104728699)
[2024-11-13 05:16:13,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:13,824][root][INFO] - Training Epoch: 4/10, step 298/574 completed (loss: 0.4521605372428894, acc: 0.8421052694320679)
[2024-11-13 05:16:13,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:14,127][root][INFO] - Training Epoch: 4/10, step 299/574 completed (loss: 0.30458471179008484, acc: 0.9285714030265808)
[2024-11-13 05:16:14,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:14,436][root][INFO] - Training Epoch: 4/10, step 300/574 completed (loss: 0.20490595698356628, acc: 0.9375)
[2024-11-13 05:16:14,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:14,774][root][INFO] - Training Epoch: 4/10, step 301/574 completed (loss: 0.28892359137535095, acc: 0.9245283007621765)
[2024-11-13 05:16:14,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:15,105][root][INFO] - Training Epoch: 4/10, step 302/574 completed (loss: 0.04715042561292648, acc: 1.0)
[2024-11-13 05:16:15,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:15,446][root][INFO] - Training Epoch: 4/10, step 303/574 completed (loss: 0.06512005627155304, acc: 1.0)
[2024-11-13 05:16:15,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:15,780][root][INFO] - Training Epoch: 4/10, step 304/574 completed (loss: 0.22455357015132904, acc: 0.9375)
[2024-11-13 05:16:15,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:16,111][root][INFO] - Training Epoch: 4/10, step 305/574 completed (loss: 0.38452619314193726, acc: 0.8852459192276001)
[2024-11-13 05:16:16,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:16,417][root][INFO] - Training Epoch: 4/10, step 306/574 completed (loss: 0.0416577011346817, acc: 1.0)
[2024-11-13 05:16:16,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:16,799][root][INFO] - Training Epoch: 4/10, step 307/574 completed (loss: 0.0259175356477499, acc: 1.0)
[2024-11-13 05:16:16,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:17,146][root][INFO] - Training Epoch: 4/10, step 308/574 completed (loss: 0.26768380403518677, acc: 0.9130434989929199)
[2024-11-13 05:16:17,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:17,553][root][INFO] - Training Epoch: 4/10, step 309/574 completed (loss: 0.35673755407333374, acc: 0.9166666865348816)
[2024-11-13 05:16:17,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:17,863][root][INFO] - Training Epoch: 4/10, step 310/574 completed (loss: 0.22674383223056793, acc: 0.9518072009086609)
[2024-11-13 05:16:17,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:18,172][root][INFO] - Training Epoch: 4/10, step 311/574 completed (loss: 0.43364378809928894, acc: 0.8589743375778198)
[2024-11-13 05:16:18,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:18,536][root][INFO] - Training Epoch: 4/10, step 312/574 completed (loss: 0.31451839208602905, acc: 0.918367326259613)
[2024-11-13 05:16:18,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:18,863][root][INFO] - Training Epoch: 4/10, step 313/574 completed (loss: 0.02825489453971386, acc: 1.0)
[2024-11-13 05:16:18,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:19,164][root][INFO] - Training Epoch: 4/10, step 314/574 completed (loss: 0.08997956663370132, acc: 0.9583333134651184)
[2024-11-13 05:16:19,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:19,447][root][INFO] - Training Epoch: 4/10, step 315/574 completed (loss: 0.178932324051857, acc: 0.9354838728904724)
[2024-11-13 05:16:19,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:19,727][root][INFO] - Training Epoch: 4/10, step 316/574 completed (loss: 0.5253051519393921, acc: 0.8709677457809448)
[2024-11-13 05:16:19,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:20,048][root][INFO] - Training Epoch: 4/10, step 317/574 completed (loss: 0.14885437488555908, acc: 0.9701492786407471)
[2024-11-13 05:16:20,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:20,366][root][INFO] - Training Epoch: 4/10, step 318/574 completed (loss: 0.28897106647491455, acc: 0.9134615659713745)
[2024-11-13 05:16:20,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:20,664][root][INFO] - Training Epoch: 4/10, step 319/574 completed (loss: 0.1751491278409958, acc: 0.9555555582046509)
[2024-11-13 05:16:20,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:20,962][root][INFO] - Training Epoch: 4/10, step 320/574 completed (loss: 0.13376857340335846, acc: 0.9354838728904724)
[2024-11-13 05:16:21,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:21,261][root][INFO] - Training Epoch: 4/10, step 321/574 completed (loss: 0.042719896882772446, acc: 0.9800000190734863)
[2024-11-13 05:16:21,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:21,557][root][INFO] - Training Epoch: 4/10, step 322/574 completed (loss: 0.6411725282669067, acc: 0.7777777910232544)
[2024-11-13 05:16:21,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:21,840][root][INFO] - Training Epoch: 4/10, step 323/574 completed (loss: 1.2758616209030151, acc: 0.6000000238418579)
[2024-11-13 05:16:21,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:22,143][root][INFO] - Training Epoch: 4/10, step 324/574 completed (loss: 1.0833312273025513, acc: 0.6666666865348816)
[2024-11-13 05:16:22,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:22,437][root][INFO] - Training Epoch: 4/10, step 325/574 completed (loss: 1.3854472637176514, acc: 0.5609756112098694)
[2024-11-13 05:16:22,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:22,732][root][INFO] - Training Epoch: 4/10, step 326/574 completed (loss: 1.1290227174758911, acc: 0.6578947305679321)
[2024-11-13 05:16:22,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:23,029][root][INFO] - Training Epoch: 4/10, step 327/574 completed (loss: 0.18759635090827942, acc: 0.9473684430122375)
[2024-11-13 05:16:23,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:23,381][root][INFO] - Training Epoch: 4/10, step 328/574 completed (loss: 0.04281182959675789, acc: 0.9642857313156128)
[2024-11-13 05:16:23,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:23,701][root][INFO] - Training Epoch: 4/10, step 329/574 completed (loss: 0.08504432439804077, acc: 1.0)
[2024-11-13 05:16:23,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:24,036][root][INFO] - Training Epoch: 4/10, step 330/574 completed (loss: 0.044549573212862015, acc: 0.96875)
[2024-11-13 05:16:24,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:24,385][root][INFO] - Training Epoch: 4/10, step 331/574 completed (loss: 0.3446773886680603, acc: 0.8870967626571655)
[2024-11-13 05:16:24,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:24,742][root][INFO] - Training Epoch: 4/10, step 332/574 completed (loss: 0.17139758169651031, acc: 0.9649122953414917)
[2024-11-13 05:16:24,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:25,049][root][INFO] - Training Epoch: 4/10, step 333/574 completed (loss: 0.41378623247146606, acc: 0.90625)
[2024-11-13 05:16:25,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:25,409][root][INFO] - Training Epoch: 4/10, step 334/574 completed (loss: 0.13253392279148102, acc: 0.9666666388511658)
[2024-11-13 05:16:25,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:25,736][root][INFO] - Training Epoch: 4/10, step 335/574 completed (loss: 0.20482003688812256, acc: 0.9473684430122375)
[2024-11-13 05:16:25,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:26,064][root][INFO] - Training Epoch: 4/10, step 336/574 completed (loss: 0.9120551347732544, acc: 0.800000011920929)
[2024-11-13 05:16:26,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:26,388][root][INFO] - Training Epoch: 4/10, step 337/574 completed (loss: 1.5266467332839966, acc: 0.5747126340866089)
[2024-11-13 05:16:26,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:26,715][root][INFO] - Training Epoch: 4/10, step 338/574 completed (loss: 1.4300487041473389, acc: 0.6063829660415649)
[2024-11-13 05:16:26,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:27,013][root][INFO] - Training Epoch: 4/10, step 339/574 completed (loss: 1.6103506088256836, acc: 0.5662650465965271)
[2024-11-13 05:16:27,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:27,250][root][INFO] - Training Epoch: 4/10, step 340/574 completed (loss: 0.058649249374866486, acc: 1.0)
[2024-11-13 05:16:27,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:27,542][root][INFO] - Training Epoch: 4/10, step 341/574 completed (loss: 0.43626466393470764, acc: 0.8717948794364929)
[2024-11-13 05:16:27,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:27,884][root][INFO] - Training Epoch: 4/10, step 342/574 completed (loss: 0.5141239166259766, acc: 0.9036144614219666)
[2024-11-13 05:16:27,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:28,197][root][INFO] - Training Epoch: 4/10, step 343/574 completed (loss: 0.5674546957015991, acc: 0.7735849022865295)
[2024-11-13 05:16:28,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:28,502][root][INFO] - Training Epoch: 4/10, step 344/574 completed (loss: 0.24144023656845093, acc: 0.9113923907279968)
[2024-11-13 05:16:28,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:28,840][root][INFO] - Training Epoch: 4/10, step 345/574 completed (loss: 0.21245039999485016, acc: 0.9215686321258545)
[2024-11-13 05:16:28,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:29,154][root][INFO] - Training Epoch: 4/10, step 346/574 completed (loss: 0.6706807017326355, acc: 0.8059701323509216)
[2024-11-13 05:16:29,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:29,459][root][INFO] - Training Epoch: 4/10, step 347/574 completed (loss: 0.05681856721639633, acc: 0.949999988079071)
[2024-11-13 05:16:29,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:29,756][root][INFO] - Training Epoch: 4/10, step 348/574 completed (loss: 0.22144486010074615, acc: 0.9200000166893005)
[2024-11-13 05:16:29,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:30,141][root][INFO] - Training Epoch: 4/10, step 349/574 completed (loss: 0.698616623878479, acc: 0.8333333134651184)
[2024-11-13 05:16:30,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:30,449][root][INFO] - Training Epoch: 4/10, step 350/574 completed (loss: 0.7173685431480408, acc: 0.7674418687820435)
[2024-11-13 05:16:30,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:30,779][root][INFO] - Training Epoch: 4/10, step 351/574 completed (loss: 0.26278647780418396, acc: 0.9230769276618958)
[2024-11-13 05:16:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:31,144][root][INFO] - Training Epoch: 4/10, step 352/574 completed (loss: 1.2203446626663208, acc: 0.6000000238418579)
[2024-11-13 05:16:31,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:31,481][root][INFO] - Training Epoch: 4/10, step 353/574 completed (loss: 0.07511338591575623, acc: 0.95652174949646)
[2024-11-13 05:16:31,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:31,780][root][INFO] - Training Epoch: 4/10, step 354/574 completed (loss: 0.5724878907203674, acc: 0.7692307829856873)
[2024-11-13 05:16:31,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:32,117][root][INFO] - Training Epoch: 4/10, step 355/574 completed (loss: 0.9909457564353943, acc: 0.7142857313156128)
[2024-11-13 05:16:32,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:32,610][root][INFO] - Training Epoch: 4/10, step 356/574 completed (loss: 0.7691152095794678, acc: 0.7652173638343811)
[2024-11-13 05:16:32,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:32,977][root][INFO] - Training Epoch: 4/10, step 357/574 completed (loss: 0.715854823589325, acc: 0.8260869383811951)
[2024-11-13 05:16:33,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:33,316][root][INFO] - Training Epoch: 4/10, step 358/574 completed (loss: 0.7642994523048401, acc: 0.795918345451355)
[2024-11-13 05:16:33,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:33,628][root][INFO] - Training Epoch: 4/10, step 359/574 completed (loss: 0.04857664927840233, acc: 0.9583333134651184)
[2024-11-13 05:16:33,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:33,934][root][INFO] - Training Epoch: 4/10, step 360/574 completed (loss: 0.0359615683555603, acc: 1.0)
[2024-11-13 05:16:34,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:34,228][root][INFO] - Training Epoch: 4/10, step 361/574 completed (loss: 0.4495110809803009, acc: 0.8536585569381714)
[2024-11-13 05:16:34,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:34,539][root][INFO] - Training Epoch: 4/10, step 362/574 completed (loss: 0.46268534660339355, acc: 0.8444444537162781)
[2024-11-13 05:16:34,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:34,873][root][INFO] - Training Epoch: 4/10, step 363/574 completed (loss: 0.2198140025138855, acc: 0.9342105388641357)
[2024-11-13 05:16:34,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:35,189][root][INFO] - Training Epoch: 4/10, step 364/574 completed (loss: 0.31245023012161255, acc: 0.8780487775802612)
[2024-11-13 05:16:35,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:35,486][root][INFO] - Training Epoch: 4/10, step 365/574 completed (loss: 0.13835427165031433, acc: 0.9696969985961914)
[2024-11-13 05:16:35,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:35,782][root][INFO] - Training Epoch: 4/10, step 366/574 completed (loss: 0.23303580284118652, acc: 0.9583333134651184)
[2024-11-13 05:16:35,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:36,079][root][INFO] - Training Epoch: 4/10, step 367/574 completed (loss: 0.11578623205423355, acc: 0.95652174949646)
[2024-11-13 05:16:36,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:36,369][root][INFO] - Training Epoch: 4/10, step 368/574 completed (loss: 0.04061928018927574, acc: 1.0)
[2024-11-13 05:16:36,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:36,668][root][INFO] - Training Epoch: 4/10, step 369/574 completed (loss: 0.20969179272651672, acc: 0.96875)
[2024-11-13 05:16:36,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:37,263][root][INFO] - Training Epoch: 4/10, step 370/574 completed (loss: 0.8017112016677856, acc: 0.7696969509124756)
[2024-11-13 05:16:37,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:38,137][root][INFO] - Training Epoch: 4/10, step 371/574 completed (loss: 0.516202986240387, acc: 0.8679245114326477)
[2024-11-13 05:16:38,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:38,467][root][INFO] - Training Epoch: 4/10, step 372/574 completed (loss: 0.44931212067604065, acc: 0.9111111164093018)
[2024-11-13 05:16:38,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:38,770][root][INFO] - Training Epoch: 4/10, step 373/574 completed (loss: 0.08540765941143036, acc: 0.9642857313156128)
[2024-11-13 05:16:38,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:39,082][root][INFO] - Training Epoch: 4/10, step 374/574 completed (loss: 0.19071274995803833, acc: 0.9428571462631226)
[2024-11-13 05:16:39,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:39,369][root][INFO] - Training Epoch: 4/10, step 375/574 completed (loss: 0.005639540497213602, acc: 1.0)
[2024-11-13 05:16:39,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:39,659][root][INFO] - Training Epoch: 4/10, step 376/574 completed (loss: 0.08147218078374863, acc: 0.95652174949646)
[2024-11-13 05:16:39,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:39,965][root][INFO] - Training Epoch: 4/10, step 377/574 completed (loss: 0.16289587318897247, acc: 0.9583333134651184)
[2024-11-13 05:16:40,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:40,282][root][INFO] - Training Epoch: 4/10, step 378/574 completed (loss: 0.0909314975142479, acc: 0.9473684430122375)
[2024-11-13 05:16:40,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:40,853][root][INFO] - Training Epoch: 4/10, step 379/574 completed (loss: 0.45786115527153015, acc: 0.8802395462989807)
[2024-11-13 05:16:40,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:41,257][root][INFO] - Training Epoch: 4/10, step 380/574 completed (loss: 0.39388203620910645, acc: 0.9097744226455688)
[2024-11-13 05:16:41,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:42,511][root][INFO] - Training Epoch: 4/10, step 381/574 completed (loss: 0.6566728353500366, acc: 0.8449198007583618)
[2024-11-13 05:16:42,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:43,072][root][INFO] - Training Epoch: 4/10, step 382/574 completed (loss: 0.1377585530281067, acc: 0.9459459185600281)
[2024-11-13 05:16:43,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:43,370][root][INFO] - Training Epoch: 4/10, step 383/574 completed (loss: 0.19650717079639435, acc: 0.9642857313156128)
[2024-11-13 05:16:43,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:43,660][root][INFO] - Training Epoch: 4/10, step 384/574 completed (loss: 0.03657514974474907, acc: 1.0)
[2024-11-13 05:16:43,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:43,919][root][INFO] - Training Epoch: 4/10, step 385/574 completed (loss: 0.18289712071418762, acc: 0.9375)
[2024-11-13 05:16:43,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:44,214][root][INFO] - Training Epoch: 4/10, step 386/574 completed (loss: 0.055471792817115784, acc: 0.9722222089767456)
[2024-11-13 05:16:44,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:44,515][root][INFO] - Training Epoch: 4/10, step 387/574 completed (loss: 0.032982051372528076, acc: 1.0)
[2024-11-13 05:16:44,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:44,827][root][INFO] - Training Epoch: 4/10, step 388/574 completed (loss: 0.006716446951031685, acc: 1.0)
[2024-11-13 05:16:44,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:45,127][root][INFO] - Training Epoch: 4/10, step 389/574 completed (loss: 0.06932645291090012, acc: 0.949999988079071)
[2024-11-13 05:16:45,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:45,428][root][INFO] - Training Epoch: 4/10, step 390/574 completed (loss: 0.39210423827171326, acc: 0.9047619104385376)
[2024-11-13 05:16:45,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:45,740][root][INFO] - Training Epoch: 4/10, step 391/574 completed (loss: 0.8341448903083801, acc: 0.7777777910232544)
[2024-11-13 05:16:45,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:46,054][root][INFO] - Training Epoch: 4/10, step 392/574 completed (loss: 1.1199452877044678, acc: 0.6893203854560852)
[2024-11-13 05:16:46,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:46,602][root][INFO] - Training Epoch: 4/10, step 393/574 completed (loss: 0.9630091190338135, acc: 0.7647058963775635)
[2024-11-13 05:16:46,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:46,974][root][INFO] - Training Epoch: 4/10, step 394/574 completed (loss: 0.988497793674469, acc: 0.7400000095367432)
[2024-11-13 05:16:47,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:47,352][root][INFO] - Training Epoch: 4/10, step 395/574 completed (loss: 0.8696052432060242, acc: 0.7291666865348816)
[2024-11-13 05:16:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:47,742][root][INFO] - Training Epoch: 4/10, step 396/574 completed (loss: 0.36580201983451843, acc: 0.930232584476471)
[2024-11-13 05:16:47,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:48,066][root][INFO] - Training Epoch: 4/10, step 397/574 completed (loss: 0.12361978739500046, acc: 0.9583333134651184)
[2024-11-13 05:16:48,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:48,403][root][INFO] - Training Epoch: 4/10, step 398/574 completed (loss: 0.31375545263290405, acc: 0.9069767594337463)
[2024-11-13 05:16:48,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:48,690][root][INFO] - Training Epoch: 4/10, step 399/574 completed (loss: 0.026605544611811638, acc: 1.0)
[2024-11-13 05:16:48,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:49,219][root][INFO] - Training Epoch: 4/10, step 400/574 completed (loss: 0.3245587646961212, acc: 0.9264705777168274)
[2024-11-13 05:16:49,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:49,582][root][INFO] - Training Epoch: 4/10, step 401/574 completed (loss: 0.4871658980846405, acc: 0.8533333539962769)
[2024-11-13 05:16:49,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:49,901][root][INFO] - Training Epoch: 4/10, step 402/574 completed (loss: 0.5258517861366272, acc: 0.8787878751754761)
[2024-11-13 05:16:50,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:50,254][root][INFO] - Training Epoch: 4/10, step 403/574 completed (loss: 0.41300904750823975, acc: 0.9090909361839294)
[2024-11-13 05:16:50,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:50,570][root][INFO] - Training Epoch: 4/10, step 404/574 completed (loss: 0.053271953016519547, acc: 1.0)
[2024-11-13 05:16:50,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:50,871][root][INFO] - Training Epoch: 4/10, step 405/574 completed (loss: 0.11854252219200134, acc: 0.9629629850387573)
[2024-11-13 05:16:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:51,212][root][INFO] - Training Epoch: 4/10, step 406/574 completed (loss: 0.09785830229520798, acc: 0.9599999785423279)
[2024-11-13 05:16:51,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:51,549][root][INFO] - Training Epoch: 4/10, step 407/574 completed (loss: 0.08626013249158859, acc: 0.9722222089767456)
[2024-11-13 05:16:51,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:51,882][root][INFO] - Training Epoch: 4/10, step 408/574 completed (loss: 0.1611516773700714, acc: 0.9259259104728699)
[2024-11-13 05:16:51,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:52,199][root][INFO] - Training Epoch: 4/10, step 409/574 completed (loss: 0.055342432111501694, acc: 1.0)
[2024-11-13 05:16:52,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:52,532][root][INFO] - Training Epoch: 4/10, step 410/574 completed (loss: 0.1264294534921646, acc: 0.9482758641242981)
[2024-11-13 05:16:52,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:52,862][root][INFO] - Training Epoch: 4/10, step 411/574 completed (loss: 0.07045891135931015, acc: 1.0)
[2024-11-13 05:16:52,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:53,186][root][INFO] - Training Epoch: 4/10, step 412/574 completed (loss: 0.31325098872184753, acc: 0.8666666746139526)
[2024-11-13 05:16:53,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:53,483][root][INFO] - Training Epoch: 4/10, step 413/574 completed (loss: 0.10616985708475113, acc: 0.9696969985961914)
[2024-11-13 05:16:53,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:53,774][root][INFO] - Training Epoch: 4/10, step 414/574 completed (loss: 0.03677041083574295, acc: 1.0)
[2024-11-13 05:16:53,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:54,123][root][INFO] - Training Epoch: 4/10, step 415/574 completed (loss: 0.33854731917381287, acc: 0.8823529481887817)
[2024-11-13 05:16:54,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:54,461][root][INFO] - Training Epoch: 4/10, step 416/574 completed (loss: 0.1344035565853119, acc: 0.9615384340286255)
[2024-11-13 05:16:54,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:54,796][root][INFO] - Training Epoch: 4/10, step 417/574 completed (loss: 0.18296602368354797, acc: 0.8888888955116272)
[2024-11-13 05:16:54,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:55,134][root][INFO] - Training Epoch: 4/10, step 418/574 completed (loss: 0.14031285047531128, acc: 0.949999988079071)
[2024-11-13 05:16:55,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:55,475][root][INFO] - Training Epoch: 4/10, step 419/574 completed (loss: 0.2247038334608078, acc: 0.949999988079071)
[2024-11-13 05:16:55,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:55,817][root][INFO] - Training Epoch: 4/10, step 420/574 completed (loss: 0.05339720845222473, acc: 1.0)
[2024-11-13 05:16:55,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:56,102][root][INFO] - Training Epoch: 4/10, step 421/574 completed (loss: 0.0609358511865139, acc: 1.0)
[2024-11-13 05:16:56,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:56,388][root][INFO] - Training Epoch: 4/10, step 422/574 completed (loss: 0.32078173756599426, acc: 0.90625)
[2024-11-13 05:16:57,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:57,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:57,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:58,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:58,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:58,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:59,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:59,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:16:59,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:00,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:00,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:01,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:01,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:01,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:02,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:02,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:03,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:03,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:03,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:03,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:04,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:04,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:04,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:05,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:05,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:06,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:06,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:06,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:07,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:07,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:07,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:08,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:08,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:09,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:09,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:09,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:09,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:10,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:10,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:10,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:11,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:11,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:11,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:12,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:12,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:12,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:13,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:13,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:14,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:14,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:14,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:15,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:15,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:15,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:16,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:16,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:17,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:17,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:17,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:18,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:18,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:19,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:19,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:19,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:20,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:20,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:20,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:21,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:21,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:21,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:22,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:22,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:22,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:23,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:23,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:23,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:24,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:24,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:25,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:25,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:26,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:26,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:27,180][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3186, device='cuda:0') eval_epoch_loss=tensor(0.8409, device='cuda:0') eval_epoch_acc=tensor(0.7868, device='cuda:0')
[2024-11-13 05:17:27,182][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:17:27,182][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:17:27,489][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_4_step_423_loss_0.8409420251846313/model.pt
[2024-11-13 05:17:27,493][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:17:27,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:27,943][root][INFO] - Training Epoch: 4/10, step 423/574 completed (loss: 0.3813466429710388, acc: 0.8888888955116272)
[2024-11-13 05:17:28,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:28,250][root][INFO] - Training Epoch: 4/10, step 424/574 completed (loss: 0.07335879653692245, acc: 0.9629629850387573)
[2024-11-13 05:17:28,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:28,558][root][INFO] - Training Epoch: 4/10, step 425/574 completed (loss: 0.13761919736862183, acc: 0.939393937587738)
[2024-11-13 05:17:28,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:28,894][root][INFO] - Training Epoch: 4/10, step 426/574 completed (loss: 0.029121873900294304, acc: 1.0)
[2024-11-13 05:17:28,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:29,213][root][INFO] - Training Epoch: 4/10, step 427/574 completed (loss: 0.06872852146625519, acc: 1.0)
[2024-11-13 05:17:29,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:29,531][root][INFO] - Training Epoch: 4/10, step 428/574 completed (loss: 0.07509487867355347, acc: 0.9629629850387573)
[2024-11-13 05:17:29,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:29,870][root][INFO] - Training Epoch: 4/10, step 429/574 completed (loss: 0.013802504166960716, acc: 1.0)
[2024-11-13 05:17:29,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:30,168][root][INFO] - Training Epoch: 4/10, step 430/574 completed (loss: 0.0027268773410469294, acc: 1.0)
[2024-11-13 05:17:30,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:30,445][root][INFO] - Training Epoch: 4/10, step 431/574 completed (loss: 0.028713909909129143, acc: 1.0)
[2024-11-13 05:17:30,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:30,732][root][INFO] - Training Epoch: 4/10, step 432/574 completed (loss: 0.006039431784301996, acc: 1.0)
[2024-11-13 05:17:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:31,066][root][INFO] - Training Epoch: 4/10, step 433/574 completed (loss: 0.18802626430988312, acc: 0.9444444179534912)
[2024-11-13 05:17:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:31,393][root][INFO] - Training Epoch: 4/10, step 434/574 completed (loss: 0.003655556356534362, acc: 1.0)
[2024-11-13 05:17:31,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:31,770][root][INFO] - Training Epoch: 4/10, step 435/574 completed (loss: 0.020628847181797028, acc: 1.0)
[2024-11-13 05:17:31,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:32,123][root][INFO] - Training Epoch: 4/10, step 436/574 completed (loss: 0.3806633949279785, acc: 0.8611111044883728)
[2024-11-13 05:17:32,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:32,493][root][INFO] - Training Epoch: 4/10, step 437/574 completed (loss: 0.18078972399234772, acc: 0.9090909361839294)
[2024-11-13 05:17:32,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:32,837][root][INFO] - Training Epoch: 4/10, step 438/574 completed (loss: 0.007575959898531437, acc: 1.0)
[2024-11-13 05:17:32,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:33,197][root][INFO] - Training Epoch: 4/10, step 439/574 completed (loss: 0.28792649507522583, acc: 0.9487179517745972)
[2024-11-13 05:17:33,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:33,664][root][INFO] - Training Epoch: 4/10, step 440/574 completed (loss: 0.47151827812194824, acc: 0.8636363744735718)
[2024-11-13 05:17:33,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:34,404][root][INFO] - Training Epoch: 4/10, step 441/574 completed (loss: 0.7033557295799255, acc: 0.7680000066757202)
[2024-11-13 05:17:34,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:34,834][root][INFO] - Training Epoch: 4/10, step 442/574 completed (loss: 1.012976050376892, acc: 0.7338709831237793)
[2024-11-13 05:17:35,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:35,487][root][INFO] - Training Epoch: 4/10, step 443/574 completed (loss: 0.7123141884803772, acc: 0.8308457732200623)
[2024-11-13 05:17:35,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:35,852][root][INFO] - Training Epoch: 4/10, step 444/574 completed (loss: 0.25807985663414, acc: 0.9245283007621765)
[2024-11-13 05:17:36,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:36,314][root][INFO] - Training Epoch: 4/10, step 445/574 completed (loss: 0.11672231554985046, acc: 0.9318181872367859)
[2024-11-13 05:17:36,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:36,680][root][INFO] - Training Epoch: 4/10, step 446/574 completed (loss: 0.1394849717617035, acc: 0.9130434989929199)
[2024-11-13 05:17:36,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:37,073][root][INFO] - Training Epoch: 4/10, step 447/574 completed (loss: 0.3501388430595398, acc: 0.9615384340286255)
[2024-11-13 05:17:37,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:37,465][root][INFO] - Training Epoch: 4/10, step 448/574 completed (loss: 0.05384572222828865, acc: 1.0)
[2024-11-13 05:17:37,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:37,841][root][INFO] - Training Epoch: 4/10, step 449/574 completed (loss: 0.31318411231040955, acc: 0.89552241563797)
[2024-11-13 05:17:37,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:38,185][root][INFO] - Training Epoch: 4/10, step 450/574 completed (loss: 0.13301905989646912, acc: 0.9722222089767456)
[2024-11-13 05:17:38,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:38,472][root][INFO] - Training Epoch: 4/10, step 451/574 completed (loss: 0.16277863085269928, acc: 0.95652174949646)
[2024-11-13 05:17:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:38,812][root][INFO] - Training Epoch: 4/10, step 452/574 completed (loss: 0.2909942865371704, acc: 0.9358974099159241)
[2024-11-13 05:17:38,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:39,156][root][INFO] - Training Epoch: 4/10, step 453/574 completed (loss: 0.5383716225624084, acc: 0.8421052694320679)
[2024-11-13 05:17:39,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:39,501][root][INFO] - Training Epoch: 4/10, step 454/574 completed (loss: 0.18158255517482758, acc: 0.9387755393981934)
[2024-11-13 05:17:39,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:39,862][root][INFO] - Training Epoch: 4/10, step 455/574 completed (loss: 0.18138518929481506, acc: 0.939393937587738)
[2024-11-13 05:17:39,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:40,226][root][INFO] - Training Epoch: 4/10, step 456/574 completed (loss: 0.7985182404518127, acc: 0.7835051417350769)
[2024-11-13 05:17:40,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:40,585][root][INFO] - Training Epoch: 4/10, step 457/574 completed (loss: 0.2252078652381897, acc: 0.8999999761581421)
[2024-11-13 05:17:40,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:40,950][root][INFO] - Training Epoch: 4/10, step 458/574 completed (loss: 0.8784328699111938, acc: 0.7616279125213623)
[2024-11-13 05:17:41,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:41,245][root][INFO] - Training Epoch: 4/10, step 459/574 completed (loss: 0.32981523871421814, acc: 0.9464285969734192)
[2024-11-13 05:17:41,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:41,551][root][INFO] - Training Epoch: 4/10, step 460/574 completed (loss: 0.34401124715805054, acc: 0.9012345671653748)
[2024-11-13 05:17:41,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:41,910][root][INFO] - Training Epoch: 4/10, step 461/574 completed (loss: 0.27846798300743103, acc: 0.9722222089767456)
[2024-11-13 05:17:42,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:42,241][root][INFO] - Training Epoch: 4/10, step 462/574 completed (loss: 0.051816996186971664, acc: 0.96875)
[2024-11-13 05:17:42,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:42,572][root][INFO] - Training Epoch: 4/10, step 463/574 completed (loss: 0.30905622243881226, acc: 0.8461538553237915)
[2024-11-13 05:17:42,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:42,932][root][INFO] - Training Epoch: 4/10, step 464/574 completed (loss: 0.24857234954833984, acc: 0.9347826242446899)
[2024-11-13 05:17:43,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:43,273][root][INFO] - Training Epoch: 4/10, step 465/574 completed (loss: 0.30221787095069885, acc: 0.9047619104385376)
[2024-11-13 05:17:43,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:43,518][root][INFO] - Training Epoch: 4/10, step 466/574 completed (loss: 0.6015593409538269, acc: 0.8313252925872803)
[2024-11-13 05:17:43,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:43,910][root][INFO] - Training Epoch: 4/10, step 467/574 completed (loss: 0.35088637471199036, acc: 0.8828828930854797)
[2024-11-13 05:17:44,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:44,258][root][INFO] - Training Epoch: 4/10, step 468/574 completed (loss: 0.8145433664321899, acc: 0.7766990065574646)
[2024-11-13 05:17:44,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:44,596][root][INFO] - Training Epoch: 4/10, step 469/574 completed (loss: 0.7489303946495056, acc: 0.7804877758026123)
[2024-11-13 05:17:44,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:45,000][root][INFO] - Training Epoch: 4/10, step 470/574 completed (loss: 0.06829966604709625, acc: 0.9583333134651184)
[2024-11-13 05:17:45,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:45,382][root][INFO] - Training Epoch: 4/10, step 471/574 completed (loss: 0.1219894140958786, acc: 0.9642857313156128)
[2024-11-13 05:17:45,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:45,772][root][INFO] - Training Epoch: 4/10, step 472/574 completed (loss: 0.607442319393158, acc: 0.7941176295280457)
[2024-11-13 05:17:45,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:46,120][root][INFO] - Training Epoch: 4/10, step 473/574 completed (loss: 0.923288881778717, acc: 0.7379912734031677)
[2024-11-13 05:17:46,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:46,476][root][INFO] - Training Epoch: 4/10, step 474/574 completed (loss: 0.5590760111808777, acc: 0.8125)
[2024-11-13 05:17:46,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:46,889][root][INFO] - Training Epoch: 4/10, step 475/574 completed (loss: 0.4684193730354309, acc: 0.8834356069564819)
[2024-11-13 05:17:47,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:47,246][root][INFO] - Training Epoch: 4/10, step 476/574 completed (loss: 0.4891422688961029, acc: 0.8489208817481995)
[2024-11-13 05:17:47,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:47,634][root][INFO] - Training Epoch: 4/10, step 477/574 completed (loss: 0.8060173988342285, acc: 0.7587939500808716)
[2024-11-13 05:17:47,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:48,018][root][INFO] - Training Epoch: 4/10, step 478/574 completed (loss: 0.2722999155521393, acc: 0.8888888955116272)
[2024-11-13 05:17:48,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:48,386][root][INFO] - Training Epoch: 4/10, step 479/574 completed (loss: 0.22506681084632874, acc: 0.9090909361839294)
[2024-11-13 05:17:48,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:48,709][root][INFO] - Training Epoch: 4/10, step 480/574 completed (loss: 0.10622143000364304, acc: 0.9259259104728699)
[2024-11-13 05:17:48,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:49,054][root][INFO] - Training Epoch: 4/10, step 481/574 completed (loss: 0.6728627681732178, acc: 0.800000011920929)
[2024-11-13 05:17:49,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:49,359][root][INFO] - Training Epoch: 4/10, step 482/574 completed (loss: 0.45080798864364624, acc: 0.800000011920929)
[2024-11-13 05:17:49,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:49,742][root][INFO] - Training Epoch: 4/10, step 483/574 completed (loss: 0.7672317624092102, acc: 0.7931034564971924)
[2024-11-13 05:17:49,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:50,086][root][INFO] - Training Epoch: 4/10, step 484/574 completed (loss: 0.1306425929069519, acc: 0.9354838728904724)
[2024-11-13 05:17:50,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:50,411][root][INFO] - Training Epoch: 4/10, step 485/574 completed (loss: 0.1836613416671753, acc: 0.8947368264198303)
[2024-11-13 05:17:50,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:50,751][root][INFO] - Training Epoch: 4/10, step 486/574 completed (loss: 0.5484438538551331, acc: 0.8148148059844971)
[2024-11-13 05:17:50,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:51,073][root][INFO] - Training Epoch: 4/10, step 487/574 completed (loss: 0.5654450058937073, acc: 0.8095238208770752)
[2024-11-13 05:17:51,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:51,385][root][INFO] - Training Epoch: 4/10, step 488/574 completed (loss: 0.21702560782432556, acc: 0.9090909361839294)
[2024-11-13 05:17:51,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:51,752][root][INFO] - Training Epoch: 4/10, step 489/574 completed (loss: 1.0611530542373657, acc: 0.7538461685180664)
[2024-11-13 05:17:51,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:52,118][root][INFO] - Training Epoch: 4/10, step 490/574 completed (loss: 0.16374441981315613, acc: 0.9666666388511658)
[2024-11-13 05:17:52,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:52,441][root][INFO] - Training Epoch: 4/10, step 491/574 completed (loss: 0.22375008463859558, acc: 0.931034505367279)
[2024-11-13 05:17:52,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:52,797][root][INFO] - Training Epoch: 4/10, step 492/574 completed (loss: 0.6705851554870605, acc: 0.8039215803146362)
[2024-11-13 05:17:52,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:53,149][root][INFO] - Training Epoch: 4/10, step 493/574 completed (loss: 0.24098680913448334, acc: 0.931034505367279)
[2024-11-13 05:17:53,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:53,468][root][INFO] - Training Epoch: 4/10, step 494/574 completed (loss: 0.3961344361305237, acc: 0.8947368264198303)
[2024-11-13 05:17:53,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:53,785][root][INFO] - Training Epoch: 4/10, step 495/574 completed (loss: 0.4257288873195648, acc: 0.8947368264198303)
[2024-11-13 05:17:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:54,134][root][INFO] - Training Epoch: 4/10, step 496/574 completed (loss: 0.7704639434814453, acc: 0.8125)
[2024-11-13 05:17:54,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:54,524][root][INFO] - Training Epoch: 4/10, step 497/574 completed (loss: 0.4615972340106964, acc: 0.8426966071128845)
[2024-11-13 05:17:54,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:54,915][root][INFO] - Training Epoch: 4/10, step 498/574 completed (loss: 0.5843348503112793, acc: 0.8089887499809265)
[2024-11-13 05:17:55,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:55,256][root][INFO] - Training Epoch: 4/10, step 499/574 completed (loss: 1.2602005004882812, acc: 0.652482271194458)
[2024-11-13 05:17:55,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:55,578][root][INFO] - Training Epoch: 4/10, step 500/574 completed (loss: 0.8969284296035767, acc: 0.70652174949646)
[2024-11-13 05:17:55,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:55,937][root][INFO] - Training Epoch: 4/10, step 501/574 completed (loss: 0.08010596036911011, acc: 0.9599999785423279)
[2024-11-13 05:17:56,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:56,335][root][INFO] - Training Epoch: 4/10, step 502/574 completed (loss: 0.02782493084669113, acc: 1.0)
[2024-11-13 05:17:56,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:56,739][root][INFO] - Training Epoch: 4/10, step 503/574 completed (loss: 0.25158482789993286, acc: 0.9259259104728699)
[2024-11-13 05:17:56,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:57,092][root][INFO] - Training Epoch: 4/10, step 504/574 completed (loss: 0.10612845420837402, acc: 0.9629629850387573)
[2024-11-13 05:17:57,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:57,502][root][INFO] - Training Epoch: 4/10, step 505/574 completed (loss: 0.5498747825622559, acc: 0.849056601524353)
[2024-11-13 05:17:57,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:57,874][root][INFO] - Training Epoch: 4/10, step 506/574 completed (loss: 0.725602388381958, acc: 0.8620689511299133)
[2024-11-13 05:17:58,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:58,513][root][INFO] - Training Epoch: 4/10, step 507/574 completed (loss: 1.0633845329284668, acc: 0.7117117047309875)
[2024-11-13 05:17:58,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:58,955][root][INFO] - Training Epoch: 4/10, step 508/574 completed (loss: 0.6186633110046387, acc: 0.8450704216957092)
[2024-11-13 05:17:59,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:59,290][root][INFO] - Training Epoch: 4/10, step 509/574 completed (loss: 0.10384855419397354, acc: 0.949999988079071)
[2024-11-13 05:17:59,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:59,597][root][INFO] - Training Epoch: 4/10, step 510/574 completed (loss: 0.1377524882555008, acc: 0.9666666388511658)
[2024-11-13 05:17:59,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:17:59,904][root][INFO] - Training Epoch: 4/10, step 511/574 completed (loss: 0.15610164403915405, acc: 0.9230769276618958)
[2024-11-13 05:18:01,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:02,962][root][INFO] - Training Epoch: 4/10, step 512/574 completed (loss: 1.0539969205856323, acc: 0.7571428418159485)
[2024-11-13 05:18:03,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:03,736][root][INFO] - Training Epoch: 4/10, step 513/574 completed (loss: 0.3471453785896301, acc: 0.8809523582458496)
[2024-11-13 05:18:03,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:04,028][root][INFO] - Training Epoch: 4/10, step 514/574 completed (loss: 0.3112840950489044, acc: 0.8928571343421936)
[2024-11-13 05:18:04,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:04,368][root][INFO] - Training Epoch: 4/10, step 515/574 completed (loss: 0.050658296793699265, acc: 1.0)
[2024-11-13 05:18:04,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:05,073][root][INFO] - Training Epoch: 4/10, step 516/574 completed (loss: 0.5074901580810547, acc: 0.9027777910232544)
[2024-11-13 05:18:05,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:05,375][root][INFO] - Training Epoch: 4/10, step 517/574 completed (loss: 0.022576341405510902, acc: 1.0)
[2024-11-13 05:18:05,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:05,677][root][INFO] - Training Epoch: 4/10, step 518/574 completed (loss: 0.20193608105182648, acc: 0.9354838728904724)
[2024-11-13 05:18:05,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:05,973][root][INFO] - Training Epoch: 4/10, step 519/574 completed (loss: 0.06660185009241104, acc: 1.0)
[2024-11-13 05:18:06,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:06,275][root][INFO] - Training Epoch: 4/10, step 520/574 completed (loss: 0.37383362650871277, acc: 0.8148148059844971)
[2024-11-13 05:18:06,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:07,294][root][INFO] - Training Epoch: 4/10, step 521/574 completed (loss: 0.7642298936843872, acc: 0.7838982939720154)
[2024-11-13 05:18:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:07,637][root][INFO] - Training Epoch: 4/10, step 522/574 completed (loss: 0.44611528515815735, acc: 0.8507462739944458)
[2024-11-13 05:18:07,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:07,999][root][INFO] - Training Epoch: 4/10, step 523/574 completed (loss: 0.45454347133636475, acc: 0.8905109763145447)
[2024-11-13 05:18:08,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:08,557][root][INFO] - Training Epoch: 4/10, step 524/574 completed (loss: 0.7680220603942871, acc: 0.7900000214576721)
[2024-11-13 05:18:08,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:08,858][root][INFO] - Training Epoch: 4/10, step 525/574 completed (loss: 0.04729976877570152, acc: 1.0)
[2024-11-13 05:18:08,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:09,167][root][INFO] - Training Epoch: 4/10, step 526/574 completed (loss: 0.1753399521112442, acc: 0.942307710647583)
[2024-11-13 05:18:09,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:09,457][root][INFO] - Training Epoch: 4/10, step 527/574 completed (loss: 0.03934197500348091, acc: 1.0)
[2024-11-13 05:18:09,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:09,792][root][INFO] - Training Epoch: 4/10, step 528/574 completed (loss: 1.578603744506836, acc: 0.5245901346206665)
[2024-11-13 05:18:09,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:10,086][root][INFO] - Training Epoch: 4/10, step 529/574 completed (loss: 0.2634851038455963, acc: 0.9152542352676392)
[2024-11-13 05:18:10,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:10,401][root][INFO] - Training Epoch: 4/10, step 530/574 completed (loss: 1.2115237712860107, acc: 0.6976743936538696)
[2024-11-13 05:18:10,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:10,746][root][INFO] - Training Epoch: 4/10, step 531/574 completed (loss: 0.9122255444526672, acc: 0.75)
[2024-11-13 05:18:10,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:11,103][root][INFO] - Training Epoch: 4/10, step 532/574 completed (loss: 0.8914313912391663, acc: 0.8679245114326477)
[2024-11-13 05:18:11,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:11,432][root][INFO] - Training Epoch: 4/10, step 533/574 completed (loss: 0.6040332317352295, acc: 0.8636363744735718)
[2024-11-13 05:18:11,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:11,741][root][INFO] - Training Epoch: 4/10, step 534/574 completed (loss: 0.2700932025909424, acc: 0.9599999785423279)
[2024-11-13 05:18:11,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:12,033][root][INFO] - Training Epoch: 4/10, step 535/574 completed (loss: 0.354964941740036, acc: 0.949999988079071)
[2024-11-13 05:18:12,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:12,309][root][INFO] - Training Epoch: 4/10, step 536/574 completed (loss: 0.17239008843898773, acc: 0.9545454382896423)
[2024-11-13 05:18:12,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:12,690][root][INFO] - Training Epoch: 4/10, step 537/574 completed (loss: 0.46831610798835754, acc: 0.9076923131942749)
[2024-11-13 05:18:12,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:13,009][root][INFO] - Training Epoch: 4/10, step 538/574 completed (loss: 0.4960777759552002, acc: 0.875)
[2024-11-13 05:18:13,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:13,400][root][INFO] - Training Epoch: 4/10, step 539/574 completed (loss: 0.542625904083252, acc: 0.8125)
[2024-11-13 05:18:13,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:13,699][root][INFO] - Training Epoch: 4/10, step 540/574 completed (loss: 0.4613555669784546, acc: 0.9090909361839294)
[2024-11-13 05:18:13,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:13,992][root][INFO] - Training Epoch: 4/10, step 541/574 completed (loss: 0.21648909151554108, acc: 0.9375)
[2024-11-13 05:18:14,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:14,286][root][INFO] - Training Epoch: 4/10, step 542/574 completed (loss: 0.05856567993760109, acc: 1.0)
[2024-11-13 05:18:14,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:14,588][root][INFO] - Training Epoch: 4/10, step 543/574 completed (loss: 0.02256596088409424, acc: 1.0)
[2024-11-13 05:18:14,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:14,899][root][INFO] - Training Epoch: 4/10, step 544/574 completed (loss: 0.10043272376060486, acc: 0.9666666388511658)
[2024-11-13 05:18:14,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:15,208][root][INFO] - Training Epoch: 4/10, step 545/574 completed (loss: 0.07589294761419296, acc: 0.9756097793579102)
[2024-11-13 05:18:15,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:15,501][root][INFO] - Training Epoch: 4/10, step 546/574 completed (loss: 0.04991287738084793, acc: 1.0)
[2024-11-13 05:18:15,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:15,839][root][INFO] - Training Epoch: 4/10, step 547/574 completed (loss: 0.06916763633489609, acc: 0.9736841917037964)
[2024-11-13 05:18:15,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:16,146][root][INFO] - Training Epoch: 4/10, step 548/574 completed (loss: 0.10070425271987915, acc: 0.9354838728904724)
[2024-11-13 05:18:16,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:16,456][root][INFO] - Training Epoch: 4/10, step 549/574 completed (loss: 0.004843715578317642, acc: 1.0)
[2024-11-13 05:18:16,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:16,795][root][INFO] - Training Epoch: 4/10, step 550/574 completed (loss: 0.3665793240070343, acc: 0.9090909361839294)
[2024-11-13 05:18:16,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:17,101][root][INFO] - Training Epoch: 4/10, step 551/574 completed (loss: 0.2420380562543869, acc: 0.949999988079071)
[2024-11-13 05:18:17,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:17,409][root][INFO] - Training Epoch: 4/10, step 552/574 completed (loss: 0.13097886741161346, acc: 0.9428571462631226)
[2024-11-13 05:18:17,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:17,711][root][INFO] - Training Epoch: 4/10, step 553/574 completed (loss: 0.634345293045044, acc: 0.8394160866737366)
[2024-11-13 05:18:17,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:18,017][root][INFO] - Training Epoch: 4/10, step 554/574 completed (loss: 0.3592974841594696, acc: 0.8896551728248596)
[2024-11-13 05:18:18,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:18,316][root][INFO] - Training Epoch: 4/10, step 555/574 completed (loss: 0.4210579991340637, acc: 0.8642857074737549)
[2024-11-13 05:18:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:18,608][root][INFO] - Training Epoch: 4/10, step 556/574 completed (loss: 0.48568516969680786, acc: 0.8543046116828918)
[2024-11-13 05:18:18,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:18,925][root][INFO] - Training Epoch: 4/10, step 557/574 completed (loss: 0.1937675178050995, acc: 0.9487179517745972)
[2024-11-13 05:18:18,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:19,218][root][INFO] - Training Epoch: 4/10, step 558/574 completed (loss: 0.11168817430734634, acc: 0.9200000166893005)
[2024-11-13 05:18:19,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:19,530][root][INFO] - Training Epoch: 4/10, step 559/574 completed (loss: 0.07870504260063171, acc: 0.9615384340286255)
[2024-11-13 05:18:19,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:19,897][root][INFO] - Training Epoch: 4/10, step 560/574 completed (loss: 0.00824772845953703, acc: 1.0)
[2024-11-13 05:18:20,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:20,236][root][INFO] - Training Epoch: 4/10, step 561/574 completed (loss: 0.3359418511390686, acc: 0.9230769276618958)
[2024-11-13 05:18:20,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:20,587][root][INFO] - Training Epoch: 4/10, step 562/574 completed (loss: 0.3979838788509369, acc: 0.8888888955116272)
[2024-11-13 05:18:20,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:20,922][root][INFO] - Training Epoch: 4/10, step 563/574 completed (loss: 0.30528682470321655, acc: 0.9220778942108154)
[2024-11-13 05:18:21,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:21,241][root][INFO] - Training Epoch: 4/10, step 564/574 completed (loss: 0.3110891878604889, acc: 0.9166666865348816)
[2024-11-13 05:18:21,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:21,532][root][INFO] - Training Epoch: 4/10, step 565/574 completed (loss: 0.4124852120876312, acc: 0.8620689511299133)
[2024-11-13 05:18:22,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:22,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:22,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:23,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:23,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:24,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:24,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:24,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:25,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:25,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:25,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:26,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:26,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:26,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:27,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:27,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:28,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:29,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:29,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:29,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:30,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:30,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:30,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:31,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:31,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:31,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:32,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:32,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:33,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:33,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:33,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:34,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:34,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:34,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:35,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:35,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:36,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:36,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:36,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:37,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:37,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:37,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:38,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:38,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:38,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:39,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:39,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:39,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:40,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:40,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:40,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:41,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:41,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:41,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:42,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:42,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:42,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:43,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:43,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:43,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:44,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:44,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:45,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:45,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:45,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:46,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:46,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:47,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:47,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:48,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:48,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:48,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:48,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:49,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:49,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:49,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:50,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:50,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:50,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:51,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:51,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:51,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:52,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:52,850][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5133, device='cuda:0') eval_epoch_loss=tensor(0.9216, device='cuda:0') eval_epoch_acc=tensor(0.7691, device='cuda:0')
[2024-11-13 05:18:52,851][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:18:52,851][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:18:53,140][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_4_step_566_loss_0.9215793609619141/model.pt
[2024-11-13 05:18:53,144][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:18:53,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:53,500][root][INFO] - Training Epoch: 4/10, step 566/574 completed (loss: 0.4033794403076172, acc: 0.8928571343421936)
[2024-11-13 05:18:53,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:53,838][root][INFO] - Training Epoch: 4/10, step 567/574 completed (loss: 0.14059318602085114, acc: 0.9736841917037964)
[2024-11-13 05:18:53,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:54,207][root][INFO] - Training Epoch: 4/10, step 568/574 completed (loss: 0.01306837797164917, acc: 1.0)
[2024-11-13 05:18:54,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:54,584][root][INFO] - Training Epoch: 4/10, step 569/574 completed (loss: 0.37549835443496704, acc: 0.8823529481887817)
[2024-11-13 05:18:54,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:54,883][root][INFO] - Training Epoch: 4/10, step 570/574 completed (loss: 0.07962581515312195, acc: 0.9838709831237793)
[2024-11-13 05:18:54,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:55,196][root][INFO] - Training Epoch: 4/10, step 571/574 completed (loss: 0.4313551187515259, acc: 0.8888888955116272)
[2024-11-13 05:18:55,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:55,540][root][INFO] - Training Epoch: 4/10, step 572/574 completed (loss: 0.6801338195800781, acc: 0.8112244606018066)
[2024-11-13 05:18:55,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:55,880][root][INFO] - Training Epoch: 4/10, step 573/574 completed (loss: 0.6264240145683289, acc: 0.8176100850105286)
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - Epoch 4: train_perplexity=1.6666, train_epoch_loss=0.5108, epoch time 352.9757356401533s
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 14 GB
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 12
[2024-11-13 05:18:56,368][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:18:56,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:57,197][root][INFO] - Training Epoch: 5/10, step 0/574 completed (loss: 0.31113192439079285, acc: 0.9259259104728699)
[2024-11-13 05:18:57,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:57,435][root][INFO] - Training Epoch: 5/10, step 1/574 completed (loss: 0.14984238147735596, acc: 0.9599999785423279)
[2024-11-13 05:18:57,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:57,836][root][INFO] - Training Epoch: 5/10, step 2/574 completed (loss: 0.5218894481658936, acc: 0.7567567825317383)
[2024-11-13 05:18:57,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:58,201][root][INFO] - Training Epoch: 5/10, step 3/574 completed (loss: 0.2670309245586395, acc: 0.8947368264198303)
[2024-11-13 05:18:58,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:58,554][root][INFO] - Training Epoch: 5/10, step 4/574 completed (loss: 0.15650615096092224, acc: 0.9459459185600281)
[2024-11-13 05:18:58,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:58,895][root][INFO] - Training Epoch: 5/10, step 5/574 completed (loss: 0.08718021214008331, acc: 0.9642857313156128)
[2024-11-13 05:18:58,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:59,213][root][INFO] - Training Epoch: 5/10, step 6/574 completed (loss: 0.5737300515174866, acc: 0.8367347121238708)
[2024-11-13 05:18:59,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:59,471][root][INFO] - Training Epoch: 5/10, step 7/574 completed (loss: 0.23699621856212616, acc: 0.9333333373069763)
[2024-11-13 05:18:59,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:18:59,802][root][INFO] - Training Epoch: 5/10, step 8/574 completed (loss: 0.03947649896144867, acc: 1.0)
[2024-11-13 05:18:59,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:00,104][root][INFO] - Training Epoch: 5/10, step 9/574 completed (loss: 0.04570488631725311, acc: 1.0)
[2024-11-13 05:19:00,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:00,418][root][INFO] - Training Epoch: 5/10, step 10/574 completed (loss: 0.03820212557911873, acc: 1.0)
[2024-11-13 05:19:00,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:00,727][root][INFO] - Training Epoch: 5/10, step 11/574 completed (loss: 0.12839095294475555, acc: 0.9230769276618958)
[2024-11-13 05:19:00,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:01,042][root][INFO] - Training Epoch: 5/10, step 12/574 completed (loss: 0.11145126074552536, acc: 0.939393937587738)
[2024-11-13 05:19:01,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:01,374][root][INFO] - Training Epoch: 5/10, step 13/574 completed (loss: 0.1920030415058136, acc: 0.9130434989929199)
[2024-11-13 05:19:01,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:01,761][root][INFO] - Training Epoch: 5/10, step 14/574 completed (loss: 0.24294334650039673, acc: 0.9215686321258545)
[2024-11-13 05:19:01,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:02,114][root][INFO] - Training Epoch: 5/10, step 15/574 completed (loss: 0.3554726839065552, acc: 0.918367326259613)
[2024-11-13 05:19:02,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:02,472][root][INFO] - Training Epoch: 5/10, step 16/574 completed (loss: 0.15515488386154175, acc: 0.9473684430122375)
[2024-11-13 05:19:02,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:02,830][root][INFO] - Training Epoch: 5/10, step 17/574 completed (loss: 0.020379582419991493, acc: 1.0)
[2024-11-13 05:19:02,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:03,159][root][INFO] - Training Epoch: 5/10, step 18/574 completed (loss: 0.4861425757408142, acc: 0.8333333134651184)
[2024-11-13 05:19:03,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:03,486][root][INFO] - Training Epoch: 5/10, step 19/574 completed (loss: 0.046650201082229614, acc: 1.0)
[2024-11-13 05:19:03,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:03,786][root][INFO] - Training Epoch: 5/10, step 20/574 completed (loss: 0.22937795519828796, acc: 0.9615384340286255)
[2024-11-13 05:19:03,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:04,097][root][INFO] - Training Epoch: 5/10, step 21/574 completed (loss: 0.21378669142723083, acc: 0.8965517282485962)
[2024-11-13 05:19:04,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:04,413][root][INFO] - Training Epoch: 5/10, step 22/574 completed (loss: 0.5297081470489502, acc: 0.9200000166893005)
[2024-11-13 05:19:04,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:04,798][root][INFO] - Training Epoch: 5/10, step 23/574 completed (loss: 0.11876271665096283, acc: 0.9523809552192688)
[2024-11-13 05:19:04,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:05,136][root][INFO] - Training Epoch: 5/10, step 24/574 completed (loss: 0.036506615579128265, acc: 1.0)
[2024-11-13 05:19:05,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:05,558][root][INFO] - Training Epoch: 5/10, step 25/574 completed (loss: 0.6999382972717285, acc: 0.8301886916160583)
[2024-11-13 05:19:05,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:05,915][root][INFO] - Training Epoch: 5/10, step 26/574 completed (loss: 0.8934979438781738, acc: 0.7397260069847107)
[2024-11-13 05:19:06,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:07,437][root][INFO] - Training Epoch: 5/10, step 27/574 completed (loss: 1.2970319986343384, acc: 0.6640316247940063)
[2024-11-13 05:19:07,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:07,757][root][INFO] - Training Epoch: 5/10, step 28/574 completed (loss: 0.36679452657699585, acc: 0.9069767594337463)
[2024-11-13 05:19:07,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:08,133][root][INFO] - Training Epoch: 5/10, step 29/574 completed (loss: 0.6141393780708313, acc: 0.8433734774589539)
[2024-11-13 05:19:08,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:08,498][root][INFO] - Training Epoch: 5/10, step 30/574 completed (loss: 0.6733843088150024, acc: 0.8271604776382446)
[2024-11-13 05:19:08,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:08,802][root][INFO] - Training Epoch: 5/10, step 31/574 completed (loss: 0.15109598636627197, acc: 0.9642857313156128)
[2024-11-13 05:19:08,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:09,104][root][INFO] - Training Epoch: 5/10, step 32/574 completed (loss: 0.16543328762054443, acc: 0.9259259104728699)
[2024-11-13 05:19:09,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:09,407][root][INFO] - Training Epoch: 5/10, step 33/574 completed (loss: 0.11684012413024902, acc: 0.95652174949646)
[2024-11-13 05:19:09,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:09,738][root][INFO] - Training Epoch: 5/10, step 34/574 completed (loss: 0.5094361901283264, acc: 0.8571428656578064)
[2024-11-13 05:19:09,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:10,114][root][INFO] - Training Epoch: 5/10, step 35/574 completed (loss: 0.2712768614292145, acc: 0.9016393423080444)
[2024-11-13 05:19:10,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:10,521][root][INFO] - Training Epoch: 5/10, step 36/574 completed (loss: 0.36367812752723694, acc: 0.8730158805847168)
[2024-11-13 05:19:10,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:10,877][root][INFO] - Training Epoch: 5/10, step 37/574 completed (loss: 0.362430214881897, acc: 0.9152542352676392)
[2024-11-13 05:19:10,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:11,226][root][INFO] - Training Epoch: 5/10, step 38/574 completed (loss: 0.26028165221214294, acc: 0.931034505367279)
[2024-11-13 05:19:11,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:11,569][root][INFO] - Training Epoch: 5/10, step 39/574 completed (loss: 0.13849875330924988, acc: 0.9523809552192688)
[2024-11-13 05:19:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:11,861][root][INFO] - Training Epoch: 5/10, step 40/574 completed (loss: 0.2982290983200073, acc: 0.8846153616905212)
[2024-11-13 05:19:11,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:12,237][root][INFO] - Training Epoch: 5/10, step 41/574 completed (loss: 0.2496756762266159, acc: 0.9324324131011963)
[2024-11-13 05:19:12,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:12,590][root][INFO] - Training Epoch: 5/10, step 42/574 completed (loss: 0.6249800324440002, acc: 0.8615384697914124)
[2024-11-13 05:19:12,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:12,997][root][INFO] - Training Epoch: 5/10, step 43/574 completed (loss: 0.4597039222717285, acc: 0.8787878751754761)
[2024-11-13 05:19:13,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:13,409][root][INFO] - Training Epoch: 5/10, step 44/574 completed (loss: 0.3967800438404083, acc: 0.8556700944900513)
[2024-11-13 05:19:13,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:13,806][root][INFO] - Training Epoch: 5/10, step 45/574 completed (loss: 0.5692965388298035, acc: 0.8235294222831726)
[2024-11-13 05:19:13,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:14,121][root][INFO] - Training Epoch: 5/10, step 46/574 completed (loss: 0.1732175052165985, acc: 0.9230769276618958)
[2024-11-13 05:19:14,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:14,433][root][INFO] - Training Epoch: 5/10, step 47/574 completed (loss: 0.13406817615032196, acc: 0.9259259104728699)
[2024-11-13 05:19:14,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:14,703][root][INFO] - Training Epoch: 5/10, step 48/574 completed (loss: 0.23338019847869873, acc: 0.9285714030265808)
[2024-11-13 05:19:14,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:15,002][root][INFO] - Training Epoch: 5/10, step 49/574 completed (loss: 0.17825981974601746, acc: 0.9444444179534912)
[2024-11-13 05:19:15,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:15,330][root][INFO] - Training Epoch: 5/10, step 50/574 completed (loss: 0.7129946947097778, acc: 0.8070175647735596)
[2024-11-13 05:19:15,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:15,678][root][INFO] - Training Epoch: 5/10, step 51/574 completed (loss: 0.5874661803245544, acc: 0.8253968358039856)
[2024-11-13 05:19:15,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:15,997][root][INFO] - Training Epoch: 5/10, step 52/574 completed (loss: 0.8868404626846313, acc: 0.7746478915214539)
[2024-11-13 05:19:16,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:16,464][root][INFO] - Training Epoch: 5/10, step 53/574 completed (loss: 1.3630164861679077, acc: 0.653333306312561)
[2024-11-13 05:19:16,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:16,801][root][INFO] - Training Epoch: 5/10, step 54/574 completed (loss: 0.6566663980484009, acc: 0.8108108043670654)
[2024-11-13 05:19:16,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:17,117][root][INFO] - Training Epoch: 5/10, step 55/574 completed (loss: 0.10349206626415253, acc: 0.9615384340286255)
[2024-11-13 05:19:18,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:20,407][root][INFO] - Training Epoch: 5/10, step 56/574 completed (loss: 1.1618632078170776, acc: 0.6484641432762146)
[2024-11-13 05:19:20,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:21,792][root][INFO] - Training Epoch: 5/10, step 57/574 completed (loss: 1.2848279476165771, acc: 0.6274510025978088)
[2024-11-13 05:19:21,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:22,459][root][INFO] - Training Epoch: 5/10, step 58/574 completed (loss: 0.7932296991348267, acc: 0.7784090638160706)
[2024-11-13 05:19:22,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:23,028][root][INFO] - Training Epoch: 5/10, step 59/574 completed (loss: 0.47411561012268066, acc: 0.8235294222831726)
[2024-11-13 05:19:23,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:23,593][root][INFO] - Training Epoch: 5/10, step 60/574 completed (loss: 0.8621881008148193, acc: 0.760869562625885)
[2024-11-13 05:19:23,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:24,007][root][INFO] - Training Epoch: 5/10, step 61/574 completed (loss: 0.6921803951263428, acc: 0.8374999761581421)
[2024-11-13 05:19:24,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:24,315][root][INFO] - Training Epoch: 5/10, step 62/574 completed (loss: 0.21851791441440582, acc: 0.9411764740943909)
[2024-11-13 05:19:24,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:24,648][root][INFO] - Training Epoch: 5/10, step 63/574 completed (loss: 0.11758511513471603, acc: 0.9444444179534912)
[2024-11-13 05:19:24,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:24,993][root][INFO] - Training Epoch: 5/10, step 64/574 completed (loss: 0.09349824488162994, acc: 0.984375)
[2024-11-13 05:19:25,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:25,306][root][INFO] - Training Epoch: 5/10, step 65/574 completed (loss: 0.06133919581770897, acc: 1.0)
[2024-11-13 05:19:25,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:25,662][root][INFO] - Training Epoch: 5/10, step 66/574 completed (loss: 0.4903176724910736, acc: 0.875)
[2024-11-13 05:19:25,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:25,995][root][INFO] - Training Epoch: 5/10, step 67/574 completed (loss: 0.35640794038772583, acc: 0.8999999761581421)
[2024-11-13 05:19:26,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:26,321][root][INFO] - Training Epoch: 5/10, step 68/574 completed (loss: 0.2737998962402344, acc: 0.9200000166893005)
[2024-11-13 05:19:26,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:26,655][root][INFO] - Training Epoch: 5/10, step 69/574 completed (loss: 0.3402419090270996, acc: 0.9444444179534912)
[2024-11-13 05:19:26,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:26,983][root][INFO] - Training Epoch: 5/10, step 70/574 completed (loss: 0.44840526580810547, acc: 0.8181818127632141)
[2024-11-13 05:19:27,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:27,298][root][INFO] - Training Epoch: 5/10, step 71/574 completed (loss: 0.949147641658783, acc: 0.6764705777168274)
[2024-11-13 05:19:27,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:27,592][root][INFO] - Training Epoch: 5/10, step 72/574 completed (loss: 0.7742939591407776, acc: 0.7936508059501648)
[2024-11-13 05:19:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:27,916][root][INFO] - Training Epoch: 5/10, step 73/574 completed (loss: 1.3397207260131836, acc: 0.620512843132019)
[2024-11-13 05:19:27,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:28,217][root][INFO] - Training Epoch: 5/10, step 74/574 completed (loss: 0.9406818747520447, acc: 0.6938775777816772)
[2024-11-13 05:19:28,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:28,549][root][INFO] - Training Epoch: 5/10, step 75/574 completed (loss: 1.0729690790176392, acc: 0.7089552283287048)
[2024-11-13 05:19:28,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:28,943][root][INFO] - Training Epoch: 5/10, step 76/574 completed (loss: 1.385770559310913, acc: 0.6167883276939392)
[2024-11-13 05:19:29,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:29,248][root][INFO] - Training Epoch: 5/10, step 77/574 completed (loss: 0.026614824309945107, acc: 1.0)
[2024-11-13 05:19:29,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:29,557][root][INFO] - Training Epoch: 5/10, step 78/574 completed (loss: 0.04750018194317818, acc: 1.0)
[2024-11-13 05:19:29,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:29,871][root][INFO] - Training Epoch: 5/10, step 79/574 completed (loss: 0.26058757305145264, acc: 0.939393937587738)
[2024-11-13 05:19:29,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:30,190][root][INFO] - Training Epoch: 5/10, step 80/574 completed (loss: 0.037391915917396545, acc: 1.0)
[2024-11-13 05:19:30,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:30,564][root][INFO] - Training Epoch: 5/10, step 81/574 completed (loss: 0.4164043962955475, acc: 0.8653846383094788)
[2024-11-13 05:19:30,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:30,893][root][INFO] - Training Epoch: 5/10, step 82/574 completed (loss: 0.4769807457923889, acc: 0.8846153616905212)
[2024-11-13 05:19:31,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:31,259][root][INFO] - Training Epoch: 5/10, step 83/574 completed (loss: 0.2619737982749939, acc: 0.875)
[2024-11-13 05:19:31,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:31,603][root][INFO] - Training Epoch: 5/10, step 84/574 completed (loss: 0.440259724855423, acc: 0.8405796885490417)
[2024-11-13 05:19:31,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:31,976][root][INFO] - Training Epoch: 5/10, step 85/574 completed (loss: 0.36793971061706543, acc: 0.8600000143051147)
[2024-11-13 05:19:32,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:32,371][root][INFO] - Training Epoch: 5/10, step 86/574 completed (loss: 0.18229196965694427, acc: 0.95652174949646)
[2024-11-13 05:19:32,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:32,851][root][INFO] - Training Epoch: 5/10, step 87/574 completed (loss: 0.5678104162216187, acc: 0.8199999928474426)
[2024-11-13 05:19:32,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:33,176][root][INFO] - Training Epoch: 5/10, step 88/574 completed (loss: 0.881284236907959, acc: 0.7766990065574646)
[2024-11-13 05:19:33,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:34,372][root][INFO] - Training Epoch: 5/10, step 89/574 completed (loss: 0.878871500492096, acc: 0.7572815418243408)
[2024-11-13 05:19:34,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:35,214][root][INFO] - Training Epoch: 5/10, step 90/574 completed (loss: 1.0720617771148682, acc: 0.7150537371635437)
[2024-11-13 05:19:35,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:36,068][root][INFO] - Training Epoch: 5/10, step 91/574 completed (loss: 0.9499275088310242, acc: 0.75)
[2024-11-13 05:19:36,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:36,852][root][INFO] - Training Epoch: 5/10, step 92/574 completed (loss: 0.6745566725730896, acc: 0.8315789699554443)
[2024-11-13 05:19:37,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:37,889][root][INFO] - Training Epoch: 5/10, step 93/574 completed (loss: 1.1645492315292358, acc: 0.7029703259468079)
[2024-11-13 05:19:37,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:38,228][root][INFO] - Training Epoch: 5/10, step 94/574 completed (loss: 0.8365681767463684, acc: 0.7903226017951965)
[2024-11-13 05:19:38,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:38,623][root][INFO] - Training Epoch: 5/10, step 95/574 completed (loss: 0.4057967960834503, acc: 0.8840579986572266)
[2024-11-13 05:19:38,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:38,975][root][INFO] - Training Epoch: 5/10, step 96/574 completed (loss: 1.168351173400879, acc: 0.6386554837226868)
[2024-11-13 05:19:39,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:39,363][root][INFO] - Training Epoch: 5/10, step 97/574 completed (loss: 0.9272072315216064, acc: 0.7307692170143127)
[2024-11-13 05:19:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:39,792][root][INFO] - Training Epoch: 5/10, step 98/574 completed (loss: 1.2145555019378662, acc: 0.6277372241020203)
[2024-11-13 05:19:39,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:40,171][root][INFO] - Training Epoch: 5/10, step 99/574 completed (loss: 0.9318093061447144, acc: 0.7164179086685181)
[2024-11-13 05:19:40,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:40,550][root][INFO] - Training Epoch: 5/10, step 100/574 completed (loss: 0.32544398307800293, acc: 0.8999999761581421)
[2024-11-13 05:19:40,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:40,912][root][INFO] - Training Epoch: 5/10, step 101/574 completed (loss: 0.020821010693907738, acc: 1.0)
[2024-11-13 05:19:41,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:41,299][root][INFO] - Training Epoch: 5/10, step 102/574 completed (loss: 0.01995125226676464, acc: 1.0)
[2024-11-13 05:19:41,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:41,644][root][INFO] - Training Epoch: 5/10, step 103/574 completed (loss: 0.03002494014799595, acc: 1.0)
[2024-11-13 05:19:41,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:42,016][root][INFO] - Training Epoch: 5/10, step 104/574 completed (loss: 0.4573333263397217, acc: 0.8620689511299133)
[2024-11-13 05:19:42,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:42,389][root][INFO] - Training Epoch: 5/10, step 105/574 completed (loss: 0.07762371003627777, acc: 0.9767441749572754)
[2024-11-13 05:19:42,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:42,750][root][INFO] - Training Epoch: 5/10, step 106/574 completed (loss: 0.2963373064994812, acc: 0.8799999952316284)
[2024-11-13 05:19:42,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:43,135][root][INFO] - Training Epoch: 5/10, step 107/574 completed (loss: 0.0805361196398735, acc: 0.9411764740943909)
[2024-11-13 05:19:43,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:43,498][root][INFO] - Training Epoch: 5/10, step 108/574 completed (loss: 0.07942231744527817, acc: 0.9615384340286255)
[2024-11-13 05:19:43,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:43,887][root][INFO] - Training Epoch: 5/10, step 109/574 completed (loss: 0.09820352494716644, acc: 0.976190447807312)
[2024-11-13 05:19:43,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:44,268][root][INFO] - Training Epoch: 5/10, step 110/574 completed (loss: 0.15809223055839539, acc: 0.9230769276618958)
[2024-11-13 05:19:44,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:44,664][root][INFO] - Training Epoch: 5/10, step 111/574 completed (loss: 0.46703362464904785, acc: 0.8421052694320679)
[2024-11-13 05:19:44,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:45,049][root][INFO] - Training Epoch: 5/10, step 112/574 completed (loss: 0.7028732895851135, acc: 0.8070175647735596)
[2024-11-13 05:19:45,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:45,395][root][INFO] - Training Epoch: 5/10, step 113/574 completed (loss: 0.3410094678401947, acc: 0.9230769276618958)
[2024-11-13 05:19:45,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:45,789][root][INFO] - Training Epoch: 5/10, step 114/574 completed (loss: 0.2853040397167206, acc: 0.8979591727256775)
[2024-11-13 05:19:45,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:46,143][root][INFO] - Training Epoch: 5/10, step 115/574 completed (loss: 0.014156782999634743, acc: 1.0)
[2024-11-13 05:19:46,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:46,506][root][INFO] - Training Epoch: 5/10, step 116/574 completed (loss: 0.6533347964286804, acc: 0.8888888955116272)
[2024-11-13 05:19:46,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:46,870][root][INFO] - Training Epoch: 5/10, step 117/574 completed (loss: 0.5149610638618469, acc: 0.8455284833908081)
[2024-11-13 05:19:46,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:47,277][root][INFO] - Training Epoch: 5/10, step 118/574 completed (loss: 0.2677645981311798, acc: 0.9193548560142517)
[2024-11-13 05:19:47,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:48,243][root][INFO] - Training Epoch: 5/10, step 119/574 completed (loss: 0.9152196049690247, acc: 0.7186312079429626)
[2024-11-13 05:19:48,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:48,595][root][INFO] - Training Epoch: 5/10, step 120/574 completed (loss: 0.2268848717212677, acc: 0.9066666960716248)
[2024-11-13 05:19:48,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:49,014][root][INFO] - Training Epoch: 5/10, step 121/574 completed (loss: 0.334470272064209, acc: 0.9038461446762085)
[2024-11-13 05:19:49,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:49,391][root][INFO] - Training Epoch: 5/10, step 122/574 completed (loss: 0.0907694399356842, acc: 0.9583333134651184)
[2024-11-13 05:19:49,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:49,749][root][INFO] - Training Epoch: 5/10, step 123/574 completed (loss: 0.15843148529529572, acc: 0.9473684430122375)
[2024-11-13 05:19:49,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:50,086][root][INFO] - Training Epoch: 5/10, step 124/574 completed (loss: 0.9933327436447144, acc: 0.6871165633201599)
[2024-11-13 05:19:50,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:50,440][root][INFO] - Training Epoch: 5/10, step 125/574 completed (loss: 1.0366523265838623, acc: 0.7152777910232544)
[2024-11-13 05:19:50,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:50,779][root][INFO] - Training Epoch: 5/10, step 126/574 completed (loss: 1.038636326789856, acc: 0.6916666626930237)
[2024-11-13 05:19:50,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:51,129][root][INFO] - Training Epoch: 5/10, step 127/574 completed (loss: 0.9331026673316956, acc: 0.761904776096344)
[2024-11-13 05:19:51,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:51,477][root][INFO] - Training Epoch: 5/10, step 128/574 completed (loss: 0.831515908241272, acc: 0.7538461685180664)
[2024-11-13 05:19:51,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:51,887][root][INFO] - Training Epoch: 5/10, step 129/574 completed (loss: 0.8636667132377625, acc: 0.7573529481887817)
[2024-11-13 05:19:51,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:52,255][root][INFO] - Training Epoch: 5/10, step 130/574 completed (loss: 0.3481469750404358, acc: 0.8846153616905212)
[2024-11-13 05:19:52,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:52,600][root][INFO] - Training Epoch: 5/10, step 131/574 completed (loss: 0.21183328330516815, acc: 0.95652174949646)
[2024-11-13 05:19:52,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:52,918][root][INFO] - Training Epoch: 5/10, step 132/574 completed (loss: 0.31847426295280457, acc: 0.875)
[2024-11-13 05:19:52,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:53,210][root][INFO] - Training Epoch: 5/10, step 133/574 completed (loss: 0.27304473519325256, acc: 0.95652174949646)
[2024-11-13 05:19:53,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:53,538][root][INFO] - Training Epoch: 5/10, step 134/574 completed (loss: 0.5642569661140442, acc: 0.8285714387893677)
[2024-11-13 05:19:54,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:54,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:55,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:55,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:55,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:56,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:56,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:56,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:57,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:57,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:57,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:58,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:58,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:59,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:59,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:19:59,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:00,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:00,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:00,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:01,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:01,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:02,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:02,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:02,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:03,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:03,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:03,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:04,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:05,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:05,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:05,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:05,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:06,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:06,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:07,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:07,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:07,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:08,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:08,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:08,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:08,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:09,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:09,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:09,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:10,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:10,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:11,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:11,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:11,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:12,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:12,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:12,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:13,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:13,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:14,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:14,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:14,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:15,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:16,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:16,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:16,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:17,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:17,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:17,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:18,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:18,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:19,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:19,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:19,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:20,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:20,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:20,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:21,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:21,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:21,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:22,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:22,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:22,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:22,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:23,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:23,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:23,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:24,783][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2579, device='cuda:0') eval_epoch_loss=tensor(0.8144, device='cuda:0') eval_epoch_acc=tensor(0.7923, device='cuda:0')
[2024-11-13 05:20:24,784][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:20:24,785][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:20:25,070][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_5_step_135_loss_0.8144344687461853/model.pt
[2024-11-13 05:20:25,074][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:20:25,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:25,408][root][INFO] - Training Epoch: 5/10, step 135/574 completed (loss: 0.18699638545513153, acc: 0.9615384340286255)
[2024-11-13 05:20:25,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:25,708][root][INFO] - Training Epoch: 5/10, step 136/574 completed (loss: 0.2885654866695404, acc: 0.9047619104385376)
[2024-11-13 05:20:25,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:26,063][root][INFO] - Training Epoch: 5/10, step 137/574 completed (loss: 0.5918395519256592, acc: 0.800000011920929)
[2024-11-13 05:20:26,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:26,371][root][INFO] - Training Epoch: 5/10, step 138/574 completed (loss: 0.2455279678106308, acc: 0.9130434989929199)
[2024-11-13 05:20:26,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:26,737][root][INFO] - Training Epoch: 5/10, step 139/574 completed (loss: 0.2354898750782013, acc: 0.9523809552192688)
[2024-11-13 05:20:26,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:27,101][root][INFO] - Training Epoch: 5/10, step 140/574 completed (loss: 0.10895930975675583, acc: 0.9615384340286255)
[2024-11-13 05:20:27,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:27,436][root][INFO] - Training Epoch: 5/10, step 141/574 completed (loss: 0.41592496633529663, acc: 0.9032257795333862)
[2024-11-13 05:20:27,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:27,793][root][INFO] - Training Epoch: 5/10, step 142/574 completed (loss: 0.6099566221237183, acc: 0.8108108043670654)
[2024-11-13 05:20:27,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:28,328][root][INFO] - Training Epoch: 5/10, step 143/574 completed (loss: 0.9032739400863647, acc: 0.7280701994895935)
[2024-11-13 05:20:28,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:28,725][root][INFO] - Training Epoch: 5/10, step 144/574 completed (loss: 1.0044069290161133, acc: 0.753731369972229)
[2024-11-13 05:20:28,882][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:29,132][root][INFO] - Training Epoch: 5/10, step 145/574 completed (loss: 0.6214005351066589, acc: 0.8469387888908386)
[2024-11-13 05:20:29,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:29,572][root][INFO] - Training Epoch: 5/10, step 146/574 completed (loss: 1.0845059156417847, acc: 0.7127659320831299)
[2024-11-13 05:20:29,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:29,905][root][INFO] - Training Epoch: 5/10, step 147/574 completed (loss: 0.5340933203697205, acc: 0.8142856955528259)
[2024-11-13 05:20:30,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:30,285][root][INFO] - Training Epoch: 5/10, step 148/574 completed (loss: 0.49518880248069763, acc: 0.75)
[2024-11-13 05:20:30,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:30,655][root][INFO] - Training Epoch: 5/10, step 149/574 completed (loss: 0.5087276697158813, acc: 0.8695651888847351)
[2024-11-13 05:20:30,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:31,041][root][INFO] - Training Epoch: 5/10, step 150/574 completed (loss: 0.34516236186027527, acc: 0.8275862336158752)
[2024-11-13 05:20:31,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:31,443][root][INFO] - Training Epoch: 5/10, step 151/574 completed (loss: 0.6524853706359863, acc: 0.760869562625885)
[2024-11-13 05:20:31,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:31,821][root][INFO] - Training Epoch: 5/10, step 152/574 completed (loss: 0.6714966297149658, acc: 0.8305084705352783)
[2024-11-13 05:20:31,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:32,193][root][INFO] - Training Epoch: 5/10, step 153/574 completed (loss: 0.6351897120475769, acc: 0.8245614171028137)
[2024-11-13 05:20:32,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:32,564][root][INFO] - Training Epoch: 5/10, step 154/574 completed (loss: 0.5998232364654541, acc: 0.8243243098258972)
[2024-11-13 05:20:32,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:32,916][root][INFO] - Training Epoch: 5/10, step 155/574 completed (loss: 0.10489044338464737, acc: 0.9642857313156128)
[2024-11-13 05:20:33,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:33,267][root][INFO] - Training Epoch: 5/10, step 156/574 completed (loss: 0.15494535863399506, acc: 1.0)
[2024-11-13 05:20:33,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:33,611][root][INFO] - Training Epoch: 5/10, step 157/574 completed (loss: 0.9855669736862183, acc: 0.6842105388641357)
[2024-11-13 05:20:34,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:35,403][root][INFO] - Training Epoch: 5/10, step 158/574 completed (loss: 0.7218095660209656, acc: 0.837837815284729)
[2024-11-13 05:20:35,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:35,769][root][INFO] - Training Epoch: 5/10, step 159/574 completed (loss: 1.1098132133483887, acc: 0.6481481194496155)
[2024-11-13 05:20:35,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:36,160][root][INFO] - Training Epoch: 5/10, step 160/574 completed (loss: 0.9870002865791321, acc: 0.7325581312179565)
[2024-11-13 05:20:36,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:36,746][root][INFO] - Training Epoch: 5/10, step 161/574 completed (loss: 1.0366512537002563, acc: 0.6941176652908325)
[2024-11-13 05:20:36,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:37,302][root][INFO] - Training Epoch: 5/10, step 162/574 completed (loss: 1.0977001190185547, acc: 0.7191011309623718)
[2024-11-13 05:20:37,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:37,615][root][INFO] - Training Epoch: 5/10, step 163/574 completed (loss: 0.31246837973594666, acc: 0.9090909361839294)
[2024-11-13 05:20:37,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:37,920][root][INFO] - Training Epoch: 5/10, step 164/574 completed (loss: 0.33290553092956543, acc: 0.8571428656578064)
[2024-11-13 05:20:38,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:38,248][root][INFO] - Training Epoch: 5/10, step 165/574 completed (loss: 0.6775588989257812, acc: 0.8275862336158752)
[2024-11-13 05:20:38,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:38,633][root][INFO] - Training Epoch: 5/10, step 166/574 completed (loss: 0.28102967143058777, acc: 0.8979591727256775)
[2024-11-13 05:20:38,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:38,991][root][INFO] - Training Epoch: 5/10, step 167/574 completed (loss: 0.22255605459213257, acc: 0.8799999952316284)
[2024-11-13 05:20:39,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:39,415][root][INFO] - Training Epoch: 5/10, step 168/574 completed (loss: 0.5205405354499817, acc: 0.8611111044883728)
[2024-11-13 05:20:39,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:39,730][root][INFO] - Training Epoch: 5/10, step 169/574 completed (loss: 0.966727077960968, acc: 0.7254902124404907)
[2024-11-13 05:20:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:40,764][root][INFO] - Training Epoch: 5/10, step 170/574 completed (loss: 0.9363850355148315, acc: 0.7739726305007935)
[2024-11-13 05:20:40,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:41,082][root][INFO] - Training Epoch: 5/10, step 171/574 completed (loss: 0.13514386117458344, acc: 0.9583333134651184)
[2024-11-13 05:20:41,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:41,430][root][INFO] - Training Epoch: 5/10, step 172/574 completed (loss: 0.30052703619003296, acc: 0.8888888955116272)
[2024-11-13 05:20:41,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:41,739][root][INFO] - Training Epoch: 5/10, step 173/574 completed (loss: 0.2699414789676666, acc: 0.8571428656578064)
[2024-11-13 05:20:41,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:42,283][root][INFO] - Training Epoch: 5/10, step 174/574 completed (loss: 0.9371698498725891, acc: 0.769911527633667)
[2024-11-13 05:20:42,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:42,689][root][INFO] - Training Epoch: 5/10, step 175/574 completed (loss: 0.6498171091079712, acc: 0.8260869383811951)
[2024-11-13 05:20:42,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:43,122][root][INFO] - Training Epoch: 5/10, step 176/574 completed (loss: 0.4444955587387085, acc: 0.8522727489471436)
[2024-11-13 05:20:43,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:44,042][root][INFO] - Training Epoch: 5/10, step 177/574 completed (loss: 1.177847146987915, acc: 0.6717557311058044)
[2024-11-13 05:20:44,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:44,710][root][INFO] - Training Epoch: 5/10, step 178/574 completed (loss: 0.9646767973899841, acc: 0.7555555701255798)
[2024-11-13 05:20:44,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:45,087][root][INFO] - Training Epoch: 5/10, step 179/574 completed (loss: 0.34103816747665405, acc: 0.868852436542511)
[2024-11-13 05:20:45,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:45,446][root][INFO] - Training Epoch: 5/10, step 180/574 completed (loss: 0.021553844213485718, acc: 1.0)
[2024-11-13 05:20:45,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:45,781][root][INFO] - Training Epoch: 5/10, step 181/574 completed (loss: 0.12826412916183472, acc: 0.9200000166893005)
[2024-11-13 05:20:45,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:46,161][root][INFO] - Training Epoch: 5/10, step 182/574 completed (loss: 0.08612871915102005, acc: 0.9642857313156128)
[2024-11-13 05:20:46,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:46,492][root][INFO] - Training Epoch: 5/10, step 183/574 completed (loss: 0.1628911942243576, acc: 0.9756097793579102)
[2024-11-13 05:20:46,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:46,891][root][INFO] - Training Epoch: 5/10, step 184/574 completed (loss: 0.7153649926185608, acc: 0.8277945518493652)
[2024-11-13 05:20:47,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:47,296][root][INFO] - Training Epoch: 5/10, step 185/574 completed (loss: 0.7391908168792725, acc: 0.789625346660614)
[2024-11-13 05:20:47,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:47,781][root][INFO] - Training Epoch: 5/10, step 186/574 completed (loss: 0.7541545033454895, acc: 0.7593749761581421)
[2024-11-13 05:20:47,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:48,307][root][INFO] - Training Epoch: 5/10, step 187/574 completed (loss: 0.8437109589576721, acc: 0.7598499059677124)
[2024-11-13 05:20:48,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:48,696][root][INFO] - Training Epoch: 5/10, step 188/574 completed (loss: 0.7105366587638855, acc: 0.7793594598770142)
[2024-11-13 05:20:48,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:49,040][root][INFO] - Training Epoch: 5/10, step 189/574 completed (loss: 0.28748422861099243, acc: 0.9599999785423279)
[2024-11-13 05:20:49,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:49,601][root][INFO] - Training Epoch: 5/10, step 190/574 completed (loss: 0.8063380122184753, acc: 0.7441860437393188)
[2024-11-13 05:20:49,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:50,400][root][INFO] - Training Epoch: 5/10, step 191/574 completed (loss: 1.0133217573165894, acc: 0.6428571343421936)
[2024-11-13 05:20:50,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:51,316][root][INFO] - Training Epoch: 5/10, step 192/574 completed (loss: 0.9969971179962158, acc: 0.689393937587738)
[2024-11-13 05:20:51,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:52,067][root][INFO] - Training Epoch: 5/10, step 193/574 completed (loss: 0.49412500858306885, acc: 0.8588235378265381)
[2024-11-13 05:20:52,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:53,151][root][INFO] - Training Epoch: 5/10, step 194/574 completed (loss: 0.9159096479415894, acc: 0.709876537322998)
[2024-11-13 05:20:53,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:54,112][root][INFO] - Training Epoch: 5/10, step 195/574 completed (loss: 0.4605030417442322, acc: 0.8387096524238586)
[2024-11-13 05:20:54,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:54,401][root][INFO] - Training Epoch: 5/10, step 196/574 completed (loss: 0.06405921280384064, acc: 0.9642857313156128)
[2024-11-13 05:20:54,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:54,698][root][INFO] - Training Epoch: 5/10, step 197/574 completed (loss: 0.4571840167045593, acc: 0.8999999761581421)
[2024-11-13 05:20:54,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:55,007][root][INFO] - Training Epoch: 5/10, step 198/574 completed (loss: 0.5752893090248108, acc: 0.779411792755127)
[2024-11-13 05:20:55,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:55,323][root][INFO] - Training Epoch: 5/10, step 199/574 completed (loss: 0.7923723459243774, acc: 0.7573529481887817)
[2024-11-13 05:20:55,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:55,696][root][INFO] - Training Epoch: 5/10, step 200/574 completed (loss: 0.7346528172492981, acc: 0.7966101765632629)
[2024-11-13 05:20:55,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:56,002][root][INFO] - Training Epoch: 5/10, step 201/574 completed (loss: 0.822361409664154, acc: 0.7761194109916687)
[2024-11-13 05:20:56,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:56,348][root][INFO] - Training Epoch: 5/10, step 202/574 completed (loss: 0.721564531326294, acc: 0.7669903039932251)
[2024-11-13 05:20:56,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:56,668][root][INFO] - Training Epoch: 5/10, step 203/574 completed (loss: 0.5427749156951904, acc: 0.8253968358039856)
[2024-11-13 05:20:56,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:57,014][root][INFO] - Training Epoch: 5/10, step 204/574 completed (loss: 0.2223043292760849, acc: 0.9450549483299255)
[2024-11-13 05:20:57,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:57,358][root][INFO] - Training Epoch: 5/10, step 205/574 completed (loss: 0.3604806363582611, acc: 0.878923773765564)
[2024-11-13 05:20:57,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:57,765][root][INFO] - Training Epoch: 5/10, step 206/574 completed (loss: 0.5630638003349304, acc: 0.8503937125205994)
[2024-11-13 05:20:57,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:58,121][root][INFO] - Training Epoch: 5/10, step 207/574 completed (loss: 0.5219793915748596, acc: 0.8534482717514038)
[2024-11-13 05:20:58,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:58,466][root][INFO] - Training Epoch: 5/10, step 208/574 completed (loss: 0.49934110045433044, acc: 0.8659420013427734)
[2024-11-13 05:20:58,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:58,836][root][INFO] - Training Epoch: 5/10, step 209/574 completed (loss: 0.5249382257461548, acc: 0.844357967376709)
[2024-11-13 05:20:58,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:59,209][root][INFO] - Training Epoch: 5/10, step 210/574 completed (loss: 0.31105202436447144, acc: 0.8804348111152649)
[2024-11-13 05:20:59,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:59,531][root][INFO] - Training Epoch: 5/10, step 211/574 completed (loss: 0.0800705999135971, acc: 1.0)
[2024-11-13 05:20:59,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:20:59,839][root][INFO] - Training Epoch: 5/10, step 212/574 completed (loss: 0.13896970450878143, acc: 0.9642857313156128)
[2024-11-13 05:20:59,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:00,147][root][INFO] - Training Epoch: 5/10, step 213/574 completed (loss: 0.18285325169563293, acc: 0.957446813583374)
[2024-11-13 05:21:00,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:00,822][root][INFO] - Training Epoch: 5/10, step 214/574 completed (loss: 0.2326602041721344, acc: 0.9384615421295166)
[2024-11-13 05:21:00,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:01,141][root][INFO] - Training Epoch: 5/10, step 215/574 completed (loss: 0.15206575393676758, acc: 0.9594594836235046)
[2024-11-13 05:21:01,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:01,471][root][INFO] - Training Epoch: 5/10, step 216/574 completed (loss: 0.09723751246929169, acc: 0.9651162624359131)
[2024-11-13 05:21:01,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:02,007][root][INFO] - Training Epoch: 5/10, step 217/574 completed (loss: 0.19431370496749878, acc: 0.954954981803894)
[2024-11-13 05:21:02,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:02,391][root][INFO] - Training Epoch: 5/10, step 218/574 completed (loss: 0.1280037760734558, acc: 0.9555555582046509)
[2024-11-13 05:21:02,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:02,708][root][INFO] - Training Epoch: 5/10, step 219/574 completed (loss: 0.1604154258966446, acc: 0.9696969985961914)
[2024-11-13 05:21:02,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:03,014][root][INFO] - Training Epoch: 5/10, step 220/574 completed (loss: 0.0917467400431633, acc: 0.9629629850387573)
[2024-11-13 05:21:03,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:03,316][root][INFO] - Training Epoch: 5/10, step 221/574 completed (loss: 0.11889031529426575, acc: 0.9599999785423279)
[2024-11-13 05:21:03,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:03,634][root][INFO] - Training Epoch: 5/10, step 222/574 completed (loss: 0.5241308808326721, acc: 0.8461538553237915)
[2024-11-13 05:21:03,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:04,427][root][INFO] - Training Epoch: 5/10, step 223/574 completed (loss: 0.4204845130443573, acc: 0.875)
[2024-11-13 05:21:04,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:04,969][root][INFO] - Training Epoch: 5/10, step 224/574 completed (loss: 0.4939715564250946, acc: 0.8409090638160706)
[2024-11-13 05:21:05,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:05,412][root][INFO] - Training Epoch: 5/10, step 225/574 completed (loss: 0.5483013391494751, acc: 0.7978723645210266)
[2024-11-13 05:21:05,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:05,772][root][INFO] - Training Epoch: 5/10, step 226/574 completed (loss: 0.47732922434806824, acc: 0.9245283007621765)
[2024-11-13 05:21:05,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:06,113][root][INFO] - Training Epoch: 5/10, step 227/574 completed (loss: 0.2597106695175171, acc: 0.9166666865348816)
[2024-11-13 05:21:06,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:06,420][root][INFO] - Training Epoch: 5/10, step 228/574 completed (loss: 0.1489609330892563, acc: 0.9534883499145508)
[2024-11-13 05:21:06,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:06,705][root][INFO] - Training Epoch: 5/10, step 229/574 completed (loss: 0.5944944620132446, acc: 0.8333333134651184)
[2024-11-13 05:21:06,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:07,062][root][INFO] - Training Epoch: 5/10, step 230/574 completed (loss: 1.8349848985671997, acc: 0.4736842215061188)
[2024-11-13 05:21:07,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:07,358][root][INFO] - Training Epoch: 5/10, step 231/574 completed (loss: 1.40394926071167, acc: 0.6666666865348816)
[2024-11-13 05:21:07,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:07,772][root][INFO] - Training Epoch: 5/10, step 232/574 completed (loss: 1.2026605606079102, acc: 0.6833333373069763)
[2024-11-13 05:21:07,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:08,308][root][INFO] - Training Epoch: 5/10, step 233/574 completed (loss: 1.650347352027893, acc: 0.5504587292671204)
[2024-11-13 05:21:08,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:08,782][root][INFO] - Training Epoch: 5/10, step 234/574 completed (loss: 1.2890279293060303, acc: 0.6461538672447205)
[2024-11-13 05:21:08,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:09,073][root][INFO] - Training Epoch: 5/10, step 235/574 completed (loss: 0.04328162968158722, acc: 1.0)
[2024-11-13 05:21:09,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:09,384][root][INFO] - Training Epoch: 5/10, step 236/574 completed (loss: 0.09339474886655807, acc: 1.0)
[2024-11-13 05:21:09,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:09,690][root][INFO] - Training Epoch: 5/10, step 237/574 completed (loss: 0.33380335569381714, acc: 0.9090909361839294)
[2024-11-13 05:21:09,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:10,034][root][INFO] - Training Epoch: 5/10, step 238/574 completed (loss: 0.4689812958240509, acc: 0.9259259104728699)
[2024-11-13 05:21:10,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:10,369][root][INFO] - Training Epoch: 5/10, step 239/574 completed (loss: 0.22300539910793304, acc: 0.9142857193946838)
[2024-11-13 05:21:10,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:10,707][root][INFO] - Training Epoch: 5/10, step 240/574 completed (loss: 0.6853979229927063, acc: 0.8636363744735718)
[2024-11-13 05:21:10,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:11,110][root][INFO] - Training Epoch: 5/10, step 241/574 completed (loss: 0.5168111324310303, acc: 0.8181818127632141)
[2024-11-13 05:21:11,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:11,705][root][INFO] - Training Epoch: 5/10, step 242/574 completed (loss: 1.009667992591858, acc: 0.725806474685669)
[2024-11-13 05:21:11,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:12,243][root][INFO] - Training Epoch: 5/10, step 243/574 completed (loss: 1.0376523733139038, acc: 0.7045454382896423)
[2024-11-13 05:21:12,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:12,559][root][INFO] - Training Epoch: 5/10, step 244/574 completed (loss: 0.034870445728302, acc: 1.0)
[2024-11-13 05:21:12,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:12,890][root][INFO] - Training Epoch: 5/10, step 245/574 completed (loss: 0.47143691778182983, acc: 0.8846153616905212)
[2024-11-13 05:21:12,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:13,222][root][INFO] - Training Epoch: 5/10, step 246/574 completed (loss: 0.03503704443573952, acc: 1.0)
[2024-11-13 05:21:13,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:13,524][root][INFO] - Training Epoch: 5/10, step 247/574 completed (loss: 0.20531490445137024, acc: 0.8999999761581421)
[2024-11-13 05:21:13,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:13,899][root][INFO] - Training Epoch: 5/10, step 248/574 completed (loss: 0.401748925447464, acc: 0.9189189076423645)
[2024-11-13 05:21:13,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:14,196][root][INFO] - Training Epoch: 5/10, step 249/574 completed (loss: 0.1961718648672104, acc: 0.9459459185600281)
[2024-11-13 05:21:14,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:14,505][root][INFO] - Training Epoch: 5/10, step 250/574 completed (loss: 0.07570207118988037, acc: 1.0)
[2024-11-13 05:21:14,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:14,822][root][INFO] - Training Epoch: 5/10, step 251/574 completed (loss: 0.25020575523376465, acc: 0.9117646813392639)
[2024-11-13 05:21:14,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:15,128][root][INFO] - Training Epoch: 5/10, step 252/574 completed (loss: 0.05682175233960152, acc: 1.0)
[2024-11-13 05:21:15,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:15,412][root][INFO] - Training Epoch: 5/10, step 253/574 completed (loss: 0.015124308876693249, acc: 1.0)
[2024-11-13 05:21:15,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:15,697][root][INFO] - Training Epoch: 5/10, step 254/574 completed (loss: 0.015537317842245102, acc: 1.0)
[2024-11-13 05:21:15,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:16,003][root][INFO] - Training Epoch: 5/10, step 255/574 completed (loss: 0.04990382120013237, acc: 1.0)
[2024-11-13 05:21:16,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:16,289][root][INFO] - Training Epoch: 5/10, step 256/574 completed (loss: 0.2920132875442505, acc: 0.9298245906829834)
[2024-11-13 05:21:16,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:16,594][root][INFO] - Training Epoch: 5/10, step 257/574 completed (loss: 0.20065361261367798, acc: 0.8999999761581421)
[2024-11-13 05:21:16,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:16,919][root][INFO] - Training Epoch: 5/10, step 258/574 completed (loss: 0.20495280623435974, acc: 0.9605262875556946)
[2024-11-13 05:21:17,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:17,494][root][INFO] - Training Epoch: 5/10, step 259/574 completed (loss: 0.5023853778839111, acc: 0.8584905862808228)
[2024-11-13 05:21:17,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:18,078][root][INFO] - Training Epoch: 5/10, step 260/574 completed (loss: 0.47779685258865356, acc: 0.8916666507720947)
[2024-11-13 05:21:18,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:18,373][root][INFO] - Training Epoch: 5/10, step 261/574 completed (loss: 0.09367205947637558, acc: 0.9722222089767456)
[2024-11-13 05:21:18,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:18,663][root][INFO] - Training Epoch: 5/10, step 262/574 completed (loss: 0.42367202043533325, acc: 0.9354838728904724)
[2024-11-13 05:21:18,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:18,988][root][INFO] - Training Epoch: 5/10, step 263/574 completed (loss: 0.875286877155304, acc: 0.7733333110809326)
[2024-11-13 05:21:19,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:19,294][root][INFO] - Training Epoch: 5/10, step 264/574 completed (loss: 0.468032568693161, acc: 0.7916666865348816)
[2024-11-13 05:21:19,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:20,190][root][INFO] - Training Epoch: 5/10, step 265/574 completed (loss: 1.036131739616394, acc: 0.6880000233650208)
[2024-11-13 05:21:20,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:20,502][root][INFO] - Training Epoch: 5/10, step 266/574 completed (loss: 0.827786386013031, acc: 0.7528089880943298)
[2024-11-13 05:21:20,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:20,889][root][INFO] - Training Epoch: 5/10, step 267/574 completed (loss: 0.6191802024841309, acc: 0.7972972989082336)
[2024-11-13 05:21:21,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:21,354][root][INFO] - Training Epoch: 5/10, step 268/574 completed (loss: 0.5907644033432007, acc: 0.8275862336158752)
[2024-11-13 05:21:21,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:21,689][root][INFO] - Training Epoch: 5/10, step 269/574 completed (loss: 0.11430595070123672, acc: 0.9545454382896423)
[2024-11-13 05:21:21,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:21,987][root][INFO] - Training Epoch: 5/10, step 270/574 completed (loss: 0.14280925691127777, acc: 0.9090909361839294)
[2024-11-13 05:21:22,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:22,287][root][INFO] - Training Epoch: 5/10, step 271/574 completed (loss: 0.1521475613117218, acc: 0.9375)
[2024-11-13 05:21:22,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:22,616][root][INFO] - Training Epoch: 5/10, step 272/574 completed (loss: 0.1943293958902359, acc: 0.9666666388511658)
[2024-11-13 05:21:22,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:22,998][root][INFO] - Training Epoch: 5/10, step 273/574 completed (loss: 0.29116013646125793, acc: 0.8999999761581421)
[2024-11-13 05:21:23,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:23,333][root][INFO] - Training Epoch: 5/10, step 274/574 completed (loss: 0.08468153327703476, acc: 1.0)
[2024-11-13 05:21:23,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:23,699][root][INFO] - Training Epoch: 5/10, step 275/574 completed (loss: 0.18396107852458954, acc: 0.9333333373069763)
[2024-11-13 05:21:23,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:24,034][root][INFO] - Training Epoch: 5/10, step 276/574 completed (loss: 0.3403770327568054, acc: 0.9655172228813171)
[2024-11-13 05:21:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:24,347][root][INFO] - Training Epoch: 5/10, step 277/574 completed (loss: 0.3461103141307831, acc: 0.8799999952316284)
[2024-11-13 05:21:25,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:25,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:25,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:26,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:26,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:27,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:27,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:27,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:28,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:28,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:28,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:29,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:29,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:29,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:30,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:31,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:31,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:31,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:32,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:32,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:33,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:33,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:33,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:33,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:34,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:34,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:34,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:35,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:35,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:35,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:36,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:36,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:36,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:37,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:37,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:38,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:38,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:38,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:39,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:39,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:39,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:41,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:41,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:41,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:42,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:42,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:42,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:42,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:43,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:43,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:44,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:44,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:44,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:45,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:45,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:45,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:46,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:46,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:47,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:47,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:47,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:48,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:48,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:48,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:49,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:49,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:50,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:50,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:50,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:51,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:51,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:51,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:52,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:52,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:52,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:53,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:53,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:53,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:54,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:54,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:54,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:55,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:55,725][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.2692, device='cuda:0') eval_epoch_loss=tensor(0.8194, device='cuda:0') eval_epoch_acc=tensor(0.7971, device='cuda:0')
[2024-11-13 05:21:55,726][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:21:55,727][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:21:56,006][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_5_step_278_loss_0.8194366693496704/model.pt
[2024-11-13 05:21:56,014][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:21:56,015][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 5 is 0.7970611453056335
[2024-11-13 05:21:56,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:56,355][root][INFO] - Training Epoch: 5/10, step 278/574 completed (loss: 0.5745661854743958, acc: 0.8297872543334961)
[2024-11-13 05:21:56,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:56,672][root][INFO] - Training Epoch: 5/10, step 279/574 completed (loss: 0.35149335861206055, acc: 0.875)
[2024-11-13 05:21:56,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:57,032][root][INFO] - Training Epoch: 5/10, step 280/574 completed (loss: 0.11585605889558792, acc: 0.9772727489471436)
[2024-11-13 05:21:57,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:57,478][root][INFO] - Training Epoch: 5/10, step 281/574 completed (loss: 0.6716229319572449, acc: 0.8313252925872803)
[2024-11-13 05:21:57,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:57,838][root][INFO] - Training Epoch: 5/10, step 282/574 completed (loss: 0.6323468685150146, acc: 0.8333333134651184)
[2024-11-13 05:21:57,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:58,162][root][INFO] - Training Epoch: 5/10, step 283/574 completed (loss: 0.11546943336725235, acc: 0.9736841917037964)
[2024-11-13 05:21:58,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:58,466][root][INFO] - Training Epoch: 5/10, step 284/574 completed (loss: 0.1653130203485489, acc: 0.9411764740943909)
[2024-11-13 05:21:58,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:58,781][root][INFO] - Training Epoch: 5/10, step 285/574 completed (loss: 0.12064284086227417, acc: 0.949999988079071)
[2024-11-13 05:21:58,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:59,106][root][INFO] - Training Epoch: 5/10, step 286/574 completed (loss: 0.5954470634460449, acc: 0.8671875)
[2024-11-13 05:21:59,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:59,466][root][INFO] - Training Epoch: 5/10, step 287/574 completed (loss: 0.5048060417175293, acc: 0.8479999899864197)
[2024-11-13 05:21:59,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:21:59,767][root][INFO] - Training Epoch: 5/10, step 288/574 completed (loss: 0.32836586236953735, acc: 0.9120879173278809)
[2024-11-13 05:21:59,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:00,086][root][INFO] - Training Epoch: 5/10, step 289/574 completed (loss: 0.46123385429382324, acc: 0.8633540272712708)
[2024-11-13 05:22:00,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:00,435][root][INFO] - Training Epoch: 5/10, step 290/574 completed (loss: 0.7511069774627686, acc: 0.7886598110198975)
[2024-11-13 05:22:00,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:00,820][root][INFO] - Training Epoch: 5/10, step 291/574 completed (loss: 0.17959605157375336, acc: 0.9545454382896423)
[2024-11-13 05:22:00,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:01,182][root][INFO] - Training Epoch: 5/10, step 292/574 completed (loss: 0.6826105117797852, acc: 0.8095238208770752)
[2024-11-13 05:22:01,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:01,517][root][INFO] - Training Epoch: 5/10, step 293/574 completed (loss: 0.22983470559120178, acc: 0.9482758641242981)
[2024-11-13 05:22:01,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:02,000][root][INFO] - Training Epoch: 5/10, step 294/574 completed (loss: 0.3214007019996643, acc: 0.9272727370262146)
[2024-11-13 05:22:02,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:02,596][root][INFO] - Training Epoch: 5/10, step 295/574 completed (loss: 0.6349383592605591, acc: 0.8092783689498901)
[2024-11-13 05:22:02,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:02,891][root][INFO] - Training Epoch: 5/10, step 296/574 completed (loss: 0.3402383327484131, acc: 0.9137930870056152)
[2024-11-13 05:22:02,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:03,201][root][INFO] - Training Epoch: 5/10, step 297/574 completed (loss: 0.04362504184246063, acc: 1.0)
[2024-11-13 05:22:03,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:03,515][root][INFO] - Training Epoch: 5/10, step 298/574 completed (loss: 0.2057662457227707, acc: 0.8947368264198303)
[2024-11-13 05:22:03,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:03,814][root][INFO] - Training Epoch: 5/10, step 299/574 completed (loss: 0.22118183970451355, acc: 0.9285714030265808)
[2024-11-13 05:22:03,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:04,115][root][INFO] - Training Epoch: 5/10, step 300/574 completed (loss: 0.13036902248859406, acc: 0.96875)
[2024-11-13 05:22:04,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:04,431][root][INFO] - Training Epoch: 5/10, step 301/574 completed (loss: 0.4467709958553314, acc: 0.8113207817077637)
[2024-11-13 05:22:04,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:04,753][root][INFO] - Training Epoch: 5/10, step 302/574 completed (loss: 0.18177714943885803, acc: 0.9433962106704712)
[2024-11-13 05:22:04,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:05,047][root][INFO] - Training Epoch: 5/10, step 303/574 completed (loss: 0.06911737471818924, acc: 1.0)
[2024-11-13 05:22:05,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:05,356][root][INFO] - Training Epoch: 5/10, step 304/574 completed (loss: 0.4255186915397644, acc: 0.875)
[2024-11-13 05:22:05,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:05,687][root][INFO] - Training Epoch: 5/10, step 305/574 completed (loss: 0.2713429927825928, acc: 0.8852459192276001)
[2024-11-13 05:22:05,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:06,069][root][INFO] - Training Epoch: 5/10, step 306/574 completed (loss: 0.05999470874667168, acc: 1.0)
[2024-11-13 05:22:06,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:06,451][root][INFO] - Training Epoch: 5/10, step 307/574 completed (loss: 0.014048055745661259, acc: 1.0)
[2024-11-13 05:22:06,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:06,797][root][INFO] - Training Epoch: 5/10, step 308/574 completed (loss: 0.23412096500396729, acc: 0.9130434989929199)
[2024-11-13 05:22:06,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:07,268][root][INFO] - Training Epoch: 5/10, step 309/574 completed (loss: 0.15009750425815582, acc: 0.9444444179534912)
[2024-11-13 05:22:07,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:07,614][root][INFO] - Training Epoch: 5/10, step 310/574 completed (loss: 0.1716148853302002, acc: 0.9638554453849792)
[2024-11-13 05:22:07,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:07,961][root][INFO] - Training Epoch: 5/10, step 311/574 completed (loss: 0.34224560856819153, acc: 0.9102563858032227)
[2024-11-13 05:22:08,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:08,274][root][INFO] - Training Epoch: 5/10, step 312/574 completed (loss: 0.2529292404651642, acc: 0.9387755393981934)
[2024-11-13 05:22:08,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:08,603][root][INFO] - Training Epoch: 5/10, step 313/574 completed (loss: 0.005714157596230507, acc: 1.0)
[2024-11-13 05:22:08,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:08,973][root][INFO] - Training Epoch: 5/10, step 314/574 completed (loss: 0.039892252534627914, acc: 1.0)
[2024-11-13 05:22:09,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:09,297][root][INFO] - Training Epoch: 5/10, step 315/574 completed (loss: 0.1351461410522461, acc: 0.9677419066429138)
[2024-11-13 05:22:09,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:09,608][root][INFO] - Training Epoch: 5/10, step 316/574 completed (loss: 0.43937960267066956, acc: 0.9032257795333862)
[2024-11-13 05:22:09,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:09,947][root][INFO] - Training Epoch: 5/10, step 317/574 completed (loss: 0.13167856633663177, acc: 0.9701492786407471)
[2024-11-13 05:22:10,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:10,277][root][INFO] - Training Epoch: 5/10, step 318/574 completed (loss: 0.2827761471271515, acc: 0.9134615659713745)
[2024-11-13 05:22:10,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:10,582][root][INFO] - Training Epoch: 5/10, step 319/574 completed (loss: 0.10390111804008484, acc: 0.9333333373069763)
[2024-11-13 05:22:10,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:10,945][root][INFO] - Training Epoch: 5/10, step 320/574 completed (loss: 0.050090935081243515, acc: 1.0)
[2024-11-13 05:22:11,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:11,262][root][INFO] - Training Epoch: 5/10, step 321/574 completed (loss: 0.050919756293296814, acc: 0.9800000190734863)
[2024-11-13 05:22:11,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:11,577][root][INFO] - Training Epoch: 5/10, step 322/574 completed (loss: 0.3660370111465454, acc: 0.8518518805503845)
[2024-11-13 05:22:11,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:11,864][root][INFO] - Training Epoch: 5/10, step 323/574 completed (loss: 0.7833232879638672, acc: 0.800000011920929)
[2024-11-13 05:22:11,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:12,167][root][INFO] - Training Epoch: 5/10, step 324/574 completed (loss: 0.8342466354370117, acc: 0.7948718070983887)
[2024-11-13 05:22:12,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:12,478][root][INFO] - Training Epoch: 5/10, step 325/574 completed (loss: 1.0192095041275024, acc: 0.7317073345184326)
[2024-11-13 05:22:12,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:12,808][root][INFO] - Training Epoch: 5/10, step 326/574 completed (loss: 0.6076474189758301, acc: 0.8947368264198303)
[2024-11-13 05:22:12,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:13,124][root][INFO] - Training Epoch: 5/10, step 327/574 completed (loss: 0.19293971359729767, acc: 0.9473684430122375)
[2024-11-13 05:22:13,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:13,472][root][INFO] - Training Epoch: 5/10, step 328/574 completed (loss: 0.05138710141181946, acc: 0.9642857313156128)
[2024-11-13 05:22:13,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:13,808][root][INFO] - Training Epoch: 5/10, step 329/574 completed (loss: 0.11603210866451263, acc: 0.9629629850387573)
[2024-11-13 05:22:13,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:14,142][root][INFO] - Training Epoch: 5/10, step 330/574 completed (loss: 0.05288160964846611, acc: 0.96875)
[2024-11-13 05:22:14,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:14,450][root][INFO] - Training Epoch: 5/10, step 331/574 completed (loss: 0.27155277132987976, acc: 0.9354838728904724)
[2024-11-13 05:22:14,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:14,809][root][INFO] - Training Epoch: 5/10, step 332/574 completed (loss: 0.050229087471961975, acc: 1.0)
[2024-11-13 05:22:14,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:15,137][root][INFO] - Training Epoch: 5/10, step 333/574 completed (loss: 0.3390091359615326, acc: 0.9375)
[2024-11-13 05:22:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:15,498][root][INFO] - Training Epoch: 5/10, step 334/574 completed (loss: 0.081679567694664, acc: 0.9666666388511658)
[2024-11-13 05:22:15,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:15,858][root][INFO] - Training Epoch: 5/10, step 335/574 completed (loss: 0.14747172594070435, acc: 0.9473684430122375)
[2024-11-13 05:22:15,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:16,173][root][INFO] - Training Epoch: 5/10, step 336/574 completed (loss: 0.650978147983551, acc: 0.8399999737739563)
[2024-11-13 05:22:16,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:16,513][root][INFO] - Training Epoch: 5/10, step 337/574 completed (loss: 1.1038932800292969, acc: 0.6896551847457886)
[2024-11-13 05:22:16,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:16,850][root][INFO] - Training Epoch: 5/10, step 338/574 completed (loss: 1.3536548614501953, acc: 0.6276595592498779)
[2024-11-13 05:22:16,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:17,171][root][INFO] - Training Epoch: 5/10, step 339/574 completed (loss: 1.1738779544830322, acc: 0.6385542154312134)
[2024-11-13 05:22:17,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:17,472][root][INFO] - Training Epoch: 5/10, step 340/574 completed (loss: 0.015206804499030113, acc: 1.0)
[2024-11-13 05:22:17,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:17,780][root][INFO] - Training Epoch: 5/10, step 341/574 completed (loss: 0.19867578148841858, acc: 0.8974359035491943)
[2024-11-13 05:22:17,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:18,107][root][INFO] - Training Epoch: 5/10, step 342/574 completed (loss: 0.34206274151802063, acc: 0.891566276550293)
[2024-11-13 05:22:18,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:18,407][root][INFO] - Training Epoch: 5/10, step 343/574 completed (loss: 0.40133488178253174, acc: 0.849056601524353)
[2024-11-13 05:22:18,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:18,732][root][INFO] - Training Epoch: 5/10, step 344/574 completed (loss: 0.12454582005739212, acc: 0.9620253443717957)
[2024-11-13 05:22:18,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:19,038][root][INFO] - Training Epoch: 5/10, step 345/574 completed (loss: 0.12739069759845734, acc: 0.9411764740943909)
[2024-11-13 05:22:19,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:19,322][root][INFO] - Training Epoch: 5/10, step 346/574 completed (loss: 0.382854163646698, acc: 0.8805969953536987)
[2024-11-13 05:22:19,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:19,619][root][INFO] - Training Epoch: 5/10, step 347/574 completed (loss: 0.13310429453849792, acc: 0.949999988079071)
[2024-11-13 05:22:19,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:19,953][root][INFO] - Training Epoch: 5/10, step 348/574 completed (loss: 0.11361470073461533, acc: 0.9599999785423279)
[2024-11-13 05:22:20,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:20,360][root][INFO] - Training Epoch: 5/10, step 349/574 completed (loss: 0.753304660320282, acc: 0.8055555820465088)
[2024-11-13 05:22:20,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:20,678][root][INFO] - Training Epoch: 5/10, step 350/574 completed (loss: 0.3575499355792999, acc: 0.8837209343910217)
[2024-11-13 05:22:20,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:21,005][root][INFO] - Training Epoch: 5/10, step 351/574 completed (loss: 0.11913955956697464, acc: 1.0)
[2024-11-13 05:22:21,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:21,388][root][INFO] - Training Epoch: 5/10, step 352/574 completed (loss: 0.7022160291671753, acc: 0.8222222328186035)
[2024-11-13 05:22:21,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:21,720][root][INFO] - Training Epoch: 5/10, step 353/574 completed (loss: 0.47223883867263794, acc: 0.95652174949646)
[2024-11-13 05:22:21,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:22,039][root][INFO] - Training Epoch: 5/10, step 354/574 completed (loss: 0.41549307107925415, acc: 0.9230769276618958)
[2024-11-13 05:22:22,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:22,358][root][INFO] - Training Epoch: 5/10, step 355/574 completed (loss: 0.8184167146682739, acc: 0.7802197933197021)
[2024-11-13 05:22:22,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:22,864][root][INFO] - Training Epoch: 5/10, step 356/574 completed (loss: 0.5349766612052917, acc: 0.834782600402832)
[2024-11-13 05:22:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:23,202][root][INFO] - Training Epoch: 5/10, step 357/574 completed (loss: 0.45818406343460083, acc: 0.8695651888847351)
[2024-11-13 05:22:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:23,528][root][INFO] - Training Epoch: 5/10, step 358/574 completed (loss: 0.38783279061317444, acc: 0.918367326259613)
[2024-11-13 05:22:23,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:23,841][root][INFO] - Training Epoch: 5/10, step 359/574 completed (loss: 0.0023487822618335485, acc: 1.0)
[2024-11-13 05:22:23,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:24,162][root][INFO] - Training Epoch: 5/10, step 360/574 completed (loss: 0.1028871163725853, acc: 0.9615384340286255)
[2024-11-13 05:22:24,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:24,514][root][INFO] - Training Epoch: 5/10, step 361/574 completed (loss: 0.266250878572464, acc: 0.8780487775802612)
[2024-11-13 05:22:24,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:24,862][root][INFO] - Training Epoch: 5/10, step 362/574 completed (loss: 0.3996850848197937, acc: 0.8444444537162781)
[2024-11-13 05:22:24,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:25,208][root][INFO] - Training Epoch: 5/10, step 363/574 completed (loss: 0.12440308928489685, acc: 0.9605262875556946)
[2024-11-13 05:22:25,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:25,526][root][INFO] - Training Epoch: 5/10, step 364/574 completed (loss: 0.08700650185346603, acc: 0.9756097793579102)
[2024-11-13 05:22:25,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:25,888][root][INFO] - Training Epoch: 5/10, step 365/574 completed (loss: 0.13655675947666168, acc: 0.939393937587738)
[2024-11-13 05:22:25,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:26,221][root][INFO] - Training Epoch: 5/10, step 366/574 completed (loss: 0.0338350348174572, acc: 1.0)
[2024-11-13 05:22:26,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:26,534][root][INFO] - Training Epoch: 5/10, step 367/574 completed (loss: 0.024582551792263985, acc: 1.0)
[2024-11-13 05:22:26,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:26,874][root][INFO] - Training Epoch: 5/10, step 368/574 completed (loss: 0.03183802217245102, acc: 1.0)
[2024-11-13 05:22:26,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:27,185][root][INFO] - Training Epoch: 5/10, step 369/574 completed (loss: 0.20314307510852814, acc: 0.90625)
[2024-11-13 05:22:27,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:27,862][root][INFO] - Training Epoch: 5/10, step 370/574 completed (loss: 0.6091442108154297, acc: 0.8363636136054993)
[2024-11-13 05:22:28,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:28,807][root][INFO] - Training Epoch: 5/10, step 371/574 completed (loss: 0.44762149453163147, acc: 0.8679245114326477)
[2024-11-13 05:22:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:29,145][root][INFO] - Training Epoch: 5/10, step 372/574 completed (loss: 0.28250032663345337, acc: 0.9111111164093018)
[2024-11-13 05:22:29,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:29,522][root][INFO] - Training Epoch: 5/10, step 373/574 completed (loss: 0.18050535023212433, acc: 0.9285714030265808)
[2024-11-13 05:22:29,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:29,882][root][INFO] - Training Epoch: 5/10, step 374/574 completed (loss: 0.3467227518558502, acc: 0.9428571462631226)
[2024-11-13 05:22:29,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:30,200][root][INFO] - Training Epoch: 5/10, step 375/574 completed (loss: 0.011770810931921005, acc: 1.0)
[2024-11-13 05:22:30,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:30,503][root][INFO] - Training Epoch: 5/10, step 376/574 completed (loss: 0.00832213182002306, acc: 1.0)
[2024-11-13 05:22:30,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:30,856][root][INFO] - Training Epoch: 5/10, step 377/574 completed (loss: 0.34789738059043884, acc: 0.9583333134651184)
[2024-11-13 05:22:30,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:31,308][root][INFO] - Training Epoch: 5/10, step 378/574 completed (loss: 0.12819786369800568, acc: 0.9684210419654846)
[2024-11-13 05:22:31,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:31,933][root][INFO] - Training Epoch: 5/10, step 379/574 completed (loss: 0.2689802944660187, acc: 0.940119743347168)
[2024-11-13 05:22:32,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:32,352][root][INFO] - Training Epoch: 5/10, step 380/574 completed (loss: 0.2969478964805603, acc: 0.8947368264198303)
[2024-11-13 05:22:32,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:33,535][root][INFO] - Training Epoch: 5/10, step 381/574 completed (loss: 0.6092454791069031, acc: 0.8395721912384033)
[2024-11-13 05:22:33,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:34,186][root][INFO] - Training Epoch: 5/10, step 382/574 completed (loss: 0.10571777075529099, acc: 0.954954981803894)
[2024-11-13 05:22:34,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:34,489][root][INFO] - Training Epoch: 5/10, step 383/574 completed (loss: 0.08227124065160751, acc: 1.0)
[2024-11-13 05:22:34,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:34,761][root][INFO] - Training Epoch: 5/10, step 384/574 completed (loss: 0.02301773615181446, acc: 1.0)
[2024-11-13 05:22:34,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:35,113][root][INFO] - Training Epoch: 5/10, step 385/574 completed (loss: 0.10055787116289139, acc: 0.96875)
[2024-11-13 05:22:35,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:35,455][root][INFO] - Training Epoch: 5/10, step 386/574 completed (loss: 0.047017455101013184, acc: 1.0)
[2024-11-13 05:22:35,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:35,861][root][INFO] - Training Epoch: 5/10, step 387/574 completed (loss: 0.02265213429927826, acc: 1.0)
[2024-11-13 05:22:35,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:36,194][root][INFO] - Training Epoch: 5/10, step 388/574 completed (loss: 0.005823857616633177, acc: 1.0)
[2024-11-13 05:22:36,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:36,513][root][INFO] - Training Epoch: 5/10, step 389/574 completed (loss: 0.01364049594849348, acc: 1.0)
[2024-11-13 05:22:36,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:36,857][root][INFO] - Training Epoch: 5/10, step 390/574 completed (loss: 0.16885873675346375, acc: 0.9523809552192688)
[2024-11-13 05:22:36,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:37,159][root][INFO] - Training Epoch: 5/10, step 391/574 completed (loss: 0.5979589819908142, acc: 0.7777777910232544)
[2024-11-13 05:22:37,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:37,509][root][INFO] - Training Epoch: 5/10, step 392/574 completed (loss: 0.7738143801689148, acc: 0.7766990065574646)
[2024-11-13 05:22:37,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:38,115][root][INFO] - Training Epoch: 5/10, step 393/574 completed (loss: 0.937431812286377, acc: 0.7941176295280457)
[2024-11-13 05:22:38,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:38,489][root][INFO] - Training Epoch: 5/10, step 394/574 completed (loss: 0.7462014555931091, acc: 0.7799999713897705)
[2024-11-13 05:22:38,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:38,865][root][INFO] - Training Epoch: 5/10, step 395/574 completed (loss: 0.64604252576828, acc: 0.8333333134651184)
[2024-11-13 05:22:38,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:39,162][root][INFO] - Training Epoch: 5/10, step 396/574 completed (loss: 0.5556460618972778, acc: 0.8372092843055725)
[2024-11-13 05:22:39,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:39,461][root][INFO] - Training Epoch: 5/10, step 397/574 completed (loss: 0.05023214593529701, acc: 1.0)
[2024-11-13 05:22:39,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:39,855][root][INFO] - Training Epoch: 5/10, step 398/574 completed (loss: 0.21262496709823608, acc: 0.9534883499145508)
[2024-11-13 05:22:39,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:40,185][root][INFO] - Training Epoch: 5/10, step 399/574 completed (loss: 0.031963132321834564, acc: 1.0)
[2024-11-13 05:22:40,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:40,775][root][INFO] - Training Epoch: 5/10, step 400/574 completed (loss: 0.2697249948978424, acc: 0.9411764740943909)
[2024-11-13 05:22:40,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:41,097][root][INFO] - Training Epoch: 5/10, step 401/574 completed (loss: 0.6875643134117126, acc: 0.7866666913032532)
[2024-11-13 05:22:41,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:41,448][root][INFO] - Training Epoch: 5/10, step 402/574 completed (loss: 0.2574264407157898, acc: 0.9090909361839294)
[2024-11-13 05:22:41,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:41,807][root][INFO] - Training Epoch: 5/10, step 403/574 completed (loss: 0.4602917432785034, acc: 0.8787878751754761)
[2024-11-13 05:22:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:42,128][root][INFO] - Training Epoch: 5/10, step 404/574 completed (loss: 0.06681390106678009, acc: 0.9677419066429138)
[2024-11-13 05:22:42,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:42,512][root][INFO] - Training Epoch: 5/10, step 405/574 completed (loss: 0.04587864503264427, acc: 1.0)
[2024-11-13 05:22:42,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:42,833][root][INFO] - Training Epoch: 5/10, step 406/574 completed (loss: 0.04737094044685364, acc: 1.0)
[2024-11-13 05:22:42,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:43,143][root][INFO] - Training Epoch: 5/10, step 407/574 completed (loss: 0.04914838820695877, acc: 1.0)
[2024-11-13 05:22:43,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:43,469][root][INFO] - Training Epoch: 5/10, step 408/574 completed (loss: 0.06181216612458229, acc: 1.0)
[2024-11-13 05:22:43,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:43,852][root][INFO] - Training Epoch: 5/10, step 409/574 completed (loss: 0.0484200082719326, acc: 1.0)
[2024-11-13 05:22:43,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:44,193][root][INFO] - Training Epoch: 5/10, step 410/574 completed (loss: 0.09046436846256256, acc: 0.982758641242981)
[2024-11-13 05:22:44,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:44,493][root][INFO] - Training Epoch: 5/10, step 411/574 completed (loss: 0.16284307837486267, acc: 0.9642857313156128)
[2024-11-13 05:22:44,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:44,879][root][INFO] - Training Epoch: 5/10, step 412/574 completed (loss: 0.05053717643022537, acc: 1.0)
[2024-11-13 05:22:44,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:45,242][root][INFO] - Training Epoch: 5/10, step 413/574 completed (loss: 0.10049839317798615, acc: 0.9696969985961914)
[2024-11-13 05:22:45,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:45,580][root][INFO] - Training Epoch: 5/10, step 414/574 completed (loss: 0.12618161737918854, acc: 0.9545454382896423)
[2024-11-13 05:22:45,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:45,941][root][INFO] - Training Epoch: 5/10, step 415/574 completed (loss: 0.4166724383831024, acc: 0.8627451062202454)
[2024-11-13 05:22:46,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:46,321][root][INFO] - Training Epoch: 5/10, step 416/574 completed (loss: 0.06415953487157822, acc: 1.0)
[2024-11-13 05:22:46,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:46,703][root][INFO] - Training Epoch: 5/10, step 417/574 completed (loss: 0.1636938452720642, acc: 0.9444444179534912)
[2024-11-13 05:22:46,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:47,107][root][INFO] - Training Epoch: 5/10, step 418/574 completed (loss: 0.17612628638744354, acc: 0.925000011920929)
[2024-11-13 05:22:47,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:47,478][root][INFO] - Training Epoch: 5/10, step 419/574 completed (loss: 0.15835247933864594, acc: 0.949999988079071)
[2024-11-13 05:22:47,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:47,816][root][INFO] - Training Epoch: 5/10, step 420/574 completed (loss: 0.045326296240091324, acc: 1.0)
[2024-11-13 05:22:48,731][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:49,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:49,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:49,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:50,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:50,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:50,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:50,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:51,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:51,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:51,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:52,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:52,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:53,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:53,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:53,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:54,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:54,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:54,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:55,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:55,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:55,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:56,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:56,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:56,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:57,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:57,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:57,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:58,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:58,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:59,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:59,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:22:59,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:00,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:00,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:00,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:00,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:01,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:01,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:02,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:02,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:02,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:03,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:03,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:03,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:04,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:04,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:04,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:05,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:05,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:05,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:05,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:06,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:06,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:06,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:07,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:07,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:07,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:08,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:08,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:08,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:09,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:09,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:10,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:10,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:10,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:11,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:11,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:12,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:12,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:13,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:13,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:13,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:13,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:14,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:14,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:15,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:15,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:15,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:16,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:16,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:16,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:17,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:17,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:17,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:18,663][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4384, device='cuda:0') eval_epoch_loss=tensor(0.8913, device='cuda:0') eval_epoch_acc=tensor(0.7800, device='cuda:0')
[2024-11-13 05:23:18,665][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:23:18,665][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:23:18,906][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_5_step_421_loss_0.8913336396217346/model.pt
[2024-11-13 05:23:18,910][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:23:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:19,256][root][INFO] - Training Epoch: 5/10, step 421/574 completed (loss: 0.1689590960741043, acc: 0.9333333373069763)
[2024-11-13 05:23:19,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:19,568][root][INFO] - Training Epoch: 5/10, step 422/574 completed (loss: 0.252475380897522, acc: 0.90625)
[2024-11-13 05:23:19,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:19,949][root][INFO] - Training Epoch: 5/10, step 423/574 completed (loss: 0.12228649109601974, acc: 0.9722222089767456)
[2024-11-13 05:23:20,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:20,253][root][INFO] - Training Epoch: 5/10, step 424/574 completed (loss: 0.2730323076248169, acc: 0.9629629850387573)
[2024-11-13 05:23:20,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:20,542][root][INFO] - Training Epoch: 5/10, step 425/574 completed (loss: 0.07764729857444763, acc: 0.9696969985961914)
[2024-11-13 05:23:20,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:20,838][root][INFO] - Training Epoch: 5/10, step 426/574 completed (loss: 0.016496455296874046, acc: 1.0)
[2024-11-13 05:23:20,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:21,150][root][INFO] - Training Epoch: 5/10, step 427/574 completed (loss: 0.038214296102523804, acc: 1.0)
[2024-11-13 05:23:21,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:21,496][root][INFO] - Training Epoch: 5/10, step 428/574 completed (loss: 0.03799436613917351, acc: 1.0)
[2024-11-13 05:23:21,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:21,834][root][INFO] - Training Epoch: 5/10, step 429/574 completed (loss: 0.015986446291208267, acc: 1.0)
[2024-11-13 05:23:21,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:22,147][root][INFO] - Training Epoch: 5/10, step 430/574 completed (loss: 0.028306981548666954, acc: 1.0)
[2024-11-13 05:23:22,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:22,476][root][INFO] - Training Epoch: 5/10, step 431/574 completed (loss: 0.014904269017279148, acc: 1.0)
[2024-11-13 05:23:22,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:22,886][root][INFO] - Training Epoch: 5/10, step 432/574 completed (loss: 0.057819727808237076, acc: 1.0)
[2024-11-13 05:23:23,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:23,248][root][INFO] - Training Epoch: 5/10, step 433/574 completed (loss: 0.10160085558891296, acc: 0.9444444179534912)
[2024-11-13 05:23:23,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:23,543][root][INFO] - Training Epoch: 5/10, step 434/574 completed (loss: 0.00497409189119935, acc: 1.0)
[2024-11-13 05:23:23,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:23,879][root][INFO] - Training Epoch: 5/10, step 435/574 completed (loss: 0.032508734613657, acc: 0.9696969985961914)
[2024-11-13 05:23:23,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:24,197][root][INFO] - Training Epoch: 5/10, step 436/574 completed (loss: 0.1327204704284668, acc: 0.8888888955116272)
[2024-11-13 05:23:24,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:24,558][root][INFO] - Training Epoch: 5/10, step 437/574 completed (loss: 0.07670003920793533, acc: 0.9545454382896423)
[2024-11-13 05:23:24,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:24,898][root][INFO] - Training Epoch: 5/10, step 438/574 completed (loss: 0.007605826016515493, acc: 1.0)
[2024-11-13 05:23:25,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:25,278][root][INFO] - Training Epoch: 5/10, step 439/574 completed (loss: 0.20605739951133728, acc: 0.9487179517745972)
[2024-11-13 05:23:25,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:25,756][root][INFO] - Training Epoch: 5/10, step 440/574 completed (loss: 0.23921680450439453, acc: 0.939393937587738)
[2024-11-13 05:23:26,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:26,520][root][INFO] - Training Epoch: 5/10, step 441/574 completed (loss: 0.6867349147796631, acc: 0.7760000228881836)
[2024-11-13 05:23:26,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:26,942][root][INFO] - Training Epoch: 5/10, step 442/574 completed (loss: 0.8966941833496094, acc: 0.8064516186714172)
[2024-11-13 05:23:27,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:27,603][root][INFO] - Training Epoch: 5/10, step 443/574 completed (loss: 0.6122106313705444, acc: 0.8358209133148193)
[2024-11-13 05:23:27,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:27,996][root][INFO] - Training Epoch: 5/10, step 444/574 completed (loss: 0.20858322083950043, acc: 0.9433962106704712)
[2024-11-13 05:23:28,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:28,427][root][INFO] - Training Epoch: 5/10, step 445/574 completed (loss: 0.10964798182249069, acc: 0.9772727489471436)
[2024-11-13 05:23:28,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:28,785][root][INFO] - Training Epoch: 5/10, step 446/574 completed (loss: 0.34607747197151184, acc: 0.8695651888847351)
[2024-11-13 05:23:28,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:29,119][root][INFO] - Training Epoch: 5/10, step 447/574 completed (loss: 0.19494186341762543, acc: 0.9230769276618958)
[2024-11-13 05:23:29,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:29,390][root][INFO] - Training Epoch: 5/10, step 448/574 completed (loss: 0.20669949054718018, acc: 0.9642857313156128)
[2024-11-13 05:23:29,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:29,626][root][INFO] - Training Epoch: 5/10, step 449/574 completed (loss: 0.11168814450502396, acc: 0.9701492786407471)
[2024-11-13 05:23:29,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:29,931][root][INFO] - Training Epoch: 5/10, step 450/574 completed (loss: 0.13756978511810303, acc: 0.9583333134651184)
[2024-11-13 05:23:30,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:30,231][root][INFO] - Training Epoch: 5/10, step 451/574 completed (loss: 0.14145982265472412, acc: 0.95652174949646)
[2024-11-13 05:23:30,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:30,604][root][INFO] - Training Epoch: 5/10, step 452/574 completed (loss: 0.33806222677230835, acc: 0.9230769276618958)
[2024-11-13 05:23:30,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:30,944][root][INFO] - Training Epoch: 5/10, step 453/574 completed (loss: 0.5839715003967285, acc: 0.8815789222717285)
[2024-11-13 05:23:31,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:31,207][root][INFO] - Training Epoch: 5/10, step 454/574 completed (loss: 0.1392030119895935, acc: 0.9591836929321289)
[2024-11-13 05:23:31,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:31,559][root][INFO] - Training Epoch: 5/10, step 455/574 completed (loss: 0.12356230616569519, acc: 0.9696969985961914)
[2024-11-13 05:23:31,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:31,904][root][INFO] - Training Epoch: 5/10, step 456/574 completed (loss: 0.5253643989562988, acc: 0.876288652420044)
[2024-11-13 05:23:31,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:32,241][root][INFO] - Training Epoch: 5/10, step 457/574 completed (loss: 0.18088014423847198, acc: 0.9428571462631226)
[2024-11-13 05:23:32,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:32,619][root][INFO] - Training Epoch: 5/10, step 458/574 completed (loss: 0.5219811201095581, acc: 0.8255813717842102)
[2024-11-13 05:23:32,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:32,921][root][INFO] - Training Epoch: 5/10, step 459/574 completed (loss: 0.209612175822258, acc: 0.9642857313156128)
[2024-11-13 05:23:33,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:33,250][root][INFO] - Training Epoch: 5/10, step 460/574 completed (loss: 0.2563403844833374, acc: 0.9012345671653748)
[2024-11-13 05:23:33,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:33,565][root][INFO] - Training Epoch: 5/10, step 461/574 completed (loss: 0.21935993432998657, acc: 0.9166666865348816)
[2024-11-13 05:23:33,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:33,889][root][INFO] - Training Epoch: 5/10, step 462/574 completed (loss: 0.1506834775209427, acc: 0.96875)
[2024-11-13 05:23:33,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:34,220][root][INFO] - Training Epoch: 5/10, step 463/574 completed (loss: 0.3218931555747986, acc: 0.9230769276618958)
[2024-11-13 05:23:34,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:34,635][root][INFO] - Training Epoch: 5/10, step 464/574 completed (loss: 0.1603146344423294, acc: 0.95652174949646)
[2024-11-13 05:23:34,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:34,998][root][INFO] - Training Epoch: 5/10, step 465/574 completed (loss: 0.3006625771522522, acc: 0.9166666865348816)
[2024-11-13 05:23:35,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:35,361][root][INFO] - Training Epoch: 5/10, step 466/574 completed (loss: 0.4179365634918213, acc: 0.8795180916786194)
[2024-11-13 05:23:35,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:35,728][root][INFO] - Training Epoch: 5/10, step 467/574 completed (loss: 0.20003250241279602, acc: 0.9459459185600281)
[2024-11-13 05:23:35,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:36,127][root][INFO] - Training Epoch: 5/10, step 468/574 completed (loss: 0.5907639265060425, acc: 0.844660222530365)
[2024-11-13 05:23:36,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:36,537][root][INFO] - Training Epoch: 5/10, step 469/574 completed (loss: 0.43519383668899536, acc: 0.8861788511276245)
[2024-11-13 05:23:36,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:36,859][root][INFO] - Training Epoch: 5/10, step 470/574 completed (loss: 0.031676530838012695, acc: 1.0)
[2024-11-13 05:23:36,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:37,163][root][INFO] - Training Epoch: 5/10, step 471/574 completed (loss: 0.18829762935638428, acc: 0.9285714030265808)
[2024-11-13 05:23:37,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:37,579][root][INFO] - Training Epoch: 5/10, step 472/574 completed (loss: 0.4562983810901642, acc: 0.8627451062202454)
[2024-11-13 05:23:37,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:37,929][root][INFO] - Training Epoch: 5/10, step 473/574 completed (loss: 0.7517940998077393, acc: 0.7947598099708557)
[2024-11-13 05:23:38,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:38,269][root][INFO] - Training Epoch: 5/10, step 474/574 completed (loss: 0.2970651388168335, acc: 0.875)
[2024-11-13 05:23:38,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:38,624][root][INFO] - Training Epoch: 5/10, step 475/574 completed (loss: 0.43442460894584656, acc: 0.8711656332015991)
[2024-11-13 05:23:38,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:38,960][root][INFO] - Training Epoch: 5/10, step 476/574 completed (loss: 0.38717320561408997, acc: 0.9208633303642273)
[2024-11-13 05:23:39,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:39,303][root][INFO] - Training Epoch: 5/10, step 477/574 completed (loss: 0.6323397755622864, acc: 0.8190954923629761)
[2024-11-13 05:23:39,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:39,659][root][INFO] - Training Epoch: 5/10, step 478/574 completed (loss: 0.26763954758644104, acc: 0.9444444179534912)
[2024-11-13 05:23:39,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:40,004][root][INFO] - Training Epoch: 5/10, step 479/574 completed (loss: 0.20502229034900665, acc: 0.939393937587738)
[2024-11-13 05:23:40,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:40,309][root][INFO] - Training Epoch: 5/10, step 480/574 completed (loss: 0.15932351350784302, acc: 0.9629629850387573)
[2024-11-13 05:23:40,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:40,659][root][INFO] - Training Epoch: 5/10, step 481/574 completed (loss: 0.23707544803619385, acc: 0.8500000238418579)
[2024-11-13 05:23:40,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:40,969][root][INFO] - Training Epoch: 5/10, step 482/574 completed (loss: 0.23007309436798096, acc: 0.949999988079071)
[2024-11-13 05:23:41,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:41,350][root][INFO] - Training Epoch: 5/10, step 483/574 completed (loss: 0.5105615258216858, acc: 0.8103448152542114)
[2024-11-13 05:23:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:41,735][root][INFO] - Training Epoch: 5/10, step 484/574 completed (loss: 0.053788311779499054, acc: 1.0)
[2024-11-13 05:23:41,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:42,071][root][INFO] - Training Epoch: 5/10, step 485/574 completed (loss: 0.03971875458955765, acc: 1.0)
[2024-11-13 05:23:42,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:42,388][root][INFO] - Training Epoch: 5/10, step 486/574 completed (loss: 0.28792211413383484, acc: 0.9629629850387573)
[2024-11-13 05:23:42,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:42,683][root][INFO] - Training Epoch: 5/10, step 487/574 completed (loss: 0.4021245837211609, acc: 0.9047619104385376)
[2024-11-13 05:23:42,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:42,952][root][INFO] - Training Epoch: 5/10, step 488/574 completed (loss: 0.344905823469162, acc: 0.9090909361839294)
[2024-11-13 05:23:43,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:43,308][root][INFO] - Training Epoch: 5/10, step 489/574 completed (loss: 0.8345176577568054, acc: 0.7538461685180664)
[2024-11-13 05:23:43,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:43,625][root][INFO] - Training Epoch: 5/10, step 490/574 completed (loss: 0.16806451976299286, acc: 0.9666666388511658)
[2024-11-13 05:23:43,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:43,918][root][INFO] - Training Epoch: 5/10, step 491/574 completed (loss: 0.12738512456417084, acc: 0.931034505367279)
[2024-11-13 05:23:44,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:44,249][root][INFO] - Training Epoch: 5/10, step 492/574 completed (loss: 0.1754029393196106, acc: 0.9803921580314636)
[2024-11-13 05:23:44,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:44,569][root][INFO] - Training Epoch: 5/10, step 493/574 completed (loss: 0.14088748395442963, acc: 1.0)
[2024-11-13 05:23:44,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:44,901][root][INFO] - Training Epoch: 5/10, step 494/574 completed (loss: 0.20143990218639374, acc: 0.8947368264198303)
[2024-11-13 05:23:45,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:45,239][root][INFO] - Training Epoch: 5/10, step 495/574 completed (loss: 0.1042737364768982, acc: 1.0)
[2024-11-13 05:23:45,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:45,587][root][INFO] - Training Epoch: 5/10, step 496/574 completed (loss: 0.642393946647644, acc: 0.8214285969734192)
[2024-11-13 05:23:45,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:45,961][root][INFO] - Training Epoch: 5/10, step 497/574 completed (loss: 0.30072247982025146, acc: 0.9101123809814453)
[2024-11-13 05:23:46,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:46,269][root][INFO] - Training Epoch: 5/10, step 498/574 completed (loss: 0.8705847859382629, acc: 0.7752808928489685)
[2024-11-13 05:23:46,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:46,577][root][INFO] - Training Epoch: 5/10, step 499/574 completed (loss: 1.0367918014526367, acc: 0.6808510422706604)
[2024-11-13 05:23:46,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:46,902][root][INFO] - Training Epoch: 5/10, step 500/574 completed (loss: 0.6139169335365295, acc: 0.8369565010070801)
[2024-11-13 05:23:46,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:47,187][root][INFO] - Training Epoch: 5/10, step 501/574 completed (loss: 0.0251691285520792, acc: 1.0)
[2024-11-13 05:23:47,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:47,560][root][INFO] - Training Epoch: 5/10, step 502/574 completed (loss: 0.03540441021323204, acc: 1.0)
[2024-11-13 05:23:47,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:47,888][root][INFO] - Training Epoch: 5/10, step 503/574 completed (loss: 0.10342895239591599, acc: 0.9629629850387573)
[2024-11-13 05:23:47,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:48,211][root][INFO] - Training Epoch: 5/10, step 504/574 completed (loss: 0.16315515339374542, acc: 0.9629629850387573)
[2024-11-13 05:23:48,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:48,501][root][INFO] - Training Epoch: 5/10, step 505/574 completed (loss: 0.37777450680732727, acc: 0.8867924809455872)
[2024-11-13 05:23:48,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:48,838][root][INFO] - Training Epoch: 5/10, step 506/574 completed (loss: 0.545646071434021, acc: 0.8620689511299133)
[2024-11-13 05:23:49,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:49,472][root][INFO] - Training Epoch: 5/10, step 507/574 completed (loss: 0.9273875951766968, acc: 0.7297297120094299)
[2024-11-13 05:23:49,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:49,942][root][INFO] - Training Epoch: 5/10, step 508/574 completed (loss: 0.4600774347782135, acc: 0.9014084339141846)
[2024-11-13 05:23:50,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:50,225][root][INFO] - Training Epoch: 5/10, step 509/574 completed (loss: 0.06789921224117279, acc: 0.949999988079071)
[2024-11-13 05:23:50,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:50,529][root][INFO] - Training Epoch: 5/10, step 510/574 completed (loss: 0.041256602853536606, acc: 1.0)
[2024-11-13 05:23:50,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:50,845][root][INFO] - Training Epoch: 5/10, step 511/574 completed (loss: 0.04552531987428665, acc: 1.0)
[2024-11-13 05:23:52,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:53,868][root][INFO] - Training Epoch: 5/10, step 512/574 completed (loss: 1.1049249172210693, acc: 0.6785714030265808)
[2024-11-13 05:23:54,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:54,698][root][INFO] - Training Epoch: 5/10, step 513/574 completed (loss: 0.3512715697288513, acc: 0.8730158805847168)
[2024-11-13 05:23:54,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:54,985][root][INFO] - Training Epoch: 5/10, step 514/574 completed (loss: 0.25092455744743347, acc: 0.9285714030265808)
[2024-11-13 05:23:55,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:55,271][root][INFO] - Training Epoch: 5/10, step 515/574 completed (loss: 0.04622018709778786, acc: 0.9833333492279053)
[2024-11-13 05:23:55,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:55,968][root][INFO] - Training Epoch: 5/10, step 516/574 completed (loss: 0.4226055145263672, acc: 0.875)
[2024-11-13 05:23:56,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:56,275][root][INFO] - Training Epoch: 5/10, step 517/574 completed (loss: 0.001521033002063632, acc: 1.0)
[2024-11-13 05:23:56,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:56,575][root][INFO] - Training Epoch: 5/10, step 518/574 completed (loss: 0.01672612689435482, acc: 1.0)
[2024-11-13 05:23:56,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:56,905][root][INFO] - Training Epoch: 5/10, step 519/574 completed (loss: 0.184344083070755, acc: 0.8999999761581421)
[2024-11-13 05:23:56,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:57,216][root][INFO] - Training Epoch: 5/10, step 520/574 completed (loss: 0.16890554130077362, acc: 0.9629629850387573)
[2024-11-13 05:23:57,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:58,282][root][INFO] - Training Epoch: 5/10, step 521/574 completed (loss: 0.6096922159194946, acc: 0.8177965879440308)
[2024-11-13 05:23:58,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:58,704][root][INFO] - Training Epoch: 5/10, step 522/574 completed (loss: 0.27849525213241577, acc: 0.9104477763175964)
[2024-11-13 05:23:58,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:59,133][root][INFO] - Training Epoch: 5/10, step 523/574 completed (loss: 0.32728591561317444, acc: 0.8832116723060608)
[2024-11-13 05:23:59,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:23:59,745][root][INFO] - Training Epoch: 5/10, step 524/574 completed (loss: 0.5922318696975708, acc: 0.8550000190734863)
[2024-11-13 05:23:59,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:00,109][root][INFO] - Training Epoch: 5/10, step 525/574 completed (loss: 0.025763938203454018, acc: 1.0)
[2024-11-13 05:24:00,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:00,433][root][INFO] - Training Epoch: 5/10, step 526/574 completed (loss: 0.07794566452503204, acc: 0.9807692170143127)
[2024-11-13 05:24:00,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:00,819][root][INFO] - Training Epoch: 5/10, step 527/574 completed (loss: 0.20105066895484924, acc: 0.9047619104385376)
[2024-11-13 05:24:00,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:01,167][root][INFO] - Training Epoch: 5/10, step 528/574 completed (loss: 1.0850456953048706, acc: 0.7213114500045776)
[2024-11-13 05:24:01,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:01,568][root][INFO] - Training Epoch: 5/10, step 529/574 completed (loss: 0.203327938914299, acc: 0.9152542352676392)
[2024-11-13 05:24:01,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:01,904][root][INFO] - Training Epoch: 5/10, step 530/574 completed (loss: 0.840061366558075, acc: 0.7209302186965942)
[2024-11-13 05:24:02,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:02,268][root][INFO] - Training Epoch: 5/10, step 531/574 completed (loss: 0.45166006684303284, acc: 0.8636363744735718)
[2024-11-13 05:24:02,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:02,604][root][INFO] - Training Epoch: 5/10, step 532/574 completed (loss: 0.6671414375305176, acc: 0.849056601524353)
[2024-11-13 05:24:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:02,931][root][INFO] - Training Epoch: 5/10, step 533/574 completed (loss: 0.3156083822250366, acc: 0.9090909361839294)
[2024-11-13 05:24:03,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:03,231][root][INFO] - Training Epoch: 5/10, step 534/574 completed (loss: 0.4325050115585327, acc: 0.9200000166893005)
[2024-11-13 05:24:03,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:03,524][root][INFO] - Training Epoch: 5/10, step 535/574 completed (loss: 0.1259448379278183, acc: 0.949999988079071)
[2024-11-13 05:24:03,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:03,817][root][INFO] - Training Epoch: 5/10, step 536/574 completed (loss: 0.05346380174160004, acc: 1.0)
[2024-11-13 05:24:03,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:04,207][root][INFO] - Training Epoch: 5/10, step 537/574 completed (loss: 0.3368412256240845, acc: 0.8769230842590332)
[2024-11-13 05:24:04,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:04,526][root][INFO] - Training Epoch: 5/10, step 538/574 completed (loss: 0.2474176287651062, acc: 0.921875)
[2024-11-13 05:24:04,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:04,916][root][INFO] - Training Epoch: 5/10, step 539/574 completed (loss: 0.2733653783798218, acc: 0.9375)
[2024-11-13 05:24:04,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:05,241][root][INFO] - Training Epoch: 5/10, step 540/574 completed (loss: 0.3252306580543518, acc: 0.939393937587738)
[2024-11-13 05:24:05,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:05,568][root][INFO] - Training Epoch: 5/10, step 541/574 completed (loss: 0.09880180656909943, acc: 0.9375)
[2024-11-13 05:24:05,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:05,884][root][INFO] - Training Epoch: 5/10, step 542/574 completed (loss: 0.011303656734526157, acc: 1.0)
[2024-11-13 05:24:05,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:06,191][root][INFO] - Training Epoch: 5/10, step 543/574 completed (loss: 0.004293105565011501, acc: 1.0)
[2024-11-13 05:24:06,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:06,491][root][INFO] - Training Epoch: 5/10, step 544/574 completed (loss: 0.027098678052425385, acc: 1.0)
[2024-11-13 05:24:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:06,840][root][INFO] - Training Epoch: 5/10, step 545/574 completed (loss: 0.03401267156004906, acc: 1.0)
[2024-11-13 05:24:06,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:07,199][root][INFO] - Training Epoch: 5/10, step 546/574 completed (loss: 0.03405759483575821, acc: 1.0)
[2024-11-13 05:24:07,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:07,543][root][INFO] - Training Epoch: 5/10, step 547/574 completed (loss: 0.018818052485585213, acc: 1.0)
[2024-11-13 05:24:07,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:07,883][root][INFO] - Training Epoch: 5/10, step 548/574 completed (loss: 0.013030366972088814, acc: 1.0)
[2024-11-13 05:24:07,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:08,230][root][INFO] - Training Epoch: 5/10, step 549/574 completed (loss: 0.05772734060883522, acc: 0.9599999785423279)
[2024-11-13 05:24:08,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:08,618][root][INFO] - Training Epoch: 5/10, step 550/574 completed (loss: 0.13937446475028992, acc: 0.939393937587738)
[2024-11-13 05:24:08,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:08,959][root][INFO] - Training Epoch: 5/10, step 551/574 completed (loss: 0.14392375946044922, acc: 0.925000011920929)
[2024-11-13 05:24:09,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:09,279][root][INFO] - Training Epoch: 5/10, step 552/574 completed (loss: 0.2599281370639801, acc: 0.9285714030265808)
[2024-11-13 05:24:09,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:09,577][root][INFO] - Training Epoch: 5/10, step 553/574 completed (loss: 0.426884263753891, acc: 0.8905109763145447)
[2024-11-13 05:24:09,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:09,921][root][INFO] - Training Epoch: 5/10, step 554/574 completed (loss: 0.16907918453216553, acc: 0.9448275566101074)
[2024-11-13 05:24:10,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:10,292][root][INFO] - Training Epoch: 5/10, step 555/574 completed (loss: 0.33256229758262634, acc: 0.8999999761581421)
[2024-11-13 05:24:10,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:10,651][root][INFO] - Training Epoch: 5/10, step 556/574 completed (loss: 0.4158017337322235, acc: 0.887417197227478)
[2024-11-13 05:24:10,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:11,047][root][INFO] - Training Epoch: 5/10, step 557/574 completed (loss: 0.159715473651886, acc: 0.9572649598121643)
[2024-11-13 05:24:11,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:11,425][root][INFO] - Training Epoch: 5/10, step 558/574 completed (loss: 0.2810520827770233, acc: 0.9599999785423279)
[2024-11-13 05:24:11,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:11,818][root][INFO] - Training Epoch: 5/10, step 559/574 completed (loss: 0.016926944255828857, acc: 1.0)
[2024-11-13 05:24:11,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:12,160][root][INFO] - Training Epoch: 5/10, step 560/574 completed (loss: 0.07560663670301437, acc: 0.9615384340286255)
[2024-11-13 05:24:12,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:12,514][root][INFO] - Training Epoch: 5/10, step 561/574 completed (loss: 0.4195147156715393, acc: 0.9230769276618958)
[2024-11-13 05:24:12,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:12,873][root][INFO] - Training Epoch: 5/10, step 562/574 completed (loss: 0.24815694987773895, acc: 0.8888888955116272)
[2024-11-13 05:24:12,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:13,181][root][INFO] - Training Epoch: 5/10, step 563/574 completed (loss: 0.16576115787029266, acc: 0.9350649118423462)
[2024-11-13 05:24:14,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:14,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:14,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:15,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:15,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:15,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:16,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:16,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:16,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:17,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:17,756][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:18,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:18,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:19,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:19,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:19,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:19,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:20,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:20,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:20,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:21,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:21,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:21,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:22,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:22,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:23,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:23,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:23,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:24,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:24,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:24,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:24,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:25,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:25,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:26,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:26,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:26,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:27,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:27,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:27,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:28,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:28,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:28,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:29,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:29,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:29,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:30,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:30,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:31,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:31,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:31,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:32,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:32,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:32,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:32,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:33,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:34,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:34,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:34,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:35,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:35,610][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:35,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:36,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:37,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:37,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:37,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:38,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:38,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:38,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:39,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:39,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:40,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:40,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:40,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:41,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:41,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:41,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:41,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:42,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:42,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:43,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:43,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:44,553][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3779, device='cuda:0') eval_epoch_loss=tensor(0.8662, device='cuda:0') eval_epoch_acc=tensor(0.7968, device='cuda:0')
[2024-11-13 05:24:44,555][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:24:44,555][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:24:44,870][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_5_step_564_loss_0.8662307858467102/model.pt
[2024-11-13 05:24:44,877][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:24:44,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:45,320][root][INFO] - Training Epoch: 5/10, step 564/574 completed (loss: 0.2621360123157501, acc: 0.9375)
[2024-11-13 05:24:45,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:45,653][root][INFO] - Training Epoch: 5/10, step 565/574 completed (loss: 0.2629808187484741, acc: 0.8965517282485962)
[2024-11-13 05:24:45,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:46,004][root][INFO] - Training Epoch: 5/10, step 566/574 completed (loss: 0.23308168351650238, acc: 0.9285714030265808)
[2024-11-13 05:24:46,095][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:46,332][root][INFO] - Training Epoch: 5/10, step 567/574 completed (loss: 0.04736225679516792, acc: 1.0)
[2024-11-13 05:24:46,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:46,665][root][INFO] - Training Epoch: 5/10, step 568/574 completed (loss: 0.1272578239440918, acc: 0.9629629850387573)
[2024-11-13 05:24:46,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:47,115][root][INFO] - Training Epoch: 5/10, step 569/574 completed (loss: 0.2937770187854767, acc: 0.9197860956192017)
[2024-11-13 05:24:47,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:47,528][root][INFO] - Training Epoch: 5/10, step 570/574 completed (loss: 0.05532307177782059, acc: 0.9838709831237793)
[2024-11-13 05:24:47,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:47,892][root][INFO] - Training Epoch: 5/10, step 571/574 completed (loss: 0.18980708718299866, acc: 0.9059829115867615)
[2024-11-13 05:24:47,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:48,208][root][INFO] - Training Epoch: 5/10, step 572/574 completed (loss: 0.5165456533432007, acc: 0.8469387888908386)
[2024-11-13 05:24:48,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:48,543][root][INFO] - Training Epoch: 5/10, step 573/574 completed (loss: 0.3820713460445404, acc: 0.8742138147354126)
[2024-11-13 05:24:49,083][slam_llm.utils.train_utils][INFO] - Epoch 5: train_perplexity=1.4557, train_epoch_loss=0.3755, epoch time 352.7136244866997s
[2024-11-13 05:24:49,083][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:24:49,083][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-13 05:24:49,083][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:24:49,084][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 14
[2024-11-13 05:24:49,084][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:24:49,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:49,986][root][INFO] - Training Epoch: 6/10, step 0/574 completed (loss: 0.043137259781360626, acc: 1.0)
[2024-11-13 05:24:50,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:50,321][root][INFO] - Training Epoch: 6/10, step 1/574 completed (loss: 0.3266000747680664, acc: 0.9200000166893005)
[2024-11-13 05:24:50,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:50,695][root][INFO] - Training Epoch: 6/10, step 2/574 completed (loss: 0.3797260522842407, acc: 0.8918918967247009)
[2024-11-13 05:24:50,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:51,093][root][INFO] - Training Epoch: 6/10, step 3/574 completed (loss: 0.13075222074985504, acc: 0.9473684430122375)
[2024-11-13 05:24:51,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:51,520][root][INFO] - Training Epoch: 6/10, step 4/574 completed (loss: 0.22549386322498322, acc: 0.9459459185600281)
[2024-11-13 05:24:51,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:51,895][root][INFO] - Training Epoch: 6/10, step 5/574 completed (loss: 0.08375026285648346, acc: 1.0)
[2024-11-13 05:24:52,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:52,284][root][INFO] - Training Epoch: 6/10, step 6/574 completed (loss: 0.42864367365837097, acc: 0.8979591727256775)
[2024-11-13 05:24:52,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:52,624][root][INFO] - Training Epoch: 6/10, step 7/574 completed (loss: 0.25275906920433044, acc: 0.9333333373069763)
[2024-11-13 05:24:52,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:52,992][root][INFO] - Training Epoch: 6/10, step 8/574 completed (loss: 0.10865616798400879, acc: 0.9545454382896423)
[2024-11-13 05:24:53,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:53,336][root][INFO] - Training Epoch: 6/10, step 9/574 completed (loss: 0.0645119696855545, acc: 0.9615384340286255)
[2024-11-13 05:24:53,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:53,675][root][INFO] - Training Epoch: 6/10, step 10/574 completed (loss: 0.07491633296012878, acc: 0.9629629850387573)
[2024-11-13 05:24:53,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:54,079][root][INFO] - Training Epoch: 6/10, step 11/574 completed (loss: 0.11545038223266602, acc: 0.8974359035491943)
[2024-11-13 05:24:54,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:54,486][root][INFO] - Training Epoch: 6/10, step 12/574 completed (loss: 0.03827589750289917, acc: 1.0)
[2024-11-13 05:24:54,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:54,846][root][INFO] - Training Epoch: 6/10, step 13/574 completed (loss: 0.10555203258991241, acc: 0.97826087474823)
[2024-11-13 05:24:54,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:55,154][root][INFO] - Training Epoch: 6/10, step 14/574 completed (loss: 0.04081038758158684, acc: 1.0)
[2024-11-13 05:24:55,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:55,492][root][INFO] - Training Epoch: 6/10, step 15/574 completed (loss: 0.2983907461166382, acc: 0.918367326259613)
[2024-11-13 05:24:55,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:55,874][root][INFO] - Training Epoch: 6/10, step 16/574 completed (loss: 0.05064385384321213, acc: 1.0)
[2024-11-13 05:24:55,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:56,203][root][INFO] - Training Epoch: 6/10, step 17/574 completed (loss: 0.39737212657928467, acc: 0.875)
[2024-11-13 05:24:56,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:56,523][root][INFO] - Training Epoch: 6/10, step 18/574 completed (loss: 0.32029107213020325, acc: 0.9444444179534912)
[2024-11-13 05:24:56,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:56,885][root][INFO] - Training Epoch: 6/10, step 19/574 completed (loss: 0.17247352004051208, acc: 0.8947368264198303)
[2024-11-13 05:24:56,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:57,247][root][INFO] - Training Epoch: 6/10, step 20/574 completed (loss: 0.39506134390830994, acc: 0.8846153616905212)
[2024-11-13 05:24:57,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:57,630][root][INFO] - Training Epoch: 6/10, step 21/574 completed (loss: 0.1278415322303772, acc: 0.931034505367279)
[2024-11-13 05:24:57,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:57,998][root][INFO] - Training Epoch: 6/10, step 22/574 completed (loss: 0.2629174590110779, acc: 0.8799999952316284)
[2024-11-13 05:24:58,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:58,345][root][INFO] - Training Epoch: 6/10, step 23/574 completed (loss: 0.2088654786348343, acc: 0.9047619104385376)
[2024-11-13 05:24:58,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:58,713][root][INFO] - Training Epoch: 6/10, step 24/574 completed (loss: 0.1036674752831459, acc: 0.9375)
[2024-11-13 05:24:58,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:59,069][root][INFO] - Training Epoch: 6/10, step 25/574 completed (loss: 0.39915481209754944, acc: 0.849056601524353)
[2024-11-13 05:24:59,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:24:59,404][root][INFO] - Training Epoch: 6/10, step 26/574 completed (loss: 0.7732855677604675, acc: 0.7945205569267273)
[2024-11-13 05:25:00,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:00,974][root][INFO] - Training Epoch: 6/10, step 27/574 completed (loss: 0.9650136232376099, acc: 0.7509881258010864)
[2024-11-13 05:25:01,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:01,282][root][INFO] - Training Epoch: 6/10, step 28/574 completed (loss: 0.34921795129776, acc: 0.8604651093482971)
[2024-11-13 05:25:01,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:01,666][root][INFO] - Training Epoch: 6/10, step 29/574 completed (loss: 0.46284881234169006, acc: 0.8674699068069458)
[2024-11-13 05:25:01,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:02,010][root][INFO] - Training Epoch: 6/10, step 30/574 completed (loss: 0.6757726073265076, acc: 0.8395061492919922)
[2024-11-13 05:25:02,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:02,324][root][INFO] - Training Epoch: 6/10, step 31/574 completed (loss: 0.2878054678440094, acc: 0.9285714030265808)
[2024-11-13 05:25:02,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:02,702][root][INFO] - Training Epoch: 6/10, step 32/574 completed (loss: 0.12469936907291412, acc: 0.9259259104728699)
[2024-11-13 05:25:02,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:03,079][root][INFO] - Training Epoch: 6/10, step 33/574 completed (loss: 0.08719196170568466, acc: 0.95652174949646)
[2024-11-13 05:25:03,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:03,461][root][INFO] - Training Epoch: 6/10, step 34/574 completed (loss: 0.4353158473968506, acc: 0.8655462265014648)
[2024-11-13 05:25:03,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:03,830][root][INFO] - Training Epoch: 6/10, step 35/574 completed (loss: 0.18126370012760162, acc: 0.9344262480735779)
[2024-11-13 05:25:03,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:04,234][root][INFO] - Training Epoch: 6/10, step 36/574 completed (loss: 0.41720524430274963, acc: 0.8730158805847168)
[2024-11-13 05:25:04,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:04,580][root][INFO] - Training Epoch: 6/10, step 37/574 completed (loss: 0.40940916538238525, acc: 0.9152542352676392)
[2024-11-13 05:25:04,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:04,958][root][INFO] - Training Epoch: 6/10, step 38/574 completed (loss: 0.21346454322338104, acc: 0.9195402264595032)
[2024-11-13 05:25:05,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:05,334][root][INFO] - Training Epoch: 6/10, step 39/574 completed (loss: 0.1127343624830246, acc: 1.0)
[2024-11-13 05:25:05,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:05,740][root][INFO] - Training Epoch: 6/10, step 40/574 completed (loss: 0.20167581737041473, acc: 0.9615384340286255)
[2024-11-13 05:25:05,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:06,168][root][INFO] - Training Epoch: 6/10, step 41/574 completed (loss: 0.2484743744134903, acc: 0.9054054021835327)
[2024-11-13 05:25:06,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:06,496][root][INFO] - Training Epoch: 6/10, step 42/574 completed (loss: 0.5210083723068237, acc: 0.8615384697914124)
[2024-11-13 05:25:06,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:06,904][root][INFO] - Training Epoch: 6/10, step 43/574 completed (loss: 0.42775964736938477, acc: 0.8888888955116272)
[2024-11-13 05:25:07,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:07,318][root][INFO] - Training Epoch: 6/10, step 44/574 completed (loss: 0.3138737082481384, acc: 0.907216489315033)
[2024-11-13 05:25:07,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:07,722][root][INFO] - Training Epoch: 6/10, step 45/574 completed (loss: 0.36440274119377136, acc: 0.8823529481887817)
[2024-11-13 05:25:07,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:08,034][root][INFO] - Training Epoch: 6/10, step 46/574 completed (loss: 0.05633978545665741, acc: 1.0)
[2024-11-13 05:25:08,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:08,402][root][INFO] - Training Epoch: 6/10, step 47/574 completed (loss: 0.11593437939882278, acc: 0.9629629850387573)
[2024-11-13 05:25:08,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:08,744][root][INFO] - Training Epoch: 6/10, step 48/574 completed (loss: 0.2994723618030548, acc: 0.8928571343421936)
[2024-11-13 05:25:08,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:09,129][root][INFO] - Training Epoch: 6/10, step 49/574 completed (loss: 0.04556029662489891, acc: 0.9722222089767456)
[2024-11-13 05:25:09,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:09,516][root][INFO] - Training Epoch: 6/10, step 50/574 completed (loss: 0.5068203806877136, acc: 0.8245614171028137)
[2024-11-13 05:25:09,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:09,935][root][INFO] - Training Epoch: 6/10, step 51/574 completed (loss: 0.4045880138874054, acc: 0.9047619104385376)
[2024-11-13 05:25:10,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:10,284][root][INFO] - Training Epoch: 6/10, step 52/574 completed (loss: 0.5661986470222473, acc: 0.7887324094772339)
[2024-11-13 05:25:10,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:10,733][root][INFO] - Training Epoch: 6/10, step 53/574 completed (loss: 1.122967004776001, acc: 0.7133333086967468)
[2024-11-13 05:25:10,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:11,028][root][INFO] - Training Epoch: 6/10, step 54/574 completed (loss: 0.2998248040676117, acc: 0.8648648858070374)
[2024-11-13 05:25:11,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:11,408][root][INFO] - Training Epoch: 6/10, step 55/574 completed (loss: 0.10026887059211731, acc: 0.9230769276618958)
[2024-11-13 05:25:12,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:14,422][root][INFO] - Training Epoch: 6/10, step 56/574 completed (loss: 1.0915900468826294, acc: 0.6996586918830872)
[2024-11-13 05:25:14,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:15,758][root][INFO] - Training Epoch: 6/10, step 57/574 completed (loss: 1.2231284379959106, acc: 0.6448801755905151)
[2024-11-13 05:25:15,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:16,382][root][INFO] - Training Epoch: 6/10, step 58/574 completed (loss: 0.6123594045639038, acc: 0.7954545617103577)
[2024-11-13 05:25:16,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:16,950][root][INFO] - Training Epoch: 6/10, step 59/574 completed (loss: 0.3388339579105377, acc: 0.8602941036224365)
[2024-11-13 05:25:17,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:17,518][root][INFO] - Training Epoch: 6/10, step 60/574 completed (loss: 0.7549703121185303, acc: 0.7681159377098083)
[2024-11-13 05:25:17,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:17,986][root][INFO] - Training Epoch: 6/10, step 61/574 completed (loss: 0.5557567477226257, acc: 0.824999988079071)
[2024-11-13 05:25:18,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:18,387][root][INFO] - Training Epoch: 6/10, step 62/574 completed (loss: 0.04738700017333031, acc: 1.0)
[2024-11-13 05:25:18,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:18,763][root][INFO] - Training Epoch: 6/10, step 63/574 completed (loss: 0.10235486924648285, acc: 0.9722222089767456)
[2024-11-13 05:25:18,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:19,113][root][INFO] - Training Epoch: 6/10, step 64/574 completed (loss: 0.12568047642707825, acc: 0.953125)
[2024-11-13 05:25:19,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:19,476][root][INFO] - Training Epoch: 6/10, step 65/574 completed (loss: 0.14802725613117218, acc: 0.931034505367279)
[2024-11-13 05:25:19,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:19,836][root][INFO] - Training Epoch: 6/10, step 66/574 completed (loss: 0.5775377154350281, acc: 0.7857142686843872)
[2024-11-13 05:25:19,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:20,223][root][INFO] - Training Epoch: 6/10, step 67/574 completed (loss: 0.2584402859210968, acc: 0.9166666865348816)
[2024-11-13 05:25:20,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:20,612][root][INFO] - Training Epoch: 6/10, step 68/574 completed (loss: 0.026770882308483124, acc: 1.0)
[2024-11-13 05:25:20,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:20,922][root][INFO] - Training Epoch: 6/10, step 69/574 completed (loss: 0.20339412987232208, acc: 0.9444444179534912)
[2024-11-13 05:25:21,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:21,280][root][INFO] - Training Epoch: 6/10, step 70/574 completed (loss: 0.1919853240251541, acc: 0.939393937587738)
[2024-11-13 05:25:21,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:21,692][root][INFO] - Training Epoch: 6/10, step 71/574 completed (loss: 0.6896601319313049, acc: 0.7941176295280457)
[2024-11-13 05:25:21,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:22,039][root][INFO] - Training Epoch: 6/10, step 72/574 completed (loss: 0.7039896249771118, acc: 0.7857142686843872)
[2024-11-13 05:25:22,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:22,422][root][INFO] - Training Epoch: 6/10, step 73/574 completed (loss: 1.2102714776992798, acc: 0.6461538672447205)
[2024-11-13 05:25:22,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:22,801][root][INFO] - Training Epoch: 6/10, step 74/574 completed (loss: 0.6437578201293945, acc: 0.8367347121238708)
[2024-11-13 05:25:22,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:23,134][root][INFO] - Training Epoch: 6/10, step 75/574 completed (loss: 0.7545719146728516, acc: 0.7910447716712952)
[2024-11-13 05:25:23,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:23,572][root][INFO] - Training Epoch: 6/10, step 76/574 completed (loss: 1.3003202676773071, acc: 0.6204379796981812)
[2024-11-13 05:25:23,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:23,936][root][INFO] - Training Epoch: 6/10, step 77/574 completed (loss: 0.00454676290974021, acc: 1.0)
[2024-11-13 05:25:24,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:24,317][root][INFO] - Training Epoch: 6/10, step 78/574 completed (loss: 0.03395454213023186, acc: 1.0)
[2024-11-13 05:25:24,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:24,706][root][INFO] - Training Epoch: 6/10, step 79/574 completed (loss: 0.09111596643924713, acc: 0.9696969985961914)
[2024-11-13 05:25:24,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:25,046][root][INFO] - Training Epoch: 6/10, step 80/574 completed (loss: 0.015624474734067917, acc: 1.0)
[2024-11-13 05:25:25,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:25,408][root][INFO] - Training Epoch: 6/10, step 81/574 completed (loss: 0.21671104431152344, acc: 0.9615384340286255)
[2024-11-13 05:25:25,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:25,815][root][INFO] - Training Epoch: 6/10, step 82/574 completed (loss: 0.4141829311847687, acc: 0.8846153616905212)
[2024-11-13 05:25:25,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:26,199][root][INFO] - Training Epoch: 6/10, step 83/574 completed (loss: 0.22300487756729126, acc: 0.9375)
[2024-11-13 05:25:26,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:26,598][root][INFO] - Training Epoch: 6/10, step 84/574 completed (loss: 0.1958191990852356, acc: 0.9420289993286133)
[2024-11-13 05:25:26,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:26,992][root][INFO] - Training Epoch: 6/10, step 85/574 completed (loss: 0.2593146860599518, acc: 0.8799999952316284)
[2024-11-13 05:25:27,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:27,403][root][INFO] - Training Epoch: 6/10, step 86/574 completed (loss: 0.1539340317249298, acc: 0.95652174949646)
[2024-11-13 05:25:27,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:27,872][root][INFO] - Training Epoch: 6/10, step 87/574 completed (loss: 0.3457738757133484, acc: 0.8799999952316284)
[2024-11-13 05:25:27,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:28,215][root][INFO] - Training Epoch: 6/10, step 88/574 completed (loss: 0.6716498136520386, acc: 0.8349514603614807)
[2024-11-13 05:25:28,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:29,324][root][INFO] - Training Epoch: 6/10, step 89/574 completed (loss: 0.7835617661476135, acc: 0.7766990065574646)
[2024-11-13 05:25:29,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:30,148][root][INFO] - Training Epoch: 6/10, step 90/574 completed (loss: 0.9519304037094116, acc: 0.7311828136444092)
[2024-11-13 05:25:30,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:30,949][root][INFO] - Training Epoch: 6/10, step 91/574 completed (loss: 0.8387940526008606, acc: 0.767241358757019)
[2024-11-13 05:25:31,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:31,697][root][INFO] - Training Epoch: 6/10, step 92/574 completed (loss: 0.6513770222663879, acc: 0.8105263113975525)
[2024-11-13 05:25:31,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:32,697][root][INFO] - Training Epoch: 6/10, step 93/574 completed (loss: 0.8682931661605835, acc: 0.7623762488365173)
[2024-11-13 05:25:32,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:33,048][root][INFO] - Training Epoch: 6/10, step 94/574 completed (loss: 0.6357249021530151, acc: 0.8225806355476379)
[2024-11-13 05:25:33,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:33,459][root][INFO] - Training Epoch: 6/10, step 95/574 completed (loss: 0.34829649329185486, acc: 0.8985507488250732)
[2024-11-13 05:25:33,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:33,868][root][INFO] - Training Epoch: 6/10, step 96/574 completed (loss: 0.7541651129722595, acc: 0.7647058963775635)
[2024-11-13 05:25:33,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:34,247][root][INFO] - Training Epoch: 6/10, step 97/574 completed (loss: 0.8914204835891724, acc: 0.7307692170143127)
[2024-11-13 05:25:34,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:34,635][root][INFO] - Training Epoch: 6/10, step 98/574 completed (loss: 1.03667414188385, acc: 0.6788321137428284)
[2024-11-13 05:25:34,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:34,984][root][INFO] - Training Epoch: 6/10, step 99/574 completed (loss: 0.6900545954704285, acc: 0.8059701323509216)
[2024-11-13 05:25:35,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:35,315][root][INFO] - Training Epoch: 6/10, step 100/574 completed (loss: 0.2183094024658203, acc: 0.8999999761581421)
[2024-11-13 05:25:35,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:35,718][root][INFO] - Training Epoch: 6/10, step 101/574 completed (loss: 0.009467764757573605, acc: 1.0)
[2024-11-13 05:25:35,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:36,048][root][INFO] - Training Epoch: 6/10, step 102/574 completed (loss: 0.01689048670232296, acc: 1.0)
[2024-11-13 05:25:36,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:36,372][root][INFO] - Training Epoch: 6/10, step 103/574 completed (loss: 0.01422132272273302, acc: 1.0)
[2024-11-13 05:25:36,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:36,682][root][INFO] - Training Epoch: 6/10, step 104/574 completed (loss: 0.255608469247818, acc: 0.9137930870056152)
[2024-11-13 05:25:36,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:36,998][root][INFO] - Training Epoch: 6/10, step 105/574 completed (loss: 0.13663873076438904, acc: 0.930232584476471)
[2024-11-13 05:25:37,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:37,295][root][INFO] - Training Epoch: 6/10, step 106/574 completed (loss: 0.14277051389217377, acc: 0.9599999785423279)
[2024-11-13 05:25:37,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:37,631][root][INFO] - Training Epoch: 6/10, step 107/574 completed (loss: 0.020784106105566025, acc: 1.0)
[2024-11-13 05:25:37,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:37,945][root][INFO] - Training Epoch: 6/10, step 108/574 completed (loss: 0.0014534768415614963, acc: 1.0)
[2024-11-13 05:25:38,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:38,238][root][INFO] - Training Epoch: 6/10, step 109/574 completed (loss: 0.04072562977671623, acc: 1.0)
[2024-11-13 05:25:38,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:38,608][root][INFO] - Training Epoch: 6/10, step 110/574 completed (loss: 0.12604063749313354, acc: 0.9692307710647583)
[2024-11-13 05:25:38,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:39,043][root][INFO] - Training Epoch: 6/10, step 111/574 completed (loss: 0.25238481163978577, acc: 0.8947368264198303)
[2024-11-13 05:25:39,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:39,415][root][INFO] - Training Epoch: 6/10, step 112/574 completed (loss: 0.5013540983200073, acc: 0.8421052694320679)
[2024-11-13 05:25:39,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:39,794][root][INFO] - Training Epoch: 6/10, step 113/574 completed (loss: 0.29263943433761597, acc: 0.9230769276618958)
[2024-11-13 05:25:39,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:40,162][root][INFO] - Training Epoch: 6/10, step 114/574 completed (loss: 0.2573166787624359, acc: 0.8979591727256775)
[2024-11-13 05:25:40,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:40,461][root][INFO] - Training Epoch: 6/10, step 115/574 completed (loss: 0.00697547011077404, acc: 1.0)
[2024-11-13 05:25:40,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:40,792][root][INFO] - Training Epoch: 6/10, step 116/574 completed (loss: 0.4374952018260956, acc: 0.9047619104385376)
[2024-11-13 05:25:40,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:41,131][root][INFO] - Training Epoch: 6/10, step 117/574 completed (loss: 0.3358819782733917, acc: 0.8943089246749878)
[2024-11-13 05:25:41,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:41,496][root][INFO] - Training Epoch: 6/10, step 118/574 completed (loss: 0.2143995314836502, acc: 0.9354838728904724)
[2024-11-13 05:25:41,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:42,403][root][INFO] - Training Epoch: 6/10, step 119/574 completed (loss: 0.8315392732620239, acc: 0.7908745408058167)
[2024-11-13 05:25:42,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:42,782][root][INFO] - Training Epoch: 6/10, step 120/574 completed (loss: 0.1525799036026001, acc: 0.9466666579246521)
[2024-11-13 05:25:42,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:43,231][root][INFO] - Training Epoch: 6/10, step 121/574 completed (loss: 0.15120093524456024, acc: 0.9615384340286255)
[2024-11-13 05:25:43,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:43,641][root][INFO] - Training Epoch: 6/10, step 122/574 completed (loss: 0.020518789067864418, acc: 1.0)
[2024-11-13 05:25:43,774][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:44,030][root][INFO] - Training Epoch: 6/10, step 123/574 completed (loss: 0.09847753494977951, acc: 0.9473684430122375)
[2024-11-13 05:25:44,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:44,415][root][INFO] - Training Epoch: 6/10, step 124/574 completed (loss: 0.7733557224273682, acc: 0.754601240158081)
[2024-11-13 05:25:44,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:44,779][root][INFO] - Training Epoch: 6/10, step 125/574 completed (loss: 1.0337626934051514, acc: 0.6944444179534912)
[2024-11-13 05:25:44,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:45,150][root][INFO] - Training Epoch: 6/10, step 126/574 completed (loss: 0.9158147573471069, acc: 0.7083333134651184)
[2024-11-13 05:25:45,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:45,558][root][INFO] - Training Epoch: 6/10, step 127/574 completed (loss: 0.7447739839553833, acc: 0.7797619104385376)
[2024-11-13 05:25:45,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:45,924][root][INFO] - Training Epoch: 6/10, step 128/574 completed (loss: 0.7573479413986206, acc: 0.8051282167434692)
[2024-11-13 05:25:46,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:46,326][root][INFO] - Training Epoch: 6/10, step 129/574 completed (loss: 0.7081582546234131, acc: 0.8161764740943909)
[2024-11-13 05:25:46,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:46,644][root][INFO] - Training Epoch: 6/10, step 130/574 completed (loss: 0.05861499533057213, acc: 1.0)
[2024-11-13 05:25:46,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:47,003][root][INFO] - Training Epoch: 6/10, step 131/574 completed (loss: 0.013370822183787823, acc: 1.0)
[2024-11-13 05:25:47,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:47,377][root][INFO] - Training Epoch: 6/10, step 132/574 completed (loss: 0.06041358411312103, acc: 1.0)
[2024-11-13 05:25:48,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:48,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:49,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:49,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:49,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:50,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:50,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:50,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:51,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:51,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:52,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:52,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:52,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:53,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:53,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:53,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:54,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:54,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:54,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:55,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:55,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:55,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:56,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:56,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:56,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:57,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:57,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:57,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:58,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:58,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:58,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:59,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:59,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:59,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:25:59,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:00,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:00,736][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:01,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:01,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:01,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:02,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:02,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:02,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:02,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:03,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:03,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:03,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:04,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:04,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:04,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:05,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:05,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:06,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:06,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:06,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:07,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:07,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:07,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:08,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:08,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:08,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:09,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:09,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:10,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:10,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:10,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:11,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:11,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:12,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:12,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:12,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:13,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:13,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:13,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:13,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:14,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:14,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:14,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:15,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:15,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:15,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:16,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:16,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:16,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:17,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:17,800][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3394, device='cuda:0') eval_epoch_loss=tensor(0.8499, device='cuda:0') eval_epoch_acc=tensor(0.7966, device='cuda:0')
[2024-11-13 05:26:17,802][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:26:17,802][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:26:18,050][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_6_step_133_loss_0.849901556968689/model.pt
[2024-11-13 05:26:18,058][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:26:18,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:18,453][root][INFO] - Training Epoch: 6/10, step 133/574 completed (loss: 0.17642101645469666, acc: 0.95652174949646)
[2024-11-13 05:26:18,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:18,849][root][INFO] - Training Epoch: 6/10, step 134/574 completed (loss: 0.22518374025821686, acc: 0.9142857193946838)
[2024-11-13 05:26:18,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:19,182][root][INFO] - Training Epoch: 6/10, step 135/574 completed (loss: 0.2771604657173157, acc: 0.9230769276618958)
[2024-11-13 05:26:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:19,478][root][INFO] - Training Epoch: 6/10, step 136/574 completed (loss: 0.1635848879814148, acc: 0.9285714030265808)
[2024-11-13 05:26:19,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:19,769][root][INFO] - Training Epoch: 6/10, step 137/574 completed (loss: 0.3990863561630249, acc: 0.8333333134651184)
[2024-11-13 05:26:19,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:20,065][root][INFO] - Training Epoch: 6/10, step 138/574 completed (loss: 0.3787654936313629, acc: 0.8695651888847351)
[2024-11-13 05:26:20,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:20,354][root][INFO] - Training Epoch: 6/10, step 139/574 completed (loss: 0.04750695452094078, acc: 1.0)
[2024-11-13 05:26:20,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:20,629][root][INFO] - Training Epoch: 6/10, step 140/574 completed (loss: 0.1312393695116043, acc: 0.9615384340286255)
[2024-11-13 05:26:20,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:20,920][root][INFO] - Training Epoch: 6/10, step 141/574 completed (loss: 0.13287170231342316, acc: 0.9677419066429138)
[2024-11-13 05:26:20,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:21,212][root][INFO] - Training Epoch: 6/10, step 142/574 completed (loss: 0.5550229549407959, acc: 0.8648648858070374)
[2024-11-13 05:26:21,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:21,733][root][INFO] - Training Epoch: 6/10, step 143/574 completed (loss: 0.5333842039108276, acc: 0.7894737124443054)
[2024-11-13 05:26:21,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:22,075][root][INFO] - Training Epoch: 6/10, step 144/574 completed (loss: 0.6267711520195007, acc: 0.8134328126907349)
[2024-11-13 05:26:22,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:22,428][root][INFO] - Training Epoch: 6/10, step 145/574 completed (loss: 0.47000473737716675, acc: 0.8367347121238708)
[2024-11-13 05:26:22,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:22,861][root][INFO] - Training Epoch: 6/10, step 146/574 completed (loss: 0.6216545104980469, acc: 0.7446808218955994)
[2024-11-13 05:26:22,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:23,159][root][INFO] - Training Epoch: 6/10, step 147/574 completed (loss: 0.46862363815307617, acc: 0.8714285492897034)
[2024-11-13 05:26:23,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:23,442][root][INFO] - Training Epoch: 6/10, step 148/574 completed (loss: 0.2231213003396988, acc: 0.9285714030265808)
[2024-11-13 05:26:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:23,736][root][INFO] - Training Epoch: 6/10, step 149/574 completed (loss: 0.03464299812912941, acc: 1.0)
[2024-11-13 05:26:23,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:24,040][root][INFO] - Training Epoch: 6/10, step 150/574 completed (loss: 0.08967674523591995, acc: 1.0)
[2024-11-13 05:26:24,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:24,346][root][INFO] - Training Epoch: 6/10, step 151/574 completed (loss: 0.47355228662490845, acc: 0.9130434989929199)
[2024-11-13 05:26:24,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:24,651][root][INFO] - Training Epoch: 6/10, step 152/574 completed (loss: 0.5025621652603149, acc: 0.8644067645072937)
[2024-11-13 05:26:24,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:24,951][root][INFO] - Training Epoch: 6/10, step 153/574 completed (loss: 0.37128520011901855, acc: 0.859649121761322)
[2024-11-13 05:26:25,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:25,266][root][INFO] - Training Epoch: 6/10, step 154/574 completed (loss: 0.5124327540397644, acc: 0.8243243098258972)
[2024-11-13 05:26:25,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:25,541][root][INFO] - Training Epoch: 6/10, step 155/574 completed (loss: 0.06155044585466385, acc: 1.0)
[2024-11-13 05:26:25,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:25,836][root][INFO] - Training Epoch: 6/10, step 156/574 completed (loss: 0.06531065702438354, acc: 1.0)
[2024-11-13 05:26:25,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:26,160][root][INFO] - Training Epoch: 6/10, step 157/574 completed (loss: 0.6859314441680908, acc: 0.7368420958518982)
[2024-11-13 05:26:26,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:27,866][root][INFO] - Training Epoch: 6/10, step 158/574 completed (loss: 0.5687963962554932, acc: 0.837837815284729)
[2024-11-13 05:26:27,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:28,138][root][INFO] - Training Epoch: 6/10, step 159/574 completed (loss: 0.8933433294296265, acc: 0.6851851940155029)
[2024-11-13 05:26:28,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:28,542][root][INFO] - Training Epoch: 6/10, step 160/574 completed (loss: 0.8057594299316406, acc: 0.7441860437393188)
[2024-11-13 05:26:28,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:29,134][root][INFO] - Training Epoch: 6/10, step 161/574 completed (loss: 0.8234630823135376, acc: 0.7764706015586853)
[2024-11-13 05:26:29,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:29,689][root][INFO] - Training Epoch: 6/10, step 162/574 completed (loss: 0.9821937680244446, acc: 0.7078651785850525)
[2024-11-13 05:26:29,781][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:30,005][root][INFO] - Training Epoch: 6/10, step 163/574 completed (loss: 0.23946291208267212, acc: 0.9545454382896423)
[2024-11-13 05:26:30,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:30,289][root][INFO] - Training Epoch: 6/10, step 164/574 completed (loss: 0.14750514924526215, acc: 0.9523809552192688)
[2024-11-13 05:26:30,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:30,586][root][INFO] - Training Epoch: 6/10, step 165/574 completed (loss: 0.5496826767921448, acc: 0.7931034564971924)
[2024-11-13 05:26:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:30,895][root][INFO] - Training Epoch: 6/10, step 166/574 completed (loss: 0.2071443349123001, acc: 0.918367326259613)
[2024-11-13 05:26:30,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:31,186][root][INFO] - Training Epoch: 6/10, step 167/574 completed (loss: 0.11969722807407379, acc: 0.9800000190734863)
[2024-11-13 05:26:31,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:31,577][root][INFO] - Training Epoch: 6/10, step 168/574 completed (loss: 0.40754270553588867, acc: 0.9027777910232544)
[2024-11-13 05:26:31,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:31,881][root][INFO] - Training Epoch: 6/10, step 169/574 completed (loss: 1.098493218421936, acc: 0.6764705777168274)
[2024-11-13 05:26:32,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:32,907][root][INFO] - Training Epoch: 6/10, step 170/574 completed (loss: 0.7197214961051941, acc: 0.7945205569267273)
[2024-11-13 05:26:32,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:33,200][root][INFO] - Training Epoch: 6/10, step 171/574 completed (loss: 0.012197941541671753, acc: 1.0)
[2024-11-13 05:26:33,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:33,492][root][INFO] - Training Epoch: 6/10, step 172/574 completed (loss: 0.21564553678035736, acc: 0.9259259104728699)
[2024-11-13 05:26:33,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:33,821][root][INFO] - Training Epoch: 6/10, step 173/574 completed (loss: 0.07485949993133545, acc: 1.0)
[2024-11-13 05:26:33,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:34,358][root][INFO] - Training Epoch: 6/10, step 174/574 completed (loss: 0.7875210046768188, acc: 0.8053097128868103)
[2024-11-13 05:26:34,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:34,651][root][INFO] - Training Epoch: 6/10, step 175/574 completed (loss: 0.5151397585868835, acc: 0.7971014380455017)
[2024-11-13 05:26:34,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:34,951][root][INFO] - Training Epoch: 6/10, step 176/574 completed (loss: 0.35561370849609375, acc: 0.8863636255264282)
[2024-11-13 05:26:35,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:35,877][root][INFO] - Training Epoch: 6/10, step 177/574 completed (loss: 0.9318190217018127, acc: 0.694656491279602)
[2024-11-13 05:26:36,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:36,558][root][INFO] - Training Epoch: 6/10, step 178/574 completed (loss: 0.7627725601196289, acc: 0.8370370268821716)
[2024-11-13 05:26:36,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:36,900][root][INFO] - Training Epoch: 6/10, step 179/574 completed (loss: 0.22040534019470215, acc: 0.9180327653884888)
[2024-11-13 05:26:37,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:37,235][root][INFO] - Training Epoch: 6/10, step 180/574 completed (loss: 0.07193690538406372, acc: 0.9583333134651184)
[2024-11-13 05:26:37,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:37,543][root][INFO] - Training Epoch: 6/10, step 181/574 completed (loss: 0.029951773583889008, acc: 1.0)
[2024-11-13 05:26:37,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:37,843][root][INFO] - Training Epoch: 6/10, step 182/574 completed (loss: 0.05614462494850159, acc: 1.0)
[2024-11-13 05:26:37,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:38,167][root][INFO] - Training Epoch: 6/10, step 183/574 completed (loss: 0.18776430189609528, acc: 0.9512194991111755)
[2024-11-13 05:26:38,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:38,534][root][INFO] - Training Epoch: 6/10, step 184/574 completed (loss: 0.605708122253418, acc: 0.8580060601234436)
[2024-11-13 05:26:38,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:38,887][root][INFO] - Training Epoch: 6/10, step 185/574 completed (loss: 0.6149747371673584, acc: 0.8213256597518921)
[2024-11-13 05:26:39,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:39,367][root][INFO] - Training Epoch: 6/10, step 186/574 completed (loss: 0.5756015181541443, acc: 0.8125)
[2024-11-13 05:26:39,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:39,892][root][INFO] - Training Epoch: 6/10, step 187/574 completed (loss: 0.732652485370636, acc: 0.8067542314529419)
[2024-11-13 05:26:39,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:40,287][root][INFO] - Training Epoch: 6/10, step 188/574 completed (loss: 0.5939528942108154, acc: 0.8256227970123291)
[2024-11-13 05:26:40,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:40,579][root][INFO] - Training Epoch: 6/10, step 189/574 completed (loss: 0.025775255635380745, acc: 1.0)
[2024-11-13 05:26:40,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:41,127][root][INFO] - Training Epoch: 6/10, step 190/574 completed (loss: 0.689873456954956, acc: 0.7441860437393188)
[2024-11-13 05:26:41,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:41,929][root][INFO] - Training Epoch: 6/10, step 191/574 completed (loss: 0.925948977470398, acc: 0.7460317611694336)
[2024-11-13 05:26:42,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:42,847][root][INFO] - Training Epoch: 6/10, step 192/574 completed (loss: 0.7683955430984497, acc: 0.7803030014038086)
[2024-11-13 05:26:43,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:43,589][root][INFO] - Training Epoch: 6/10, step 193/574 completed (loss: 0.35993796586990356, acc: 0.9058823585510254)
[2024-11-13 05:26:43,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:44,667][root][INFO] - Training Epoch: 6/10, step 194/574 completed (loss: 0.8214699029922485, acc: 0.7469135522842407)
[2024-11-13 05:26:44,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:45,624][root][INFO] - Training Epoch: 6/10, step 195/574 completed (loss: 0.21245934069156647, acc: 0.9193548560142517)
[2024-11-13 05:26:45,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:45,900][root][INFO] - Training Epoch: 6/10, step 196/574 completed (loss: 0.07602669298648834, acc: 0.9642857313156128)
[2024-11-13 05:26:46,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:46,223][root][INFO] - Training Epoch: 6/10, step 197/574 completed (loss: 0.19315609335899353, acc: 0.925000011920929)
[2024-11-13 05:26:46,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:46,541][root][INFO] - Training Epoch: 6/10, step 198/574 completed (loss: 0.4027080237865448, acc: 0.8676470518112183)
[2024-11-13 05:26:46,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:46,885][root][INFO] - Training Epoch: 6/10, step 199/574 completed (loss: 0.6647941470146179, acc: 0.7867646813392639)
[2024-11-13 05:26:46,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:47,214][root][INFO] - Training Epoch: 6/10, step 200/574 completed (loss: 0.6311911344528198, acc: 0.7796609997749329)
[2024-11-13 05:26:47,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:47,532][root][INFO] - Training Epoch: 6/10, step 201/574 completed (loss: 0.5684384107589722, acc: 0.8134328126907349)
[2024-11-13 05:26:47,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:47,884][root][INFO] - Training Epoch: 6/10, step 202/574 completed (loss: 0.7042745351791382, acc: 0.7961165308952332)
[2024-11-13 05:26:47,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:48,223][root][INFO] - Training Epoch: 6/10, step 203/574 completed (loss: 0.43836313486099243, acc: 0.8253968358039856)
[2024-11-13 05:26:48,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:48,537][root][INFO] - Training Epoch: 6/10, step 204/574 completed (loss: 0.10687699168920517, acc: 0.9450549483299255)
[2024-11-13 05:26:48,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:48,884][root][INFO] - Training Epoch: 6/10, step 205/574 completed (loss: 0.23686213791370392, acc: 0.9192824959754944)
[2024-11-13 05:26:48,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:49,271][root][INFO] - Training Epoch: 6/10, step 206/574 completed (loss: 0.51032954454422, acc: 0.8543307185173035)
[2024-11-13 05:26:49,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:49,579][root][INFO] - Training Epoch: 6/10, step 207/574 completed (loss: 0.406034380197525, acc: 0.8965517282485962)
[2024-11-13 05:26:49,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:49,910][root][INFO] - Training Epoch: 6/10, step 208/574 completed (loss: 0.41041478514671326, acc: 0.8804348111152649)
[2024-11-13 05:26:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:50,263][root][INFO] - Training Epoch: 6/10, step 209/574 completed (loss: 0.3184053301811218, acc: 0.9066147804260254)
[2024-11-13 05:26:50,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:50,599][root][INFO] - Training Epoch: 6/10, step 210/574 completed (loss: 0.2202121913433075, acc: 0.945652186870575)
[2024-11-13 05:26:50,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:50,906][root][INFO] - Training Epoch: 6/10, step 211/574 completed (loss: 0.14685717225074768, acc: 0.95652174949646)
[2024-11-13 05:26:51,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:51,273][root][INFO] - Training Epoch: 6/10, step 212/574 completed (loss: 0.04641193524003029, acc: 0.9642857313156128)
[2024-11-13 05:26:51,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:51,640][root][INFO] - Training Epoch: 6/10, step 213/574 completed (loss: 0.12145902961492538, acc: 0.957446813583374)
[2024-11-13 05:26:51,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:52,327][root][INFO] - Training Epoch: 6/10, step 214/574 completed (loss: 0.13386666774749756, acc: 0.9769230484962463)
[2024-11-13 05:26:52,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:52,740][root][INFO] - Training Epoch: 6/10, step 215/574 completed (loss: 0.0767647996544838, acc: 0.9864864945411682)
[2024-11-13 05:26:52,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:53,130][root][INFO] - Training Epoch: 6/10, step 216/574 completed (loss: 0.09280750900506973, acc: 0.9651162624359131)
[2024-11-13 05:26:53,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:53,665][root][INFO] - Training Epoch: 6/10, step 217/574 completed (loss: 0.24471306800842285, acc: 0.9459459185600281)
[2024-11-13 05:26:53,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:54,066][root][INFO] - Training Epoch: 6/10, step 218/574 completed (loss: 0.1312088668346405, acc: 0.9555555582046509)
[2024-11-13 05:26:54,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:54,367][root][INFO] - Training Epoch: 6/10, step 219/574 completed (loss: 0.10595852881669998, acc: 0.9696969985961914)
[2024-11-13 05:26:54,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:54,721][root][INFO] - Training Epoch: 6/10, step 220/574 completed (loss: 0.00647020572796464, acc: 1.0)
[2024-11-13 05:26:54,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:55,054][root][INFO] - Training Epoch: 6/10, step 221/574 completed (loss: 0.01715897209942341, acc: 1.0)
[2024-11-13 05:26:55,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:55,435][root][INFO] - Training Epoch: 6/10, step 222/574 completed (loss: 0.3170352578163147, acc: 0.8846153616905212)
[2024-11-13 05:26:55,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:56,196][root][INFO] - Training Epoch: 6/10, step 223/574 completed (loss: 0.41606733202934265, acc: 0.89673912525177)
[2024-11-13 05:26:56,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:56,745][root][INFO] - Training Epoch: 6/10, step 224/574 completed (loss: 0.5550711750984192, acc: 0.8238636255264282)
[2024-11-13 05:26:56,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:57,194][root][INFO] - Training Epoch: 6/10, step 225/574 completed (loss: 0.5641563534736633, acc: 0.7872340679168701)
[2024-11-13 05:26:57,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:57,545][root][INFO] - Training Epoch: 6/10, step 226/574 completed (loss: 0.13784554600715637, acc: 0.9811320900917053)
[2024-11-13 05:26:57,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:57,915][root][INFO] - Training Epoch: 6/10, step 227/574 completed (loss: 0.2689654529094696, acc: 0.8999999761581421)
[2024-11-13 05:26:58,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:58,320][root][INFO] - Training Epoch: 6/10, step 228/574 completed (loss: 0.09072469174861908, acc: 0.9534883499145508)
[2024-11-13 05:26:58,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:58,641][root][INFO] - Training Epoch: 6/10, step 229/574 completed (loss: 0.3037213683128357, acc: 0.9666666388511658)
[2024-11-13 05:26:58,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:59,046][root][INFO] - Training Epoch: 6/10, step 230/574 completed (loss: 1.3548767566680908, acc: 0.6315789222717285)
[2024-11-13 05:26:59,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:59,423][root][INFO] - Training Epoch: 6/10, step 231/574 completed (loss: 1.133199691772461, acc: 0.6333333253860474)
[2024-11-13 05:26:59,575][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:26:59,838][root][INFO] - Training Epoch: 6/10, step 232/574 completed (loss: 0.9747065305709839, acc: 0.7222222089767456)
[2024-11-13 05:26:59,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:00,325][root][INFO] - Training Epoch: 6/10, step 233/574 completed (loss: 1.4225654602050781, acc: 0.60550457239151)
[2024-11-13 05:27:00,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:00,791][root][INFO] - Training Epoch: 6/10, step 234/574 completed (loss: 1.0141311883926392, acc: 0.692307710647583)
[2024-11-13 05:27:00,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:01,093][root][INFO] - Training Epoch: 6/10, step 235/574 completed (loss: 0.011212521232664585, acc: 1.0)
[2024-11-13 05:27:01,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:01,403][root][INFO] - Training Epoch: 6/10, step 236/574 completed (loss: 0.2624092698097229, acc: 0.9583333134651184)
[2024-11-13 05:27:01,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:01,710][root][INFO] - Training Epoch: 6/10, step 237/574 completed (loss: 0.176747664809227, acc: 0.9090909361839294)
[2024-11-13 05:27:01,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:02,055][root][INFO] - Training Epoch: 6/10, step 238/574 completed (loss: 0.17963507771492004, acc: 0.9259259104728699)
[2024-11-13 05:27:02,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:02,427][root][INFO] - Training Epoch: 6/10, step 239/574 completed (loss: 0.19555887579917908, acc: 0.9142857193946838)
[2024-11-13 05:27:02,557][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:02,815][root][INFO] - Training Epoch: 6/10, step 240/574 completed (loss: 0.5257073640823364, acc: 0.8409090638160706)
[2024-11-13 05:27:02,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:03,178][root][INFO] - Training Epoch: 6/10, step 241/574 completed (loss: 0.3163478374481201, acc: 0.8863636255264282)
[2024-11-13 05:27:03,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:03,763][root][INFO] - Training Epoch: 6/10, step 242/574 completed (loss: 0.7284940481185913, acc: 0.7419354915618896)
[2024-11-13 05:27:03,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:04,297][root][INFO] - Training Epoch: 6/10, step 243/574 completed (loss: 0.6591305732727051, acc: 0.8181818127632141)
[2024-11-13 05:27:04,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:04,639][root][INFO] - Training Epoch: 6/10, step 244/574 completed (loss: 0.002714333590120077, acc: 1.0)
[2024-11-13 05:27:04,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:05,027][root][INFO] - Training Epoch: 6/10, step 245/574 completed (loss: 0.14178910851478577, acc: 0.9230769276618958)
[2024-11-13 05:27:05,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:05,365][root][INFO] - Training Epoch: 6/10, step 246/574 completed (loss: 0.007657904177904129, acc: 1.0)
[2024-11-13 05:27:05,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:05,637][root][INFO] - Training Epoch: 6/10, step 247/574 completed (loss: 0.05396318435668945, acc: 1.0)
[2024-11-13 05:27:05,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:05,951][root][INFO] - Training Epoch: 6/10, step 248/574 completed (loss: 0.2431165874004364, acc: 0.9459459185600281)
[2024-11-13 05:27:06,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:06,242][root][INFO] - Training Epoch: 6/10, step 249/574 completed (loss: 0.13019753992557526, acc: 0.9729729890823364)
[2024-11-13 05:27:06,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:06,615][root][INFO] - Training Epoch: 6/10, step 250/574 completed (loss: 0.03557896986603737, acc: 1.0)
[2024-11-13 05:27:06,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:06,979][root][INFO] - Training Epoch: 6/10, step 251/574 completed (loss: 0.1277124136686325, acc: 0.9558823704719543)
[2024-11-13 05:27:07,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:07,348][root][INFO] - Training Epoch: 6/10, step 252/574 completed (loss: 0.04071029648184776, acc: 1.0)
[2024-11-13 05:27:07,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:07,668][root][INFO] - Training Epoch: 6/10, step 253/574 completed (loss: 0.0043360767886042595, acc: 1.0)
[2024-11-13 05:27:07,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:07,982][root][INFO] - Training Epoch: 6/10, step 254/574 completed (loss: 0.0017718812450766563, acc: 1.0)
[2024-11-13 05:27:08,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:08,336][root][INFO] - Training Epoch: 6/10, step 255/574 completed (loss: 0.010808970779180527, acc: 1.0)
[2024-11-13 05:27:08,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:08,718][root][INFO] - Training Epoch: 6/10, step 256/574 completed (loss: 0.09449939429759979, acc: 0.9824561476707458)
[2024-11-13 05:27:08,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:09,123][root][INFO] - Training Epoch: 6/10, step 257/574 completed (loss: 0.16430990397930145, acc: 0.9428571462631226)
[2024-11-13 05:27:09,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:09,523][root][INFO] - Training Epoch: 6/10, step 258/574 completed (loss: 0.1898711919784546, acc: 0.9605262875556946)
[2024-11-13 05:27:09,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:10,086][root][INFO] - Training Epoch: 6/10, step 259/574 completed (loss: 0.3932914137840271, acc: 0.8867924809455872)
[2024-11-13 05:27:10,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:10,667][root][INFO] - Training Epoch: 6/10, step 260/574 completed (loss: 0.4399057924747467, acc: 0.875)
[2024-11-13 05:27:10,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:11,041][root][INFO] - Training Epoch: 6/10, step 261/574 completed (loss: 0.08355316519737244, acc: 0.9722222089767456)
[2024-11-13 05:27:11,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:11,419][root][INFO] - Training Epoch: 6/10, step 262/574 completed (loss: 0.07046069949865341, acc: 1.0)
[2024-11-13 05:27:11,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:11,741][root][INFO] - Training Epoch: 6/10, step 263/574 completed (loss: 0.6850985884666443, acc: 0.746666669845581)
[2024-11-13 05:27:11,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:12,072][root][INFO] - Training Epoch: 6/10, step 264/574 completed (loss: 0.4260273873806, acc: 0.8541666865348816)
[2024-11-13 05:27:12,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:12,910][root][INFO] - Training Epoch: 6/10, step 265/574 completed (loss: 0.9808217883110046, acc: 0.7039999961853027)
[2024-11-13 05:27:13,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:13,284][root][INFO] - Training Epoch: 6/10, step 266/574 completed (loss: 0.8130064606666565, acc: 0.7415730357170105)
[2024-11-13 05:27:13,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:13,635][root][INFO] - Training Epoch: 6/10, step 267/574 completed (loss: 0.544765055179596, acc: 0.8108108043670654)
[2024-11-13 05:27:13,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:14,087][root][INFO] - Training Epoch: 6/10, step 268/574 completed (loss: 0.27272409200668335, acc: 0.931034505367279)
[2024-11-13 05:27:14,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:14,439][root][INFO] - Training Epoch: 6/10, step 269/574 completed (loss: 0.021373076364398003, acc: 1.0)
[2024-11-13 05:27:14,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:14,756][root][INFO] - Training Epoch: 6/10, step 270/574 completed (loss: 0.02252066880464554, acc: 1.0)
[2024-11-13 05:27:14,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:15,121][root][INFO] - Training Epoch: 6/10, step 271/574 completed (loss: 0.024027083069086075, acc: 1.0)
[2024-11-13 05:27:15,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:15,487][root][INFO] - Training Epoch: 6/10, step 272/574 completed (loss: 0.035443004220724106, acc: 0.9666666388511658)
[2024-11-13 05:27:15,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:15,859][root][INFO] - Training Epoch: 6/10, step 273/574 completed (loss: 0.14212583005428314, acc: 0.9666666388511658)
[2024-11-13 05:27:15,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:16,208][root][INFO] - Training Epoch: 6/10, step 274/574 completed (loss: 0.12514472007751465, acc: 0.9375)
[2024-11-13 05:27:16,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:16,590][root][INFO] - Training Epoch: 6/10, step 275/574 completed (loss: 0.03392026573419571, acc: 1.0)
[2024-11-13 05:27:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:17,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:18,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:18,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:18,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:19,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:19,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:19,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:20,256][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:20,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:20,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:21,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:21,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:21,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:22,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:22,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:23,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:23,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:23,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:24,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:24,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:24,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:25,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:25,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:25,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:26,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:26,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:26,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:27,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:27,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:27,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:28,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:28,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:29,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:29,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:29,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:30,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:30,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:30,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:31,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:31,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:31,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:32,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:32,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:32,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:33,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:33,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:33,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:34,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:34,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:34,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:35,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:35,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:35,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:36,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:36,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:36,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:37,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:37,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:37,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:38,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:38,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:39,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:39,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:39,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:40,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:40,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:40,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:41,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:41,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:41,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:42,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:42,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:43,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:43,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:43,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:43,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:44,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:44,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:44,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:45,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:45,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:45,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:46,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:46,848][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5076, device='cuda:0') eval_epoch_loss=tensor(0.9193, device='cuda:0') eval_epoch_acc=tensor(0.7859, device='cuda:0')
[2024-11-13 05:27:46,850][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:27:46,850][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:27:47,095][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_6_step_276_loss_0.919317901134491/model.pt
[2024-11-13 05:27:47,105][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:27:47,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:47,501][root][INFO] - Training Epoch: 6/10, step 276/574 completed (loss: 0.23702223598957062, acc: 0.9655172228813171)
[2024-11-13 05:27:47,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:47,845][root][INFO] - Training Epoch: 6/10, step 277/574 completed (loss: 0.044426288455724716, acc: 1.0)
[2024-11-13 05:27:47,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:48,197][root][INFO] - Training Epoch: 6/10, step 278/574 completed (loss: 0.2894517183303833, acc: 0.8723404407501221)
[2024-11-13 05:27:48,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:48,508][root][INFO] - Training Epoch: 6/10, step 279/574 completed (loss: 0.40735873579978943, acc: 0.8958333134651184)
[2024-11-13 05:27:48,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:48,818][root][INFO] - Training Epoch: 6/10, step 280/574 completed (loss: 0.05192776024341583, acc: 0.9772727489471436)
[2024-11-13 05:27:48,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:49,228][root][INFO] - Training Epoch: 6/10, step 281/574 completed (loss: 0.8275818228721619, acc: 0.759036123752594)
[2024-11-13 05:27:49,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:49,583][root][INFO] - Training Epoch: 6/10, step 282/574 completed (loss: 0.7751414775848389, acc: 0.7777777910232544)
[2024-11-13 05:27:49,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:49,922][root][INFO] - Training Epoch: 6/10, step 283/574 completed (loss: 0.029553469270467758, acc: 1.0)
[2024-11-13 05:27:50,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:50,236][root][INFO] - Training Epoch: 6/10, step 284/574 completed (loss: 0.09119293838739395, acc: 0.970588207244873)
[2024-11-13 05:27:50,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:50,554][root][INFO] - Training Epoch: 6/10, step 285/574 completed (loss: 0.17190760374069214, acc: 0.8999999761581421)
[2024-11-13 05:27:50,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:50,854][root][INFO] - Training Epoch: 6/10, step 286/574 completed (loss: 0.34523841738700867, acc: 0.90625)
[2024-11-13 05:27:50,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:51,226][root][INFO] - Training Epoch: 6/10, step 287/574 completed (loss: 0.35437068343162537, acc: 0.9120000004768372)
[2024-11-13 05:27:51,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:51,570][root][INFO] - Training Epoch: 6/10, step 288/574 completed (loss: 0.2748161256313324, acc: 0.9450549483299255)
[2024-11-13 05:27:51,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:51,911][root][INFO] - Training Epoch: 6/10, step 289/574 completed (loss: 0.3186357617378235, acc: 0.8944099545478821)
[2024-11-13 05:27:51,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:52,244][root][INFO] - Training Epoch: 6/10, step 290/574 completed (loss: 0.6289170384407043, acc: 0.8402062058448792)
[2024-11-13 05:27:52,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:52,554][root][INFO] - Training Epoch: 6/10, step 291/574 completed (loss: 0.1169854924082756, acc: 0.9545454382896423)
[2024-11-13 05:27:52,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:52,888][root][INFO] - Training Epoch: 6/10, step 292/574 completed (loss: 0.23217809200286865, acc: 0.9285714030265808)
[2024-11-13 05:27:52,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:53,217][root][INFO] - Training Epoch: 6/10, step 293/574 completed (loss: 0.11053810268640518, acc: 0.9482758641242981)
[2024-11-13 05:27:53,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:53,685][root][INFO] - Training Epoch: 6/10, step 294/574 completed (loss: 0.2619342803955078, acc: 0.9454545378684998)
[2024-11-13 05:27:53,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:54,231][root][INFO] - Training Epoch: 6/10, step 295/574 completed (loss: 0.7376940846443176, acc: 0.8195876479148865)
[2024-11-13 05:27:54,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:54,542][root][INFO] - Training Epoch: 6/10, step 296/574 completed (loss: 0.3425742983818054, acc: 0.8793103694915771)
[2024-11-13 05:27:54,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:54,897][root][INFO] - Training Epoch: 6/10, step 297/574 completed (loss: 0.06662067025899887, acc: 0.9629629850387573)
[2024-11-13 05:27:54,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:55,213][root][INFO] - Training Epoch: 6/10, step 298/574 completed (loss: 0.29716911911964417, acc: 0.8684210777282715)
[2024-11-13 05:27:55,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:55,519][root][INFO] - Training Epoch: 6/10, step 299/574 completed (loss: 0.08575177937746048, acc: 0.9464285969734192)
[2024-11-13 05:27:55,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:55,923][root][INFO] - Training Epoch: 6/10, step 300/574 completed (loss: 0.009892230853438377, acc: 1.0)
[2024-11-13 05:27:56,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:56,269][root][INFO] - Training Epoch: 6/10, step 301/574 completed (loss: 0.056228797882795334, acc: 0.9811320900917053)
[2024-11-13 05:27:56,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:56,606][root][INFO] - Training Epoch: 6/10, step 302/574 completed (loss: 0.04281061887741089, acc: 0.9811320900917053)
[2024-11-13 05:27:56,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:56,911][root][INFO] - Training Epoch: 6/10, step 303/574 completed (loss: 0.15606297552585602, acc: 0.970588207244873)
[2024-11-13 05:27:57,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:57,234][root][INFO] - Training Epoch: 6/10, step 304/574 completed (loss: 0.016389422118663788, acc: 1.0)
[2024-11-13 05:27:57,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:57,555][root][INFO] - Training Epoch: 6/10, step 305/574 completed (loss: 0.1719571352005005, acc: 0.9672130942344666)
[2024-11-13 05:27:57,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:57,839][root][INFO] - Training Epoch: 6/10, step 306/574 completed (loss: 0.03295133262872696, acc: 1.0)
[2024-11-13 05:27:57,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:58,138][root][INFO] - Training Epoch: 6/10, step 307/574 completed (loss: 0.006052664015442133, acc: 1.0)
[2024-11-13 05:27:58,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:58,450][root][INFO] - Training Epoch: 6/10, step 308/574 completed (loss: 0.2430749088525772, acc: 0.9130434989929199)
[2024-11-13 05:27:58,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:58,858][root][INFO] - Training Epoch: 6/10, step 309/574 completed (loss: 0.2263774573802948, acc: 0.9166666865348816)
[2024-11-13 05:27:58,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:59,171][root][INFO] - Training Epoch: 6/10, step 310/574 completed (loss: 0.19011464715003967, acc: 0.9518072009086609)
[2024-11-13 05:27:59,278][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:59,512][root][INFO] - Training Epoch: 6/10, step 311/574 completed (loss: 0.2998586595058441, acc: 0.9487179517745972)
[2024-11-13 05:27:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:27:59,868][root][INFO] - Training Epoch: 6/10, step 312/574 completed (loss: 0.11952264606952667, acc: 0.9489796161651611)
[2024-11-13 05:27:59,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:00,223][root][INFO] - Training Epoch: 6/10, step 313/574 completed (loss: 0.04090708866715431, acc: 1.0)
[2024-11-13 05:28:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:00,553][root][INFO] - Training Epoch: 6/10, step 314/574 completed (loss: 0.029569663107395172, acc: 1.0)
[2024-11-13 05:28:00,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:00,858][root][INFO] - Training Epoch: 6/10, step 315/574 completed (loss: 0.04999733716249466, acc: 0.9677419066429138)
[2024-11-13 05:28:00,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:01,185][root][INFO] - Training Epoch: 6/10, step 316/574 completed (loss: 0.3978482782840729, acc: 0.9032257795333862)
[2024-11-13 05:28:01,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:01,522][root][INFO] - Training Epoch: 6/10, step 317/574 completed (loss: 0.10233532637357712, acc: 0.9552238583564758)
[2024-11-13 05:28:01,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:01,832][root][INFO] - Training Epoch: 6/10, step 318/574 completed (loss: 0.10135690122842789, acc: 0.9711538553237915)
[2024-11-13 05:28:01,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:02,198][root][INFO] - Training Epoch: 6/10, step 319/574 completed (loss: 0.06317251920700073, acc: 0.9555555582046509)
[2024-11-13 05:28:02,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:02,543][root][INFO] - Training Epoch: 6/10, step 320/574 completed (loss: 0.039592768996953964, acc: 0.9838709831237793)
[2024-11-13 05:28:02,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:02,869][root][INFO] - Training Epoch: 6/10, step 321/574 completed (loss: 0.007258676458150148, acc: 1.0)
[2024-11-13 05:28:02,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:03,199][root][INFO] - Training Epoch: 6/10, step 322/574 completed (loss: 0.5297603607177734, acc: 0.7407407164573669)
[2024-11-13 05:28:03,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:03,551][root][INFO] - Training Epoch: 6/10, step 323/574 completed (loss: 0.5514212250709534, acc: 0.9142857193946838)
[2024-11-13 05:28:03,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:03,889][root][INFO] - Training Epoch: 6/10, step 324/574 completed (loss: 0.42983171343803406, acc: 0.8974359035491943)
[2024-11-13 05:28:03,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:04,194][root][INFO] - Training Epoch: 6/10, step 325/574 completed (loss: 0.6424039006233215, acc: 0.8780487775802612)
[2024-11-13 05:28:04,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:04,511][root][INFO] - Training Epoch: 6/10, step 326/574 completed (loss: 0.4210280179977417, acc: 0.8684210777282715)
[2024-11-13 05:28:04,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:04,817][root][INFO] - Training Epoch: 6/10, step 327/574 completed (loss: 0.036320775747299194, acc: 1.0)
[2024-11-13 05:28:04,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:05,107][root][INFO] - Training Epoch: 6/10, step 328/574 completed (loss: 0.02586944028735161, acc: 1.0)
[2024-11-13 05:28:05,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:05,410][root][INFO] - Training Epoch: 6/10, step 329/574 completed (loss: 0.06612341105937958, acc: 0.9629629850387573)
[2024-11-13 05:28:05,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:05,669][root][INFO] - Training Epoch: 6/10, step 330/574 completed (loss: 0.026879029348492622, acc: 1.0)
[2024-11-13 05:28:05,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:05,983][root][INFO] - Training Epoch: 6/10, step 331/574 completed (loss: 0.18749494850635529, acc: 0.9193548560142517)
[2024-11-13 05:28:06,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:06,341][root][INFO] - Training Epoch: 6/10, step 332/574 completed (loss: 0.09930986911058426, acc: 0.9649122953414917)
[2024-11-13 05:28:06,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:06,639][root][INFO] - Training Epoch: 6/10, step 333/574 completed (loss: 0.2291649430990219, acc: 0.9375)
[2024-11-13 05:28:06,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:07,001][root][INFO] - Training Epoch: 6/10, step 334/574 completed (loss: 0.033319275826215744, acc: 1.0)
[2024-11-13 05:28:07,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:07,324][root][INFO] - Training Epoch: 6/10, step 335/574 completed (loss: 0.0066584316082298756, acc: 1.0)
[2024-11-13 05:28:07,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:07,661][root][INFO] - Training Epoch: 6/10, step 336/574 completed (loss: 0.6411009430885315, acc: 0.8199999928474426)
[2024-11-13 05:28:07,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:08,012][root][INFO] - Training Epoch: 6/10, step 337/574 completed (loss: 0.8338603973388672, acc: 0.7356321811676025)
[2024-11-13 05:28:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:08,348][root][INFO] - Training Epoch: 6/10, step 338/574 completed (loss: 0.77472984790802, acc: 0.7021276354789734)
[2024-11-13 05:28:08,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:08,706][root][INFO] - Training Epoch: 6/10, step 339/574 completed (loss: 0.8669565320014954, acc: 0.7228915691375732)
[2024-11-13 05:28:08,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:09,033][root][INFO] - Training Epoch: 6/10, step 340/574 completed (loss: 0.011213084682822227, acc: 1.0)
[2024-11-13 05:28:09,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:09,345][root][INFO] - Training Epoch: 6/10, step 341/574 completed (loss: 0.028952598571777344, acc: 1.0)
[2024-11-13 05:28:09,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:09,706][root][INFO] - Training Epoch: 6/10, step 342/574 completed (loss: 0.2534884810447693, acc: 0.9156626462936401)
[2024-11-13 05:28:09,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:10,026][root][INFO] - Training Epoch: 6/10, step 343/574 completed (loss: 0.3003937005996704, acc: 0.9245283007621765)
[2024-11-13 05:28:10,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:10,325][root][INFO] - Training Epoch: 6/10, step 344/574 completed (loss: 0.08936570584774017, acc: 0.9620253443717957)
[2024-11-13 05:28:10,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:10,696][root][INFO] - Training Epoch: 6/10, step 345/574 completed (loss: 0.09698311239480972, acc: 0.9803921580314636)
[2024-11-13 05:28:10,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:11,033][root][INFO] - Training Epoch: 6/10, step 346/574 completed (loss: 0.21980924904346466, acc: 0.9402984976768494)
[2024-11-13 05:28:11,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:11,341][root][INFO] - Training Epoch: 6/10, step 347/574 completed (loss: 0.01276320405304432, acc: 1.0)
[2024-11-13 05:28:11,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:11,637][root][INFO] - Training Epoch: 6/10, step 348/574 completed (loss: 0.09160443395376205, acc: 0.9599999785423279)
[2024-11-13 05:28:11,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:12,008][root][INFO] - Training Epoch: 6/10, step 349/574 completed (loss: 0.5447919368743896, acc: 0.8611111044883728)
[2024-11-13 05:28:12,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:12,316][root][INFO] - Training Epoch: 6/10, step 350/574 completed (loss: 0.23287250101566315, acc: 0.9069767594337463)
[2024-11-13 05:28:12,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:12,650][root][INFO] - Training Epoch: 6/10, step 351/574 completed (loss: 0.137986421585083, acc: 0.9487179517745972)
[2024-11-13 05:28:12,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:13,008][root][INFO] - Training Epoch: 6/10, step 352/574 completed (loss: 0.33874762058258057, acc: 0.8888888955116272)
[2024-11-13 05:28:13,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:13,301][root][INFO] - Training Epoch: 6/10, step 353/574 completed (loss: 0.05762679502367973, acc: 0.95652174949646)
[2024-11-13 05:28:13,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:13,597][root][INFO] - Training Epoch: 6/10, step 354/574 completed (loss: 0.15236113965511322, acc: 0.9230769276618958)
[2024-11-13 05:28:13,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:13,937][root][INFO] - Training Epoch: 6/10, step 355/574 completed (loss: 0.5574730038642883, acc: 0.8461538553237915)
[2024-11-13 05:28:14,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:14,450][root][INFO] - Training Epoch: 6/10, step 356/574 completed (loss: 0.43153470754623413, acc: 0.852173924446106)
[2024-11-13 05:28:14,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:14,815][root][INFO] - Training Epoch: 6/10, step 357/574 completed (loss: 0.392674058675766, acc: 0.8695651888847351)
[2024-11-13 05:28:14,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:15,145][root][INFO] - Training Epoch: 6/10, step 358/574 completed (loss: 0.2796693742275238, acc: 0.918367326259613)
[2024-11-13 05:28:15,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:15,476][root][INFO] - Training Epoch: 6/10, step 359/574 completed (loss: 0.001670833327807486, acc: 1.0)
[2024-11-13 05:28:15,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:15,788][root][INFO] - Training Epoch: 6/10, step 360/574 completed (loss: 0.025349851697683334, acc: 1.0)
[2024-11-13 05:28:15,886][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:16,118][root][INFO] - Training Epoch: 6/10, step 361/574 completed (loss: 0.23797067999839783, acc: 0.9512194991111755)
[2024-11-13 05:28:16,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:16,428][root][INFO] - Training Epoch: 6/10, step 362/574 completed (loss: 0.16745106875896454, acc: 0.9777777791023254)
[2024-11-13 05:28:16,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:16,741][root][INFO] - Training Epoch: 6/10, step 363/574 completed (loss: 0.09377316385507584, acc: 0.9736841917037964)
[2024-11-13 05:28:16,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:17,071][root][INFO] - Training Epoch: 6/10, step 364/574 completed (loss: 0.05479690432548523, acc: 0.9756097793579102)
[2024-11-13 05:28:17,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:17,401][root][INFO] - Training Epoch: 6/10, step 365/574 completed (loss: 0.019742798060178757, acc: 1.0)
[2024-11-13 05:28:17,498][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:17,765][root][INFO] - Training Epoch: 6/10, step 366/574 completed (loss: 0.003227819921448827, acc: 1.0)
[2024-11-13 05:28:17,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:18,101][root][INFO] - Training Epoch: 6/10, step 367/574 completed (loss: 0.004484531935304403, acc: 1.0)
[2024-11-13 05:28:18,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:18,423][root][INFO] - Training Epoch: 6/10, step 368/574 completed (loss: 0.012157285585999489, acc: 1.0)
[2024-11-13 05:28:18,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:18,709][root][INFO] - Training Epoch: 6/10, step 369/574 completed (loss: 0.23151451349258423, acc: 0.90625)
[2024-11-13 05:28:18,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:19,324][root][INFO] - Training Epoch: 6/10, step 370/574 completed (loss: 0.5559389591217041, acc: 0.8363636136054993)
[2024-11-13 05:28:19,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:20,206][root][INFO] - Training Epoch: 6/10, step 371/574 completed (loss: 0.21548277139663696, acc: 0.9245283007621765)
[2024-11-13 05:28:20,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:20,625][root][INFO] - Training Epoch: 6/10, step 372/574 completed (loss: 0.12942004203796387, acc: 0.9555555582046509)
[2024-11-13 05:28:20,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:20,992][root][INFO] - Training Epoch: 6/10, step 373/574 completed (loss: 0.13464893400669098, acc: 0.9464285969734192)
[2024-11-13 05:28:21,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:21,340][root][INFO] - Training Epoch: 6/10, step 374/574 completed (loss: 0.21537767350673676, acc: 0.9428571462631226)
[2024-11-13 05:28:21,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:21,686][root][INFO] - Training Epoch: 6/10, step 375/574 completed (loss: 0.00960055086761713, acc: 1.0)
[2024-11-13 05:28:21,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:21,975][root][INFO] - Training Epoch: 6/10, step 376/574 completed (loss: 0.0015870167408138514, acc: 1.0)
[2024-11-13 05:28:22,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:22,359][root][INFO] - Training Epoch: 6/10, step 377/574 completed (loss: 0.13248763978481293, acc: 0.9583333134651184)
[2024-11-13 05:28:22,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:22,769][root][INFO] - Training Epoch: 6/10, step 378/574 completed (loss: 0.014795425347983837, acc: 1.0)
[2024-11-13 05:28:22,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:23,377][root][INFO] - Training Epoch: 6/10, step 379/574 completed (loss: 0.17209534347057343, acc: 0.9341317415237427)
[2024-11-13 05:28:23,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:23,786][root][INFO] - Training Epoch: 6/10, step 380/574 completed (loss: 0.25591978430747986, acc: 0.9248120188713074)
[2024-11-13 05:28:24,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:25,085][root][INFO] - Training Epoch: 6/10, step 381/574 completed (loss: 0.5761845111846924, acc: 0.8395721912384033)
[2024-11-13 05:28:25,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:25,696][root][INFO] - Training Epoch: 6/10, step 382/574 completed (loss: 0.11319119483232498, acc: 0.9639639854431152)
[2024-11-13 05:28:25,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:26,076][root][INFO] - Training Epoch: 6/10, step 383/574 completed (loss: 0.2186131477355957, acc: 0.9285714030265808)
[2024-11-13 05:28:26,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:26,455][root][INFO] - Training Epoch: 6/10, step 384/574 completed (loss: 0.0341227687895298, acc: 1.0)
[2024-11-13 05:28:26,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:26,796][root][INFO] - Training Epoch: 6/10, step 385/574 completed (loss: 0.26925796270370483, acc: 0.96875)
[2024-11-13 05:28:26,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:27,120][root][INFO] - Training Epoch: 6/10, step 386/574 completed (loss: 0.0038094024639576674, acc: 1.0)
[2024-11-13 05:28:27,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:27,487][root][INFO] - Training Epoch: 6/10, step 387/574 completed (loss: 0.01937694661319256, acc: 1.0)
[2024-11-13 05:28:27,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:27,804][root][INFO] - Training Epoch: 6/10, step 388/574 completed (loss: 0.002934161340817809, acc: 1.0)
[2024-11-13 05:28:27,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:28,131][root][INFO] - Training Epoch: 6/10, step 389/574 completed (loss: 0.010540245100855827, acc: 1.0)
[2024-11-13 05:28:28,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:28,479][root][INFO] - Training Epoch: 6/10, step 390/574 completed (loss: 0.06355716288089752, acc: 1.0)
[2024-11-13 05:28:28,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:28,851][root][INFO] - Training Epoch: 6/10, step 391/574 completed (loss: 0.3850422501564026, acc: 0.9074074029922485)
[2024-11-13 05:28:28,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:29,249][root][INFO] - Training Epoch: 6/10, step 392/574 completed (loss: 0.6547858119010925, acc: 0.8349514603614807)
[2024-11-13 05:28:29,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:29,775][root][INFO] - Training Epoch: 6/10, step 393/574 completed (loss: 0.683522641658783, acc: 0.8235294222831726)
[2024-11-13 05:28:29,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:30,172][root][INFO] - Training Epoch: 6/10, step 394/574 completed (loss: 0.6133216023445129, acc: 0.8333333134651184)
[2024-11-13 05:28:30,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:30,582][root][INFO] - Training Epoch: 6/10, step 395/574 completed (loss: 0.5625637173652649, acc: 0.8402777910232544)
[2024-11-13 05:28:30,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:30,896][root][INFO] - Training Epoch: 6/10, step 396/574 completed (loss: 0.159720316529274, acc: 0.9534883499145508)
[2024-11-13 05:28:30,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:31,200][root][INFO] - Training Epoch: 6/10, step 397/574 completed (loss: 0.016698481515049934, acc: 1.0)
[2024-11-13 05:28:31,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:31,530][root][INFO] - Training Epoch: 6/10, step 398/574 completed (loss: 0.13379333913326263, acc: 0.9534883499145508)
[2024-11-13 05:28:31,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:31,892][root][INFO] - Training Epoch: 6/10, step 399/574 completed (loss: 0.02198066934943199, acc: 1.0)
[2024-11-13 05:28:32,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:32,447][root][INFO] - Training Epoch: 6/10, step 400/574 completed (loss: 0.23712167143821716, acc: 0.9558823704719543)
[2024-11-13 05:28:32,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:32,843][root][INFO] - Training Epoch: 6/10, step 401/574 completed (loss: 0.35752373933792114, acc: 0.8933333158493042)
[2024-11-13 05:28:32,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:33,215][root][INFO] - Training Epoch: 6/10, step 402/574 completed (loss: 0.1155850738286972, acc: 0.939393937587738)
[2024-11-13 05:28:33,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:33,564][root][INFO] - Training Epoch: 6/10, step 403/574 completed (loss: 0.08827804774045944, acc: 0.9696969985961914)
[2024-11-13 05:28:33,680][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:33,910][root][INFO] - Training Epoch: 6/10, step 404/574 completed (loss: 0.08522430807352066, acc: 0.9677419066429138)
[2024-11-13 05:28:33,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:34,259][root][INFO] - Training Epoch: 6/10, step 405/574 completed (loss: 0.007364736869931221, acc: 1.0)
[2024-11-13 05:28:34,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:34,660][root][INFO] - Training Epoch: 6/10, step 406/574 completed (loss: 0.015423456206917763, acc: 1.0)
[2024-11-13 05:28:34,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:35,036][root][INFO] - Training Epoch: 6/10, step 407/574 completed (loss: 0.005406645126640797, acc: 1.0)
[2024-11-13 05:28:35,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:35,391][root][INFO] - Training Epoch: 6/10, step 408/574 completed (loss: 0.011056636460125446, acc: 1.0)
[2024-11-13 05:28:35,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:35,759][root][INFO] - Training Epoch: 6/10, step 409/574 completed (loss: 0.007604910060763359, acc: 1.0)
[2024-11-13 05:28:35,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:36,130][root][INFO] - Training Epoch: 6/10, step 410/574 completed (loss: 0.043466076254844666, acc: 1.0)
[2024-11-13 05:28:36,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:36,479][root][INFO] - Training Epoch: 6/10, step 411/574 completed (loss: 0.07545974105596542, acc: 0.9642857313156128)
[2024-11-13 05:28:36,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:36,816][root][INFO] - Training Epoch: 6/10, step 412/574 completed (loss: 0.07033980637788773, acc: 1.0)
[2024-11-13 05:28:36,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:37,181][root][INFO] - Training Epoch: 6/10, step 413/574 completed (loss: 0.02754390984773636, acc: 0.9696969985961914)
[2024-11-13 05:28:37,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:37,527][root][INFO] - Training Epoch: 6/10, step 414/574 completed (loss: 0.036606576293706894, acc: 1.0)
[2024-11-13 05:28:37,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:37,865][root][INFO] - Training Epoch: 6/10, step 415/574 completed (loss: 0.1253993809223175, acc: 0.9607843160629272)
[2024-11-13 05:28:37,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:38,171][root][INFO] - Training Epoch: 6/10, step 416/574 completed (loss: 0.21954020857810974, acc: 0.9230769276618958)
[2024-11-13 05:28:38,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:38,541][root][INFO] - Training Epoch: 6/10, step 417/574 completed (loss: 0.18521833419799805, acc: 0.8888888955116272)
[2024-11-13 05:28:38,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:38,907][root][INFO] - Training Epoch: 6/10, step 418/574 completed (loss: 0.10489126294851303, acc: 0.949999988079071)
[2024-11-13 05:28:39,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:39,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:40,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:40,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:40,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:41,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:41,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:42,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:42,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:42,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:43,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:43,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:43,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:44,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:44,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:44,939][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:45,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:45,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:45,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:46,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:46,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:47,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:47,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:47,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:48,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:48,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:48,719][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:49,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:49,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:49,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:50,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:50,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:50,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:51,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:51,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:51,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:51,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:52,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:52,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:52,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:53,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:53,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:54,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:54,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:54,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:55,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:55,412][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:55,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:56,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:56,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:56,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:57,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:57,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:57,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:58,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:58,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:59,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:59,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:28:59,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:00,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:00,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:01,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:01,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:01,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:02,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:02,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:03,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:03,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:03,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:04,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:04,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:04,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:05,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:05,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:06,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:06,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:06,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:07,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:07,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:07,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:08,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:08,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:09,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:09,886][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4527, device='cuda:0') eval_epoch_loss=tensor(0.8972, device='cuda:0') eval_epoch_acc=tensor(0.7905, device='cuda:0')
[2024-11-13 05:29:09,888][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:29:09,888][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:29:10,163][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_6_step_419_loss_0.8971840739250183/model.pt
[2024-11-13 05:29:10,169][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:29:10,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:10,583][root][INFO] - Training Epoch: 6/10, step 419/574 completed (loss: 0.04824434965848923, acc: 1.0)
[2024-11-13 05:29:10,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:10,913][root][INFO] - Training Epoch: 6/10, step 420/574 completed (loss: 0.012343685142695904, acc: 1.0)
[2024-11-13 05:29:10,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:11,224][root][INFO] - Training Epoch: 6/10, step 421/574 completed (loss: 0.40845996141433716, acc: 0.8333333134651184)
[2024-11-13 05:29:11,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:11,546][root][INFO] - Training Epoch: 6/10, step 422/574 completed (loss: 0.32856065034866333, acc: 0.90625)
[2024-11-13 05:29:11,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:11,899][root][INFO] - Training Epoch: 6/10, step 423/574 completed (loss: 0.02532993070781231, acc: 1.0)
[2024-11-13 05:29:12,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:12,244][root][INFO] - Training Epoch: 6/10, step 424/574 completed (loss: 0.056613948196172714, acc: 1.0)
[2024-11-13 05:29:12,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:12,587][root][INFO] - Training Epoch: 6/10, step 425/574 completed (loss: 0.03498353436589241, acc: 1.0)
[2024-11-13 05:29:12,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:12,922][root][INFO] - Training Epoch: 6/10, step 426/574 completed (loss: 0.019903993234038353, acc: 1.0)
[2024-11-13 05:29:13,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:13,249][root][INFO] - Training Epoch: 6/10, step 427/574 completed (loss: 0.026387838646769524, acc: 1.0)
[2024-11-13 05:29:13,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:13,578][root][INFO] - Training Epoch: 6/10, step 428/574 completed (loss: 0.027213672176003456, acc: 1.0)
[2024-11-13 05:29:13,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:13,889][root][INFO] - Training Epoch: 6/10, step 429/574 completed (loss: 0.01046578399837017, acc: 1.0)
[2024-11-13 05:29:13,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:14,199][root][INFO] - Training Epoch: 6/10, step 430/574 completed (loss: 0.00782280694693327, acc: 1.0)
[2024-11-13 05:29:14,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:14,491][root][INFO] - Training Epoch: 6/10, step 431/574 completed (loss: 0.005252712406218052, acc: 1.0)
[2024-11-13 05:29:14,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:14,792][root][INFO] - Training Epoch: 6/10, step 432/574 completed (loss: 0.042773421853780746, acc: 1.0)
[2024-11-13 05:29:14,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:15,141][root][INFO] - Training Epoch: 6/10, step 433/574 completed (loss: 0.39979037642478943, acc: 0.8888888955116272)
[2024-11-13 05:29:15,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:15,480][root][INFO] - Training Epoch: 6/10, step 434/574 completed (loss: 0.006430042441934347, acc: 1.0)
[2024-11-13 05:29:15,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:15,796][root][INFO] - Training Epoch: 6/10, step 435/574 completed (loss: 0.021192578598856926, acc: 1.0)
[2024-11-13 05:29:15,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:16,094][root][INFO] - Training Epoch: 6/10, step 436/574 completed (loss: 0.09225862473249435, acc: 0.9722222089767456)
[2024-11-13 05:29:16,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:16,408][root][INFO] - Training Epoch: 6/10, step 437/574 completed (loss: 0.03444874659180641, acc: 1.0)
[2024-11-13 05:29:16,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:16,699][root][INFO] - Training Epoch: 6/10, step 438/574 completed (loss: 0.004026560112833977, acc: 1.0)
[2024-11-13 05:29:16,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:17,058][root][INFO] - Training Epoch: 6/10, step 439/574 completed (loss: 0.10164175927639008, acc: 0.9487179517745972)
[2024-11-13 05:29:17,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:17,518][root][INFO] - Training Epoch: 6/10, step 440/574 completed (loss: 0.24562881886959076, acc: 0.8787878751754761)
[2024-11-13 05:29:17,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:18,262][root][INFO] - Training Epoch: 6/10, step 441/574 completed (loss: 0.6474267840385437, acc: 0.8159999847412109)
[2024-11-13 05:29:18,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:18,655][root][INFO] - Training Epoch: 6/10, step 442/574 completed (loss: 0.6888394951820374, acc: 0.8306451439857483)
[2024-11-13 05:29:18,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:19,319][root][INFO] - Training Epoch: 6/10, step 443/574 completed (loss: 0.4743941128253937, acc: 0.8606964945793152)
[2024-11-13 05:29:19,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:19,637][root][INFO] - Training Epoch: 6/10, step 444/574 completed (loss: 0.11007526516914368, acc: 0.9811320900917053)
[2024-11-13 05:29:19,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:20,047][root][INFO] - Training Epoch: 6/10, step 445/574 completed (loss: 0.03221529722213745, acc: 1.0)
[2024-11-13 05:29:20,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:20,335][root][INFO] - Training Epoch: 6/10, step 446/574 completed (loss: 0.1016727015376091, acc: 0.95652174949646)
[2024-11-13 05:29:20,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:20,636][root][INFO] - Training Epoch: 6/10, step 447/574 completed (loss: 0.23280853033065796, acc: 0.9230769276618958)
[2024-11-13 05:29:20,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:20,983][root][INFO] - Training Epoch: 6/10, step 448/574 completed (loss: 0.0415058508515358, acc: 0.9642857313156128)
[2024-11-13 05:29:21,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:21,295][root][INFO] - Training Epoch: 6/10, step 449/574 completed (loss: 0.11306857317686081, acc: 0.9552238583564758)
[2024-11-13 05:29:21,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:21,615][root][INFO] - Training Epoch: 6/10, step 450/574 completed (loss: 0.04095180705189705, acc: 1.0)
[2024-11-13 05:29:21,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:21,965][root][INFO] - Training Epoch: 6/10, step 451/574 completed (loss: 0.07949648797512054, acc: 0.967391312122345)
[2024-11-13 05:29:22,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:22,275][root][INFO] - Training Epoch: 6/10, step 452/574 completed (loss: 0.18406130373477936, acc: 0.9358974099159241)
[2024-11-13 05:29:22,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:22,613][root][INFO] - Training Epoch: 6/10, step 453/574 completed (loss: 0.22001303732395172, acc: 0.9473684430122375)
[2024-11-13 05:29:22,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:22,951][root][INFO] - Training Epoch: 6/10, step 454/574 completed (loss: 0.03140920400619507, acc: 1.0)
[2024-11-13 05:29:23,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:23,263][root][INFO] - Training Epoch: 6/10, step 455/574 completed (loss: 0.07306735217571259, acc: 0.9696969985961914)
[2024-11-13 05:29:23,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:23,640][root][INFO] - Training Epoch: 6/10, step 456/574 completed (loss: 0.3747689425945282, acc: 0.8969072103500366)
[2024-11-13 05:29:23,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:23,978][root][INFO] - Training Epoch: 6/10, step 457/574 completed (loss: 0.08851004391908646, acc: 0.9857142567634583)
[2024-11-13 05:29:24,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:24,341][root][INFO] - Training Epoch: 6/10, step 458/574 completed (loss: 0.4311186671257019, acc: 0.8720930218696594)
[2024-11-13 05:29:24,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:24,634][root][INFO] - Training Epoch: 6/10, step 459/574 completed (loss: 0.04046712443232536, acc: 1.0)
[2024-11-13 05:29:24,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:24,944][root][INFO] - Training Epoch: 6/10, step 460/574 completed (loss: 0.0993175357580185, acc: 0.9876543283462524)
[2024-11-13 05:29:25,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:25,235][root][INFO] - Training Epoch: 6/10, step 461/574 completed (loss: 0.1455884426832199, acc: 0.9444444179534912)
[2024-11-13 05:29:25,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:25,533][root][INFO] - Training Epoch: 6/10, step 462/574 completed (loss: 0.04141701012849808, acc: 1.0)
[2024-11-13 05:29:25,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:25,830][root][INFO] - Training Epoch: 6/10, step 463/574 completed (loss: 0.134548157453537, acc: 0.9615384340286255)
[2024-11-13 05:29:25,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:26,128][root][INFO] - Training Epoch: 6/10, step 464/574 completed (loss: 0.06276141107082367, acc: 0.97826087474823)
[2024-11-13 05:29:26,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:26,430][root][INFO] - Training Epoch: 6/10, step 465/574 completed (loss: 0.12518510222434998, acc: 0.9642857313156128)
[2024-11-13 05:29:26,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:26,730][root][INFO] - Training Epoch: 6/10, step 466/574 completed (loss: 0.4319379925727844, acc: 0.891566276550293)
[2024-11-13 05:29:26,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:27,089][root][INFO] - Training Epoch: 6/10, step 467/574 completed (loss: 0.12848566472530365, acc: 0.954954981803894)
[2024-11-13 05:29:27,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:27,411][root][INFO] - Training Epoch: 6/10, step 468/574 completed (loss: 0.5626335740089417, acc: 0.8834951519966125)
[2024-11-13 05:29:27,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:27,728][root][INFO] - Training Epoch: 6/10, step 469/574 completed (loss: 0.41994062066078186, acc: 0.8780487775802612)
[2024-11-13 05:29:27,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:28,067][root][INFO] - Training Epoch: 6/10, step 470/574 completed (loss: 0.07146771252155304, acc: 0.9583333134651184)
[2024-11-13 05:29:28,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:28,378][root][INFO] - Training Epoch: 6/10, step 471/574 completed (loss: 0.27458277344703674, acc: 0.9285714030265808)
[2024-11-13 05:29:28,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:28,776][root][INFO] - Training Epoch: 6/10, step 472/574 completed (loss: 0.1869598776102066, acc: 0.9313725233078003)
[2024-11-13 05:29:28,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:29,111][root][INFO] - Training Epoch: 6/10, step 473/574 completed (loss: 0.6320326328277588, acc: 0.847161591053009)
[2024-11-13 05:29:29,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:29,424][root][INFO] - Training Epoch: 6/10, step 474/574 completed (loss: 0.2742873728275299, acc: 0.8958333134651184)
[2024-11-13 05:29:29,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:29,731][root][INFO] - Training Epoch: 6/10, step 475/574 completed (loss: 0.2704710364341736, acc: 0.9202454090118408)
[2024-11-13 05:29:29,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:30,032][root][INFO] - Training Epoch: 6/10, step 476/574 completed (loss: 0.3277915418148041, acc: 0.9136690497398376)
[2024-11-13 05:29:30,124][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:30,371][root][INFO] - Training Epoch: 6/10, step 477/574 completed (loss: 0.532909631729126, acc: 0.8341708779335022)
[2024-11-13 05:29:30,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:30,688][root][INFO] - Training Epoch: 6/10, step 478/574 completed (loss: 0.1166333258152008, acc: 0.9444444179534912)
[2024-11-13 05:29:30,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:31,023][root][INFO] - Training Epoch: 6/10, step 479/574 completed (loss: 0.11827950179576874, acc: 0.9696969985961914)
[2024-11-13 05:29:31,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:31,358][root][INFO] - Training Epoch: 6/10, step 480/574 completed (loss: 0.15724237263202667, acc: 0.9259259104728699)
[2024-11-13 05:29:31,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:31,675][root][INFO] - Training Epoch: 6/10, step 481/574 completed (loss: 0.12410658597946167, acc: 0.949999988079071)
[2024-11-13 05:29:31,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:31,964][root][INFO] - Training Epoch: 6/10, step 482/574 completed (loss: 0.3712540566921234, acc: 0.8500000238418579)
[2024-11-13 05:29:32,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:32,322][root][INFO] - Training Epoch: 6/10, step 483/574 completed (loss: 0.3308209478855133, acc: 0.8620689511299133)
[2024-11-13 05:29:32,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:32,623][root][INFO] - Training Epoch: 6/10, step 484/574 completed (loss: 0.029541874304413795, acc: 1.0)
[2024-11-13 05:29:32,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:32,921][root][INFO] - Training Epoch: 6/10, step 485/574 completed (loss: 0.046145010739564896, acc: 1.0)
[2024-11-13 05:29:32,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:33,212][root][INFO] - Training Epoch: 6/10, step 486/574 completed (loss: 0.2040051370859146, acc: 0.9629629850387573)
[2024-11-13 05:29:33,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:33,504][root][INFO] - Training Epoch: 6/10, step 487/574 completed (loss: 0.42083272337913513, acc: 0.9047619104385376)
[2024-11-13 05:29:33,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:33,803][root][INFO] - Training Epoch: 6/10, step 488/574 completed (loss: 0.2437731772661209, acc: 0.9545454382896423)
[2024-11-13 05:29:33,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:34,138][root][INFO] - Training Epoch: 6/10, step 489/574 completed (loss: 0.4589218199253082, acc: 0.8615384697914124)
[2024-11-13 05:29:34,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:34,448][root][INFO] - Training Epoch: 6/10, step 490/574 completed (loss: 0.02567599155008793, acc: 1.0)
[2024-11-13 05:29:34,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:34,797][root][INFO] - Training Epoch: 6/10, step 491/574 completed (loss: 0.17808789014816284, acc: 0.8965517282485962)
[2024-11-13 05:29:34,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:35,128][root][INFO] - Training Epoch: 6/10, step 492/574 completed (loss: 0.1671832799911499, acc: 0.9803921580314636)
[2024-11-13 05:29:35,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:35,463][root][INFO] - Training Epoch: 6/10, step 493/574 completed (loss: 0.0825604796409607, acc: 1.0)
[2024-11-13 05:29:35,549][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:35,776][root][INFO] - Training Epoch: 6/10, step 494/574 completed (loss: 0.20609143376350403, acc: 0.9473684430122375)
[2024-11-13 05:29:35,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:36,090][root][INFO] - Training Epoch: 6/10, step 495/574 completed (loss: 0.2917555868625641, acc: 0.8421052694320679)
[2024-11-13 05:29:36,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:36,423][root][INFO] - Training Epoch: 6/10, step 496/574 completed (loss: 0.5761436223983765, acc: 0.8571428656578064)
[2024-11-13 05:29:36,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:36,798][root][INFO] - Training Epoch: 6/10, step 497/574 completed (loss: 0.30901241302490234, acc: 0.898876428604126)
[2024-11-13 05:29:36,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:37,114][root][INFO] - Training Epoch: 6/10, step 498/574 completed (loss: 0.4673854112625122, acc: 0.8426966071128845)
[2024-11-13 05:29:37,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:37,437][root][INFO] - Training Epoch: 6/10, step 499/574 completed (loss: 0.9635905623435974, acc: 0.7446808218955994)
[2024-11-13 05:29:37,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:37,755][root][INFO] - Training Epoch: 6/10, step 500/574 completed (loss: 0.46678754687309265, acc: 0.8695651888847351)
[2024-11-13 05:29:37,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:38,051][root][INFO] - Training Epoch: 6/10, step 501/574 completed (loss: 0.010644065216183662, acc: 1.0)
[2024-11-13 05:29:38,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:38,397][root][INFO] - Training Epoch: 6/10, step 502/574 completed (loss: 0.004612336866557598, acc: 1.0)
[2024-11-13 05:29:38,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:38,712][root][INFO] - Training Epoch: 6/10, step 503/574 completed (loss: 0.01677665486931801, acc: 1.0)
[2024-11-13 05:29:38,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:39,063][root][INFO] - Training Epoch: 6/10, step 504/574 completed (loss: 0.054446764290332794, acc: 1.0)
[2024-11-13 05:29:39,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:39,385][root][INFO] - Training Epoch: 6/10, step 505/574 completed (loss: 0.434037983417511, acc: 0.8679245114326477)
[2024-11-13 05:29:39,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:39,720][root][INFO] - Training Epoch: 6/10, step 506/574 completed (loss: 0.7958127856254578, acc: 0.8275862336158752)
[2024-11-13 05:29:39,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:40,302][root][INFO] - Training Epoch: 6/10, step 507/574 completed (loss: 0.7483919858932495, acc: 0.7837837934494019)
[2024-11-13 05:29:40,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:40,736][root][INFO] - Training Epoch: 6/10, step 508/574 completed (loss: 0.4539290964603424, acc: 0.8732394576072693)
[2024-11-13 05:29:40,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:41,035][root][INFO] - Training Epoch: 6/10, step 509/574 completed (loss: 0.013859467580914497, acc: 1.0)
[2024-11-13 05:29:41,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:41,364][root][INFO] - Training Epoch: 6/10, step 510/574 completed (loss: 0.012024551630020142, acc: 1.0)
[2024-11-13 05:29:41,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:41,685][root][INFO] - Training Epoch: 6/10, step 511/574 completed (loss: 0.1227409765124321, acc: 0.9230769276618958)
[2024-11-13 05:29:43,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:44,664][root][INFO] - Training Epoch: 6/10, step 512/574 completed (loss: 0.9406423568725586, acc: 0.7357142567634583)
[2024-11-13 05:29:44,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:45,471][root][INFO] - Training Epoch: 6/10, step 513/574 completed (loss: 0.24923327565193176, acc: 0.9365079402923584)
[2024-11-13 05:29:45,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:45,761][root][INFO] - Training Epoch: 6/10, step 514/574 completed (loss: 0.732974648475647, acc: 0.8214285969734192)
[2024-11-13 05:29:45,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:46,067][root][INFO] - Training Epoch: 6/10, step 515/574 completed (loss: 0.043312739580869675, acc: 1.0)
[2024-11-13 05:29:46,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:46,754][root][INFO] - Training Epoch: 6/10, step 516/574 completed (loss: 0.38779887557029724, acc: 0.8888888955116272)
[2024-11-13 05:29:46,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:47,047][root][INFO] - Training Epoch: 6/10, step 517/574 completed (loss: 0.003749607363715768, acc: 1.0)
[2024-11-13 05:29:47,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:47,398][root][INFO] - Training Epoch: 6/10, step 518/574 completed (loss: 0.07756753265857697, acc: 1.0)
[2024-11-13 05:29:47,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:47,725][root][INFO] - Training Epoch: 6/10, step 519/574 completed (loss: 0.11294876039028168, acc: 0.949999988079071)
[2024-11-13 05:29:47,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:48,076][root][INFO] - Training Epoch: 6/10, step 520/574 completed (loss: 0.4586256444454193, acc: 0.8148148059844971)
[2024-11-13 05:29:48,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:49,081][root][INFO] - Training Epoch: 6/10, step 521/574 completed (loss: 0.5443912148475647, acc: 0.8516949415206909)
[2024-11-13 05:29:49,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:49,421][root][INFO] - Training Epoch: 6/10, step 522/574 completed (loss: 0.2910011410713196, acc: 0.9104477763175964)
[2024-11-13 05:29:49,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:49,783][root][INFO] - Training Epoch: 6/10, step 523/574 completed (loss: 0.20406301319599152, acc: 0.9270073175430298)
[2024-11-13 05:29:49,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:50,342][root][INFO] - Training Epoch: 6/10, step 524/574 completed (loss: 0.5551410913467407, acc: 0.8799999952316284)
[2024-11-13 05:29:50,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:50,631][root][INFO] - Training Epoch: 6/10, step 525/574 completed (loss: 0.0641089677810669, acc: 0.9814814925193787)
[2024-11-13 05:29:50,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:50,902][root][INFO] - Training Epoch: 6/10, step 526/574 completed (loss: 0.11271163821220398, acc: 0.942307710647583)
[2024-11-13 05:29:51,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:51,263][root][INFO] - Training Epoch: 6/10, step 527/574 completed (loss: 0.23220527172088623, acc: 0.9523809552192688)
[2024-11-13 05:29:51,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:51,619][root][INFO] - Training Epoch: 6/10, step 528/574 completed (loss: 0.9691972136497498, acc: 0.688524603843689)
[2024-11-13 05:29:51,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:51,952][root][INFO] - Training Epoch: 6/10, step 529/574 completed (loss: 0.15330033004283905, acc: 0.9661017060279846)
[2024-11-13 05:29:52,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:52,259][root][INFO] - Training Epoch: 6/10, step 530/574 completed (loss: 0.673958957195282, acc: 0.7209302186965942)
[2024-11-13 05:29:52,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:52,587][root][INFO] - Training Epoch: 6/10, step 531/574 completed (loss: 0.4811391830444336, acc: 0.8636363744735718)
[2024-11-13 05:29:52,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:52,935][root][INFO] - Training Epoch: 6/10, step 532/574 completed (loss: 0.6216434836387634, acc: 0.8679245114326477)
[2024-11-13 05:29:53,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:53,304][root][INFO] - Training Epoch: 6/10, step 533/574 completed (loss: 0.26354920864105225, acc: 0.9318181872367859)
[2024-11-13 05:29:53,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:53,633][root][INFO] - Training Epoch: 6/10, step 534/574 completed (loss: 0.2916894257068634, acc: 0.9200000166893005)
[2024-11-13 05:29:53,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:53,915][root][INFO] - Training Epoch: 6/10, step 535/574 completed (loss: 0.1708923876285553, acc: 0.949999988079071)
[2024-11-13 05:29:53,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:54,219][root][INFO] - Training Epoch: 6/10, step 536/574 completed (loss: 0.17210331559181213, acc: 0.9090909361839294)
[2024-11-13 05:29:54,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:54,617][root][INFO] - Training Epoch: 6/10, step 537/574 completed (loss: 0.37150126695632935, acc: 0.9076923131942749)
[2024-11-13 05:29:54,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:54,937][root][INFO] - Training Epoch: 6/10, step 538/574 completed (loss: 0.2962121367454529, acc: 0.90625)
[2024-11-13 05:29:55,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:55,316][root][INFO] - Training Epoch: 6/10, step 539/574 completed (loss: 0.39680472016334534, acc: 0.84375)
[2024-11-13 05:29:55,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:55,615][root][INFO] - Training Epoch: 6/10, step 540/574 completed (loss: 0.3509630560874939, acc: 0.8484848737716675)
[2024-11-13 05:29:55,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:55,964][root][INFO] - Training Epoch: 6/10, step 541/574 completed (loss: 0.2301049381494522, acc: 0.9375)
[2024-11-13 05:29:56,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:56,279][root][INFO] - Training Epoch: 6/10, step 542/574 completed (loss: 0.08660828322172165, acc: 0.9677419066429138)
[2024-11-13 05:29:56,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:56,615][root][INFO] - Training Epoch: 6/10, step 543/574 completed (loss: 0.06266480684280396, acc: 0.95652174949646)
[2024-11-13 05:29:56,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:56,960][root][INFO] - Training Epoch: 6/10, step 544/574 completed (loss: 0.09891891479492188, acc: 1.0)
[2024-11-13 05:29:57,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:57,279][root][INFO] - Training Epoch: 6/10, step 545/574 completed (loss: 0.04263889417052269, acc: 1.0)
[2024-11-13 05:29:57,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:57,608][root][INFO] - Training Epoch: 6/10, step 546/574 completed (loss: 0.007989621721208096, acc: 1.0)
[2024-11-13 05:29:57,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:57,913][root][INFO] - Training Epoch: 6/10, step 547/574 completed (loss: 0.04866650700569153, acc: 0.9736841917037964)
[2024-11-13 05:29:58,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:58,263][root][INFO] - Training Epoch: 6/10, step 548/574 completed (loss: 0.010644170455634594, acc: 1.0)
[2024-11-13 05:29:58,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:58,592][root][INFO] - Training Epoch: 6/10, step 549/574 completed (loss: 0.12475038319826126, acc: 0.9599999785423279)
[2024-11-13 05:29:58,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:58,942][root][INFO] - Training Epoch: 6/10, step 550/574 completed (loss: 0.17763680219650269, acc: 0.939393937587738)
[2024-11-13 05:29:59,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:59,258][root][INFO] - Training Epoch: 6/10, step 551/574 completed (loss: 0.013765144161880016, acc: 1.0)
[2024-11-13 05:29:59,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:59,586][root][INFO] - Training Epoch: 6/10, step 552/574 completed (loss: 0.1141241192817688, acc: 0.9714285731315613)
[2024-11-13 05:29:59,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:29:59,959][root][INFO] - Training Epoch: 6/10, step 553/574 completed (loss: 0.3301447927951813, acc: 0.9051094651222229)
[2024-11-13 05:30:00,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:00,285][root][INFO] - Training Epoch: 6/10, step 554/574 completed (loss: 0.18906857073307037, acc: 0.9448275566101074)
[2024-11-13 05:30:00,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:00,599][root][INFO] - Training Epoch: 6/10, step 555/574 completed (loss: 0.2218722552061081, acc: 0.949999988079071)
[2024-11-13 05:30:00,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:00,950][root][INFO] - Training Epoch: 6/10, step 556/574 completed (loss: 0.33114299178123474, acc: 0.9006622433662415)
[2024-11-13 05:30:01,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:01,279][root][INFO] - Training Epoch: 6/10, step 557/574 completed (loss: 0.06491199880838394, acc: 0.9914529919624329)
[2024-11-13 05:30:01,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:01,610][root][INFO] - Training Epoch: 6/10, step 558/574 completed (loss: 0.02874651737511158, acc: 1.0)
[2024-11-13 05:30:01,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:01,932][root][INFO] - Training Epoch: 6/10, step 559/574 completed (loss: 0.07357583194971085, acc: 0.9615384340286255)
[2024-11-13 05:30:02,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:02,240][root][INFO] - Training Epoch: 6/10, step 560/574 completed (loss: 0.03082781843841076, acc: 1.0)
[2024-11-13 05:30:02,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:02,524][root][INFO] - Training Epoch: 6/10, step 561/574 completed (loss: 0.12492501735687256, acc: 0.9743589758872986)
[2024-11-13 05:30:03,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:03,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:03,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:04,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:04,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:04,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:05,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:05,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:05,880][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:06,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:06,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:06,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:07,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:07,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:07,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:08,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:08,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:09,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:09,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:09,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:10,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:10,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:10,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:11,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:11,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:11,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:12,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:12,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:13,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:13,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:13,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:13,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:14,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:14,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:14,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:15,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:15,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:15,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:16,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:16,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:16,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:17,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:17,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:17,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:18,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:18,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:18,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:19,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:19,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:19,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:19,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:20,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:20,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:20,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:21,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:21,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:21,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:22,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:22,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:22,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:23,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:23,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:24,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:24,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:24,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:25,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:25,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:25,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:26,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:26,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:27,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:27,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:27,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:27,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:28,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:28,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:28,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:29,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:29,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:29,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:30,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:30,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:31,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:32,259][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5724, device='cuda:0') eval_epoch_loss=tensor(0.9448, device='cuda:0') eval_epoch_acc=tensor(0.7841, device='cuda:0')
[2024-11-13 05:30:32,262][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:30:32,263][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:30:32,625][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_6_step_562_loss_0.9448229670524597/model.pt
[2024-11-13 05:30:32,628][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:30:32,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:33,028][root][INFO] - Training Epoch: 6/10, step 562/574 completed (loss: 0.2483956217765808, acc: 0.9111111164093018)
[2024-11-13 05:30:33,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:33,282][root][INFO] - Training Epoch: 6/10, step 563/574 completed (loss: 0.18283124268054962, acc: 0.948051929473877)
[2024-11-13 05:30:33,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:33,578][root][INFO] - Training Epoch: 6/10, step 564/574 completed (loss: 0.0837484821677208, acc: 1.0)
[2024-11-13 05:30:33,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:33,963][root][INFO] - Training Epoch: 6/10, step 565/574 completed (loss: 0.1519898921251297, acc: 0.9482758641242981)
[2024-11-13 05:30:34,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:34,329][root][INFO] - Training Epoch: 6/10, step 566/574 completed (loss: 0.09314295649528503, acc: 0.976190447807312)
[2024-11-13 05:30:34,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:34,685][root][INFO] - Training Epoch: 6/10, step 567/574 completed (loss: 0.07612891495227814, acc: 0.9736841917037964)
[2024-11-13 05:30:34,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:35,018][root][INFO] - Training Epoch: 6/10, step 568/574 completed (loss: 0.05700882896780968, acc: 0.9629629850387573)
[2024-11-13 05:30:35,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:35,401][root][INFO] - Training Epoch: 6/10, step 569/574 completed (loss: 0.20942191779613495, acc: 0.9465240836143494)
[2024-11-13 05:30:35,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:35,743][root][INFO] - Training Epoch: 6/10, step 570/574 completed (loss: 0.04091405123472214, acc: 0.9838709831237793)
[2024-11-13 05:30:35,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:36,071][root][INFO] - Training Epoch: 6/10, step 571/574 completed (loss: 0.13112662732601166, acc: 0.9658119678497314)
[2024-11-13 05:30:36,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:36,385][root][INFO] - Training Epoch: 6/10, step 572/574 completed (loss: 0.49277764558792114, acc: 0.8775510191917419)
[2024-11-13 05:30:36,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:36,716][root][INFO] - Training Epoch: 6/10, step 573/574 completed (loss: 0.304132342338562, acc: 0.893081784248352)
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - Epoch 6: train_perplexity=1.3307, train_epoch_loss=0.2857, epoch time 348.1048321723938s
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 17
[2024-11-13 05:30:37,190][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:30:37,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:38,040][root][INFO] - Training Epoch: 7/10, step 0/574 completed (loss: 0.048545122146606445, acc: 0.9629629850387573)
[2024-11-13 05:30:38,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:38,346][root][INFO] - Training Epoch: 7/10, step 1/574 completed (loss: 0.13989494740962982, acc: 0.9599999785423279)
[2024-11-13 05:30:38,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:38,665][root][INFO] - Training Epoch: 7/10, step 2/574 completed (loss: 0.3620156943798065, acc: 0.8918918967247009)
[2024-11-13 05:30:38,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:38,980][root][INFO] - Training Epoch: 7/10, step 3/574 completed (loss: 0.15851116180419922, acc: 0.9210526347160339)
[2024-11-13 05:30:39,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:39,294][root][INFO] - Training Epoch: 7/10, step 4/574 completed (loss: 0.09106738865375519, acc: 0.9729729890823364)
[2024-11-13 05:30:39,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:39,607][root][INFO] - Training Epoch: 7/10, step 5/574 completed (loss: 0.03507877141237259, acc: 1.0)
[2024-11-13 05:30:39,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:39,924][root][INFO] - Training Epoch: 7/10, step 6/574 completed (loss: 0.2686355710029602, acc: 0.918367326259613)
[2024-11-13 05:30:39,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:40,223][root][INFO] - Training Epoch: 7/10, step 7/574 completed (loss: 0.08647168427705765, acc: 0.9666666388511658)
[2024-11-13 05:30:40,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:40,541][root][INFO] - Training Epoch: 7/10, step 8/574 completed (loss: 0.0012842768337577581, acc: 1.0)
[2024-11-13 05:30:40,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:40,876][root][INFO] - Training Epoch: 7/10, step 9/574 completed (loss: 0.10092711448669434, acc: 0.9615384340286255)
[2024-11-13 05:30:40,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:41,198][root][INFO] - Training Epoch: 7/10, step 10/574 completed (loss: 0.13452447950839996, acc: 0.9259259104728699)
[2024-11-13 05:30:41,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:41,513][root][INFO] - Training Epoch: 7/10, step 11/574 completed (loss: 0.09024850279092789, acc: 0.9743589758872986)
[2024-11-13 05:30:41,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:41,854][root][INFO] - Training Epoch: 7/10, step 12/574 completed (loss: 0.018236057832837105, acc: 1.0)
[2024-11-13 05:30:41,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:42,171][root][INFO] - Training Epoch: 7/10, step 13/574 completed (loss: 0.05909816548228264, acc: 0.97826087474823)
[2024-11-13 05:30:42,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:42,500][root][INFO] - Training Epoch: 7/10, step 14/574 completed (loss: 0.0791010856628418, acc: 0.9607843160629272)
[2024-11-13 05:30:42,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:42,845][root][INFO] - Training Epoch: 7/10, step 15/574 completed (loss: 0.08778015524148941, acc: 0.9795918464660645)
[2024-11-13 05:30:42,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:43,115][root][INFO] - Training Epoch: 7/10, step 16/574 completed (loss: 0.010055086575448513, acc: 1.0)
[2024-11-13 05:30:43,184][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:43,370][root][INFO] - Training Epoch: 7/10, step 17/574 completed (loss: 0.3073410391807556, acc: 0.9166666865348816)
[2024-11-13 05:30:43,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:43,667][root][INFO] - Training Epoch: 7/10, step 18/574 completed (loss: 0.09704142063856125, acc: 0.9444444179534912)
[2024-11-13 05:30:43,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:43,967][root][INFO] - Training Epoch: 7/10, step 19/574 completed (loss: 0.039567865431308746, acc: 1.0)
[2024-11-13 05:30:44,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:44,330][root][INFO] - Training Epoch: 7/10, step 20/574 completed (loss: 0.22192756831645966, acc: 0.9615384340286255)
[2024-11-13 05:30:44,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:44,670][root][INFO] - Training Epoch: 7/10, step 21/574 completed (loss: 0.18711644411087036, acc: 0.9655172228813171)
[2024-11-13 05:30:44,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:44,991][root][INFO] - Training Epoch: 7/10, step 22/574 completed (loss: 0.0354062020778656, acc: 1.0)
[2024-11-13 05:30:45,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:45,322][root][INFO] - Training Epoch: 7/10, step 23/574 completed (loss: 0.004420052748173475, acc: 1.0)
[2024-11-13 05:30:45,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:45,654][root][INFO] - Training Epoch: 7/10, step 24/574 completed (loss: 0.019073905423283577, acc: 1.0)
[2024-11-13 05:30:45,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:45,979][root][INFO] - Training Epoch: 7/10, step 25/574 completed (loss: 0.4575328230857849, acc: 0.9433962106704712)
[2024-11-13 05:30:46,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:46,291][root][INFO] - Training Epoch: 7/10, step 26/574 completed (loss: 0.497346967458725, acc: 0.835616409778595)
[2024-11-13 05:30:46,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:47,668][root][INFO] - Training Epoch: 7/10, step 27/574 completed (loss: 0.9907273650169373, acc: 0.7430830001831055)
[2024-11-13 05:30:47,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:47,959][root][INFO] - Training Epoch: 7/10, step 28/574 completed (loss: 0.19109588861465454, acc: 0.9069767594337463)
[2024-11-13 05:30:48,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:48,272][root][INFO] - Training Epoch: 7/10, step 29/574 completed (loss: 0.22356504201889038, acc: 0.9277108311653137)
[2024-11-13 05:30:48,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:48,585][root][INFO] - Training Epoch: 7/10, step 30/574 completed (loss: 0.35933345556259155, acc: 0.9012345671653748)
[2024-11-13 05:30:48,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:48,885][root][INFO] - Training Epoch: 7/10, step 31/574 completed (loss: 0.1857290416955948, acc: 0.9285714030265808)
[2024-11-13 05:30:48,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:49,178][root][INFO] - Training Epoch: 7/10, step 32/574 completed (loss: 0.026990382000803947, acc: 1.0)
[2024-11-13 05:30:49,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:49,555][root][INFO] - Training Epoch: 7/10, step 33/574 completed (loss: 0.012370751239359379, acc: 1.0)
[2024-11-13 05:30:49,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:49,922][root][INFO] - Training Epoch: 7/10, step 34/574 completed (loss: 0.41410690546035767, acc: 0.8739495873451233)
[2024-11-13 05:30:50,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:50,266][root][INFO] - Training Epoch: 7/10, step 35/574 completed (loss: 0.28719791769981384, acc: 0.9180327653884888)
[2024-11-13 05:30:50,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:50,606][root][INFO] - Training Epoch: 7/10, step 36/574 completed (loss: 0.25239938497543335, acc: 0.9365079402923584)
[2024-11-13 05:30:50,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:50,950][root][INFO] - Training Epoch: 7/10, step 37/574 completed (loss: 0.2467532604932785, acc: 0.8983050584793091)
[2024-11-13 05:30:51,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:51,275][root][INFO] - Training Epoch: 7/10, step 38/574 completed (loss: 0.2801630198955536, acc: 0.9080459475517273)
[2024-11-13 05:30:51,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:51,584][root][INFO] - Training Epoch: 7/10, step 39/574 completed (loss: 0.05769522860646248, acc: 1.0)
[2024-11-13 05:30:51,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:51,921][root][INFO] - Training Epoch: 7/10, step 40/574 completed (loss: 0.10720168799161911, acc: 0.9615384340286255)
[2024-11-13 05:30:52,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:52,273][root][INFO] - Training Epoch: 7/10, step 41/574 completed (loss: 0.18910515308380127, acc: 0.9324324131011963)
[2024-11-13 05:30:52,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:52,595][root][INFO] - Training Epoch: 7/10, step 42/574 completed (loss: 0.298665314912796, acc: 0.9076923131942749)
[2024-11-13 05:30:52,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:52,988][root][INFO] - Training Epoch: 7/10, step 43/574 completed (loss: 0.3658759891986847, acc: 0.8484848737716675)
[2024-11-13 05:30:53,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:53,403][root][INFO] - Training Epoch: 7/10, step 44/574 completed (loss: 0.3350186049938202, acc: 0.907216489315033)
[2024-11-13 05:30:53,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:53,802][root][INFO] - Training Epoch: 7/10, step 45/574 completed (loss: 0.29889819025993347, acc: 0.904411792755127)
[2024-11-13 05:30:53,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:54,105][root][INFO] - Training Epoch: 7/10, step 46/574 completed (loss: 0.033176351338624954, acc: 1.0)
[2024-11-13 05:30:54,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:54,397][root][INFO] - Training Epoch: 7/10, step 47/574 completed (loss: 0.038838427513837814, acc: 1.0)
[2024-11-13 05:30:54,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:54,705][root][INFO] - Training Epoch: 7/10, step 48/574 completed (loss: 0.5012226104736328, acc: 0.8571428656578064)
[2024-11-13 05:30:54,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:55,025][root][INFO] - Training Epoch: 7/10, step 49/574 completed (loss: 0.03609684482216835, acc: 1.0)
[2024-11-13 05:30:55,114][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:55,339][root][INFO] - Training Epoch: 7/10, step 50/574 completed (loss: 0.44959527254104614, acc: 0.859649121761322)
[2024-11-13 05:30:55,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:55,654][root][INFO] - Training Epoch: 7/10, step 51/574 completed (loss: 0.3269326388835907, acc: 0.8730158805847168)
[2024-11-13 05:30:55,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:55,955][root][INFO] - Training Epoch: 7/10, step 52/574 completed (loss: 0.5210566520690918, acc: 0.8450704216957092)
[2024-11-13 05:30:56,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:56,412][root][INFO] - Training Epoch: 7/10, step 53/574 completed (loss: 1.1418585777282715, acc: 0.6399999856948853)
[2024-11-13 05:30:56,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:56,768][root][INFO] - Training Epoch: 7/10, step 54/574 completed (loss: 0.23931047320365906, acc: 0.9459459185600281)
[2024-11-13 05:30:56,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:30:57,110][root][INFO] - Training Epoch: 7/10, step 55/574 completed (loss: 0.014899646863341331, acc: 1.0)
[2024-11-13 05:30:58,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:00,311][root][INFO] - Training Epoch: 7/10, step 56/574 completed (loss: 0.899722695350647, acc: 0.744027316570282)
[2024-11-13 05:31:00,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:01,603][root][INFO] - Training Epoch: 7/10, step 57/574 completed (loss: 1.2418076992034912, acc: 0.6688452959060669)
[2024-11-13 05:31:01,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:02,223][root][INFO] - Training Epoch: 7/10, step 58/574 completed (loss: 0.5296739935874939, acc: 0.8181818127632141)
[2024-11-13 05:31:02,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:02,792][root][INFO] - Training Epoch: 7/10, step 59/574 completed (loss: 0.24671010673046112, acc: 0.9264705777168274)
[2024-11-13 05:31:02,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:03,351][root][INFO] - Training Epoch: 7/10, step 60/574 completed (loss: 0.7003504037857056, acc: 0.7753623127937317)
[2024-11-13 05:31:03,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:03,778][root][INFO] - Training Epoch: 7/10, step 61/574 completed (loss: 0.6808431148529053, acc: 0.8374999761581421)
[2024-11-13 05:31:03,872][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:04,111][root][INFO] - Training Epoch: 7/10, step 62/574 completed (loss: 0.07654908299446106, acc: 0.970588207244873)
[2024-11-13 05:31:04,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:04,454][root][INFO] - Training Epoch: 7/10, step 63/574 completed (loss: 0.07694119215011597, acc: 0.9722222089767456)
[2024-11-13 05:31:04,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:04,857][root][INFO] - Training Epoch: 7/10, step 64/574 completed (loss: 0.046008430421352386, acc: 0.984375)
[2024-11-13 05:31:05,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:05,299][root][INFO] - Training Epoch: 7/10, step 65/574 completed (loss: 0.00944881234318018, acc: 1.0)
[2024-11-13 05:31:05,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:05,685][root][INFO] - Training Epoch: 7/10, step 66/574 completed (loss: 0.37464943528175354, acc: 0.875)
[2024-11-13 05:31:05,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:06,065][root][INFO] - Training Epoch: 7/10, step 67/574 completed (loss: 0.19801241159439087, acc: 0.9166666865348816)
[2024-11-13 05:31:06,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:06,413][root][INFO] - Training Epoch: 7/10, step 68/574 completed (loss: 0.11231373995542526, acc: 0.9599999785423279)
[2024-11-13 05:31:06,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:06,804][root][INFO] - Training Epoch: 7/10, step 69/574 completed (loss: 0.2873939275741577, acc: 0.8888888955116272)
[2024-11-13 05:31:06,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:07,110][root][INFO] - Training Epoch: 7/10, step 70/574 completed (loss: 0.3622903525829315, acc: 0.8787878751754761)
[2024-11-13 05:31:07,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:07,458][root][INFO] - Training Epoch: 7/10, step 71/574 completed (loss: 0.5808162689208984, acc: 0.7941176295280457)
[2024-11-13 05:31:07,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:07,826][root][INFO] - Training Epoch: 7/10, step 72/574 completed (loss: 0.43710729479789734, acc: 0.8888888955116272)
[2024-11-13 05:31:07,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:08,261][root][INFO] - Training Epoch: 7/10, step 73/574 completed (loss: 1.031431794166565, acc: 0.7128205299377441)
[2024-11-13 05:31:08,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:08,681][root][INFO] - Training Epoch: 7/10, step 74/574 completed (loss: 0.5677829384803772, acc: 0.8163265585899353)
[2024-11-13 05:31:08,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:09,025][root][INFO] - Training Epoch: 7/10, step 75/574 completed (loss: 0.7444275617599487, acc: 0.7910447716712952)
[2024-11-13 05:31:09,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:09,414][root][INFO] - Training Epoch: 7/10, step 76/574 completed (loss: 1.1444135904312134, acc: 0.6678832173347473)
[2024-11-13 05:31:09,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:09,712][root][INFO] - Training Epoch: 7/10, step 77/574 completed (loss: 0.023162847384810448, acc: 1.0)
[2024-11-13 05:31:09,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:10,065][root][INFO] - Training Epoch: 7/10, step 78/574 completed (loss: 0.09267596155405045, acc: 0.9583333134651184)
[2024-11-13 05:31:10,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:10,439][root][INFO] - Training Epoch: 7/10, step 79/574 completed (loss: 0.044262807816267014, acc: 1.0)
[2024-11-13 05:31:10,546][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:10,779][root][INFO] - Training Epoch: 7/10, step 80/574 completed (loss: 0.01236254908144474, acc: 1.0)
[2024-11-13 05:31:10,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:11,169][root][INFO] - Training Epoch: 7/10, step 81/574 completed (loss: 0.142066091299057, acc: 0.9615384340286255)
[2024-11-13 05:31:11,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:11,502][root][INFO] - Training Epoch: 7/10, step 82/574 completed (loss: 0.251585453748703, acc: 0.9230769276618958)
[2024-11-13 05:31:11,578][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:11,850][root][INFO] - Training Epoch: 7/10, step 83/574 completed (loss: 0.08982285112142563, acc: 1.0)
[2024-11-13 05:31:11,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:12,175][root][INFO] - Training Epoch: 7/10, step 84/574 completed (loss: 0.1498815268278122, acc: 0.9710144996643066)
[2024-11-13 05:31:12,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:12,577][root][INFO] - Training Epoch: 7/10, step 85/574 completed (loss: 0.1976287066936493, acc: 0.9599999785423279)
[2024-11-13 05:31:12,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:12,909][root][INFO] - Training Epoch: 7/10, step 86/574 completed (loss: 0.02955767698585987, acc: 1.0)
[2024-11-13 05:31:13,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:13,372][root][INFO] - Training Epoch: 7/10, step 87/574 completed (loss: 0.2665872871875763, acc: 0.9200000166893005)
[2024-11-13 05:31:13,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:13,720][root][INFO] - Training Epoch: 7/10, step 88/574 completed (loss: 0.5429436564445496, acc: 0.8252426981925964)
[2024-11-13 05:31:14,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:14,881][root][INFO] - Training Epoch: 7/10, step 89/574 completed (loss: 0.7765741944313049, acc: 0.8106796145439148)
[2024-11-13 05:31:15,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:15,700][root][INFO] - Training Epoch: 7/10, step 90/574 completed (loss: 0.846168041229248, acc: 0.7526881694793701)
[2024-11-13 05:31:15,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:16,500][root][INFO] - Training Epoch: 7/10, step 91/574 completed (loss: 0.6141959428787231, acc: 0.8232758641242981)
[2024-11-13 05:31:16,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:17,243][root][INFO] - Training Epoch: 7/10, step 92/574 completed (loss: 0.6578090190887451, acc: 0.8315789699554443)
[2024-11-13 05:31:17,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:18,231][root][INFO] - Training Epoch: 7/10, step 93/574 completed (loss: 0.7484514117240906, acc: 0.7920792102813721)
[2024-11-13 05:31:18,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:18,516][root][INFO] - Training Epoch: 7/10, step 94/574 completed (loss: 0.602684736251831, acc: 0.8225806355476379)
[2024-11-13 05:31:18,617][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:18,864][root][INFO] - Training Epoch: 7/10, step 95/574 completed (loss: 0.5496748089790344, acc: 0.8405796885490417)
[2024-11-13 05:31:19,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:19,279][root][INFO] - Training Epoch: 7/10, step 96/574 completed (loss: 0.692505955696106, acc: 0.7310924530029297)
[2024-11-13 05:31:19,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:19,676][root][INFO] - Training Epoch: 7/10, step 97/574 completed (loss: 0.5950260758399963, acc: 0.8365384340286255)
[2024-11-13 05:31:19,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:20,084][root][INFO] - Training Epoch: 7/10, step 98/574 completed (loss: 0.7037178874015808, acc: 0.7737226486206055)
[2024-11-13 05:31:20,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:20,422][root][INFO] - Training Epoch: 7/10, step 99/574 completed (loss: 0.5630102753639221, acc: 0.8358209133148193)
[2024-11-13 05:31:20,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:20,777][root][INFO] - Training Epoch: 7/10, step 100/574 completed (loss: 0.05761270597577095, acc: 1.0)
[2024-11-13 05:31:20,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:21,103][root][INFO] - Training Epoch: 7/10, step 101/574 completed (loss: 0.09965315461158752, acc: 0.9545454382896423)
[2024-11-13 05:31:21,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:21,443][root][INFO] - Training Epoch: 7/10, step 102/574 completed (loss: 0.012638254091143608, acc: 1.0)
[2024-11-13 05:31:21,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:21,799][root][INFO] - Training Epoch: 7/10, step 103/574 completed (loss: 0.053671933710575104, acc: 0.9772727489471436)
[2024-11-13 05:31:21,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:22,178][root][INFO] - Training Epoch: 7/10, step 104/574 completed (loss: 0.21780171990394592, acc: 0.931034505367279)
[2024-11-13 05:31:22,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:22,496][root][INFO] - Training Epoch: 7/10, step 105/574 completed (loss: 0.045841705054044724, acc: 0.9767441749572754)
[2024-11-13 05:31:22,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:22,857][root][INFO] - Training Epoch: 7/10, step 106/574 completed (loss: 0.12588244676589966, acc: 0.9599999785423279)
[2024-11-13 05:31:22,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:23,264][root][INFO] - Training Epoch: 7/10, step 107/574 completed (loss: 0.02687498740851879, acc: 1.0)
[2024-11-13 05:31:23,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:23,627][root][INFO] - Training Epoch: 7/10, step 108/574 completed (loss: 0.004213152918964624, acc: 1.0)
[2024-11-13 05:31:23,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:23,965][root][INFO] - Training Epoch: 7/10, step 109/574 completed (loss: 0.03384951874613762, acc: 0.976190447807312)
[2024-11-13 05:31:24,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:24,383][root][INFO] - Training Epoch: 7/10, step 110/574 completed (loss: 0.06278538703918457, acc: 0.9846153855323792)
[2024-11-13 05:31:24,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:24,851][root][INFO] - Training Epoch: 7/10, step 111/574 completed (loss: 0.16238351166248322, acc: 0.9649122953414917)
[2024-11-13 05:31:24,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:25,211][root][INFO] - Training Epoch: 7/10, step 112/574 completed (loss: 0.3607748746871948, acc: 0.8421052694320679)
[2024-11-13 05:31:25,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:25,585][root][INFO] - Training Epoch: 7/10, step 113/574 completed (loss: 0.20326930284500122, acc: 0.9487179517745972)
[2024-11-13 05:31:25,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:26,005][root][INFO] - Training Epoch: 7/10, step 114/574 completed (loss: 0.10159606486558914, acc: 0.9387755393981934)
[2024-11-13 05:31:26,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:26,361][root][INFO] - Training Epoch: 7/10, step 115/574 completed (loss: 0.029750652611255646, acc: 1.0)
[2024-11-13 05:31:26,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:26,756][root][INFO] - Training Epoch: 7/10, step 116/574 completed (loss: 0.42288511991500854, acc: 0.8730158805847168)
[2024-11-13 05:31:26,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:27,177][root][INFO] - Training Epoch: 7/10, step 117/574 completed (loss: 0.2924037277698517, acc: 0.8861788511276245)
[2024-11-13 05:31:27,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:27,562][root][INFO] - Training Epoch: 7/10, step 118/574 completed (loss: 0.12639299035072327, acc: 0.9677419066429138)
[2024-11-13 05:31:27,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:28,436][root][INFO] - Training Epoch: 7/10, step 119/574 completed (loss: 0.8595894575119019, acc: 0.7794677019119263)
[2024-11-13 05:31:28,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:28,777][root][INFO] - Training Epoch: 7/10, step 120/574 completed (loss: 0.16731834411621094, acc: 0.9466666579246521)
[2024-11-13 05:31:28,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:29,182][root][INFO] - Training Epoch: 7/10, step 121/574 completed (loss: 0.17270377278327942, acc: 0.9230769276618958)
[2024-11-13 05:31:29,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:29,458][root][INFO] - Training Epoch: 7/10, step 122/574 completed (loss: 0.005991354119032621, acc: 1.0)
[2024-11-13 05:31:29,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:29,832][root][INFO] - Training Epoch: 7/10, step 123/574 completed (loss: 0.04190053418278694, acc: 1.0)
[2024-11-13 05:31:29,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:30,233][root][INFO] - Training Epoch: 7/10, step 124/574 completed (loss: 0.8424306511878967, acc: 0.7423312664031982)
[2024-11-13 05:31:30,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:30,688][root][INFO] - Training Epoch: 7/10, step 125/574 completed (loss: 0.7013353705406189, acc: 0.8333333134651184)
[2024-11-13 05:31:30,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:31,088][root][INFO] - Training Epoch: 7/10, step 126/574 completed (loss: 0.7076565027236938, acc: 0.7749999761581421)
[2024-11-13 05:31:31,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:31,443][root][INFO] - Training Epoch: 7/10, step 127/574 completed (loss: 0.7077282667160034, acc: 0.7976190447807312)
[2024-11-13 05:31:31,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:31,849][root][INFO] - Training Epoch: 7/10, step 128/574 completed (loss: 0.6373188495635986, acc: 0.8307692408561707)
[2024-11-13 05:31:31,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:32,256][root][INFO] - Training Epoch: 7/10, step 129/574 completed (loss: 0.6116848587989807, acc: 0.8235294222831726)
[2024-11-13 05:31:32,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:32,566][root][INFO] - Training Epoch: 7/10, step 130/574 completed (loss: 0.06972650438547134, acc: 1.0)
[2024-11-13 05:31:33,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:33,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:34,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:34,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:34,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:35,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:35,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:35,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:36,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:36,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:37,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:37,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:37,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:38,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:38,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:39,163][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:39,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:39,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:40,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:40,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:40,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:41,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:41,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:41,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:42,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:42,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:42,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:43,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:43,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:43,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:44,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:44,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:44,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:45,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:45,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:45,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:46,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:46,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:46,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:47,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:47,712][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:47,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:48,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:48,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:49,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:49,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:49,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:50,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:50,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:50,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:50,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:51,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:51,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:51,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:52,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:52,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:53,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:53,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:53,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:53,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:54,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:55,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:55,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:56,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:56,675][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:57,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:57,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:57,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:58,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:58,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:59,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:59,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:31:59,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:00,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:00,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:00,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:01,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:01,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:01,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:02,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:02,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:02,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:03,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:03,795][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4466, device='cuda:0') eval_epoch_loss=tensor(0.8947, device='cuda:0') eval_epoch_acc=tensor(0.7945, device='cuda:0')
[2024-11-13 05:32:03,797][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:32:03,797][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:32:04,269][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_7_step_131_loss_0.8946848511695862/model.pt
[2024-11-13 05:32:04,273][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:32:04,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:04,630][root][INFO] - Training Epoch: 7/10, step 131/574 completed (loss: 0.6659626364707947, acc: 0.9130434989929199)
[2024-11-13 05:32:04,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:04,976][root][INFO] - Training Epoch: 7/10, step 132/574 completed (loss: 0.17110224068164825, acc: 0.96875)
[2024-11-13 05:32:05,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:05,314][root][INFO] - Training Epoch: 7/10, step 133/574 completed (loss: 0.11369452625513077, acc: 0.95652174949646)
[2024-11-13 05:32:05,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:05,633][root][INFO] - Training Epoch: 7/10, step 134/574 completed (loss: 0.06124512106180191, acc: 1.0)
[2024-11-13 05:32:05,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:05,926][root][INFO] - Training Epoch: 7/10, step 135/574 completed (loss: 0.03584396094083786, acc: 1.0)
[2024-11-13 05:32:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:06,220][root][INFO] - Training Epoch: 7/10, step 136/574 completed (loss: 0.13662944734096527, acc: 0.9285714030265808)
[2024-11-13 05:32:06,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:06,591][root][INFO] - Training Epoch: 7/10, step 137/574 completed (loss: 0.4808918535709381, acc: 0.8666666746139526)
[2024-11-13 05:32:06,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:06,909][root][INFO] - Training Epoch: 7/10, step 138/574 completed (loss: 0.5140293836593628, acc: 0.8695651888847351)
[2024-11-13 05:32:06,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:07,212][root][INFO] - Training Epoch: 7/10, step 139/574 completed (loss: 0.05968894809484482, acc: 0.9523809552192688)
[2024-11-13 05:32:07,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:07,510][root][INFO] - Training Epoch: 7/10, step 140/574 completed (loss: 0.07615428417921066, acc: 0.9615384340286255)
[2024-11-13 05:32:07,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:07,918][root][INFO] - Training Epoch: 7/10, step 141/574 completed (loss: 0.1374230980873108, acc: 1.0)
[2024-11-13 05:32:08,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:08,287][root][INFO] - Training Epoch: 7/10, step 142/574 completed (loss: 0.12402407079935074, acc: 0.9459459185600281)
[2024-11-13 05:32:08,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:08,847][root][INFO] - Training Epoch: 7/10, step 143/574 completed (loss: 0.5610366463661194, acc: 0.7894737124443054)
[2024-11-13 05:32:08,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:09,252][root][INFO] - Training Epoch: 7/10, step 144/574 completed (loss: 0.5483572483062744, acc: 0.8134328126907349)
[2024-11-13 05:32:09,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:09,632][root][INFO] - Training Epoch: 7/10, step 145/574 completed (loss: 0.3291846215724945, acc: 0.8877550959587097)
[2024-11-13 05:32:09,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:10,079][root][INFO] - Training Epoch: 7/10, step 146/574 completed (loss: 0.5987870097160339, acc: 0.7765957713127136)
[2024-11-13 05:32:10,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:10,451][root][INFO] - Training Epoch: 7/10, step 147/574 completed (loss: 0.40268611907958984, acc: 0.8571428656578064)
[2024-11-13 05:32:10,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:10,792][root][INFO] - Training Epoch: 7/10, step 148/574 completed (loss: 0.14978539943695068, acc: 0.9642857313156128)
[2024-11-13 05:32:10,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:11,119][root][INFO] - Training Epoch: 7/10, step 149/574 completed (loss: 0.12414053082466125, acc: 0.95652174949646)
[2024-11-13 05:32:11,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:11,536][root][INFO] - Training Epoch: 7/10, step 150/574 completed (loss: 0.14073804020881653, acc: 0.931034505367279)
[2024-11-13 05:32:11,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:11,936][root][INFO] - Training Epoch: 7/10, step 151/574 completed (loss: 0.5104876160621643, acc: 0.8695651888847351)
[2024-11-13 05:32:12,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:12,330][root][INFO] - Training Epoch: 7/10, step 152/574 completed (loss: 0.22228047251701355, acc: 0.9152542352676392)
[2024-11-13 05:32:12,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:12,674][root][INFO] - Training Epoch: 7/10, step 153/574 completed (loss: 0.2621937096118927, acc: 0.8771929740905762)
[2024-11-13 05:32:12,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:13,032][root][INFO] - Training Epoch: 7/10, step 154/574 completed (loss: 0.37157267332077026, acc: 0.8513513803482056)
[2024-11-13 05:32:13,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:13,382][root][INFO] - Training Epoch: 7/10, step 155/574 completed (loss: 0.0395239032804966, acc: 1.0)
[2024-11-13 05:32:13,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:13,703][root][INFO] - Training Epoch: 7/10, step 156/574 completed (loss: 0.42220553755760193, acc: 0.8260869383811951)
[2024-11-13 05:32:13,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:13,990][root][INFO] - Training Epoch: 7/10, step 157/574 completed (loss: 0.3797568082809448, acc: 0.8947368264198303)
[2024-11-13 05:32:14,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:15,676][root][INFO] - Training Epoch: 7/10, step 158/574 completed (loss: 0.8654889464378357, acc: 0.7837837934494019)
[2024-11-13 05:32:15,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:16,073][root][INFO] - Training Epoch: 7/10, step 159/574 completed (loss: 0.7121762633323669, acc: 0.7777777910232544)
[2024-11-13 05:32:16,203][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:16,477][root][INFO] - Training Epoch: 7/10, step 160/574 completed (loss: 0.4988497793674469, acc: 0.8837209343910217)
[2024-11-13 05:32:16,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:17,073][root][INFO] - Training Epoch: 7/10, step 161/574 completed (loss: 0.5607697367668152, acc: 0.8352941274642944)
[2024-11-13 05:32:17,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:17,665][root][INFO] - Training Epoch: 7/10, step 162/574 completed (loss: 0.7500969767570496, acc: 0.8202247023582458)
[2024-11-13 05:32:17,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:17,998][root][INFO] - Training Epoch: 7/10, step 163/574 completed (loss: 0.1955597996711731, acc: 0.9545454382896423)
[2024-11-13 05:32:18,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:18,319][root][INFO] - Training Epoch: 7/10, step 164/574 completed (loss: 0.12233944237232208, acc: 0.9523809552192688)
[2024-11-13 05:32:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:18,596][root][INFO] - Training Epoch: 7/10, step 165/574 completed (loss: 0.4133574366569519, acc: 0.7931034564971924)
[2024-11-13 05:32:18,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:18,973][root][INFO] - Training Epoch: 7/10, step 166/574 completed (loss: 0.0714283213019371, acc: 0.9795918464660645)
[2024-11-13 05:32:19,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:19,358][root][INFO] - Training Epoch: 7/10, step 167/574 completed (loss: 0.1743377447128296, acc: 0.9800000190734863)
[2024-11-13 05:32:19,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:19,766][root][INFO] - Training Epoch: 7/10, step 168/574 completed (loss: 0.5182451605796814, acc: 0.8472222089767456)
[2024-11-13 05:32:19,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:20,182][root][INFO] - Training Epoch: 7/10, step 169/574 completed (loss: 0.71466463804245, acc: 0.843137264251709)
[2024-11-13 05:32:20,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:21,210][root][INFO] - Training Epoch: 7/10, step 170/574 completed (loss: 0.5326295495033264, acc: 0.8493150472640991)
[2024-11-13 05:32:21,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:21,484][root][INFO] - Training Epoch: 7/10, step 171/574 completed (loss: 0.09408888965845108, acc: 0.9583333134651184)
[2024-11-13 05:32:21,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:21,807][root][INFO] - Training Epoch: 7/10, step 172/574 completed (loss: 0.180906280875206, acc: 0.8888888955116272)
[2024-11-13 05:32:21,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:22,205][root][INFO] - Training Epoch: 7/10, step 173/574 completed (loss: 0.09678535163402557, acc: 0.9642857313156128)
[2024-11-13 05:32:22,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:22,743][root][INFO] - Training Epoch: 7/10, step 174/574 completed (loss: 0.7861047387123108, acc: 0.752212405204773)
[2024-11-13 05:32:22,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:23,118][root][INFO] - Training Epoch: 7/10, step 175/574 completed (loss: 0.4799652099609375, acc: 0.8550724387168884)
[2024-11-13 05:32:23,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:23,498][root][INFO] - Training Epoch: 7/10, step 176/574 completed (loss: 0.2437509149312973, acc: 0.9204545617103577)
[2024-11-13 05:32:23,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:24,407][root][INFO] - Training Epoch: 7/10, step 177/574 completed (loss: 0.8461408615112305, acc: 0.732824444770813)
[2024-11-13 05:32:24,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:25,091][root][INFO] - Training Epoch: 7/10, step 178/574 completed (loss: 0.7746676802635193, acc: 0.7925925850868225)
[2024-11-13 05:32:25,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:25,444][root][INFO] - Training Epoch: 7/10, step 179/574 completed (loss: 0.24037426710128784, acc: 0.9180327653884888)
[2024-11-13 05:32:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:25,776][root][INFO] - Training Epoch: 7/10, step 180/574 completed (loss: 0.02300497144460678, acc: 1.0)
[2024-11-13 05:32:25,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:26,080][root][INFO] - Training Epoch: 7/10, step 181/574 completed (loss: 0.039118025451898575, acc: 0.9599999785423279)
[2024-11-13 05:32:26,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:26,485][root][INFO] - Training Epoch: 7/10, step 182/574 completed (loss: 0.05630610138177872, acc: 1.0)
[2024-11-13 05:32:26,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:26,828][root][INFO] - Training Epoch: 7/10, step 183/574 completed (loss: 0.10734402388334274, acc: 0.9756097793579102)
[2024-11-13 05:32:26,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:27,163][root][INFO] - Training Epoch: 7/10, step 184/574 completed (loss: 0.5002504587173462, acc: 0.8731117844581604)
[2024-11-13 05:32:27,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:27,459][root][INFO] - Training Epoch: 7/10, step 185/574 completed (loss: 0.5761085152626038, acc: 0.8270893096923828)
[2024-11-13 05:32:27,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:27,936][root][INFO] - Training Epoch: 7/10, step 186/574 completed (loss: 0.489715576171875, acc: 0.8500000238418579)
[2024-11-13 05:32:28,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:28,460][root][INFO] - Training Epoch: 7/10, step 187/574 completed (loss: 0.6297942996025085, acc: 0.8161351084709167)
[2024-11-13 05:32:28,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:28,870][root][INFO] - Training Epoch: 7/10, step 188/574 completed (loss: 0.5195334553718567, acc: 0.854092538356781)
[2024-11-13 05:32:28,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:29,195][root][INFO] - Training Epoch: 7/10, step 189/574 completed (loss: 0.030065525323152542, acc: 1.0)
[2024-11-13 05:32:29,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:29,748][root][INFO] - Training Epoch: 7/10, step 190/574 completed (loss: 0.49138548970222473, acc: 0.8139534592628479)
[2024-11-13 05:32:29,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:30,540][root][INFO] - Training Epoch: 7/10, step 191/574 completed (loss: 0.7531830072402954, acc: 0.7698412537574768)
[2024-11-13 05:32:30,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:31,451][root][INFO] - Training Epoch: 7/10, step 192/574 completed (loss: 0.6712679862976074, acc: 0.7954545617103577)
[2024-11-13 05:32:31,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:32,194][root][INFO] - Training Epoch: 7/10, step 193/574 completed (loss: 0.3015742599964142, acc: 0.8705882430076599)
[2024-11-13 05:32:32,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:33,275][root][INFO] - Training Epoch: 7/10, step 194/574 completed (loss: 0.6650894284248352, acc: 0.8086419701576233)
[2024-11-13 05:32:33,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:34,227][root][INFO] - Training Epoch: 7/10, step 195/574 completed (loss: 0.16842636466026306, acc: 0.9354838728904724)
[2024-11-13 05:32:34,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:34,527][root][INFO] - Training Epoch: 7/10, step 196/574 completed (loss: 0.00723553029820323, acc: 1.0)
[2024-11-13 05:32:34,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:34,791][root][INFO] - Training Epoch: 7/10, step 197/574 completed (loss: 0.21839284896850586, acc: 0.925000011920929)
[2024-11-13 05:32:34,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:35,096][root][INFO] - Training Epoch: 7/10, step 198/574 completed (loss: 0.25329849123954773, acc: 0.8823529481887817)
[2024-11-13 05:32:35,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:35,406][root][INFO] - Training Epoch: 7/10, step 199/574 completed (loss: 0.4931355118751526, acc: 0.845588207244873)
[2024-11-13 05:32:35,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:35,791][root][INFO] - Training Epoch: 7/10, step 200/574 completed (loss: 0.4567905366420746, acc: 0.8644067645072937)
[2024-11-13 05:32:35,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:36,184][root][INFO] - Training Epoch: 7/10, step 201/574 completed (loss: 0.5126841068267822, acc: 0.8208954930305481)
[2024-11-13 05:32:36,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:36,520][root][INFO] - Training Epoch: 7/10, step 202/574 completed (loss: 0.4867590665817261, acc: 0.8640776872634888)
[2024-11-13 05:32:36,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:36,916][root][INFO] - Training Epoch: 7/10, step 203/574 completed (loss: 0.2210518717765808, acc: 0.9047619104385376)
[2024-11-13 05:32:37,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:37,238][root][INFO] - Training Epoch: 7/10, step 204/574 completed (loss: 0.09821730107069016, acc: 0.9890109896659851)
[2024-11-13 05:32:37,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:37,558][root][INFO] - Training Epoch: 7/10, step 205/574 completed (loss: 0.21049532294273376, acc: 0.9372197389602661)
[2024-11-13 05:32:37,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:37,954][root][INFO] - Training Epoch: 7/10, step 206/574 completed (loss: 0.310364305973053, acc: 0.9251968264579773)
[2024-11-13 05:32:38,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:38,270][root][INFO] - Training Epoch: 7/10, step 207/574 completed (loss: 0.2980839014053345, acc: 0.9051724076271057)
[2024-11-13 05:32:38,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:38,668][root][INFO] - Training Epoch: 7/10, step 208/574 completed (loss: 0.35627150535583496, acc: 0.9057971239089966)
[2024-11-13 05:32:38,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:39,094][root][INFO] - Training Epoch: 7/10, step 209/574 completed (loss: 0.25292283296585083, acc: 0.9105058312416077)
[2024-11-13 05:32:39,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:39,500][root][INFO] - Training Epoch: 7/10, step 210/574 completed (loss: 0.12360922247171402, acc: 0.97826087474823)
[2024-11-13 05:32:39,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:39,822][root][INFO] - Training Epoch: 7/10, step 211/574 completed (loss: 0.06606142967939377, acc: 0.95652174949646)
[2024-11-13 05:32:39,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:40,166][root][INFO] - Training Epoch: 7/10, step 212/574 completed (loss: 0.03422131761908531, acc: 1.0)
[2024-11-13 05:32:40,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:40,532][root][INFO] - Training Epoch: 7/10, step 213/574 completed (loss: 0.17720210552215576, acc: 0.957446813583374)
[2024-11-13 05:32:40,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:41,218][root][INFO] - Training Epoch: 7/10, step 214/574 completed (loss: 0.23282389342784882, acc: 0.9230769276618958)
[2024-11-13 05:32:41,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:41,557][root][INFO] - Training Epoch: 7/10, step 215/574 completed (loss: 0.11131438612937927, acc: 0.9864864945411682)
[2024-11-13 05:32:41,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:41,908][root][INFO] - Training Epoch: 7/10, step 216/574 completed (loss: 0.06448506563901901, acc: 0.9883720874786377)
[2024-11-13 05:32:42,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:42,442][root][INFO] - Training Epoch: 7/10, step 217/574 completed (loss: 0.11312057822942734, acc: 0.9729729890823364)
[2024-11-13 05:32:42,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:42,829][root][INFO] - Training Epoch: 7/10, step 218/574 completed (loss: 0.13673464953899384, acc: 0.9333333373069763)
[2024-11-13 05:32:42,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:43,145][root][INFO] - Training Epoch: 7/10, step 219/574 completed (loss: 0.022868525236845016, acc: 1.0)
[2024-11-13 05:32:43,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:43,428][root][INFO] - Training Epoch: 7/10, step 220/574 completed (loss: 0.03661980852484703, acc: 1.0)
[2024-11-13 05:32:43,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:43,804][root][INFO] - Training Epoch: 7/10, step 221/574 completed (loss: 0.15015767514705658, acc: 0.9599999785423279)
[2024-11-13 05:32:43,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:44,206][root][INFO] - Training Epoch: 7/10, step 222/574 completed (loss: 0.5524299144744873, acc: 0.8461538553237915)
[2024-11-13 05:32:44,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:44,970][root][INFO] - Training Epoch: 7/10, step 223/574 completed (loss: 0.30935904383659363, acc: 0.8913043737411499)
[2024-11-13 05:32:45,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:45,535][root][INFO] - Training Epoch: 7/10, step 224/574 completed (loss: 0.3762156665325165, acc: 0.8863636255264282)
[2024-11-13 05:32:45,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:45,976][root][INFO] - Training Epoch: 7/10, step 225/574 completed (loss: 0.34142035245895386, acc: 0.8510638475418091)
[2024-11-13 05:32:46,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:46,370][root][INFO] - Training Epoch: 7/10, step 226/574 completed (loss: 0.1570798009634018, acc: 0.9622641801834106)
[2024-11-13 05:32:46,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:46,718][root][INFO] - Training Epoch: 7/10, step 227/574 completed (loss: 0.12704338133335114, acc: 0.9666666388511658)
[2024-11-13 05:32:46,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:47,067][root][INFO] - Training Epoch: 7/10, step 228/574 completed (loss: 0.24156007170677185, acc: 0.930232584476471)
[2024-11-13 05:32:47,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:47,362][root][INFO] - Training Epoch: 7/10, step 229/574 completed (loss: 0.440778911113739, acc: 0.8666666746139526)
[2024-11-13 05:32:47,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:47,688][root][INFO] - Training Epoch: 7/10, step 230/574 completed (loss: 1.152190089225769, acc: 0.6842105388641357)
[2024-11-13 05:32:47,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:47,979][root][INFO] - Training Epoch: 7/10, step 231/574 completed (loss: 0.8268312215805054, acc: 0.7555555701255798)
[2024-11-13 05:32:48,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:48,382][root][INFO] - Training Epoch: 7/10, step 232/574 completed (loss: 1.0304783582687378, acc: 0.7166666388511658)
[2024-11-13 05:32:48,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:48,869][root][INFO] - Training Epoch: 7/10, step 233/574 completed (loss: 1.4018584489822388, acc: 0.6146789193153381)
[2024-11-13 05:32:49,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:49,348][root][INFO] - Training Epoch: 7/10, step 234/574 completed (loss: 0.7835683226585388, acc: 0.7769230604171753)
[2024-11-13 05:32:49,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:49,707][root][INFO] - Training Epoch: 7/10, step 235/574 completed (loss: 0.039997246116399765, acc: 1.0)
[2024-11-13 05:32:49,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:50,091][root][INFO] - Training Epoch: 7/10, step 236/574 completed (loss: 0.02512221783399582, acc: 1.0)
[2024-11-13 05:32:50,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:50,485][root][INFO] - Training Epoch: 7/10, step 237/574 completed (loss: 0.225747212767601, acc: 0.9545454382896423)
[2024-11-13 05:32:50,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:50,857][root][INFO] - Training Epoch: 7/10, step 238/574 completed (loss: 0.29985421895980835, acc: 0.8888888955116272)
[2024-11-13 05:32:50,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:51,167][root][INFO] - Training Epoch: 7/10, step 239/574 completed (loss: 0.2647978365421295, acc: 0.9428571462631226)
[2024-11-13 05:32:51,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:51,505][root][INFO] - Training Epoch: 7/10, step 240/574 completed (loss: 0.3496212661266327, acc: 0.9090909361839294)
[2024-11-13 05:32:51,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:51,906][root][INFO] - Training Epoch: 7/10, step 241/574 completed (loss: 0.3771365284919739, acc: 0.8863636255264282)
[2024-11-13 05:32:52,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:52,484][root][INFO] - Training Epoch: 7/10, step 242/574 completed (loss: 0.756209135055542, acc: 0.7419354915618896)
[2024-11-13 05:32:52,641][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:53,014][root][INFO] - Training Epoch: 7/10, step 243/574 completed (loss: 0.4692453145980835, acc: 0.8636363744735718)
[2024-11-13 05:32:53,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:53,337][root][INFO] - Training Epoch: 7/10, step 244/574 completed (loss: 0.006782102398574352, acc: 1.0)
[2024-11-13 05:32:53,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:53,687][root][INFO] - Training Epoch: 7/10, step 245/574 completed (loss: 0.23898299038410187, acc: 0.9615384340286255)
[2024-11-13 05:32:53,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:54,051][root][INFO] - Training Epoch: 7/10, step 246/574 completed (loss: 0.10792887955904007, acc: 0.9354838728904724)
[2024-11-13 05:32:54,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:54,366][root][INFO] - Training Epoch: 7/10, step 247/574 completed (loss: 0.03196167200803757, acc: 1.0)
[2024-11-13 05:32:54,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:54,697][root][INFO] - Training Epoch: 7/10, step 248/574 completed (loss: 0.28507447242736816, acc: 0.8918918967247009)
[2024-11-13 05:32:54,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:55,032][root][INFO] - Training Epoch: 7/10, step 249/574 completed (loss: 0.40605053305625916, acc: 0.8918918967247009)
[2024-11-13 05:32:55,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:55,385][root][INFO] - Training Epoch: 7/10, step 250/574 completed (loss: 0.13577647507190704, acc: 0.9459459185600281)
[2024-11-13 05:32:55,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:55,760][root][INFO] - Training Epoch: 7/10, step 251/574 completed (loss: 0.25502869486808777, acc: 0.9411764740943909)
[2024-11-13 05:32:55,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:56,156][root][INFO] - Training Epoch: 7/10, step 252/574 completed (loss: 0.02192085236310959, acc: 1.0)
[2024-11-13 05:32:56,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:56,529][root][INFO] - Training Epoch: 7/10, step 253/574 completed (loss: 0.011315636336803436, acc: 1.0)
[2024-11-13 05:32:56,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:56,849][root][INFO] - Training Epoch: 7/10, step 254/574 completed (loss: 0.0037062272895127535, acc: 1.0)
[2024-11-13 05:32:56,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:57,182][root][INFO] - Training Epoch: 7/10, step 255/574 completed (loss: 0.009384090080857277, acc: 1.0)
[2024-11-13 05:32:57,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:57,591][root][INFO] - Training Epoch: 7/10, step 256/574 completed (loss: 0.08454286307096481, acc: 0.9824561476707458)
[2024-11-13 05:32:57,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:57,891][root][INFO] - Training Epoch: 7/10, step 257/574 completed (loss: 0.2021401971578598, acc: 0.9428571462631226)
[2024-11-13 05:32:57,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:58,241][root][INFO] - Training Epoch: 7/10, step 258/574 completed (loss: 0.13466030359268188, acc: 0.9736841917037964)
[2024-11-13 05:32:58,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:58,801][root][INFO] - Training Epoch: 7/10, step 259/574 completed (loss: 0.3642542064189911, acc: 0.9056603908538818)
[2024-11-13 05:32:58,967][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:59,416][root][INFO] - Training Epoch: 7/10, step 260/574 completed (loss: 0.3476918935775757, acc: 0.9083333611488342)
[2024-11-13 05:32:59,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:32:59,731][root][INFO] - Training Epoch: 7/10, step 261/574 completed (loss: 0.13540615141391754, acc: 0.9444444179534912)
[2024-11-13 05:32:59,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:00,042][root][INFO] - Training Epoch: 7/10, step 262/574 completed (loss: 0.2186722755432129, acc: 0.9354838728904724)
[2024-11-13 05:33:00,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:00,366][root][INFO] - Training Epoch: 7/10, step 263/574 completed (loss: 0.705942690372467, acc: 0.7599999904632568)
[2024-11-13 05:33:00,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:00,731][root][INFO] - Training Epoch: 7/10, step 264/574 completed (loss: 0.3864503800868988, acc: 0.8958333134651184)
[2024-11-13 05:33:01,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:01,642][root][INFO] - Training Epoch: 7/10, step 265/574 completed (loss: 0.8370964527130127, acc: 0.6959999799728394)
[2024-11-13 05:33:01,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:02,006][root][INFO] - Training Epoch: 7/10, step 266/574 completed (loss: 0.5532910227775574, acc: 0.8202247023582458)
[2024-11-13 05:33:02,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:02,398][root][INFO] - Training Epoch: 7/10, step 267/574 completed (loss: 0.36365383863449097, acc: 0.8648648858070374)
[2024-11-13 05:33:02,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:02,848][root][INFO] - Training Epoch: 7/10, step 268/574 completed (loss: 0.22056230902671814, acc: 0.931034505367279)
[2024-11-13 05:33:02,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:03,143][root][INFO] - Training Epoch: 7/10, step 269/574 completed (loss: 0.03713288903236389, acc: 1.0)
[2024-11-13 05:33:03,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:03,474][root][INFO] - Training Epoch: 7/10, step 270/574 completed (loss: 0.023152798414230347, acc: 1.0)
[2024-11-13 05:33:03,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:03,779][root][INFO] - Training Epoch: 7/10, step 271/574 completed (loss: 0.030790990218520164, acc: 1.0)
[2024-11-13 05:33:03,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:04,124][root][INFO] - Training Epoch: 7/10, step 272/574 completed (loss: 0.23649050295352936, acc: 0.9666666388511658)
[2024-11-13 05:33:04,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:04,554][root][INFO] - Training Epoch: 7/10, step 273/574 completed (loss: 0.17874763906002045, acc: 0.9666666388511658)
[2024-11-13 05:33:05,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:05,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:06,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:06,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:06,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:06,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:07,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:07,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:08,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:08,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:08,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:09,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:09,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:10,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:10,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:11,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:11,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:12,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:12,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:12,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:13,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:13,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:14,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:14,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:14,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:15,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:15,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:15,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:16,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:16,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:17,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:17,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:18,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:18,359][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:18,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:19,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:19,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:19,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:20,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:20,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:21,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:21,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:21,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:22,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:22,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:22,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:23,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:23,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:23,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:24,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:24,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:24,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:25,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:25,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:25,859][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:26,202][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:26,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:26,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:27,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:27,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:28,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:28,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:28,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:29,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:29,511][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:29,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:30,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:30,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:30,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:31,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:31,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:31,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:32,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:32,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:32,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:33,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:33,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:33,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:34,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:34,353][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:34,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:35,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:35,785][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5172, device='cuda:0') eval_epoch_loss=tensor(0.9231, device='cuda:0') eval_epoch_acc=tensor(0.7847, device='cuda:0')
[2024-11-13 05:33:35,787][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:33:35,787][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:33:36,105][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_7_step_274_loss_0.923147976398468/model.pt
[2024-11-13 05:33:36,109][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:33:36,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:36,585][root][INFO] - Training Epoch: 7/10, step 274/574 completed (loss: 0.041760992258787155, acc: 1.0)
[2024-11-13 05:33:36,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:36,962][root][INFO] - Training Epoch: 7/10, step 275/574 completed (loss: 0.04163146764039993, acc: 1.0)
[2024-11-13 05:33:37,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:37,360][root][INFO] - Training Epoch: 7/10, step 276/574 completed (loss: 0.09125122427940369, acc: 0.9655172228813171)
[2024-11-13 05:33:37,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:37,752][root][INFO] - Training Epoch: 7/10, step 277/574 completed (loss: 0.07847192883491516, acc: 1.0)
[2024-11-13 05:33:37,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:38,123][root][INFO] - Training Epoch: 7/10, step 278/574 completed (loss: 0.2814467251300812, acc: 0.914893627166748)
[2024-11-13 05:33:38,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:38,509][root][INFO] - Training Epoch: 7/10, step 279/574 completed (loss: 0.2469034194946289, acc: 0.9375)
[2024-11-13 05:33:38,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:38,910][root][INFO] - Training Epoch: 7/10, step 280/574 completed (loss: 0.05689265578985214, acc: 1.0)
[2024-11-13 05:33:39,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:39,366][root][INFO] - Training Epoch: 7/10, step 281/574 completed (loss: 0.4719572961330414, acc: 0.8674699068069458)
[2024-11-13 05:33:39,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:39,759][root][INFO] - Training Epoch: 7/10, step 282/574 completed (loss: 0.9075618982315063, acc: 0.75)
[2024-11-13 05:33:39,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:40,107][root][INFO] - Training Epoch: 7/10, step 283/574 completed (loss: 0.0237242691218853, acc: 1.0)
[2024-11-13 05:33:40,185][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:40,419][root][INFO] - Training Epoch: 7/10, step 284/574 completed (loss: 0.1838928908109665, acc: 0.9411764740943909)
[2024-11-13 05:33:40,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:40,704][root][INFO] - Training Epoch: 7/10, step 285/574 completed (loss: 0.037973802536726, acc: 0.9750000238418579)
[2024-11-13 05:33:40,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:41,072][root][INFO] - Training Epoch: 7/10, step 286/574 completed (loss: 0.2598566710948944, acc: 0.921875)
[2024-11-13 05:33:41,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:41,470][root][INFO] - Training Epoch: 7/10, step 287/574 completed (loss: 0.36316588521003723, acc: 0.9039999842643738)
[2024-11-13 05:33:41,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:41,875][root][INFO] - Training Epoch: 7/10, step 288/574 completed (loss: 0.17008332908153534, acc: 0.9560439586639404)
[2024-11-13 05:33:41,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:42,220][root][INFO] - Training Epoch: 7/10, step 289/574 completed (loss: 0.24896612763404846, acc: 0.9192546606063843)
[2024-11-13 05:33:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:42,578][root][INFO] - Training Epoch: 7/10, step 290/574 completed (loss: 0.438846617937088, acc: 0.8711340427398682)
[2024-11-13 05:33:42,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:42,960][root][INFO] - Training Epoch: 7/10, step 291/574 completed (loss: 0.01018503773957491, acc: 1.0)
[2024-11-13 05:33:43,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:43,301][root][INFO] - Training Epoch: 7/10, step 292/574 completed (loss: 0.2006816416978836, acc: 0.9523809552192688)
[2024-11-13 05:33:43,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:43,623][root][INFO] - Training Epoch: 7/10, step 293/574 completed (loss: 0.05000239983201027, acc: 1.0)
[2024-11-13 05:33:43,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:44,069][root][INFO] - Training Epoch: 7/10, step 294/574 completed (loss: 0.1907527595758438, acc: 0.9272727370262146)
[2024-11-13 05:33:44,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:44,677][root][INFO] - Training Epoch: 7/10, step 295/574 completed (loss: 0.5661507248878479, acc: 0.8247422575950623)
[2024-11-13 05:33:44,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:45,075][root][INFO] - Training Epoch: 7/10, step 296/574 completed (loss: 0.3002389371395111, acc: 0.9482758641242981)
[2024-11-13 05:33:45,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:45,413][root][INFO] - Training Epoch: 7/10, step 297/574 completed (loss: 0.036105092614889145, acc: 1.0)
[2024-11-13 05:33:45,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:45,720][root][INFO] - Training Epoch: 7/10, step 298/574 completed (loss: 0.11475841701030731, acc: 0.9473684430122375)
[2024-11-13 05:33:45,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:46,116][root][INFO] - Training Epoch: 7/10, step 299/574 completed (loss: 0.11798304319381714, acc: 0.9464285969734192)
[2024-11-13 05:33:46,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:46,439][root][INFO] - Training Epoch: 7/10, step 300/574 completed (loss: 0.05975829437375069, acc: 0.96875)
[2024-11-13 05:33:46,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:46,767][root][INFO] - Training Epoch: 7/10, step 301/574 completed (loss: 0.024546349421143532, acc: 1.0)
[2024-11-13 05:33:46,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:47,082][root][INFO] - Training Epoch: 7/10, step 302/574 completed (loss: 0.0149247320368886, acc: 1.0)
[2024-11-13 05:33:47,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:47,376][root][INFO] - Training Epoch: 7/10, step 303/574 completed (loss: 0.018757233396172523, acc: 1.0)
[2024-11-13 05:33:47,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:47,723][root][INFO] - Training Epoch: 7/10, step 304/574 completed (loss: 0.08161487430334091, acc: 0.96875)
[2024-11-13 05:33:47,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:48,038][root][INFO] - Training Epoch: 7/10, step 305/574 completed (loss: 0.21387025713920593, acc: 0.9016393423080444)
[2024-11-13 05:33:48,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:48,380][root][INFO] - Training Epoch: 7/10, step 306/574 completed (loss: 0.04855513945221901, acc: 1.0)
[2024-11-13 05:33:48,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:48,641][root][INFO] - Training Epoch: 7/10, step 307/574 completed (loss: 0.004020028281956911, acc: 1.0)
[2024-11-13 05:33:48,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:49,044][root][INFO] - Training Epoch: 7/10, step 308/574 completed (loss: 0.10187727212905884, acc: 0.9710144996643066)
[2024-11-13 05:33:49,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:49,480][root][INFO] - Training Epoch: 7/10, step 309/574 completed (loss: 0.1840820163488388, acc: 0.9583333134651184)
[2024-11-13 05:33:49,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:49,838][root][INFO] - Training Epoch: 7/10, step 310/574 completed (loss: 0.13923047482967377, acc: 0.9518072009086609)
[2024-11-13 05:33:49,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:50,225][root][INFO] - Training Epoch: 7/10, step 311/574 completed (loss: 0.24604149162769318, acc: 0.9102563858032227)
[2024-11-13 05:33:50,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:50,613][root][INFO] - Training Epoch: 7/10, step 312/574 completed (loss: 0.1857316792011261, acc: 0.9591836929321289)
[2024-11-13 05:33:50,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:50,921][root][INFO] - Training Epoch: 7/10, step 313/574 completed (loss: 0.01173620019108057, acc: 1.0)
[2024-11-13 05:33:51,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:51,241][root][INFO] - Training Epoch: 7/10, step 314/574 completed (loss: 0.056563232094049454, acc: 1.0)
[2024-11-13 05:33:51,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:51,532][root][INFO] - Training Epoch: 7/10, step 315/574 completed (loss: 0.22548751533031464, acc: 0.9354838728904724)
[2024-11-13 05:33:51,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:51,865][root][INFO] - Training Epoch: 7/10, step 316/574 completed (loss: 0.2178431749343872, acc: 0.9354838728904724)
[2024-11-13 05:33:51,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:52,189][root][INFO] - Training Epoch: 7/10, step 317/574 completed (loss: 0.0635748878121376, acc: 0.9701492786407471)
[2024-11-13 05:33:52,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:52,553][root][INFO] - Training Epoch: 7/10, step 318/574 completed (loss: 0.030234185978770256, acc: 1.0)
[2024-11-13 05:33:52,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:52,886][root][INFO] - Training Epoch: 7/10, step 319/574 completed (loss: 0.023284126073122025, acc: 1.0)
[2024-11-13 05:33:53,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:53,236][root][INFO] - Training Epoch: 7/10, step 320/574 completed (loss: 0.046680353581905365, acc: 0.9838709831237793)
[2024-11-13 05:33:53,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:53,635][root][INFO] - Training Epoch: 7/10, step 321/574 completed (loss: 0.009375978261232376, acc: 1.0)
[2024-11-13 05:33:53,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:53,973][root][INFO] - Training Epoch: 7/10, step 322/574 completed (loss: 0.6912440657615662, acc: 0.7777777910232544)
[2024-11-13 05:33:54,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:54,346][root][INFO] - Training Epoch: 7/10, step 323/574 completed (loss: 0.2944301962852478, acc: 0.9428571462631226)
[2024-11-13 05:33:54,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:54,759][root][INFO] - Training Epoch: 7/10, step 324/574 completed (loss: 0.20197422802448273, acc: 0.9743589758872986)
[2024-11-13 05:33:54,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:55,140][root][INFO] - Training Epoch: 7/10, step 325/574 completed (loss: 0.516063392162323, acc: 0.8536585569381714)
[2024-11-13 05:33:55,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:55,474][root][INFO] - Training Epoch: 7/10, step 326/574 completed (loss: 0.2353593409061432, acc: 0.9473684430122375)
[2024-11-13 05:33:55,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:55,794][root][INFO] - Training Epoch: 7/10, step 327/574 completed (loss: 0.008640303276479244, acc: 1.0)
[2024-11-13 05:33:55,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:56,159][root][INFO] - Training Epoch: 7/10, step 328/574 completed (loss: 0.044222358614206314, acc: 0.9642857313156128)
[2024-11-13 05:33:56,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:56,504][root][INFO] - Training Epoch: 7/10, step 329/574 completed (loss: 0.006327562499791384, acc: 1.0)
[2024-11-13 05:33:56,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:56,851][root][INFO] - Training Epoch: 7/10, step 330/574 completed (loss: 0.0012908423086628318, acc: 1.0)
[2024-11-13 05:33:56,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:57,257][root][INFO] - Training Epoch: 7/10, step 331/574 completed (loss: 0.07125133275985718, acc: 0.9838709831237793)
[2024-11-13 05:33:57,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:57,639][root][INFO] - Training Epoch: 7/10, step 332/574 completed (loss: 0.012797978706657887, acc: 1.0)
[2024-11-13 05:33:57,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:57,991][root][INFO] - Training Epoch: 7/10, step 333/574 completed (loss: 0.2328270971775055, acc: 0.96875)
[2024-11-13 05:33:58,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:58,355][root][INFO] - Training Epoch: 7/10, step 334/574 completed (loss: 0.11567529290914536, acc: 0.9666666388511658)
[2024-11-13 05:33:58,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:58,681][root][INFO] - Training Epoch: 7/10, step 335/574 completed (loss: 0.07046528160572052, acc: 0.9473684430122375)
[2024-11-13 05:33:58,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:59,041][root][INFO] - Training Epoch: 7/10, step 336/574 completed (loss: 0.2651561498641968, acc: 0.9399999976158142)
[2024-11-13 05:33:59,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:59,413][root][INFO] - Training Epoch: 7/10, step 337/574 completed (loss: 0.6592136025428772, acc: 0.7701149582862854)
[2024-11-13 05:33:59,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:33:59,790][root][INFO] - Training Epoch: 7/10, step 338/574 completed (loss: 0.7392744421958923, acc: 0.7765957713127136)
[2024-11-13 05:33:59,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:00,193][root][INFO] - Training Epoch: 7/10, step 339/574 completed (loss: 0.4968717694282532, acc: 0.8674699068069458)
[2024-11-13 05:34:00,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:00,498][root][INFO] - Training Epoch: 7/10, step 340/574 completed (loss: 0.008041242137551308, acc: 1.0)
[2024-11-13 05:34:00,570][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:00,787][root][INFO] - Training Epoch: 7/10, step 341/574 completed (loss: 0.13771584630012512, acc: 0.9743589758872986)
[2024-11-13 05:34:00,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:01,191][root][INFO] - Training Epoch: 7/10, step 342/574 completed (loss: 0.13326986134052277, acc: 0.9397590160369873)
[2024-11-13 05:34:01,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:01,604][root][INFO] - Training Epoch: 7/10, step 343/574 completed (loss: 0.21161112189292908, acc: 0.9622641801834106)
[2024-11-13 05:34:01,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:01,976][root][INFO] - Training Epoch: 7/10, step 344/574 completed (loss: 0.06322960555553436, acc: 0.9746835231781006)
[2024-11-13 05:34:02,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:02,354][root][INFO] - Training Epoch: 7/10, step 345/574 completed (loss: 0.11217901110649109, acc: 0.9607843160629272)
[2024-11-13 05:34:02,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:02,743][root][INFO] - Training Epoch: 7/10, step 346/574 completed (loss: 0.12390679121017456, acc: 0.9552238583564758)
[2024-11-13 05:34:02,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:03,097][root][INFO] - Training Epoch: 7/10, step 347/574 completed (loss: 0.15045787394046783, acc: 0.949999988079071)
[2024-11-13 05:34:03,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:03,493][root][INFO] - Training Epoch: 7/10, step 348/574 completed (loss: 0.04577118903398514, acc: 1.0)
[2024-11-13 05:34:03,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:03,915][root][INFO] - Training Epoch: 7/10, step 349/574 completed (loss: 0.3685806095600128, acc: 0.8055555820465088)
[2024-11-13 05:34:04,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:04,334][root][INFO] - Training Epoch: 7/10, step 350/574 completed (loss: 0.5033102035522461, acc: 0.7674418687820435)
[2024-11-13 05:34:04,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:04,741][root][INFO] - Training Epoch: 7/10, step 351/574 completed (loss: 0.09497974067926407, acc: 0.9743589758872986)
[2024-11-13 05:34:04,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:05,123][root][INFO] - Training Epoch: 7/10, step 352/574 completed (loss: 0.26826807856559753, acc: 0.8888888955116272)
[2024-11-13 05:34:05,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:05,439][root][INFO] - Training Epoch: 7/10, step 353/574 completed (loss: 0.2264120876789093, acc: 0.95652174949646)
[2024-11-13 05:34:05,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:05,843][root][INFO] - Training Epoch: 7/10, step 354/574 completed (loss: 0.12574154138565063, acc: 0.9230769276618958)
[2024-11-13 05:34:05,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:06,236][root][INFO] - Training Epoch: 7/10, step 355/574 completed (loss: 0.49890896677970886, acc: 0.8571428656578064)
[2024-11-13 05:34:06,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:06,750][root][INFO] - Training Epoch: 7/10, step 356/574 completed (loss: 0.3438560366630554, acc: 0.886956512928009)
[2024-11-13 05:34:06,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:07,105][root][INFO] - Training Epoch: 7/10, step 357/574 completed (loss: 0.277327299118042, acc: 0.9130434989929199)
[2024-11-13 05:34:07,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:07,485][root][INFO] - Training Epoch: 7/10, step 358/574 completed (loss: 0.24212850630283356, acc: 0.9387755393981934)
[2024-11-13 05:34:07,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:07,845][root][INFO] - Training Epoch: 7/10, step 359/574 completed (loss: 0.0020558072719722986, acc: 1.0)
[2024-11-13 05:34:07,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:08,218][root][INFO] - Training Epoch: 7/10, step 360/574 completed (loss: 0.033415764570236206, acc: 1.0)
[2024-11-13 05:34:08,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:08,598][root][INFO] - Training Epoch: 7/10, step 361/574 completed (loss: 0.09424653649330139, acc: 1.0)
[2024-11-13 05:34:08,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:08,989][root][INFO] - Training Epoch: 7/10, step 362/574 completed (loss: 0.0337483286857605, acc: 1.0)
[2024-11-13 05:34:09,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:09,399][root][INFO] - Training Epoch: 7/10, step 363/574 completed (loss: 0.046778593212366104, acc: 0.9736841917037964)
[2024-11-13 05:34:09,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:09,771][root][INFO] - Training Epoch: 7/10, step 364/574 completed (loss: 0.01810990646481514, acc: 1.0)
[2024-11-13 05:34:09,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:10,122][root][INFO] - Training Epoch: 7/10, step 365/574 completed (loss: 0.03104032203555107, acc: 1.0)
[2024-11-13 05:34:10,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:10,511][root][INFO] - Training Epoch: 7/10, step 366/574 completed (loss: 0.002761872485280037, acc: 1.0)
[2024-11-13 05:34:10,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:10,860][root][INFO] - Training Epoch: 7/10, step 367/574 completed (loss: 0.022731568664312363, acc: 1.0)
[2024-11-13 05:34:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:11,200][root][INFO] - Training Epoch: 7/10, step 368/574 completed (loss: 0.03965082764625549, acc: 1.0)
[2024-11-13 05:34:11,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:11,515][root][INFO] - Training Epoch: 7/10, step 369/574 completed (loss: 0.14529800415039062, acc: 0.96875)
[2024-11-13 05:34:11,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:12,131][root][INFO] - Training Epoch: 7/10, step 370/574 completed (loss: 0.5436489582061768, acc: 0.8545454740524292)
[2024-11-13 05:34:12,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:13,016][root][INFO] - Training Epoch: 7/10, step 371/574 completed (loss: 0.1768987774848938, acc: 0.9528301954269409)
[2024-11-13 05:34:13,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:13,334][root][INFO] - Training Epoch: 7/10, step 372/574 completed (loss: 0.07735477387905121, acc: 0.9777777791023254)
[2024-11-13 05:34:13,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:13,637][root][INFO] - Training Epoch: 7/10, step 373/574 completed (loss: 0.03603307157754898, acc: 1.0)
[2024-11-13 05:34:13,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:14,019][root][INFO] - Training Epoch: 7/10, step 374/574 completed (loss: 0.02646906115114689, acc: 1.0)
[2024-11-13 05:34:14,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:14,379][root][INFO] - Training Epoch: 7/10, step 375/574 completed (loss: 0.0045022242702543736, acc: 1.0)
[2024-11-13 05:34:14,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:14,724][root][INFO] - Training Epoch: 7/10, step 376/574 completed (loss: 0.01523483358323574, acc: 1.0)
[2024-11-13 05:34:14,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:15,050][root][INFO] - Training Epoch: 7/10, step 377/574 completed (loss: 0.10441675037145615, acc: 0.9791666865348816)
[2024-11-13 05:34:15,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:15,389][root][INFO] - Training Epoch: 7/10, step 378/574 completed (loss: 0.06028060242533684, acc: 0.9684210419654846)
[2024-11-13 05:34:15,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:15,960][root][INFO] - Training Epoch: 7/10, step 379/574 completed (loss: 0.27282220125198364, acc: 0.9221556782722473)
[2024-11-13 05:34:16,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:16,367][root][INFO] - Training Epoch: 7/10, step 380/574 completed (loss: 0.22823192179203033, acc: 0.9473684430122375)
[2024-11-13 05:34:16,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:17,447][root][INFO] - Training Epoch: 7/10, step 381/574 completed (loss: 0.468051940202713, acc: 0.8716577291488647)
[2024-11-13 05:34:17,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:18,017][root][INFO] - Training Epoch: 7/10, step 382/574 completed (loss: 0.03419940173625946, acc: 1.0)
[2024-11-13 05:34:18,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:18,311][root][INFO] - Training Epoch: 7/10, step 383/574 completed (loss: 0.11545753479003906, acc: 0.9642857313156128)
[2024-11-13 05:34:18,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:18,587][root][INFO] - Training Epoch: 7/10, step 384/574 completed (loss: 0.0037409462966024876, acc: 1.0)
[2024-11-13 05:34:18,662][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:18,862][root][INFO] - Training Epoch: 7/10, step 385/574 completed (loss: 0.027372712269425392, acc: 1.0)
[2024-11-13 05:34:18,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:19,199][root][INFO] - Training Epoch: 7/10, step 386/574 completed (loss: 0.0028568576090037823, acc: 1.0)
[2024-11-13 05:34:19,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:19,512][root][INFO] - Training Epoch: 7/10, step 387/574 completed (loss: 0.013026305474340916, acc: 1.0)
[2024-11-13 05:34:19,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:19,841][root][INFO] - Training Epoch: 7/10, step 388/574 completed (loss: 0.006083079148083925, acc: 1.0)
[2024-11-13 05:34:19,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:20,146][root][INFO] - Training Epoch: 7/10, step 389/574 completed (loss: 0.003949411679059267, acc: 1.0)
[2024-11-13 05:34:20,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:20,443][root][INFO] - Training Epoch: 7/10, step 390/574 completed (loss: 0.2425200343132019, acc: 0.9523809552192688)
[2024-11-13 05:34:20,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:20,762][root][INFO] - Training Epoch: 7/10, step 391/574 completed (loss: 0.2765197157859802, acc: 0.9074074029922485)
[2024-11-13 05:34:20,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:21,104][root][INFO] - Training Epoch: 7/10, step 392/574 completed (loss: 0.48004791140556335, acc: 0.8349514603614807)
[2024-11-13 05:34:21,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:21,628][root][INFO] - Training Epoch: 7/10, step 393/574 completed (loss: 0.588538408279419, acc: 0.8308823704719543)
[2024-11-13 05:34:21,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:22,047][root][INFO] - Training Epoch: 7/10, step 394/574 completed (loss: 0.4259462356567383, acc: 0.8533333539962769)
[2024-11-13 05:34:22,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:22,442][root][INFO] - Training Epoch: 7/10, step 395/574 completed (loss: 0.35228899121284485, acc: 0.9166666865348816)
[2024-11-13 05:34:22,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:22,804][root][INFO] - Training Epoch: 7/10, step 396/574 completed (loss: 0.09674983471632004, acc: 0.9767441749572754)
[2024-11-13 05:34:22,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:23,200][root][INFO] - Training Epoch: 7/10, step 397/574 completed (loss: 0.08611341565847397, acc: 0.9583333134651184)
[2024-11-13 05:34:23,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:23,542][root][INFO] - Training Epoch: 7/10, step 398/574 completed (loss: 0.03858885541558266, acc: 1.0)
[2024-11-13 05:34:23,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:23,835][root][INFO] - Training Epoch: 7/10, step 399/574 completed (loss: 0.051851753145456314, acc: 0.9599999785423279)
[2024-11-13 05:34:24,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:24,370][root][INFO] - Training Epoch: 7/10, step 400/574 completed (loss: 0.18498879671096802, acc: 0.970588207244873)
[2024-11-13 05:34:24,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:24,678][root][INFO] - Training Epoch: 7/10, step 401/574 completed (loss: 0.28252801299095154, acc: 0.9200000166893005)
[2024-11-13 05:34:24,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:24,974][root][INFO] - Training Epoch: 7/10, step 402/574 completed (loss: 0.07958585768938065, acc: 1.0)
[2024-11-13 05:34:25,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:25,343][root][INFO] - Training Epoch: 7/10, step 403/574 completed (loss: 0.1283315122127533, acc: 0.9090909361839294)
[2024-11-13 05:34:25,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:25,679][root][INFO] - Training Epoch: 7/10, step 404/574 completed (loss: 0.04222588986158371, acc: 1.0)
[2024-11-13 05:34:25,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:26,061][root][INFO] - Training Epoch: 7/10, step 405/574 completed (loss: 0.15933319926261902, acc: 0.9259259104728699)
[2024-11-13 05:34:26,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:26,382][root][INFO] - Training Epoch: 7/10, step 406/574 completed (loss: 0.005557948723435402, acc: 1.0)
[2024-11-13 05:34:26,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:26,693][root][INFO] - Training Epoch: 7/10, step 407/574 completed (loss: 0.04285050556063652, acc: 0.9722222089767456)
[2024-11-13 05:34:26,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:26,982][root][INFO] - Training Epoch: 7/10, step 408/574 completed (loss: 0.08139801770448685, acc: 0.9629629850387573)
[2024-11-13 05:34:27,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:27,333][root][INFO] - Training Epoch: 7/10, step 409/574 completed (loss: 0.004747022874653339, acc: 1.0)
[2024-11-13 05:34:27,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:27,714][root][INFO] - Training Epoch: 7/10, step 410/574 completed (loss: 0.0210769884288311, acc: 1.0)
[2024-11-13 05:34:27,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:28,048][root][INFO] - Training Epoch: 7/10, step 411/574 completed (loss: 0.4485323429107666, acc: 0.8928571343421936)
[2024-11-13 05:34:28,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:28,366][root][INFO] - Training Epoch: 7/10, step 412/574 completed (loss: 0.07755205035209656, acc: 0.9666666388511658)
[2024-11-13 05:34:28,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:28,673][root][INFO] - Training Epoch: 7/10, step 413/574 completed (loss: 0.17210553586483002, acc: 0.9696969985961914)
[2024-11-13 05:34:28,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:28,983][root][INFO] - Training Epoch: 7/10, step 414/574 completed (loss: 0.2759508192539215, acc: 0.9545454382896423)
[2024-11-13 05:34:29,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:29,289][root][INFO] - Training Epoch: 7/10, step 415/574 completed (loss: 0.10574986785650253, acc: 0.9803921580314636)
[2024-11-13 05:34:29,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:29,588][root][INFO] - Training Epoch: 7/10, step 416/574 completed (loss: 0.05296151340007782, acc: 1.0)
[2024-11-13 05:34:30,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:30,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:31,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:31,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:31,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:32,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:32,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:32,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:33,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:33,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:33,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:34,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:34,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:35,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:35,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:35,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:36,112][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:36,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:36,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:37,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:37,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:37,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:38,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:38,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:38,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:39,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:39,475][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:39,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:40,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:40,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:40,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:41,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:41,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:41,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:42,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:42,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:43,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:43,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:43,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:44,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:44,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:44,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:45,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:45,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:45,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:46,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:46,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:46,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:47,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:47,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:47,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:48,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:48,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:49,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:49,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:49,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:49,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:50,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:51,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:51,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:52,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:52,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:52,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:53,192][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:53,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:53,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:54,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:54,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:55,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:55,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:55,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:55,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:56,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:56,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:56,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:57,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:57,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:57,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:58,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:59,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:59,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:34:59,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:00,556][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4946, device='cuda:0') eval_epoch_loss=tensor(0.9141, device='cuda:0') eval_epoch_acc=tensor(0.7872, device='cuda:0')
[2024-11-13 05:35:00,557][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:35:00,557][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:35:00,987][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_7_step_417_loss_0.9141311049461365/model.pt
[2024-11-13 05:35:00,991][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:35:01,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:01,337][root][INFO] - Training Epoch: 7/10, step 417/574 completed (loss: 0.12928152084350586, acc: 0.9444444179534912)
[2024-11-13 05:35:01,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:01,692][root][INFO] - Training Epoch: 7/10, step 418/574 completed (loss: 0.01909237913787365, acc: 1.0)
[2024-11-13 05:35:01,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:02,008][root][INFO] - Training Epoch: 7/10, step 419/574 completed (loss: 0.062028490006923676, acc: 1.0)
[2024-11-13 05:35:02,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:02,362][root][INFO] - Training Epoch: 7/10, step 420/574 completed (loss: 0.039267126470804214, acc: 1.0)
[2024-11-13 05:35:02,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:02,731][root][INFO] - Training Epoch: 7/10, step 421/574 completed (loss: 0.044657349586486816, acc: 1.0)
[2024-11-13 05:35:02,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:03,088][root][INFO] - Training Epoch: 7/10, step 422/574 completed (loss: 0.08726534992456436, acc: 0.96875)
[2024-11-13 05:35:03,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:03,482][root][INFO] - Training Epoch: 7/10, step 423/574 completed (loss: 0.08337586373090744, acc: 0.9722222089767456)
[2024-11-13 05:35:03,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:03,862][root][INFO] - Training Epoch: 7/10, step 424/574 completed (loss: 0.021059583872556686, acc: 1.0)
[2024-11-13 05:35:03,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:04,284][root][INFO] - Training Epoch: 7/10, step 425/574 completed (loss: 0.048976242542266846, acc: 1.0)
[2024-11-13 05:35:04,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:04,616][root][INFO] - Training Epoch: 7/10, step 426/574 completed (loss: 0.05232013761997223, acc: 1.0)
[2024-11-13 05:35:04,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:04,942][root][INFO] - Training Epoch: 7/10, step 427/574 completed (loss: 0.17976050078868866, acc: 0.9459459185600281)
[2024-11-13 05:35:05,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:05,237][root][INFO] - Training Epoch: 7/10, step 428/574 completed (loss: 0.026039443910121918, acc: 1.0)
[2024-11-13 05:35:05,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:05,579][root][INFO] - Training Epoch: 7/10, step 429/574 completed (loss: 0.011885407380759716, acc: 1.0)
[2024-11-13 05:35:05,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:05,957][root][INFO] - Training Epoch: 7/10, step 430/574 completed (loss: 0.0040818159468472, acc: 1.0)
[2024-11-13 05:35:06,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:06,264][root][INFO] - Training Epoch: 7/10, step 431/574 completed (loss: 0.023638859391212463, acc: 1.0)
[2024-11-13 05:35:06,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:06,563][root][INFO] - Training Epoch: 7/10, step 432/574 completed (loss: 0.0050873709842562675, acc: 1.0)
[2024-11-13 05:35:06,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:06,980][root][INFO] - Training Epoch: 7/10, step 433/574 completed (loss: 0.012708652764558792, acc: 1.0)
[2024-11-13 05:35:07,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:07,331][root][INFO] - Training Epoch: 7/10, step 434/574 completed (loss: 0.008169504813849926, acc: 1.0)
[2024-11-13 05:35:07,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:07,689][root][INFO] - Training Epoch: 7/10, step 435/574 completed (loss: 0.04261576384305954, acc: 1.0)
[2024-11-13 05:35:07,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:08,044][root][INFO] - Training Epoch: 7/10, step 436/574 completed (loss: 0.024582788348197937, acc: 1.0)
[2024-11-13 05:35:08,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:08,449][root][INFO] - Training Epoch: 7/10, step 437/574 completed (loss: 0.006583814043551683, acc: 1.0)
[2024-11-13 05:35:08,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:08,775][root][INFO] - Training Epoch: 7/10, step 438/574 completed (loss: 0.01108329463750124, acc: 1.0)
[2024-11-13 05:35:08,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:09,159][root][INFO] - Training Epoch: 7/10, step 439/574 completed (loss: 0.18105721473693848, acc: 0.9743589758872986)
[2024-11-13 05:35:09,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:09,661][root][INFO] - Training Epoch: 7/10, step 440/574 completed (loss: 0.20611682534217834, acc: 0.9090909361839294)
[2024-11-13 05:35:09,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:10,403][root][INFO] - Training Epoch: 7/10, step 441/574 completed (loss: 0.5625684857368469, acc: 0.800000011920929)
[2024-11-13 05:35:10,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:10,857][root][INFO] - Training Epoch: 7/10, step 442/574 completed (loss: 0.4917776882648468, acc: 0.8306451439857483)
[2024-11-13 05:35:11,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:11,532][root][INFO] - Training Epoch: 7/10, step 443/574 completed (loss: 0.4528428614139557, acc: 0.8606964945793152)
[2024-11-13 05:35:11,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:11,848][root][INFO] - Training Epoch: 7/10, step 444/574 completed (loss: 0.049680400639772415, acc: 1.0)
[2024-11-13 05:35:11,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:12,297][root][INFO] - Training Epoch: 7/10, step 445/574 completed (loss: 0.04337276890873909, acc: 0.9772727489471436)
[2024-11-13 05:35:12,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:12,639][root][INFO] - Training Epoch: 7/10, step 446/574 completed (loss: 0.04189886897802353, acc: 1.0)
[2024-11-13 05:35:12,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:12,964][root][INFO] - Training Epoch: 7/10, step 447/574 completed (loss: 0.06475760787725449, acc: 0.9615384340286255)
[2024-11-13 05:35:13,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:13,348][root][INFO] - Training Epoch: 7/10, step 448/574 completed (loss: 0.023357996717095375, acc: 1.0)
[2024-11-13 05:35:13,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:13,693][root][INFO] - Training Epoch: 7/10, step 449/574 completed (loss: 0.036164380609989166, acc: 1.0)
[2024-11-13 05:35:13,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:14,062][root][INFO] - Training Epoch: 7/10, step 450/574 completed (loss: 0.013687375001609325, acc: 1.0)
[2024-11-13 05:35:14,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:14,378][root][INFO] - Training Epoch: 7/10, step 451/574 completed (loss: 0.05805381387472153, acc: 0.97826087474823)
[2024-11-13 05:35:14,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:14,691][root][INFO] - Training Epoch: 7/10, step 452/574 completed (loss: 0.1364869475364685, acc: 0.9358974099159241)
[2024-11-13 05:35:14,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:14,999][root][INFO] - Training Epoch: 7/10, step 453/574 completed (loss: 0.1166796088218689, acc: 0.9473684430122375)
[2024-11-13 05:35:15,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:15,325][root][INFO] - Training Epoch: 7/10, step 454/574 completed (loss: 0.0709184929728508, acc: 0.9591836929321289)
[2024-11-13 05:35:15,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:15,638][root][INFO] - Training Epoch: 7/10, step 455/574 completed (loss: 0.05139021947979927, acc: 0.9696969985961914)
[2024-11-13 05:35:15,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:15,954][root][INFO] - Training Epoch: 7/10, step 456/574 completed (loss: 0.3860001266002655, acc: 0.907216489315033)
[2024-11-13 05:35:16,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:16,269][root][INFO] - Training Epoch: 7/10, step 457/574 completed (loss: 0.04813951998949051, acc: 0.9857142567634583)
[2024-11-13 05:35:16,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:16,689][root][INFO] - Training Epoch: 7/10, step 458/574 completed (loss: 0.341193288564682, acc: 0.8837209343910217)
[2024-11-13 05:35:16,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:16,979][root][INFO] - Training Epoch: 7/10, step 459/574 completed (loss: 0.02707083150744438, acc: 1.0)
[2024-11-13 05:35:17,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:17,289][root][INFO] - Training Epoch: 7/10, step 460/574 completed (loss: 0.19939661026000977, acc: 0.9259259104728699)
[2024-11-13 05:35:17,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:17,556][root][INFO] - Training Epoch: 7/10, step 461/574 completed (loss: 0.011714104562997818, acc: 1.0)
[2024-11-13 05:35:17,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:17,879][root][INFO] - Training Epoch: 7/10, step 462/574 completed (loss: 0.21844914555549622, acc: 0.96875)
[2024-11-13 05:35:17,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:18,174][root][INFO] - Training Epoch: 7/10, step 463/574 completed (loss: 0.016801053658127785, acc: 1.0)
[2024-11-13 05:35:18,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:18,539][root][INFO] - Training Epoch: 7/10, step 464/574 completed (loss: 0.0363384410738945, acc: 1.0)
[2024-11-13 05:35:18,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:18,899][root][INFO] - Training Epoch: 7/10, step 465/574 completed (loss: 0.1995171755552292, acc: 0.9523809552192688)
[2024-11-13 05:35:18,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:19,255][root][INFO] - Training Epoch: 7/10, step 466/574 completed (loss: 0.304934561252594, acc: 0.9156626462936401)
[2024-11-13 05:35:19,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:19,640][root][INFO] - Training Epoch: 7/10, step 467/574 completed (loss: 0.1870938092470169, acc: 0.9459459185600281)
[2024-11-13 05:35:19,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:20,036][root][INFO] - Training Epoch: 7/10, step 468/574 completed (loss: 0.7562209963798523, acc: 0.7961165308952332)
[2024-11-13 05:35:20,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:20,377][root][INFO] - Training Epoch: 7/10, step 469/574 completed (loss: 0.48673540353775024, acc: 0.8617886304855347)
[2024-11-13 05:35:20,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:20,687][root][INFO] - Training Epoch: 7/10, step 470/574 completed (loss: 0.11970067769289017, acc: 0.9583333134651184)
[2024-11-13 05:35:20,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:20,986][root][INFO] - Training Epoch: 7/10, step 471/574 completed (loss: 0.00915430672466755, acc: 1.0)
[2024-11-13 05:35:21,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:21,385][root][INFO] - Training Epoch: 7/10, step 472/574 completed (loss: 0.6446024775505066, acc: 0.8039215803146362)
[2024-11-13 05:35:21,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:21,733][root][INFO] - Training Epoch: 7/10, step 473/574 completed (loss: 0.6085991263389587, acc: 0.7991266250610352)
[2024-11-13 05:35:21,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:22,032][root][INFO] - Training Epoch: 7/10, step 474/574 completed (loss: 0.18783414363861084, acc: 0.9479166865348816)
[2024-11-13 05:35:22,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:22,347][root][INFO] - Training Epoch: 7/10, step 475/574 completed (loss: 0.17792214453220367, acc: 0.9447852969169617)
[2024-11-13 05:35:22,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:22,650][root][INFO] - Training Epoch: 7/10, step 476/574 completed (loss: 0.3442288041114807, acc: 0.8920863270759583)
[2024-11-13 05:35:22,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:22,997][root][INFO] - Training Epoch: 7/10, step 477/574 completed (loss: 0.47578340768814087, acc: 0.8793969750404358)
[2024-11-13 05:35:23,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:23,296][root][INFO] - Training Epoch: 7/10, step 478/574 completed (loss: 0.2620679438114166, acc: 0.8888888955116272)
[2024-11-13 05:35:23,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:23,588][root][INFO] - Training Epoch: 7/10, step 479/574 completed (loss: 0.297709584236145, acc: 0.9090909361839294)
[2024-11-13 05:35:23,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:23,881][root][INFO] - Training Epoch: 7/10, step 480/574 completed (loss: 0.17825184762477875, acc: 0.9259259104728699)
[2024-11-13 05:35:23,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:24,161][root][INFO] - Training Epoch: 7/10, step 481/574 completed (loss: 0.21710661053657532, acc: 0.8999999761581421)
[2024-11-13 05:35:24,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:24,486][root][INFO] - Training Epoch: 7/10, step 482/574 completed (loss: 0.0852527916431427, acc: 1.0)
[2024-11-13 05:35:24,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:24,848][root][INFO] - Training Epoch: 7/10, step 483/574 completed (loss: 0.24684840440750122, acc: 0.9482758641242981)
[2024-11-13 05:35:24,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:25,135][root][INFO] - Training Epoch: 7/10, step 484/574 completed (loss: 0.1897842437028885, acc: 0.9354838728904724)
[2024-11-13 05:35:25,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:25,432][root][INFO] - Training Epoch: 7/10, step 485/574 completed (loss: 0.16287530958652496, acc: 0.9473684430122375)
[2024-11-13 05:35:25,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:25,722][root][INFO] - Training Epoch: 7/10, step 486/574 completed (loss: 0.11171659827232361, acc: 0.9629629850387573)
[2024-11-13 05:35:25,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:26,026][root][INFO] - Training Epoch: 7/10, step 487/574 completed (loss: 0.16857469081878662, acc: 0.9523809552192688)
[2024-11-13 05:35:26,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:26,364][root][INFO] - Training Epoch: 7/10, step 488/574 completed (loss: 0.3569422960281372, acc: 0.8636363744735718)
[2024-11-13 05:35:26,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:26,721][root][INFO] - Training Epoch: 7/10, step 489/574 completed (loss: 0.6212332248687744, acc: 0.8461538553237915)
[2024-11-13 05:35:26,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:27,024][root][INFO] - Training Epoch: 7/10, step 490/574 completed (loss: 0.06390805542469025, acc: 0.9666666388511658)
[2024-11-13 05:35:27,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:27,318][root][INFO] - Training Epoch: 7/10, step 491/574 completed (loss: 0.14713478088378906, acc: 0.931034505367279)
[2024-11-13 05:35:27,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:27,594][root][INFO] - Training Epoch: 7/10, step 492/574 completed (loss: 0.1227363869547844, acc: 0.9803921580314636)
[2024-11-13 05:35:27,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:27,847][root][INFO] - Training Epoch: 7/10, step 493/574 completed (loss: 0.04102149233222008, acc: 1.0)
[2024-11-13 05:35:27,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:28,144][root][INFO] - Training Epoch: 7/10, step 494/574 completed (loss: 0.08189983665943146, acc: 0.9473684430122375)
[2024-11-13 05:35:28,218][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:28,433][root][INFO] - Training Epoch: 7/10, step 495/574 completed (loss: 0.1232437938451767, acc: 0.8947368264198303)
[2024-11-13 05:35:28,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:28,798][root][INFO] - Training Epoch: 7/10, step 496/574 completed (loss: 0.5445235371589661, acc: 0.875)
[2024-11-13 05:35:28,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:29,187][root][INFO] - Training Epoch: 7/10, step 497/574 completed (loss: 0.27554652094841003, acc: 0.898876428604126)
[2024-11-13 05:35:29,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:29,548][root][INFO] - Training Epoch: 7/10, step 498/574 completed (loss: 0.3614727854728699, acc: 0.8426966071128845)
[2024-11-13 05:35:29,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:29,901][root][INFO] - Training Epoch: 7/10, step 499/574 completed (loss: 0.8434834480285645, acc: 0.7234042286872864)
[2024-11-13 05:35:29,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:30,229][root][INFO] - Training Epoch: 7/10, step 500/574 completed (loss: 0.4541473090648651, acc: 0.8695651888847351)
[2024-11-13 05:35:30,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:30,552][root][INFO] - Training Epoch: 7/10, step 501/574 completed (loss: 0.04076702147722244, acc: 1.0)
[2024-11-13 05:35:30,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:30,892][root][INFO] - Training Epoch: 7/10, step 502/574 completed (loss: 0.16231240332126617, acc: 0.9615384340286255)
[2024-11-13 05:35:30,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:31,206][root][INFO] - Training Epoch: 7/10, step 503/574 completed (loss: 0.07602372020483017, acc: 1.0)
[2024-11-13 05:35:31,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:31,507][root][INFO] - Training Epoch: 7/10, step 504/574 completed (loss: 0.0525779165327549, acc: 1.0)
[2024-11-13 05:35:31,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:31,814][root][INFO] - Training Epoch: 7/10, step 505/574 completed (loss: 0.2470300942659378, acc: 0.9245283007621765)
[2024-11-13 05:35:31,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:32,127][root][INFO] - Training Epoch: 7/10, step 506/574 completed (loss: 0.4546998143196106, acc: 0.8620689511299133)
[2024-11-13 05:35:32,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:32,836][root][INFO] - Training Epoch: 7/10, step 507/574 completed (loss: 0.7761225700378418, acc: 0.8108108043670654)
[2024-11-13 05:35:32,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:33,290][root][INFO] - Training Epoch: 7/10, step 508/574 completed (loss: 0.43080559372901917, acc: 0.8873239159584045)
[2024-11-13 05:35:33,365][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:33,595][root][INFO] - Training Epoch: 7/10, step 509/574 completed (loss: 0.2116577923297882, acc: 0.949999988079071)
[2024-11-13 05:35:33,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:33,936][root][INFO] - Training Epoch: 7/10, step 510/574 completed (loss: 0.04857868328690529, acc: 0.9666666388511658)
[2024-11-13 05:35:34,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:34,254][root][INFO] - Training Epoch: 7/10, step 511/574 completed (loss: 0.2351025640964508, acc: 0.9615384340286255)
[2024-11-13 05:35:35,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:37,237][root][INFO] - Training Epoch: 7/10, step 512/574 completed (loss: 0.7554001212120056, acc: 0.7928571701049805)
[2024-11-13 05:35:37,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:38,134][root][INFO] - Training Epoch: 7/10, step 513/574 completed (loss: 0.16019760072231293, acc: 0.9444444179534912)
[2024-11-13 05:35:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:38,512][root][INFO] - Training Epoch: 7/10, step 514/574 completed (loss: 0.12131785601377487, acc: 0.9285714030265808)
[2024-11-13 05:35:38,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:38,931][root][INFO] - Training Epoch: 7/10, step 515/574 completed (loss: 0.056350842118263245, acc: 0.9666666388511658)
[2024-11-13 05:35:39,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:39,849][root][INFO] - Training Epoch: 7/10, step 516/574 completed (loss: 0.2146032303571701, acc: 0.9305555820465088)
[2024-11-13 05:35:39,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:40,285][root][INFO] - Training Epoch: 7/10, step 517/574 completed (loss: 0.002777506597340107, acc: 1.0)
[2024-11-13 05:35:40,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:40,643][root][INFO] - Training Epoch: 7/10, step 518/574 completed (loss: 0.062260083854198456, acc: 0.9677419066429138)
[2024-11-13 05:35:40,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:40,941][root][INFO] - Training Epoch: 7/10, step 519/574 completed (loss: 0.02465927228331566, acc: 1.0)
[2024-11-13 05:35:41,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:41,281][root][INFO] - Training Epoch: 7/10, step 520/574 completed (loss: 0.056723956018686295, acc: 0.9629629850387573)
[2024-11-13 05:35:41,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:42,433][root][INFO] - Training Epoch: 7/10, step 521/574 completed (loss: 0.6384837627410889, acc: 0.8262711763381958)
[2024-11-13 05:35:42,517][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:42,783][root][INFO] - Training Epoch: 7/10, step 522/574 completed (loss: 0.26367995142936707, acc: 0.9402984976768494)
[2024-11-13 05:35:42,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:43,158][root][INFO] - Training Epoch: 7/10, step 523/574 completed (loss: 0.2601264417171478, acc: 0.9051094651222229)
[2024-11-13 05:35:43,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:43,730][root][INFO] - Training Epoch: 7/10, step 524/574 completed (loss: 0.45252788066864014, acc: 0.875)
[2024-11-13 05:35:43,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:44,056][root][INFO] - Training Epoch: 7/10, step 525/574 completed (loss: 0.0361519493162632, acc: 1.0)
[2024-11-13 05:35:44,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:44,365][root][INFO] - Training Epoch: 7/10, step 526/574 completed (loss: 0.20765426754951477, acc: 0.942307710647583)
[2024-11-13 05:35:44,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:44,763][root][INFO] - Training Epoch: 7/10, step 527/574 completed (loss: 0.09679941087961197, acc: 1.0)
[2024-11-13 05:35:44,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:45,181][root][INFO] - Training Epoch: 7/10, step 528/574 completed (loss: 0.5236768126487732, acc: 0.8360655903816223)
[2024-11-13 05:35:45,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:45,480][root][INFO] - Training Epoch: 7/10, step 529/574 completed (loss: 0.11700102686882019, acc: 0.9491525292396545)
[2024-11-13 05:35:45,566][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:45,802][root][INFO] - Training Epoch: 7/10, step 530/574 completed (loss: 0.3445844054222107, acc: 0.8604651093482971)
[2024-11-13 05:35:45,887][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:46,128][root][INFO] - Training Epoch: 7/10, step 531/574 completed (loss: 0.2155882716178894, acc: 0.9318181872367859)
[2024-11-13 05:35:46,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:46,418][root][INFO] - Training Epoch: 7/10, step 532/574 completed (loss: 0.5369614958763123, acc: 0.9056603908538818)
[2024-11-13 05:35:46,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:46,690][root][INFO] - Training Epoch: 7/10, step 533/574 completed (loss: 0.21290916204452515, acc: 0.9772727489471436)
[2024-11-13 05:35:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:47,067][root][INFO] - Training Epoch: 7/10, step 534/574 completed (loss: 0.27077624201774597, acc: 0.9599999785423279)
[2024-11-13 05:35:47,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:47,422][root][INFO] - Training Epoch: 7/10, step 535/574 completed (loss: 0.05042906478047371, acc: 1.0)
[2024-11-13 05:35:47,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:47,735][root][INFO] - Training Epoch: 7/10, step 536/574 completed (loss: 0.034521833062171936, acc: 1.0)
[2024-11-13 05:35:47,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:48,216][root][INFO] - Training Epoch: 7/10, step 537/574 completed (loss: 0.2580125331878662, acc: 0.9230769276618958)
[2024-11-13 05:35:48,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:48,632][root][INFO] - Training Epoch: 7/10, step 538/574 completed (loss: 0.30999520421028137, acc: 0.921875)
[2024-11-13 05:35:48,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:49,108][root][INFO] - Training Epoch: 7/10, step 539/574 completed (loss: 0.16892454028129578, acc: 0.96875)
[2024-11-13 05:35:49,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:49,459][root][INFO] - Training Epoch: 7/10, step 540/574 completed (loss: 0.21997839212417603, acc: 0.9696969985961914)
[2024-11-13 05:35:49,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:49,801][root][INFO] - Training Epoch: 7/10, step 541/574 completed (loss: 0.03280913829803467, acc: 1.0)
[2024-11-13 05:35:49,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:50,211][root][INFO] - Training Epoch: 7/10, step 542/574 completed (loss: 0.048058152198791504, acc: 0.9677419066429138)
[2024-11-13 05:35:50,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:50,542][root][INFO] - Training Epoch: 7/10, step 543/574 completed (loss: 0.0018047867342829704, acc: 1.0)
[2024-11-13 05:35:50,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:50,920][root][INFO] - Training Epoch: 7/10, step 544/574 completed (loss: 0.02213704213500023, acc: 1.0)
[2024-11-13 05:35:51,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:51,287][root][INFO] - Training Epoch: 7/10, step 545/574 completed (loss: 0.059037335216999054, acc: 0.9756097793579102)
[2024-11-13 05:35:51,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:51,596][root][INFO] - Training Epoch: 7/10, step 546/574 completed (loss: 0.024556726217269897, acc: 1.0)
[2024-11-13 05:35:51,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:51,911][root][INFO] - Training Epoch: 7/10, step 547/574 completed (loss: 0.01170919369906187, acc: 1.0)
[2024-11-13 05:35:51,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:52,218][root][INFO] - Training Epoch: 7/10, step 548/574 completed (loss: 0.01530392374843359, acc: 1.0)
[2024-11-13 05:35:52,296][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:52,505][root][INFO] - Training Epoch: 7/10, step 549/574 completed (loss: 0.006733161862939596, acc: 1.0)
[2024-11-13 05:35:52,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:52,799][root][INFO] - Training Epoch: 7/10, step 550/574 completed (loss: 0.042038705199956894, acc: 1.0)
[2024-11-13 05:35:52,874][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:53,094][root][INFO] - Training Epoch: 7/10, step 551/574 completed (loss: 0.06099633127450943, acc: 0.9750000238418579)
[2024-11-13 05:35:53,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:53,516][root][INFO] - Training Epoch: 7/10, step 552/574 completed (loss: 0.1853972226381302, acc: 0.9571428298950195)
[2024-11-13 05:35:53,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:53,917][root][INFO] - Training Epoch: 7/10, step 553/574 completed (loss: 0.31376272439956665, acc: 0.9197080135345459)
[2024-11-13 05:35:54,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:54,245][root][INFO] - Training Epoch: 7/10, step 554/574 completed (loss: 0.12733423709869385, acc: 0.9724137783050537)
[2024-11-13 05:35:54,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:54,557][root][INFO] - Training Epoch: 7/10, step 555/574 completed (loss: 0.16222535073757172, acc: 0.949999988079071)
[2024-11-13 05:35:54,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:54,862][root][INFO] - Training Epoch: 7/10, step 556/574 completed (loss: 0.18895161151885986, acc: 0.9337748289108276)
[2024-11-13 05:35:54,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:55,187][root][INFO] - Training Epoch: 7/10, step 557/574 completed (loss: 0.08603465557098389, acc: 0.9658119678497314)
[2024-11-13 05:35:55,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:55,479][root][INFO] - Training Epoch: 7/10, step 558/574 completed (loss: 0.1500641256570816, acc: 0.9599999785423279)
[2024-11-13 05:35:55,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:55,734][root][INFO] - Training Epoch: 7/10, step 559/574 completed (loss: 0.08828668296337128, acc: 0.9615384340286255)
[2024-11-13 05:35:56,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:57,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:57,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:57,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:58,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:58,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:58,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:59,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:35:59,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:00,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:00,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:00,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:01,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:01,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:01,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:02,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:02,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:02,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:03,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:03,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:04,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:04,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:04,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:05,316][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:05,612][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:06,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:06,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:06,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:07,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:07,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:07,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:08,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:08,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:09,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:09,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:09,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:09,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:10,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:10,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:10,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:11,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:11,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:12,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:12,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:12,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:13,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:13,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:14,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:14,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:14,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:15,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:15,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:15,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:16,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:16,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:16,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:17,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:17,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:17,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:18,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:18,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:19,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:19,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:20,217][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:20,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:20,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:21,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:21,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:21,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:22,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:22,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:22,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:23,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:23,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:23,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:24,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:24,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:25,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:25,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:25,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:26,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:26,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:26,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:27,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:27,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:28,369][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5423, device='cuda:0') eval_epoch_loss=tensor(0.9331, device='cuda:0') eval_epoch_acc=tensor(0.8021, device='cuda:0')
[2024-11-13 05:36:28,371][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:36:28,371][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:36:28,685][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_7_step_560_loss_0.9330625534057617/model.pt
[2024-11-13 05:36:28,691][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:36:28,692][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 7 is 0.8021467328071594
[2024-11-13 05:36:28,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:29,012][root][INFO] - Training Epoch: 7/10, step 560/574 completed (loss: 0.013558023609220982, acc: 1.0)
[2024-11-13 05:36:29,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:29,308][root][INFO] - Training Epoch: 7/10, step 561/574 completed (loss: 0.1483066827058792, acc: 0.9743589758872986)
[2024-11-13 05:36:29,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:29,584][root][INFO] - Training Epoch: 7/10, step 562/574 completed (loss: 0.20896175503730774, acc: 0.9222221970558167)
[2024-11-13 05:36:29,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:29,845][root][INFO] - Training Epoch: 7/10, step 563/574 completed (loss: 0.13708795607089996, acc: 0.948051929473877)
[2024-11-13 05:36:29,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:30,183][root][INFO] - Training Epoch: 7/10, step 564/574 completed (loss: 0.09386635571718216, acc: 0.9583333134651184)
[2024-11-13 05:36:30,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:30,508][root][INFO] - Training Epoch: 7/10, step 565/574 completed (loss: 0.21452344954013824, acc: 0.9482758641242981)
[2024-11-13 05:36:30,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:30,917][root][INFO] - Training Epoch: 7/10, step 566/574 completed (loss: 0.054941240698099136, acc: 0.988095223903656)
[2024-11-13 05:36:31,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:31,346][root][INFO] - Training Epoch: 7/10, step 567/574 completed (loss: 0.20264238119125366, acc: 0.9473684430122375)
[2024-11-13 05:36:31,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:31,698][root][INFO] - Training Epoch: 7/10, step 568/574 completed (loss: 0.08803729712963104, acc: 0.9629629850387573)
[2024-11-13 05:36:31,858][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:32,152][root][INFO] - Training Epoch: 7/10, step 569/574 completed (loss: 0.24492357671260834, acc: 0.9358288645744324)
[2024-11-13 05:36:32,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:32,512][root][INFO] - Training Epoch: 7/10, step 570/574 completed (loss: 0.07517017424106598, acc: 0.9677419066429138)
[2024-11-13 05:36:32,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:32,808][root][INFO] - Training Epoch: 7/10, step 571/574 completed (loss: 0.10156875103712082, acc: 0.9658119678497314)
[2024-11-13 05:36:32,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:33,096][root][INFO] - Training Epoch: 7/10, step 572/574 completed (loss: 0.43656283617019653, acc: 0.8673469424247742)
[2024-11-13 05:36:33,208][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:33,434][root][INFO] - Training Epoch: 7/10, step 573/574 completed (loss: 0.3613387644290924, acc: 0.8867924809455872)
[2024-11-13 05:36:34,020][slam_llm.utils.train_utils][INFO] - Epoch 7: train_perplexity=1.2718, train_epoch_loss=0.2404, epoch time 356.8285499960184s
[2024-11-13 05:36:34,020][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:36:34,020][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 18 GB
[2024-11-13 05:36:34,020][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:36:34,021][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 19
[2024-11-13 05:36:34,021][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:36:34,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:34,925][root][INFO] - Training Epoch: 8/10, step 0/574 completed (loss: 0.10553479194641113, acc: 0.9629629850387573)
[2024-11-13 05:36:35,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:35,235][root][INFO] - Training Epoch: 8/10, step 1/574 completed (loss: 0.045813221484422684, acc: 0.9599999785423279)
[2024-11-13 05:36:35,345][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:35,533][root][INFO] - Training Epoch: 8/10, step 2/574 completed (loss: 0.3225758969783783, acc: 0.8918918967247009)
[2024-11-13 05:36:35,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:35,892][root][INFO] - Training Epoch: 8/10, step 3/574 completed (loss: 0.07101466506719589, acc: 0.9736841917037964)
[2024-11-13 05:36:35,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:36,197][root][INFO] - Training Epoch: 8/10, step 4/574 completed (loss: 0.13142678141593933, acc: 0.9189189076423645)
[2024-11-13 05:36:36,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:36,534][root][INFO] - Training Epoch: 8/10, step 5/574 completed (loss: 0.03035534918308258, acc: 1.0)
[2024-11-13 05:36:36,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:36,885][root][INFO] - Training Epoch: 8/10, step 6/574 completed (loss: 0.3921777904033661, acc: 0.8775510191917419)
[2024-11-13 05:36:36,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:37,177][root][INFO] - Training Epoch: 8/10, step 7/574 completed (loss: 0.10013175755739212, acc: 0.9666666388511658)
[2024-11-13 05:36:37,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:37,501][root][INFO] - Training Epoch: 8/10, step 8/574 completed (loss: 0.07666396349668503, acc: 0.9545454382896423)
[2024-11-13 05:36:37,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:37,799][root][INFO] - Training Epoch: 8/10, step 9/574 completed (loss: 0.0025300406850874424, acc: 1.0)
[2024-11-13 05:36:37,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:38,075][root][INFO] - Training Epoch: 8/10, step 10/574 completed (loss: 0.23621788620948792, acc: 0.9629629850387573)
[2024-11-13 05:36:38,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:38,356][root][INFO] - Training Epoch: 8/10, step 11/574 completed (loss: 0.04337022826075554, acc: 0.9743589758872986)
[2024-11-13 05:36:38,466][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:38,752][root][INFO] - Training Epoch: 8/10, step 12/574 completed (loss: 0.01506835874170065, acc: 1.0)
[2024-11-13 05:36:38,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:39,162][root][INFO] - Training Epoch: 8/10, step 13/574 completed (loss: 0.06484987586736679, acc: 0.97826087474823)
[2024-11-13 05:36:39,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:39,528][root][INFO] - Training Epoch: 8/10, step 14/574 completed (loss: 0.052184220403432846, acc: 0.9803921580314636)
[2024-11-13 05:36:39,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:39,955][root][INFO] - Training Epoch: 8/10, step 15/574 completed (loss: 0.14449867606163025, acc: 0.9795918464660645)
[2024-11-13 05:36:40,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:40,368][root][INFO] - Training Epoch: 8/10, step 16/574 completed (loss: 0.07781050354242325, acc: 0.9473684430122375)
[2024-11-13 05:36:40,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:40,725][root][INFO] - Training Epoch: 8/10, step 17/574 completed (loss: 0.1390383541584015, acc: 0.9166666865348816)
[2024-11-13 05:36:40,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:41,118][root][INFO] - Training Epoch: 8/10, step 18/574 completed (loss: 0.15507720410823822, acc: 0.9444444179534912)
[2024-11-13 05:36:41,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:41,464][root][INFO] - Training Epoch: 8/10, step 19/574 completed (loss: 0.00930696539580822, acc: 1.0)
[2024-11-13 05:36:41,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:41,829][root][INFO] - Training Epoch: 8/10, step 20/574 completed (loss: 0.39619460701942444, acc: 0.9615384340286255)
[2024-11-13 05:36:41,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:42,198][root][INFO] - Training Epoch: 8/10, step 21/574 completed (loss: 0.03472139686346054, acc: 1.0)
[2024-11-13 05:36:42,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:42,574][root][INFO] - Training Epoch: 8/10, step 22/574 completed (loss: 0.23603403568267822, acc: 0.9200000166893005)
[2024-11-13 05:36:42,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:42,947][root][INFO] - Training Epoch: 8/10, step 23/574 completed (loss: 0.11380235105752945, acc: 0.9523809552192688)
[2024-11-13 05:36:43,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:43,332][root][INFO] - Training Epoch: 8/10, step 24/574 completed (loss: 0.04075852781534195, acc: 1.0)
[2024-11-13 05:36:43,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:43,722][root][INFO] - Training Epoch: 8/10, step 25/574 completed (loss: 0.6208811402320862, acc: 0.8867924809455872)
[2024-11-13 05:36:43,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:44,136][root][INFO] - Training Epoch: 8/10, step 26/574 completed (loss: 0.26191043853759766, acc: 0.931506872177124)
[2024-11-13 05:36:44,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:45,480][root][INFO] - Training Epoch: 8/10, step 27/574 completed (loss: 0.7771797776222229, acc: 0.782608687877655)
[2024-11-13 05:36:45,562][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:45,864][root][INFO] - Training Epoch: 8/10, step 28/574 completed (loss: 0.3528747260570526, acc: 0.9069767594337463)
[2024-11-13 05:36:46,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:46,323][root][INFO] - Training Epoch: 8/10, step 29/574 completed (loss: 0.1610194444656372, acc: 0.9638554453849792)
[2024-11-13 05:36:46,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:46,716][root][INFO] - Training Epoch: 8/10, step 30/574 completed (loss: 0.40709757804870605, acc: 0.8518518805503845)
[2024-11-13 05:36:46,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:47,058][root][INFO] - Training Epoch: 8/10, step 31/574 completed (loss: 0.09524232149124146, acc: 0.9642857313156128)
[2024-11-13 05:36:47,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:47,419][root][INFO] - Training Epoch: 8/10, step 32/574 completed (loss: 0.1296057105064392, acc: 0.9629629850387573)
[2024-11-13 05:36:47,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:47,748][root][INFO] - Training Epoch: 8/10, step 33/574 completed (loss: 0.007078445050865412, acc: 1.0)
[2024-11-13 05:36:47,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:48,093][root][INFO] - Training Epoch: 8/10, step 34/574 completed (loss: 0.23901894688606262, acc: 0.924369752407074)
[2024-11-13 05:36:48,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:48,477][root][INFO] - Training Epoch: 8/10, step 35/574 completed (loss: 0.09717302769422531, acc: 0.9508196711540222)
[2024-11-13 05:36:48,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:48,896][root][INFO] - Training Epoch: 8/10, step 36/574 completed (loss: 0.16859528422355652, acc: 0.9682539701461792)
[2024-11-13 05:36:48,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:49,189][root][INFO] - Training Epoch: 8/10, step 37/574 completed (loss: 0.16549357771873474, acc: 0.9322034120559692)
[2024-11-13 05:36:49,277][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:49,518][root][INFO] - Training Epoch: 8/10, step 38/574 completed (loss: 0.24089306592941284, acc: 0.9195402264595032)
[2024-11-13 05:36:49,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:49,901][root][INFO] - Training Epoch: 8/10, step 39/574 completed (loss: 0.07711808383464813, acc: 0.9523809552192688)
[2024-11-13 05:36:50,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:50,301][root][INFO] - Training Epoch: 8/10, step 40/574 completed (loss: 0.0844983384013176, acc: 0.9615384340286255)
[2024-11-13 05:36:50,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:50,634][root][INFO] - Training Epoch: 8/10, step 41/574 completed (loss: 0.21562285721302032, acc: 0.9189189076423645)
[2024-11-13 05:36:50,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:50,972][root][INFO] - Training Epoch: 8/10, step 42/574 completed (loss: 0.19326283037662506, acc: 0.9538461565971375)
[2024-11-13 05:36:51,109][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:51,418][root][INFO] - Training Epoch: 8/10, step 43/574 completed (loss: 0.19245773553848267, acc: 0.9696969985961914)
[2024-11-13 05:36:51,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:51,827][root][INFO] - Training Epoch: 8/10, step 44/574 completed (loss: 0.19226479530334473, acc: 0.9278350472450256)
[2024-11-13 05:36:51,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:52,254][root][INFO] - Training Epoch: 8/10, step 45/574 completed (loss: 0.22793181240558624, acc: 0.9264705777168274)
[2024-11-13 05:36:52,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:52,587][root][INFO] - Training Epoch: 8/10, step 46/574 completed (loss: 0.08753205090761185, acc: 1.0)
[2024-11-13 05:36:52,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:52,982][root][INFO] - Training Epoch: 8/10, step 47/574 completed (loss: 0.010106794536113739, acc: 1.0)
[2024-11-13 05:36:53,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:53,275][root][INFO] - Training Epoch: 8/10, step 48/574 completed (loss: 0.018506856635212898, acc: 1.0)
[2024-11-13 05:36:53,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:53,606][root][INFO] - Training Epoch: 8/10, step 49/574 completed (loss: 0.030893521383404732, acc: 1.0)
[2024-11-13 05:36:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:54,009][root][INFO] - Training Epoch: 8/10, step 50/574 completed (loss: 0.3874276876449585, acc: 0.8771929740905762)
[2024-11-13 05:36:54,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:54,338][root][INFO] - Training Epoch: 8/10, step 51/574 completed (loss: 0.14717456698417664, acc: 0.9523809552192688)
[2024-11-13 05:36:54,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:54,665][root][INFO] - Training Epoch: 8/10, step 52/574 completed (loss: 0.3653014898300171, acc: 0.8591549396514893)
[2024-11-13 05:36:54,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:55,114][root][INFO] - Training Epoch: 8/10, step 53/574 completed (loss: 0.9217893481254578, acc: 0.7066666483879089)
[2024-11-13 05:36:55,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:55,502][root][INFO] - Training Epoch: 8/10, step 54/574 completed (loss: 0.26051148772239685, acc: 0.9459459185600281)
[2024-11-13 05:36:55,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:55,853][root][INFO] - Training Epoch: 8/10, step 55/574 completed (loss: 0.057978369295597076, acc: 0.9615384340286255)
[2024-11-13 05:36:57,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:36:58,940][root][INFO] - Training Epoch: 8/10, step 56/574 completed (loss: 0.7806652784347534, acc: 0.76450514793396)
[2024-11-13 05:36:59,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:00,282][root][INFO] - Training Epoch: 8/10, step 57/574 completed (loss: 1.1451647281646729, acc: 0.7080609798431396)
[2024-11-13 05:37:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:00,904][root][INFO] - Training Epoch: 8/10, step 58/574 completed (loss: 0.43237027525901794, acc: 0.8409090638160706)
[2024-11-13 05:37:01,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:01,471][root][INFO] - Training Epoch: 8/10, step 59/574 completed (loss: 0.1860252171754837, acc: 0.9338235259056091)
[2024-11-13 05:37:01,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:02,039][root][INFO] - Training Epoch: 8/10, step 60/574 completed (loss: 0.41826844215393066, acc: 0.8478260636329651)
[2024-11-13 05:37:02,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:02,459][root][INFO] - Training Epoch: 8/10, step 61/574 completed (loss: 0.4114606976509094, acc: 0.8999999761581421)
[2024-11-13 05:37:02,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:02,863][root][INFO] - Training Epoch: 8/10, step 62/574 completed (loss: 0.02634367160499096, acc: 1.0)
[2024-11-13 05:37:02,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:03,213][root][INFO] - Training Epoch: 8/10, step 63/574 completed (loss: 0.14461150765419006, acc: 0.9722222089767456)
[2024-11-13 05:37:03,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:03,624][root][INFO] - Training Epoch: 8/10, step 64/574 completed (loss: 0.08756885677576065, acc: 0.984375)
[2024-11-13 05:37:03,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:03,919][root][INFO] - Training Epoch: 8/10, step 65/574 completed (loss: 0.017485570162534714, acc: 1.0)
[2024-11-13 05:37:04,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:04,233][root][INFO] - Training Epoch: 8/10, step 66/574 completed (loss: 0.26847562193870544, acc: 0.9285714030265808)
[2024-11-13 05:37:04,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:04,623][root][INFO] - Training Epoch: 8/10, step 67/574 completed (loss: 0.19162262976169586, acc: 0.9333333373069763)
[2024-11-13 05:37:04,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:05,027][root][INFO] - Training Epoch: 8/10, step 68/574 completed (loss: 0.0042036594823002815, acc: 1.0)
[2024-11-13 05:37:05,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:05,416][root][INFO] - Training Epoch: 8/10, step 69/574 completed (loss: 0.09916608780622482, acc: 0.9444444179534912)
[2024-11-13 05:37:05,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:05,810][root][INFO] - Training Epoch: 8/10, step 70/574 completed (loss: 0.07366681843996048, acc: 0.9696969985961914)
[2024-11-13 05:37:05,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:06,178][root][INFO] - Training Epoch: 8/10, step 71/574 completed (loss: 0.45514458417892456, acc: 0.845588207244873)
[2024-11-13 05:37:06,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:06,541][root][INFO] - Training Epoch: 8/10, step 72/574 completed (loss: 0.38884302973747253, acc: 0.8809523582458496)
[2024-11-13 05:37:06,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:06,862][root][INFO] - Training Epoch: 8/10, step 73/574 completed (loss: 0.9599856734275818, acc: 0.7179487347602844)
[2024-11-13 05:37:06,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:07,128][root][INFO] - Training Epoch: 8/10, step 74/574 completed (loss: 0.4312353730201721, acc: 0.8877550959587097)
[2024-11-13 05:37:07,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:07,513][root][INFO] - Training Epoch: 8/10, step 75/574 completed (loss: 0.6622344255447388, acc: 0.8134328126907349)
[2024-11-13 05:37:07,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:07,911][root][INFO] - Training Epoch: 8/10, step 76/574 completed (loss: 1.1701347827911377, acc: 0.6861313581466675)
[2024-11-13 05:37:08,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:08,234][root][INFO] - Training Epoch: 8/10, step 77/574 completed (loss: 0.004120954778045416, acc: 1.0)
[2024-11-13 05:37:08,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:08,544][root][INFO] - Training Epoch: 8/10, step 78/574 completed (loss: 0.019276220351457596, acc: 1.0)
[2024-11-13 05:37:08,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:08,949][root][INFO] - Training Epoch: 8/10, step 79/574 completed (loss: 0.029592270031571388, acc: 1.0)
[2024-11-13 05:37:09,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:09,333][root][INFO] - Training Epoch: 8/10, step 80/574 completed (loss: 0.0346163846552372, acc: 1.0)
[2024-11-13 05:37:09,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:09,694][root][INFO] - Training Epoch: 8/10, step 81/574 completed (loss: 0.16559718549251556, acc: 0.942307710647583)
[2024-11-13 05:37:09,818][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:10,079][root][INFO] - Training Epoch: 8/10, step 82/574 completed (loss: 0.20640829205513, acc: 0.942307710647583)
[2024-11-13 05:37:10,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:10,466][root][INFO] - Training Epoch: 8/10, step 83/574 completed (loss: 0.02245449647307396, acc: 1.0)
[2024-11-13 05:37:10,572][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:10,857][root][INFO] - Training Epoch: 8/10, step 84/574 completed (loss: 0.28075212240219116, acc: 0.9130434989929199)
[2024-11-13 05:37:10,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:11,269][root][INFO] - Training Epoch: 8/10, step 85/574 completed (loss: 0.0604977048933506, acc: 1.0)
[2024-11-13 05:37:11,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:11,684][root][INFO] - Training Epoch: 8/10, step 86/574 completed (loss: 0.05869822949171066, acc: 1.0)
[2024-11-13 05:37:11,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:12,172][root][INFO] - Training Epoch: 8/10, step 87/574 completed (loss: 0.19677266478538513, acc: 0.9399999976158142)
[2024-11-13 05:37:12,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:12,489][root][INFO] - Training Epoch: 8/10, step 88/574 completed (loss: 0.48765140771865845, acc: 0.844660222530365)
[2024-11-13 05:37:12,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:13,610][root][INFO] - Training Epoch: 8/10, step 89/574 completed (loss: 0.625156044960022, acc: 0.8106796145439148)
[2024-11-13 05:37:13,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:14,428][root][INFO] - Training Epoch: 8/10, step 90/574 completed (loss: 0.7533604502677917, acc: 0.7849462628364563)
[2024-11-13 05:37:14,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:15,232][root][INFO] - Training Epoch: 8/10, step 91/574 completed (loss: 0.5535737872123718, acc: 0.8491379022598267)
[2024-11-13 05:37:15,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:15,974][root][INFO] - Training Epoch: 8/10, step 92/574 completed (loss: 0.43328696489334106, acc: 0.8631578683853149)
[2024-11-13 05:37:16,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:16,962][root][INFO] - Training Epoch: 8/10, step 93/574 completed (loss: 0.5547803640365601, acc: 0.8514851331710815)
[2024-11-13 05:37:17,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:17,270][root][INFO] - Training Epoch: 8/10, step 94/574 completed (loss: 0.3000171482563019, acc: 0.8870967626571655)
[2024-11-13 05:37:17,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:17,619][root][INFO] - Training Epoch: 8/10, step 95/574 completed (loss: 0.18031597137451172, acc: 0.95652174949646)
[2024-11-13 05:37:17,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:17,922][root][INFO] - Training Epoch: 8/10, step 96/574 completed (loss: 0.540559709072113, acc: 0.8151260614395142)
[2024-11-13 05:37:18,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:18,286][root][INFO] - Training Epoch: 8/10, step 97/574 completed (loss: 0.5056541562080383, acc: 0.807692289352417)
[2024-11-13 05:37:18,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:18,667][root][INFO] - Training Epoch: 8/10, step 98/574 completed (loss: 0.7131136655807495, acc: 0.7445255517959595)
[2024-11-13 05:37:18,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:19,019][root][INFO] - Training Epoch: 8/10, step 99/574 completed (loss: 0.2023753672838211, acc: 0.9402984976768494)
[2024-11-13 05:37:19,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:19,331][root][INFO] - Training Epoch: 8/10, step 100/574 completed (loss: 0.02705763839185238, acc: 1.0)
[2024-11-13 05:37:19,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:19,640][root][INFO] - Training Epoch: 8/10, step 101/574 completed (loss: 0.0025390423834323883, acc: 1.0)
[2024-11-13 05:37:19,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:19,914][root][INFO] - Training Epoch: 8/10, step 102/574 completed (loss: 0.012071755714714527, acc: 1.0)
[2024-11-13 05:37:19,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:20,168][root][INFO] - Training Epoch: 8/10, step 103/574 completed (loss: 0.011492064222693443, acc: 1.0)
[2024-11-13 05:37:20,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:20,479][root][INFO] - Training Epoch: 8/10, step 104/574 completed (loss: 0.08923545479774475, acc: 0.9482758641242981)
[2024-11-13 05:37:20,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:20,821][root][INFO] - Training Epoch: 8/10, step 105/574 completed (loss: 0.050170548260211945, acc: 0.9767441749572754)
[2024-11-13 05:37:20,902][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:21,135][root][INFO] - Training Epoch: 8/10, step 106/574 completed (loss: 0.01780432090163231, acc: 1.0)
[2024-11-13 05:37:21,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:21,435][root][INFO] - Training Epoch: 8/10, step 107/574 completed (loss: 0.02760699950158596, acc: 1.0)
[2024-11-13 05:37:21,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:21,727][root][INFO] - Training Epoch: 8/10, step 108/574 completed (loss: 0.0038414932787418365, acc: 1.0)
[2024-11-13 05:37:21,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:22,029][root][INFO] - Training Epoch: 8/10, step 109/574 completed (loss: 0.08264566212892532, acc: 0.976190447807312)
[2024-11-13 05:37:22,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:22,373][root][INFO] - Training Epoch: 8/10, step 110/574 completed (loss: 0.08502097427845001, acc: 0.9538461565971375)
[2024-11-13 05:37:22,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:22,780][root][INFO] - Training Epoch: 8/10, step 111/574 completed (loss: 0.19054189324378967, acc: 0.9649122953414917)
[2024-11-13 05:37:22,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:23,142][root][INFO] - Training Epoch: 8/10, step 112/574 completed (loss: 0.25988128781318665, acc: 0.9122806787490845)
[2024-11-13 05:37:23,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:23,500][root][INFO] - Training Epoch: 8/10, step 113/574 completed (loss: 0.16947899758815765, acc: 0.9230769276618958)
[2024-11-13 05:37:23,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:23,872][root][INFO] - Training Epoch: 8/10, step 114/574 completed (loss: 0.06721556186676025, acc: 0.9795918464660645)
[2024-11-13 05:37:23,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:24,210][root][INFO] - Training Epoch: 8/10, step 115/574 completed (loss: 0.004587204195559025, acc: 1.0)
[2024-11-13 05:37:24,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:24,568][root][INFO] - Training Epoch: 8/10, step 116/574 completed (loss: 0.2415144294500351, acc: 0.9523809552192688)
[2024-11-13 05:37:24,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:24,873][root][INFO] - Training Epoch: 8/10, step 117/574 completed (loss: 0.31657013297080994, acc: 0.8943089246749878)
[2024-11-13 05:37:24,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:25,187][root][INFO] - Training Epoch: 8/10, step 118/574 completed (loss: 0.05367818847298622, acc: 0.9516128897666931)
[2024-11-13 05:37:25,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:26,024][root][INFO] - Training Epoch: 8/10, step 119/574 completed (loss: 0.617108941078186, acc: 0.8212927579879761)
[2024-11-13 05:37:26,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:26,349][root][INFO] - Training Epoch: 8/10, step 120/574 completed (loss: 0.07059528678655624, acc: 0.9733333587646484)
[2024-11-13 05:37:26,447][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:26,743][root][INFO] - Training Epoch: 8/10, step 121/574 completed (loss: 0.12242504209280014, acc: 0.9807692170143127)
[2024-11-13 05:37:26,815][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:27,045][root][INFO] - Training Epoch: 8/10, step 122/574 completed (loss: 0.02166283316910267, acc: 1.0)
[2024-11-13 05:37:27,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:27,389][root][INFO] - Training Epoch: 8/10, step 123/574 completed (loss: 0.02133491262793541, acc: 1.0)
[2024-11-13 05:37:27,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:27,736][root][INFO] - Training Epoch: 8/10, step 124/574 completed (loss: 0.5472411513328552, acc: 0.8588957190513611)
[2024-11-13 05:37:27,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:28,081][root][INFO] - Training Epoch: 8/10, step 125/574 completed (loss: 0.6722676157951355, acc: 0.8125)
[2024-11-13 05:37:28,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:28,397][root][INFO] - Training Epoch: 8/10, step 126/574 completed (loss: 0.5639951825141907, acc: 0.8416666388511658)
[2024-11-13 05:37:28,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:28,724][root][INFO] - Training Epoch: 8/10, step 127/574 completed (loss: 0.5430424809455872, acc: 0.8452380895614624)
[2024-11-13 05:37:28,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:29,056][root][INFO] - Training Epoch: 8/10, step 128/574 completed (loss: 0.4633624851703644, acc: 0.8461538553237915)
[2024-11-13 05:37:29,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:30,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:30,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:30,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:31,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:31,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:31,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:32,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:32,667][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:33,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:33,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:33,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:34,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:34,318][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:34,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:35,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:35,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:35,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:36,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:36,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:36,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:37,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:37,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:37,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:38,311][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:38,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:39,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:39,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:39,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:40,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:40,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:40,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:41,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:41,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:41,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:42,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:42,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:42,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:43,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:43,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:43,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:44,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:44,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:44,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:45,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:45,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:45,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:46,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:46,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:46,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:47,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:47,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:47,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:48,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:48,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:48,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:49,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:49,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:49,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:50,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:50,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:50,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:51,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:51,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:51,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:52,117][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:52,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:52,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:53,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:53,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:53,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:54,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:54,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:54,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:55,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:55,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:55,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:56,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:56,355][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:56,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:56,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:57,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:57,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:57,820][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:58,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:58,878][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4363, device='cuda:0') eval_epoch_loss=tensor(0.8905, device='cuda:0') eval_epoch_acc=tensor(0.8090, device='cuda:0')
[2024-11-13 05:37:58,879][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:37:58,880][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:37:59,220][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_8_step_129_loss_0.8904925584793091/model.pt
[2024-11-13 05:37:59,227][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:37:59,228][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.8090269565582275
[2024-11-13 05:37:59,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:59,661][root][INFO] - Training Epoch: 8/10, step 129/574 completed (loss: 0.42959824204444885, acc: 0.875)
[2024-11-13 05:37:59,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:37:59,978][root][INFO] - Training Epoch: 8/10, step 130/574 completed (loss: 0.043139226734638214, acc: 1.0)
[2024-11-13 05:38:00,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:00,274][root][INFO] - Training Epoch: 8/10, step 131/574 completed (loss: 0.0238121896982193, acc: 1.0)
[2024-11-13 05:38:00,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:00,584][root][INFO] - Training Epoch: 8/10, step 132/574 completed (loss: 0.13201601803302765, acc: 0.96875)
[2024-11-13 05:38:00,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:00,918][root][INFO] - Training Epoch: 8/10, step 133/574 completed (loss: 0.04923223331570625, acc: 1.0)
[2024-11-13 05:38:00,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:01,192][root][INFO] - Training Epoch: 8/10, step 134/574 completed (loss: 0.28763118386268616, acc: 0.9142857193946838)
[2024-11-13 05:38:01,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:01,492][root][INFO] - Training Epoch: 8/10, step 135/574 completed (loss: 0.04472867026925087, acc: 1.0)
[2024-11-13 05:38:01,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:01,818][root][INFO] - Training Epoch: 8/10, step 136/574 completed (loss: 0.18884193897247314, acc: 0.9285714030265808)
[2024-11-13 05:38:01,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:02,134][root][INFO] - Training Epoch: 8/10, step 137/574 completed (loss: 0.2579718828201294, acc: 0.8999999761581421)
[2024-11-13 05:38:02,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:02,429][root][INFO] - Training Epoch: 8/10, step 138/574 completed (loss: 0.009326447732746601, acc: 1.0)
[2024-11-13 05:38:02,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:02,730][root][INFO] - Training Epoch: 8/10, step 139/574 completed (loss: 0.017646770924329758, acc: 1.0)
[2024-11-13 05:38:02,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:03,062][root][INFO] - Training Epoch: 8/10, step 140/574 completed (loss: 0.015057217329740524, acc: 1.0)
[2024-11-13 05:38:03,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:03,345][root][INFO] - Training Epoch: 8/10, step 141/574 completed (loss: 0.1594608724117279, acc: 0.9354838728904724)
[2024-11-13 05:38:03,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:03,660][root][INFO] - Training Epoch: 8/10, step 142/574 completed (loss: 0.11361203342676163, acc: 0.9459459185600281)
[2024-11-13 05:38:03,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:04,211][root][INFO] - Training Epoch: 8/10, step 143/574 completed (loss: 0.504946231842041, acc: 0.7982456088066101)
[2024-11-13 05:38:04,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:04,569][root][INFO] - Training Epoch: 8/10, step 144/574 completed (loss: 0.5634949803352356, acc: 0.8134328126907349)
[2024-11-13 05:38:04,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:04,962][root][INFO] - Training Epoch: 8/10, step 145/574 completed (loss: 0.41981878876686096, acc: 0.8571428656578064)
[2024-11-13 05:38:05,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:05,400][root][INFO] - Training Epoch: 8/10, step 146/574 completed (loss: 0.6301978230476379, acc: 0.8191489577293396)
[2024-11-13 05:38:05,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:05,720][root][INFO] - Training Epoch: 8/10, step 147/574 completed (loss: 0.36027923226356506, acc: 0.8428571224212646)
[2024-11-13 05:38:05,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:05,998][root][INFO] - Training Epoch: 8/10, step 148/574 completed (loss: 0.09276983886957169, acc: 1.0)
[2024-11-13 05:38:06,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:06,302][root][INFO] - Training Epoch: 8/10, step 149/574 completed (loss: 0.03543304279446602, acc: 1.0)
[2024-11-13 05:38:06,395][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:06,589][root][INFO] - Training Epoch: 8/10, step 150/574 completed (loss: 0.04971126839518547, acc: 0.9655172228813171)
[2024-11-13 05:38:06,668][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:06,906][root][INFO] - Training Epoch: 8/10, step 151/574 completed (loss: 0.27017420530319214, acc: 0.8695651888847351)
[2024-11-13 05:38:06,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:07,279][root][INFO] - Training Epoch: 8/10, step 152/574 completed (loss: 0.2546974718570709, acc: 0.9152542352676392)
[2024-11-13 05:38:07,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:07,621][root][INFO] - Training Epoch: 8/10, step 153/574 completed (loss: 0.21386350691318512, acc: 0.9298245906829834)
[2024-11-13 05:38:07,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:07,946][root][INFO] - Training Epoch: 8/10, step 154/574 completed (loss: 0.2257462590932846, acc: 0.9324324131011963)
[2024-11-13 05:38:08,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:08,275][root][INFO] - Training Epoch: 8/10, step 155/574 completed (loss: 0.15035896003246307, acc: 0.9285714030265808)
[2024-11-13 05:38:08,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:08,617][root][INFO] - Training Epoch: 8/10, step 156/574 completed (loss: 0.2175205647945404, acc: 0.9130434989929199)
[2024-11-13 05:38:08,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:08,946][root][INFO] - Training Epoch: 8/10, step 157/574 completed (loss: 0.2860790193080902, acc: 0.8947368264198303)
[2024-11-13 05:38:09,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:10,689][root][INFO] - Training Epoch: 8/10, step 158/574 completed (loss: 0.4997198283672333, acc: 0.8513513803482056)
[2024-11-13 05:38:10,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:11,041][root][INFO] - Training Epoch: 8/10, step 159/574 completed (loss: 0.34781819581985474, acc: 0.8703703880310059)
[2024-11-13 05:38:11,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:11,446][root][INFO] - Training Epoch: 8/10, step 160/574 completed (loss: 0.4492080509662628, acc: 0.8488371968269348)
[2024-11-13 05:38:11,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:12,028][root][INFO] - Training Epoch: 8/10, step 161/574 completed (loss: 0.4420493245124817, acc: 0.8705882430076599)
[2024-11-13 05:38:12,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:12,587][root][INFO] - Training Epoch: 8/10, step 162/574 completed (loss: 0.5153744220733643, acc: 0.8876404762268066)
[2024-11-13 05:38:12,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:12,914][root][INFO] - Training Epoch: 8/10, step 163/574 completed (loss: 0.2789456248283386, acc: 0.9545454382896423)
[2024-11-13 05:38:13,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:13,204][root][INFO] - Training Epoch: 8/10, step 164/574 completed (loss: 0.13868804275989532, acc: 0.9523809552192688)
[2024-11-13 05:38:13,283][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:13,507][root][INFO] - Training Epoch: 8/10, step 165/574 completed (loss: 0.25383418798446655, acc: 0.8965517282485962)
[2024-11-13 05:38:13,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:13,846][root][INFO] - Training Epoch: 8/10, step 166/574 completed (loss: 0.08026847243309021, acc: 0.9795918464660645)
[2024-11-13 05:38:13,973][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:14,255][root][INFO] - Training Epoch: 8/10, step 167/574 completed (loss: 0.1495366245508194, acc: 0.9399999976158142)
[2024-11-13 05:38:14,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:14,627][root][INFO] - Training Epoch: 8/10, step 168/574 completed (loss: 0.40219274163246155, acc: 0.8888888955116272)
[2024-11-13 05:38:14,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:14,950][root][INFO] - Training Epoch: 8/10, step 169/574 completed (loss: 0.6210528612136841, acc: 0.8039215803146362)
[2024-11-13 05:38:15,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:15,978][root][INFO] - Training Epoch: 8/10, step 170/574 completed (loss: 0.5931724309921265, acc: 0.7808219194412231)
[2024-11-13 05:38:16,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:16,325][root][INFO] - Training Epoch: 8/10, step 171/574 completed (loss: 0.02761804312467575, acc: 1.0)
[2024-11-13 05:38:16,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:16,678][root][INFO] - Training Epoch: 8/10, step 172/574 completed (loss: 0.027753522619605064, acc: 1.0)
[2024-11-13 05:38:16,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:17,049][root][INFO] - Training Epoch: 8/10, step 173/574 completed (loss: 0.12929776310920715, acc: 0.8928571343421936)
[2024-11-13 05:38:17,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:17,586][root][INFO] - Training Epoch: 8/10, step 174/574 completed (loss: 0.5882116556167603, acc: 0.8672566413879395)
[2024-11-13 05:38:17,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:17,966][root][INFO] - Training Epoch: 8/10, step 175/574 completed (loss: 0.2759178876876831, acc: 0.8840579986572266)
[2024-11-13 05:38:18,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:18,310][root][INFO] - Training Epoch: 8/10, step 176/574 completed (loss: 0.1475464105606079, acc: 0.9545454382896423)
[2024-11-13 05:38:18,651][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:19,308][root][INFO] - Training Epoch: 8/10, step 177/574 completed (loss: 0.6951000094413757, acc: 0.7480915784835815)
[2024-11-13 05:38:19,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:19,979][root][INFO] - Training Epoch: 8/10, step 178/574 completed (loss: 0.6613423824310303, acc: 0.8444444537162781)
[2024-11-13 05:38:20,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:20,339][root][INFO] - Training Epoch: 8/10, step 179/574 completed (loss: 0.12894785404205322, acc: 0.9344262480735779)
[2024-11-13 05:38:20,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:20,745][root][INFO] - Training Epoch: 8/10, step 180/574 completed (loss: 0.0141178322955966, acc: 1.0)
[2024-11-13 05:38:20,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:21,145][root][INFO] - Training Epoch: 8/10, step 181/574 completed (loss: 0.02109784446656704, acc: 1.0)
[2024-11-13 05:38:21,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:21,490][root][INFO] - Training Epoch: 8/10, step 182/574 completed (loss: 0.01390320248901844, acc: 1.0)
[2024-11-13 05:38:21,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:21,812][root][INFO] - Training Epoch: 8/10, step 183/574 completed (loss: 0.14528749883174896, acc: 0.9512194991111755)
[2024-11-13 05:38:21,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:22,230][root][INFO] - Training Epoch: 8/10, step 184/574 completed (loss: 0.4059161841869354, acc: 0.8821752071380615)
[2024-11-13 05:38:22,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:22,555][root][INFO] - Training Epoch: 8/10, step 185/574 completed (loss: 0.45099523663520813, acc: 0.8731988668441772)
[2024-11-13 05:38:22,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:23,043][root][INFO] - Training Epoch: 8/10, step 186/574 completed (loss: 0.49843019247055054, acc: 0.828125)
[2024-11-13 05:38:23,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:23,569][root][INFO] - Training Epoch: 8/10, step 187/574 completed (loss: 0.5663763284683228, acc: 0.8424015045166016)
[2024-11-13 05:38:23,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:23,964][root][INFO] - Training Epoch: 8/10, step 188/574 completed (loss: 0.4696807861328125, acc: 0.8505337834358215)
[2024-11-13 05:38:24,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:24,307][root][INFO] - Training Epoch: 8/10, step 189/574 completed (loss: 0.01054433360695839, acc: 1.0)
[2024-11-13 05:38:24,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:24,857][root][INFO] - Training Epoch: 8/10, step 190/574 completed (loss: 0.543285071849823, acc: 0.7906976938247681)
[2024-11-13 05:38:25,072][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:25,660][root][INFO] - Training Epoch: 8/10, step 191/574 completed (loss: 0.6967101693153381, acc: 0.7857142686843872)
[2024-11-13 05:38:25,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:26,582][root][INFO] - Training Epoch: 8/10, step 192/574 completed (loss: 0.6273540258407593, acc: 0.7651515007019043)
[2024-11-13 05:38:26,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:27,323][root][INFO] - Training Epoch: 8/10, step 193/574 completed (loss: 0.2911907732486725, acc: 0.929411768913269)
[2024-11-13 05:38:27,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:28,396][root][INFO] - Training Epoch: 8/10, step 194/574 completed (loss: 0.5205198526382446, acc: 0.8209876418113708)
[2024-11-13 05:38:28,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:29,355][root][INFO] - Training Epoch: 8/10, step 195/574 completed (loss: 0.17733368277549744, acc: 0.9193548560142517)
[2024-11-13 05:38:29,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:29,659][root][INFO] - Training Epoch: 8/10, step 196/574 completed (loss: 0.001742568681947887, acc: 1.0)
[2024-11-13 05:38:29,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:29,973][root][INFO] - Training Epoch: 8/10, step 197/574 completed (loss: 0.03521957993507385, acc: 1.0)
[2024-11-13 05:38:30,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:30,343][root][INFO] - Training Epoch: 8/10, step 198/574 completed (loss: 0.1876290738582611, acc: 0.9411764740943909)
[2024-11-13 05:38:30,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:30,726][root][INFO] - Training Epoch: 8/10, step 199/574 completed (loss: 0.3917596638202667, acc: 0.8602941036224365)
[2024-11-13 05:38:30,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:31,067][root][INFO] - Training Epoch: 8/10, step 200/574 completed (loss: 0.44609716534614563, acc: 0.8983050584793091)
[2024-11-13 05:38:31,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:31,406][root][INFO] - Training Epoch: 8/10, step 201/574 completed (loss: 0.4226095378398895, acc: 0.8432835936546326)
[2024-11-13 05:38:31,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:31,809][root][INFO] - Training Epoch: 8/10, step 202/574 completed (loss: 0.3976592719554901, acc: 0.8640776872634888)
[2024-11-13 05:38:31,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:32,206][root][INFO] - Training Epoch: 8/10, step 203/574 completed (loss: 0.1317962110042572, acc: 0.9841269850730896)
[2024-11-13 05:38:32,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:32,527][root][INFO] - Training Epoch: 8/10, step 204/574 completed (loss: 0.07324724644422531, acc: 0.9670329689979553)
[2024-11-13 05:38:32,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:32,923][root][INFO] - Training Epoch: 8/10, step 205/574 completed (loss: 0.15287750959396362, acc: 0.9551569223403931)
[2024-11-13 05:38:33,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:33,360][root][INFO] - Training Epoch: 8/10, step 206/574 completed (loss: 0.24917948246002197, acc: 0.9212598204612732)
[2024-11-13 05:38:33,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:33,739][root][INFO] - Training Epoch: 8/10, step 207/574 completed (loss: 0.2055463343858719, acc: 0.9396551847457886)
[2024-11-13 05:38:33,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:34,088][root][INFO] - Training Epoch: 8/10, step 208/574 completed (loss: 0.2062886655330658, acc: 0.9239130616188049)
[2024-11-13 05:38:34,194][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:34,468][root][INFO] - Training Epoch: 8/10, step 209/574 completed (loss: 0.19472388923168182, acc: 0.9338521361351013)
[2024-11-13 05:38:34,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:34,824][root][INFO] - Training Epoch: 8/10, step 210/574 completed (loss: 0.15531708300113678, acc: 0.95652174949646)
[2024-11-13 05:38:34,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:35,208][root][INFO] - Training Epoch: 8/10, step 211/574 completed (loss: 0.003939248621463776, acc: 1.0)
[2024-11-13 05:38:35,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:35,572][root][INFO] - Training Epoch: 8/10, step 212/574 completed (loss: 0.01414058543741703, acc: 1.0)
[2024-11-13 05:38:35,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:35,963][root][INFO] - Training Epoch: 8/10, step 213/574 completed (loss: 0.03402435779571533, acc: 0.978723406791687)
[2024-11-13 05:38:36,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:36,688][root][INFO] - Training Epoch: 8/10, step 214/574 completed (loss: 0.11226686090230942, acc: 0.9846153855323792)
[2024-11-13 05:38:36,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:37,002][root][INFO] - Training Epoch: 8/10, step 215/574 completed (loss: 0.090669184923172, acc: 0.9729729890823364)
[2024-11-13 05:38:37,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:37,364][root][INFO] - Training Epoch: 8/10, step 216/574 completed (loss: 0.16604848206043243, acc: 0.9651162624359131)
[2024-11-13 05:38:37,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:37,896][root][INFO] - Training Epoch: 8/10, step 217/574 completed (loss: 0.09987752139568329, acc: 0.954954981803894)
[2024-11-13 05:38:38,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:38,305][root][INFO] - Training Epoch: 8/10, step 218/574 completed (loss: 0.11129189282655716, acc: 0.9666666388511658)
[2024-11-13 05:38:38,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:38,639][root][INFO] - Training Epoch: 8/10, step 219/574 completed (loss: 0.007463390007615089, acc: 1.0)
[2024-11-13 05:38:38,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:38,980][root][INFO] - Training Epoch: 8/10, step 220/574 completed (loss: 0.007571467198431492, acc: 1.0)
[2024-11-13 05:38:39,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:39,305][root][INFO] - Training Epoch: 8/10, step 221/574 completed (loss: 0.0031950832344591618, acc: 1.0)
[2024-11-13 05:38:39,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:39,601][root][INFO] - Training Epoch: 8/10, step 222/574 completed (loss: 0.20120730996131897, acc: 0.9038461446762085)
[2024-11-13 05:38:39,814][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:40,384][root][INFO] - Training Epoch: 8/10, step 223/574 completed (loss: 0.2890070974826813, acc: 0.91847825050354)
[2024-11-13 05:38:40,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:40,931][root][INFO] - Training Epoch: 8/10, step 224/574 completed (loss: 0.3593311607837677, acc: 0.8977272510528564)
[2024-11-13 05:38:41,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:41,355][root][INFO] - Training Epoch: 8/10, step 225/574 completed (loss: 0.45891639590263367, acc: 0.8723404407501221)
[2024-11-13 05:38:41,448][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:41,730][root][INFO] - Training Epoch: 8/10, step 226/574 completed (loss: 0.15112286806106567, acc: 0.9433962106704712)
[2024-11-13 05:38:41,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:42,126][root][INFO] - Training Epoch: 8/10, step 227/574 completed (loss: 0.10802187025547028, acc: 0.9833333492279053)
[2024-11-13 05:38:42,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:42,508][root][INFO] - Training Epoch: 8/10, step 228/574 completed (loss: 0.14292971789836884, acc: 0.9534883499145508)
[2024-11-13 05:38:42,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:42,870][root][INFO] - Training Epoch: 8/10, step 229/574 completed (loss: 0.1962234377861023, acc: 0.8999999761581421)
[2024-11-13 05:38:42,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:43,245][root][INFO] - Training Epoch: 8/10, step 230/574 completed (loss: 0.9052408933639526, acc: 0.7473683953285217)
[2024-11-13 05:38:43,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:43,530][root][INFO] - Training Epoch: 8/10, step 231/574 completed (loss: 0.6408798694610596, acc: 0.8333333134651184)
[2024-11-13 05:38:43,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:43,933][root][INFO] - Training Epoch: 8/10, step 232/574 completed (loss: 0.8050416707992554, acc: 0.75)
[2024-11-13 05:38:44,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:44,419][root][INFO] - Training Epoch: 8/10, step 233/574 completed (loss: 1.228827953338623, acc: 0.6330274939537048)
[2024-11-13 05:38:44,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:44,893][root][INFO] - Training Epoch: 8/10, step 234/574 completed (loss: 0.5954086780548096, acc: 0.8230769038200378)
[2024-11-13 05:38:44,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:45,209][root][INFO] - Training Epoch: 8/10, step 235/574 completed (loss: 0.03137728199362755, acc: 1.0)
[2024-11-13 05:38:45,284][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:45,510][root][INFO] - Training Epoch: 8/10, step 236/574 completed (loss: 0.0336211733520031, acc: 1.0)
[2024-11-13 05:38:45,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:45,861][root][INFO] - Training Epoch: 8/10, step 237/574 completed (loss: 0.019235169515013695, acc: 1.0)
[2024-11-13 05:38:45,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:46,220][root][INFO] - Training Epoch: 8/10, step 238/574 completed (loss: 0.1240793988108635, acc: 0.9259259104728699)
[2024-11-13 05:38:46,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:46,585][root][INFO] - Training Epoch: 8/10, step 239/574 completed (loss: 0.14455831050872803, acc: 0.9428571462631226)
[2024-11-13 05:38:46,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:46,928][root][INFO] - Training Epoch: 8/10, step 240/574 completed (loss: 0.1266830861568451, acc: 0.9772727489471436)
[2024-11-13 05:38:47,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:47,227][root][INFO] - Training Epoch: 8/10, step 241/574 completed (loss: 0.07692360132932663, acc: 0.9545454382896423)
[2024-11-13 05:38:47,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:47,810][root][INFO] - Training Epoch: 8/10, step 242/574 completed (loss: 0.4025861918926239, acc: 0.8064516186714172)
[2024-11-13 05:38:47,956][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:48,349][root][INFO] - Training Epoch: 8/10, step 243/574 completed (loss: 0.19532084465026855, acc: 0.9318181872367859)
[2024-11-13 05:38:48,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:48,692][root][INFO] - Training Epoch: 8/10, step 244/574 completed (loss: 0.0005336703616194427, acc: 1.0)
[2024-11-13 05:38:48,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:49,055][root][INFO] - Training Epoch: 8/10, step 245/574 completed (loss: 0.32963818311691284, acc: 0.9615384340286255)
[2024-11-13 05:38:49,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:49,363][root][INFO] - Training Epoch: 8/10, step 246/574 completed (loss: 0.004063238389790058, acc: 1.0)
[2024-11-13 05:38:49,451][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:49,660][root][INFO] - Training Epoch: 8/10, step 247/574 completed (loss: 0.005634508095681667, acc: 1.0)
[2024-11-13 05:38:49,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:49,986][root][INFO] - Training Epoch: 8/10, step 248/574 completed (loss: 0.13932906091213226, acc: 0.9459459185600281)
[2024-11-13 05:38:50,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:50,356][root][INFO] - Training Epoch: 8/10, step 249/574 completed (loss: 0.14505450427532196, acc: 0.9189189076423645)
[2024-11-13 05:38:50,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:50,724][root][INFO] - Training Epoch: 8/10, step 250/574 completed (loss: 0.002823891583830118, acc: 1.0)
[2024-11-13 05:38:50,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:51,120][root][INFO] - Training Epoch: 8/10, step 251/574 completed (loss: 0.0494890995323658, acc: 0.9852941036224365)
[2024-11-13 05:38:51,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:51,485][root][INFO] - Training Epoch: 8/10, step 252/574 completed (loss: 0.012254836037755013, acc: 1.0)
[2024-11-13 05:38:51,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:51,885][root][INFO] - Training Epoch: 8/10, step 253/574 completed (loss: 0.00351168611086905, acc: 1.0)
[2024-11-13 05:38:51,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:52,166][root][INFO] - Training Epoch: 8/10, step 254/574 completed (loss: 0.000728311890270561, acc: 1.0)
[2024-11-13 05:38:52,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:52,523][root][INFO] - Training Epoch: 8/10, step 255/574 completed (loss: 0.007834735326468945, acc: 1.0)
[2024-11-13 05:38:52,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:52,846][root][INFO] - Training Epoch: 8/10, step 256/574 completed (loss: 0.03178570419549942, acc: 0.9824561476707458)
[2024-11-13 05:38:52,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:53,222][root][INFO] - Training Epoch: 8/10, step 257/574 completed (loss: 0.05620698258280754, acc: 0.9857142567634583)
[2024-11-13 05:38:53,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:53,571][root][INFO] - Training Epoch: 8/10, step 258/574 completed (loss: 0.0533798485994339, acc: 0.9605262875556946)
[2024-11-13 05:38:53,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:54,133][root][INFO] - Training Epoch: 8/10, step 259/574 completed (loss: 0.14168530702590942, acc: 0.9339622855186462)
[2024-11-13 05:38:54,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:54,714][root][INFO] - Training Epoch: 8/10, step 260/574 completed (loss: 0.18694251775741577, acc: 0.949999988079071)
[2024-11-13 05:38:54,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:55,022][root][INFO] - Training Epoch: 8/10, step 261/574 completed (loss: 0.032859403640031815, acc: 0.9722222089767456)
[2024-11-13 05:38:55,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:55,416][root][INFO] - Training Epoch: 8/10, step 262/574 completed (loss: 0.10349760204553604, acc: 0.9677419066429138)
[2024-11-13 05:38:55,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:55,795][root][INFO] - Training Epoch: 8/10, step 263/574 completed (loss: 0.3023661673069, acc: 0.9066666960716248)
[2024-11-13 05:38:55,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:56,175][root][INFO] - Training Epoch: 8/10, step 264/574 completed (loss: 0.2432028204202652, acc: 0.9583333134651184)
[2024-11-13 05:38:56,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:57,024][root][INFO] - Training Epoch: 8/10, step 265/574 completed (loss: 0.6847919821739197, acc: 0.800000011920929)
[2024-11-13 05:38:57,105][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:57,339][root][INFO] - Training Epoch: 8/10, step 266/574 completed (loss: 0.4321078062057495, acc: 0.8314606547355652)
[2024-11-13 05:38:57,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:57,669][root][INFO] - Training Epoch: 8/10, step 267/574 completed (loss: 0.2550322413444519, acc: 0.9189189076423645)
[2024-11-13 05:38:57,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:58,124][root][INFO] - Training Epoch: 8/10, step 268/574 completed (loss: 0.16425630450248718, acc: 0.9482758641242981)
[2024-11-13 05:38:58,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:58,484][root][INFO] - Training Epoch: 8/10, step 269/574 completed (loss: 0.007377330679446459, acc: 1.0)
[2024-11-13 05:38:58,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:58,869][root][INFO] - Training Epoch: 8/10, step 270/574 completed (loss: 0.04321950674057007, acc: 1.0)
[2024-11-13 05:38:58,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:38:59,302][root][INFO] - Training Epoch: 8/10, step 271/574 completed (loss: 0.025513077154755592, acc: 1.0)
[2024-11-13 05:39:00,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:00,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:00,755][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:01,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:01,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:01,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:02,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:02,597][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:02,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:03,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:03,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:04,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:04,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:04,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:05,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:05,394][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:05,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:05,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:06,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:06,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:06,924][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:07,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:07,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:08,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:08,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:08,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:09,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:09,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:09,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:10,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:10,747][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:11,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:11,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:11,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:12,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:12,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:12,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:13,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:13,453][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:13,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:14,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:14,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:14,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:15,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:15,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:15,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:16,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:16,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:16,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:17,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:17,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:17,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:18,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:18,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:19,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:19,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:19,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:20,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:20,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:21,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:21,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:21,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:22,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:22,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:23,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:23,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:23,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:24,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:24,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:24,884][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:25,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:25,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:25,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:26,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:26,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:26,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:27,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:27,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:27,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:28,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:28,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:28,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:29,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:29,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:30,218][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.3792, device='cuda:0') eval_epoch_loss=tensor(0.8668, device='cuda:0') eval_epoch_acc=tensor(0.8151, device='cuda:0')
[2024-11-13 05:39:30,220][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:39:30,221][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:39:30,638][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_8_step_272_loss_0.866784393787384/model.pt
[2024-11-13 05:39:30,654][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:39:30,655][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 8 is 0.8151166439056396
[2024-11-13 05:39:30,768][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:31,096][root][INFO] - Training Epoch: 8/10, step 272/574 completed (loss: 0.02566707134246826, acc: 0.9666666388511658)
[2024-11-13 05:39:31,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:31,547][root][INFO] - Training Epoch: 8/10, step 273/574 completed (loss: 0.1528484970331192, acc: 0.9666666388511658)
[2024-11-13 05:39:31,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:31,940][root][INFO] - Training Epoch: 8/10, step 274/574 completed (loss: 0.08143894374370575, acc: 0.96875)
[2024-11-13 05:39:32,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:32,324][root][INFO] - Training Epoch: 8/10, step 275/574 completed (loss: 0.05960879847407341, acc: 1.0)
[2024-11-13 05:39:32,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:32,708][root][INFO] - Training Epoch: 8/10, step 276/574 completed (loss: 0.0280004870146513, acc: 1.0)
[2024-11-13 05:39:32,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:33,104][root][INFO] - Training Epoch: 8/10, step 277/574 completed (loss: 0.005959127098321915, acc: 1.0)
[2024-11-13 05:39:33,210][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:33,474][root][INFO] - Training Epoch: 8/10, step 278/574 completed (loss: 0.14773128926753998, acc: 0.957446813583374)
[2024-11-13 05:39:33,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:33,858][root][INFO] - Training Epoch: 8/10, step 279/574 completed (loss: 0.1507386714220047, acc: 0.9583333134651184)
[2024-11-13 05:39:33,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:34,263][root][INFO] - Training Epoch: 8/10, step 280/574 completed (loss: 0.10273237526416779, acc: 0.9545454382896423)
[2024-11-13 05:39:34,469][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:34,760][root][INFO] - Training Epoch: 8/10, step 281/574 completed (loss: 0.43378493189811707, acc: 0.8433734774589539)
[2024-11-13 05:39:34,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:35,178][root][INFO] - Training Epoch: 8/10, step 282/574 completed (loss: 0.5006288886070251, acc: 0.8425925970077515)
[2024-11-13 05:39:35,271][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:35,517][root][INFO] - Training Epoch: 8/10, step 283/574 completed (loss: 0.05670131370425224, acc: 0.9736841917037964)
[2024-11-13 05:39:35,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:35,817][root][INFO] - Training Epoch: 8/10, step 284/574 completed (loss: 0.1577954739332199, acc: 0.970588207244873)
[2024-11-13 05:39:35,901][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:36,142][root][INFO] - Training Epoch: 8/10, step 285/574 completed (loss: 0.03200269490480423, acc: 1.0)
[2024-11-13 05:39:36,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:36,498][root][INFO] - Training Epoch: 8/10, step 286/574 completed (loss: 0.18634989857673645, acc: 0.9453125)
[2024-11-13 05:39:36,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:36,874][root][INFO] - Training Epoch: 8/10, step 287/574 completed (loss: 0.29449495673179626, acc: 0.8960000276565552)
[2024-11-13 05:39:36,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:37,204][root][INFO] - Training Epoch: 8/10, step 288/574 completed (loss: 0.05348074063658714, acc: 0.9780219793319702)
[2024-11-13 05:39:37,285][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:37,568][root][INFO] - Training Epoch: 8/10, step 289/574 completed (loss: 0.14181895554065704, acc: 0.95652174949646)
[2024-11-13 05:39:37,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:37,930][root][INFO] - Training Epoch: 8/10, step 290/574 completed (loss: 0.3404180705547333, acc: 0.907216489315033)
[2024-11-13 05:39:38,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:38,243][root][INFO] - Training Epoch: 8/10, step 291/574 completed (loss: 0.00885075330734253, acc: 1.0)
[2024-11-13 05:39:38,325][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:38,555][root][INFO] - Training Epoch: 8/10, step 292/574 completed (loss: 0.13079798221588135, acc: 0.9523809552192688)
[2024-11-13 05:39:38,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:38,963][root][INFO] - Training Epoch: 8/10, step 293/574 completed (loss: 0.11647709459066391, acc: 0.9655172228813171)
[2024-11-13 05:39:39,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:39,469][root][INFO] - Training Epoch: 8/10, step 294/574 completed (loss: 0.1650773584842682, acc: 0.9454545378684998)
[2024-11-13 05:39:39,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:40,081][root][INFO] - Training Epoch: 8/10, step 295/574 completed (loss: 0.4496650993824005, acc: 0.8659793734550476)
[2024-11-13 05:39:40,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:40,413][root][INFO] - Training Epoch: 8/10, step 296/574 completed (loss: 0.1803402602672577, acc: 0.931034505367279)
[2024-11-13 05:39:40,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:40,803][root][INFO] - Training Epoch: 8/10, step 297/574 completed (loss: 0.08200835436582565, acc: 0.9629629850387573)
[2024-11-13 05:39:40,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:41,209][root][INFO] - Training Epoch: 8/10, step 298/574 completed (loss: 0.45445969700813293, acc: 0.9473684430122375)
[2024-11-13 05:39:41,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:41,548][root][INFO] - Training Epoch: 8/10, step 299/574 completed (loss: 0.06368070840835571, acc: 0.9821428656578064)
[2024-11-13 05:39:41,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:41,884][root][INFO] - Training Epoch: 8/10, step 300/574 completed (loss: 0.004758310038596392, acc: 1.0)
[2024-11-13 05:39:42,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:42,233][root][INFO] - Training Epoch: 8/10, step 301/574 completed (loss: 0.08692751079797745, acc: 0.9811320900917053)
[2024-11-13 05:39:42,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:42,584][root][INFO] - Training Epoch: 8/10, step 302/574 completed (loss: 0.006721341051161289, acc: 1.0)
[2024-11-13 05:39:42,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:42,938][root][INFO] - Training Epoch: 8/10, step 303/574 completed (loss: 0.0012632075231522322, acc: 1.0)
[2024-11-13 05:39:43,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:43,289][root][INFO] - Training Epoch: 8/10, step 304/574 completed (loss: 0.19902490079402924, acc: 0.96875)
[2024-11-13 05:39:43,402][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:43,672][root][INFO] - Training Epoch: 8/10, step 305/574 completed (loss: 0.08271854370832443, acc: 0.9508196711540222)
[2024-11-13 05:39:43,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:44,013][root][INFO] - Training Epoch: 8/10, step 306/574 completed (loss: 0.008606703020632267, acc: 1.0)
[2024-11-13 05:39:44,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:44,346][root][INFO] - Training Epoch: 8/10, step 307/574 completed (loss: 0.012111719697713852, acc: 1.0)
[2024-11-13 05:39:44,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:44,683][root][INFO] - Training Epoch: 8/10, step 308/574 completed (loss: 0.03877153992652893, acc: 1.0)
[2024-11-13 05:39:44,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:45,123][root][INFO] - Training Epoch: 8/10, step 309/574 completed (loss: 0.0668950006365776, acc: 0.9861111044883728)
[2024-11-13 05:39:45,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:45,524][root][INFO] - Training Epoch: 8/10, step 310/574 completed (loss: 0.08487033098936081, acc: 0.9759036302566528)
[2024-11-13 05:39:45,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:45,854][root][INFO] - Training Epoch: 8/10, step 311/574 completed (loss: 0.12336540222167969, acc: 0.9615384340286255)
[2024-11-13 05:39:45,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:46,196][root][INFO] - Training Epoch: 8/10, step 312/574 completed (loss: 0.08006966859102249, acc: 0.9693877696990967)
[2024-11-13 05:39:46,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:46,538][root][INFO] - Training Epoch: 8/10, step 313/574 completed (loss: 0.004352046642452478, acc: 1.0)
[2024-11-13 05:39:46,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:46,932][root][INFO] - Training Epoch: 8/10, step 314/574 completed (loss: 0.005693607497960329, acc: 1.0)
[2024-11-13 05:39:47,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:47,263][root][INFO] - Training Epoch: 8/10, step 315/574 completed (loss: 0.0048611960373818874, acc: 1.0)
[2024-11-13 05:39:47,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:47,644][root][INFO] - Training Epoch: 8/10, step 316/574 completed (loss: 0.0534571036696434, acc: 1.0)
[2024-11-13 05:39:47,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:47,987][root][INFO] - Training Epoch: 8/10, step 317/574 completed (loss: 0.1019037514925003, acc: 0.9701492786407471)
[2024-11-13 05:39:48,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:48,348][root][INFO] - Training Epoch: 8/10, step 318/574 completed (loss: 0.04092412814497948, acc: 0.9903846383094788)
[2024-11-13 05:39:48,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:48,638][root][INFO] - Training Epoch: 8/10, step 319/574 completed (loss: 0.11926330626010895, acc: 0.9555555582046509)
[2024-11-13 05:39:48,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:48,915][root][INFO] - Training Epoch: 8/10, step 320/574 completed (loss: 0.07410328835248947, acc: 0.9677419066429138)
[2024-11-13 05:39:48,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:49,202][root][INFO] - Training Epoch: 8/10, step 321/574 completed (loss: 0.05817893147468567, acc: 0.9800000190734863)
[2024-11-13 05:39:49,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:49,542][root][INFO] - Training Epoch: 8/10, step 322/574 completed (loss: 0.1423211395740509, acc: 0.9259259104728699)
[2024-11-13 05:39:49,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:49,910][root][INFO] - Training Epoch: 8/10, step 323/574 completed (loss: 0.07527708262205124, acc: 1.0)
[2024-11-13 05:39:50,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:50,298][root][INFO] - Training Epoch: 8/10, step 324/574 completed (loss: 0.19957967102527618, acc: 0.9743589758872986)
[2024-11-13 05:39:50,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:50,674][root][INFO] - Training Epoch: 8/10, step 325/574 completed (loss: 0.6691629886627197, acc: 0.8048780560493469)
[2024-11-13 05:39:50,773][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:51,004][root][INFO] - Training Epoch: 8/10, step 326/574 completed (loss: 0.09397200495004654, acc: 0.9736841917037964)
[2024-11-13 05:39:51,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:51,351][root][INFO] - Training Epoch: 8/10, step 327/574 completed (loss: 0.016516096889972687, acc: 1.0)
[2024-11-13 05:39:51,454][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:51,692][root][INFO] - Training Epoch: 8/10, step 328/574 completed (loss: 0.09057683497667313, acc: 0.9642857313156128)
[2024-11-13 05:39:51,782][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:51,970][root][INFO] - Training Epoch: 8/10, step 329/574 completed (loss: 0.05135829374194145, acc: 0.9629629850387573)
[2024-11-13 05:39:52,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:52,279][root][INFO] - Training Epoch: 8/10, step 330/574 completed (loss: 0.011447446420788765, acc: 1.0)
[2024-11-13 05:39:52,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:52,640][root][INFO] - Training Epoch: 8/10, step 331/574 completed (loss: 0.18513232469558716, acc: 0.9354838728904724)
[2024-11-13 05:39:52,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:53,060][root][INFO] - Training Epoch: 8/10, step 332/574 completed (loss: 0.016485080122947693, acc: 1.0)
[2024-11-13 05:39:53,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:53,415][root][INFO] - Training Epoch: 8/10, step 333/574 completed (loss: 0.09050256758928299, acc: 0.9375)
[2024-11-13 05:39:53,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:53,759][root][INFO] - Training Epoch: 8/10, step 334/574 completed (loss: 0.04935823753476143, acc: 0.9666666388511658)
[2024-11-13 05:39:53,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:54,134][root][INFO] - Training Epoch: 8/10, step 335/574 completed (loss: 0.017385367304086685, acc: 1.0)
[2024-11-13 05:39:54,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:54,482][root][INFO] - Training Epoch: 8/10, step 336/574 completed (loss: 0.2230934202671051, acc: 0.9599999785423279)
[2024-11-13 05:39:54,598][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:54,807][root][INFO] - Training Epoch: 8/10, step 337/574 completed (loss: 0.3162461519241333, acc: 0.8965517282485962)
[2024-11-13 05:39:54,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:55,200][root][INFO] - Training Epoch: 8/10, step 338/574 completed (loss: 0.6429421901702881, acc: 0.8723404407501221)
[2024-11-13 05:39:55,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:55,585][root][INFO] - Training Epoch: 8/10, step 339/574 completed (loss: 0.7767773270606995, acc: 0.7951807379722595)
[2024-11-13 05:39:55,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:55,906][root][INFO] - Training Epoch: 8/10, step 340/574 completed (loss: 0.010142856277525425, acc: 1.0)
[2024-11-13 05:39:55,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:56,181][root][INFO] - Training Epoch: 8/10, step 341/574 completed (loss: 0.08228163421154022, acc: 0.9487179517745972)
[2024-11-13 05:39:56,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:56,495][root][INFO] - Training Epoch: 8/10, step 342/574 completed (loss: 0.11188233643770218, acc: 0.9518072009086609)
[2024-11-13 05:39:56,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:56,773][root][INFO] - Training Epoch: 8/10, step 343/574 completed (loss: 0.05914197489619255, acc: 0.9811320900917053)
[2024-11-13 05:39:56,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:57,089][root][INFO] - Training Epoch: 8/10, step 344/574 completed (loss: 0.07646114379167557, acc: 0.9620253443717957)
[2024-11-13 05:39:57,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:57,444][root][INFO] - Training Epoch: 8/10, step 345/574 completed (loss: 0.032336458563804626, acc: 0.9803921580314636)
[2024-11-13 05:39:57,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:57,833][root][INFO] - Training Epoch: 8/10, step 346/574 completed (loss: 0.06982403993606567, acc: 0.9701492786407471)
[2024-11-13 05:39:57,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:58,167][root][INFO] - Training Epoch: 8/10, step 347/574 completed (loss: 0.1996217519044876, acc: 0.949999988079071)
[2024-11-13 05:39:58,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:58,484][root][INFO] - Training Epoch: 8/10, step 348/574 completed (loss: 0.03792741149663925, acc: 1.0)
[2024-11-13 05:39:58,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:58,871][root][INFO] - Training Epoch: 8/10, step 349/574 completed (loss: 0.1322098672389984, acc: 0.9444444179534912)
[2024-11-13 05:39:58,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:59,238][root][INFO] - Training Epoch: 8/10, step 350/574 completed (loss: 0.3525184392929077, acc: 0.8837209343910217)
[2024-11-13 05:39:59,362][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:59,568][root][INFO] - Training Epoch: 8/10, step 351/574 completed (loss: 0.029574237763881683, acc: 1.0)
[2024-11-13 05:39:59,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:39:59,938][root][INFO] - Training Epoch: 8/10, step 352/574 completed (loss: 0.18612314760684967, acc: 0.8888888955116272)
[2024-11-13 05:40:00,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:00,281][root][INFO] - Training Epoch: 8/10, step 353/574 completed (loss: 0.023277627304196358, acc: 1.0)
[2024-11-13 05:40:00,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:00,686][root][INFO] - Training Epoch: 8/10, step 354/574 completed (loss: 0.02960081584751606, acc: 1.0)
[2024-11-13 05:40:00,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:01,012][root][INFO] - Training Epoch: 8/10, step 355/574 completed (loss: 0.3472423255443573, acc: 0.9120879173278809)
[2024-11-13 05:40:01,125][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:01,513][root][INFO] - Training Epoch: 8/10, step 356/574 completed (loss: 0.2313305139541626, acc: 0.9130434989929199)
[2024-11-13 05:40:01,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:01,891][root][INFO] - Training Epoch: 8/10, step 357/574 completed (loss: 0.15324728190898895, acc: 0.95652174949646)
[2024-11-13 05:40:02,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:02,272][root][INFO] - Training Epoch: 8/10, step 358/574 completed (loss: 0.19440414011478424, acc: 0.9387755393981934)
[2024-11-13 05:40:02,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:02,658][root][INFO] - Training Epoch: 8/10, step 359/574 completed (loss: 0.0010402955813333392, acc: 1.0)
[2024-11-13 05:40:02,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:03,015][root][INFO] - Training Epoch: 8/10, step 360/574 completed (loss: 0.029944557696580887, acc: 0.9615384340286255)
[2024-11-13 05:40:03,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:03,415][root][INFO] - Training Epoch: 8/10, step 361/574 completed (loss: 0.06550263613462448, acc: 1.0)
[2024-11-13 05:40:03,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:03,816][root][INFO] - Training Epoch: 8/10, step 362/574 completed (loss: 0.14768239855766296, acc: 0.9555555582046509)
[2024-11-13 05:40:03,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:04,165][root][INFO] - Training Epoch: 8/10, step 363/574 completed (loss: 0.09929567575454712, acc: 0.9868420958518982)
[2024-11-13 05:40:04,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:04,517][root][INFO] - Training Epoch: 8/10, step 364/574 completed (loss: 0.015877284109592438, acc: 1.0)
[2024-11-13 05:40:04,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:04,885][root][INFO] - Training Epoch: 8/10, step 365/574 completed (loss: 0.1276518851518631, acc: 0.939393937587738)
[2024-11-13 05:40:05,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:05,272][root][INFO] - Training Epoch: 8/10, step 366/574 completed (loss: 0.0024619840551167727, acc: 1.0)
[2024-11-13 05:40:05,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:05,631][root][INFO] - Training Epoch: 8/10, step 367/574 completed (loss: 0.001427354640327394, acc: 1.0)
[2024-11-13 05:40:05,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:05,932][root][INFO] - Training Epoch: 8/10, step 368/574 completed (loss: 0.07437164336442947, acc: 0.9642857313156128)
[2024-11-13 05:40:06,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:06,290][root][INFO] - Training Epoch: 8/10, step 369/574 completed (loss: 0.08384215086698532, acc: 0.96875)
[2024-11-13 05:40:06,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:06,896][root][INFO] - Training Epoch: 8/10, step 370/574 completed (loss: 0.3777623474597931, acc: 0.8545454740524292)
[2024-11-13 05:40:07,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:07,772][root][INFO] - Training Epoch: 8/10, step 371/574 completed (loss: 0.22470977902412415, acc: 0.9150943160057068)
[2024-11-13 05:40:07,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:08,128][root][INFO] - Training Epoch: 8/10, step 372/574 completed (loss: 0.07040533423423767, acc: 0.9777777791023254)
[2024-11-13 05:40:08,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:08,500][root][INFO] - Training Epoch: 8/10, step 373/574 completed (loss: 0.07028474658727646, acc: 0.9642857313156128)
[2024-11-13 05:40:08,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:08,887][root][INFO] - Training Epoch: 8/10, step 374/574 completed (loss: 0.016997147351503372, acc: 1.0)
[2024-11-13 05:40:09,001][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:09,252][root][INFO] - Training Epoch: 8/10, step 375/574 completed (loss: 0.0007243438740260899, acc: 1.0)
[2024-11-13 05:40:09,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:09,560][root][INFO] - Training Epoch: 8/10, step 376/574 completed (loss: 0.0026746378280222416, acc: 1.0)
[2024-11-13 05:40:09,658][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:09,888][root][INFO] - Training Epoch: 8/10, step 377/574 completed (loss: 0.033988047391176224, acc: 1.0)
[2024-11-13 05:40:09,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:10,195][root][INFO] - Training Epoch: 8/10, step 378/574 completed (loss: 0.014313803054392338, acc: 0.9894737005233765)
[2024-11-13 05:40:10,349][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:10,769][root][INFO] - Training Epoch: 8/10, step 379/574 completed (loss: 0.15158015489578247, acc: 0.9520958065986633)
[2024-11-13 05:40:10,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:11,149][root][INFO] - Training Epoch: 8/10, step 380/574 completed (loss: 0.16792547702789307, acc: 0.9548872113227844)
[2024-11-13 05:40:11,625][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:12,404][root][INFO] - Training Epoch: 8/10, step 381/574 completed (loss: 0.369002103805542, acc: 0.8877005577087402)
[2024-11-13 05:40:12,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:12,978][root][INFO] - Training Epoch: 8/10, step 382/574 completed (loss: 0.04618550091981888, acc: 0.9819819927215576)
[2024-11-13 05:40:13,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:13,311][root][INFO] - Training Epoch: 8/10, step 383/574 completed (loss: 0.022356392815709114, acc: 1.0)
[2024-11-13 05:40:13,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:13,614][root][INFO] - Training Epoch: 8/10, step 384/574 completed (loss: 0.01887405477464199, acc: 1.0)
[2024-11-13 05:40:13,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:13,928][root][INFO] - Training Epoch: 8/10, step 385/574 completed (loss: 0.010936105623841286, acc: 1.0)
[2024-11-13 05:40:14,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:14,282][root][INFO] - Training Epoch: 8/10, step 386/574 completed (loss: 0.0039008664898574352, acc: 1.0)
[2024-11-13 05:40:14,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:14,671][root][INFO] - Training Epoch: 8/10, step 387/574 completed (loss: 0.036657217890024185, acc: 0.9736841917037964)
[2024-11-13 05:40:14,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:15,042][root][INFO] - Training Epoch: 8/10, step 388/574 completed (loss: 0.0018926411867141724, acc: 1.0)
[2024-11-13 05:40:15,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:15,410][root][INFO] - Training Epoch: 8/10, step 389/574 completed (loss: 0.01572008989751339, acc: 1.0)
[2024-11-13 05:40:15,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:15,744][root][INFO] - Training Epoch: 8/10, step 390/574 completed (loss: 0.4190467298030853, acc: 0.9047619104385376)
[2024-11-13 05:40:15,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:16,051][root][INFO] - Training Epoch: 8/10, step 391/574 completed (loss: 0.3466552495956421, acc: 0.8333333134651184)
[2024-11-13 05:40:16,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:16,441][root][INFO] - Training Epoch: 8/10, step 392/574 completed (loss: 0.5590306520462036, acc: 0.8349514603614807)
[2024-11-13 05:40:16,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:16,976][root][INFO] - Training Epoch: 8/10, step 393/574 completed (loss: 0.4673575162887573, acc: 0.8382353186607361)
[2024-11-13 05:40:17,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:17,345][root][INFO] - Training Epoch: 8/10, step 394/574 completed (loss: 0.33135396242141724, acc: 0.8933333158493042)
[2024-11-13 05:40:17,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:17,724][root][INFO] - Training Epoch: 8/10, step 395/574 completed (loss: 0.39262664318084717, acc: 0.8888888955116272)
[2024-11-13 05:40:17,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:18,021][root][INFO] - Training Epoch: 8/10, step 396/574 completed (loss: 0.05879075080156326, acc: 0.9767441749572754)
[2024-11-13 05:40:18,101][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:18,320][root][INFO] - Training Epoch: 8/10, step 397/574 completed (loss: 0.019858388230204582, acc: 1.0)
[2024-11-13 05:40:18,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:18,626][root][INFO] - Training Epoch: 8/10, step 398/574 completed (loss: 0.2287300080060959, acc: 0.8837209343910217)
[2024-11-13 05:40:18,713][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:18,934][root][INFO] - Training Epoch: 8/10, step 399/574 completed (loss: 0.012566284276545048, acc: 1.0)
[2024-11-13 05:40:19,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:19,464][root][INFO] - Training Epoch: 8/10, step 400/574 completed (loss: 0.2437359094619751, acc: 0.9264705777168274)
[2024-11-13 05:40:19,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:19,788][root][INFO] - Training Epoch: 8/10, step 401/574 completed (loss: 0.16725395619869232, acc: 0.9333333373069763)
[2024-11-13 05:40:19,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:20,134][root][INFO] - Training Epoch: 8/10, step 402/574 completed (loss: 0.044664379209280014, acc: 1.0)
[2024-11-13 05:40:20,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:20,453][root][INFO] - Training Epoch: 8/10, step 403/574 completed (loss: 0.18670667707920074, acc: 0.9696969985961914)
[2024-11-13 05:40:20,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:20,737][root][INFO] - Training Epoch: 8/10, step 404/574 completed (loss: 0.06646056473255157, acc: 0.9677419066429138)
[2024-11-13 05:40:20,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:21,012][root][INFO] - Training Epoch: 8/10, step 405/574 completed (loss: 0.1537591814994812, acc: 0.9259259104728699)
[2024-11-13 05:40:21,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:21,303][root][INFO] - Training Epoch: 8/10, step 406/574 completed (loss: 0.012462385930120945, acc: 1.0)
[2024-11-13 05:40:21,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:21,596][root][INFO] - Training Epoch: 8/10, step 407/574 completed (loss: 0.011860867962241173, acc: 1.0)
[2024-11-13 05:40:21,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:21,912][root][INFO] - Training Epoch: 8/10, step 408/574 completed (loss: 0.007047336082905531, acc: 1.0)
[2024-11-13 05:40:21,987][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:22,207][root][INFO] - Training Epoch: 8/10, step 409/574 completed (loss: 0.05115118250250816, acc: 0.9615384340286255)
[2024-11-13 05:40:22,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:22,554][root][INFO] - Training Epoch: 8/10, step 410/574 completed (loss: 0.05035446584224701, acc: 1.0)
[2024-11-13 05:40:22,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:22,888][root][INFO] - Training Epoch: 8/10, step 411/574 completed (loss: 0.12357459217309952, acc: 0.8928571343421936)
[2024-11-13 05:40:22,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:23,219][root][INFO] - Training Epoch: 8/10, step 412/574 completed (loss: 0.004588793497532606, acc: 1.0)
[2024-11-13 05:40:23,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:23,499][root][INFO] - Training Epoch: 8/10, step 413/574 completed (loss: 0.010746940039098263, acc: 1.0)
[2024-11-13 05:40:23,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:23,832][root][INFO] - Training Epoch: 8/10, step 414/574 completed (loss: 0.002923829248175025, acc: 1.0)
[2024-11-13 05:40:24,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:24,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:25,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:25,826][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:26,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:26,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:26,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:27,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:27,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:27,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:28,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:28,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:28,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:29,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:29,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:30,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:30,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:30,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:31,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:31,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:31,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:32,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:32,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:33,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:33,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:33,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:34,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:34,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:34,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:35,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:35,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:35,754][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:36,186][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:36,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:36,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:37,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:37,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:37,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:37,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:38,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:38,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:39,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:39,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:39,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:40,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:40,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:41,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:41,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:41,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:42,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:42,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:42,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:43,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:43,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:43,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:44,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:44,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:44,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:45,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:45,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:45,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:46,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:46,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:46,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:46,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:47,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:47,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:47,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:48,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:48,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:49,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:49,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:49,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:50,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:50,505][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:50,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:51,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:51,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:51,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:51,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:52,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:52,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:52,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:53,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:53,778][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4721, device='cuda:0') eval_epoch_loss=tensor(0.9051, device='cuda:0') eval_epoch_acc=tensor(0.7951, device='cuda:0')
[2024-11-13 05:40:53,779][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:40:53,779][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:40:54,086][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_8_step_415_loss_0.9050807356834412/model.pt
[2024-11-13 05:40:54,089][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:40:54,179][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:54,455][root][INFO] - Training Epoch: 8/10, step 415/574 completed (loss: 0.15582561492919922, acc: 0.9411764740943909)
[2024-11-13 05:40:54,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:54,845][root][INFO] - Training Epoch: 8/10, step 416/574 completed (loss: 0.019170809537172318, acc: 1.0)
[2024-11-13 05:40:54,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:55,256][root][INFO] - Training Epoch: 8/10, step 417/574 completed (loss: 0.008999746292829514, acc: 1.0)
[2024-11-13 05:40:55,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:55,604][root][INFO] - Training Epoch: 8/10, step 418/574 completed (loss: 0.042240824550390244, acc: 1.0)
[2024-11-13 05:40:55,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:55,927][root][INFO] - Training Epoch: 8/10, step 419/574 completed (loss: 0.10522668063640594, acc: 0.949999988079071)
[2024-11-13 05:40:56,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:56,239][root][INFO] - Training Epoch: 8/10, step 420/574 completed (loss: 0.0253090001642704, acc: 1.0)
[2024-11-13 05:40:56,319][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:56,545][root][INFO] - Training Epoch: 8/10, step 421/574 completed (loss: 0.058809876441955566, acc: 0.9666666388511658)
[2024-11-13 05:40:56,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:56,941][root][INFO] - Training Epoch: 8/10, step 422/574 completed (loss: 0.05023323744535446, acc: 1.0)
[2024-11-13 05:40:57,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:57,375][root][INFO] - Training Epoch: 8/10, step 423/574 completed (loss: 0.04992496967315674, acc: 0.9722222089767456)
[2024-11-13 05:40:57,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:57,762][root][INFO] - Training Epoch: 8/10, step 424/574 completed (loss: 0.0942358672618866, acc: 0.9259259104728699)
[2024-11-13 05:40:57,845][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:58,057][root][INFO] - Training Epoch: 8/10, step 425/574 completed (loss: 0.1516389548778534, acc: 0.9696969985961914)
[2024-11-13 05:40:58,134][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:58,343][root][INFO] - Training Epoch: 8/10, step 426/574 completed (loss: 0.003211389994248748, acc: 1.0)
[2024-11-13 05:40:58,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:58,641][root][INFO] - Training Epoch: 8/10, step 427/574 completed (loss: 0.16167788207530975, acc: 0.9459459185600281)
[2024-11-13 05:40:58,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:58,921][root][INFO] - Training Epoch: 8/10, step 428/574 completed (loss: 0.007848982699215412, acc: 1.0)
[2024-11-13 05:40:58,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:59,218][root][INFO] - Training Epoch: 8/10, step 429/574 completed (loss: 0.07240492105484009, acc: 0.95652174949646)
[2024-11-13 05:40:59,295][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:59,516][root][INFO] - Training Epoch: 8/10, step 430/574 completed (loss: 0.0028185078408569098, acc: 1.0)
[2024-11-13 05:40:59,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:40:59,834][root][INFO] - Training Epoch: 8/10, step 431/574 completed (loss: 0.006428648252040148, acc: 1.0)
[2024-11-13 05:40:59,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:00,141][root][INFO] - Training Epoch: 8/10, step 432/574 completed (loss: 0.0035434705205261707, acc: 1.0)
[2024-11-13 05:41:00,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:00,533][root][INFO] - Training Epoch: 8/10, step 433/574 completed (loss: 0.06058469042181969, acc: 0.9722222089767456)
[2024-11-13 05:41:00,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:00,869][root][INFO] - Training Epoch: 8/10, step 434/574 completed (loss: 0.012195838615298271, acc: 1.0)
[2024-11-13 05:41:00,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:01,188][root][INFO] - Training Epoch: 8/10, step 435/574 completed (loss: 0.0054751732386648655, acc: 1.0)
[2024-11-13 05:41:01,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:01,492][root][INFO] - Training Epoch: 8/10, step 436/574 completed (loss: 0.041790083050727844, acc: 1.0)
[2024-11-13 05:41:01,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:01,874][root][INFO] - Training Epoch: 8/10, step 437/574 completed (loss: 0.05789943039417267, acc: 0.9545454382896423)
[2024-11-13 05:41:01,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:02,269][root][INFO] - Training Epoch: 8/10, step 438/574 completed (loss: 0.002309326082468033, acc: 1.0)
[2024-11-13 05:41:02,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:02,566][root][INFO] - Training Epoch: 8/10, step 439/574 completed (loss: 0.055740710347890854, acc: 0.9743589758872986)
[2024-11-13 05:41:02,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:03,006][root][INFO] - Training Epoch: 8/10, step 440/574 completed (loss: 0.11522085219621658, acc: 0.9696969985961914)
[2024-11-13 05:41:03,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:03,779][root][INFO] - Training Epoch: 8/10, step 441/574 completed (loss: 0.3991434872150421, acc: 0.871999979019165)
[2024-11-13 05:41:03,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:04,195][root][INFO] - Training Epoch: 8/10, step 442/574 completed (loss: 0.3744923770427704, acc: 0.8790322542190552)
[2024-11-13 05:41:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:04,855][root][INFO] - Training Epoch: 8/10, step 443/574 completed (loss: 0.3660300672054291, acc: 0.8855721354484558)
[2024-11-13 05:41:04,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:05,129][root][INFO] - Training Epoch: 8/10, step 444/574 completed (loss: 0.03762471303343773, acc: 0.9811320900917053)
[2024-11-13 05:41:05,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:05,546][root][INFO] - Training Epoch: 8/10, step 445/574 completed (loss: 0.046088751405477524, acc: 1.0)
[2024-11-13 05:41:05,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:05,824][root][INFO] - Training Epoch: 8/10, step 446/574 completed (loss: 0.0065743690356612206, acc: 1.0)
[2024-11-13 05:41:05,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:06,132][root][INFO] - Training Epoch: 8/10, step 447/574 completed (loss: 0.014463474042713642, acc: 1.0)
[2024-11-13 05:41:06,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:06,487][root][INFO] - Training Epoch: 8/10, step 448/574 completed (loss: 0.011137522757053375, acc: 1.0)
[2024-11-13 05:41:06,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:06,806][root][INFO] - Training Epoch: 8/10, step 449/574 completed (loss: 0.08215195685625076, acc: 0.9701492786407471)
[2024-11-13 05:41:06,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:07,140][root][INFO] - Training Epoch: 8/10, step 450/574 completed (loss: 0.037357527762651443, acc: 0.9722222089767456)
[2024-11-13 05:41:07,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:07,493][root][INFO] - Training Epoch: 8/10, step 451/574 completed (loss: 0.016706865280866623, acc: 0.989130437374115)
[2024-11-13 05:41:07,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:07,842][root][INFO] - Training Epoch: 8/10, step 452/574 completed (loss: 0.041050832718610764, acc: 0.9871794581413269)
[2024-11-13 05:41:07,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:08,201][root][INFO] - Training Epoch: 8/10, step 453/574 completed (loss: 0.09491036087274551, acc: 0.9736841917037964)
[2024-11-13 05:41:08,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:08,560][root][INFO] - Training Epoch: 8/10, step 454/574 completed (loss: 0.07279828935861588, acc: 0.9795918464660645)
[2024-11-13 05:41:08,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:08,927][root][INFO] - Training Epoch: 8/10, step 455/574 completed (loss: 0.1161855086684227, acc: 0.9696969985961914)
[2024-11-13 05:41:09,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:09,312][root][INFO] - Training Epoch: 8/10, step 456/574 completed (loss: 0.24516259133815765, acc: 0.9175257682800293)
[2024-11-13 05:41:09,439][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:09,714][root][INFO] - Training Epoch: 8/10, step 457/574 completed (loss: 0.03038644790649414, acc: 0.9857142567634583)
[2024-11-13 05:41:09,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:10,089][root][INFO] - Training Epoch: 8/10, step 458/574 completed (loss: 0.15874049067497253, acc: 0.9418604373931885)
[2024-11-13 05:41:10,197][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:10,423][root][INFO] - Training Epoch: 8/10, step 459/574 completed (loss: 0.07724151760339737, acc: 0.9821428656578064)
[2024-11-13 05:41:10,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:10,762][root][INFO] - Training Epoch: 8/10, step 460/574 completed (loss: 0.14510129392147064, acc: 0.9629629850387573)
[2024-11-13 05:41:10,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:11,105][root][INFO] - Training Epoch: 8/10, step 461/574 completed (loss: 0.0804385095834732, acc: 0.9722222089767456)
[2024-11-13 05:41:11,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:11,423][root][INFO] - Training Epoch: 8/10, step 462/574 completed (loss: 0.9148527979850769, acc: 0.90625)
[2024-11-13 05:41:11,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:11,693][root][INFO] - Training Epoch: 8/10, step 463/574 completed (loss: 0.009096814319491386, acc: 1.0)
[2024-11-13 05:41:11,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:12,068][root][INFO] - Training Epoch: 8/10, step 464/574 completed (loss: 0.13851723074913025, acc: 0.97826087474823)
[2024-11-13 05:41:12,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:12,418][root][INFO] - Training Epoch: 8/10, step 465/574 completed (loss: 0.06763223558664322, acc: 0.988095223903656)
[2024-11-13 05:41:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:12,778][root][INFO] - Training Epoch: 8/10, step 466/574 completed (loss: 0.2730922996997833, acc: 0.9397590160369873)
[2024-11-13 05:41:12,885][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:13,142][root][INFO] - Training Epoch: 8/10, step 467/574 completed (loss: 0.21250653266906738, acc: 0.9369369149208069)
[2024-11-13 05:41:13,245][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:13,502][root][INFO] - Training Epoch: 8/10, step 468/574 completed (loss: 0.23560522496700287, acc: 0.9320388436317444)
[2024-11-13 05:41:13,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:13,882][root][INFO] - Training Epoch: 8/10, step 469/574 completed (loss: 0.179860919713974, acc: 0.9512194991111755)
[2024-11-13 05:41:14,000][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:14,198][root][INFO] - Training Epoch: 8/10, step 470/574 completed (loss: 0.013076392002403736, acc: 1.0)
[2024-11-13 05:41:14,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:14,562][root][INFO] - Training Epoch: 8/10, step 471/574 completed (loss: 0.013877565041184425, acc: 1.0)
[2024-11-13 05:41:14,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:14,974][root][INFO] - Training Epoch: 8/10, step 472/574 completed (loss: 0.3762909770011902, acc: 0.8823529481887817)
[2024-11-13 05:41:15,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:15,335][root][INFO] - Training Epoch: 8/10, step 473/574 completed (loss: 0.4712475836277008, acc: 0.8733624219894409)
[2024-11-13 05:41:15,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:15,610][root][INFO] - Training Epoch: 8/10, step 474/574 completed (loss: 0.15004579722881317, acc: 0.9583333134651184)
[2024-11-13 05:41:15,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:15,912][root][INFO] - Training Epoch: 8/10, step 475/574 completed (loss: 0.23374532163143158, acc: 0.9263803958892822)
[2024-11-13 05:41:15,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:16,191][root][INFO] - Training Epoch: 8/10, step 476/574 completed (loss: 0.23580466210842133, acc: 0.9208633303642273)
[2024-11-13 05:41:16,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:16,573][root][INFO] - Training Epoch: 8/10, step 477/574 completed (loss: 0.4776111841201782, acc: 0.8542713522911072)
[2024-11-13 05:41:16,688][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:16,957][root][INFO] - Training Epoch: 8/10, step 478/574 completed (loss: 0.041081055998802185, acc: 1.0)
[2024-11-13 05:41:17,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:17,264][root][INFO] - Training Epoch: 8/10, step 479/574 completed (loss: 0.02941797487437725, acc: 1.0)
[2024-11-13 05:41:17,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:17,578][root][INFO] - Training Epoch: 8/10, step 480/574 completed (loss: 0.16790027916431427, acc: 0.9259259104728699)
[2024-11-13 05:41:17,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:17,930][root][INFO] - Training Epoch: 8/10, step 481/574 completed (loss: 0.2355698049068451, acc: 0.8999999761581421)
[2024-11-13 05:41:18,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:18,264][root][INFO] - Training Epoch: 8/10, step 482/574 completed (loss: 0.027509868144989014, acc: 1.0)
[2024-11-13 05:41:18,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:18,648][root][INFO] - Training Epoch: 8/10, step 483/574 completed (loss: 0.7756268978118896, acc: 0.8275862336158752)
[2024-11-13 05:41:18,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:19,029][root][INFO] - Training Epoch: 8/10, step 484/574 completed (loss: 0.10756834596395493, acc: 0.9677419066429138)
[2024-11-13 05:41:19,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:19,392][root][INFO] - Training Epoch: 8/10, step 485/574 completed (loss: 0.01558124739676714, acc: 1.0)
[2024-11-13 05:41:19,502][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:19,697][root][INFO] - Training Epoch: 8/10, step 486/574 completed (loss: 0.04477585107088089, acc: 1.0)
[2024-11-13 05:41:19,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:19,968][root][INFO] - Training Epoch: 8/10, step 487/574 completed (loss: 0.060862403362989426, acc: 1.0)
[2024-11-13 05:41:20,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:20,255][root][INFO] - Training Epoch: 8/10, step 488/574 completed (loss: 0.04009136185050011, acc: 1.0)
[2024-11-13 05:41:20,363][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:20,660][root][INFO] - Training Epoch: 8/10, step 489/574 completed (loss: 0.2793378233909607, acc: 0.9384615421295166)
[2024-11-13 05:41:20,772][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:20,958][root][INFO] - Training Epoch: 8/10, step 490/574 completed (loss: 0.02537425048649311, acc: 1.0)
[2024-11-13 05:41:21,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:21,259][root][INFO] - Training Epoch: 8/10, step 491/574 completed (loss: 0.013246946968138218, acc: 1.0)
[2024-11-13 05:41:21,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:21,620][root][INFO] - Training Epoch: 8/10, step 492/574 completed (loss: 0.2628229856491089, acc: 0.9215686321258545)
[2024-11-13 05:41:21,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:21,978][root][INFO] - Training Epoch: 8/10, step 493/574 completed (loss: 0.29957136511802673, acc: 0.8965517282485962)
[2024-11-13 05:41:22,063][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:22,256][root][INFO] - Training Epoch: 8/10, step 494/574 completed (loss: 0.16189417243003845, acc: 0.8947368264198303)
[2024-11-13 05:41:22,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:22,509][root][INFO] - Training Epoch: 8/10, step 495/574 completed (loss: 0.032037459313869476, acc: 1.0)
[2024-11-13 05:41:22,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:22,856][root][INFO] - Training Epoch: 8/10, step 496/574 completed (loss: 0.3071046769618988, acc: 0.9017857313156128)
[2024-11-13 05:41:22,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:23,269][root][INFO] - Training Epoch: 8/10, step 497/574 completed (loss: 0.16871307790279388, acc: 0.9550561904907227)
[2024-11-13 05:41:23,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:23,636][root][INFO] - Training Epoch: 8/10, step 498/574 completed (loss: 0.3338013291358948, acc: 0.8876404762268066)
[2024-11-13 05:41:23,735][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:23,996][root][INFO] - Training Epoch: 8/10, step 499/574 completed (loss: 0.6698300838470459, acc: 0.7659574747085571)
[2024-11-13 05:41:24,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:24,329][root][INFO] - Training Epoch: 8/10, step 500/574 completed (loss: 0.3069371283054352, acc: 0.9130434989929199)
[2024-11-13 05:41:24,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:24,664][root][INFO] - Training Epoch: 8/10, step 501/574 completed (loss: 0.10459013283252716, acc: 0.9599999785423279)
[2024-11-13 05:41:24,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:24,961][root][INFO] - Training Epoch: 8/10, step 502/574 completed (loss: 0.002855949103832245, acc: 1.0)
[2024-11-13 05:41:25,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:25,314][root][INFO] - Training Epoch: 8/10, step 503/574 completed (loss: 0.020484816282987595, acc: 1.0)
[2024-11-13 05:41:25,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:25,629][root][INFO] - Training Epoch: 8/10, step 504/574 completed (loss: 0.08688363432884216, acc: 0.9629629850387573)
[2024-11-13 05:41:25,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:25,876][root][INFO] - Training Epoch: 8/10, step 505/574 completed (loss: 0.2257264107465744, acc: 0.9433962106704712)
[2024-11-13 05:41:25,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:26,126][root][INFO] - Training Epoch: 8/10, step 506/574 completed (loss: 0.35839176177978516, acc: 0.8965517282485962)
[2024-11-13 05:41:26,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:26,715][root][INFO] - Training Epoch: 8/10, step 507/574 completed (loss: 0.5843181610107422, acc: 0.8288288116455078)
[2024-11-13 05:41:26,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:27,149][root][INFO] - Training Epoch: 8/10, step 508/574 completed (loss: 0.35670948028564453, acc: 0.9154929518699646)
[2024-11-13 05:41:27,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:27,508][root][INFO] - Training Epoch: 8/10, step 509/574 completed (loss: 0.05043930560350418, acc: 0.949999988079071)
[2024-11-13 05:41:27,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:27,814][root][INFO] - Training Epoch: 8/10, step 510/574 completed (loss: 0.11164578050374985, acc: 0.9333333373069763)
[2024-11-13 05:41:27,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:28,096][root][INFO] - Training Epoch: 8/10, step 511/574 completed (loss: 0.015032464638352394, acc: 1.0)
[2024-11-13 05:41:29,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:31,128][root][INFO] - Training Epoch: 8/10, step 512/574 completed (loss: 0.7343819737434387, acc: 0.8142856955528259)
[2024-11-13 05:41:31,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:31,900][root][INFO] - Training Epoch: 8/10, step 513/574 completed (loss: 0.2934127748012543, acc: 0.9047619104385376)
[2024-11-13 05:41:32,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:32,267][root][INFO] - Training Epoch: 8/10, step 514/574 completed (loss: 0.15806470811367035, acc: 0.9285714030265808)
[2024-11-13 05:41:32,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:32,642][root][INFO] - Training Epoch: 8/10, step 515/574 completed (loss: 0.09874412417411804, acc: 0.9666666388511658)
[2024-11-13 05:41:32,827][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:33,339][root][INFO] - Training Epoch: 8/10, step 516/574 completed (loss: 0.12166532129049301, acc: 0.9444444179534912)
[2024-11-13 05:41:33,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:33,654][root][INFO] - Training Epoch: 8/10, step 517/574 completed (loss: 0.0018025075551122427, acc: 1.0)
[2024-11-13 05:41:33,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:33,963][root][INFO] - Training Epoch: 8/10, step 518/574 completed (loss: 0.029452325776219368, acc: 1.0)
[2024-11-13 05:41:34,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:34,323][root][INFO] - Training Epoch: 8/10, step 519/574 completed (loss: 0.27628764510154724, acc: 0.949999988079071)
[2024-11-13 05:41:34,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:34,697][root][INFO] - Training Epoch: 8/10, step 520/574 completed (loss: 0.22750899195671082, acc: 0.9629629850387573)
[2024-11-13 05:41:34,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:35,702][root][INFO] - Training Epoch: 8/10, step 521/574 completed (loss: 0.6050097942352295, acc: 0.8177965879440308)
[2024-11-13 05:41:35,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:36,045][root][INFO] - Training Epoch: 8/10, step 522/574 completed (loss: 0.2671673893928528, acc: 0.9179104566574097)
[2024-11-13 05:41:36,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:36,434][root][INFO] - Training Epoch: 8/10, step 523/574 completed (loss: 0.26226329803466797, acc: 0.9124087691307068)
[2024-11-13 05:41:36,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:36,994][root][INFO] - Training Epoch: 8/10, step 524/574 completed (loss: 0.45661982893943787, acc: 0.8799999952316284)
[2024-11-13 05:41:37,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:37,355][root][INFO] - Training Epoch: 8/10, step 525/574 completed (loss: 0.022087644785642624, acc: 1.0)
[2024-11-13 05:41:37,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:37,743][root][INFO] - Training Epoch: 8/10, step 526/574 completed (loss: 0.1017741709947586, acc: 0.9807692170143127)
[2024-11-13 05:41:37,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:38,116][root][INFO] - Training Epoch: 8/10, step 527/574 completed (loss: 0.08056571334600449, acc: 0.9523809552192688)
[2024-11-13 05:41:38,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:38,498][root][INFO] - Training Epoch: 8/10, step 528/574 completed (loss: 0.44815561175346375, acc: 0.8852459192276001)
[2024-11-13 05:41:38,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:38,835][root][INFO] - Training Epoch: 8/10, step 529/574 completed (loss: 0.22083669900894165, acc: 0.9491525292396545)
[2024-11-13 05:41:38,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:39,148][root][INFO] - Training Epoch: 8/10, step 530/574 completed (loss: 0.36803072690963745, acc: 0.8604651093482971)
[2024-11-13 05:41:39,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:39,530][root][INFO] - Training Epoch: 8/10, step 531/574 completed (loss: 0.22994574904441833, acc: 0.9318181872367859)
[2024-11-13 05:41:39,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:39,849][root][INFO] - Training Epoch: 8/10, step 532/574 completed (loss: 0.35702475905418396, acc: 0.849056601524353)
[2024-11-13 05:41:39,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:40,236][root][INFO] - Training Epoch: 8/10, step 533/574 completed (loss: 0.23928092420101166, acc: 0.9318181872367859)
[2024-11-13 05:41:40,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:40,571][root][INFO] - Training Epoch: 8/10, step 534/574 completed (loss: 0.12484601885080338, acc: 0.9599999785423279)
[2024-11-13 05:41:40,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:40,957][root][INFO] - Training Epoch: 8/10, step 535/574 completed (loss: 0.08902567625045776, acc: 0.949999988079071)
[2024-11-13 05:41:41,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:41,320][root][INFO] - Training Epoch: 8/10, step 536/574 completed (loss: 0.022298984229564667, acc: 1.0)
[2024-11-13 05:41:41,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:41,748][root][INFO] - Training Epoch: 8/10, step 537/574 completed (loss: 0.14574939012527466, acc: 0.9538461565971375)
[2024-11-13 05:41:41,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:42,132][root][INFO] - Training Epoch: 8/10, step 538/574 completed (loss: 0.137135848402977, acc: 0.96875)
[2024-11-13 05:41:42,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:42,531][root][INFO] - Training Epoch: 8/10, step 539/574 completed (loss: 0.26788657903671265, acc: 0.90625)
[2024-11-13 05:41:42,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:42,825][root][INFO] - Training Epoch: 8/10, step 540/574 completed (loss: 0.26818597316741943, acc: 0.939393937587738)
[2024-11-13 05:41:42,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:43,166][root][INFO] - Training Epoch: 8/10, step 541/574 completed (loss: 0.02797234244644642, acc: 1.0)
[2024-11-13 05:41:43,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:43,526][root][INFO] - Training Epoch: 8/10, step 542/574 completed (loss: 0.1307738721370697, acc: 0.9354838728904724)
[2024-11-13 05:41:43,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:43,850][root][INFO] - Training Epoch: 8/10, step 543/574 completed (loss: 0.0073960404843091965, acc: 1.0)
[2024-11-13 05:41:43,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:44,207][root][INFO] - Training Epoch: 8/10, step 544/574 completed (loss: 0.13204573094844818, acc: 0.9333333373069763)
[2024-11-13 05:41:44,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:44,561][root][INFO] - Training Epoch: 8/10, step 545/574 completed (loss: 0.07808434218168259, acc: 0.9756097793579102)
[2024-11-13 05:41:44,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:44,867][root][INFO] - Training Epoch: 8/10, step 546/574 completed (loss: 0.013570521958172321, acc: 1.0)
[2024-11-13 05:41:44,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:45,221][root][INFO] - Training Epoch: 8/10, step 547/574 completed (loss: 0.011919637210667133, acc: 1.0)
[2024-11-13 05:41:45,346][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:45,582][root][INFO] - Training Epoch: 8/10, step 548/574 completed (loss: 0.01234657596796751, acc: 1.0)
[2024-11-13 05:41:45,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:45,887][root][INFO] - Training Epoch: 8/10, step 549/574 completed (loss: 0.0012763679260388017, acc: 1.0)
[2024-11-13 05:41:45,969][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:46,190][root][INFO] - Training Epoch: 8/10, step 550/574 completed (loss: 0.03401266038417816, acc: 1.0)
[2024-11-13 05:41:46,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:46,480][root][INFO] - Training Epoch: 8/10, step 551/574 completed (loss: 0.07508023828268051, acc: 0.9750000238418579)
[2024-11-13 05:41:46,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:46,783][root][INFO] - Training Epoch: 8/10, step 552/574 completed (loss: 0.08316553384065628, acc: 0.9714285731315613)
[2024-11-13 05:41:46,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:47,109][root][INFO] - Training Epoch: 8/10, step 553/574 completed (loss: 0.2649792432785034, acc: 0.9197080135345459)
[2024-11-13 05:41:47,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:47,423][root][INFO] - Training Epoch: 8/10, step 554/574 completed (loss: 0.1464410275220871, acc: 0.951724112033844)
[2024-11-13 05:41:47,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:47,725][root][INFO] - Training Epoch: 8/10, step 555/574 completed (loss: 0.15612798929214478, acc: 0.9357143044471741)
[2024-11-13 05:41:47,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:48,038][root][INFO] - Training Epoch: 8/10, step 556/574 completed (loss: 0.16971227526664734, acc: 0.9470198750495911)
[2024-11-13 05:41:48,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:48,360][root][INFO] - Training Epoch: 8/10, step 557/574 completed (loss: 0.07172416895627975, acc: 0.9743589758872986)
[2024-11-13 05:41:49,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:49,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:49,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:50,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:50,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:51,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:51,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:51,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:52,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:52,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:52,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:53,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:53,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:54,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:54,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:54,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:55,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:55,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:55,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:56,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:56,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:56,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:57,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:57,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:57,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:58,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:58,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:58,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:59,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:41:59,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:00,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:00,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:00,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:01,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:01,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:01,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:02,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:02,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:02,837][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:03,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:03,666][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:03,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:04,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:04,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:04,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:05,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:05,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:05,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:06,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:06,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:06,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:07,201][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:07,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:07,916][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:08,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:08,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:08,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:09,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:09,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:09,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:10,389][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:10,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:11,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:11,746][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:12,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:12,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:12,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:13,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:13,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:14,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:14,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:14,812][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:15,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:15,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:15,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:16,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:16,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:16,883][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:17,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:17,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:17,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:18,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:18,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:19,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:19,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:20,099][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6422, device='cuda:0') eval_epoch_loss=tensor(0.9716, device='cuda:0') eval_epoch_acc=tensor(0.7947, device='cuda:0')
[2024-11-13 05:42:20,100][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:42:20,100][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:42:20,484][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_8_step_558_loss_0.9716230034828186/model.pt
[2024-11-13 05:42:20,487][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:42:20,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:20,920][root][INFO] - Training Epoch: 8/10, step 558/574 completed (loss: 0.08169505000114441, acc: 0.9599999785423279)
[2024-11-13 05:42:21,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:21,296][root][INFO] - Training Epoch: 8/10, step 559/574 completed (loss: 0.03687896952033043, acc: 1.0)
[2024-11-13 05:42:21,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:21,558][root][INFO] - Training Epoch: 8/10, step 560/574 completed (loss: 0.06930860131978989, acc: 0.9615384340286255)
[2024-11-13 05:42:21,669][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:21,951][root][INFO] - Training Epoch: 8/10, step 561/574 completed (loss: 0.12529781460762024, acc: 0.9743589758872986)
[2024-11-13 05:42:22,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:22,333][root][INFO] - Training Epoch: 8/10, step 562/574 completed (loss: 0.0956568494439125, acc: 0.9666666388511658)
[2024-11-13 05:42:22,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:22,688][root][INFO] - Training Epoch: 8/10, step 563/574 completed (loss: 0.13772346079349518, acc: 0.9610389471054077)
[2024-11-13 05:42:22,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:22,981][root][INFO] - Training Epoch: 8/10, step 564/574 completed (loss: 0.10182458907365799, acc: 0.9583333134651184)
[2024-11-13 05:42:23,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:23,328][root][INFO] - Training Epoch: 8/10, step 565/574 completed (loss: 0.026158910244703293, acc: 0.982758641242981)
[2024-11-13 05:42:23,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:23,681][root][INFO] - Training Epoch: 8/10, step 566/574 completed (loss: 0.043266016989946365, acc: 1.0)
[2024-11-13 05:42:23,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:24,075][root][INFO] - Training Epoch: 8/10, step 567/574 completed (loss: 0.0064524258486926556, acc: 1.0)
[2024-11-13 05:42:24,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:24,408][root][INFO] - Training Epoch: 8/10, step 568/574 completed (loss: 0.1252439320087433, acc: 0.9629629850387573)
[2024-11-13 05:42:24,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:24,814][root][INFO] - Training Epoch: 8/10, step 569/574 completed (loss: 0.2621922492980957, acc: 0.9090909361839294)
[2024-11-13 05:42:24,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:25,103][root][INFO] - Training Epoch: 8/10, step 570/574 completed (loss: 0.004960118792951107, acc: 1.0)
[2024-11-13 05:42:25,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:25,506][root][INFO] - Training Epoch: 8/10, step 571/574 completed (loss: 0.10261145979166031, acc: 0.9572649598121643)
[2024-11-13 05:42:25,602][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:25,836][root][INFO] - Training Epoch: 8/10, step 572/574 completed (loss: 0.39924943447113037, acc: 0.8877550959587097)
[2024-11-13 05:42:25,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:26,169][root][INFO] - Training Epoch: 8/10, step 573/574 completed (loss: 0.31951603293418884, acc: 0.9245283007621765)
[2024-11-13 05:42:26,605][slam_llm.utils.train_utils][INFO] - Epoch 8: train_perplexity=1.2044, train_epoch_loss=0.1860, epoch time 352.58387061581016s
[2024-11-13 05:42:26,606][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:42:26,606][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 15 GB
[2024-11-13 05:42:26,606][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:42:26,606][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 22
[2024-11-13 05:42:26,606][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:42:27,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:27,491][root][INFO] - Training Epoch: 9/10, step 0/574 completed (loss: 0.09814492613077164, acc: 0.9629629850387573)
[2024-11-13 05:42:27,614][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:27,868][root][INFO] - Training Epoch: 9/10, step 1/574 completed (loss: 0.04623352363705635, acc: 0.9599999785423279)
[2024-11-13 05:42:27,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:28,129][root][INFO] - Training Epoch: 9/10, step 2/574 completed (loss: 0.12265489995479584, acc: 0.9729729890823364)
[2024-11-13 05:42:28,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:28,505][root][INFO] - Training Epoch: 9/10, step 3/574 completed (loss: 0.020006820559501648, acc: 1.0)
[2024-11-13 05:42:28,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:28,885][root][INFO] - Training Epoch: 9/10, step 4/574 completed (loss: 0.1466759741306305, acc: 0.9459459185600281)
[2024-11-13 05:42:29,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:29,319][root][INFO] - Training Epoch: 9/10, step 5/574 completed (loss: 0.02224631793797016, acc: 1.0)
[2024-11-13 05:42:29,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:29,671][root][INFO] - Training Epoch: 9/10, step 6/574 completed (loss: 0.2441428005695343, acc: 0.918367326259613)
[2024-11-13 05:42:29,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:30,034][root][INFO] - Training Epoch: 9/10, step 7/574 completed (loss: 0.033065542578697205, acc: 1.0)
[2024-11-13 05:42:30,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:30,422][root][INFO] - Training Epoch: 9/10, step 8/574 completed (loss: 0.0841042697429657, acc: 0.9545454382896423)
[2024-11-13 05:42:30,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:30,760][root][INFO] - Training Epoch: 9/10, step 9/574 completed (loss: 0.0024747285060584545, acc: 1.0)
[2024-11-13 05:42:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:31,114][root][INFO] - Training Epoch: 9/10, step 10/574 completed (loss: 0.0015476143453270197, acc: 1.0)
[2024-11-13 05:42:31,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:31,457][root][INFO] - Training Epoch: 9/10, step 11/574 completed (loss: 0.04715721681714058, acc: 0.9743589758872986)
[2024-11-13 05:42:31,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:31,748][root][INFO] - Training Epoch: 9/10, step 12/574 completed (loss: 0.0367187038064003, acc: 1.0)
[2024-11-13 05:42:31,843][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:32,089][root][INFO] - Training Epoch: 9/10, step 13/574 completed (loss: 0.25760865211486816, acc: 0.95652174949646)
[2024-11-13 05:42:32,174][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:32,410][root][INFO] - Training Epoch: 9/10, step 14/574 completed (loss: 0.02413242496550083, acc: 1.0)
[2024-11-13 05:42:32,487][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:32,720][root][INFO] - Training Epoch: 9/10, step 15/574 completed (loss: 0.15958520770072937, acc: 0.9387755393981934)
[2024-11-13 05:42:32,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:33,010][root][INFO] - Training Epoch: 9/10, step 16/574 completed (loss: 0.0010689073242247105, acc: 1.0)
[2024-11-13 05:42:33,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:33,293][root][INFO] - Training Epoch: 9/10, step 17/574 completed (loss: 0.029599564149975777, acc: 1.0)
[2024-11-13 05:42:33,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:33,573][root][INFO] - Training Epoch: 9/10, step 18/574 completed (loss: 0.022298431023955345, acc: 1.0)
[2024-11-13 05:42:33,645][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:33,872][root][INFO] - Training Epoch: 9/10, step 19/574 completed (loss: 0.12672913074493408, acc: 0.8947368264198303)
[2024-11-13 05:42:33,977][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:34,212][root][INFO] - Training Epoch: 9/10, step 20/574 completed (loss: 0.07208224385976791, acc: 0.9615384340286255)
[2024-11-13 05:42:34,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:34,510][root][INFO] - Training Epoch: 9/10, step 21/574 completed (loss: 0.06692814081907272, acc: 1.0)
[2024-11-13 05:42:34,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:34,865][root][INFO] - Training Epoch: 9/10, step 22/574 completed (loss: 0.012993781827390194, acc: 1.0)
[2024-11-13 05:42:34,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:35,158][root][INFO] - Training Epoch: 9/10, step 23/574 completed (loss: 0.002416943898424506, acc: 1.0)
[2024-11-13 05:42:35,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:35,435][root][INFO] - Training Epoch: 9/10, step 24/574 completed (loss: 0.01650065928697586, acc: 1.0)
[2024-11-13 05:42:35,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:35,719][root][INFO] - Training Epoch: 9/10, step 25/574 completed (loss: 0.21716594696044922, acc: 0.9056603908538818)
[2024-11-13 05:42:35,802][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:36,051][root][INFO] - Training Epoch: 9/10, step 26/574 completed (loss: 0.19855162501335144, acc: 0.931506872177124)
[2024-11-13 05:42:36,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:37,472][root][INFO] - Training Epoch: 9/10, step 27/574 completed (loss: 0.6679028868675232, acc: 0.7984189987182617)
[2024-11-13 05:42:37,538][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:37,755][root][INFO] - Training Epoch: 9/10, step 28/574 completed (loss: 0.1822091042995453, acc: 0.9534883499145508)
[2024-11-13 05:42:37,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:38,071][root][INFO] - Training Epoch: 9/10, step 29/574 completed (loss: 0.2103712260723114, acc: 0.9397590160369873)
[2024-11-13 05:42:38,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:38,397][root][INFO] - Training Epoch: 9/10, step 30/574 completed (loss: 0.18322470784187317, acc: 0.9259259104728699)
[2024-11-13 05:42:38,471][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:38,704][root][INFO] - Training Epoch: 9/10, step 31/574 completed (loss: 0.03894132748246193, acc: 0.9642857313156128)
[2024-11-13 05:42:38,817][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:39,129][root][INFO] - Training Epoch: 9/10, step 32/574 completed (loss: 0.01872236281633377, acc: 1.0)
[2024-11-13 05:42:39,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:39,493][root][INFO] - Training Epoch: 9/10, step 33/574 completed (loss: 0.0017746940720826387, acc: 1.0)
[2024-11-13 05:42:39,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:39,875][root][INFO] - Training Epoch: 9/10, step 34/574 completed (loss: 0.17286360263824463, acc: 0.9495798349380493)
[2024-11-13 05:42:39,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:40,218][root][INFO] - Training Epoch: 9/10, step 35/574 completed (loss: 0.0782075971364975, acc: 0.9836065769195557)
[2024-11-13 05:42:40,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:40,563][root][INFO] - Training Epoch: 9/10, step 36/574 completed (loss: 0.0779033899307251, acc: 0.9841269850730896)
[2024-11-13 05:42:40,697][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:40,960][root][INFO] - Training Epoch: 9/10, step 37/574 completed (loss: 0.0780811533331871, acc: 0.9830508232116699)
[2024-11-13 05:42:41,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:41,325][root][INFO] - Training Epoch: 9/10, step 38/574 completed (loss: 0.06794974207878113, acc: 0.9655172228813171)
[2024-11-13 05:42:41,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:41,659][root][INFO] - Training Epoch: 9/10, step 39/574 completed (loss: 0.06437353044748306, acc: 0.9523809552192688)
[2024-11-13 05:42:41,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:41,997][root][INFO] - Training Epoch: 9/10, step 40/574 completed (loss: 0.4558993875980377, acc: 0.9230769276618958)
[2024-11-13 05:42:42,106][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:42,363][root][INFO] - Training Epoch: 9/10, step 41/574 completed (loss: 0.11186008155345917, acc: 0.9729729890823364)
[2024-11-13 05:42:42,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:42,706][root][INFO] - Training Epoch: 9/10, step 42/574 completed (loss: 0.2512596845626831, acc: 0.9230769276618958)
[2024-11-13 05:42:42,811][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:43,118][root][INFO] - Training Epoch: 9/10, step 43/574 completed (loss: 0.1483316421508789, acc: 0.9494949579238892)
[2024-11-13 05:42:43,269][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:43,557][root][INFO] - Training Epoch: 9/10, step 44/574 completed (loss: 0.18396365642547607, acc: 0.938144326210022)
[2024-11-13 05:42:43,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:43,957][root][INFO] - Training Epoch: 9/10, step 45/574 completed (loss: 0.2306281328201294, acc: 0.9264705777168274)
[2024-11-13 05:42:44,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:44,253][root][INFO] - Training Epoch: 9/10, step 46/574 completed (loss: 0.012705051340162754, acc: 1.0)
[2024-11-13 05:42:44,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:44,558][root][INFO] - Training Epoch: 9/10, step 47/574 completed (loss: 0.003394082188606262, acc: 1.0)
[2024-11-13 05:42:44,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:44,875][root][INFO] - Training Epoch: 9/10, step 48/574 completed (loss: 0.016788406297564507, acc: 1.0)
[2024-11-13 05:42:44,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:45,197][root][INFO] - Training Epoch: 9/10, step 49/574 completed (loss: 0.003700236091390252, acc: 1.0)
[2024-11-13 05:42:45,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:45,547][root][INFO] - Training Epoch: 9/10, step 50/574 completed (loss: 0.15637916326522827, acc: 0.9473684430122375)
[2024-11-13 05:42:45,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:45,892][root][INFO] - Training Epoch: 9/10, step 51/574 completed (loss: 0.09785467386245728, acc: 0.9523809552192688)
[2024-11-13 05:42:45,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:46,202][root][INFO] - Training Epoch: 9/10, step 52/574 completed (loss: 0.14484502375125885, acc: 0.9436619877815247)
[2024-11-13 05:42:46,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:46,650][root][INFO] - Training Epoch: 9/10, step 53/574 completed (loss: 0.7042829394340515, acc: 0.7733333110809326)
[2024-11-13 05:42:46,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:47,020][root][INFO] - Training Epoch: 9/10, step 54/574 completed (loss: 0.1643408238887787, acc: 0.9189189076423645)
[2024-11-13 05:42:47,122][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:47,364][root][INFO] - Training Epoch: 9/10, step 55/574 completed (loss: 0.03917107731103897, acc: 0.9615384340286255)
[2024-11-13 05:42:49,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:50,618][root][INFO] - Training Epoch: 9/10, step 56/574 completed (loss: 0.6893603801727295, acc: 0.7815699577331543)
[2024-11-13 05:42:51,156][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:52,018][root][INFO] - Training Epoch: 9/10, step 57/574 completed (loss: 0.9780972003936768, acc: 0.7145969271659851)
[2024-11-13 05:42:52,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:52,638][root][INFO] - Training Epoch: 9/10, step 58/574 completed (loss: 0.5163605809211731, acc: 0.8238636255264282)
[2024-11-13 05:42:52,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:53,209][root][INFO] - Training Epoch: 9/10, step 59/574 completed (loss: 0.17064125835895538, acc: 0.9558823704719543)
[2024-11-13 05:42:53,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:53,795][root][INFO] - Training Epoch: 9/10, step 60/574 completed (loss: 0.3703628182411194, acc: 0.8550724387168884)
[2024-11-13 05:42:53,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:54,210][root][INFO] - Training Epoch: 9/10, step 61/574 completed (loss: 0.29772859811782837, acc: 0.925000011920929)
[2024-11-13 05:42:54,317][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:54,562][root][INFO] - Training Epoch: 9/10, step 62/574 completed (loss: 0.1580216884613037, acc: 0.9411764740943909)
[2024-11-13 05:42:54,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:54,910][root][INFO] - Training Epoch: 9/10, step 63/574 completed (loss: 0.06807597726583481, acc: 0.9722222089767456)
[2024-11-13 05:42:55,010][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:55,257][root][INFO] - Training Epoch: 9/10, step 64/574 completed (loss: 0.2890351414680481, acc: 0.9375)
[2024-11-13 05:42:55,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:55,557][root][INFO] - Training Epoch: 9/10, step 65/574 completed (loss: 0.06772328168153763, acc: 1.0)
[2024-11-13 05:42:55,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:55,926][root][INFO] - Training Epoch: 9/10, step 66/574 completed (loss: 0.13159555196762085, acc: 0.9642857313156128)
[2024-11-13 05:42:56,023][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:56,237][root][INFO] - Training Epoch: 9/10, step 67/574 completed (loss: 0.14316080510616302, acc: 0.9666666388511658)
[2024-11-13 05:42:56,312][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:56,551][root][INFO] - Training Epoch: 9/10, step 68/574 completed (loss: 0.009717097505927086, acc: 1.0)
[2024-11-13 05:42:56,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:56,859][root][INFO] - Training Epoch: 9/10, step 69/574 completed (loss: 0.038736723363399506, acc: 1.0)
[2024-11-13 05:42:56,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:57,161][root][INFO] - Training Epoch: 9/10, step 70/574 completed (loss: 0.09523333609104156, acc: 0.939393937587738)
[2024-11-13 05:42:57,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:57,484][root][INFO] - Training Epoch: 9/10, step 71/574 completed (loss: 0.35193437337875366, acc: 0.904411792755127)
[2024-11-13 05:42:57,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:57,846][root][INFO] - Training Epoch: 9/10, step 72/574 completed (loss: 0.3374515473842621, acc: 0.8888888955116272)
[2024-11-13 05:42:57,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:58,170][root][INFO] - Training Epoch: 9/10, step 73/574 completed (loss: 0.8965979218482971, acc: 0.7692307829856873)
[2024-11-13 05:42:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:58,481][root][INFO] - Training Epoch: 9/10, step 74/574 completed (loss: 0.42526450753211975, acc: 0.8979591727256775)
[2024-11-13 05:42:58,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:58,797][root][INFO] - Training Epoch: 9/10, step 75/574 completed (loss: 0.4738858640193939, acc: 0.858208954334259)
[2024-11-13 05:42:58,891][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:59,188][root][INFO] - Training Epoch: 9/10, step 76/574 completed (loss: 0.9932072758674622, acc: 0.7299270033836365)
[2024-11-13 05:42:59,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:59,520][root][INFO] - Training Epoch: 9/10, step 77/574 completed (loss: 0.07422956824302673, acc: 0.9523809552192688)
[2024-11-13 05:42:59,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:42:59,835][root][INFO] - Training Epoch: 9/10, step 78/574 completed (loss: 0.05426079407334328, acc: 0.9583333134651184)
[2024-11-13 05:42:59,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:00,200][root][INFO] - Training Epoch: 9/10, step 79/574 completed (loss: 0.01897343061864376, acc: 1.0)
[2024-11-13 05:43:00,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:00,543][root][INFO] - Training Epoch: 9/10, step 80/574 completed (loss: 0.005868296604603529, acc: 1.0)
[2024-11-13 05:43:00,648][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:00,899][root][INFO] - Training Epoch: 9/10, step 81/574 completed (loss: 0.09913245588541031, acc: 0.9807692170143127)
[2024-11-13 05:43:00,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:01,182][root][INFO] - Training Epoch: 9/10, step 82/574 completed (loss: 0.08575158566236496, acc: 0.9807692170143127)
[2024-11-13 05:43:01,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:01,542][root][INFO] - Training Epoch: 9/10, step 83/574 completed (loss: 0.06153193116188049, acc: 0.96875)
[2024-11-13 05:43:01,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:01,935][root][INFO] - Training Epoch: 9/10, step 84/574 completed (loss: 0.10569663345813751, acc: 0.9710144996643066)
[2024-11-13 05:43:02,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:02,287][root][INFO] - Training Epoch: 9/10, step 85/574 completed (loss: 0.037745602428913116, acc: 1.0)
[2024-11-13 05:43:02,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:02,592][root][INFO] - Training Epoch: 9/10, step 86/574 completed (loss: 0.09843622148036957, acc: 0.95652174949646)
[2024-11-13 05:43:02,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:03,043][root][INFO] - Training Epoch: 9/10, step 87/574 completed (loss: 0.31690743565559387, acc: 0.8999999761581421)
[2024-11-13 05:43:03,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:03,417][root][INFO] - Training Epoch: 9/10, step 88/574 completed (loss: 0.3551427721977234, acc: 0.9029126167297363)
[2024-11-13 05:43:03,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:04,649][root][INFO] - Training Epoch: 9/10, step 89/574 completed (loss: 0.6091738343238831, acc: 0.8058252334594727)
[2024-11-13 05:43:04,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:05,468][root][INFO] - Training Epoch: 9/10, step 90/574 completed (loss: 0.6169731020927429, acc: 0.8064516186714172)
[2024-11-13 05:43:05,672][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:06,268][root][INFO] - Training Epoch: 9/10, step 91/574 completed (loss: 0.5129007697105408, acc: 0.8448275923728943)
[2024-11-13 05:43:06,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:07,012][root][INFO] - Training Epoch: 9/10, step 92/574 completed (loss: 0.3743898570537567, acc: 0.8947368264198303)
[2024-11-13 05:43:07,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:08,006][root][INFO] - Training Epoch: 9/10, step 93/574 completed (loss: 0.5347753167152405, acc: 0.8415841460227966)
[2024-11-13 05:43:08,093][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:08,341][root][INFO] - Training Epoch: 9/10, step 94/574 completed (loss: 0.3179377615451813, acc: 0.9193548560142517)
[2024-11-13 05:43:08,458][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:08,724][root][INFO] - Training Epoch: 9/10, step 95/574 completed (loss: 0.16987958550453186, acc: 0.9420289993286133)
[2024-11-13 05:43:08,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:09,116][root][INFO] - Training Epoch: 9/10, step 96/574 completed (loss: 0.3541806638240814, acc: 0.8655462265014648)
[2024-11-13 05:43:09,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:09,500][root][INFO] - Training Epoch: 9/10, step 97/574 completed (loss: 0.37014490365982056, acc: 0.875)
[2024-11-13 05:43:09,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:09,865][root][INFO] - Training Epoch: 9/10, step 98/574 completed (loss: 0.49315181374549866, acc: 0.8175182342529297)
[2024-11-13 05:43:09,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:10,210][root][INFO] - Training Epoch: 9/10, step 99/574 completed (loss: 0.3991931676864624, acc: 0.8656716346740723)
[2024-11-13 05:43:10,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:10,581][root][INFO] - Training Epoch: 9/10, step 100/574 completed (loss: 0.07606105506420135, acc: 1.0)
[2024-11-13 05:43:10,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:10,958][root][INFO] - Training Epoch: 9/10, step 101/574 completed (loss: 0.0046607013791799545, acc: 1.0)
[2024-11-13 05:43:11,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:11,331][root][INFO] - Training Epoch: 9/10, step 102/574 completed (loss: 0.014839563518762589, acc: 1.0)
[2024-11-13 05:43:11,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:11,685][root][INFO] - Training Epoch: 9/10, step 103/574 completed (loss: 0.01834171824157238, acc: 1.0)
[2024-11-13 05:43:11,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:12,014][root][INFO] - Training Epoch: 9/10, step 104/574 completed (loss: 0.04719311371445656, acc: 0.982758641242981)
[2024-11-13 05:43:12,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:12,382][root][INFO] - Training Epoch: 9/10, step 105/574 completed (loss: 0.06390603631734848, acc: 0.9767441749572754)
[2024-11-13 05:43:12,483][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:12,712][root][INFO] - Training Epoch: 9/10, step 106/574 completed (loss: 0.00592576852068305, acc: 1.0)
[2024-11-13 05:43:12,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:13,042][root][INFO] - Training Epoch: 9/10, step 107/574 completed (loss: 0.0021230941638350487, acc: 1.0)
[2024-11-13 05:43:13,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:13,349][root][INFO] - Training Epoch: 9/10, step 108/574 completed (loss: 0.0030492483638226986, acc: 1.0)
[2024-11-13 05:43:13,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:13,674][root][INFO] - Training Epoch: 9/10, step 109/574 completed (loss: 0.007488952483981848, acc: 1.0)
[2024-11-13 05:43:13,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:14,071][root][INFO] - Training Epoch: 9/10, step 110/574 completed (loss: 0.02622169442474842, acc: 1.0)
[2024-11-13 05:43:14,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:14,472][root][INFO] - Training Epoch: 9/10, step 111/574 completed (loss: 0.08400982618331909, acc: 0.9649122953414917)
[2024-11-13 05:43:14,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:14,855][root][INFO] - Training Epoch: 9/10, step 112/574 completed (loss: 0.14336097240447998, acc: 0.9473684430122375)
[2024-11-13 05:43:14,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:15,221][root][INFO] - Training Epoch: 9/10, step 113/574 completed (loss: 0.03963548690080643, acc: 1.0)
[2024-11-13 05:43:15,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:15,605][root][INFO] - Training Epoch: 9/10, step 114/574 completed (loss: 0.2568364143371582, acc: 0.9387755393981934)
[2024-11-13 05:43:15,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:15,952][root][INFO] - Training Epoch: 9/10, step 115/574 completed (loss: 0.003095651511102915, acc: 1.0)
[2024-11-13 05:43:16,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:16,288][root][INFO] - Training Epoch: 9/10, step 116/574 completed (loss: 0.1699649542570114, acc: 0.9523809552192688)
[2024-11-13 05:43:16,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:16,661][root][INFO] - Training Epoch: 9/10, step 117/574 completed (loss: 0.15978996455669403, acc: 0.9593495726585388)
[2024-11-13 05:43:16,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:17,013][root][INFO] - Training Epoch: 9/10, step 118/574 completed (loss: 0.029743505641818047, acc: 1.0)
[2024-11-13 05:43:17,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:17,847][root][INFO] - Training Epoch: 9/10, step 119/574 completed (loss: 0.47430723905563354, acc: 0.8897338509559631)
[2024-11-13 05:43:17,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:18,202][root][INFO] - Training Epoch: 9/10, step 120/574 completed (loss: 0.03280510753393173, acc: 0.9866666793823242)
[2024-11-13 05:43:18,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:18,618][root][INFO] - Training Epoch: 9/10, step 121/574 completed (loss: 0.2987412214279175, acc: 0.942307710647583)
[2024-11-13 05:43:18,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:18,961][root][INFO] - Training Epoch: 9/10, step 122/574 completed (loss: 0.03229840472340584, acc: 1.0)
[2024-11-13 05:43:19,050][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:19,331][root][INFO] - Training Epoch: 9/10, step 123/574 completed (loss: 0.5881200432777405, acc: 0.9473684430122375)
[2024-11-13 05:43:19,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:19,722][root][INFO] - Training Epoch: 9/10, step 124/574 completed (loss: 0.24460990726947784, acc: 0.9202454090118408)
[2024-11-13 05:43:19,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:20,160][root][INFO] - Training Epoch: 9/10, step 125/574 completed (loss: 0.5932148098945618, acc: 0.8263888955116272)
[2024-11-13 05:43:20,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:20,531][root][INFO] - Training Epoch: 9/10, step 126/574 completed (loss: 0.4053405821323395, acc: 0.875)
[2024-11-13 05:43:21,396][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:21,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:22,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:22,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:22,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:22,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:23,334][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:23,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:23,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:24,292][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:24,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:24,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:25,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:25,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:25,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:26,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:26,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:26,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:27,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:27,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:28,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:28,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:28,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:29,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:29,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:29,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:30,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:30,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:30,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:31,386][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:31,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:32,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:32,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:32,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:32,978][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:33,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:33,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:34,091][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:34,494][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:34,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:35,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:35,674][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:35,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:36,257][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:36,580][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:36,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:37,252][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:37,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:38,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:38,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:38,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:39,266][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:39,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:39,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:40,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:40,699][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:41,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:41,398][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:41,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:42,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:42,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:42,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:43,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:43,876][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:44,178][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:44,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:44,894][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:45,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:45,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:46,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:46,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:46,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:46,993][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:47,302][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:47,605][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:47,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:48,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:48,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:48,848][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:49,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:49,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:49,941][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:50,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:50,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:51,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:51,855][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.5127, device='cuda:0') eval_epoch_loss=tensor(0.9214, device='cuda:0') eval_epoch_acc=tensor(0.8140, device='cuda:0')
[2024-11-13 05:43:51,856][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:43:51,856][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:43:52,150][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_9_step_127_loss_0.9213563799858093/model.pt
[2024-11-13 05:43:52,154][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:43:52,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:52,538][root][INFO] - Training Epoch: 9/10, step 127/574 completed (loss: 0.36939606070518494, acc: 0.886904776096344)
[2024-11-13 05:43:52,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:52,927][root][INFO] - Training Epoch: 9/10, step 128/574 completed (loss: 0.35174521803855896, acc: 0.8769230842590332)
[2024-11-13 05:43:53,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:53,348][root][INFO] - Training Epoch: 9/10, step 129/574 completed (loss: 0.4352797865867615, acc: 0.8529411554336548)
[2024-11-13 05:43:53,461][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:53,705][root][INFO] - Training Epoch: 9/10, step 130/574 completed (loss: 0.20753619074821472, acc: 0.9230769276618958)
[2024-11-13 05:43:53,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:54,012][root][INFO] - Training Epoch: 9/10, step 131/574 completed (loss: 0.07809025049209595, acc: 0.95652174949646)
[2024-11-13 05:43:54,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:54,325][root][INFO] - Training Epoch: 9/10, step 132/574 completed (loss: 0.1502443253993988, acc: 0.9375)
[2024-11-13 05:43:54,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:54,683][root][INFO] - Training Epoch: 9/10, step 133/574 completed (loss: 0.3713783919811249, acc: 0.9130434989929199)
[2024-11-13 05:43:54,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:55,068][root][INFO] - Training Epoch: 9/10, step 134/574 completed (loss: 0.05418220907449722, acc: 0.9714285731315613)
[2024-11-13 05:43:55,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:55,413][root][INFO] - Training Epoch: 9/10, step 135/574 completed (loss: 0.12948757410049438, acc: 0.9615384340286255)
[2024-11-13 05:43:55,510][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:55,739][root][INFO] - Training Epoch: 9/10, step 136/574 completed (loss: 0.1359812617301941, acc: 0.976190447807312)
[2024-11-13 05:43:55,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:56,096][root][INFO] - Training Epoch: 9/10, step 137/574 completed (loss: 0.19699051976203918, acc: 0.9666666388511658)
[2024-11-13 05:43:56,195][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:56,435][root][INFO] - Training Epoch: 9/10, step 138/574 completed (loss: 0.01254416722804308, acc: 1.0)
[2024-11-13 05:43:56,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:56,795][root][INFO] - Training Epoch: 9/10, step 139/574 completed (loss: 0.03897375613451004, acc: 1.0)
[2024-11-13 05:43:56,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:57,167][root][INFO] - Training Epoch: 9/10, step 140/574 completed (loss: 0.040338460355997086, acc: 1.0)
[2024-11-13 05:43:57,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:57,485][root][INFO] - Training Epoch: 9/10, step 141/574 completed (loss: 0.05589936673641205, acc: 1.0)
[2024-11-13 05:43:57,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:57,837][root][INFO] - Training Epoch: 9/10, step 142/574 completed (loss: 0.19287721812725067, acc: 0.9729729890823364)
[2024-11-13 05:43:58,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:58,409][root][INFO] - Training Epoch: 9/10, step 143/574 completed (loss: 0.2746185064315796, acc: 0.8947368264198303)
[2024-11-13 05:43:58,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:58,747][root][INFO] - Training Epoch: 9/10, step 144/574 completed (loss: 0.46832510828971863, acc: 0.8507462739944458)
[2024-11-13 05:43:58,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:59,137][root][INFO] - Training Epoch: 9/10, step 145/574 completed (loss: 0.27149465680122375, acc: 0.9081632494926453)
[2024-11-13 05:43:59,304][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:59,584][root][INFO] - Training Epoch: 9/10, step 146/574 completed (loss: 0.3735102415084839, acc: 0.8617021441459656)
[2024-11-13 05:43:59,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:43:59,911][root][INFO] - Training Epoch: 9/10, step 147/574 completed (loss: 0.15303058922290802, acc: 0.9571428298950195)
[2024-11-13 05:44:00,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:00,277][root][INFO] - Training Epoch: 9/10, step 148/574 completed (loss: 0.05627065524458885, acc: 1.0)
[2024-11-13 05:44:00,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:00,612][root][INFO] - Training Epoch: 9/10, step 149/574 completed (loss: 0.359332799911499, acc: 0.9130434989929199)
[2024-11-13 05:44:00,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:00,917][root][INFO] - Training Epoch: 9/10, step 150/574 completed (loss: 0.09881308674812317, acc: 0.9655172228813171)
[2024-11-13 05:44:01,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:01,237][root][INFO] - Training Epoch: 9/10, step 151/574 completed (loss: 0.09304997324943542, acc: 0.97826087474823)
[2024-11-13 05:44:01,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:01,587][root][INFO] - Training Epoch: 9/10, step 152/574 completed (loss: 0.2769131064414978, acc: 0.9661017060279846)
[2024-11-13 05:44:01,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:01,930][root][INFO] - Training Epoch: 9/10, step 153/574 completed (loss: 0.19736428558826447, acc: 0.9473684430122375)
[2024-11-13 05:44:02,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:02,253][root][INFO] - Training Epoch: 9/10, step 154/574 completed (loss: 0.45170295238494873, acc: 0.9054054021835327)
[2024-11-13 05:44:02,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:02,596][root][INFO] - Training Epoch: 9/10, step 155/574 completed (loss: 0.10688977688550949, acc: 0.9642857313156128)
[2024-11-13 05:44:02,679][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:02,945][root][INFO] - Training Epoch: 9/10, step 156/574 completed (loss: 0.004780725110322237, acc: 1.0)
[2024-11-13 05:44:03,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:03,320][root][INFO] - Training Epoch: 9/10, step 157/574 completed (loss: 0.23138327896595, acc: 0.8947368264198303)
[2024-11-13 05:44:04,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:05,072][root][INFO] - Training Epoch: 9/10, step 158/574 completed (loss: 0.32740703225135803, acc: 0.8918918967247009)
[2024-11-13 05:44:05,150][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:05,397][root][INFO] - Training Epoch: 9/10, step 159/574 completed (loss: 0.6613049507141113, acc: 0.8148148059844971)
[2024-11-13 05:44:05,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:05,797][root][INFO] - Training Epoch: 9/10, step 160/574 completed (loss: 0.46238207817077637, acc: 0.8372092843055725)
[2024-11-13 05:44:05,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:06,381][root][INFO] - Training Epoch: 9/10, step 161/574 completed (loss: 0.2647755444049835, acc: 0.9411764740943909)
[2024-11-13 05:44:06,513][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:06,936][root][INFO] - Training Epoch: 9/10, step 162/574 completed (loss: 0.46339207887649536, acc: 0.8876404762268066)
[2024-11-13 05:44:07,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:07,263][root][INFO] - Training Epoch: 9/10, step 163/574 completed (loss: 0.18680697679519653, acc: 0.9545454382896423)
[2024-11-13 05:44:07,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:07,578][root][INFO] - Training Epoch: 9/10, step 164/574 completed (loss: 0.22719556093215942, acc: 0.9047619104385376)
[2024-11-13 05:44:07,661][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:07,914][root][INFO] - Training Epoch: 9/10, step 165/574 completed (loss: 0.33840394020080566, acc: 0.8965517282485962)
[2024-11-13 05:44:08,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:08,280][root][INFO] - Training Epoch: 9/10, step 166/574 completed (loss: 0.022624943405389786, acc: 1.0)
[2024-11-13 05:44:08,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:08,627][root][INFO] - Training Epoch: 9/10, step 167/574 completed (loss: 0.356379896402359, acc: 0.9399999976158142)
[2024-11-13 05:44:08,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:09,084][root][INFO] - Training Epoch: 9/10, step 168/574 completed (loss: 0.26818281412124634, acc: 0.9305555820465088)
[2024-11-13 05:44:09,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:09,458][root][INFO] - Training Epoch: 9/10, step 169/574 completed (loss: 0.7968924045562744, acc: 0.7941176295280457)
[2024-11-13 05:44:09,832][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:10,593][root][INFO] - Training Epoch: 9/10, step 170/574 completed (loss: 0.4169459939002991, acc: 0.8904109597206116)
[2024-11-13 05:44:10,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:10,910][root][INFO] - Training Epoch: 9/10, step 171/574 completed (loss: 0.2031370997428894, acc: 0.9583333134651184)
[2024-11-13 05:44:10,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:11,266][root][INFO] - Training Epoch: 9/10, step 172/574 completed (loss: 0.06767517328262329, acc: 1.0)
[2024-11-13 05:44:11,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:11,659][root][INFO] - Training Epoch: 9/10, step 173/574 completed (loss: 0.027285335585474968, acc: 1.0)
[2024-11-13 05:44:11,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:12,231][root][INFO] - Training Epoch: 9/10, step 174/574 completed (loss: 0.41946864128112793, acc: 0.8584070801734924)
[2024-11-13 05:44:12,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:12,584][root][INFO] - Training Epoch: 9/10, step 175/574 completed (loss: 0.2880840599536896, acc: 0.9130434989929199)
[2024-11-13 05:44:12,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:12,964][root][INFO] - Training Epoch: 9/10, step 176/574 completed (loss: 0.15892630815505981, acc: 0.9545454382896423)
[2024-11-13 05:44:13,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:13,904][root][INFO] - Training Epoch: 9/10, step 177/574 completed (loss: 0.609550416469574, acc: 0.8396946787834167)
[2024-11-13 05:44:14,071][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:14,574][root][INFO] - Training Epoch: 9/10, step 178/574 completed (loss: 0.4549986720085144, acc: 0.8296296000480652)
[2024-11-13 05:44:14,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:14,918][root][INFO] - Training Epoch: 9/10, step 179/574 completed (loss: 0.07466309517621994, acc: 0.9672130942344666)
[2024-11-13 05:44:15,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:15,270][root][INFO] - Training Epoch: 9/10, step 180/574 completed (loss: 0.003528914414346218, acc: 1.0)
[2024-11-13 05:44:15,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:15,634][root][INFO] - Training Epoch: 9/10, step 181/574 completed (loss: 0.018339205533266068, acc: 1.0)
[2024-11-13 05:44:15,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:15,919][root][INFO] - Training Epoch: 9/10, step 182/574 completed (loss: 0.03618773818016052, acc: 1.0)
[2024-11-13 05:44:15,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:16,227][root][INFO] - Training Epoch: 9/10, step 183/574 completed (loss: 0.14385724067687988, acc: 0.9390243887901306)
[2024-11-13 05:44:16,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:16,610][root][INFO] - Training Epoch: 9/10, step 184/574 completed (loss: 0.3502286970615387, acc: 0.903323233127594)
[2024-11-13 05:44:16,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:17,022][root][INFO] - Training Epoch: 9/10, step 185/574 completed (loss: 0.41014692187309265, acc: 0.8645533323287964)
[2024-11-13 05:44:17,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:17,510][root][INFO] - Training Epoch: 9/10, step 186/574 completed (loss: 0.38913556933403015, acc: 0.871874988079071)
[2024-11-13 05:44:17,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:18,122][root][INFO] - Training Epoch: 9/10, step 187/574 completed (loss: 0.5224079489707947, acc: 0.8386491537094116)
[2024-11-13 05:44:18,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:18,547][root][INFO] - Training Epoch: 9/10, step 188/574 completed (loss: 0.33660808205604553, acc: 0.918149471282959)
[2024-11-13 05:44:18,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:18,897][root][INFO] - Training Epoch: 9/10, step 189/574 completed (loss: 0.16380856931209564, acc: 0.9599999785423279)
[2024-11-13 05:44:19,086][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:19,505][root][INFO] - Training Epoch: 9/10, step 190/574 completed (loss: 0.4097687005996704, acc: 0.8720930218696594)
[2024-11-13 05:44:19,778][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:20,361][root][INFO] - Training Epoch: 9/10, step 191/574 completed (loss: 0.6286017298698425, acc: 0.817460298538208)
[2024-11-13 05:44:20,621][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:21,280][root][INFO] - Training Epoch: 9/10, step 192/574 completed (loss: 0.45064830780029297, acc: 0.8257575631141663)
[2024-11-13 05:44:21,526][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:22,066][root][INFO] - Training Epoch: 9/10, step 193/574 completed (loss: 0.247639000415802, acc: 0.929411768913269)
[2024-11-13 05:44:22,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:23,155][root][INFO] - Training Epoch: 9/10, step 194/574 completed (loss: 0.440198689699173, acc: 0.8703703880310059)
[2024-11-13 05:44:23,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:24,105][root][INFO] - Training Epoch: 9/10, step 195/574 completed (loss: 0.10679619759321213, acc: 0.9677419066429138)
[2024-11-13 05:44:24,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:24,446][root][INFO] - Training Epoch: 9/10, step 196/574 completed (loss: 0.02253475785255432, acc: 1.0)
[2024-11-13 05:44:24,541][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:24,711][root][INFO] - Training Epoch: 9/10, step 197/574 completed (loss: 0.08462756872177124, acc: 0.9750000238418579)
[2024-11-13 05:44:24,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:25,063][root][INFO] - Training Epoch: 9/10, step 198/574 completed (loss: 0.1149662435054779, acc: 0.9558823704719543)
[2024-11-13 05:44:25,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:25,415][root][INFO] - Training Epoch: 9/10, step 199/574 completed (loss: 0.34378987550735474, acc: 0.8970588445663452)
[2024-11-13 05:44:25,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:25,807][root][INFO] - Training Epoch: 9/10, step 200/574 completed (loss: 0.35233214497566223, acc: 0.8898305296897888)
[2024-11-13 05:44:25,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:26,164][root][INFO] - Training Epoch: 9/10, step 201/574 completed (loss: 0.21266041696071625, acc: 0.9179104566574097)
[2024-11-13 05:44:26,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:26,551][root][INFO] - Training Epoch: 9/10, step 202/574 completed (loss: 0.23678873479366302, acc: 0.9223300814628601)
[2024-11-13 05:44:26,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:26,894][root][INFO] - Training Epoch: 9/10, step 203/574 completed (loss: 0.17575600743293762, acc: 0.9523809552192688)
[2024-11-13 05:44:26,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:27,179][root][INFO] - Training Epoch: 9/10, step 204/574 completed (loss: 0.10582949966192245, acc: 0.9670329689979553)
[2024-11-13 05:44:27,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:27,553][root][INFO] - Training Epoch: 9/10, step 205/574 completed (loss: 0.1503617912530899, acc: 0.9461883306503296)
[2024-11-13 05:44:27,653][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:27,945][root][INFO] - Training Epoch: 9/10, step 206/574 completed (loss: 0.23080727458000183, acc: 0.9330708384513855)
[2024-11-13 05:44:28,038][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:28,293][root][INFO] - Training Epoch: 9/10, step 207/574 completed (loss: 0.1779215931892395, acc: 0.9525862336158752)
[2024-11-13 05:44:28,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:28,681][root][INFO] - Training Epoch: 9/10, step 208/574 completed (loss: 0.23161153495311737, acc: 0.9239130616188049)
[2024-11-13 05:44:28,804][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:29,060][root][INFO] - Training Epoch: 9/10, step 209/574 completed (loss: 0.1447434425354004, acc: 0.9533073902130127)
[2024-11-13 05:44:29,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:29,388][root][INFO] - Training Epoch: 9/10, step 210/574 completed (loss: 0.057753827422857285, acc: 0.989130437374115)
[2024-11-13 05:44:29,470][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:29,706][root][INFO] - Training Epoch: 9/10, step 211/574 completed (loss: 0.09326992928981781, acc: 0.95652174949646)
[2024-11-13 05:44:29,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:30,081][root][INFO] - Training Epoch: 9/10, step 212/574 completed (loss: 0.01654415763914585, acc: 1.0)
[2024-11-13 05:44:30,216][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:30,483][root][INFO] - Training Epoch: 9/10, step 213/574 completed (loss: 0.06353631615638733, acc: 0.978723406791687)
[2024-11-13 05:44:30,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:31,211][root][INFO] - Training Epoch: 9/10, step 214/574 completed (loss: 0.07977963984012604, acc: 0.9846153855323792)
[2024-11-13 05:44:31,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:31,571][root][INFO] - Training Epoch: 9/10, step 215/574 completed (loss: 0.015007412061095238, acc: 1.0)
[2024-11-13 05:44:31,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:31,914][root][INFO] - Training Epoch: 9/10, step 216/574 completed (loss: 0.041227810084819794, acc: 0.9767441749572754)
[2024-11-13 05:44:32,074][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:32,445][root][INFO] - Training Epoch: 9/10, step 217/574 completed (loss: 0.029232317581772804, acc: 0.9909909963607788)
[2024-11-13 05:44:32,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:32,856][root][INFO] - Training Epoch: 9/10, step 218/574 completed (loss: 0.047655560076236725, acc: 0.9888888597488403)
[2024-11-13 05:44:32,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:33,206][root][INFO] - Training Epoch: 9/10, step 219/574 completed (loss: 0.015956426039338112, acc: 1.0)
[2024-11-13 05:44:33,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:33,487][root][INFO] - Training Epoch: 9/10, step 220/574 completed (loss: 0.006897679530084133, acc: 1.0)
[2024-11-13 05:44:33,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:33,813][root][INFO] - Training Epoch: 9/10, step 221/574 completed (loss: 0.017403461039066315, acc: 1.0)
[2024-11-13 05:44:33,913][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:34,148][root][INFO] - Training Epoch: 9/10, step 222/574 completed (loss: 0.22870144248008728, acc: 0.9230769276618958)
[2024-11-13 05:44:34,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:34,975][root][INFO] - Training Epoch: 9/10, step 223/574 completed (loss: 0.2657802700996399, acc: 0.907608687877655)
[2024-11-13 05:44:35,099][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:35,518][root][INFO] - Training Epoch: 9/10, step 224/574 completed (loss: 0.3431278467178345, acc: 0.9147727489471436)
[2024-11-13 05:44:35,646][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:35,969][root][INFO] - Training Epoch: 9/10, step 225/574 completed (loss: 0.5430186986923218, acc: 0.8617021441459656)
[2024-11-13 05:44:36,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:36,315][root][INFO] - Training Epoch: 9/10, step 226/574 completed (loss: 0.08462387323379517, acc: 0.9811320900917053)
[2024-11-13 05:44:36,413][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:36,658][root][INFO] - Training Epoch: 9/10, step 227/574 completed (loss: 0.12205816060304642, acc: 0.9666666388511658)
[2024-11-13 05:44:36,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:37,058][root][INFO] - Training Epoch: 9/10, step 228/574 completed (loss: 0.04603128880262375, acc: 0.9767441749572754)
[2024-11-13 05:44:37,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:37,400][root][INFO] - Training Epoch: 9/10, step 229/574 completed (loss: 0.12998494505882263, acc: 1.0)
[2024-11-13 05:44:37,553][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:37,823][root][INFO] - Training Epoch: 9/10, step 230/574 completed (loss: 0.870267391204834, acc: 0.7368420958518982)
[2024-11-13 05:44:37,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:38,235][root][INFO] - Training Epoch: 9/10, step 231/574 completed (loss: 0.5450329184532166, acc: 0.8333333134651184)
[2024-11-13 05:44:38,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:38,685][root][INFO] - Training Epoch: 9/10, step 232/574 completed (loss: 0.7288386821746826, acc: 0.75)
[2024-11-13 05:44:38,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:39,176][root][INFO] - Training Epoch: 9/10, step 233/574 completed (loss: 1.1707637310028076, acc: 0.6743119359016418)
[2024-11-13 05:44:39,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:39,636][root][INFO] - Training Epoch: 9/10, step 234/574 completed (loss: 0.5613301992416382, acc: 0.8230769038200378)
[2024-11-13 05:44:39,707][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:39,933][root][INFO] - Training Epoch: 9/10, step 235/574 completed (loss: 0.05188215896487236, acc: 0.9473684430122375)
[2024-11-13 05:44:40,018][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:40,252][root][INFO] - Training Epoch: 9/10, step 236/574 completed (loss: 0.014370557852089405, acc: 1.0)
[2024-11-13 05:44:40,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:40,649][root][INFO] - Training Epoch: 9/10, step 237/574 completed (loss: 0.0792643129825592, acc: 1.0)
[2024-11-13 05:44:40,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:41,021][root][INFO] - Training Epoch: 9/10, step 238/574 completed (loss: 0.143906369805336, acc: 0.9629629850387573)
[2024-11-13 05:44:41,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:41,364][root][INFO] - Training Epoch: 9/10, step 239/574 completed (loss: 0.3261492848396301, acc: 0.9428571462631226)
[2024-11-13 05:44:41,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:41,740][root][INFO] - Training Epoch: 9/10, step 240/574 completed (loss: 0.18931061029434204, acc: 0.9090909361839294)
[2024-11-13 05:44:41,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:42,105][root][INFO] - Training Epoch: 9/10, step 241/574 completed (loss: 0.1303553432226181, acc: 0.9772727489471436)
[2024-11-13 05:44:42,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:42,694][root][INFO] - Training Epoch: 9/10, step 242/574 completed (loss: 0.35395464301109314, acc: 0.8709677457809448)
[2024-11-13 05:44:42,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:43,224][root][INFO] - Training Epoch: 9/10, step 243/574 completed (loss: 0.22796306014060974, acc: 0.9318181872367859)
[2024-11-13 05:44:43,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:43,584][root][INFO] - Training Epoch: 9/10, step 244/574 completed (loss: 0.0006104870699346066, acc: 1.0)
[2024-11-13 05:44:43,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:43,916][root][INFO] - Training Epoch: 9/10, step 245/574 completed (loss: 0.17497922480106354, acc: 0.9230769276618958)
[2024-11-13 05:44:44,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:44,223][root][INFO] - Training Epoch: 9/10, step 246/574 completed (loss: 0.11769334971904755, acc: 0.9354838728904724)
[2024-11-13 05:44:44,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:44,570][root][INFO] - Training Epoch: 9/10, step 247/574 completed (loss: 0.012841734103858471, acc: 1.0)
[2024-11-13 05:44:44,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:44,935][root][INFO] - Training Epoch: 9/10, step 248/574 completed (loss: 0.07841284573078156, acc: 0.9459459185600281)
[2024-11-13 05:44:45,007][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:45,205][root][INFO] - Training Epoch: 9/10, step 249/574 completed (loss: 0.043136116117239, acc: 1.0)
[2024-11-13 05:44:45,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:45,550][root][INFO] - Training Epoch: 9/10, step 250/574 completed (loss: 0.036037977784872055, acc: 0.9729729890823364)
[2024-11-13 05:44:45,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:45,923][root][INFO] - Training Epoch: 9/10, step 251/574 completed (loss: 0.03123500756919384, acc: 1.0)
[2024-11-13 05:44:46,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:46,249][root][INFO] - Training Epoch: 9/10, step 252/574 completed (loss: 0.02370034158229828, acc: 1.0)
[2024-11-13 05:44:46,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:46,539][root][INFO] - Training Epoch: 9/10, step 253/574 completed (loss: 0.1006832867860794, acc: 0.9599999785423279)
[2024-11-13 05:44:46,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:46,909][root][INFO] - Training Epoch: 9/10, step 254/574 completed (loss: 0.0024382611736655235, acc: 1.0)
[2024-11-13 05:44:47,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:47,287][root][INFO] - Training Epoch: 9/10, step 255/574 completed (loss: 0.02194647118449211, acc: 1.0)
[2024-11-13 05:44:47,404][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:47,657][root][INFO] - Training Epoch: 9/10, step 256/574 completed (loss: 0.008101061917841434, acc: 1.0)
[2024-11-13 05:44:47,761][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:48,009][root][INFO] - Training Epoch: 9/10, step 257/574 completed (loss: 0.1523800492286682, acc: 0.9571428298950195)
[2024-11-13 05:44:48,120][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:48,346][root][INFO] - Training Epoch: 9/10, step 258/574 completed (loss: 0.056077927350997925, acc: 0.9868420958518982)
[2024-11-13 05:44:48,501][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:48,926][root][INFO] - Training Epoch: 9/10, step 259/574 completed (loss: 0.21614201366901398, acc: 0.9245283007621765)
[2024-11-13 05:44:49,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:49,518][root][INFO] - Training Epoch: 9/10, step 260/574 completed (loss: 0.1225251853466034, acc: 0.949999988079071)
[2024-11-13 05:44:49,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:49,902][root][INFO] - Training Epoch: 9/10, step 261/574 completed (loss: 0.007363317534327507, acc: 1.0)
[2024-11-13 05:44:50,011][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:50,266][root][INFO] - Training Epoch: 9/10, step 262/574 completed (loss: 0.026591232046484947, acc: 1.0)
[2024-11-13 05:44:50,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:50,642][root][INFO] - Training Epoch: 9/10, step 263/574 completed (loss: 0.2464786320924759, acc: 0.9200000166893005)
[2024-11-13 05:44:50,763][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:51,013][root][INFO] - Training Epoch: 9/10, step 264/574 completed (loss: 0.19533048570156097, acc: 0.9166666865348816)
[2024-11-13 05:44:51,303][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:51,922][root][INFO] - Training Epoch: 9/10, step 265/574 completed (loss: 0.4830518662929535, acc: 0.8240000009536743)
[2024-11-13 05:44:52,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:52,311][root][INFO] - Training Epoch: 9/10, step 266/574 completed (loss: 0.5622705817222595, acc: 0.8314606547355652)
[2024-11-13 05:44:52,459][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:52,703][root][INFO] - Training Epoch: 9/10, step 267/574 completed (loss: 0.23824946582317352, acc: 0.9054054021835327)
[2024-11-13 05:44:52,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:53,167][root][INFO] - Training Epoch: 9/10, step 268/574 completed (loss: 0.16610784828662872, acc: 0.9482758641242981)
[2024-11-13 05:44:53,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:53,471][root][INFO] - Training Epoch: 9/10, step 269/574 completed (loss: 0.006058445665985346, acc: 1.0)
[2024-11-13 05:44:54,168][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:54,523][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:54,867][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:55,115][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:55,405][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:55,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:55,995][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:56,375][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:56,779][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:57,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:57,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:57,961][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:58,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:58,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:59,059][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:59,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:44:59,730][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:00,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:00,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:00,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:01,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:01,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:01,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:01,974][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:02,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:02,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:03,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:03,515][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:03,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:04,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:04,430][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:04,759][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:05,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:05,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:05,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:06,092][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:06,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:06,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:07,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:07,522][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:07,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:08,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:08,431][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:08,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:09,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:09,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:09,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:10,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:10,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:10,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:11,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:11,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:11,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:12,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:12,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:12,968][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:13,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:13,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:13,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:14,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:14,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:15,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:15,591][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:15,980][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:16,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:16,644][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:16,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:17,344][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:17,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:18,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:18,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:18,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:19,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:19,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:19,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:20,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:20,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:20,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:21,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:21,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:21,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:22,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:22,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:22,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:23,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:23,887][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.4388, device='cuda:0') eval_epoch_loss=tensor(0.8915, device='cuda:0') eval_epoch_acc=tensor(0.8165, device='cuda:0')
[2024-11-13 05:45:23,888][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:45:23,888][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:45:24,157][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_9_step_270_loss_0.8915184736251831/model.pt
[2024-11-13 05:45:24,161][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:45:24,162][slam_llm.utils.train_utils][INFO] - best eval acc on epoch 9 is 0.8165109157562256
[2024-11-13 05:45:24,242][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:24,507][root][INFO] - Training Epoch: 9/10, step 270/574 completed (loss: 0.009570185095071793, acc: 1.0)
[2024-11-13 05:45:24,623][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:24,855][root][INFO] - Training Epoch: 9/10, step 271/574 completed (loss: 0.006609147880226374, acc: 1.0)
[2024-11-13 05:45:24,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:25,155][root][INFO] - Training Epoch: 9/10, step 272/574 completed (loss: 0.002927277470007539, acc: 1.0)
[2024-11-13 05:45:25,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:25,541][root][INFO] - Training Epoch: 9/10, step 273/574 completed (loss: 0.11258677393198013, acc: 0.9666666388511658)
[2024-11-13 05:45:25,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:25,869][root][INFO] - Training Epoch: 9/10, step 274/574 completed (loss: 0.060330476611852646, acc: 0.96875)
[2024-11-13 05:45:25,963][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:26,194][root][INFO] - Training Epoch: 9/10, step 275/574 completed (loss: 0.003728728275746107, acc: 1.0)
[2024-11-13 05:45:26,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:26,505][root][INFO] - Training Epoch: 9/10, step 276/574 completed (loss: 0.26070642471313477, acc: 0.9655172228813171)
[2024-11-13 05:45:26,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:26,861][root][INFO] - Training Epoch: 9/10, step 277/574 completed (loss: 0.0822916328907013, acc: 0.9599999785423279)
[2024-11-13 05:45:26,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:27,191][root][INFO] - Training Epoch: 9/10, step 278/574 completed (loss: 0.03307757154107094, acc: 1.0)
[2024-11-13 05:45:27,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:27,542][root][INFO] - Training Epoch: 9/10, step 279/574 completed (loss: 0.15424613654613495, acc: 0.9583333134651184)
[2024-11-13 05:45:27,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:27,850][root][INFO] - Training Epoch: 9/10, step 280/574 completed (loss: 0.025398971512913704, acc: 1.0)
[2024-11-13 05:45:27,958][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:28,271][root][INFO] - Training Epoch: 9/10, step 281/574 completed (loss: 0.1846703290939331, acc: 0.9397590160369873)
[2024-11-13 05:45:28,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:28,632][root][INFO] - Training Epoch: 9/10, step 282/574 completed (loss: 0.3788391351699829, acc: 0.8981481194496155)
[2024-11-13 05:45:28,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:28,997][root][INFO] - Training Epoch: 9/10, step 283/574 completed (loss: 0.11346107721328735, acc: 0.9473684430122375)
[2024-11-13 05:45:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:29,295][root][INFO] - Training Epoch: 9/10, step 284/574 completed (loss: 0.1119627133011818, acc: 0.970588207244873)
[2024-11-13 05:45:29,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:29,626][root][INFO] - Training Epoch: 9/10, step 285/574 completed (loss: 0.10483869165182114, acc: 0.949999988079071)
[2024-11-13 05:45:29,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:29,932][root][INFO] - Training Epoch: 9/10, step 286/574 completed (loss: 0.17620119452476501, acc: 0.9609375)
[2024-11-13 05:45:30,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:30,328][root][INFO] - Training Epoch: 9/10, step 287/574 completed (loss: 0.18083061277866364, acc: 0.9520000219345093)
[2024-11-13 05:45:30,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:30,683][root][INFO] - Training Epoch: 9/10, step 288/574 completed (loss: 0.06585028767585754, acc: 0.9780219793319702)
[2024-11-13 05:45:30,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:31,008][root][INFO] - Training Epoch: 9/10, step 289/574 completed (loss: 0.1146700456738472, acc: 0.9813664555549622)
[2024-11-13 05:45:31,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:31,366][root][INFO] - Training Epoch: 9/10, step 290/574 completed (loss: 0.2849705219268799, acc: 0.907216489315033)
[2024-11-13 05:45:31,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:31,687][root][INFO] - Training Epoch: 9/10, step 291/574 completed (loss: 0.0016687993193045259, acc: 1.0)
[2024-11-13 05:45:31,805][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:32,070][root][INFO] - Training Epoch: 9/10, step 292/574 completed (loss: 0.05950523167848587, acc: 0.976190447807312)
[2024-11-13 05:45:32,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:32,422][root][INFO] - Training Epoch: 9/10, step 293/574 completed (loss: 0.08183734863996506, acc: 0.9655172228813171)
[2024-11-13 05:45:32,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:32,888][root][INFO] - Training Epoch: 9/10, step 294/574 completed (loss: 0.2006436437368393, acc: 0.9454545378684998)
[2024-11-13 05:45:33,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:33,452][root][INFO] - Training Epoch: 9/10, step 295/574 completed (loss: 0.4362066090106964, acc: 0.876288652420044)
[2024-11-13 05:45:33,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:33,737][root][INFO] - Training Epoch: 9/10, step 296/574 completed (loss: 0.05518266186118126, acc: 1.0)
[2024-11-13 05:45:33,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:34,118][root][INFO] - Training Epoch: 9/10, step 297/574 completed (loss: 0.006569769699126482, acc: 1.0)
[2024-11-13 05:45:34,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:34,451][root][INFO] - Training Epoch: 9/10, step 298/574 completed (loss: 0.01795039512217045, acc: 1.0)
[2024-11-13 05:45:34,536][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:34,762][root][INFO] - Training Epoch: 9/10, step 299/574 completed (loss: 0.027914663776755333, acc: 1.0)
[2024-11-13 05:45:34,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:35,052][root][INFO] - Training Epoch: 9/10, step 300/574 completed (loss: 0.0013573229080066085, acc: 1.0)
[2024-11-13 05:45:35,135][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:35,357][root][INFO] - Training Epoch: 9/10, step 301/574 completed (loss: 0.01330776046961546, acc: 1.0)
[2024-11-13 05:45:35,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:35,663][root][INFO] - Training Epoch: 9/10, step 302/574 completed (loss: 0.005998021457344294, acc: 1.0)
[2024-11-13 05:45:35,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:36,015][root][INFO] - Training Epoch: 9/10, step 303/574 completed (loss: 0.005652709864079952, acc: 1.0)
[2024-11-13 05:45:36,108][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:36,331][root][INFO] - Training Epoch: 9/10, step 304/574 completed (loss: 0.0039012839552015066, acc: 1.0)
[2024-11-13 05:45:36,423][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:36,658][root][INFO] - Training Epoch: 9/10, step 305/574 completed (loss: 0.052063826471567154, acc: 0.9836065769195557)
[2024-11-13 05:45:36,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:36,981][root][INFO] - Training Epoch: 9/10, step 306/574 completed (loss: 0.004087408073246479, acc: 1.0)
[2024-11-13 05:45:37,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:37,283][root][INFO] - Training Epoch: 9/10, step 307/574 completed (loss: 0.02632371336221695, acc: 1.0)
[2024-11-13 05:45:37,372][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:37,573][root][INFO] - Training Epoch: 9/10, step 308/574 completed (loss: 0.02671722136437893, acc: 0.9855072498321533)
[2024-11-13 05:45:37,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:37,995][root][INFO] - Training Epoch: 9/10, step 309/574 completed (loss: 0.01612916961312294, acc: 1.0)
[2024-11-13 05:45:38,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:38,298][root][INFO] - Training Epoch: 9/10, step 310/574 completed (loss: 0.13152283430099487, acc: 0.9759036302566528)
[2024-11-13 05:45:38,378][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:38,606][root][INFO] - Training Epoch: 9/10, step 311/574 completed (loss: 0.06454476714134216, acc: 0.9871794581413269)
[2024-11-13 05:45:38,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:38,963][root][INFO] - Training Epoch: 9/10, step 312/574 completed (loss: 0.09361845254898071, acc: 0.9693877696990967)
[2024-11-13 05:45:39,040][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:39,261][root][INFO] - Training Epoch: 9/10, step 313/574 completed (loss: 0.0033910954371094704, acc: 1.0)
[2024-11-13 05:45:39,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:39,615][root][INFO] - Training Epoch: 9/10, step 314/574 completed (loss: 0.04190746322274208, acc: 0.9583333134651184)
[2024-11-13 05:45:39,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:39,954][root][INFO] - Training Epoch: 9/10, step 315/574 completed (loss: 0.02122880332171917, acc: 1.0)
[2024-11-13 05:45:40,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:40,334][root][INFO] - Training Epoch: 9/10, step 316/574 completed (loss: 0.12079048156738281, acc: 0.9677419066429138)
[2024-11-13 05:45:40,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:40,685][root][INFO] - Training Epoch: 9/10, step 317/574 completed (loss: 0.08856596052646637, acc: 0.9701492786407471)
[2024-11-13 05:45:40,809][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:41,043][root][INFO] - Training Epoch: 9/10, step 318/574 completed (loss: 0.02107476256787777, acc: 1.0)
[2024-11-13 05:45:41,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:41,356][root][INFO] - Training Epoch: 9/10, step 319/574 completed (loss: 0.05592016503214836, acc: 0.9777777791023254)
[2024-11-13 05:45:41,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:41,654][root][INFO] - Training Epoch: 9/10, step 320/574 completed (loss: 0.032553400844335556, acc: 0.9838709831237793)
[2024-11-13 05:45:41,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:41,958][root][INFO] - Training Epoch: 9/10, step 321/574 completed (loss: 0.006426811683923006, acc: 1.0)
[2024-11-13 05:45:42,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:42,259][root][INFO] - Training Epoch: 9/10, step 322/574 completed (loss: 0.07804474234580994, acc: 0.9629629850387573)
[2024-11-13 05:45:42,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:42,577][root][INFO] - Training Epoch: 9/10, step 323/574 completed (loss: 0.12026116251945496, acc: 1.0)
[2024-11-13 05:45:42,659][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:42,879][root][INFO] - Training Epoch: 9/10, step 324/574 completed (loss: 0.0839025154709816, acc: 0.9743589758872986)
[2024-11-13 05:45:42,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:43,186][root][INFO] - Training Epoch: 9/10, step 325/574 completed (loss: 0.3319512903690338, acc: 0.8780487775802612)
[2024-11-13 05:45:43,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:43,484][root][INFO] - Training Epoch: 9/10, step 326/574 completed (loss: 0.20319987833499908, acc: 0.9473684430122375)
[2024-11-13 05:45:43,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:43,783][root][INFO] - Training Epoch: 9/10, step 327/574 completed (loss: 0.29632875323295593, acc: 0.9473684430122375)
[2024-11-13 05:45:43,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:44,084][root][INFO] - Training Epoch: 9/10, step 328/574 completed (loss: 0.003305311081930995, acc: 1.0)
[2024-11-13 05:45:44,166][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:44,398][root][INFO] - Training Epoch: 9/10, step 329/574 completed (loss: 0.005319011397659779, acc: 1.0)
[2024-11-13 05:45:44,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:44,736][root][INFO] - Training Epoch: 9/10, step 330/574 completed (loss: 0.002249093260616064, acc: 1.0)
[2024-11-13 05:45:44,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:45,062][root][INFO] - Training Epoch: 9/10, step 331/574 completed (loss: 0.04922715947031975, acc: 0.9838709831237793)
[2024-11-13 05:45:45,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:45,424][root][INFO] - Training Epoch: 9/10, step 332/574 completed (loss: 0.022442735731601715, acc: 1.0)
[2024-11-13 05:45:45,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:45,749][root][INFO] - Training Epoch: 9/10, step 333/574 completed (loss: 0.12958838045597076, acc: 0.96875)
[2024-11-13 05:45:45,846][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:46,073][root][INFO] - Training Epoch: 9/10, step 334/574 completed (loss: 0.050027571618556976, acc: 0.9666666388511658)
[2024-11-13 05:45:46,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:46,377][root][INFO] - Training Epoch: 9/10, step 335/574 completed (loss: 0.010328306816518307, acc: 1.0)
[2024-11-13 05:45:46,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:46,720][root][INFO] - Training Epoch: 9/10, step 336/574 completed (loss: 0.09390242397785187, acc: 0.9599999785423279)
[2024-11-13 05:45:46,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:47,050][root][INFO] - Training Epoch: 9/10, step 337/574 completed (loss: 0.33324798941612244, acc: 0.8965517282485962)
[2024-11-13 05:45:47,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:47,409][root][INFO] - Training Epoch: 9/10, step 338/574 completed (loss: 0.3325716555118561, acc: 0.8617021441459656)
[2024-11-13 05:45:47,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:47,762][root][INFO] - Training Epoch: 9/10, step 339/574 completed (loss: 0.31698182225227356, acc: 0.8674699068069458)
[2024-11-13 05:45:47,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:48,087][root][INFO] - Training Epoch: 9/10, step 340/574 completed (loss: 0.0027633109129965305, acc: 1.0)
[2024-11-13 05:45:48,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:48,409][root][INFO] - Training Epoch: 9/10, step 341/574 completed (loss: 0.01896163634955883, acc: 1.0)
[2024-11-13 05:45:48,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:48,772][root][INFO] - Training Epoch: 9/10, step 342/574 completed (loss: 0.04121198505163193, acc: 0.9879518151283264)
[2024-11-13 05:45:48,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:49,111][root][INFO] - Training Epoch: 9/10, step 343/574 completed (loss: 0.227614164352417, acc: 0.9433962106704712)
[2024-11-13 05:45:49,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:49,434][root][INFO] - Training Epoch: 9/10, step 344/574 completed (loss: 0.08295278996229172, acc: 0.9620253443717957)
[2024-11-13 05:45:49,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:49,779][root][INFO] - Training Epoch: 9/10, step 345/574 completed (loss: 0.018577467650175095, acc: 1.0)
[2024-11-13 05:45:49,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:50,086][root][INFO] - Training Epoch: 9/10, step 346/574 completed (loss: 0.07829735428094864, acc: 0.9701492786407471)
[2024-11-13 05:45:50,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:50,396][root][INFO] - Training Epoch: 9/10, step 347/574 completed (loss: 0.025176024064421654, acc: 1.0)
[2024-11-13 05:45:50,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:50,746][root][INFO] - Training Epoch: 9/10, step 348/574 completed (loss: 0.08303941786289215, acc: 0.9599999785423279)
[2024-11-13 05:45:50,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:51,127][root][INFO] - Training Epoch: 9/10, step 349/574 completed (loss: 0.14579367637634277, acc: 0.9444444179534912)
[2024-11-13 05:45:51,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:51,465][root][INFO] - Training Epoch: 9/10, step 350/574 completed (loss: 0.12289639562368393, acc: 0.9534883499145508)
[2024-11-13 05:45:51,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:51,799][root][INFO] - Training Epoch: 9/10, step 351/574 completed (loss: 0.18147258460521698, acc: 0.9487179517745972)
[2024-11-13 05:45:51,898][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:52,155][root][INFO] - Training Epoch: 9/10, step 352/574 completed (loss: 0.21064132452011108, acc: 0.9555555582046509)
[2024-11-13 05:45:52,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:52,460][root][INFO] - Training Epoch: 9/10, step 353/574 completed (loss: 0.0009771304903551936, acc: 1.0)
[2024-11-13 05:45:52,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:52,746][root][INFO] - Training Epoch: 9/10, step 354/574 completed (loss: 0.034671492874622345, acc: 1.0)
[2024-11-13 05:45:52,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:53,074][root][INFO] - Training Epoch: 9/10, step 355/574 completed (loss: 0.33183255791664124, acc: 0.901098906993866)
[2024-11-13 05:45:53,199][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:53,575][root][INFO] - Training Epoch: 9/10, step 356/574 completed (loss: 0.2010289877653122, acc: 0.939130425453186)
[2024-11-13 05:45:53,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:53,944][root][INFO] - Training Epoch: 9/10, step 357/574 completed (loss: 0.12202631682157516, acc: 0.95652174949646)
[2024-11-13 05:45:54,034][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:54,273][root][INFO] - Training Epoch: 9/10, step 358/574 completed (loss: 0.05135456845164299, acc: 1.0)
[2024-11-13 05:45:54,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:54,602][root][INFO] - Training Epoch: 9/10, step 359/574 completed (loss: 0.0008927526068873703, acc: 1.0)
[2024-11-13 05:45:54,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:54,912][root][INFO] - Training Epoch: 9/10, step 360/574 completed (loss: 0.005601497367024422, acc: 1.0)
[2024-11-13 05:45:54,991][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:55,229][root][INFO] - Training Epoch: 9/10, step 361/574 completed (loss: 0.21892531216144562, acc: 0.9024389982223511)
[2024-11-13 05:45:55,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:55,584][root][INFO] - Training Epoch: 9/10, step 362/574 completed (loss: 0.20013703405857086, acc: 0.9111111164093018)
[2024-11-13 05:45:55,692][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:55,958][root][INFO] - Training Epoch: 9/10, step 363/574 completed (loss: 0.012563244439661503, acc: 1.0)
[2024-11-13 05:45:56,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:56,295][root][INFO] - Training Epoch: 9/10, step 364/574 completed (loss: 0.009904888458549976, acc: 1.0)
[2024-11-13 05:45:56,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:56,596][root][INFO] - Training Epoch: 9/10, step 365/574 completed (loss: 0.1751069724559784, acc: 0.9696969985961914)
[2024-11-13 05:45:56,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:56,884][root][INFO] - Training Epoch: 9/10, step 366/574 completed (loss: 0.0013847971567884088, acc: 1.0)
[2024-11-13 05:45:56,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:57,186][root][INFO] - Training Epoch: 9/10, step 367/574 completed (loss: 0.0068474807776510715, acc: 1.0)
[2024-11-13 05:45:57,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:57,482][root][INFO] - Training Epoch: 9/10, step 368/574 completed (loss: 0.01346865389496088, acc: 1.0)
[2024-11-13 05:45:57,548][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:57,763][root][INFO] - Training Epoch: 9/10, step 369/574 completed (loss: 0.03625950217247009, acc: 0.96875)
[2024-11-13 05:45:57,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:58,368][root][INFO] - Training Epoch: 9/10, step 370/574 completed (loss: 0.2874666750431061, acc: 0.9151515364646912)
[2024-11-13 05:45:58,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:59,284][root][INFO] - Training Epoch: 9/10, step 371/574 completed (loss: 0.17077496647834778, acc: 0.9528301954269409)
[2024-11-13 05:45:59,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:45:59,612][root][INFO] - Training Epoch: 9/10, step 372/574 completed (loss: 0.10296623408794403, acc: 0.9555555582046509)
[2024-11-13 05:45:59,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:00,014][root][INFO] - Training Epoch: 9/10, step 373/574 completed (loss: 0.07247395068407059, acc: 0.9642857313156128)
[2024-11-13 05:46:00,121][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:00,352][root][INFO] - Training Epoch: 9/10, step 374/574 completed (loss: 0.06962470710277557, acc: 0.9714285731315613)
[2024-11-13 05:46:00,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:00,633][root][INFO] - Training Epoch: 9/10, step 375/574 completed (loss: 0.00306299957446754, acc: 1.0)
[2024-11-13 05:46:00,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:00,926][root][INFO] - Training Epoch: 9/10, step 376/574 completed (loss: 0.009516201913356781, acc: 1.0)
[2024-11-13 05:46:01,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:01,273][root][INFO] - Training Epoch: 9/10, step 377/574 completed (loss: 0.03149677440524101, acc: 1.0)
[2024-11-13 05:46:01,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:01,620][root][INFO] - Training Epoch: 9/10, step 378/574 completed (loss: 0.04144396632909775, acc: 0.9894737005233765)
[2024-11-13 05:46:01,783][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:02,217][root][INFO] - Training Epoch: 9/10, step 379/574 completed (loss: 0.21766194701194763, acc: 0.940119743347168)
[2024-11-13 05:46:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:02,657][root][INFO] - Training Epoch: 9/10, step 380/574 completed (loss: 0.15696151554584503, acc: 0.9624060392379761)
[2024-11-13 05:46:03,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:03,971][root][INFO] - Training Epoch: 9/10, step 381/574 completed (loss: 0.40297138690948486, acc: 0.8716577291488647)
[2024-11-13 05:46:04,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:04,569][root][INFO] - Training Epoch: 9/10, step 382/574 completed (loss: 0.059911422431468964, acc: 0.9819819927215576)
[2024-11-13 05:46:04,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:04,878][root][INFO] - Training Epoch: 9/10, step 383/574 completed (loss: 0.02095307596027851, acc: 1.0)
[2024-11-13 05:46:04,950][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:05,135][root][INFO] - Training Epoch: 9/10, step 384/574 completed (loss: 0.008364749141037464, acc: 1.0)
[2024-11-13 05:46:05,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:05,374][root][INFO] - Training Epoch: 9/10, step 385/574 completed (loss: 0.012282270938158035, acc: 1.0)
[2024-11-13 05:46:05,443][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:05,656][root][INFO] - Training Epoch: 9/10, step 386/574 completed (loss: 0.004215218126773834, acc: 1.0)
[2024-11-13 05:46:05,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:05,952][root][INFO] - Training Epoch: 9/10, step 387/574 completed (loss: 0.018772514536976814, acc: 1.0)
[2024-11-13 05:46:06,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:06,256][root][INFO] - Training Epoch: 9/10, step 388/574 completed (loss: 0.0034319073893129826, acc: 1.0)
[2024-11-13 05:46:06,331][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:06,542][root][INFO] - Training Epoch: 9/10, step 389/574 completed (loss: 0.0007191350450739264, acc: 1.0)
[2024-11-13 05:46:06,660][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:06,891][root][INFO] - Training Epoch: 9/10, step 390/574 completed (loss: 0.0975816622376442, acc: 0.9523809552192688)
[2024-11-13 05:46:06,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:07,176][root][INFO] - Training Epoch: 9/10, step 391/574 completed (loss: 0.26341554522514343, acc: 0.9074074029922485)
[2024-11-13 05:46:07,273][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:07,518][root][INFO] - Training Epoch: 9/10, step 392/574 completed (loss: 0.321800172328949, acc: 0.8834951519966125)
[2024-11-13 05:46:07,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:08,043][root][INFO] - Training Epoch: 9/10, step 393/574 completed (loss: 0.34692293405532837, acc: 0.9191176295280457)
[2024-11-13 05:46:08,146][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:08,416][root][INFO] - Training Epoch: 9/10, step 394/574 completed (loss: 0.42122626304626465, acc: 0.8999999761581421)
[2024-11-13 05:46:08,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:08,811][root][INFO] - Training Epoch: 9/10, step 395/574 completed (loss: 0.30434098839759827, acc: 0.9027777910232544)
[2024-11-13 05:46:08,903][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:09,136][root][INFO] - Training Epoch: 9/10, step 396/574 completed (loss: 0.0573844350874424, acc: 0.9767441749572754)
[2024-11-13 05:46:09,215][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:09,432][root][INFO] - Training Epoch: 9/10, step 397/574 completed (loss: 0.012194554321467876, acc: 1.0)
[2024-11-13 05:46:09,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:09,739][root][INFO] - Training Epoch: 9/10, step 398/574 completed (loss: 0.10984162241220474, acc: 0.9767441749572754)
[2024-11-13 05:46:09,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:10,098][root][INFO] - Training Epoch: 9/10, step 399/574 completed (loss: 0.01618064008653164, acc: 1.0)
[2024-11-13 05:46:10,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:10,632][root][INFO] - Training Epoch: 9/10, step 400/574 completed (loss: 0.12167779356241226, acc: 0.9558823704719543)
[2024-11-13 05:46:10,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:10,961][root][INFO] - Training Epoch: 9/10, step 401/574 completed (loss: 0.08639403432607651, acc: 0.9599999785423279)
[2024-11-13 05:46:11,042][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:11,273][root][INFO] - Training Epoch: 9/10, step 402/574 completed (loss: 0.043909866362810135, acc: 1.0)
[2024-11-13 05:46:11,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:11,571][root][INFO] - Training Epoch: 9/10, step 403/574 completed (loss: 0.010947558097541332, acc: 1.0)
[2024-11-13 05:46:11,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:11,865][root][INFO] - Training Epoch: 9/10, step 404/574 completed (loss: 0.22101496160030365, acc: 0.9354838728904724)
[2024-11-13 05:46:11,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:12,154][root][INFO] - Training Epoch: 9/10, step 405/574 completed (loss: 0.007847248576581478, acc: 1.0)
[2024-11-13 05:46:12,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:12,463][root][INFO] - Training Epoch: 9/10, step 406/574 completed (loss: 0.03359825909137726, acc: 1.0)
[2024-11-13 05:46:12,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:12,803][root][INFO] - Training Epoch: 9/10, step 407/574 completed (loss: 0.007629628758877516, acc: 1.0)
[2024-11-13 05:46:12,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:13,138][root][INFO] - Training Epoch: 9/10, step 408/574 completed (loss: 0.0044447267428040504, acc: 1.0)
[2024-11-13 05:46:13,226][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:13,447][root][INFO] - Training Epoch: 9/10, step 409/574 completed (loss: 0.002570210723206401, acc: 1.0)
[2024-11-13 05:46:13,530][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:13,760][root][INFO] - Training Epoch: 9/10, step 410/574 completed (loss: 0.03182891756296158, acc: 0.982758641242981)
[2024-11-13 05:46:13,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:14,005][root][INFO] - Training Epoch: 9/10, step 411/574 completed (loss: 0.00812269002199173, acc: 1.0)
[2024-11-13 05:46:14,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:14,273][root][INFO] - Training Epoch: 9/10, step 412/574 completed (loss: 0.009746492840349674, acc: 1.0)
[2024-11-13 05:46:14,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:15,436][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:15,819][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:16,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:16,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:16,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:17,090][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:17,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:17,862][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:18,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:18,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:18,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:19,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:19,583][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:19,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:20,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:20,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:21,030][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:21,407][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:21,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:22,002][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:22,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:22,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:22,935][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:23,309][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:23,627][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:23,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:24,314][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:24,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:24,962][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:25,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:25,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:25,972][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:26,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:26,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:27,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:27,427][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:27,831][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:28,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:28,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:29,080][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:29,504][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:29,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:30,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:30,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:31,051][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:31,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:31,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:32,133][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:32,488][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:32,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:33,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:33,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:33,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:33,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:34,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:34,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:34,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:35,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:35,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:36,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:36,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:37,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:37,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:37,878][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:38,239][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:38,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:39,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:39,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:39,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:40,342][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:40,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:41,067][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:41,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:41,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:42,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:42,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:42,989][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:43,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:43,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:44,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:44,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:44,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:45,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:45,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:46,069][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.7943, device='cuda:0') eval_epoch_loss=tensor(1.0276, device='cuda:0') eval_epoch_acc=tensor(0.7959, device='cuda:0')
[2024-11-13 05:46:46,070][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:46:46,071][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:46:46,343][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_9_step_413_loss_1.0275901556015015/model.pt
[2024-11-13 05:46:46,346][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:46:46,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:46,710][root][INFO] - Training Epoch: 9/10, step 413/574 completed (loss: 0.006119161378592253, acc: 1.0)
[2024-11-13 05:46:46,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:47,048][root][INFO] - Training Epoch: 9/10, step 414/574 completed (loss: 0.016653195023536682, acc: 1.0)
[2024-11-13 05:46:47,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:47,371][root][INFO] - Training Epoch: 9/10, step 415/574 completed (loss: 0.13012315332889557, acc: 0.9607843160629272)
[2024-11-13 05:46:47,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:47,672][root][INFO] - Training Epoch: 9/10, step 416/574 completed (loss: 0.005322165321558714, acc: 1.0)
[2024-11-13 05:46:47,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:47,979][root][INFO] - Training Epoch: 9/10, step 417/574 completed (loss: 0.005959549453109503, acc: 1.0)
[2024-11-13 05:46:48,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:48,302][root][INFO] - Training Epoch: 9/10, step 418/574 completed (loss: 0.03169155865907669, acc: 1.0)
[2024-11-13 05:46:48,383][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:48,609][root][INFO] - Training Epoch: 9/10, step 419/574 completed (loss: 0.02154752053320408, acc: 1.0)
[2024-11-13 05:46:48,687][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:48,903][root][INFO] - Training Epoch: 9/10, step 420/574 completed (loss: 0.010162263177335262, acc: 1.0)
[2024-11-13 05:46:48,979][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:49,186][root][INFO] - Training Epoch: 9/10, step 421/574 completed (loss: 0.03536100685596466, acc: 1.0)
[2024-11-13 05:46:49,263][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:49,487][root][INFO] - Training Epoch: 9/10, step 422/574 completed (loss: 0.004926580004394054, acc: 1.0)
[2024-11-13 05:46:49,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:49,835][root][INFO] - Training Epoch: 9/10, step 423/574 completed (loss: 0.0866001695394516, acc: 0.9722222089767456)
[2024-11-13 05:46:49,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:50,144][root][INFO] - Training Epoch: 9/10, step 424/574 completed (loss: 0.03642354905605316, acc: 1.0)
[2024-11-13 05:46:50,230][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:50,431][root][INFO] - Training Epoch: 9/10, step 425/574 completed (loss: 0.0015003063017502427, acc: 1.0)
[2024-11-13 05:46:50,507][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:50,723][root][INFO] - Training Epoch: 9/10, step 426/574 completed (loss: 0.001993473619222641, acc: 1.0)
[2024-11-13 05:46:50,801][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:51,036][root][INFO] - Training Epoch: 9/10, step 427/574 completed (loss: 0.008963738568127155, acc: 1.0)
[2024-11-13 05:46:51,113][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:51,332][root][INFO] - Training Epoch: 9/10, step 428/574 completed (loss: 0.0021062179002910852, acc: 1.0)
[2024-11-13 05:46:51,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:51,644][root][INFO] - Training Epoch: 9/10, step 429/574 completed (loss: 0.0013813907280564308, acc: 1.0)
[2024-11-13 05:46:51,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:51,970][root][INFO] - Training Epoch: 9/10, step 430/574 completed (loss: 0.00619687931612134, acc: 1.0)
[2024-11-13 05:46:52,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:52,290][root][INFO] - Training Epoch: 9/10, step 431/574 completed (loss: 0.0009448379860259593, acc: 1.0)
[2024-11-13 05:46:52,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:52,604][root][INFO] - Training Epoch: 9/10, step 432/574 completed (loss: 0.0022728180047124624, acc: 1.0)
[2024-11-13 05:46:52,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:52,968][root][INFO] - Training Epoch: 9/10, step 433/574 completed (loss: 0.0061493501998484135, acc: 1.0)
[2024-11-13 05:46:53,044][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:53,251][root][INFO] - Training Epoch: 9/10, step 434/574 completed (loss: 0.00033311350853182375, acc: 1.0)
[2024-11-13 05:46:53,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:53,543][root][INFO] - Training Epoch: 9/10, step 435/574 completed (loss: 0.018728556111454964, acc: 1.0)
[2024-11-13 05:46:53,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:53,850][root][INFO] - Training Epoch: 9/10, step 436/574 completed (loss: 0.021105734631419182, acc: 1.0)
[2024-11-13 05:46:53,932][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:54,136][root][INFO] - Training Epoch: 9/10, step 437/574 completed (loss: 0.002629924798384309, acc: 1.0)
[2024-11-13 05:46:54,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:54,419][root][INFO] - Training Epoch: 9/10, step 438/574 completed (loss: 0.0018387576565146446, acc: 1.0)
[2024-11-13 05:46:54,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:54,771][root][INFO] - Training Epoch: 9/10, step 439/574 completed (loss: 0.13786843419075012, acc: 0.9487179517745972)
[2024-11-13 05:46:54,899][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:55,239][root][INFO] - Training Epoch: 9/10, step 440/574 completed (loss: 0.30230239033699036, acc: 0.8484848737716675)
[2024-11-13 05:46:55,452][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:55,960][root][INFO] - Training Epoch: 9/10, step 441/574 completed (loss: 0.4891863167285919, acc: 0.871999979019165)
[2024-11-13 05:46:56,062][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:56,361][root][INFO] - Training Epoch: 9/10, step 442/574 completed (loss: 0.3341429531574249, acc: 0.8951612710952759)
[2024-11-13 05:46:56,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:57,011][root][INFO] - Training Epoch: 9/10, step 443/574 completed (loss: 0.3878823518753052, acc: 0.89552241563797)
[2024-11-13 05:46:57,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:57,311][root][INFO] - Training Epoch: 9/10, step 444/574 completed (loss: 0.08845309168100357, acc: 0.9811320900917053)
[2024-11-13 05:46:57,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:57,722][root][INFO] - Training Epoch: 9/10, step 445/574 completed (loss: 0.07765652984380722, acc: 0.9545454382896423)
[2024-11-13 05:46:57,797][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:58,016][root][INFO] - Training Epoch: 9/10, step 446/574 completed (loss: 0.0049746958538889885, acc: 1.0)
[2024-11-13 05:46:58,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:58,306][root][INFO] - Training Epoch: 9/10, step 447/574 completed (loss: 0.1846279799938202, acc: 0.9615384340286255)
[2024-11-13 05:46:58,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:58,599][root][INFO] - Training Epoch: 9/10, step 448/574 completed (loss: 0.02263633906841278, acc: 1.0)
[2024-11-13 05:46:58,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:58,859][root][INFO] - Training Epoch: 9/10, step 449/574 completed (loss: 0.04411361366510391, acc: 0.9850746393203735)
[2024-11-13 05:46:58,938][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:59,191][root][INFO] - Training Epoch: 9/10, step 450/574 completed (loss: 0.05157868191599846, acc: 0.9861111044883728)
[2024-11-13 05:46:59,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:59,541][root][INFO] - Training Epoch: 9/10, step 451/574 completed (loss: 0.02400394342839718, acc: 1.0)
[2024-11-13 05:46:59,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:46:59,858][root][INFO] - Training Epoch: 9/10, step 452/574 completed (loss: 0.03413008525967598, acc: 0.9871794581413269)
[2024-11-13 05:46:59,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:00,174][root][INFO] - Training Epoch: 9/10, step 453/574 completed (loss: 0.03933935612440109, acc: 0.9868420958518982)
[2024-11-13 05:47:00,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:00,528][root][INFO] - Training Epoch: 9/10, step 454/574 completed (loss: 0.09136170893907547, acc: 0.9591836929321289)
[2024-11-13 05:47:00,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:00,860][root][INFO] - Training Epoch: 9/10, step 455/574 completed (loss: 0.01605348475277424, acc: 1.0)
[2024-11-13 05:47:00,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:01,187][root][INFO] - Training Epoch: 9/10, step 456/574 completed (loss: 0.14842095971107483, acc: 0.9587628841400146)
[2024-11-13 05:47:01,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:01,516][root][INFO] - Training Epoch: 9/10, step 457/574 completed (loss: 0.03233964741230011, acc: 1.0)
[2024-11-13 05:47:01,639][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:01,897][root][INFO] - Training Epoch: 9/10, step 458/574 completed (loss: 0.1433991938829422, acc: 0.9593023061752319)
[2024-11-13 05:47:01,975][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:02,198][root][INFO] - Training Epoch: 9/10, step 459/574 completed (loss: 0.04344358667731285, acc: 0.9821428656578064)
[2024-11-13 05:47:02,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:02,504][root][INFO] - Training Epoch: 9/10, step 460/574 completed (loss: 0.09651017189025879, acc: 0.9629629850387573)
[2024-11-13 05:47:02,581][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:02,794][root][INFO] - Training Epoch: 9/10, step 461/574 completed (loss: 0.015072818845510483, acc: 1.0)
[2024-11-13 05:47:02,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:03,079][root][INFO] - Training Epoch: 9/10, step 462/574 completed (loss: 0.16018787026405334, acc: 0.96875)
[2024-11-13 05:47:03,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:03,371][root][INFO] - Training Epoch: 9/10, step 463/574 completed (loss: 0.059289321303367615, acc: 0.9615384340286255)
[2024-11-13 05:47:03,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:03,750][root][INFO] - Training Epoch: 9/10, step 464/574 completed (loss: 0.04955151677131653, acc: 1.0)
[2024-11-13 05:47:03,856][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:04,094][root][INFO] - Training Epoch: 9/10, step 465/574 completed (loss: 0.07664512097835541, acc: 0.9642857313156128)
[2024-11-13 05:47:04,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:04,392][root][INFO] - Training Epoch: 9/10, step 466/574 completed (loss: 0.1445235162973404, acc: 0.9518072009086609)
[2024-11-13 05:47:04,480][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:04,729][root][INFO] - Training Epoch: 9/10, step 467/574 completed (loss: 0.11203904449939728, acc: 0.9639639854431152)
[2024-11-13 05:47:04,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:05,085][root][INFO] - Training Epoch: 9/10, step 468/574 completed (loss: 0.2430286556482315, acc: 0.9417475461959839)
[2024-11-13 05:47:05,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:05,426][root][INFO] - Training Epoch: 9/10, step 469/574 completed (loss: 0.17883819341659546, acc: 0.9268292784690857)
[2024-11-13 05:47:05,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:05,731][root][INFO] - Training Epoch: 9/10, step 470/574 completed (loss: 0.008028312586247921, acc: 1.0)
[2024-11-13 05:47:05,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:06,012][root][INFO] - Training Epoch: 9/10, step 471/574 completed (loss: 0.03167705982923508, acc: 1.0)
[2024-11-13 05:47:06,164][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:06,419][root][INFO] - Training Epoch: 9/10, step 472/574 completed (loss: 0.19541984796524048, acc: 0.9313725233078003)
[2024-11-13 05:47:06,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:06,804][root][INFO] - Training Epoch: 9/10, step 473/574 completed (loss: 0.34461429715156555, acc: 0.8777292370796204)
[2024-11-13 05:47:06,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:07,149][root][INFO] - Training Epoch: 9/10, step 474/574 completed (loss: 0.08548477292060852, acc: 0.96875)
[2024-11-13 05:47:07,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:07,504][root][INFO] - Training Epoch: 9/10, step 475/574 completed (loss: 0.11138124763965607, acc: 0.9693251252174377)
[2024-11-13 05:47:07,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:07,833][root][INFO] - Training Epoch: 9/10, step 476/574 completed (loss: 0.12915465235710144, acc: 0.9640287756919861)
[2024-11-13 05:47:07,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:08,197][root][INFO] - Training Epoch: 9/10, step 477/574 completed (loss: 0.21632209420204163, acc: 0.9346733689308167)
[2024-11-13 05:47:08,276][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:08,512][root][INFO] - Training Epoch: 9/10, step 478/574 completed (loss: 0.035016100853681564, acc: 1.0)
[2024-11-13 05:47:08,622][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:08,860][root][INFO] - Training Epoch: 9/10, step 479/574 completed (loss: 0.04703701660037041, acc: 0.9696969985961914)
[2024-11-13 05:47:08,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:09,180][root][INFO] - Training Epoch: 9/10, step 480/574 completed (loss: 0.008538306690752506, acc: 1.0)
[2024-11-13 05:47:09,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:09,477][root][INFO] - Training Epoch: 9/10, step 481/574 completed (loss: 0.0876229777932167, acc: 0.949999988079071)
[2024-11-13 05:47:09,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:09,786][root][INFO] - Training Epoch: 9/10, step 482/574 completed (loss: 0.40508079528808594, acc: 0.8999999761581421)
[2024-11-13 05:47:09,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:10,151][root][INFO] - Training Epoch: 9/10, step 483/574 completed (loss: 0.3661649227142334, acc: 0.8965517282485962)
[2024-11-13 05:47:10,224][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:10,452][root][INFO] - Training Epoch: 9/10, step 484/574 completed (loss: 0.009778299368917942, acc: 1.0)
[2024-11-13 05:47:10,533][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:10,778][root][INFO] - Training Epoch: 9/10, step 485/574 completed (loss: 0.19536253809928894, acc: 0.9473684430122375)
[2024-11-13 05:47:10,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:11,099][root][INFO] - Training Epoch: 9/10, step 486/574 completed (loss: 0.12136835604906082, acc: 0.9259259104728699)
[2024-11-13 05:47:11,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:11,390][root][INFO] - Training Epoch: 9/10, step 487/574 completed (loss: 0.10830391943454742, acc: 0.9523809552192688)
[2024-11-13 05:47:11,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:11,691][root][INFO] - Training Epoch: 9/10, step 488/574 completed (loss: 0.26515868306159973, acc: 0.8636363744735718)
[2024-11-13 05:47:11,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:12,049][root][INFO] - Training Epoch: 9/10, step 489/574 completed (loss: 0.11297472566366196, acc: 0.9384615421295166)
[2024-11-13 05:47:12,149][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:12,378][root][INFO] - Training Epoch: 9/10, step 490/574 completed (loss: 0.018038004636764526, acc: 1.0)
[2024-11-13 05:47:12,460][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:12,659][root][INFO] - Training Epoch: 9/10, step 491/574 completed (loss: 0.05773593485355377, acc: 0.9655172228813171)
[2024-11-13 05:47:12,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:12,996][root][INFO] - Training Epoch: 9/10, step 492/574 completed (loss: 0.11646857857704163, acc: 0.9607843160629272)
[2024-11-13 05:47:13,085][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:13,306][root][INFO] - Training Epoch: 9/10, step 493/574 completed (loss: 0.0168509129434824, acc: 1.0)
[2024-11-13 05:47:13,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:13,610][root][INFO] - Training Epoch: 9/10, step 494/574 completed (loss: 0.13373132050037384, acc: 0.9473684430122375)
[2024-11-13 05:47:13,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:13,929][root][INFO] - Training Epoch: 9/10, step 495/574 completed (loss: 0.4051159620285034, acc: 0.8947368264198303)
[2024-11-13 05:47:14,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:14,277][root][INFO] - Training Epoch: 9/10, step 496/574 completed (loss: 0.3820207417011261, acc: 0.8660714030265808)
[2024-11-13 05:47:14,368][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:14,659][root][INFO] - Training Epoch: 9/10, step 497/574 completed (loss: 0.21674014627933502, acc: 0.9550561904907227)
[2024-11-13 05:47:14,757][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:14,994][root][INFO] - Training Epoch: 9/10, step 498/574 completed (loss: 0.5105740427970886, acc: 0.8876404762268066)
[2024-11-13 05:47:15,132][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:15,381][root][INFO] - Training Epoch: 9/10, step 499/574 completed (loss: 0.6615141034126282, acc: 0.8085106611251831)
[2024-11-13 05:47:15,481][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:15,678][root][INFO] - Training Epoch: 9/10, step 500/574 completed (loss: 0.28745636343955994, acc: 0.9130434989929199)
[2024-11-13 05:47:15,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:15,964][root][INFO] - Training Epoch: 9/10, step 501/574 completed (loss: 0.10350281745195389, acc: 0.9599999785423279)
[2024-11-13 05:47:16,045][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:16,270][root][INFO] - Training Epoch: 9/10, step 502/574 completed (loss: 0.0027419826947152615, acc: 1.0)
[2024-11-13 05:47:16,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:16,577][root][INFO] - Training Epoch: 9/10, step 503/574 completed (loss: 0.019556649029254913, acc: 1.0)
[2024-11-13 05:47:16,682][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:16,913][root][INFO] - Training Epoch: 9/10, step 504/574 completed (loss: 0.011463034898042679, acc: 1.0)
[2024-11-13 05:47:16,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:17,209][root][INFO] - Training Epoch: 9/10, step 505/574 completed (loss: 0.11400161683559418, acc: 0.9811320900917053)
[2024-11-13 05:47:17,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:17,526][root][INFO] - Training Epoch: 9/10, step 506/574 completed (loss: 0.2598409950733185, acc: 0.931034505367279)
[2024-11-13 05:47:17,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:18,138][root][INFO] - Training Epoch: 9/10, step 507/574 completed (loss: 0.5734897255897522, acc: 0.8198198080062866)
[2024-11-13 05:47:18,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:18,582][root][INFO] - Training Epoch: 9/10, step 508/574 completed (loss: 0.3352479636669159, acc: 0.9295774698257446)
[2024-11-13 05:47:18,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:18,864][root][INFO] - Training Epoch: 9/10, step 509/574 completed (loss: 0.05287272483110428, acc: 0.949999988079071)
[2024-11-13 05:47:18,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:19,167][root][INFO] - Training Epoch: 9/10, step 510/574 completed (loss: 0.2472369223833084, acc: 0.9666666388511658)
[2024-11-13 05:47:19,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:19,449][root][INFO] - Training Epoch: 9/10, step 511/574 completed (loss: 0.007646826561540365, acc: 1.0)
[2024-11-13 05:47:21,151][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:22,444][root][INFO] - Training Epoch: 9/10, step 512/574 completed (loss: 0.5448007583618164, acc: 0.8571428656578064)
[2024-11-13 05:47:22,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:23,217][root][INFO] - Training Epoch: 9/10, step 513/574 completed (loss: 0.12933415174484253, acc: 0.9444444179534912)
[2024-11-13 05:47:23,288][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:23,517][root][INFO] - Training Epoch: 9/10, step 514/574 completed (loss: 0.35004153847694397, acc: 0.8571428656578064)
[2024-11-13 05:47:23,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:23,867][root][INFO] - Training Epoch: 9/10, step 515/574 completed (loss: 0.016421128064393997, acc: 1.0)
[2024-11-13 05:47:24,052][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:24,553][root][INFO] - Training Epoch: 9/10, step 516/574 completed (loss: 0.23990648984909058, acc: 0.9583333134651184)
[2024-11-13 05:47:24,624][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:24,852][root][INFO] - Training Epoch: 9/10, step 517/574 completed (loss: 0.0081796208396554, acc: 1.0)
[2024-11-13 05:47:24,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:25,145][root][INFO] - Training Epoch: 9/10, step 518/574 completed (loss: 0.11922968178987503, acc: 0.9354838728904724)
[2024-11-13 05:47:25,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:25,434][root][INFO] - Training Epoch: 9/10, step 519/574 completed (loss: 0.031492751091718674, acc: 1.0)
[2024-11-13 05:47:25,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:25,707][root][INFO] - Training Epoch: 9/10, step 520/574 completed (loss: 0.1275755763053894, acc: 0.9629629850387573)
[2024-11-13 05:47:25,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:26,707][root][INFO] - Training Epoch: 9/10, step 521/574 completed (loss: 0.5069566965103149, acc: 0.8389830589294434)
[2024-11-13 05:47:26,794][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:27,049][root][INFO] - Training Epoch: 9/10, step 522/574 completed (loss: 0.17187882959842682, acc: 0.9328358173370361)
[2024-11-13 05:47:27,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:27,409][root][INFO] - Training Epoch: 9/10, step 523/574 completed (loss: 0.2261960655450821, acc: 0.9124087691307068)
[2024-11-13 05:47:27,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:27,964][root][INFO] - Training Epoch: 9/10, step 524/574 completed (loss: 0.4298762083053589, acc: 0.8600000143051147)
[2024-11-13 05:47:28,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:28,266][root][INFO] - Training Epoch: 9/10, step 525/574 completed (loss: 0.056824587285518646, acc: 0.9814814925193787)
[2024-11-13 05:47:28,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:28,559][root][INFO] - Training Epoch: 9/10, step 526/574 completed (loss: 0.05942455306649208, acc: 0.9615384340286255)
[2024-11-13 05:47:28,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:28,849][root][INFO] - Training Epoch: 9/10, step 527/574 completed (loss: 0.16874340176582336, acc: 0.8571428656578064)
[2024-11-13 05:47:28,934][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:29,170][root][INFO] - Training Epoch: 9/10, step 528/574 completed (loss: 0.3550090193748474, acc: 0.8524590134620667)
[2024-11-13 05:47:29,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:29,455][root][INFO] - Training Epoch: 9/10, step 529/574 completed (loss: 0.10917907953262329, acc: 0.9661017060279846)
[2024-11-13 05:47:29,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:29,751][root][INFO] - Training Epoch: 9/10, step 530/574 completed (loss: 0.202018141746521, acc: 0.9534883499145508)
[2024-11-13 05:47:29,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:30,052][root][INFO] - Training Epoch: 9/10, step 531/574 completed (loss: 0.12379774451255798, acc: 0.9545454382896423)
[2024-11-13 05:47:30,138][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:30,363][root][INFO] - Training Epoch: 9/10, step 532/574 completed (loss: 0.3150184154510498, acc: 0.8679245114326477)
[2024-11-13 05:47:30,440][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:30,659][root][INFO] - Training Epoch: 9/10, step 533/574 completed (loss: 0.3148077726364136, acc: 0.9090909361839294)
[2024-11-13 05:47:30,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:30,947][root][INFO] - Training Epoch: 9/10, step 534/574 completed (loss: 0.10070003569126129, acc: 0.9599999785423279)
[2024-11-13 05:47:31,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:31,243][root][INFO] - Training Epoch: 9/10, step 535/574 completed (loss: 0.19948866963386536, acc: 0.8999999761581421)
[2024-11-13 05:47:31,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:31,537][root][INFO] - Training Epoch: 9/10, step 536/574 completed (loss: 0.020364461466670036, acc: 1.0)
[2024-11-13 05:47:31,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:31,938][root][INFO] - Training Epoch: 9/10, step 537/574 completed (loss: 0.2036118507385254, acc: 0.9230769276618958)
[2024-11-13 05:47:32,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:32,256][root][INFO] - Training Epoch: 9/10, step 538/574 completed (loss: 0.1411866843700409, acc: 0.953125)
[2024-11-13 05:47:32,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:32,640][root][INFO] - Training Epoch: 9/10, step 539/574 completed (loss: 0.32509851455688477, acc: 0.875)
[2024-11-13 05:47:32,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:32,936][root][INFO] - Training Epoch: 9/10, step 540/574 completed (loss: 0.13184243440628052, acc: 0.939393937587738)
[2024-11-13 05:47:33,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:33,232][root][INFO] - Training Epoch: 9/10, step 541/574 completed (loss: 0.02070261910557747, acc: 1.0)
[2024-11-13 05:47:33,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:33,530][root][INFO] - Training Epoch: 9/10, step 542/574 completed (loss: 0.06056785210967064, acc: 0.9677419066429138)
[2024-11-13 05:47:33,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:33,867][root][INFO] - Training Epoch: 9/10, step 543/574 completed (loss: 0.015264700166881084, acc: 1.0)
[2024-11-13 05:47:33,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:34,173][root][INFO] - Training Epoch: 9/10, step 544/574 completed (loss: 0.09403590857982635, acc: 0.9333333373069763)
[2024-11-13 05:47:34,249][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:34,477][root][INFO] - Training Epoch: 9/10, step 545/574 completed (loss: 0.006758455652743578, acc: 1.0)
[2024-11-13 05:47:34,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:34,765][root][INFO] - Training Epoch: 9/10, step 546/574 completed (loss: 0.031249864026904106, acc: 0.9714285731315613)
[2024-11-13 05:47:34,842][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:35,062][root][INFO] - Training Epoch: 9/10, step 547/574 completed (loss: 0.08128395676612854, acc: 0.9473684430122375)
[2024-11-13 05:47:35,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:35,354][root][INFO] - Training Epoch: 9/10, step 548/574 completed (loss: 0.06827758997678757, acc: 0.9677419066429138)
[2024-11-13 05:47:35,432][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:35,651][root][INFO] - Training Epoch: 9/10, step 549/574 completed (loss: 0.01126126293092966, acc: 1.0)
[2024-11-13 05:47:35,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:35,940][root][INFO] - Training Epoch: 9/10, step 550/574 completed (loss: 0.06737887114286423, acc: 0.9696969985961914)
[2024-11-13 05:47:36,015][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:36,230][root][INFO] - Training Epoch: 9/10, step 551/574 completed (loss: 0.029248932376503944, acc: 0.9750000238418579)
[2024-11-13 05:47:36,315][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:36,574][root][INFO] - Training Epoch: 9/10, step 552/574 completed (loss: 0.10188525170087814, acc: 0.9714285731315613)
[2024-11-13 05:47:36,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:36,928][root][INFO] - Training Epoch: 9/10, step 553/574 completed (loss: 0.1524806171655655, acc: 0.956204354763031)
[2024-11-13 05:47:37,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:37,240][root][INFO] - Training Epoch: 9/10, step 554/574 completed (loss: 0.10337494313716888, acc: 0.9724137783050537)
[2024-11-13 05:47:37,321][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:37,500][root][INFO] - Training Epoch: 9/10, step 555/574 completed (loss: 0.13159990310668945, acc: 0.9714285731315613)
[2024-11-13 05:47:38,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:38,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:38,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:39,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:39,615][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:39,964][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:40,299][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:40,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:40,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:41,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:41,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:42,290][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:42,678][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:43,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:43,417][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:43,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:43,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:44,251][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:44,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:45,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:45,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:45,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:46,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:46,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:46,703][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:47,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:47,376][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:47,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:48,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:48,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:48,724][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:49,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:49,441][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:49,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:50,107][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:50,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:50,760][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:51,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:51,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:52,003][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:52,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:52,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:53,076][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:53,433][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:53,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:54,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:54,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:54,864][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:55,145][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:55,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:55,750][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:56,130][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:56,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:56,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:57,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:57,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:57,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:58,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:58,509][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:58,911][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:59,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:47:59,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:00,183][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:00,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:00,965][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:01,354][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:01,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:02,037][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:02,410][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:02,881][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:03,193][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:03,446][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:03,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:04,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:04,400][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:04,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:04,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:05,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:05,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:06,012][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:06,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:06,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:06,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:07,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:07,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:08,566][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6670, device='cuda:0') eval_epoch_loss=tensor(0.9810, device='cuda:0') eval_epoch_acc=tensor(0.7880, device='cuda:0')
[2024-11-13 05:48:08,567][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:48:08,567][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:48:08,831][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_9_step_556_loss_0.980969250202179/model.pt
[2024-11-13 05:48:08,837][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:48:08,914][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:09,176][root][INFO] - Training Epoch: 9/10, step 556/574 completed (loss: 0.29382333159446716, acc: 0.9205297827720642)
[2024-11-13 05:48:09,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:09,483][root][INFO] - Training Epoch: 9/10, step 557/574 completed (loss: 0.05620959773659706, acc: 0.9829059839248657)
[2024-11-13 05:48:09,584][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:09,830][root][INFO] - Training Epoch: 9/10, step 558/574 completed (loss: 0.038375891745090485, acc: 0.9599999785423279)
[2024-11-13 05:48:09,943][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:10,166][root][INFO] - Training Epoch: 9/10, step 559/574 completed (loss: 0.003603406483307481, acc: 1.0)
[2024-11-13 05:48:10,270][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:10,501][root][INFO] - Training Epoch: 9/10, step 560/574 completed (loss: 0.0025713073555380106, acc: 1.0)
[2024-11-13 05:48:10,609][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:10,837][root][INFO] - Training Epoch: 9/10, step 561/574 completed (loss: 0.054258041083812714, acc: 1.0)
[2024-11-13 05:48:10,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:11,164][root][INFO] - Training Epoch: 9/10, step 562/574 completed (loss: 0.07519978284835815, acc: 0.9666666388511658)
[2024-11-13 05:48:11,275][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:11,507][root][INFO] - Training Epoch: 9/10, step 563/574 completed (loss: 0.08432456851005554, acc: 0.9610389471054077)
[2024-11-13 05:48:11,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:11,839][root][INFO] - Training Epoch: 9/10, step 564/574 completed (loss: 0.17512083053588867, acc: 0.9375)
[2024-11-13 05:48:11,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:12,153][root][INFO] - Training Epoch: 9/10, step 565/574 completed (loss: 0.18307682871818542, acc: 0.9655172228813171)
[2024-11-13 05:48:12,264][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:12,493][root][INFO] - Training Epoch: 9/10, step 566/574 completed (loss: 0.05221434310078621, acc: 0.988095223903656)
[2024-11-13 05:48:12,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:12,823][root][INFO] - Training Epoch: 9/10, step 567/574 completed (loss: 0.030889080837368965, acc: 0.9736841917037964)
[2024-11-13 05:48:12,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:13,135][root][INFO] - Training Epoch: 9/10, step 568/574 completed (loss: 0.017840886488556862, acc: 1.0)
[2024-11-13 05:48:13,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:13,507][root][INFO] - Training Epoch: 9/10, step 569/574 completed (loss: 0.09695133566856384, acc: 0.9732620120048523)
[2024-11-13 05:48:13,613][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:13,835][root][INFO] - Training Epoch: 9/10, step 570/574 completed (loss: 0.03818938136100769, acc: 0.9838709831237793)
[2024-11-13 05:48:13,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:14,152][root][INFO] - Training Epoch: 9/10, step 571/574 completed (loss: 0.05532429367303848, acc: 0.9829059839248657)
[2024-11-13 05:48:14,254][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:14,485][root][INFO] - Training Epoch: 9/10, step 572/574 completed (loss: 0.31372570991516113, acc: 0.8979591727256775)
[2024-11-13 05:48:14,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:14,826][root][INFO] - Training Epoch: 9/10, step 573/574 completed (loss: 0.17454959452152252, acc: 0.9433962106704712)
[2024-11-13 05:48:15,261][slam_llm.utils.train_utils][INFO] - Epoch 9: train_perplexity=1.1680, train_epoch_loss=0.1553, epoch time 348.6536867041141s
[2024-11-13 05:48:15,261][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:48:15,261][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 13 GB
[2024-11-13 05:48:15,262][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:48:15,262][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 25
[2024-11-13 05:48:15,262][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:48:15,808][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:16,231][root][INFO] - Training Epoch: 10/10, step 0/574 completed (loss: 0.12884913384914398, acc: 0.9629629850387573)
[2024-11-13 05:48:16,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:16,570][root][INFO] - Training Epoch: 10/10, step 1/574 completed (loss: 0.022442910820245743, acc: 1.0)
[2024-11-13 05:48:16,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:16,894][root][INFO] - Training Epoch: 10/10, step 2/574 completed (loss: 0.08257615566253662, acc: 0.9729729890823364)
[2024-11-13 05:48:17,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:17,305][root][INFO] - Training Epoch: 10/10, step 3/574 completed (loss: 0.011983762495219707, acc: 1.0)
[2024-11-13 05:48:17,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:17,722][root][INFO] - Training Epoch: 10/10, step 4/574 completed (loss: 0.07889353483915329, acc: 0.9729729890823364)
[2024-11-13 05:48:17,824][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:18,070][root][INFO] - Training Epoch: 10/10, step 5/574 completed (loss: 0.1076498031616211, acc: 0.9285714030265808)
[2024-11-13 05:48:18,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:18,387][root][INFO] - Training Epoch: 10/10, step 6/574 completed (loss: 0.07437226921319962, acc: 0.9795918464660645)
[2024-11-13 05:48:18,464][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:18,699][root][INFO] - Training Epoch: 10/10, step 7/574 completed (loss: 0.4106510281562805, acc: 0.8999999761581421)
[2024-11-13 05:48:18,795][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:19,088][root][INFO] - Training Epoch: 10/10, step 8/574 completed (loss: 0.0011422266252338886, acc: 1.0)
[2024-11-13 05:48:19,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:19,414][root][INFO] - Training Epoch: 10/10, step 9/574 completed (loss: 0.0008796025067567825, acc: 1.0)
[2024-11-13 05:48:19,527][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:19,802][root][INFO] - Training Epoch: 10/10, step 10/574 completed (loss: 0.004577710293233395, acc: 1.0)
[2024-11-13 05:48:19,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:20,159][root][INFO] - Training Epoch: 10/10, step 11/574 completed (loss: 0.04458973556756973, acc: 1.0)
[2024-11-13 05:48:20,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:20,452][root][INFO] - Training Epoch: 10/10, step 12/574 completed (loss: 0.000953255279455334, acc: 1.0)
[2024-11-13 05:48:20,531][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:20,759][root][INFO] - Training Epoch: 10/10, step 13/574 completed (loss: 0.013699077069759369, acc: 1.0)
[2024-11-13 05:48:20,840][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:21,067][root][INFO] - Training Epoch: 10/10, step 14/574 completed (loss: 0.05647560581564903, acc: 0.9607843160629272)
[2024-11-13 05:48:21,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:21,374][root][INFO] - Training Epoch: 10/10, step 15/574 completed (loss: 0.05294151231646538, acc: 1.0)
[2024-11-13 05:48:21,449][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:21,680][root][INFO] - Training Epoch: 10/10, step 16/574 completed (loss: 0.7336593270301819, acc: 0.9473684430122375)
[2024-11-13 05:48:21,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:21,985][root][INFO] - Training Epoch: 10/10, step 17/574 completed (loss: 0.008771119639277458, acc: 1.0)
[2024-11-13 05:48:22,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:22,342][root][INFO] - Training Epoch: 10/10, step 18/574 completed (loss: 0.08851922303438187, acc: 1.0)
[2024-11-13 05:48:22,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:22,660][root][INFO] - Training Epoch: 10/10, step 19/574 completed (loss: 0.01588289998471737, acc: 1.0)
[2024-11-13 05:48:22,738][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:22,968][root][INFO] - Training Epoch: 10/10, step 20/574 completed (loss: 0.18503838777542114, acc: 0.9615384340286255)
[2024-11-13 05:48:23,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:23,269][root][INFO] - Training Epoch: 10/10, step 21/574 completed (loss: 0.11507474631071091, acc: 0.9655172228813171)
[2024-11-13 05:48:23,352][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:23,580][root][INFO] - Training Epoch: 10/10, step 22/574 completed (loss: 0.03362900763750076, acc: 1.0)
[2024-11-13 05:48:23,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:23,869][root][INFO] - Training Epoch: 10/10, step 23/574 completed (loss: 0.019608959555625916, acc: 1.0)
[2024-11-13 05:48:23,944][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:24,161][root][INFO] - Training Epoch: 10/10, step 24/574 completed (loss: 0.115784652531147, acc: 0.9375)
[2024-11-13 05:48:24,262][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:24,494][root][INFO] - Training Epoch: 10/10, step 25/574 completed (loss: 0.09879612177610397, acc: 0.9433962106704712)
[2024-11-13 05:48:24,606][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:24,857][root][INFO] - Training Epoch: 10/10, step 26/574 completed (loss: 0.09689871221780777, acc: 0.9726027250289917)
[2024-11-13 05:48:25,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:26,308][root][INFO] - Training Epoch: 10/10, step 27/574 completed (loss: 0.556415319442749, acc: 0.8181818127632141)
[2024-11-13 05:48:26,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:26,720][root][INFO] - Training Epoch: 10/10, step 28/574 completed (loss: 0.04360654950141907, acc: 0.9767441749572754)
[2024-11-13 05:48:26,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:27,087][root][INFO] - Training Epoch: 10/10, step 29/574 completed (loss: 0.1393798291683197, acc: 0.9397590160369873)
[2024-11-13 05:48:27,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:27,387][root][INFO] - Training Epoch: 10/10, step 30/574 completed (loss: 0.11896928399801254, acc: 0.9629629850387573)
[2024-11-13 05:48:27,506][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:27,735][root][INFO] - Training Epoch: 10/10, step 31/574 completed (loss: 0.04746595025062561, acc: 1.0)
[2024-11-13 05:48:27,833][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:28,073][root][INFO] - Training Epoch: 10/10, step 32/574 completed (loss: 0.004561899695545435, acc: 1.0)
[2024-11-13 05:48:28,154][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:28,385][root][INFO] - Training Epoch: 10/10, step 33/574 completed (loss: 0.0180270504206419, acc: 1.0)
[2024-11-13 05:48:28,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:28,713][root][INFO] - Training Epoch: 10/10, step 34/574 completed (loss: 0.18169578909873962, acc: 0.9411764740943909)
[2024-11-13 05:48:28,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:29,074][root][INFO] - Training Epoch: 10/10, step 35/574 completed (loss: 0.04277506843209267, acc: 1.0)
[2024-11-13 05:48:29,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:29,455][root][INFO] - Training Epoch: 10/10, step 36/574 completed (loss: 0.16649968922138214, acc: 0.9523809552192688)
[2024-11-13 05:48:29,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:29,800][root][INFO] - Training Epoch: 10/10, step 37/574 completed (loss: 0.12688568234443665, acc: 0.9830508232116699)
[2024-11-13 05:48:29,915][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:30,161][root][INFO] - Training Epoch: 10/10, step 38/574 completed (loss: 0.0958513617515564, acc: 0.9655172228813171)
[2024-11-13 05:48:30,243][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:30,476][root][INFO] - Training Epoch: 10/10, step 39/574 completed (loss: 0.034856878221035004, acc: 1.0)
[2024-11-13 05:48:30,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:30,773][root][INFO] - Training Epoch: 10/10, step 40/574 completed (loss: 0.06698758900165558, acc: 1.0)
[2024-11-13 05:48:30,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:31,146][root][INFO] - Training Epoch: 10/10, step 41/574 completed (loss: 0.11881373077630997, acc: 0.9594594836235046)
[2024-11-13 05:48:31,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:31,479][root][INFO] - Training Epoch: 10/10, step 42/574 completed (loss: 0.11888660490512848, acc: 0.9692307710647583)
[2024-11-13 05:48:31,590][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:31,894][root][INFO] - Training Epoch: 10/10, step 43/574 completed (loss: 0.19847220182418823, acc: 0.9191918969154358)
[2024-11-13 05:48:31,994][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:32,275][root][INFO] - Training Epoch: 10/10, step 44/574 completed (loss: 0.11427407711744308, acc: 0.969072163105011)
[2024-11-13 05:48:32,374][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:32,672][root][INFO] - Training Epoch: 10/10, step 45/574 completed (loss: 0.14761416614055634, acc: 0.9411764740943909)
[2024-11-13 05:48:32,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:33,015][root][INFO] - Training Epoch: 10/10, step 46/574 completed (loss: 0.05074959993362427, acc: 1.0)
[2024-11-13 05:48:33,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:33,332][root][INFO] - Training Epoch: 10/10, step 47/574 completed (loss: 0.15684455633163452, acc: 0.9629629850387573)
[2024-11-13 05:48:33,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:33,641][root][INFO] - Training Epoch: 10/10, step 48/574 completed (loss: 0.05932244285941124, acc: 0.9642857313156128)
[2024-11-13 05:48:33,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:33,946][root][INFO] - Training Epoch: 10/10, step 49/574 completed (loss: 0.007186666131019592, acc: 1.0)
[2024-11-13 05:48:34,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:34,296][root][INFO] - Training Epoch: 10/10, step 50/574 completed (loss: 0.1963815540075302, acc: 0.9298245906829834)
[2024-11-13 05:48:34,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:34,615][root][INFO] - Training Epoch: 10/10, step 51/574 completed (loss: 0.10194158554077148, acc: 0.9682539701461792)
[2024-11-13 05:48:34,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:34,957][root][INFO] - Training Epoch: 10/10, step 52/574 completed (loss: 0.20667904615402222, acc: 0.9154929518699646)
[2024-11-13 05:48:35,073][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:35,407][root][INFO] - Training Epoch: 10/10, step 53/574 completed (loss: 0.6650802493095398, acc: 0.753333330154419)
[2024-11-13 05:48:35,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:35,748][root][INFO] - Training Epoch: 10/10, step 54/574 completed (loss: 0.08285469561815262, acc: 0.9459459185600281)
[2024-11-13 05:48:35,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:36,066][root][INFO] - Training Epoch: 10/10, step 55/574 completed (loss: 0.027748188003897667, acc: 1.0)
[2024-11-13 05:48:37,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:39,435][root][INFO] - Training Epoch: 10/10, step 56/574 completed (loss: 0.5259449481964111, acc: 0.8430033922195435)
[2024-11-13 05:48:39,908][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:40,770][root][INFO] - Training Epoch: 10/10, step 57/574 completed (loss: 0.9028446078300476, acc: 0.7472766637802124)
[2024-11-13 05:48:40,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:41,390][root][INFO] - Training Epoch: 10/10, step 58/574 completed (loss: 0.3248433768749237, acc: 0.8920454382896423)
[2024-11-13 05:48:41,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:41,958][root][INFO] - Training Epoch: 10/10, step 59/574 completed (loss: 0.16582053899765015, acc: 0.9485294222831726)
[2024-11-13 05:48:42,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:42,531][root][INFO] - Training Epoch: 10/10, step 60/574 completed (loss: 0.3077664375305176, acc: 0.8913043737411499)
[2024-11-13 05:48:42,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:42,939][root][INFO] - Training Epoch: 10/10, step 61/574 completed (loss: 0.3171156346797943, acc: 0.9125000238418579)
[2024-11-13 05:48:43,022][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:43,253][root][INFO] - Training Epoch: 10/10, step 62/574 completed (loss: 0.24017328023910522, acc: 0.9411764740943909)
[2024-11-13 05:48:43,336][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:43,579][root][INFO] - Training Epoch: 10/10, step 63/574 completed (loss: 0.11305292695760727, acc: 0.9444444179534912)
[2024-11-13 05:48:43,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:43,949][root][INFO] - Training Epoch: 10/10, step 64/574 completed (loss: 0.20250552892684937, acc: 0.96875)
[2024-11-13 05:48:44,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:44,265][root][INFO] - Training Epoch: 10/10, step 65/574 completed (loss: 0.005648999009281397, acc: 1.0)
[2024-11-13 05:48:44,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:44,573][root][INFO] - Training Epoch: 10/10, step 66/574 completed (loss: 0.1310015320777893, acc: 0.9464285969734192)
[2024-11-13 05:48:44,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:44,893][root][INFO] - Training Epoch: 10/10, step 67/574 completed (loss: 0.12651017308235168, acc: 0.9666666388511658)
[2024-11-13 05:48:44,966][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:45,205][root][INFO] - Training Epoch: 10/10, step 68/574 completed (loss: 0.0017624828033149242, acc: 1.0)
[2024-11-13 05:48:45,279][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:45,510][root][INFO] - Training Epoch: 10/10, step 69/574 completed (loss: 0.16439057886600494, acc: 0.9444444179534912)
[2024-11-13 05:48:45,620][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:45,843][root][INFO] - Training Epoch: 10/10, step 70/574 completed (loss: 0.05977046117186546, acc: 1.0)
[2024-11-13 05:48:45,930][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:46,167][root][INFO] - Training Epoch: 10/10, step 71/574 completed (loss: 0.3707290589809418, acc: 0.875)
[2024-11-13 05:48:46,244][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:46,471][root][INFO] - Training Epoch: 10/10, step 72/574 completed (loss: 0.38001611828804016, acc: 0.9047619104385376)
[2024-11-13 05:48:46,565][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:46,808][root][INFO] - Training Epoch: 10/10, step 73/574 completed (loss: 0.7400779724121094, acc: 0.7846153974533081)
[2024-11-13 05:48:46,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:47,092][root][INFO] - Training Epoch: 10/10, step 74/574 completed (loss: 0.4332413971424103, acc: 0.8877550959587097)
[2024-11-13 05:48:47,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:47,387][root][INFO] - Training Epoch: 10/10, step 75/574 completed (loss: 0.4674435257911682, acc: 0.8656716346740723)
[2024-11-13 05:48:47,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:47,765][root][INFO] - Training Epoch: 10/10, step 76/574 completed (loss: 0.9707573652267456, acc: 0.7262773513793945)
[2024-11-13 05:48:47,841][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:48,064][root][INFO] - Training Epoch: 10/10, step 77/574 completed (loss: 0.0013333229580894113, acc: 1.0)
[2024-11-13 05:48:48,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:48,367][root][INFO] - Training Epoch: 10/10, step 78/574 completed (loss: 0.0028830065857619047, acc: 1.0)
[2024-11-13 05:48:48,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:48,667][root][INFO] - Training Epoch: 10/10, step 79/574 completed (loss: 0.03470921516418457, acc: 1.0)
[2024-11-13 05:48:48,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:48,995][root][INFO] - Training Epoch: 10/10, step 80/574 completed (loss: 0.0030387858860194683, acc: 1.0)
[2024-11-13 05:48:49,098][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:49,334][root][INFO] - Training Epoch: 10/10, step 81/574 completed (loss: 0.15349788963794708, acc: 0.942307710647583)
[2024-11-13 05:48:49,428][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:49,666][root][INFO] - Training Epoch: 10/10, step 82/574 completed (loss: 0.2471139281988144, acc: 0.9615384340286255)
[2024-11-13 05:48:49,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:49,932][root][INFO] - Training Epoch: 10/10, step 83/574 completed (loss: 0.019345538690686226, acc: 1.0)
[2024-11-13 05:48:50,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:50,219][root][INFO] - Training Epoch: 10/10, step 84/574 completed (loss: 0.05363861098885536, acc: 0.9855072498321533)
[2024-11-13 05:48:50,301][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:50,523][root][INFO] - Training Epoch: 10/10, step 85/574 completed (loss: 0.11292964220046997, acc: 0.9399999976158142)
[2024-11-13 05:48:50,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:50,870][root][INFO] - Training Epoch: 10/10, step 86/574 completed (loss: 0.018209140747785568, acc: 1.0)
[2024-11-13 05:48:50,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:51,326][root][INFO] - Training Epoch: 10/10, step 87/574 completed (loss: 0.3015190064907074, acc: 0.9200000166893005)
[2024-11-13 05:48:51,411][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:51,658][root][INFO] - Training Epoch: 10/10, step 88/574 completed (loss: 0.2492024302482605, acc: 0.9611650705337524)
[2024-11-13 05:48:52,054][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:52,811][root][INFO] - Training Epoch: 10/10, step 89/574 completed (loss: 0.5242136716842651, acc: 0.8349514603614807)
[2024-11-13 05:48:53,065][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:53,683][root][INFO] - Training Epoch: 10/10, step 90/574 completed (loss: 0.5668336153030396, acc: 0.8494623899459839)
[2024-11-13 05:48:53,890][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:54,486][root][INFO] - Training Epoch: 10/10, step 91/574 completed (loss: 0.4573630690574646, acc: 0.8620689511299133)
[2024-11-13 05:48:54,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:55,227][root][INFO] - Training Epoch: 10/10, step 92/574 completed (loss: 0.29562515020370483, acc: 0.9052631855010986)
[2024-11-13 05:48:55,496][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:56,216][root][INFO] - Training Epoch: 10/10, step 93/574 completed (loss: 0.4943088889122009, acc: 0.8316831588745117)
[2024-11-13 05:48:56,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:56,514][root][INFO] - Training Epoch: 10/10, step 94/574 completed (loss: 0.22850355505943298, acc: 0.9354838728904724)
[2024-11-13 05:48:56,618][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:56,865][root][INFO] - Training Epoch: 10/10, step 95/574 completed (loss: 0.08977289497852325, acc: 1.0)
[2024-11-13 05:48:56,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:57,189][root][INFO] - Training Epoch: 10/10, step 96/574 completed (loss: 0.27085068821907043, acc: 0.9159663915634155)
[2024-11-13 05:48:57,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:57,568][root][INFO] - Training Epoch: 10/10, step 97/574 completed (loss: 0.3574720025062561, acc: 0.8942307829856873)
[2024-11-13 05:48:57,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:57,954][root][INFO] - Training Epoch: 10/10, step 98/574 completed (loss: 0.40519118309020996, acc: 0.8613138794898987)
[2024-11-13 05:48:58,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:58,263][root][INFO] - Training Epoch: 10/10, step 99/574 completed (loss: 0.29538190364837646, acc: 0.9253731369972229)
[2024-11-13 05:48:58,339][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:58,563][root][INFO] - Training Epoch: 10/10, step 100/574 completed (loss: 0.015326401218771935, acc: 1.0)
[2024-11-13 05:48:58,634][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:58,861][root][INFO] - Training Epoch: 10/10, step 101/574 completed (loss: 0.008911767043173313, acc: 1.0)
[2024-11-13 05:48:58,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:59,158][root][INFO] - Training Epoch: 10/10, step 102/574 completed (loss: 0.013114187866449356, acc: 1.0)
[2024-11-13 05:48:59,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:59,458][root][INFO] - Training Epoch: 10/10, step 103/574 completed (loss: 0.007420840673148632, acc: 1.0)
[2024-11-13 05:48:59,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:48:59,786][root][INFO] - Training Epoch: 10/10, step 104/574 completed (loss: 0.06456726789474487, acc: 0.9655172228813171)
[2024-11-13 05:48:59,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:00,139][root][INFO] - Training Epoch: 10/10, step 105/574 completed (loss: 0.02154920995235443, acc: 1.0)
[2024-11-13 05:49:00,246][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:00,479][root][INFO] - Training Epoch: 10/10, step 106/574 completed (loss: 0.08799760043621063, acc: 0.9599999785423279)
[2024-11-13 05:49:00,567][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:00,802][root][INFO] - Training Epoch: 10/10, step 107/574 completed (loss: 0.002085284795612097, acc: 1.0)
[2024-11-13 05:49:00,906][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:01,146][root][INFO] - Training Epoch: 10/10, step 108/574 completed (loss: 0.0017760172486305237, acc: 1.0)
[2024-11-13 05:49:01,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:01,454][root][INFO] - Training Epoch: 10/10, step 109/574 completed (loss: 0.04370773583650589, acc: 1.0)
[2024-11-13 05:49:01,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:01,790][root][INFO] - Training Epoch: 10/10, step 110/574 completed (loss: 0.02442946285009384, acc: 1.0)
[2024-11-13 05:49:01,920][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:02,182][root][INFO] - Training Epoch: 10/10, step 111/574 completed (loss: 0.02397439442574978, acc: 1.0)
[2024-11-13 05:49:02,274][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:02,528][root][INFO] - Training Epoch: 10/10, step 112/574 completed (loss: 0.17959563434123993, acc: 0.9473684430122375)
[2024-11-13 05:49:02,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:02,859][root][INFO] - Training Epoch: 10/10, step 113/574 completed (loss: 0.2172619253396988, acc: 0.9230769276618958)
[2024-11-13 05:49:02,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:03,215][root][INFO] - Training Epoch: 10/10, step 114/574 completed (loss: 0.03693867102265358, acc: 0.9795918464660645)
[2024-11-13 05:49:03,291][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:03,514][root][INFO] - Training Epoch: 10/10, step 115/574 completed (loss: 0.0014300881884992123, acc: 1.0)
[2024-11-13 05:49:03,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:03,846][root][INFO] - Training Epoch: 10/10, step 116/574 completed (loss: 0.09605428576469421, acc: 0.9682539701461792)
[2024-11-13 05:49:03,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:04,206][root][INFO] - Training Epoch: 10/10, step 117/574 completed (loss: 0.15725381672382355, acc: 0.934959352016449)
[2024-11-13 05:49:04,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:04,539][root][INFO] - Training Epoch: 10/10, step 118/574 completed (loss: 0.07621753960847855, acc: 0.9677419066429138)
[2024-11-13 05:49:04,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:05,419][root][INFO] - Training Epoch: 10/10, step 119/574 completed (loss: 0.36441001296043396, acc: 0.8897338509559631)
[2024-11-13 05:49:05,500][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:05,799][root][INFO] - Training Epoch: 10/10, step 120/574 completed (loss: 0.014104445464909077, acc: 1.0)
[2024-11-13 05:49:05,954][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:06,220][root][INFO] - Training Epoch: 10/10, step 121/574 completed (loss: 0.02460065856575966, acc: 1.0)
[2024-11-13 05:49:06,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:06,542][root][INFO] - Training Epoch: 10/10, step 122/574 completed (loss: 0.001990266377106309, acc: 1.0)
[2024-11-13 05:49:06,647][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:06,879][root][INFO] - Training Epoch: 10/10, step 123/574 completed (loss: 0.010371786542236805, acc: 1.0)
[2024-11-13 05:49:06,971][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:07,211][root][INFO] - Training Epoch: 10/10, step 124/574 completed (loss: 0.38579118251800537, acc: 0.9141104221343994)
[2024-11-13 05:49:08,180][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:08,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:08,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:09,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:09,563][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:10,014][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:10,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:10,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:10,997][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:11,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:11,834][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:12,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:12,519][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:12,852][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:13,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:13,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:14,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:14,434][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:14,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:15,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:15,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:15,799][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:16,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:16,390][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:16,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:17,064][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:17,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:17,923][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:18,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:18,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:19,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:19,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:19,749][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:20,004][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:20,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:20,767][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:21,148][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:21,525][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:21,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:22,222][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:22,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:22,912][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:23,204][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:23,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:24,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:24,399][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:24,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:25,159][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:25,529][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:25,823][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:26,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:26,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:26,733][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:27,024][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:27,287][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:27,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:27,873][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:28,103][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:28,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:28,871][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:29,213][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:29,694][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:30,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:30,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:30,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:31,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:31,468][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:31,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:32,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:32,689][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:33,017][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:33,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:33,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:34,053][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:34,406][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:34,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:35,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:35,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:35,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:36,079][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:36,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:36,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:36,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:37,247][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:37,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:38,309][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6824, device='cuda:0') eval_epoch_loss=tensor(0.9867, device='cuda:0') eval_epoch_acc=tensor(0.8052, device='cuda:0')
[2024-11-13 05:49:38,310][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:49:38,311][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:49:38,640][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_10_step_125_loss_0.9867203831672668/model.pt
[2024-11-13 05:49:38,643][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:49:38,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:39,061][root][INFO] - Training Epoch: 10/10, step 125/574 completed (loss: 0.4761435091495514, acc: 0.8472222089767456)
[2024-11-13 05:49:39,175][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:39,475][root][INFO] - Training Epoch: 10/10, step 126/574 completed (loss: 0.3910733759403229, acc: 0.8833333253860474)
[2024-11-13 05:49:39,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:39,822][root][INFO] - Training Epoch: 10/10, step 127/574 completed (loss: 0.3421304225921631, acc: 0.9107142686843872)
[2024-11-13 05:49:39,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:40,161][root][INFO] - Training Epoch: 10/10, step 128/574 completed (loss: 0.3327871561050415, acc: 0.892307698726654)
[2024-11-13 05:49:40,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:40,556][root][INFO] - Training Epoch: 10/10, step 129/574 completed (loss: 0.3149888813495636, acc: 0.875)
[2024-11-13 05:49:40,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:40,878][root][INFO] - Training Epoch: 10/10, step 130/574 completed (loss: 0.007132797501981258, acc: 1.0)
[2024-11-13 05:49:40,951][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:41,162][root][INFO] - Training Epoch: 10/10, step 131/574 completed (loss: 0.09460247308015823, acc: 0.95652174949646)
[2024-11-13 05:49:41,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:41,465][root][INFO] - Training Epoch: 10/10, step 132/574 completed (loss: 0.06518106907606125, acc: 0.96875)
[2024-11-13 05:49:41,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:41,764][root][INFO] - Training Epoch: 10/10, step 133/574 completed (loss: 0.08068962395191193, acc: 0.95652174949646)
[2024-11-13 05:49:41,847][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:42,075][root][INFO] - Training Epoch: 10/10, step 134/574 completed (loss: 0.14386063814163208, acc: 0.9714285731315613)
[2024-11-13 05:49:42,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:42,370][root][INFO] - Training Epoch: 10/10, step 135/574 completed (loss: 0.01861662045121193, acc: 1.0)
[2024-11-13 05:49:42,442][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:42,666][root][INFO] - Training Epoch: 10/10, step 136/574 completed (loss: 0.04340149834752083, acc: 0.976190447807312)
[2024-11-13 05:49:42,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:42,964][root][INFO] - Training Epoch: 10/10, step 137/574 completed (loss: 0.04969573765993118, acc: 1.0)
[2024-11-13 05:49:43,066][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:43,303][root][INFO] - Training Epoch: 10/10, step 138/574 completed (loss: 0.013679097406566143, acc: 1.0)
[2024-11-13 05:49:43,382][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:43,609][root][INFO] - Training Epoch: 10/10, step 139/574 completed (loss: 0.021287625655531883, acc: 1.0)
[2024-11-13 05:49:43,718][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:43,958][root][INFO] - Training Epoch: 10/10, step 140/574 completed (loss: 0.12211763858795166, acc: 0.9230769276618958)
[2024-11-13 05:49:44,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:44,242][root][INFO] - Training Epoch: 10/10, step 141/574 completed (loss: 0.16858631372451782, acc: 0.9354838728904724)
[2024-11-13 05:49:44,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:44,513][root][INFO] - Training Epoch: 10/10, step 142/574 completed (loss: 0.110711008310318, acc: 0.9459459185600281)
[2024-11-13 05:49:44,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:45,032][root][INFO] - Training Epoch: 10/10, step 143/574 completed (loss: 0.2795915901660919, acc: 0.9210526347160339)
[2024-11-13 05:49:45,128][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:45,377][root][INFO] - Training Epoch: 10/10, step 144/574 completed (loss: 0.36972159147262573, acc: 0.8731343150138855)
[2024-11-13 05:49:45,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:45,720][root][INFO] - Training Epoch: 10/10, step 145/574 completed (loss: 0.17195892333984375, acc: 0.9489796161651611)
[2024-11-13 05:49:45,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:46,155][root][INFO] - Training Epoch: 10/10, step 146/574 completed (loss: 0.28147751092910767, acc: 0.9042553305625916)
[2024-11-13 05:49:46,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:46,459][root][INFO] - Training Epoch: 10/10, step 147/574 completed (loss: 0.10764501988887787, acc: 0.9571428298950195)
[2024-11-13 05:49:46,540][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:46,763][root][INFO] - Training Epoch: 10/10, step 148/574 completed (loss: 0.02252356894314289, acc: 1.0)
[2024-11-13 05:49:46,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:47,050][root][INFO] - Training Epoch: 10/10, step 149/574 completed (loss: 0.2531391382217407, acc: 0.9130434989929199)
[2024-11-13 05:49:47,126][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:47,401][root][INFO] - Training Epoch: 10/10, step 150/574 completed (loss: 0.1830558329820633, acc: 0.931034505367279)
[2024-11-13 05:49:47,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:47,738][root][INFO] - Training Epoch: 10/10, step 151/574 completed (loss: 0.083529531955719, acc: 0.97826087474823)
[2024-11-13 05:49:47,829][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:48,079][root][INFO] - Training Epoch: 10/10, step 152/574 completed (loss: 0.09548542648553848, acc: 0.9491525292396545)
[2024-11-13 05:49:48,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:48,398][root][INFO] - Training Epoch: 10/10, step 153/574 completed (loss: 0.2430127114057541, acc: 0.9473684430122375)
[2024-11-13 05:49:48,485][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:48,711][root][INFO] - Training Epoch: 10/10, step 154/574 completed (loss: 0.1962197721004486, acc: 0.9594594836235046)
[2024-11-13 05:49:48,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:49,005][root][INFO] - Training Epoch: 10/10, step 155/574 completed (loss: 0.08885826915502548, acc: 0.9642857313156128)
[2024-11-13 05:49:49,082][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:49,303][root][INFO] - Training Epoch: 10/10, step 156/574 completed (loss: 0.161941796541214, acc: 0.9130434989929199)
[2024-11-13 05:49:49,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:49,592][root][INFO] - Training Epoch: 10/10, step 157/574 completed (loss: 0.17056189477443695, acc: 0.9473684430122375)
[2024-11-13 05:49:50,324][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:51,336][root][INFO] - Training Epoch: 10/10, step 158/574 completed (loss: 0.35143938660621643, acc: 0.9189189076423645)
[2024-11-13 05:49:51,424][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:51,592][root][INFO] - Training Epoch: 10/10, step 159/574 completed (loss: 0.49002671241760254, acc: 0.8148148059844971)
[2024-11-13 05:49:51,700][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:51,990][root][INFO] - Training Epoch: 10/10, step 160/574 completed (loss: 0.3222882151603699, acc: 0.8837209343910217)
[2024-11-13 05:49:52,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:52,584][root][INFO] - Training Epoch: 10/10, step 161/574 completed (loss: 0.32946109771728516, acc: 0.929411768913269)
[2024-11-13 05:49:52,725][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:53,143][root][INFO] - Training Epoch: 10/10, step 162/574 completed (loss: 0.34861883521080017, acc: 0.9213483333587646)
[2024-11-13 05:49:53,228][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:53,458][root][INFO] - Training Epoch: 10/10, step 163/574 completed (loss: 0.06917224079370499, acc: 0.9772727489471436)
[2024-11-13 05:49:53,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:53,745][root][INFO] - Training Epoch: 10/10, step 164/574 completed (loss: 0.08393502980470657, acc: 0.9523809552192688)
[2024-11-13 05:49:53,821][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:54,035][root][INFO] - Training Epoch: 10/10, step 165/574 completed (loss: 0.31214237213134766, acc: 0.9655172228813171)
[2024-11-13 05:49:54,157][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:54,394][root][INFO] - Training Epoch: 10/10, step 166/574 completed (loss: 0.01823422499001026, acc: 1.0)
[2024-11-13 05:49:54,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:54,711][root][INFO] - Training Epoch: 10/10, step 167/574 completed (loss: 0.01662416383624077, acc: 1.0)
[2024-11-13 05:49:54,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:55,073][root][INFO] - Training Epoch: 10/10, step 168/574 completed (loss: 0.12645994126796722, acc: 0.9166666865348816)
[2024-11-13 05:49:55,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:55,394][root][INFO] - Training Epoch: 10/10, step 169/574 completed (loss: 0.42264267802238464, acc: 0.8725489974021912)
[2024-11-13 05:49:55,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:56,452][root][INFO] - Training Epoch: 10/10, step 170/574 completed (loss: 0.20958435535430908, acc: 0.931506872177124)
[2024-11-13 05:49:56,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:56,783][root][INFO] - Training Epoch: 10/10, step 171/574 completed (loss: 0.00639498233795166, acc: 1.0)
[2024-11-13 05:49:56,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:57,127][root][INFO] - Training Epoch: 10/10, step 172/574 completed (loss: 0.010073023848235607, acc: 1.0)
[2024-11-13 05:49:57,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:57,454][root][INFO] - Training Epoch: 10/10, step 173/574 completed (loss: 0.054943233728408813, acc: 0.9642857313156128)
[2024-11-13 05:49:57,587][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:57,992][root][INFO] - Training Epoch: 10/10, step 174/574 completed (loss: 0.4861608147621155, acc: 0.8761062026023865)
[2024-11-13 05:49:58,069][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:58,303][root][INFO] - Training Epoch: 10/10, step 175/574 completed (loss: 0.19497597217559814, acc: 0.9420289993286133)
[2024-11-13 05:49:58,414][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:58,646][root][INFO] - Training Epoch: 10/10, step 176/574 completed (loss: 0.17505700886249542, acc: 0.9204545617103577)
[2024-11-13 05:49:58,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:49:59,563][root][INFO] - Training Epoch: 10/10, step 177/574 completed (loss: 0.3437853157520294, acc: 0.8702290058135986)
[2024-11-13 05:49:59,739][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:00,235][root][INFO] - Training Epoch: 10/10, step 178/574 completed (loss: 0.41153889894485474, acc: 0.8666666746139526)
[2024-11-13 05:50:00,338][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:00,588][root][INFO] - Training Epoch: 10/10, step 179/574 completed (loss: 0.11772129684686661, acc: 0.9672130942344666)
[2024-11-13 05:50:00,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:00,942][root][INFO] - Training Epoch: 10/10, step 180/574 completed (loss: 0.005196089390665293, acc: 1.0)
[2024-11-13 05:50:01,061][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:01,313][root][INFO] - Training Epoch: 10/10, step 181/574 completed (loss: 0.013951645232737064, acc: 1.0)
[2024-11-13 05:50:01,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:01,626][root][INFO] - Training Epoch: 10/10, step 182/574 completed (loss: 0.00474120257422328, acc: 1.0)
[2024-11-13 05:50:01,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:01,947][root][INFO] - Training Epoch: 10/10, step 183/574 completed (loss: 0.016322296112775803, acc: 1.0)
[2024-11-13 05:50:02,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:02,333][root][INFO] - Training Epoch: 10/10, step 184/574 completed (loss: 0.2841457724571228, acc: 0.9244713187217712)
[2024-11-13 05:50:02,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:02,717][root][INFO] - Training Epoch: 10/10, step 185/574 completed (loss: 0.3839167654514313, acc: 0.878962516784668)
[2024-11-13 05:50:02,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:03,206][root][INFO] - Training Epoch: 10/10, step 186/574 completed (loss: 0.311029851436615, acc: 0.878125011920929)
[2024-11-13 05:50:03,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:03,732][root][INFO] - Training Epoch: 10/10, step 187/574 completed (loss: 0.48406076431274414, acc: 0.8574109077453613)
[2024-11-13 05:50:03,870][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:04,131][root][INFO] - Training Epoch: 10/10, step 188/574 completed (loss: 0.39119383692741394, acc: 0.8612099885940552)
[2024-11-13 05:50:04,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:04,400][root][INFO] - Training Epoch: 10/10, step 189/574 completed (loss: 0.1359165608882904, acc: 0.9599999785423279)
[2024-11-13 05:50:04,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:04,946][root][INFO] - Training Epoch: 10/10, step 190/574 completed (loss: 0.18505588173866272, acc: 0.9418604373931885)
[2024-11-13 05:50:05,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:05,740][root][INFO] - Training Epoch: 10/10, step 191/574 completed (loss: 0.5131867527961731, acc: 0.8650793433189392)
[2024-11-13 05:50:05,999][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:06,655][root][INFO] - Training Epoch: 10/10, step 192/574 completed (loss: 0.39573362469673157, acc: 0.9090909361839294)
[2024-11-13 05:50:06,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:07,400][root][INFO] - Training Epoch: 10/10, step 193/574 completed (loss: 0.124598927795887, acc: 0.9529411792755127)
[2024-11-13 05:50:07,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:08,477][root][INFO] - Training Epoch: 10/10, step 194/574 completed (loss: 0.45302048325538635, acc: 0.8827160596847534)
[2024-11-13 05:50:08,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:09,430][root][INFO] - Training Epoch: 10/10, step 195/574 completed (loss: 0.13326361775398254, acc: 0.9354838728904724)
[2024-11-13 05:50:09,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:09,797][root][INFO] - Training Epoch: 10/10, step 196/574 completed (loss: 0.005375896114856005, acc: 1.0)
[2024-11-13 05:50:09,888][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:10,153][root][INFO] - Training Epoch: 10/10, step 197/574 completed (loss: 0.14558053016662598, acc: 0.9750000238418579)
[2024-11-13 05:50:10,267][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:10,483][root][INFO] - Training Epoch: 10/10, step 198/574 completed (loss: 0.1366092413663864, acc: 0.9558823704719543)
[2024-11-13 05:50:10,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:10,887][root][INFO] - Training Epoch: 10/10, step 199/574 completed (loss: 0.23803511261940002, acc: 0.904411792755127)
[2024-11-13 05:50:11,005][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:11,254][root][INFO] - Training Epoch: 10/10, step 200/574 completed (loss: 0.32572996616363525, acc: 0.8983050584793091)
[2024-11-13 05:50:11,343][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:11,612][root][INFO] - Training Epoch: 10/10, step 201/574 completed (loss: 0.2948620319366455, acc: 0.89552241563797)
[2024-11-13 05:50:11,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:12,024][root][INFO] - Training Epoch: 10/10, step 202/574 completed (loss: 0.2417253702878952, acc: 0.9223300814628601)
[2024-11-13 05:50:12,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:12,353][root][INFO] - Training Epoch: 10/10, step 203/574 completed (loss: 0.15784819424152374, acc: 0.9523809552192688)
[2024-11-13 05:50:12,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:12,699][root][INFO] - Training Epoch: 10/10, step 204/574 completed (loss: 0.01698247902095318, acc: 1.0)
[2024-11-13 05:50:12,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:13,031][root][INFO] - Training Epoch: 10/10, step 205/574 completed (loss: 0.13555315136909485, acc: 0.9596412777900696)
[2024-11-13 05:50:13,171][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:13,430][root][INFO] - Training Epoch: 10/10, step 206/574 completed (loss: 0.19556976854801178, acc: 0.9409449100494385)
[2024-11-13 05:50:13,545][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:13,833][root][INFO] - Training Epoch: 10/10, step 207/574 completed (loss: 0.12412048131227493, acc: 0.9612069129943848)
[2024-11-13 05:50:13,981][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:14,247][root][INFO] - Training Epoch: 10/10, step 208/574 completed (loss: 0.2213655263185501, acc: 0.9420289993286133)
[2024-11-13 05:50:14,364][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:14,613][root][INFO] - Training Epoch: 10/10, step 209/574 completed (loss: 0.22097240388393402, acc: 0.9416342377662659)
[2024-11-13 05:50:14,704][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:14,990][root][INFO] - Training Epoch: 10/10, step 210/574 completed (loss: 0.10128908604383469, acc: 0.95652174949646)
[2024-11-13 05:50:15,110][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:15,379][root][INFO] - Training Epoch: 10/10, step 211/574 completed (loss: 0.01707570254802704, acc: 1.0)
[2024-11-13 05:50:15,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:15,737][root][INFO] - Training Epoch: 10/10, step 212/574 completed (loss: 0.011051996611058712, acc: 1.0)
[2024-11-13 05:50:15,865][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:16,119][root][INFO] - Training Epoch: 10/10, step 213/574 completed (loss: 0.052883706986904144, acc: 0.978723406791687)
[2024-11-13 05:50:16,327][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:16,850][root][INFO] - Training Epoch: 10/10, step 214/574 completed (loss: 0.0915607362985611, acc: 0.9692307710647583)
[2024-11-13 05:50:16,960][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:17,197][root][INFO] - Training Epoch: 10/10, step 215/574 completed (loss: 0.025872737169265747, acc: 1.0)
[2024-11-13 05:50:17,320][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:17,585][root][INFO] - Training Epoch: 10/10, step 216/574 completed (loss: 0.02232680283486843, acc: 0.9883720874786377)
[2024-11-13 05:50:17,737][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:18,124][root][INFO] - Training Epoch: 10/10, step 217/574 completed (loss: 0.07757255434989929, acc: 0.9729729890823364)
[2024-11-13 05:50:18,229][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:18,511][root][INFO] - Training Epoch: 10/10, step 218/574 completed (loss: 0.06309037655591965, acc: 0.9666666388511658)
[2024-11-13 05:50:18,635][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:18,880][root][INFO] - Training Epoch: 10/10, step 219/574 completed (loss: 0.033999253064394, acc: 1.0)
[2024-11-13 05:50:18,976][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:19,215][root][INFO] - Training Epoch: 10/10, step 220/574 completed (loss: 0.003465130925178528, acc: 1.0)
[2024-11-13 05:50:19,310][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:19,560][root][INFO] - Training Epoch: 10/10, step 221/574 completed (loss: 0.09390544891357422, acc: 0.9599999785423279)
[2024-11-13 05:50:19,676][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:19,932][root][INFO] - Training Epoch: 10/10, step 222/574 completed (loss: 0.18025033175945282, acc: 0.9615384340286255)
[2024-11-13 05:50:20,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:20,767][root][INFO] - Training Epoch: 10/10, step 223/574 completed (loss: 0.1658538430929184, acc: 0.95652174949646)
[2024-11-13 05:50:20,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:21,304][root][INFO] - Training Epoch: 10/10, step 224/574 completed (loss: 0.2350587248802185, acc: 0.9261363744735718)
[2024-11-13 05:50:21,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:21,735][root][INFO] - Training Epoch: 10/10, step 225/574 completed (loss: 0.40671592950820923, acc: 0.8936170339584351)
[2024-11-13 05:50:21,863][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:22,119][root][INFO] - Training Epoch: 10/10, step 226/574 completed (loss: 0.0680432841181755, acc: 0.9622641801834106)
[2024-11-13 05:50:22,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:22,509][root][INFO] - Training Epoch: 10/10, step 227/574 completed (loss: 0.10761924833059311, acc: 0.9833333492279053)
[2024-11-13 05:50:22,631][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:22,888][root][INFO] - Training Epoch: 10/10, step 228/574 completed (loss: 0.11474393308162689, acc: 0.9534883499145508)
[2024-11-13 05:50:22,988][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:23,223][root][INFO] - Training Epoch: 10/10, step 229/574 completed (loss: 0.038033533841371536, acc: 1.0)
[2024-11-13 05:50:23,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:23,667][root][INFO] - Training Epoch: 10/10, step 230/574 completed (loss: 0.44644081592559814, acc: 0.8526315689086914)
[2024-11-13 05:50:23,777][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:24,063][root][INFO] - Training Epoch: 10/10, step 231/574 completed (loss: 0.3925762176513672, acc: 0.8666666746139526)
[2024-11-13 05:50:24,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:24,510][root][INFO] - Training Epoch: 10/10, step 232/574 completed (loss: 0.6205261945724487, acc: 0.7777777910232544)
[2024-11-13 05:50:24,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:24,999][root][INFO] - Training Epoch: 10/10, step 233/574 completed (loss: 0.9321633577346802, acc: 0.7018348574638367)
[2024-11-13 05:50:25,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:25,470][root][INFO] - Training Epoch: 10/10, step 234/574 completed (loss: 0.422305703163147, acc: 0.8384615182876587)
[2024-11-13 05:50:25,551][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:25,801][root][INFO] - Training Epoch: 10/10, step 235/574 completed (loss: 0.003996079321950674, acc: 1.0)
[2024-11-13 05:50:25,868][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:26,131][root][INFO] - Training Epoch: 10/10, step 236/574 completed (loss: 0.2866964638233185, acc: 0.9583333134651184)
[2024-11-13 05:50:26,235][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:26,466][root][INFO] - Training Epoch: 10/10, step 237/574 completed (loss: 0.015248416922986507, acc: 1.0)
[2024-11-13 05:50:26,556][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:26,756][root][INFO] - Training Epoch: 10/10, step 238/574 completed (loss: 0.13866616785526276, acc: 0.9629629850387573)
[2024-11-13 05:50:26,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:27,122][root][INFO] - Training Epoch: 10/10, step 239/574 completed (loss: 0.06098068132996559, acc: 0.9714285731315613)
[2024-11-13 05:50:27,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:27,530][root][INFO] - Training Epoch: 10/10, step 240/574 completed (loss: 0.19053946435451508, acc: 0.9318181872367859)
[2024-11-13 05:50:27,636][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:27,891][root][INFO] - Training Epoch: 10/10, step 241/574 completed (loss: 0.05620180442929268, acc: 0.9772727489471436)
[2024-11-13 05:50:28,060][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:28,484][root][INFO] - Training Epoch: 10/10, step 242/574 completed (loss: 0.3127899169921875, acc: 0.9193548560142517)
[2024-11-13 05:50:28,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:29,011][root][INFO] - Training Epoch: 10/10, step 243/574 completed (loss: 0.11360184848308563, acc: 0.9318181872367859)
[2024-11-13 05:50:29,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:29,345][root][INFO] - Training Epoch: 10/10, step 244/574 completed (loss: 0.0006600258639082313, acc: 1.0)
[2024-11-13 05:50:29,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:29,721][root][INFO] - Training Epoch: 10/10, step 245/574 completed (loss: 0.06504107266664505, acc: 0.9615384340286255)
[2024-11-13 05:50:29,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:30,053][root][INFO] - Training Epoch: 10/10, step 246/574 completed (loss: 0.006902084685862064, acc: 1.0)
[2024-11-13 05:50:30,129][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:30,332][root][INFO] - Training Epoch: 10/10, step 247/574 completed (loss: 0.0015143672935664654, acc: 1.0)
[2024-11-13 05:50:30,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:30,741][root][INFO] - Training Epoch: 10/10, step 248/574 completed (loss: 0.006044274661689997, acc: 1.0)
[2024-11-13 05:50:30,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:31,112][root][INFO] - Training Epoch: 10/10, step 249/574 completed (loss: 0.04097120836377144, acc: 0.9729729890823364)
[2024-11-13 05:50:31,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:31,501][root][INFO] - Training Epoch: 10/10, step 250/574 completed (loss: 0.0583951473236084, acc: 0.9729729890823364)
[2024-11-13 05:50:31,638][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:31,840][root][INFO] - Training Epoch: 10/10, step 251/574 completed (loss: 0.016283763572573662, acc: 1.0)
[2024-11-13 05:50:31,940][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:32,140][root][INFO] - Training Epoch: 10/10, step 252/574 completed (loss: 0.011948080733418465, acc: 1.0)
[2024-11-13 05:50:32,214][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:32,448][root][INFO] - Training Epoch: 10/10, step 253/574 completed (loss: 0.015538942068815231, acc: 1.0)
[2024-11-13 05:50:32,552][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:32,807][root][INFO] - Training Epoch: 10/10, step 254/574 completed (loss: 0.0008480346878059208, acc: 1.0)
[2024-11-13 05:50:32,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:33,144][root][INFO] - Training Epoch: 10/10, step 255/574 completed (loss: 0.015821781009435654, acc: 1.0)
[2024-11-13 05:50:33,238][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:33,505][root][INFO] - Training Epoch: 10/10, step 256/574 completed (loss: 0.0744028091430664, acc: 0.9473684430122375)
[2024-11-13 05:50:33,585][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:33,837][root][INFO] - Training Epoch: 10/10, step 257/574 completed (loss: 0.02021501585841179, acc: 1.0)
[2024-11-13 05:50:33,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:34,177][root][INFO] - Training Epoch: 10/10, step 258/574 completed (loss: 0.03720993548631668, acc: 0.9868420958518982)
[2024-11-13 05:50:34,351][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:34,770][root][INFO] - Training Epoch: 10/10, step 259/574 completed (loss: 0.0473359115421772, acc: 0.9905660152435303)
[2024-11-13 05:50:34,910][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:35,348][root][INFO] - Training Epoch: 10/10, step 260/574 completed (loss: 0.25605443120002747, acc: 0.8999999761581421)
[2024-11-13 05:50:35,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:35,704][root][INFO] - Training Epoch: 10/10, step 261/574 completed (loss: 0.06810437142848969, acc: 0.9722222089767456)
[2024-11-13 05:50:35,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:36,084][root][INFO] - Training Epoch: 10/10, step 262/574 completed (loss: 0.009382390417158604, acc: 1.0)
[2024-11-13 05:50:36,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:36,418][root][INFO] - Training Epoch: 10/10, step 263/574 completed (loss: 0.21407288312911987, acc: 0.9066666960716248)
[2024-11-13 05:50:36,524][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:36,787][root][INFO] - Training Epoch: 10/10, step 264/574 completed (loss: 0.321925550699234, acc: 0.9583333134651184)
[2024-11-13 05:50:37,078][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:37,692][root][INFO] - Training Epoch: 10/10, step 265/574 completed (loss: 0.5102612376213074, acc: 0.8479999899864197)
[2024-11-13 05:50:37,771][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:38,060][root][INFO] - Training Epoch: 10/10, step 266/574 completed (loss: 0.34669768810272217, acc: 0.898876428604126)
[2024-11-13 05:50:38,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:38,423][root][INFO] - Training Epoch: 10/10, step 267/574 completed (loss: 0.1449352651834488, acc: 0.9729729890823364)
[2024-11-13 05:50:39,127][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:39,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:39,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:40,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:40,539][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:40,855][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:41,167][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:41,478][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:41,860][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:42,255][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:42,558][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:43,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:43,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:43,853][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:44,170][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:44,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:44,925][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:45,385][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:45,741][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:46,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:46,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:46,720][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:47,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:47,391][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:47,656][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:47,955][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:48,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:48,559][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:48,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:49,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:49,649][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:50,056][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:50,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:50,776][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:51,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:51,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:51,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:52,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:52,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:52,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:53,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:53,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:53,711][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:54,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:54,367][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:54,663][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:54,996][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:55,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:55,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:56,141][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:56,535][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:56,904][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:57,188][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:57,482][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:57,806][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:58,147][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:58,450][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:58,745][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:59,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:59,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:50:59,766][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:00,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:00,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:01,087][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:01,357][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:01,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:02,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:02,577][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:03,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:03,543][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:03,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:04,096][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:04,380][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:04,705][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:05,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:05,377][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:05,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:06,055][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:06,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:06,734][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:07,100][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:07,435][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:07,769][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:08,219][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:08,619][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:09,269][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.6012, device='cuda:0') eval_epoch_loss=tensor(0.9560, device='cuda:0') eval_epoch_acc=tensor(0.8151, device='cuda:0')
[2024-11-13 05:51:09,271][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:51:09,271][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:51:09,531][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_10_step_268_loss_0.9559765458106995/model.pt
[2024-11-13 05:51:09,537][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:51:09,701][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:10,031][root][INFO] - Training Epoch: 10/10, step 268/574 completed (loss: 0.10962511599063873, acc: 0.931034505367279)
[2024-11-13 05:51:10,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:10,344][root][INFO] - Training Epoch: 10/10, step 269/574 completed (loss: 0.0024043875746428967, acc: 1.0)
[2024-11-13 05:51:10,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:10,652][root][INFO] - Training Epoch: 10/10, step 270/574 completed (loss: 0.015089944936335087, acc: 1.0)
[2024-11-13 05:51:10,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:10,941][root][INFO] - Training Epoch: 10/10, step 271/574 completed (loss: 0.01433437131345272, acc: 1.0)
[2024-11-13 05:51:11,049][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:11,328][root][INFO] - Training Epoch: 10/10, step 272/574 completed (loss: 0.024171132594347, acc: 1.0)
[2024-11-13 05:51:11,473][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:11,737][root][INFO] - Training Epoch: 10/10, step 273/574 completed (loss: 0.20525550842285156, acc: 0.9166666865348816)
[2024-11-13 05:51:11,849][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:12,107][root][INFO] - Training Epoch: 10/10, step 274/574 completed (loss: 0.08272095769643784, acc: 0.96875)
[2024-11-13 05:51:12,227][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:12,481][root][INFO] - Training Epoch: 10/10, step 275/574 completed (loss: 0.004139403346925974, acc: 1.0)
[2024-11-13 05:51:12,573][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:12,834][root][INFO] - Training Epoch: 10/10, step 276/574 completed (loss: 0.010640764608979225, acc: 1.0)
[2024-11-13 05:51:12,928][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:13,167][root][INFO] - Training Epoch: 10/10, step 277/574 completed (loss: 0.009436305612325668, acc: 1.0)
[2024-11-13 05:51:13,253][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:13,510][root][INFO] - Training Epoch: 10/10, step 278/574 completed (loss: 0.0669151097536087, acc: 0.978723406791687)
[2024-11-13 05:51:13,628][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:13,889][root][INFO] - Training Epoch: 10/10, step 279/574 completed (loss: 0.1584460437297821, acc: 0.9166666865348816)
[2024-11-13 05:51:13,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:14,261][root][INFO] - Training Epoch: 10/10, step 280/574 completed (loss: 0.0176230501383543, acc: 1.0)
[2024-11-13 05:51:14,397][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:14,689][root][INFO] - Training Epoch: 10/10, step 281/574 completed (loss: 0.1631968915462494, acc: 0.9277108311653137)
[2024-11-13 05:51:14,822][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:15,067][root][INFO] - Training Epoch: 10/10, step 282/574 completed (loss: 0.28396016359329224, acc: 0.8981481194496155)
[2024-11-13 05:51:15,161][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:15,361][root][INFO] - Training Epoch: 10/10, step 283/574 completed (loss: 0.14328762888908386, acc: 0.9736841917037964)
[2024-11-13 05:51:15,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:15,722][root][INFO] - Training Epoch: 10/10, step 284/574 completed (loss: 0.03493230789899826, acc: 0.970588207244873)
[2024-11-13 05:51:15,850][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:16,121][root][INFO] - Training Epoch: 10/10, step 285/574 completed (loss: 0.022418804466724396, acc: 0.9750000238418579)
[2024-11-13 05:51:16,220][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:16,468][root][INFO] - Training Epoch: 10/10, step 286/574 completed (loss: 0.13691887259483337, acc: 0.953125)
[2024-11-13 05:51:16,589][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:16,837][root][INFO] - Training Epoch: 10/10, step 287/574 completed (loss: 0.1858295351266861, acc: 0.9440000057220459)
[2024-11-13 05:51:16,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:17,186][root][INFO] - Training Epoch: 10/10, step 288/574 completed (loss: 0.134210467338562, acc: 0.9560439586639404)
[2024-11-13 05:51:17,300][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:17,533][root][INFO] - Training Epoch: 10/10, step 289/574 completed (loss: 0.08878212422132492, acc: 0.95652174949646)
[2024-11-13 05:51:17,642][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:17,855][root][INFO] - Training Epoch: 10/10, step 290/574 completed (loss: 0.3638235628604889, acc: 0.9175257682800293)
[2024-11-13 05:51:17,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:18,167][root][INFO] - Training Epoch: 10/10, step 291/574 completed (loss: 0.002477404661476612, acc: 1.0)
[2024-11-13 05:51:18,232][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:18,452][root][INFO] - Training Epoch: 10/10, step 292/574 completed (loss: 0.057379309087991714, acc: 0.976190447807312)
[2024-11-13 05:51:18,576][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:18,830][root][INFO] - Training Epoch: 10/10, step 293/574 completed (loss: 0.01974429190158844, acc: 1.0)
[2024-11-13 05:51:18,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:19,293][root][INFO] - Training Epoch: 10/10, step 294/574 completed (loss: 0.08264525979757309, acc: 0.9636363387107849)
[2024-11-13 05:51:19,438][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:19,857][root][INFO] - Training Epoch: 10/10, step 295/574 completed (loss: 0.2510891258716583, acc: 0.907216489315033)
[2024-11-13 05:51:19,942][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:20,209][root][INFO] - Training Epoch: 10/10, step 296/574 completed (loss: 0.06493686884641647, acc: 0.982758641242981)
[2024-11-13 05:51:20,328][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:20,559][root][INFO] - Training Epoch: 10/10, step 297/574 completed (loss: 0.02091871201992035, acc: 1.0)
[2024-11-13 05:51:20,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:20,866][root][INFO] - Training Epoch: 10/10, step 298/574 completed (loss: 0.04230055958032608, acc: 1.0)
[2024-11-13 05:51:20,957][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:21,242][root][INFO] - Training Epoch: 10/10, step 299/574 completed (loss: 0.06639913469552994, acc: 0.9821428656578064)
[2024-11-13 05:51:21,358][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:21,602][root][INFO] - Training Epoch: 10/10, step 300/574 completed (loss: 0.014698166400194168, acc: 1.0)
[2024-11-13 05:51:21,708][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:21,941][root][INFO] - Training Epoch: 10/10, step 301/574 completed (loss: 0.04145301133394241, acc: 0.9811320900917053)
[2024-11-13 05:51:22,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:22,252][root][INFO] - Training Epoch: 10/10, step 302/574 completed (loss: 0.005213064607232809, acc: 1.0)
[2024-11-13 05:51:22,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:22,592][root][INFO] - Training Epoch: 10/10, step 303/574 completed (loss: 0.004574433900415897, acc: 1.0)
[2024-11-13 05:51:22,702][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:22,947][root][INFO] - Training Epoch: 10/10, step 304/574 completed (loss: 0.047112155705690384, acc: 0.96875)
[2024-11-13 05:51:23,081][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:23,331][root][INFO] - Training Epoch: 10/10, step 305/574 completed (loss: 0.042707450687885284, acc: 0.9836065769195557)
[2024-11-13 05:51:23,425][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:23,646][root][INFO] - Training Epoch: 10/10, step 306/574 completed (loss: 0.03511654585599899, acc: 1.0)
[2024-11-13 05:51:23,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:23,954][root][INFO] - Training Epoch: 10/10, step 307/574 completed (loss: 0.003550856141373515, acc: 1.0)
[2024-11-13 05:51:24,070][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:24,293][root][INFO] - Training Epoch: 10/10, step 308/574 completed (loss: 0.040666744112968445, acc: 0.9855072498321533)
[2024-11-13 05:51:24,408][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:24,709][root][INFO] - Training Epoch: 10/10, step 309/574 completed (loss: 0.018805086612701416, acc: 1.0)
[2024-11-13 05:51:24,796][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:25,005][root][INFO] - Training Epoch: 10/10, step 310/574 completed (loss: 0.030255550518631935, acc: 0.9879518151283264)
[2024-11-13 05:51:25,123][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:25,322][root][INFO] - Training Epoch: 10/10, step 311/574 completed (loss: 0.07948819547891617, acc: 0.9743589758872986)
[2024-11-13 05:51:25,462][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:25,703][root][INFO] - Training Epoch: 10/10, step 312/574 completed (loss: 0.14811398088932037, acc: 0.9693877696990967)
[2024-11-13 05:51:25,787][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:26,005][root][INFO] - Training Epoch: 10/10, step 313/574 completed (loss: 0.0021704260725528, acc: 1.0)
[2024-11-13 05:51:26,094][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:26,337][root][INFO] - Training Epoch: 10/10, step 314/574 completed (loss: 0.0013712042709812522, acc: 1.0)
[2024-11-13 05:51:26,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:26,678][root][INFO] - Training Epoch: 10/10, step 315/574 completed (loss: 0.047846030443906784, acc: 0.9677419066429138)
[2024-11-13 05:51:26,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:27,054][root][INFO] - Training Epoch: 10/10, step 316/574 completed (loss: 0.20627546310424805, acc: 0.9032257795333862)
[2024-11-13 05:51:27,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:27,412][root][INFO] - Training Epoch: 10/10, step 317/574 completed (loss: 0.08087318390607834, acc: 0.9701492786407471)
[2024-11-13 05:51:27,499][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:27,729][root][INFO] - Training Epoch: 10/10, step 318/574 completed (loss: 0.037043411284685135, acc: 0.9903846383094788)
[2024-11-13 05:51:27,810][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:28,038][root][INFO] - Training Epoch: 10/10, step 319/574 completed (loss: 0.007044575642794371, acc: 1.0)
[2024-11-13 05:51:28,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:28,333][root][INFO] - Training Epoch: 10/10, step 320/574 completed (loss: 0.004735890310257673, acc: 1.0)
[2024-11-13 05:51:28,426][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:28,686][root][INFO] - Training Epoch: 10/10, step 321/574 completed (loss: 0.04753917083144188, acc: 0.9800000190734863)
[2024-11-13 05:51:28,793][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:29,027][root][INFO] - Training Epoch: 10/10, step 322/574 completed (loss: 0.09518452733755112, acc: 0.9629629850387573)
[2024-11-13 05:51:29,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:29,399][root][INFO] - Training Epoch: 10/10, step 323/574 completed (loss: 0.14122721552848816, acc: 0.9142857193946838)
[2024-11-13 05:51:29,520][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:29,718][root][INFO] - Training Epoch: 10/10, step 324/574 completed (loss: 0.2889305055141449, acc: 0.8717948794364929)
[2024-11-13 05:51:29,835][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:30,073][root][INFO] - Training Epoch: 10/10, step 325/574 completed (loss: 0.45239871740341187, acc: 0.8292682766914368)
[2024-11-13 05:51:30,190][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:30,417][root][INFO] - Training Epoch: 10/10, step 326/574 completed (loss: 0.12905696034431458, acc: 0.9736841917037964)
[2024-11-13 05:51:30,493][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:30,732][root][INFO] - Training Epoch: 10/10, step 327/574 completed (loss: 0.03334806486964226, acc: 1.0)
[2024-11-13 05:51:30,869][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:31,117][root][INFO] - Training Epoch: 10/10, step 328/574 completed (loss: 0.003504845080897212, acc: 1.0)
[2024-11-13 05:51:31,221][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:31,486][root][INFO] - Training Epoch: 10/10, step 329/574 completed (loss: 0.03155173733830452, acc: 1.0)
[2024-11-13 05:51:31,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:31,863][root][INFO] - Training Epoch: 10/10, step 330/574 completed (loss: 0.011000462807714939, acc: 1.0)
[2024-11-13 05:51:31,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:32,235][root][INFO] - Training Epoch: 10/10, step 331/574 completed (loss: 0.013982167467474937, acc: 1.0)
[2024-11-13 05:51:32,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:32,628][root][INFO] - Training Epoch: 10/10, step 332/574 completed (loss: 0.018538696691393852, acc: 1.0)
[2024-11-13 05:51:32,732][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:32,985][root][INFO] - Training Epoch: 10/10, step 333/574 completed (loss: 0.01832503452897072, acc: 1.0)
[2024-11-13 05:51:33,111][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:33,361][root][INFO] - Training Epoch: 10/10, step 334/574 completed (loss: 0.11048977822065353, acc: 0.9666666388511658)
[2024-11-13 05:51:33,474][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:33,730][root][INFO] - Training Epoch: 10/10, step 335/574 completed (loss: 0.014451462775468826, acc: 1.0)
[2024-11-13 05:51:33,844][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:34,089][root][INFO] - Training Epoch: 10/10, step 336/574 completed (loss: 0.18278981745243073, acc: 0.9599999785423279)
[2024-11-13 05:51:34,187][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:34,428][root][INFO] - Training Epoch: 10/10, step 337/574 completed (loss: 0.288371741771698, acc: 0.9080459475517273)
[2024-11-13 05:51:34,564][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:34,821][root][INFO] - Training Epoch: 10/10, step 338/574 completed (loss: 0.2863690257072449, acc: 0.9042553305625916)
[2024-11-13 05:51:34,931][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:35,174][root][INFO] - Training Epoch: 10/10, step 339/574 completed (loss: 0.2871730625629425, acc: 0.8795180916786194)
[2024-11-13 05:51:35,298][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:35,550][root][INFO] - Training Epoch: 10/10, step 340/574 completed (loss: 0.001645982381887734, acc: 1.0)
[2024-11-13 05:51:35,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:35,910][root][INFO] - Training Epoch: 10/10, step 341/574 completed (loss: 0.0033914041705429554, acc: 1.0)
[2024-11-13 05:51:36,027][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:36,252][root][INFO] - Training Epoch: 10/10, step 342/574 completed (loss: 0.08156692236661911, acc: 0.9759036302566528)
[2024-11-13 05:51:36,370][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:36,641][root][INFO] - Training Epoch: 10/10, step 343/574 completed (loss: 0.13503944873809814, acc: 0.9811320900917053)
[2024-11-13 05:51:36,758][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:36,981][root][INFO] - Training Epoch: 10/10, step 344/574 completed (loss: 0.03169211372733116, acc: 0.9873417615890503)
[2024-11-13 05:51:37,097][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:37,353][root][INFO] - Training Epoch: 10/10, step 345/574 completed (loss: 0.021387392655014992, acc: 0.9803921580314636)
[2024-11-13 05:51:37,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:37,722][root][INFO] - Training Epoch: 10/10, step 346/574 completed (loss: 0.035446763038635254, acc: 0.9850746393203735)
[2024-11-13 05:51:37,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:38,085][root][INFO] - Training Epoch: 10/10, step 347/574 completed (loss: 0.004147546365857124, acc: 1.0)
[2024-11-13 05:51:38,144][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:38,378][root][INFO] - Training Epoch: 10/10, step 348/574 completed (loss: 0.012090018019080162, acc: 1.0)
[2024-11-13 05:51:38,532][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:38,810][root][INFO] - Training Epoch: 10/10, step 349/574 completed (loss: 0.07333579659461975, acc: 0.9722222089767456)
[2024-11-13 05:51:38,893][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:39,157][root][INFO] - Training Epoch: 10/10, step 350/574 completed (loss: 0.09370490163564682, acc: 0.9534883499145508)
[2024-11-13 05:51:39,282][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:39,517][root][INFO] - Training Epoch: 10/10, step 351/574 completed (loss: 0.026395531371235847, acc: 1.0)
[2024-11-13 05:51:39,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:39,924][root][INFO] - Training Epoch: 10/10, step 352/574 completed (loss: 0.1534060835838318, acc: 0.9777777791023254)
[2024-11-13 05:51:40,047][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:40,299][root][INFO] - Training Epoch: 10/10, step 353/574 completed (loss: 0.0009987218072637916, acc: 1.0)
[2024-11-13 05:51:40,421][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:40,657][root][INFO] - Training Epoch: 10/10, step 354/574 completed (loss: 0.026621924713253975, acc: 1.0)
[2024-11-13 05:51:40,765][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:41,016][root][INFO] - Training Epoch: 10/10, step 355/574 completed (loss: 0.21587136387825012, acc: 0.9230769276618958)
[2024-11-13 05:51:41,176][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:41,532][root][INFO] - Training Epoch: 10/10, step 356/574 completed (loss: 0.14801350235939026, acc: 0.947826087474823)
[2024-11-13 05:51:41,655][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:41,893][root][INFO] - Training Epoch: 10/10, step 357/574 completed (loss: 0.10655824095010757, acc: 0.945652186870575)
[2024-11-13 05:51:41,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:42,204][root][INFO] - Training Epoch: 10/10, step 358/574 completed (loss: 0.12317008525133133, acc: 0.9591836929321289)
[2024-11-13 05:51:42,280][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:42,497][root][INFO] - Training Epoch: 10/10, step 359/574 completed (loss: 0.0008792357402853668, acc: 1.0)
[2024-11-13 05:51:42,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:42,853][root][INFO] - Training Epoch: 10/10, step 360/574 completed (loss: 0.001643782714381814, acc: 1.0)
[2024-11-13 05:51:42,990][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:43,270][root][INFO] - Training Epoch: 10/10, step 361/574 completed (loss: 0.11956283450126648, acc: 0.9512194991111755)
[2024-11-13 05:51:43,373][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:43,616][root][INFO] - Training Epoch: 10/10, step 362/574 completed (loss: 0.15522627532482147, acc: 0.9555555582046509)
[2024-11-13 05:51:43,706][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:43,933][root][INFO] - Training Epoch: 10/10, step 363/574 completed (loss: 0.03177153319120407, acc: 0.9868420958518982)
[2024-11-13 05:51:44,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:44,263][root][INFO] - Training Epoch: 10/10, step 364/574 completed (loss: 0.06278736144304276, acc: 0.9756097793579102)
[2024-11-13 05:51:44,366][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:44,611][root][INFO] - Training Epoch: 10/10, step 365/574 completed (loss: 0.019631920382380486, acc: 1.0)
[2024-11-13 05:51:44,714][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:44,940][root][INFO] - Training Epoch: 10/10, step 366/574 completed (loss: 0.0011016727657988667, acc: 1.0)
[2024-11-13 05:51:45,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:45,246][root][INFO] - Training Epoch: 10/10, step 367/574 completed (loss: 0.042006682604551315, acc: 0.95652174949646)
[2024-11-13 05:51:45,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:45,595][root][INFO] - Training Epoch: 10/10, step 368/574 completed (loss: 0.0025260162074118853, acc: 1.0)
[2024-11-13 05:51:45,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:45,933][root][INFO] - Training Epoch: 10/10, step 369/574 completed (loss: 0.05463414266705513, acc: 0.96875)
[2024-11-13 05:51:46,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:46,551][root][INFO] - Training Epoch: 10/10, step 370/574 completed (loss: 0.28313538432121277, acc: 0.8909090757369995)
[2024-11-13 05:51:46,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:47,445][root][INFO] - Training Epoch: 10/10, step 371/574 completed (loss: 0.13654005527496338, acc: 0.9622641801834106)
[2024-11-13 05:51:47,592][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:47,868][root][INFO] - Training Epoch: 10/10, step 372/574 completed (loss: 0.048846323043107986, acc: 0.9777777791023254)
[2024-11-13 05:51:47,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:48,207][root][INFO] - Training Epoch: 10/10, step 373/574 completed (loss: 0.008258914574980736, acc: 1.0)
[2024-11-13 05:51:48,323][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:48,555][root][INFO] - Training Epoch: 10/10, step 374/574 completed (loss: 0.015947332605719566, acc: 1.0)
[2024-11-13 05:51:48,677][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:48,926][root][INFO] - Training Epoch: 10/10, step 375/574 completed (loss: 0.0015108580701053143, acc: 1.0)
[2024-11-13 05:51:49,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:49,258][root][INFO] - Training Epoch: 10/10, step 376/574 completed (loss: 0.0011938705574721098, acc: 1.0)
[2024-11-13 05:51:49,360][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:49,648][root][INFO] - Training Epoch: 10/10, step 377/574 completed (loss: 0.013393346220254898, acc: 1.0)
[2024-11-13 05:51:49,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:50,042][root][INFO] - Training Epoch: 10/10, step 378/574 completed (loss: 0.02005627378821373, acc: 0.9894737005233765)
[2024-11-13 05:51:50,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:50,625][root][INFO] - Training Epoch: 10/10, step 379/574 completed (loss: 0.21953240036964417, acc: 0.9640718698501587)
[2024-11-13 05:51:50,762][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:51,025][root][INFO] - Training Epoch: 10/10, step 380/574 completed (loss: 0.17121084034442902, acc: 0.9548872113227844)
[2024-11-13 05:51:51,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:52,349][root][INFO] - Training Epoch: 10/10, step 381/574 completed (loss: 0.3783095180988312, acc: 0.893048107624054)
[2024-11-13 05:51:52,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:52,922][root][INFO] - Training Epoch: 10/10, step 382/574 completed (loss: 0.04717022180557251, acc: 0.9909909963607788)
[2024-11-13 05:51:53,009][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:53,288][root][INFO] - Training Epoch: 10/10, step 383/574 completed (loss: 0.0029733791016042233, acc: 1.0)
[2024-11-13 05:51:53,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:53,604][root][INFO] - Training Epoch: 10/10, step 384/574 completed (loss: 0.01575675792992115, acc: 1.0)
[2024-11-13 05:51:53,690][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:53,866][root][INFO] - Training Epoch: 10/10, step 385/574 completed (loss: 0.00689128739759326, acc: 1.0)
[2024-11-13 05:51:53,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:54,170][root][INFO] - Training Epoch: 10/10, step 386/574 completed (loss: 0.056679144501686096, acc: 0.9444444179534912)
[2024-11-13 05:51:54,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:54,543][root][INFO] - Training Epoch: 10/10, step 387/574 completed (loss: 0.0011782963993027806, acc: 1.0)
[2024-11-13 05:51:54,652][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:54,916][root][INFO] - Training Epoch: 10/10, step 388/574 completed (loss: 0.004209805745631456, acc: 1.0)
[2024-11-13 05:51:55,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:55,292][root][INFO] - Training Epoch: 10/10, step 389/574 completed (loss: 0.000974946771748364, acc: 1.0)
[2024-11-13 05:51:55,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:55,673][root][INFO] - Training Epoch: 10/10, step 390/574 completed (loss: 0.0876564309000969, acc: 0.9523809552192688)
[2024-11-13 05:51:55,785][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:56,023][root][INFO] - Training Epoch: 10/10, step 391/574 completed (loss: 0.12284474819898605, acc: 0.9629629850387573)
[2024-11-13 05:51:56,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:56,379][root][INFO] - Training Epoch: 10/10, step 392/574 completed (loss: 0.17956048250198364, acc: 0.9417475461959839)
[2024-11-13 05:51:56,516][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:56,912][root][INFO] - Training Epoch: 10/10, step 393/574 completed (loss: 0.38299840688705444, acc: 0.8970588445663452)
[2024-11-13 05:51:57,025][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:57,306][root][INFO] - Training Epoch: 10/10, step 394/574 completed (loss: 0.19684657454490662, acc: 0.9266666769981384)
[2024-11-13 05:51:57,415][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:57,683][root][INFO] - Training Epoch: 10/10, step 395/574 completed (loss: 0.2727859616279602, acc: 0.9027777910232544)
[2024-11-13 05:51:57,813][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:58,066][root][INFO] - Training Epoch: 10/10, step 396/574 completed (loss: 0.36906898021698, acc: 0.9069767594337463)
[2024-11-13 05:51:58,165][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:58,450][root][INFO] - Training Epoch: 10/10, step 397/574 completed (loss: 0.053908463567495346, acc: 0.9583333134651184)
[2024-11-13 05:51:58,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:58,803][root][INFO] - Training Epoch: 10/10, step 398/574 completed (loss: 0.03202879801392555, acc: 1.0)
[2024-11-13 05:51:58,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:59,188][root][INFO] - Training Epoch: 10/10, step 399/574 completed (loss: 0.005599158816039562, acc: 1.0)
[2024-11-13 05:51:59,387][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:51:59,721][root][INFO] - Training Epoch: 10/10, step 400/574 completed (loss: 0.07406743615865707, acc: 0.9852941036224365)
[2024-11-13 05:51:59,803][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:00,043][root][INFO] - Training Epoch: 10/10, step 401/574 completed (loss: 0.15385107696056366, acc: 0.9466666579246521)
[2024-11-13 05:52:00,142][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:00,355][root][INFO] - Training Epoch: 10/10, step 402/574 completed (loss: 0.11703849583864212, acc: 0.9696969985961914)
[2024-11-13 05:52:00,472][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:00,725][root][INFO] - Training Epoch: 10/10, step 403/574 completed (loss: 0.050560932606458664, acc: 1.0)
[2024-11-13 05:52:00,830][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:01,085][root][INFO] - Training Epoch: 10/10, step 404/574 completed (loss: 0.30971235036849976, acc: 0.9677419066429138)
[2024-11-13 05:52:01,209][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:01,482][root][INFO] - Training Epoch: 10/10, step 405/574 completed (loss: 0.01879439689218998, acc: 1.0)
[2024-11-13 05:52:01,595][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:01,854][root][INFO] - Training Epoch: 10/10, step 406/574 completed (loss: 0.002953906310722232, acc: 1.0)
[2024-11-13 05:52:01,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:02,225][root][INFO] - Training Epoch: 10/10, step 407/574 completed (loss: 0.036578066647052765, acc: 1.0)
[2024-11-13 05:52:02,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:02,525][root][INFO] - Training Epoch: 10/10, step 408/574 completed (loss: 0.028107348829507828, acc: 0.9629629850387573)
[2024-11-13 05:52:02,616][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:02,846][root][INFO] - Training Epoch: 10/10, step 409/574 completed (loss: 0.10209954530000687, acc: 0.9615384340286255)
[2024-11-13 05:52:02,970][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:03,212][root][INFO] - Training Epoch: 10/10, step 410/574 completed (loss: 0.0061757913790643215, acc: 1.0)
[2024-11-13 05:52:03,945][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:04,248][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:04,601][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:04,927][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:05,207][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:05,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:05,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:06,116][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:06,467][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:06,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:07,119][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:07,463][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:07,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:08,131][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:08,477][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:08,879][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:09,234][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:09,586][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:09,839][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:10,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:10,521][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:10,786][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:11,068][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:11,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:11,716][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:12,189][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:12,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:12,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:13,333][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:13,748][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:14,102][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:14,392][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:14,792][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:15,152][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:15,444][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:15,742][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:16,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:16,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:16,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:17,212][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:17,547][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:17,949][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:18,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:18,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:19,008][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:19,381][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:19,729][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:20,089][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:20,403][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:20,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:21,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:21,384][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:21,686][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:22,016][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:22,361][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:22,683][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:22,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:23,330][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:23,637][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:23,933][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:24,286][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:24,866][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:25,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:25,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:25,953][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:26,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:26,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:27,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:27,418][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:27,857][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:28,196][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:28,484][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:28,790][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:29,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:29,495][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:29,753][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:30,035][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:30,388][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:30,721][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:31,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:31,329][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:31,607][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:31,905][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:32,259][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:32,691][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:33,342][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.7152, device='cuda:0') eval_epoch_loss=tensor(0.9989, device='cuda:0') eval_epoch_acc=tensor(0.7997, device='cuda:0')
[2024-11-13 05:52:33,343][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:52:33,343][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:52:33,595][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_10_step_411_loss_0.9988546967506409/model.pt
[2024-11-13 05:52:33,598][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:52:33,664][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:33,937][root][INFO] - Training Epoch: 10/10, step 411/574 completed (loss: 0.0011737149907276034, acc: 1.0)
[2024-11-13 05:52:34,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:34,263][root][INFO] - Training Epoch: 10/10, step 412/574 completed (loss: 0.010099273175001144, acc: 1.0)
[2024-11-13 05:52:34,350][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:34,597][root][INFO] - Training Epoch: 10/10, step 413/574 completed (loss: 0.11240166425704956, acc: 0.9696969985961914)
[2024-11-13 05:52:34,695][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:34,908][root][INFO] - Training Epoch: 10/10, step 414/574 completed (loss: 0.24943366646766663, acc: 0.9545454382896423)
[2024-11-13 05:52:35,033][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:35,297][root][INFO] - Training Epoch: 10/10, step 415/574 completed (loss: 0.11683318018913269, acc: 0.9607843160629272)
[2024-11-13 05:52:35,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:35,678][root][INFO] - Training Epoch: 10/10, step 416/574 completed (loss: 0.17716151475906372, acc: 0.9615384340286255)
[2024-11-13 05:52:35,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:36,045][root][INFO] - Training Epoch: 10/10, step 417/574 completed (loss: 0.04033851623535156, acc: 1.0)
[2024-11-13 05:52:36,155][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:36,399][root][INFO] - Training Epoch: 10/10, step 418/574 completed (loss: 0.03359701484441757, acc: 0.9750000238418579)
[2024-11-13 05:52:36,479][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:36,715][root][INFO] - Training Epoch: 10/10, step 419/574 completed (loss: 0.016596581786870956, acc: 1.0)
[2024-11-13 05:52:36,825][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:37,050][root][INFO] - Training Epoch: 10/10, step 420/574 completed (loss: 0.0049879057332873344, acc: 1.0)
[2024-11-13 05:52:37,162][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:37,398][root][INFO] - Training Epoch: 10/10, step 421/574 completed (loss: 0.0480472557246685, acc: 0.9666666388511658)
[2024-11-13 05:52:37,492][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:37,724][root][INFO] - Training Epoch: 10/10, step 422/574 completed (loss: 0.009731089696288109, acc: 1.0)
[2024-11-13 05:52:37,836][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:38,121][root][INFO] - Training Epoch: 10/10, step 423/574 completed (loss: 0.05487838387489319, acc: 0.9722222089767456)
[2024-11-13 05:52:38,237][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:38,458][root][INFO] - Training Epoch: 10/10, step 424/574 completed (loss: 0.03459276631474495, acc: 1.0)
[2024-11-13 05:52:38,554][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:38,809][root][INFO] - Training Epoch: 10/10, step 425/574 completed (loss: 0.020362867042422295, acc: 1.0)
[2024-11-13 05:52:38,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:39,184][root][INFO] - Training Epoch: 10/10, step 426/574 completed (loss: 0.003491308307275176, acc: 1.0)
[2024-11-13 05:52:39,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:39,566][root][INFO] - Training Epoch: 10/10, step 427/574 completed (loss: 0.037978094071149826, acc: 1.0)
[2024-11-13 05:52:39,671][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:39,933][root][INFO] - Training Epoch: 10/10, step 428/574 completed (loss: 0.10190289467573166, acc: 0.9629629850387573)
[2024-11-13 05:52:40,036][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:40,263][root][INFO] - Training Epoch: 10/10, step 429/574 completed (loss: 0.05648872256278992, acc: 0.95652174949646)
[2024-11-13 05:52:40,348][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:40,633][root][INFO] - Training Epoch: 10/10, step 430/574 completed (loss: 0.0017416595946997404, acc: 1.0)
[2024-11-13 05:52:40,722][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:40,943][root][INFO] - Training Epoch: 10/10, step 431/574 completed (loss: 0.008148287422955036, acc: 1.0)
[2024-11-13 05:52:41,021][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:41,230][root][INFO] - Training Epoch: 10/10, step 432/574 completed (loss: 0.06068949028849602, acc: 0.95652174949646)
[2024-11-13 05:52:41,335][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:41,585][root][INFO] - Training Epoch: 10/10, step 433/574 completed (loss: 0.13463684916496277, acc: 0.9444444179534912)
[2024-11-13 05:52:41,715][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:41,959][root][INFO] - Training Epoch: 10/10, step 434/574 completed (loss: 0.01751035265624523, acc: 1.0)
[2024-11-13 05:52:42,029][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:42,307][root][INFO] - Training Epoch: 10/10, step 435/574 completed (loss: 0.006977423559874296, acc: 1.0)
[2024-11-13 05:52:42,422][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:42,668][root][INFO] - Training Epoch: 10/10, step 436/574 completed (loss: 0.12931086122989655, acc: 0.9722222089767456)
[2024-11-13 05:52:42,789][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:43,044][root][INFO] - Training Epoch: 10/10, step 437/574 completed (loss: 0.010480226017534733, acc: 1.0)
[2024-11-13 05:52:43,160][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:43,405][root][INFO] - Training Epoch: 10/10, step 438/574 completed (loss: 0.01299221906810999, acc: 1.0)
[2024-11-13 05:52:43,508][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:43,793][root][INFO] - Training Epoch: 10/10, step 439/574 completed (loss: 0.056426145136356354, acc: 0.9743589758872986)
[2024-11-13 05:52:43,937][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:44,272][root][INFO] - Training Epoch: 10/10, step 440/574 completed (loss: 0.17126215994358063, acc: 0.9545454382896423)
[2024-11-13 05:52:44,544][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:45,051][root][INFO] - Training Epoch: 10/10, step 441/574 completed (loss: 0.5870844125747681, acc: 0.8320000171661377)
[2024-11-13 05:52:45,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:45,454][root][INFO] - Training Epoch: 10/10, step 442/574 completed (loss: 0.4445568919181824, acc: 0.8790322542190552)
[2024-11-13 05:52:45,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:46,101][root][INFO] - Training Epoch: 10/10, step 443/574 completed (loss: 0.34873032569885254, acc: 0.89552241563797)
[2024-11-13 05:52:46,177][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:46,445][root][INFO] - Training Epoch: 10/10, step 444/574 completed (loss: 0.06697340309619904, acc: 0.9811320900917053)
[2024-11-13 05:52:46,569][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:46,865][root][INFO] - Training Epoch: 10/10, step 445/574 completed (loss: 0.01108123641461134, acc: 1.0)
[2024-11-13 05:52:46,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:47,169][root][INFO] - Training Epoch: 10/10, step 446/574 completed (loss: 0.0692470520734787, acc: 0.95652174949646)
[2024-11-13 05:52:47,265][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:47,509][root][INFO] - Training Epoch: 10/10, step 447/574 completed (loss: 0.021541688591241837, acc: 1.0)
[2024-11-13 05:52:47,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:47,805][root][INFO] - Training Epoch: 10/10, step 448/574 completed (loss: 0.06618048995733261, acc: 1.0)
[2024-11-13 05:52:47,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:48,196][root][INFO] - Training Epoch: 10/10, step 449/574 completed (loss: 0.018671950325369835, acc: 1.0)
[2024-11-13 05:52:48,293][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:48,509][root][INFO] - Training Epoch: 10/10, step 450/574 completed (loss: 0.016557469964027405, acc: 1.0)
[2024-11-13 05:52:48,599][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:48,834][root][INFO] - Training Epoch: 10/10, step 451/574 completed (loss: 0.11411372572183609, acc: 0.97826087474823)
[2024-11-13 05:52:48,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:49,213][root][INFO] - Training Epoch: 10/10, step 452/574 completed (loss: 0.09724642336368561, acc: 0.9743589758872986)
[2024-11-13 05:52:49,313][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:49,561][root][INFO] - Training Epoch: 10/10, step 453/574 completed (loss: 0.11117034405469894, acc: 0.9605262875556946)
[2024-11-13 05:52:49,693][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:49,953][root][INFO] - Training Epoch: 10/10, step 454/574 completed (loss: 0.03888709098100662, acc: 1.0)
[2024-11-13 05:52:50,057][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:50,251][root][INFO] - Training Epoch: 10/10, step 455/574 completed (loss: 0.06983385235071182, acc: 0.9696969985961914)
[2024-11-13 05:52:50,340][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:50,584][root][INFO] - Training Epoch: 10/10, step 456/574 completed (loss: 0.1569472849369049, acc: 0.938144326210022)
[2024-11-13 05:52:50,685][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:50,925][root][INFO] - Training Epoch: 10/10, step 457/574 completed (loss: 0.08450736850500107, acc: 0.9714285731315613)
[2024-11-13 05:52:51,028][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:51,302][root][INFO] - Training Epoch: 10/10, step 458/574 completed (loss: 0.2303982377052307, acc: 0.9418604373931885)
[2024-11-13 05:52:51,379][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:51,631][root][INFO] - Training Epoch: 10/10, step 459/574 completed (loss: 0.09719350188970566, acc: 0.9285714030265808)
[2024-11-13 05:52:51,740][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:51,964][root][INFO] - Training Epoch: 10/10, step 460/574 completed (loss: 0.09242785722017288, acc: 0.9753086566925049)
[2024-11-13 05:52:52,039][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:52,251][root][INFO] - Training Epoch: 10/10, step 461/574 completed (loss: 0.057112038135528564, acc: 0.9722222089767456)
[2024-11-13 05:52:52,337][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:52,590][root][INFO] - Training Epoch: 10/10, step 462/574 completed (loss: 0.027811085805296898, acc: 1.0)
[2024-11-13 05:52:52,698][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:52,970][root][INFO] - Training Epoch: 10/10, step 463/574 completed (loss: 0.027034349739551544, acc: 1.0)
[2024-11-13 05:52:53,118][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:53,371][root][INFO] - Training Epoch: 10/10, step 464/574 completed (loss: 0.060562290251255035, acc: 0.95652174949646)
[2024-11-13 05:52:53,503][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:53,751][root][INFO] - Training Epoch: 10/10, step 465/574 completed (loss: 0.06856302171945572, acc: 0.976190447807312)
[2024-11-13 05:52:53,875][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:54,144][root][INFO] - Training Epoch: 10/10, step 466/574 completed (loss: 0.17024223506450653, acc: 0.9156626462936401)
[2024-11-13 05:52:54,268][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:54,529][root][INFO] - Training Epoch: 10/10, step 467/574 completed (loss: 0.08110073208808899, acc: 0.9639639854431152)
[2024-11-13 05:52:54,640][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:54,878][root][INFO] - Training Epoch: 10/10, step 468/574 completed (loss: 0.09623150527477264, acc: 0.9805825352668762)
[2024-11-13 05:52:54,998][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:55,250][root][INFO] - Training Epoch: 10/10, step 469/574 completed (loss: 0.11847841739654541, acc: 0.9756097793579102)
[2024-11-13 05:52:55,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:55,554][root][INFO] - Training Epoch: 10/10, step 470/574 completed (loss: 0.05056120082736015, acc: 0.9583333134651184)
[2024-11-13 05:52:55,650][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:55,882][root][INFO] - Training Epoch: 10/10, step 471/574 completed (loss: 0.29291537404060364, acc: 0.8928571343421936)
[2024-11-13 05:52:56,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:56,317][root][INFO] - Training Epoch: 10/10, step 472/574 completed (loss: 0.20557901263237, acc: 0.9313725233078003)
[2024-11-13 05:52:56,416][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:56,682][root][INFO] - Training Epoch: 10/10, step 473/574 completed (loss: 0.38472527265548706, acc: 0.847161591053009)
[2024-11-13 05:52:56,807][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:57,024][root][INFO] - Training Epoch: 10/10, step 474/574 completed (loss: 0.14295579493045807, acc: 0.9375)
[2024-11-13 05:52:57,158][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:57,399][root][INFO] - Training Epoch: 10/10, step 475/574 completed (loss: 0.18485207855701447, acc: 0.9263803958892822)
[2024-11-13 05:52:57,490][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:57,747][root][INFO] - Training Epoch: 10/10, step 476/574 completed (loss: 0.3113315999507904, acc: 0.9280575513839722)
[2024-11-13 05:52:57,889][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:58,126][root][INFO] - Training Epoch: 10/10, step 477/574 completed (loss: 0.2710627615451813, acc: 0.909547746181488)
[2024-11-13 05:52:58,225][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:58,475][root][INFO] - Training Epoch: 10/10, step 478/574 completed (loss: 0.06221524998545647, acc: 0.9722222089767456)
[2024-11-13 05:52:58,593][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:58,829][root][INFO] - Training Epoch: 10/10, step 479/574 completed (loss: 0.07618554681539536, acc: 0.9696969985961914)
[2024-11-13 05:52:58,922][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:59,160][root][INFO] - Training Epoch: 10/10, step 480/574 completed (loss: 0.373931884765625, acc: 0.8888888955116272)
[2024-11-13 05:52:59,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:59,511][root][INFO] - Training Epoch: 10/10, step 481/574 completed (loss: 0.019322698935866356, acc: 1.0)
[2024-11-13 05:52:59,611][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:52:59,842][root][INFO] - Training Epoch: 10/10, step 482/574 completed (loss: 0.3131304085254669, acc: 0.8999999761581421)
[2024-11-13 05:52:59,946][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:00,215][root][INFO] - Training Epoch: 10/10, step 483/574 completed (loss: 0.283454954624176, acc: 0.931034505367279)
[2024-11-13 05:53:00,308][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:00,540][root][INFO] - Training Epoch: 10/10, step 484/574 completed (loss: 0.005516963079571724, acc: 1.0)
[2024-11-13 05:53:00,632][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:00,852][root][INFO] - Training Epoch: 10/10, step 485/574 completed (loss: 0.013412682339549065, acc: 1.0)
[2024-11-13 05:53:00,929][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:01,147][root][INFO] - Training Epoch: 10/10, step 486/574 completed (loss: 0.23673246800899506, acc: 0.9259259104728699)
[2024-11-13 05:53:01,223][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:01,430][root][INFO] - Training Epoch: 10/10, step 487/574 completed (loss: 0.3301520347595215, acc: 0.9523809552192688)
[2024-11-13 05:53:01,512][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:01,733][root][INFO] - Training Epoch: 10/10, step 488/574 completed (loss: 0.27050548791885376, acc: 0.9090909361839294)
[2024-11-13 05:53:01,828][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:02,068][root][INFO] - Training Epoch: 10/10, step 489/574 completed (loss: 0.20480979979038239, acc: 0.9230769276618958)
[2024-11-13 05:53:02,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:02,361][root][INFO] - Training Epoch: 10/10, step 490/574 completed (loss: 0.0378965362906456, acc: 1.0)
[2024-11-13 05:53:02,445][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:02,664][root][INFO] - Training Epoch: 10/10, step 491/574 completed (loss: 0.11264514178037643, acc: 1.0)
[2024-11-13 05:53:02,743][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:02,969][root][INFO] - Training Epoch: 10/10, step 492/574 completed (loss: 0.08001408725976944, acc: 0.9803921580314636)
[2024-11-13 05:53:03,046][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:03,266][root][INFO] - Training Epoch: 10/10, step 493/574 completed (loss: 0.08276683837175369, acc: 0.9655172228813171)
[2024-11-13 05:53:03,341][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:03,553][root][INFO] - Training Epoch: 10/10, step 494/574 completed (loss: 0.06252656877040863, acc: 0.9473684430122375)
[2024-11-13 05:53:03,626][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:03,841][root][INFO] - Training Epoch: 10/10, step 495/574 completed (loss: 0.09554651379585266, acc: 0.9473684430122375)
[2024-11-13 05:53:03,936][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:04,177][root][INFO] - Training Epoch: 10/10, step 496/574 completed (loss: 0.28144875168800354, acc: 0.8928571343421936)
[2024-11-13 05:53:04,272][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:04,554][root][INFO] - Training Epoch: 10/10, step 497/574 completed (loss: 0.1911727637052536, acc: 0.9550561904907227)
[2024-11-13 05:53:04,665][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:04,900][root][INFO] - Training Epoch: 10/10, step 498/574 completed (loss: 0.22712405025959015, acc: 0.9438202381134033)
[2024-11-13 05:53:04,992][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:05,218][root][INFO] - Training Epoch: 10/10, step 499/574 completed (loss: 0.5637649893760681, acc: 0.8297872543334961)
[2024-11-13 05:53:05,307][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:05,531][root][INFO] - Training Epoch: 10/10, step 500/574 completed (loss: 0.27065011858940125, acc: 0.9021739363670349)
[2024-11-13 05:53:05,604][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:05,825][root][INFO] - Training Epoch: 10/10, step 501/574 completed (loss: 0.06108254939317703, acc: 0.9599999785423279)
[2024-11-13 05:53:05,900][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:06,123][root][INFO] - Training Epoch: 10/10, step 502/574 completed (loss: 0.00228698062710464, acc: 1.0)
[2024-11-13 05:53:06,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:06,418][root][INFO] - Training Epoch: 10/10, step 503/574 completed (loss: 0.01374155841767788, acc: 1.0)
[2024-11-13 05:53:06,497][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:06,717][root][INFO] - Training Epoch: 10/10, step 504/574 completed (loss: 0.0646762028336525, acc: 0.9629629850387573)
[2024-11-13 05:53:06,800][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:07,035][root][INFO] - Training Epoch: 10/10, step 505/574 completed (loss: 0.14797347784042358, acc: 0.9811320900917053)
[2024-11-13 05:53:07,137][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:07,352][root][INFO] - Training Epoch: 10/10, step 506/574 completed (loss: 0.22584231197834015, acc: 0.931034505367279)
[2024-11-13 05:53:07,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:07,973][root][INFO] - Training Epoch: 10/10, step 507/574 completed (loss: 0.4818017780780792, acc: 0.8288288116455078)
[2024-11-13 05:53:08,075][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:08,409][root][INFO] - Training Epoch: 10/10, step 508/574 completed (loss: 0.27602675557136536, acc: 0.9577465057373047)
[2024-11-13 05:53:08,486][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:08,705][root][INFO] - Training Epoch: 10/10, step 509/574 completed (loss: 0.3987681269645691, acc: 0.949999988079071)
[2024-11-13 05:53:08,780][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:09,001][root][INFO] - Training Epoch: 10/10, step 510/574 completed (loss: 0.0064998809248209, acc: 1.0)
[2024-11-13 05:53:09,104][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:09,327][root][INFO] - Training Epoch: 10/10, step 511/574 completed (loss: 0.0326780341565609, acc: 1.0)
[2024-11-13 05:53:11,048][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:12,343][root][INFO] - Training Epoch: 10/10, step 512/574 completed (loss: 0.5338887572288513, acc: 0.8285714387893677)
[2024-11-13 05:53:12,560][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:13,123][root][INFO] - Training Epoch: 10/10, step 513/574 completed (loss: 0.1659601628780365, acc: 0.9603174328804016)
[2024-11-13 05:53:13,198][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:13,475][root][INFO] - Training Epoch: 10/10, step 514/574 completed (loss: 0.5192458033561707, acc: 0.9285714030265808)
[2024-11-13 05:53:13,579][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:13,811][root][INFO] - Training Epoch: 10/10, step 515/574 completed (loss: 0.027985481545329094, acc: 1.0)
[2024-11-13 05:53:13,985][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:14,498][root][INFO] - Training Epoch: 10/10, step 516/574 completed (loss: 0.06431880593299866, acc: 0.9722222089767456)
[2024-11-13 05:53:14,629][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:14,875][root][INFO] - Training Epoch: 10/10, step 517/574 completed (loss: 0.0006531024700962007, acc: 1.0)
[2024-11-13 05:53:14,984][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:15,211][root][INFO] - Training Epoch: 10/10, step 518/574 completed (loss: 0.027434149757027626, acc: 1.0)
[2024-11-13 05:53:15,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:15,575][root][INFO] - Training Epoch: 10/10, step 519/574 completed (loss: 0.01281878910958767, acc: 1.0)
[2024-11-13 05:53:15,673][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:15,924][root][INFO] - Training Epoch: 10/10, step 520/574 completed (loss: 0.07010913640260696, acc: 0.9629629850387573)
[2024-11-13 05:53:16,211][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:16,949][root][INFO] - Training Epoch: 10/10, step 521/574 completed (loss: 0.4460655450820923, acc: 0.8686440587043762)
[2024-11-13 05:53:17,041][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:17,297][root][INFO] - Training Epoch: 10/10, step 522/574 completed (loss: 0.20366916060447693, acc: 0.9179104566574097)
[2024-11-13 05:53:17,393][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:17,659][root][INFO] - Training Epoch: 10/10, step 523/574 completed (loss: 0.09268058091402054, acc: 0.9781022071838379)
[2024-11-13 05:53:17,784][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:18,214][root][INFO] - Training Epoch: 10/10, step 524/574 completed (loss: 0.31252241134643555, acc: 0.9150000214576721)
[2024-11-13 05:53:18,289][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:18,527][root][INFO] - Training Epoch: 10/10, step 525/574 completed (loss: 0.031003545969724655, acc: 1.0)
[2024-11-13 05:53:18,633][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:18,863][root][INFO] - Training Epoch: 10/10, step 526/574 completed (loss: 0.10289009660482407, acc: 0.9615384340286255)
[2024-11-13 05:53:18,952][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:19,174][root][INFO] - Training Epoch: 10/10, step 527/574 completed (loss: 0.02159959450364113, acc: 1.0)
[2024-11-13 05:53:19,260][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:19,494][root][INFO] - Training Epoch: 10/10, step 528/574 completed (loss: 0.27510207891464233, acc: 0.9016393423080444)
[2024-11-13 05:53:19,588][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:19,817][root][INFO] - Training Epoch: 10/10, step 529/574 completed (loss: 0.09047199040651321, acc: 0.9661017060279846)
[2024-11-13 05:53:19,921][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:20,149][root][INFO] - Training Epoch: 10/10, step 530/574 completed (loss: 0.2949550151824951, acc: 0.9069767594337463)
[2024-11-13 05:53:20,231][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:20,457][root][INFO] - Training Epoch: 10/10, step 531/574 completed (loss: 0.24232730269432068, acc: 0.8863636255264282)
[2024-11-13 05:53:20,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:20,783][root][INFO] - Training Epoch: 10/10, step 532/574 completed (loss: 0.23823873698711395, acc: 0.9245283007621765)
[2024-11-13 05:53:20,851][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:21,061][root][INFO] - Training Epoch: 10/10, step 533/574 completed (loss: 0.10428816825151443, acc: 0.9772727489471436)
[2024-11-13 05:53:21,136][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:21,356][root][INFO] - Training Epoch: 10/10, step 534/574 completed (loss: 0.14208225905895233, acc: 0.9599999785423279)
[2024-11-13 05:53:21,437][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:21,648][root][INFO] - Training Epoch: 10/10, step 535/574 completed (loss: 0.17483089864253998, acc: 0.949999988079071)
[2024-11-13 05:53:21,726][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:21,949][root][INFO] - Training Epoch: 10/10, step 536/574 completed (loss: 0.006800239905714989, acc: 1.0)
[2024-11-13 05:53:22,058][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:22,334][root][INFO] - Training Epoch: 10/10, step 537/574 completed (loss: 0.07689037173986435, acc: 0.9846153855323792)
[2024-11-13 05:53:22,420][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:22,646][root][INFO] - Training Epoch: 10/10, step 538/574 completed (loss: 0.21232017874717712, acc: 0.953125)
[2024-11-13 05:53:22,744][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:23,032][root][INFO] - Training Epoch: 10/10, step 539/574 completed (loss: 0.21192370355129242, acc: 0.90625)
[2024-11-13 05:53:23,140][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:23,308][root][INFO] - Training Epoch: 10/10, step 540/574 completed (loss: 0.18682800233364105, acc: 0.9090909361839294)
[2024-11-13 05:53:23,419][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:23,640][root][INFO] - Training Epoch: 10/10, step 541/574 completed (loss: 0.04110683128237724, acc: 1.0)
[2024-11-13 05:53:23,728][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:23,955][root][INFO] - Training Epoch: 10/10, step 542/574 completed (loss: 0.016246559098362923, acc: 1.0)
[2024-11-13 05:53:24,031][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:24,245][root][INFO] - Training Epoch: 10/10, step 543/574 completed (loss: 0.019890405237674713, acc: 1.0)
[2024-11-13 05:53:24,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:24,546][root][INFO] - Training Epoch: 10/10, step 544/574 completed (loss: 0.06035316362977028, acc: 0.9666666388511658)
[2024-11-13 05:53:24,657][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:24,920][root][INFO] - Training Epoch: 10/10, step 545/574 completed (loss: 0.013513593934476376, acc: 1.0)
[2024-11-13 05:53:25,019][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:25,251][root][INFO] - Training Epoch: 10/10, step 546/574 completed (loss: 0.10956359654664993, acc: 0.9714285731315613)
[2024-11-13 05:53:25,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:25,614][root][INFO] - Training Epoch: 10/10, step 547/574 completed (loss: 0.042103081941604614, acc: 0.9736841917037964)
[2024-11-13 05:53:25,709][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:25,937][root][INFO] - Training Epoch: 10/10, step 548/574 completed (loss: 0.013515294529497623, acc: 1.0)
[2024-11-13 05:53:26,026][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:26,294][root][INFO] - Training Epoch: 10/10, step 549/574 completed (loss: 0.015422612428665161, acc: 1.0)
[2024-11-13 05:53:26,401][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:26,629][root][INFO] - Training Epoch: 10/10, step 550/574 completed (loss: 0.08613225817680359, acc: 0.9696969985961914)
[2024-11-13 05:53:26,723][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:26,952][root][INFO] - Training Epoch: 10/10, step 551/574 completed (loss: 0.012465013191103935, acc: 1.0)
[2024-11-13 05:53:27,032][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:27,253][root][INFO] - Training Epoch: 10/10, step 552/574 completed (loss: 0.054573047906160355, acc: 0.9714285731315613)
[2024-11-13 05:53:27,332][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:27,553][root][INFO] - Training Epoch: 10/10, step 553/574 completed (loss: 0.18635740876197815, acc: 0.9416058659553528)
[2024-11-13 05:53:28,297][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:28,670][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:29,084][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:29,457][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:29,710][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:30,139][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:30,571][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:30,907][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:31,182][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:31,568][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:31,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:32,409][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:32,727][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:32,983][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:33,371][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:33,696][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:34,020][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:34,347][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:34,788][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:35,083][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:35,356][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:35,681][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:35,959][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:36,326][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:36,643][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:37,006][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:37,369][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:37,751][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:38,200][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:38,600][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:38,896][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:39,172][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:39,550][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:39,861][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:40,169][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:40,456][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:40,775][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:41,077][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:41,476][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:41,770][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:42,143][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:42,489][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:42,752][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:43,043][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:43,429][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:43,816][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:44,153][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:44,528][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:44,798][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:45,088][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:45,465][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:45,764][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:46,191][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:46,582][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:46,926][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:47,305][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:47,594][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:47,877][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:48,233][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:48,534][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:48,918][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:49,455][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:49,854][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:50,261][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:50,555][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:50,947][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:51,258][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:51,608][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:52,013][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:52,518][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:52,897][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:53,281][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:53,596][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:53,909][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:54,241][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:54,603][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:54,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:55,181][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:55,542][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:55,895][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:56,206][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:56,561][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:56,919][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:57,294][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:57,684][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:58,379][slam_llm.utils.train_utils][INFO] -  eval_ppl=tensor(2.7751, device='cuda:0') eval_epoch_loss=tensor(1.0207, device='cuda:0') eval_epoch_acc=tensor(0.8014, device='cuda:0')
[2024-11-13 05:53:58,381][slam_llm.utils.train_utils][INFO] - we are about to save the PEFT modules
[2024-11-13 05:53:58,381][slam_llm.utils.checkpoint_handler][INFO] - --> saving model ...
[2024-11-13 05:53:58,690][slam_llm.utils.checkpoint_handler][INFO] - encoder saved at /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_1.0206900835037231/model.pt
[2024-11-13 05:53:58,693][slam_llm.utils.train_utils][INFO] - PEFT modules are saved in /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft directory
[2024-11-13 05:53:58,791][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:59,095][root][INFO] - Training Epoch: 10/10, step 554/574 completed (loss: 0.10267054289579391, acc: 0.9793103337287903)
[2024-11-13 05:53:59,173][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:59,396][root][INFO] - Training Epoch: 10/10, step 555/574 completed (loss: 0.2623797059059143, acc: 0.9357143044471741)
[2024-11-13 05:53:59,491][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:53:59,736][root][INFO] - Training Epoch: 10/10, step 556/574 completed (loss: 0.10797858238220215, acc: 0.9668874144554138)
[2024-11-13 05:53:59,838][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:00,104][root][INFO] - Training Epoch: 10/10, step 557/574 completed (loss: 0.056378673762083054, acc: 0.9914529919624329)
[2024-11-13 05:54:00,205][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:00,467][root][INFO] - Training Epoch: 10/10, step 558/574 completed (loss: 0.013387235812842846, acc: 1.0)
[2024-11-13 05:54:00,574][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:00,811][root][INFO] - Training Epoch: 10/10, step 559/574 completed (loss: 0.07405735552310944, acc: 0.9615384340286255)
[2024-11-13 05:54:00,917][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:01,164][root][INFO] - Training Epoch: 10/10, step 560/574 completed (loss: 0.004020096734166145, acc: 1.0)
[2024-11-13 05:54:01,250][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:01,517][root][INFO] - Training Epoch: 10/10, step 561/574 completed (loss: 0.012834849767386913, acc: 1.0)
[2024-11-13 05:54:01,630][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:01,872][root][INFO] - Training Epoch: 10/10, step 562/574 completed (loss: 0.10786309838294983, acc: 0.9666666388511658)
[2024-11-13 05:54:01,982][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:02,226][root][INFO] - Training Epoch: 10/10, step 563/574 completed (loss: 0.0865701362490654, acc: 0.9740259647369385)
[2024-11-13 05:54:02,322][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:02,546][root][INFO] - Training Epoch: 10/10, step 564/574 completed (loss: 0.11109649389982224, acc: 0.9583333134651184)
[2024-11-13 05:54:02,654][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:02,867][root][INFO] - Training Epoch: 10/10, step 565/574 completed (loss: 0.13935308158397675, acc: 0.931034505367279)
[2024-11-13 05:54:02,948][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:03,165][root][INFO] - Training Epoch: 10/10, step 566/574 completed (loss: 0.035768210887908936, acc: 0.988095223903656)
[2024-11-13 05:54:03,240][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:03,436][root][INFO] - Training Epoch: 10/10, step 567/574 completed (loss: 0.07354885339736938, acc: 0.9736841917037964)
[2024-11-13 05:54:03,514][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:03,737][root][INFO] - Training Epoch: 10/10, step 568/574 completed (loss: 0.008334506303071976, acc: 1.0)
[2024-11-13 05:54:03,892][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:04,159][root][INFO] - Training Epoch: 10/10, step 569/574 completed (loss: 0.15862329304218292, acc: 0.9411764740943909)
[2024-11-13 05:54:04,236][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:04,448][root][INFO] - Training Epoch: 10/10, step 570/574 completed (loss: 0.014738596975803375, acc: 1.0)
[2024-11-13 05:54:04,537][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:04,882][root][INFO] - Training Epoch: 10/10, step 571/574 completed (loss: 0.06932217627763748, acc: 0.9829059839248657)
[2024-11-13 05:54:04,986][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:05,208][root][INFO] - Training Epoch: 10/10, step 572/574 completed (loss: 0.30422061681747437, acc: 0.9132652878761292)
[2024-11-13 05:54:05,306][slam_llm.models.slam_model][INFO] - modality encoder
[2024-11-13 05:54:05,544][root][INFO] - Training Epoch: 10/10, step 573/574 completed (loss: 0.1658453494310379, acc: 0.9496855139732361)
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - Epoch 10: train_perplexity=1.1453, train_epoch_loss=0.1357, epoch time 350.8097891137004s
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - Max CUDA memory allocated was 13 GB
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - Max CUDA memory reserved was 20 GB
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - Peak active CUDA memory was 13 GB
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - Cuda Malloc retires : 28
[2024-11-13 05:54:06,073][slam_llm.utils.train_utils][INFO] - CPU Total Peak Memory consumed during the train (max): 6 GB
[2024-11-13 05:54:06,078][root][INFO] - Key: avg_train_prep, Value: 3.4093995094299316
[2024-11-13 05:54:06,079][root][INFO] - Key: avg_train_loss, Value: 0.7109953761100769
[2024-11-13 05:54:06,079][root][INFO] - Key: avg_train_acc, Value: 0.8179378509521484
[2024-11-13 05:54:06,080][root][INFO] - Key: avg_eval_prep, Value: 3.739410400390625
[2024-11-13 05:54:06,080][root][INFO] - Key: avg_eval_loss, Value: 1.131819248199463
[2024-11-13 05:54:06,080][root][INFO] - Key: avg_eval_acc, Value: 0.727729856967926
[2024-11-13 05:54:06,080][root][INFO] - Key: avg_epoch_time, Value: 355.072017236799
[2024-11-13 05:54:06,080][root][INFO] - Key: avg_checkpoint_time, Value: 0.3260482973884791
[2024-12-16 22:49:56,524][root][INFO] - train_config: {'model_name': 'asr', 'enable_ddp': False, 'enable_deepspeed': False, 'enable_fsdp': False, 'low_cpu_fsdp': False, 'run_validation': True, 'batch_size_training': 4, 'batching_strategy': 'custom', 'context_length': 4096, 'gradient_accumulation_steps': 1, 'num_epochs': 10, 'resume_step': 554, 'resume_epoch': 10, 'num_workers_dataloader': 1, 'warmup_steps': 1000, 'total_steps': 100000, 'validation_interval': 3000, 'lr': 0.0001, 'weight_decay': 0.0, 'gamma': 0.85, 'seed': 42, 'use_fp16': True, 'mixed_precision': True, 'val_batch_size': 4, 'use_peft': True, 'peft_config': {'peft_method': 'lora', 'r': 8, 'lora_alpha': 32, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'up_proj', 'gate_proj', 'down_proj'], 'bias': 'none', 'task_type': 'CAUSAL_LM', 'lora_dropout': 0.05, 'inference_mode': False}, 'output_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft', 'freeze_layers': False, 'num_freeze_layers': 1, 'quantization': False, 'one_gpu': False, 'save_model': True, 'dist_checkpoint_root_folder': 'PATH/to/save/FSDP/model', 'dist_checkpoint_folder': 'fine-tuned', 'save_optimizer': False, 'use_fast_kernels': False, 'run_test_during_validation': False, 'run_test_during_validation_file': 'test.wav', 'run_test_during_validation_prompt': '<|ASR|>', 'freeze_llm': False, 'freeze_encoder': True, 'freeze_encoder2': True, 'save_embedding': True}
[2024-12-16 22:49:56,524][root][INFO] - fsdp_config: {'mixed_precision': True, 'use_fp16': True, 'sharding_strategy': <ShardingStrategy.NO_SHARD: 3>, 'checkpoint_type': 'SHARDED_STATE_DICT', 'fsdp_activation_checkpointing': True, 'fsdp_cpu_offload': False, 'pure_bf16': False, 'optimizer': 'AdamW'}
[2024-12-16 22:49:56,524][root][INFO] - model_config: {'file': 'examples/asr_librispeech/model/slam_model_asr.py:model_factory', 'llm_name': 'llama32_1b', 'llm_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct', 'llm_type': 'decoder_only', 'llm_dim': 2048, 'llm_inference_config': 'test_config.json', 'encoder_name': 'wavlm', 'encoder_ds_rate': 2, 'encoder_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt', 'encoder_dim': 1024, 'encoder_projector': 'linear', 'encoder_projector_ds_rate': 5, 'qformer_layers': 8, 'modal': 'audio', 'normalize': True, 'encoder_type': 'finetune', 'encoder2_name': '', 'encoder2_dim': 1024, 'encoder2_path': ''}
[2024-12-16 22:49:56,524][root][INFO] - log_config: {'use_wandb': True, 'wandb_dir': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/wandb_log', 'wandb_entity_name': 'jindaz-work', 'wandb_project_name': 'SLAM-LLM', 'wandb_exp_name': 'psst_phoneme_wavlm_llama32_1b_linear_peft', 'log_file': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/log/2024-12-16_22-49-55.txt', 'log_interval': 5}
[2024-12-16 22:50:24,734][slam_llm.models.wavlm.WavLM][INFO] - WavLM Config: {'extractor_mode': 'layer_norm', 'encoder_layers': 24, 'encoder_embed_dim': 1024, 'encoder_ffn_embed_dim': 4096, 'encoder_attention_heads': 16, 'activation_fn': 'gelu', 'layer_norm_first': True, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'feature_grad_mult': 1.0, 'normalize': True, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'relative_position_embedding': True, 'num_buckets': 320, 'max_distance': 800, 'gru_rel_pos': True}
[2024-12-16 22:50:30,744][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 22:50:30,746][slam_llm.utils.train_utils][INFO] - --> wavlm has 315.45312 Million params

[2024-12-16 22:50:30,749][slam_llm.utils.train_utils][INFO] - --> Module wavlm
[2024-12-16 22:50:30,750][slam_llm.utils.train_utils][INFO] - --> wavlm has 0.0 Million params

[2024-12-16 22:50:40,973][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 22:50:40,975][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 1235.8144 Million params

[2024-12-16 22:50:40,976][slam_llm.models.slam_model][INFO] - setup peft...
[2024-12-16 22:50:41,448][slam_llm.utils.train_utils][INFO] - --> Module llama32_1b
[2024-12-16 22:50:41,450][slam_llm.utils.train_utils][INFO] - --> llama32_1b has 5.636096 Million params

[2024-12-16 22:50:41,591][slam_llm.utils.train_utils][INFO] - --> Module linear
[2024-12-16 22:50:41,591][slam_llm.utils.train_utils][INFO] - --> linear has 14.68416 Million params

[2024-12-16 22:50:41,592][slam_model_asr.py][INFO] - loading other parts from: /work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/psst_phoneme_wavlm_llama32_1b_linear_peft/asr_epoch_10_step_554_loss_1.0206900835037231/model.pt
[2024-12-16 22:50:41,799][slam_llm.utils.train_utils][INFO] - --> Model asr
[2024-12-16 22:50:41,804][slam_llm.utils.train_utils][INFO] - --> asr has 20.320256 Million params

[2024-12-16 22:50:41,818][root][INFO] - dataset_config: {'dataset': 'speech_dataset', 'file': 'src/slam_llm/datasets/speech_dataset.py:get_speech_dataset', 'train_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/train.jsonl', 'val_data_path': '/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/psst_phoneme/validation.jsonl', 'train_split': 'train', 'test_split': 'validation', 'prompt': None, 'data_path': None, 'max_words': None, 'max_mel': None, 'fix_length_audio': -1, 'inference_mode': False, 'input_type': 'raw', 'mel_size': 80, 'normalize': True}
[2024-12-16 22:50:46,022][root][INFO] - --> Training Set Length = 2298
[2024-12-16 22:50:46,044][root][INFO] - --> Validation Set Length = 341
[2024-12-16 22:50:46,045][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
[2024-12-16 22:50:46,047][slam_llm.utils.config_utils][INFO] - Using batching strategy: custom
