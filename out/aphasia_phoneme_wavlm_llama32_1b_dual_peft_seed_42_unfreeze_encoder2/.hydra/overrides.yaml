- ++model_config.llm_name=llama32_1b
- ++model_config.llm_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/Llama-3.2-1B-Instruct
- ++model_config.llm_dim=2048
- ++model_config.encoder_name=wavlm
- ++model_config.normalize=true
- ++dataset_config.normalize=true
- ++model_config.encoder_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/models/WavLM-Large.pt
- ++model_config.encoder2_name=w2v2
- ++model_config.encoder2_path=vitouphy/wav2vec2-xls-r-300m-timit-phoneme
- ++model_config.encoder_dim=1024
- ++model_config.encoder_projector=dual
- ++model_config.encoder_projector_ds_rate=5
- ++model_config.identifier=aphasia_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2
- ++dataset_config.dataset=speech_dataset
- ++dataset_config.train_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/aphasia_phoneme/train.jsonl
- ++dataset_config.file=src/slam_llm/datasets/speech_dataset.py:get_speech_dataset
- ++dataset_config.val_data_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/data/aphasia_phoneme/validation.jsonl
- ++dataset_config.input_type=raw
- ++train_config.model_name=asr
- ++train_config.num_epochs=2
- ++train_config.freeze_encoder=true
- ++train_config.freeze_encoder2=false
- ++train_config.freeze_llm=false
- ++train_config.batching_strategy=custom
- ++train_config.warmup_steps=1000
- ++train_config.total_steps=100000
- ++train_config.lr=1e-4
- ++train_config.validation_interval=3000
- ++train_config.batch_size_training=2
- ++train_config.val_batch_size=2
- ++train_config.num_workers_dataloader=1
- ++train_config.output_dir=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2
- ++train_config.use_fp16=true
- ++train_config.use_peft=true
- ++train_config.resume_epoch=1
- ++train_config.resume_step=47676
- ++log_config.use_wandb=true
- ++log_config.wandb_exp_name=aphasia_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2
- ++ckpt_path=/work/van-speech-nlp/jindaznb/jslpnb/mllm_experiments/slam-llm/out/aphasia_phoneme_wavlm_llama32_1b_dual_peft_seed_42_unfreeze_encoder2/asr_epoch_1_step_47676_loss_0.557376503944397/model.pt
- ++dataset_config.input_type=raw
- ++train_config.seed=42
